test_caching:
  llm:
    model: "openai/gpt-4o-mini"
    temperature: 0.1
    top_p: 0.3
    max_tokens: 100

  not_used_field: "xxx"

  use_prompt1:
  - role: user
    content: "Tell me a random joke"

  use_prompt_random:
  - role: system
    content: "Just provide a numeric answer"
  - role: user
    content: "Give me a random number between 1 and 3000000"

