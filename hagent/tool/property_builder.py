#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
property_builder.py
-------------------
Generate SystemVerilog properties (assert/assume/cover) from a CSV spec.

FIXES (Dec 2025, updated):
  - Use AST-derived ports JSON (<spec_top>_ports.json) if available (authoritative).
  - Correctly allow $rose/$fell/$stable/$changed/$past in identifier checks.
  - Prevent nested temporal operators: do NOT wrap a post that already contains '##' with another '##[1:$]'.
  - Avoid generating trivial (1'b1) properties for assume/assert unless explicitly intended (cover can use 1).
  - **NEW:** Do NOT generate "1 |-> ..." when CSV pre is empty/1; emit the post as a standalone property expr.
  - **NEW:** Repair broken CSV rows that embed implications inside post (e.g. "A |-> B") by moving A into pre.
  - **NEW:** If post contains temporal (##) and boolean mix with |/&/||/&&, rewrite to sequence operators "or/and"
           to avoid syntax errors like "!valid_i | ##1 !valid_i".
"""

from __future__ import annotations

import os
import re
import csv
import json
from pathlib import Path
from typing import List, Dict, Optional, Tuple

from hagent.tool.utils.clk_rst_utils import detect_clk_rst_for_top

try:
    from hagent.core.llm_wrap import LLM_wrap
except Exception:
    LLM_wrap = None


# -----------------------------------------------------------------------------
# Helpers
# -----------------------------------------------------------------------------
_ALLOWED_SVA_FUNCS = {'$stable', '$changed', '$past', '$rose', '$fell'}
_IMP_OPS = ('|->', '|=>')


def _strip_sv_comments(s: str) -> str:
    s = re.sub(r'//.*?$', '', s, flags=re.M)
    s = re.sub(r'/\*.*?\*/', '', s, flags=re.S)
    return s


def _load_ports_from_ports_json(candidate_paths: List[Path]) -> List[str]:
    """
    Load ports from <spec_top>_ports.json (generated by SpecBuilder).
    Expected format: list of objects with 'name'.
    """
    for p in candidate_paths:
        if not p or not p.exists():
            continue
        try:
            data = json.loads(p.read_text(encoding='utf-8'))
            if isinstance(data, list):
                names: List[str] = []
                for item in data:
                    if isinstance(item, dict) and item.get('name'):
                        names.append(str(item['name']).strip())
                # de-dup preserve order
                out: List[str] = []
                seen = set()
                for n in names:
                    if n and n not in seen:
                        out.append(n)
                        seen.add(n)
                if out:
                    return out
        except Exception:
            pass
    return []


def detect_top_ports_from_rtl(rtl_dir: str, top: str) -> List[str]:
    """
    Fallback: lightweight extraction from RTL headers if ports.json is missing.
    This is NOT authoritative for complex SV (imports/params/ifdefs).
    """
    rtl_dir_path = Path(rtl_dir)
    top_esc = re.escape(top)

    mod_re = re.compile(
        rf'\bmodule\s+{top_esc}\b[\s\S]*?\((?P<ports>[\s\S]*?)\)\s*;',
        re.MULTILINE,
    )

    for sv in rtl_dir_path.rglob('*'):
        if sv.suffix not in {'.sv', '.v', '.svh', '.vh'}:
            continue
        try:
            txt = sv.read_text(encoding='utf-8', errors='ignore')
        except Exception:
            continue

        m = mod_re.search(txt)
        if not m:
            continue

        port_block = _strip_sv_comments(m.group('ports') or '')

        parts: List[str] = []
        buf = []
        depth = 0
        for ch in port_block:
            if ch == '(':
                depth += 1
            elif ch == ')':
                depth = max(0, depth - 1)
            if ch == ',' and depth == 0:
                parts.append(''.join(buf).strip())
                buf = []
            else:
                buf.append(ch)
        if buf:
            parts.append(''.join(buf).strip())

        ports: List[str] = []
        for p in parts:
            if not p:
                continue
            p2 = re.sub(r'\[[^\]]+\]', ' ', p)
            toks = re.findall(r'\b[A-Za-z_]\w*\b', p2)
            if not toks:
                continue

            blacklist = {
                'input',
                'output',
                'inout',
                'wire',
                'logic',
                'reg',
                'signed',
                'unsigned',
                'parameter',
                'localparam',
                'typedef',
                'struct',
                'union',
                'enum',
            }
            name = None
            for t in reversed(toks):
                if t.lower() in blacklist:
                    continue
                name = t
                break
            if name and name not in ports:
                ports.append(name)

        if ports:
            return ports

    return []


def _is_trivial_true(expr: str) -> bool:
    e = (expr or '').strip()
    return e in {'1', "1'b1", "1'b01", "1'h1"}  # keep small set; conservative


def _split_first_implication(expr: str) -> Optional[Tuple[str, str, str]]:
    """
    Split "A |-> B" or "A |=> B" at the first occurrence.
    Returns (ante, op, cons) or None.
    """
    if not expr:
        return None
    for op in _IMP_OPS:
        idx = expr.find(op)
        if idx >= 0:
            ante = expr[:idx].strip()
            cons = expr[idx + len(op) :].strip()
            return ante, op, cons
    return None


def _rewrite_temporal_mix_to_sequence_ops(post: str) -> str:
    """
    If post contains temporal operator '##', then using boolean operators like
    '|', '||', '&', '&&' often creates illegal syntax (boolean vs sequence).
    In SVA, sequence OR/AND operators are 'or'/'and'. Convert spaced operators.
    """
    p = (post or '').strip()
    if '##' not in p:
        return p

    # Do not touch implications (handled elsewhere)
    if '|->' in p or '|=>' in p:
        return p

    # Replace logical/binary ops when they appear as separated tokens (with whitespace)
    # This avoids messing with bit-slices, concatenations, etc.
    p = re.sub(r'\s\|\|\s', ' or ', p)
    p = re.sub(r'\s\|\s', ' or ', p)
    p = re.sub(r'\s&&\s', ' and ', p)
    p = re.sub(r'\s&\s', ' and ', p)
    return p.strip()


# -----------------------------------------------------------------------------
# Property Builder
# -----------------------------------------------------------------------------
class PropertyBuilder:
    def __init__(
        self,
        spec_md: str,
        csv_path: str,
        rtl_dir: str,
        out_dir: str,
        llm_conf: Optional[str],
        design_top: Optional[str] = None,
    ):
        self.spec_md = os.path.abspath(spec_md)
        self.csv_path = os.path.abspath(csv_path)
        self.rtl_dir = os.path.abspath(rtl_dir)
        self.out_dir = os.path.abspath(out_dir)
        os.makedirs(self.out_dir, exist_ok=True)

        self.llm_conf = os.path.abspath(llm_conf) if llm_conf else None
        self.design_top = design_top

        self.llm = None
        if LLM_wrap and self.llm_conf and os.path.exists(self.llm_conf):
            print(f'[LLM] Using config: {self.llm_conf}')
            try:
                self.llm = LLM_wrap(
                    name='default',
                    conf_file=self.llm_conf,
                    log_file='property_llm.log',
                )
            except Exception as e:
                print(f'[WARN] LLM init failed: {e}. Falling back to rule-based generation.')
                self.llm = None
        else:
            print('[WARN] LLM disabled (LLM_wrap missing or llm_conf missing). Using rule-based generation.')

    # ------------------------------------------------------------------
    @staticmethod
    def _fmt(s: Optional[str]) -> str:
        if s is None:
            return ''
        return str(s).replace('{', '{{').replace('}', '}}')

    # ------------------------------------------------------------------
    def _read_csv_rows(self) -> List[Dict[str, str]]:
        rows: List[Dict[str, str]] = []
        with open(self.csv_path, 'r', encoding='utf-8', errors='ignore') as f:
            reader = csv.DictReader(f)
            for r in reader:
                clean = {(k or '').strip(): self._fmt((v or '').strip()) for k, v in r.items() if k is not None}
                rows.append(clean)
        print(f'[DEBUG] Loaded {len(rows)} CSV rows.')
        return rows

    # ------------------------------------------------------------------
    def _read_markdown(self) -> str:
        try:
            txt = Path(self.spec_md).read_text(encoding='utf-8', errors='ignore')
        except Exception:
            txt = ''
        return self._fmt(txt)

    # ------------------------------------------------------------------
    def _infer_spec_top(self) -> str:
        stem = Path(self.spec_md).stem
        if '_spec' in stem:
            return stem.split('_spec')[0]
        return stem

    # ------------------------------------------------------------------
    def _find_clk_rst(self) -> Tuple[str, str, str, str]:
        spec_top = self._infer_spec_top()
        clk_top = self.design_top or spec_top

        cr = detect_clk_rst_for_top(Path(self.rtl_dir), clk_top)
        if isinstance(cr, (list, tuple)) and len(cr) >= 3:
            clk, rst, rst_expr = cr[0], cr[1], cr[2]
        else:
            raise ValueError(f'Unexpected return from detect_clk_rst_for_top: {cr}')

        if rst_expr and str(rst_expr).strip():
            disable_cond = str(rst_expr).strip()
        else:
            disable_cond = f'!{rst}' if (rst.endswith('_ni') or rst.endswith('ni') or rst.endswith('_n')) else rst

        print(f'[INFO] Clock={clk}, Reset={rst}, disable iff ({disable_cond}) (detected from top="{clk_top}")')
        return clk, rst, disable_cond, spec_top

    # ------------------------------------------------------------------
    @staticmethod
    def _extract_sv_code(text: str) -> str:
        if not text:
            return ''
        m = re.search(r'```(?:systemverilog|sv|verilog)?\s*([\s\S]*?)```', text, re.I)
        if m:
            return m.group(1).strip()
        return text.strip()

    # ------------------------------------------------------------------
    @staticmethod
    def _normalize_csv_expr(expr: str, ports: List[str]) -> str:
        e = (expr or '').strip()
        if not e:
            return ''

        if e == '1':
            return "1'b1"
        if e == '0':
            return "1'b0"

        # Simple english normalizations (keep minimal)
        m = re.match(r'^([A-Za-z_]\w*)\s+stable\s+for\s+1\s+cycle$', e, re.I)
        if m:
            return f'$stable({m.group(1)})'

        m = re.match(r'^([A-Za-z_]\w*)\s+changes$', e, re.I)
        if m:
            return f'$changed({m.group(1)})'

        if e.lower().endswith(' changes'):
            sig = e[:-8].strip()
            if sig in ports:
                return f'$changed({sig})'

        m = re.match(r'^stable\(([\s\S]+)\)$', e, re.I)
        if m:
            return f'$stable({m.group(1).strip()})'

        return e

    # ------------------------------------------------------------------
    @staticmethod
    def _expr_uses_only_ports(expr: str, ports: List[str]) -> bool:
        """
        Allow:
          - ports
          - dotted field names (anything after a '.')
          - $rose/$fell/$stable/$changed/$past
          - SV keywords/operators tokens that appear as identifiers
        """
        if not (expr or '').strip():
            return False

        allowed_ids = set(ports) | {
            'if',
            'else',
            'and',
            'or',
            'not',
            'posedge',
            'negedge',
            'disable',
            'iff',
            # $funcs are in the raw text as "$rose", but regex sees "rose" too (handled below)
            *list(_ALLOWED_SVA_FUNCS),
        }

        for m in re.finditer(r'\b[A-Za-z_]\w*\b', expr):
            t = m.group(0)

            if t in allowed_ids:
                continue

            if re.match(r'^[A-Z0-9_]+$', t):
                continue

            idx = m.start()

            # Allow system functions: "$rose" -> regex sees "rose" preceded by '$'
            if idx > 0 and expr[idx - 1] == '$':
                if ('$' + t) in allowed_ids:
                    continue

            # Allow field names after dot
            if idx > 0 and expr[idx - 1] == '.':
                continue

            return False

        return True

    # ------------------------------------------------------------------
    @staticmethod
    def _fix_reset_deassertion(row: Dict[str, str], rst: str) -> None:
        name = (row.get('name') or '').lower()
        scen = (row.get('scenario') or '').lower()
        post = (row.get('post') or '').strip()

        if 'deassert' in name or 'deassert' in scen:
            if (rst.endswith('_ni') or rst.endswith('ni') or rst.endswith('_n')) and post in (f'!{rst}', f'! {rst}'):
                row['post'] = rst

    # ------------------------------------------------------------------
    @staticmethod
    def _wrap_property(
        sid: str,
        name: str,
        ptype: str,
        clk: str,
        disable_cond: str,
        body_expr: str,
    ) -> str:
        prop_name = (name or sid or 'prop').replace('-', '_')
        label = f'{ptype}_{prop_name}'.replace('-', '_')

        if ptype not in {'assert', 'assume', 'cover'}:
            ptype = 'assert'

        return (
            f'// {sid}: {prop_name}\n'
            f'property {prop_name};\n'
            f'  @(posedge {clk}) disable iff ({disable_cond})\n'
            f'    {body_expr};\n'
            f'endproperty\n'
            f'{label}: {ptype} property({prop_name});'
        )

    # ------------------------------------------------------------------
    @staticmethod
    def _post_has_temporal(post: str) -> bool:
        p = (post or '').strip()
        return ('##' in p) or ('[*' in p) or ('[->' in p) or ('throughout' in p)

    # ------------------------------------------------------------------
    @staticmethod
    def _pre_is_missing(pre_raw: str, pre_norm: str) -> bool:
        """
        Treat empty / 1 / 1'b1 as "no real precondition".
        """
        if (pre_raw or '').strip() in {'', '1', "1'b1"}:
            return True
        return _is_trivial_true(pre_norm)

    # ------------------------------------------------------------------
    def _repair_pre_post_from_csv(self, pre_raw: str, post_raw: str, ports: List[str]) -> Tuple[str, str]:
        """
        Repair common CSV mistakes:
          - implication inside post:  post == "A |-> B"  => move A into pre
          - implication inside pre/post multiple times => iteratively lift antecedents into pre
          - temporal + boolean mix in post: rewrite "|/&" to "or/and" when '##' exists
        """
        pre = self._normalize_csv_expr(pre_raw, ports)
        post = self._normalize_csv_expr(post_raw, ports)

        # Lift nested implications out of post
        # Example: pre="dtlb_hit_i", post="dtlb_hit_i |-> $stable(dtlb_hit_i)"
        # => pre becomes "dtlb_hit_i && dtlb_hit_i", post becomes "$stable(dtlb_hit_i)" (then we can simplify later)
        while True:
            spl = _split_first_implication(post)
            if not spl:
                break
            ante, _op, cons = spl
            if not ante or not cons:
                break
            if not pre.strip() or _is_trivial_true(pre.strip()):
                pre = ante
            else:
                pre = f'({pre}) && ({ante})'
            post = cons

        # If implication exists in pre (shouldn't), drop it (safer than generating invalid SVA)
        if '|->' in pre or '|=>' in pre:
            # keep only antecedent part
            spl = _split_first_implication(pre)
            if spl:
                pre = spl[0].strip()

        # Rewrite temporal boolean mixes into proper sequence ops
        post = _rewrite_temporal_mix_to_sequence_ops(post)

        return pre.strip(), post.strip()

    # ------------------------------------------------------------------
    def _rule_based_property_from_row(
        self,
        row: Dict[str, str],
        clk: str,
        rst: str,
        disable_cond: str,
        ports: List[str],
    ) -> Optional[str]:
        sid = row.get('sid', '').strip()
        name = row.get('name', '').strip() or sid
        ptype = (row.get('prop_type', 'assert') or 'assert').strip().lower()
        scenario = (row.get('scenario', '') or '').strip().lower()

        pre_raw = row.get('pre', '')
        post_raw = row.get('post', '')

        pre, post = self._repair_pre_post_from_csv(pre_raw, post_raw, ports)

        # Identifier whitelist checks
        if pre and not self._expr_uses_only_ports(pre, ports):
            pre = ''
        if post and not self._expr_uses_only_ports(post, ports):
            post = ''

        pre_missing = self._pre_is_missing(pre_raw, pre)

        # If post is empty: only keep for COVER (covering an event) or skip for assume/assert
        if not post:
            if ptype == 'cover':
                if pre and not pre_missing:
                    body = f'({pre})'
                else:
                    body = "1'b1"
            else:
                return None
        else:
            # IMPORTANT: user request — if no real pre, do NOT emit "1 |-> ..."
            if pre_missing:
                body = f'({post})'
            else:
                # Optional fairness wrapping only when we truly have pre and post lacks temporal
                if (('eventually' in scenario) or ('not stuck' in scenario) or ('forever' in scenario)) and (
                    not self._post_has_temporal(post)
                ):
                    body = f'({pre}) |-> ##[1:$] ({post})'
                else:
                    body = f'({pre}) |-> ({post})'

        # Drop tautologies for assume/assert
        flat = re.sub(r'\s+', '', body)
        if ptype in {'assume', 'assert'}:
            if flat in {"(1'b1)", "1'b1"}:
                return None
            if "1'b1|->1'b1" in flat or '1|->1' in flat:
                return None

        return self._wrap_property(
            sid=sid,
            name=name,
            ptype=ptype,
            clk=clk,
            disable_cond=disable_cond,
            body_expr=body,
        )

    # ------------------------------------------------------------------
    def _call_llm_for_row(
        self,
        clk: str,
        rst: str,
        disable_cond: str,
        ports: List[str],
        md: str,
        row: Dict[str, str],
    ) -> str:
        if not self.llm:
            return ''

        # IMPORTANT: Your current property_prompt.yaml ALWAYS outputs "<PRE> |-> <POST>".
        # Since you explicitly do not want "1 |-> ..." when pre is empty, we skip LLM when pre is missing.
        pre_raw = (row.get('pre', '') or '').strip()
        if pre_raw in {'', '1', "1'b1"}:
            return ''

        sid = row.get('sid', '')
        name = row.get('name', '')
        ptype = row.get('prop_type', 'assert')

        # Repair CSV mistakes BEFORE sending to LLM (prevents nested implications)
        pre_fixed, post_fixed = self._repair_pre_post_from_csv(row.get('pre', ''), row.get('post', ''), ports)

        payload = {
            'clock': clk,
            'reset': rst,
            'reset_disable': disable_cond,
            'sid': sid,
            'name': name,
            'ptype': ptype,
            'pre': pre_fixed,
            'post': post_fixed,
            'spec_markdown': md,
            'allowed_signals': ', '.join(sorted(set(ports))),
        }

        try:
            res = self.llm.inference(payload, prompt_index='sva_property_block', n=1)
        except Exception as e:
            print(f'[LLM ERROR] row {sid} ({name}): {e}')
            return ''

        if isinstance(res, str):
            text = res
        elif isinstance(res, list) and res:
            text = res[0]
        elif isinstance(res, dict) and 'choices' in res:
            try:
                text = res['choices'][0]['message']['content']
            except Exception:
                text = ''
        else:
            text = ''

        return self._extract_sv_code(text or '')

    # ------------------------------------------------------------------
    def _sanitize_llm_property(
        self,
        llm_sv: str,
        row: Dict[str, str],
        clk: str,
        rst: str,
        disable_cond: str,
        ports: List[str],
    ) -> Optional[str]:
        sv = (llm_sv or '').strip()
        if not sv:
            return None

        # If LLM returned a bare expression, fall back
        if 'property' not in sv:
            return None

        # Ensure disable iff exists; if not, inject after @(posedge clk)
        if 'disable iff' not in sv:
            sv = re.sub(
                rf'(@\(\s*posedge\s+{re.escape(clk)}\s*\))',
                rf'\1 disable iff ({disable_cond})',
                sv,
                count=1,
            )

        # Reject tautologies
        flat = re.sub(r'\s+', '', sv)
        if '1|->1' in flat or "1'b1|->1'b1" in flat:
            return None

        # Also reject nested implications inside the property text (common when CSV was broken)
        # (If present, fall back to rule-based which repairs pre/post.)
        if sv.count('|->') > 1 or sv.count('|=>') > 1:
            return None

        return sv.strip()

    # ------------------------------------------------------------------
    def generate_properties(self) -> str:
        clk, rst, disable_cond, spec_top_module = self._find_clk_rst()
        rows = self._read_csv_rows()
        md = self._read_markdown()

        # Prefer AST-derived ports json located in out_dir / near csv
        ports_json_candidates = [
            Path(self.out_dir) / f'{spec_top_module}_ports.json',
            Path(self.csv_path).parent / f'{spec_top_module}_ports.json',
            Path(self.spec_md).parent / f'{spec_top_module}_ports.json',
        ]
        ports = _load_ports_from_ports_json(ports_json_candidates)

        if not ports:
            ports = detect_top_ports_from_rtl(self.rtl_dir, spec_top_module)

        if not ports:
            # fallback: infer from CSV signals column
            ports = []
            for r in rows:
                sigs = (r.get('signals') or '').strip()
                for tok in re.split(r'[\s,]+', sigs):
                    tok = tok.strip()
                    if tok and tok not in ports:
                        ports.append(tok)

        # Always include clk/rst in allowed signals
        if clk and clk not in ports:
            ports.append(clk)
        if rst and rst not in ports:
            ports.append(rst)

        print(f'[INFO] Spec-top ports used for checking ({spec_top_module}): {ports}')

        all_props: List[str] = []
        header = (
            '// ------------------------------------------------------------------\n'
            '// Auto-generated properties\n'
            f'// Spec: {Path(self.spec_md).name}\n'
            f'// CSV : {Path(self.csv_path).name}\n'
            '// ------------------------------------------------------------------\n'
        )

        for row in rows:
            self._fix_reset_deassertion(row, rst)

            sid = row.get('sid', '').strip()
            name = row.get('name', '').strip()
            print(f'[INFO] Generating property for row {sid} ({name})')

            # LLM then sanitize; fallback to deterministic rule-based
            llm_sv = self._call_llm_for_row(clk, rst, disable_cond, ports, md, row) if self.llm else ''
            sv_text = self._sanitize_llm_property(llm_sv, row, clk, rst, disable_cond, ports)

            if not sv_text:
                sv_text = self._rule_based_property_from_row(row, clk, rst, disable_cond, ports)

            if not sv_text:
                print(f'[WARN] Could not generate usable property for row {sid} ({name}); skipping.')
                continue

            all_props.append(sv_text.strip())

        out_path = os.path.join(self.out_dir, 'properties.sv')
        final_text = header + ('\n\n'.join(all_props) if all_props else '\n// No valid properties generated\n')

        with open(out_path, 'w', encoding='utf-8') as f:
            f.write(final_text.rstrip() + '\n')

        print(f'[✅] Properties written to {out_path}')
        return out_path


if __name__ == '__main__':
    import argparse

    p = argparse.ArgumentParser()
    p.add_argument('--spec-md', required=True)
    p.add_argument('--csv', required=True)
    p.add_argument('--rtl', required=True)
    p.add_argument('--out', required=True)
    p.add_argument('--llm-conf', required=False, default=None)
    p.add_argument('--design-top')
    args = p.parse_args()

    pb = PropertyBuilder(
        spec_md=args.spec_md,
        csv_path=args.csv,
        rtl_dir=args.rtl,
        out_dir=args.out,
        llm_conf=args.llm_conf,
        design_top=args.design_top,
    )
    pb.generate_properties()
