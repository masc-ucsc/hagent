- sv_file: /code/XiangShan/build/rtl/SimTop.sv
  diff_snippet: "--- a//code/XiangShan/build/rtl/SimTop.sv\n+++ b//code/XiangShan/build/rtl/SimTop.sv\n\
    @@ -3,6 +3,19 @@..."
  search_terms: []
  chisel_hints: []
- sv_file: /code/XiangShan/build/rtl/NewCSR.sv
  diff_snippet: "--- a//code/XiangShan/build/rtl/NewCSR.sv\n+++ b//code/XiangShan/build/rtl/NewCSR.sv\n\
    @@ -2726,7 +2726,7 @@..."
  search_terms:
  - gitDirty
  - _mstatus_sstatusRdata
  chisel_hints:
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/wpu/WPUWrapper.scala
    lines: 161-171
    context: "161:     for(i <- 0 until nPorts){\n162:       wayConflictPredictor.io.pred(i).en
      := io.req(i).valid\n163:       wayConflictPredictor.io.pred(i).vaddr := io.cfpred(i).s0_vaddr\n\
      164:       s0_pred_way_conflict(i) := wayConflictPredictor.io.pred(i).way_conflict\n\
      165:       when(!s0_pred_way_conflict(i)) {\n166:         s0_pred_way_en(i)
      := UIntToOH(get_direct_map_way(io.req(i).bits.vaddr))\n167:         s0_dmSel(i)
      := true.B\n168:       }\n169:       wayConflictPredictor.io.update(i).en :=
      io.lookup_upd(i).valid\n170:       wayConflictPredictor.io.update(i).vaddr :=
      io.cfpred(i).s1_vaddr\n171:       wayConflictPredictor.io.update(i).dm_hit :=
      s1_dmSel(i) && io.cfpred(i).s1_dm_hit"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/CacheConstants.scala
    lines: 40-53
    context: "40:   def M_XA_AND  = \"b01011\".U\n41:   def M_XA_MIN  = \"b01100\"\
      .U\n42:   def M_XA_MAX  = \"b01101\".U\n43:   def M_XA_MINU = \"b01110\".U\n\
      44:   def M_XA_MAXU = \"b01111\".U\n45:   def M_FLUSH   = \"b10000\".U // write
      back dirty data and cede R/W permissions\n46:   def M_PWR     = \"b10001\".U
      // partial (masked.U store\n47:   def M_PRODUCE = \"b10010\".U // write back
      dirty data and cede W permissions\n48:   def M_CLEAN   = \"b10011\".U // write
      back dirty data and retain R/W permissions\n49:   def M_SFENCE  = \"b10100\"\
      .U // flush TLB\n50:   def M_WOK     = \"b10111\".U // check write permissions
      but don't perform a write\n51:   def M_XA_CASQ = \"b11000\".U // AMOCAS.Q\n\
      52:   def M_XA_CASW = \"b11010\".U // AMOCAS.W\n53:   def M_XA_CASD = \"b11011\"\
      .U // AMOCAS.D"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 32-42
    context: "32: import freechips.rocketchip.tilelink.ClientStates._\n33: import
      freechips.rocketchip.tilelink.MemoryOpCategories._\n34: import freechips.rocketchip.tilelink.TLPermissions._\n\
      35: import freechips.rocketchip.tilelink.TLMessages._\n36: import freechips.rocketchip.tilelink._\n\
      37: import huancun.{AliasKey, DirtyKey, PrefetchKey}\n38: import org.chipsalliance.cde.config.Parameters\n\
      39: import utility._\n40: import utils._\n41: import xiangshan._\n42: import
      xiangshan.mem.AddPipelineReg"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 106-116
    context: "106: }\n107: \n108: class MissQueueRefillInfo(implicit p: Parameters)
      extends MissReqStoreData {\n109:   // refill_info for mainpipe req awake\n110:\
      \   val miss_param = UInt(TLPermissions.bdWidth.W)\n111:   val miss_dirty =
      Bool()\n112:   val error      = Bool()\n113: }\n114: \n115: class MissReq(implicit
      p: Parameters) extends MissReqWoStoreData {\n116:   // store data and store
      mask will be written to miss queue entry"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 641-651
    context: "641:     // we only need to merge data for Store\n642:     new_mask(i)
      := Mux(req.isFromStore, req_store_mask(rowBytes * (i + 1) - 1, rowBytes * i),
      0.U)\n643:   }\n644: \n645:   val hasData = RegInit(true.B)\n646:   val isDirty
      = RegInit(false.B)\n647:   io.wfi.wfiSafe := GatedValidRegNext(no_pending &&
      io.wfi.wfiReq)\n648:   when (io.mem_grant.fire) {\n649:     w_grantfirst :=
      true.B\n650:     grant_param := io.mem_grant.bits.param\n651:     when (edge.hasData(io.mem_grant.bits))
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 679-689
    context: "679:     }\n680: \n681:     error := io.mem_grant.bits.denied || io.mem_grant.bits.corrupt
      || error\n682: \n683:     refill_data_raw(refill_count ^ isKeyword) := io.mem_grant.bits.data\n\
      684:     isDirty := io.mem_grant.bits.echo.lift(DirtyKey).getOrElse(false.B)\n\
      685:   }\n686: \n687:   when (io.mem_finish.fire) {\n688:     s_grantack :=
      true.B\n689:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 904-914
    context: "904: \n905:   io.refill_info.valid := req_valid && w_grantlast\n906:\
      \   io.refill_info.bits.store_data := refill_and_store_data.asUInt\n907:   io.refill_info.bits.store_mask
      := ~0.U(blockBytes.W)\n908:   io.refill_info.bits.miss_param := grant_param\n\
      909:   io.refill_info.bits.miss_dirty := isDirty\n910:   io.refill_info.bits.error\
      \      := error\n911: \n912:   XSPerfAccumulate(\"miss_refill_mainpipe_req\"\
      , io.main_pipe_req.fire)\n913:   XSPerfAccumulate(\"miss_refill_without_hint\"\
      , io.main_pipe_req.fire && !mainpipe_req_fired && !w_l2hint)\n914:   XSPerfAccumulate(\"\
      miss_refill_replay\", io.main_pipe_replay)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 31-41
    context: "31: \n32: class MainPipeReq(implicit p: Parameters) extends DCacheBundle
      {\n33:   val miss = Bool() // only amo miss will refill in main pipe\n34:  \
      \ val miss_id = UInt(log2Up(cfg.nMissEntries).W)\n35:   val miss_param = UInt(TLPermissions.bdWidth.W)\n\
      36:   val miss_dirty = Bool()\n37:   val occupy_way = UInt(nWays.W)\n38:   val
      miss_fail_cause_evict_btot = Bool()\n39: \n40:   val probe = Bool()\n41:   val
      probe_param = UInt(TLPermissions.bdWidth.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 83-93
    context: "83: \n84:   def convertStoreReq(store: DCacheLineReq): MainPipeReq =
      {\n85:     val req = Wire(new MainPipeReq)\n86:     req := DontCare\n87:   \
      \  req.miss := false.B\n88:     req.miss_dirty := false.B\n89:     req.probe
      := false.B\n90:     req.probe_need_data := false.B\n91:     req.source := STORE_SOURCE.U\n\
      92:     req.cmd := store.cmd\n93:     req.addr := store.addr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 309-319
    context: "309:   val s1_banked_store_wmask = RegEnable(banked_store_wmask, s0_fire)\n\
      310:   val s1_need_tag = RegEnable(s0_need_tag, s0_fire)\n311:   val s1_can_go
      = s2_ready && (io.data_readline.ready || !s1_need_data)\n312:   val s1_fire
      = s1_valid && s1_can_go\n313:   val s1_idx = get_idx(s1_req.vaddr)\n314:   val
      s1_dmWay = RegEnable(get_direct_map_way(s0_req.vaddr), s0_fire)\n315: \n316:\
      \   when (s0_fire) {\n317:     s1_valid := true.B\n318:   }.elsewhen (s1_fire)
      {\n319:     s1_valid := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 519-529
    context: "519: \n520:   // s3: write data, meta and tag\n521:   val s3_valid =
      RegInit(false.B)\n522:   val s3_req = RegEnable(s2_req, s2_fire_to_s3)\n523:\
      \   val s3_miss_param = RegEnable(io.refill_info.bits.miss_param, s2_fire_to_s3)\n\
      524:   val s3_miss_dirty = RegEnable(io.refill_info.bits.miss_dirty, s2_fire_to_s3)\n\
      525:   val s3_tag = RegEnable(s2_tag, s2_fire_to_s3)\n526:   val s3_tag_match
      = RegEnable(s2_tag_match, s2_fire_to_s3)\n527:   val s3_coh = RegEnable(s2_coh,
      s2_fire_to_s3)\n528:   val s3_hit = RegEnable(s2_hit, s2_fire_to_s3)\n529: \
      \  val s3_amo_hit = RegEnable(s2_amo_hit, s2_fire_to_s3)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 564-588
    context: "564:   val store_update_meta = s3_req.isStore && !s3_req.probe && s3_hit_coh
      =/= s3_new_hit_coh\n565:   val amo_update_meta = s3_req.isAMO && !s3_req.probe
      && s3_hit_coh =/= s3_new_hit_coh && !s3_sc_fail\n566:   val amo_wait_amoalu
      = s3_req.isAMO && s3_req.cmd =/= M_XLR && s3_req.cmd =/= M_XSC && !isAMOCAS(s3_req.cmd)\n\
      567:   val update_meta = (miss_update_meta || probe_update_meta || store_update_meta
      || amo_update_meta) && !s3_req.replace\n568: \n569:   def missCohGen(cmd: UInt,
      param: UInt, dirty: Bool) = {\n570:     val c = categorize(cmd)\n571:     MuxLookup(Cat(c,
      param, dirty), Nothing)(Seq(\n572:       //(effect param) -> (next)\n573:  \
      \     Cat(rd, toB, false.B)  -> Branch,\n574:       Cat(rd, toB, true.B)   ->
      Branch,\n575:       Cat(rd, toT, false.B)  -> Trunk,\n576:       Cat(rd, toT,
      true.B)   -> Dirty,\n577:       Cat(wi, toT, false.B)  -> Trunk,\n578:     \
      \  Cat(wi, toT, true.B)   -> Dirty,\n579:       Cat(wr, toT, false.B)  -> Dirty,\n\
      580:       Cat(wr, toT, true.B)   -> Dirty))\n581:   }\n582: \n583:   val miss_new_coh
      = ClientMetadata(missCohGen(s3_req.cmd, s3_miss_param, s3_miss_dirty))\n584:\
      \ \n585:   // report ecc error\n586:   val s3_tag_error_beu = RegEnable(s2_tag_error,
      s2_fire)\n587:   val s3_tag_error_wb = RegEnable(s2_tag_error, s2_fire_to_s3)\n\
      588: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 731-743
    context: "731:   val need_wb = miss_wb || probe_wb || replace_wb\n732: \n733:\
      \   val writeback_param = Mux(probe_wb, probe_shrink_param, miss_shrink_param)\n\
      734:   val writeback_data = if (dcacheParameters.alwaysReleaseData) {\n735:\
      \     s3_tag_match && s3_req.probe && s3_req.probe_need_data ||\n736:      \
      \ s3_coh === ClientStates.Dirty || (miss_wb || replace_wb) && s3_coh.state =/=
      ClientStates.Nothing\n737:   } else {\n738:     s3_tag_match && s3_req.probe
      && s3_req.probe_need_data || s3_coh === ClientStates.Dirty\n739:   }\n740: \n\
      741:   val s3_probe_can_go = s3_req.probe && io.wb.ready && (io.meta_write.ready
      || !probe_update_meta)\n742:   val s3_store_can_go = s3_req.source === STORE_SOURCE.U
      && !s3_req.probe && (io.meta_write.ready || !store_update_meta) && (io.data_write.ready
      || !update_data) && !s3_req.miss\n743:   val s3_amo_can_go = s3_amo_hit && (io.meta_write.ready
      || !amo_update_meta) && (io.data_write.ready || !update_data) && (s3_s_amoalu
      || !amo_wait_amoalu) || s3_sc_fail"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 992-1002
    context: "992: \n993:   io.wb.bits.addr := get_block_addr(Cat(s3_tag, get_untag(s3_req.vaddr)))\n\
      994:   io.wb.bits.param := writeback_param\n995:   io.wb.bits.voluntary := s3_req.miss
      || s3_req.replace\n996:   io.wb.bits.hasData := writeback_data && !s3_tag_error_wb\n\
      997:   io.wb.bits.dirty := s3_coh === ClientStates.Dirty\n998:   io.wb.bits.data
      := s3_data.asUInt\n999:   io.wb.bits.corrupt := s3_tag_error_wb || s3_data_error_wb\n\
      1000:   io.wb.bits.delay_release := s3_req.replace\n1001:   io.wb.bits.miss_id
      := s3_req.miss_id\n1002: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 28-38
    context: "28: class WritebackReqCtrl(implicit p: Parameters) extends DCacheBundle
      {\n29:   val param  = UInt(cWidth.W)\n30:   val voluntary = Bool()\n31:   val
      hasData = Bool()\n32:   val corrupt = Bool()\n33:   val dirty = Bool()\n34:\
      \ \n35:   val delay_release = Bool()\n36:   val miss_id = UInt(log2Up(cfg.nMissEntries).W)\n\
      37: }\n38: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 62-72
    context: "62:     out.addr := addr\n63:     out.param := param\n64:     out.voluntary
      := voluntary\n65:     out.hasData := hasData\n66:     out.corrupt := corrupt\n\
      67:     out.dirty := dirty\n68:     out.delay_release := delay_release\n69:\
      \     out.miss_id := miss_id\n70:     out\n71:   }\n72: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 74-84
    context: "74:     val out = Wire(new WritebackReqCtrl)\n75:     out.param := param\n\
      76:     out.voluntary := voluntary\n77:     out.hasData := hasData\n78:    \
      \ out.corrupt := corrupt\n79:     out.dirty := dirty\n80:     out.delay_release
      := delay_release\n81:     out.miss_id := miss_id\n82:     out\n83:   }\n84: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 257-267
    context: "257:     corrupt = req.corrupt\n258:   )._2\n259: \n260:   // voluntaryReleaseData.echo.lift(DirtyKey).foreach(_
      := req.dirty)\n261:   when(busy) {\n262:     assert(!req.dirty || req.hasData)\n\
      263:   }\n264: \n265:   val (_, _, release_done, release_count) = edge.count(io.mem_release)\n\
      266: \n267:   io.mem_release.valid := busy"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 236-246
    context: "236:   io.vtag_update.ready := true.B\n237:   // dwpu.io.tagwrite_upd.valid
      := io.vtag_update.valid\n238:   // dwpu.io.tagwrite_upd.bits.vaddr := io.vtag_update.bits.vaddr\n\
      239:   // dwpu.io.tagwrite_upd.bits.s1_real_way_en := io.vtag_update.bits.way_en\n\
      240: \n241:   val s1_direct_map_way_num = get_direct_map_way(s1_req.vaddr)\n\
      242:   if(dwpuParam.enCfPred || !env.FPGAPlatform){\n243:     /* method1: record
      the pc */\n244:     // if (!env.FPGAPlatform){\n245:     //    io.dwpu.cfpred(0).s0_vaddr
      := io.lsu.s0_pc\n246:     //    io.dwpu.cfpred(0).s1_vaddr := io.lsu.s1_pc"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 286-296
    context: "286:   val s1_hit_access = ParallelMux(s1_tag_match_way_dup_dc.asBools,
      (0 until nWays).map(w => io.extra_meta_resp(w).access))\n287: \n288:   // io.replace_way.set.valid
      := RegNext(s0_fire)\n289:   io.replace_way.set.valid := false.B\n290:   io.replace_way.set.bits
      := get_idx(s1_vaddr)\n291:   io.replace_way.dmWay := get_direct_map_way(s1_vaddr)\n\
      292:   val s1_invalid_vec = wayMap(w => !meta_resp(w).coh.isValid())\n293: \
      \  val s1_have_invalid_way = s1_invalid_vec.asUInt.orR\n294:   val s1_invalid_way_en
      = ParallelPriorityMux(s1_invalid_vec.zipWithIndex.map(x => x._1 -> UIntToOH(x._2.U(nWays.W))))\n\
      295: \n296:   val s1_need_replacement = !s1_tag_match_dup_dc"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/storepipe/StorePipe.scala
    lines: 136-146
    context: "136:   /**\n137:     * Don't choose a replace_way anymore\n138:    \
      \ */\n139:   io.replace_way.set.valid := false.B\n140:   io.replace_way.set.bits\
      \  := get_idx(s1_req.vaddr)\n141:   io.replace_way.dmWay     := get_direct_map_way(s1_req.vaddr)\n\
      142: \n143:   val s1_need_replacement = !s1_tag_match.orR\n144: \n145: /** S2:\n\
      146:   * miss: send a write hint to Dache"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 259-269
    context: "259:       // no alias problem\n260:       true.B\n261:     }\n262:\
      \   }\n263: \n264:   def get_direct_map_way(addr:UInt): UInt = {\n265:     addr(DCacheAboveIndexOffset
      + log2Up(DCacheWays) - 1, DCacheAboveIndexOffset)\n266:   }\n267: \n268:   def
      arbiter[T <: Bundle](\n269:     in: Seq[DecoupledIO[T]],"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1177-1188
    context: "1177:     val extra_flag_valid = RegNext(mainPipe.io.prefetch_flag_write.valid)\n\
      1178:     val extra_flag_way_en = RegEnable(mainPipe.io.prefetch_flag_write.bits.way_en,
      mainPipe.io.prefetch_flag_write.valid)\n1179:     val extra_flag_prefetch =
      Mux1H(extra_flag_way_en, prefetchArray.io.resp.last)\n1180:     val extra_flag_access
      = Mux1H(extra_flag_way_en, accessArray.io.resp.last)\n1181: \n1182:     prefetcherMonitor.io.validity.good_prefetch
      := extra_flag_valid && isPrefetchRelated(extra_flag_prefetch) && extra_flag_access\n\
      1183:     prefetcherMonitor.io.validity.bad_prefetch := extra_flag_valid &&
      isPrefetchRelated(extra_flag_prefetch) && !extra_flag_access\n1184:   }\n1185:\
      \ \n1186:   // write extra meta\n1187:   val error_flag_write_ports = Seq(\n\
      1188:     mainPipe.io.error_flag_write // error flag generated by corrupted
      store"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 686-699
    context: "686:   vtypeBuffer.io.fromRob.walkEnd := state === s_walk && walkFinished\n\
      687: \n688:   require(RenameWidth <= CommitWidth)\n689: \n690:   // wiring to
      csr\n691:   val (wflags, dirtyFs) = (0 until CommitWidth).map(i => {\n692: \
      \    val v = io.commits.commitValid(i)\n693:     val info = io.commits.info(i)\n\
      694:     (v & info.wflags, v & info.dirtyFs)\n695:   }).unzip\n696:   val fflags
      = Wire(Valid(UInt(5.W)))\n697:   fflags.valid := io.commits.isCommit && VecInit(wflags).asUInt.orR\n\
      698:   fflags.bits := wflags.zip(fflagsDataRead).map({\n699:     case (w, f)
      => Mux(w, f, 0.U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 696-714
    context: "696:   val fflags = Wire(Valid(UInt(5.W)))\n697:   fflags.valid := io.commits.isCommit
      && VecInit(wflags).asUInt.orR\n698:   fflags.bits := wflags.zip(fflagsDataRead).map({\n\
      699:     case (w, f) => Mux(w, f, 0.U)\n700:   }).reduce(_ | _)\n701:   val
      dirtyVs = (0 until CommitWidth).map(i => {\n702:     val v = io.commits.commitValid(i)\n\
      703:     val info = io.commits.info(i)\n704:     v & info.dirtyVs\n705:   })\n\
      706:   val dirty_fs = io.commits.isCommit && VecInit(dirtyFs).asUInt.orR\n707:\
      \   val dirty_vs = io.commits.isCommit && VecInit(dirtyVs).asUInt.orR\n708:\
      \ \n709:   val resetVstart = dirty_vs && !io.vstartIsZero\n710: \n711:   vecExcpInfo.valid
      := exceptionHappen && !intrEnable && exceptionDataRead.bits.vstartEn && exceptionDataRead.bits.isVecLoad
      && !exceptionDataRead.bits.isEnqExcp\n712:   when (exceptionHappen) {\n713:\
      \     vecExcpInfo.bits.nf := exceptionDataRead.bits.nf\n714:     vecExcpInfo.bits.vsew
      := exceptionDataRead.bits.vsew"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 810-821
    context: "810:     )\n811:   }\n812: \n813:   // sync fflags/dirty_fs/vxsat to
      csr\n814:   io.csr.fflags   := RegNextWithEnable(fflags)\n815:   io.csr.dirty_fs
      := GatedValidRegNext(dirty_fs)\n816:   io.csr.dirty_vs := GatedValidRegNext(dirty_vs)\n\
      817:   io.csr.vxsat    := RegNextWithEnable(vxsat)\n818: \n819:   // commit
      load/store to lsq\n820:   val ldCommitVec = VecInit((0 until CommitWidth).map(i
      => io.commits.commitValid(i) && io.commits.info(i).commitType === CommitType.LOAD))\n\
      821:   // TODO: Check if meet the require that only set scommit when commit
      scala store uop"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 51-61
    context: "51:     // They have side effects on the states of the processor before
      they write back\n52:     val interrupt_safe = Bool()\n53:     val fpWen = Bool()\n\
      54:     val rfWen = Bool()\n55:     val wflags = Bool()\n56:     val dirtyVs
      = Bool()\n57:     val commitType = CommitType()\n58:     val ftqIdx = new FtqPtr\n\
      59:     val ftqOffset = UInt(log2Up(PredictWidth).W)\n60:     val isRVC = Bool()\n\
      61:     val isVset = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 120-131
    context: "120:     val debug_ldest = OptionWrapper(backendParams.basicDebugEn,
      UInt(LogicRegsWidth.W))\n121:     val debug_pdest = OptionWrapper(backendParams.basicDebugEn,
      UInt(PhyRegIdxWidth.W))\n122:     val debug_otherPdest = OptionWrapper(backendParams.basicDebugEn,
      Vec(7, UInt(PhyRegIdxWidth.W)))\n123:     val debug_fuType = OptionWrapper(backendParams.debugEn,
      FuType())\n124:     // debug_end\n125:     val dirtyFs = Bool()\n126:     val
      dirtyVs = Bool()\n127:   }\n128: \n129:   def connectEnq(robEntry: RobEntryBundle,
      robEnq: DynInst): Unit = {\n130:     robEntry.wflags := robEnq.wfflags\n131:\
      \     robEntry.commitType := robEnq.commitType"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 134-145
    context: "134:     robEntry.isRVC := robEnq.preDecodeInfo.isRVC\n135:     robEntry.isVset
      := robEnq.isVset\n136:     robEntry.isHls := robEnq.isHls\n137:     robEntry.instrSize
      := robEnq.instrSize\n138:     robEntry.rfWen := robEnq.rfWen\n139:     robEntry.fpWen
      := robEnq.dirtyFs\n140:     robEntry.dirtyVs := robEnq.dirtyVs\n141:     //
      flushPipe needFlush but not exception\n142:     robEntry.needFlush := robEnq.hasException
      || robEnq.flushPipe\n143:     // trace\n144:     robEntry.traceBlockInPipe :=
      robEnq.traceBlockInPipe\n145:     robEntry.debug_pc.foreach(_ := robEnq.pc)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 168-179
    context: "168:     robCommitEntry.mmio := robEntry.mmio\n169:     robCommitEntry.ftqIdx
      := robEntry.ftqIdx\n170:     robCommitEntry.ftqOffset := robEntry.ftqOffset\n\
      171:     robCommitEntry.commitType := robEntry.commitType\n172:     robCommitEntry.instrSize
      := robEntry.instrSize\n173:     robCommitEntry.dirtyFs := robEntry.fpWen ||
      robEntry.wflags\n174:     robCommitEntry.dirtyVs := robEntry.dirtyVs\n175: \
      \    robCommitEntry.needFlush := robEntry.needFlush\n176:     robCommitEntry.traceBlockInPipe
      := robEntry.traceBlockInPipe\n177:     robCommitEntry.debug_pc.foreach(_ :=
      robEntry.debug_pc.get)\n178:     robCommitEntry.debug_instr.foreach(_ := robEntry.debug_instr.get)\n\
      179:     robCommitEntry.debug_ldest.foreach(_ := robEntry.debug_ldest.get)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 224-235
    context: "224:   val criticalErrorState = Input(Bool())\n225: \n226:   val fflags\
      \     = Output(Valid(UInt(5.W)))\n227:   val vxsat      = Output(Valid(Bool()))\n\
      228:   val vstart     = Output(Valid(UInt(XLEN.W)))\n229:   val dirty_fs   =
      Output(Bool())\n230:   val dirty_vs   = Output(Bool())\n231:   val perfinfo\
      \   = new Bundle {\n232:     val retiredInstr = Output(UInt(7.W))\n233:   }\n\
      234: }\n235: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 226-237
    context: "226:     // reg cache\n227:     val useRegCache     = Vec(backendParams.numIntRegSrc,
      Bool())\n228:     val regCacheIdx     = Vec(backendParams.numIntRegSrc, UInt(RegCacheIdxWidth.W))\n\
      229:     val robIdx          = new RobPtr\n230:     val instrSize       = UInt(log2Ceil(RenameWidth
      + 1).W)\n231:     val dirtyFs         = Bool()\n232:     val dirtyVs       \
      \  = Bool()\n233:     val traceBlockInPipe = new TracePipe(IretireWidthInPipe)\n\
      234: \n235:     val eliminatedMove  = Bool()\n236:     // Take snapshot at this
      CFI inst\n237:     val snapshot        = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 217-227
    context: "217:   private val mop          = fuOpType.map(fuOpTypeItem => LSUOpType.getVecLSMop(fuOpTypeItem))\n\
      218:   private val isVlsType    = fuType.map(fuTypeItem => isVls(fuTypeItem))\n\
      219:   private val isSegment    = fuType.map(fuTypeItem => isVsegls(fuTypeItem))\n\
      220:   private val isUnitStride = fuOpType.map(fuOpTypeItem => LSUOpType.isAllUS(fuOpTypeItem))\n\
      221:   private val nf           = fuOpType.zip(uops.map(_.vpu.nf)).map { case
      (fuOpTypeItem, nfItem) => Mux(LSUOpType.isWhole(fuOpTypeItem), 0.U, nfItem)
      }\n222:   private val mulBits      = 3 // dirty code\n223:   private val emul\
      \         = fuOpType.zipWithIndex.map { case (fuOpTypeItem, index) =>\n224:\
      \     Mux(\n225:       LSUOpType.isWhole(fuOpTypeItem),\n226:       GenUSWholeEmul(nf(index)),\n\
      227:       Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 363-374
    context: "363:       uops(i).lastUop := false.B\n364:       uops(i).numUops :=
      instrSizesVec(i) - PopCount(compressMasksVec(i) & Cat(isMove.reverse))\n365:\
      \       uops(i).numWB := instrSizesVec(i) - PopCount(compressMasksVec(i) & Cat(isMove.reverse))\n\
      366:     }\n367:     uops(i).wfflags := (compressMasksVec(i) & Cat(io.in.map(_.bits.wfflags).reverse)).orR\n\
      368:     uops(i).dirtyFs := (compressMasksVec(i) & Cat(io.in.map(_.bits.fpWen).reverse)).orR\n\
      369:     uops(i).dirtyVs := (\n370:       compressMasksVec(i) & Cat(io.in.map(in
      =>\n371:         // vector instructions' uopSplitType cannot be UopSplitType.SCA_SIM\n\
      372:         in.bits.uopSplitType =/= UopSplitType.SCA_SIM &&\n373:        \
      \ !UopSplitType.isAMOCAS(in.bits.uopSplitType) &&\n374:         // vfmv.f.s,
      vcpop.m, vfirst.m and vmv.x.s don't change vector state"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VIPU.scala
    lines: 92-102
    context: "92:   private val dataWidth = cfg.destDataBits\n93:   private val dataWidthOfDataModule
      = 64\n94:   private val numVecModule = dataWidth / dataWidthOfDataModule\n95:\
      \   private val needClearVs1 = (VipuType.vcpop_m === io.in.bits.ctrl.fuOpType
      && vuopIdx === 0.U) ||\n96:     (VipuType.viota_m === io.in.bits.ctrl.fuOpType
      && vuopIdx(log2Up(MaxUopSize)-1,1) === 0.U) ||\n97:     (VipuType.vid_v   ===
      io.in.bits.ctrl.fuOpType && vuopIdx(log2Up(MaxUopSize)-1,1) === 0.U)    // dirty
      code TODO:  inset into IAlu\n98:   private val lmul = MuxLookup(vlmul, 1.U(4.W))(Seq(\n\
      99:     \"b001\".U -> 2.U,\n100:     \"b010\".U -> 4.U,\n101:     \"b011\".U
      -> 8.U\n102:   ))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 24-37
    context: "24: {\n25:   val csrIn = io.csrio.get\n26:   val csrOut = io.csrio.get\n\
      27:   val csrToDecode = io.csrToDecode.get\n28: \n29:   val setFsDirty = csrIn.fpu.dirty_fs\n\
      30:   val setFflags = csrIn.fpu.fflags\n31: \n32:   val setVsDirty = csrIn.vpu.dirty_vs\n\
      33:   val setVstart = csrIn.vpu.set_vstart\n34:   val setVtype = csrIn.vpu.set_vtype\n\
      35:   val setVxsat = csrIn.vpu.set_vxsat\n36:   val vlFromPreg = csrIn.vpu.vl\n\
      37: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 137-150
    context: "137:   csrMod.io.fromRob.trap.bits.isHls := csrIn.exception.bits.isHls\n\
      138:   csrMod.io.fromRob.trap.bits.isFetchMalAddr := csrIn.exception.bits.isFetchMalAddr\n\
      139:   csrMod.io.fromRob.trap.bits.isForVSnonLeafPTE := csrIn.exception.bits.isForVSnonLeafPTE\n\
      140: \n141:   csrMod.io.fromRob.commit.fflags := setFflags\n142:   csrMod.io.fromRob.commit.fsDirty
      := setFsDirty\n143:   csrMod.io.fromRob.commit.vxsat.valid := setVxsat.valid\n\
      144:   csrMod.io.fromRob.commit.vxsat.bits := setVxsat.bits\n145:   csrMod.io.fromRob.commit.vsDirty
      := setVsDirty\n146:   csrMod.io.fromRob.commit.vstart := setVstart\n147:   csrMod.io.fromRob.commit.vl
      := vlFromPreg\n148:   // Todo: correct vtype\n149:   csrMod.io.fromRob.commit.vtype.valid
      := setVtype.valid\n150:   csrMod.io.fromRob.commit.vtype.bits.VILL := setVtype.bits(XLEN
      - 1)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 267-277
    context: "267:   tlb.priv.mxr := csrMod.io.tlb.mxr\n268:   tlb.priv.sum := csrMod.io.tlb.sum\n\
      269:   tlb.priv.vmxr := csrMod.io.tlb.vmxr\n270:   tlb.priv.vsum := csrMod.io.tlb.vsum\n\
      271:   tlb.priv.spvp := csrMod.io.tlb.spvp\n272:   tlb.priv.virt := csrMod.io.tlb.dvirt\n\
      273:   tlb.priv.virt_changed := DataChanged(tlb.priv.virt)\n274:   tlb.priv.imode
      := csrMod.io.tlb.imode\n275:   tlb.priv.dmode := csrMod.io.tlb.dmode\n276: \n\
      277:   // Svpbmt extension enable"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/util/CSRConst.scala
    lines: 78-88
    context: "78:   def satp_part_wmask(max_length: Int, length: Int) : UInt = {\n\
      79:     require(length > 0 && length <= max_length)\n80:     ((1L << length)
      - 1).U(max_length.W)\n81:   }\n82: \n83:   val IntPriority = Seq(\n84:     IRQ_DEBUG,\n\
      85:     IRQ_MEIP, IRQ_MSIP, IRQ_MTIP,\n86:     IRQ_SEIP, IRQ_SSIP, IRQ_STIP,\n\
      87:     IRQ_UEIP, IRQ_USIP, IRQ_UTIP,\n88:     IRQ_VSEIP, IRQ_VSSIP, IRQ_VSTIP,
      IRQ_SGEIP"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 37-47
    context: "37: import freechips.rocketchip.rocket.CSRs\n38: \n39: class FpuCsrIO
      extends Bundle {\n40:   val fflags = Output(Valid(UInt(5.W)))\n41:   val isIllegal
      = Output(Bool())\n42:   val dirty_fs = Output(Bool())\n43:   val frm = Input(UInt(3.W))\n\
      44: }\n45: \n46: class VpuCsrIO(implicit p: Parameters) extends XSBundle {\n\
      47:   val vstart = Input(UInt(XLEN.W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 51-61
    context: "51: \n52:   val set_vstart = Output(Valid(UInt(XLEN.W)))\n53:   val
      set_vtype = Output(Valid(UInt(XLEN.W)))\n54:   val set_vxsat = Output(Valid(UInt(1.W)))\n\
      55: \n56:   val dirty_vs = Output(Bool())\n57: }\n58: \n59: \n60: class PerfCounterIO(implicit
      p: Parameters) extends XSBundle {\n61:   val perfEventsFrontend  = Vec(numCSRPCntFrontend,
      new PerfEvent)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 159-169
    context: "159:     val h = Output(Bool()) // unused\n160:     val s = Output(Bool())\n\
      161:     val u = Output(Bool())\n162:   }\n163: \n164:   class MstatusStruct
      extends Bundle {\n165:     val sd = Output(UInt(1.W))\n166: \n167:     val pad1
      = if (XLEN == 64 && HasHExtension) Output(UInt(23.W)) else if (XLEN == 64) Output(UInt(25.W))
      else null\n168:     val mpv  = if (XLEN == 64 && HasHExtension) Output(UInt(1.W))
      else null\n169:     val gva  = if (XLEN == 64 && HasHExtension) Output(UInt(1.W))
      else null"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 192-202
    context: "192:     def ube_(r: UInt): Unit = {\n193:       pie.h := r(0)\n194:\
      \     }\n195:   }\n196: \n197:   class HstatusStruct extends Bundle {\n198:\
      \     val pad4 = if (HSXLEN == 64) Output(UInt(30.W)) else null\n199:     val
      vsxl = if (HSXLEN == 64) Output(UInt(2.W)) else null\n200:     val pad3 = Output(UInt(9.W))\n\
      201:     val vtsr = Output(UInt(1.W))\n202:     val vtw = Output(UInt(1.W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 365-380
    context: "365:   // | vs   | 01 |\n366:   // | spp  | 0 |\n367:   // | pie  |
      0000 | pie.h is used as UBE\n368:   // | ie   | 0000 | uie hardlinked to 0,
      as N ext is not implemented\n369: \n370:   val mstatusStruct = mstatus.asTypeOf(new
      MstatusStruct)\n371:   def mstatusUpdateSideEffect(mstatus: UInt): UInt = {\n\
      372:     val mstatusOld = WireInit(mstatus.asTypeOf(new MstatusStruct))\n373:\
      \     // Cat(sd, other)\n374:     val mstatusNew = Cat(\n375:       mstatusOld.xs
      === ContextStatus.dirty || mstatusOld.fs === ContextStatus.dirty || mstatusOld.vs
      === ContextStatus.dirty,\n376:       mstatus(XLEN-2, 0)\n377:     )\n378:  \
      \   mstatusNew\n379:   }\n380:   def vsstatusUpdateSideEffect(vsstatus: UInt):
      UInt = {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 376-386
    context: "376:       mstatus(XLEN-2, 0)\n377:     )\n378:     mstatusNew\n379:\
      \   }\n380:   def vsstatusUpdateSideEffect(vsstatus: UInt): UInt = {\n381: \
      \    val vsstatusOld = WireInit(vsstatus.asTypeOf(new MstatusStruct))\n382:\
      \     val vsstatusNew = Cat(vsstatusOld.xs === \"b11\".U || vsstatusOld.fs ===
      \"b11\".U, vsstatus(XLEN-2, 0))\n383:     vsstatusNew\n384:   }\n385:   val
      mstatusWMask = (~ZeroExt((\n386:     GenMask(63)           | // SD is read-only"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 582-592
    context: "582: \n583:   // Hypervisor CSRs\n584:   val hstatusWMask = \"h7003c0\"\
      .U(XLEN.W)\n585:   // hstatus: vtsr, vtw, vtvm, hu, spvp, spv, gva,\n586:  \
      \ val hstatus = RegInit(\"h200000000\".U(XLEN.W))\n587:   val hstatusStruct
      = hstatus.asTypeOf(new HstatusStruct)\n588:   val hedeleg = RegInit(UInt(XLEN.W),
      0.U)\n589:   val hideleg = RegInit(UInt(XLEN.W), 0.U)\n590:   val hidelegRMask
      = mideleg\n591:   val hidelegWMask = ((1 << 10) | (1 << 6) | (1 << 2)).U(XLEN.W)\n\
      592:   val hgeie   = RegInit(UInt(XLEN.W), 0.U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 605-615
    context: "605:   val hcounteren = RegInit(UInt(XLEN.W), 0.U)\n606:   // Currently,
      XiangShan don't support Unprivileged Counter/Timers CSRs (\"Zicntr\" and \"\
      Zihpm\")\n607:   val hcounterenMask = 0.U(XLEN.W)\n608: \n609:   val vsstatus
      = RegInit(\"h200002000\".U(XLEN.W))\n610:   val vsstatusStruct = vsstatus.asTypeOf(new
      MstatusStruct)\n611:   //vsie vsip\n612:   val vsMask = ((1 << 10) | (1 << 6)
      | (1 << 2)).U(XLEN.W)\n613:   val vsip_ie_Mask = ZeroExt((hideleg & mideleg
      & vsMask), XLEN)\n614:   val vsip_WMask = ZeroExt((hideleg & mideleg & vssip_Mask),
      XLEN)\n615:   val vstvec = RegInit(UInt(XLEN.W), 0.U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 994-1006
    context: "994: \n995:   // satp wen check\n996:   val satpLegalMode = (wdata.asTypeOf(new
      SatpStruct).mode===0.U) || (wdata.asTypeOf(new SatpStruct).mode===8.U)\n997:\
      \ \n998:   // csr access check, special case\n999:   val tvmNotPermit = (privilegeMode
      === ModeS && !virtMode && mstatusStruct.tvm.asBool)\n1000:   val accessPermitted
      = !(addr === Satp.U && tvmNotPermit)\n1001:   val vtvmNotPermit = (privilegeMode
      === ModeS && virtMode && hstatusStruct.vtvm.asBool)\n1002:   val vaccessPermitted
      = !(addr === Vsatp.U && vtvmNotPermit)\n1003: //  csrio.disableSfence := (tvmNotPermit
      || !virtMode && privilegeMode < ModeS) || (vtvmNotPermit || virtMode && privilegeMode
      < ModeS)\n1004: //  csrio.disableHfenceg := !((!virtMode && privilegeMode ===
      ModeS && !mstatusStruct.tvm.asBool) || (privilegeMode === ModeM)) // only valid
      in HS and mstatus.tvm == 0 or in M\n1005: //  csrio.disableHfencev :=  !(privilegeMode
      === ModeM || (!virtMode && privilegeMode === ModeS))\n1006: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1030-1046
    context: "1030:   when(RegNext(csrio.vpu.set_vxsat.valid)) {\n1031:     vcsr :=
      vxsat_wfn(update = true)(RegEnable(csrio.vpu.set_vxsat.bits, csrio.vpu.set_vxsat.valid))\n\
      1032:   }\n1033: \n1034:   // set fs and sd in mstatus\n1035:   when (csrw_dirty_fp_state
      || RegNext(csrio.fpu.dirty_fs)) {\n1036:     val mstatusNew = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1037:     mstatusNew.fs := \"b11\".U\n1038:     mstatusNew.sd
      := true.B\n1039:     mstatus := mstatusNew.asUInt\n1040:     when(virtMode){\n\
      1041:       val vsstatusNew = WireInit(vsstatus.asTypeOf(new MstatusStruct))\n\
      1042:       vsstatusNew.fs := \"b11\".U\n1043:       vsstatusNew.sd := true.B\n\
      1044:       vsstatus := vsstatusNew.asUInt\n1045:     }\n1046:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1052-1064
    context: "1052:   when (RegNext(csrio.vpu.set_vtype.valid)) {\n1053:     vtype
      := RegEnable(csrio.vpu.set_vtype.bits, csrio.vpu.set_vtype.valid)\n1054:   }\n\
      1055:   vl := csrio.vpu.vl\n1056:   // set vs and sd in mstatus\n1057:   when(csrw_dirty_vs_state
      || RegNext(csrio.vpu.dirty_vs)) {\n1058:     val mstatusNew = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1059:     mstatusNew.vs := ContextStatus.dirty\n1060:     mstatusNew.sd
      := true.B\n1061:     mstatus := mstatusNew.asUInt\n1062:   }\n1063: \n1064:\
      \   csrio.vpu.vstart := vstart"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1108-1120
    context: "1108:   val isWFI    = func === CSROpType.wfi\n1109: \n1110:   // Illegal
      privileged operation list\n1111:   val illegalMret = valid && isMret && privilegeMode
      < ModeM\n1112:   val illegalSret = valid && isSret && privilegeMode < ModeS\n\
      1113:   val illegalSModeSret = valid && isSret && privilegeMode === ModeS &&
      virtMode === false.B && mstatusStruct.tsr.asBool\n1114:   // when hstatus.vtsr
      == 1, if sret is executed in VS-mode, it will cause virtual instruction\n1115:\
      \   val illegalVSModeSret = valid && isSret && privilegeMode === ModeS && virtMode
      && hstatusStruct.vtsr.asBool\n1116:   // When TW=1, then if WFI is executed
      in any less-privileged mode,\n1117:   // and it does not complete within an
      implementation-specific, bounded time limit,\n1118:   // the WFI instruction
      causes an illegal instruction exception.\n1119:   // The time limit may always
      be 0, in which case WFI always causes\n1120:   // an illegal instruction exception
      in less-privileged modes when TW=1."
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1116-1128
    context: "1116:   // When TW=1, then if WFI is executed in any less-privileged
      mode,\n1117:   // and it does not complete within an implementation-specific,
      bounded time limit,\n1118:   // the WFI instruction causes an illegal instruction
      exception.\n1119:   // The time limit may always be 0, in which case WFI always
      causes\n1120:   // an illegal instruction exception in less-privileged modes
      when TW=1.\n1121:   val illegalWFI = valid && isWFI && (privilegeMode < ModeM
      && mstatusStruct.tw === 1.U ||  privilegeMode === ModeU && !virtMode)\n1122:\
      \   val illegalVWFI = valid && isWFI && ((virtMode && privilegeMode === ModeS
      && hstatusStruct.vtw === 1.U && mstatusStruct.tw === 0.U)||\n1123:       (virtMode
      && privilegeMode === ModeU && mstatusStruct.tw === 0.U))\n1124:   // Illegal
      privileged instruction check\n1125:   val isIllegalAddr = valid && CSROpType.isCsrAccess(func)
      && MaskedRegMap.isIllegalAddr(mapping, addr)\n1126:   val isIllegalAccess =
      !virtMode && wen && !(Mux(addrInPerfCnt, perfcntPermitted, csrAccess === 0.U
      && dcsrPermitted && triggerPermitted) && accessPermitted)\n1127:   val isIllegalPrivOp
      = illegalMret || illegalSret || illegalSModeSret || illegalWFI\n1128: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1127-1144
    context: "1127:   val isIllegalPrivOp = illegalMret || illegalSret || illegalSModeSret
      || illegalWFI\n1128: \n1129:   val isIllegalVAccess = virtMode && wen && (csrAccess
      === 2.U || !vaccessPermitted)\n1130:   val isIllegalVPrivOp = illegalVSModeSret
      || illegalVWFI\n1131:   // expose several csr bits for tlb\n1132:   tlbBundle.priv.mxr\
      \   := mstatusStruct.mxr.asBool\n1133:   tlbBundle.priv.sum   := mstatusStruct.sum.asBool\n\
      1134:   tlbBundle.priv.vmxr := vsstatusStruct.mxr.asBool\n1135:   tlbBundle.priv.vsum
      := vsstatusStruct.sum.asBool\n1136:   tlbBundle.priv.spvp := hstatusStruct.spvp\n\
      1137:   tlbBundle.priv.virt  := Mux(mstatusStruct.mprv.asBool, mstatusStruct.mpv
      & (mstatusStruct.mpp =/= ModeM), virtMode)\n1138:   tlbBundle.priv.imode :=
      privilegeMode\n1139:   tlbBundle.priv.dmode := Mux((debugMode && dcsr.asTypeOf(new
      DcsrStruct).mprven || !debugMode) && mstatusStruct.mprv.asBool, mstatusStruct.mpp,
      privilegeMode)\n1140: \n1141:   // Branch control\n1142:   val retTarget = WireInit(0.U)\n\
      1143:   val resetSatp = (addr === Satp.U || addr === Hgatp.U || addr === Vsatp.U)
      && wen // write to satp will cause the pipeline be flushed\n1144:   val writeVstart
      = addr === Vstart.U && wen // write to vstart will cause the pipeline be flushed"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1168-1178
    context: "1168:   }\n1169: \n1170:   // Mux tree for regs\n1171:   when(valid)
      {\n1172:     when(isDret) {\n1173:       val mstatusNew = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1174:       val debugModeNew = WireInit(debugMode)\n1175: \
      \      when(dcsr.asTypeOf(new DcsrStruct).prv =/= ModeM) {\n1176:         mstatusNew.mprv
      := 0.U\n1177:       } //If the new privilege mode is less privileged than M-mode,
      MPRV in mstatus is cleared.\n1178:       mstatus := mstatusNew.asUInt"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1180-1191
    context: "1180:       debugModeNew := false.B\n1181:       debugIntrEnable :=
      true.B\n1182:       debugMode := debugModeNew\n1183:       XSDebug(\"Debug Mode:
      Dret executed, returning to %x.\", retTarget)\n1184:     }.elsewhen(isMret &&
      !illegalMret) {\n1185:       val mstatusOld = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1186:       val mstatusNew = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1187:       mstatusNew.ie.m := mstatusOld.pie.m\n1188:    \
      \   privilegeMode := mstatusOld.mpp\n1189:       if (HasHExtension) {\n1190:\
      \         virtMode := mstatusOld.mpv\n1191:         mstatusNew.mpv := 0.U"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1195-1210
    context: "1195:       when(mstatusOld.mpp =/= ModeM) {\n1196:         mstatusNew.mprv
      := 0.U\n1197:       }\n1198:       mstatus := mstatusNew.asUInt\n1199:     }.elsewhen(isSret
      && !illegalSret && !illegalSModeSret && !illegalVSModeSret) {\n1200:       val
      mstatusOld = WireInit(mstatus.asTypeOf(new MstatusStruct))\n1201:       val
      mstatusNew = WireInit(mstatus.asTypeOf(new MstatusStruct))\n1202:       val
      hstatusOld = WireInit(hstatus.asTypeOf(new HstatusStruct))\n1203:       val
      hstatusNew = WireInit(hstatus.asTypeOf(new HstatusStruct))\n1204:       val
      vsstatusOld = WireInit(vsstatus.asTypeOf(new MstatusStruct))\n1205:       val
      vsstatusNew = WireInit(vsstatus.asTypeOf(new MstatusStruct))\n1206:       when(virtMode
      === 0.U) {\n1207:         virtMode := hstatusOld.spv\n1208:         hstatusNew.spv
      := 0.U\n1209:         mstatusNew.ie.s := mstatusOld.pie.s\n1210:         privilegeMode
      := Cat(0.U(1.W), mstatusOld.spp)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1221-1232
    context: "1221:         vsstatusNew.ie.s := vsstatusOld.pie.s\n1222:         vsstatusNew.pie.s
      := 1.U\n1223:         vsstatus := vsstatusNew.asUInt\n1224:       }\n1225: \
      \    }.elsewhen(isUret) {\n1226:       val mstatusOld = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1227:       val mstatusNew = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1228:       // mstatusNew.mpp.m := ModeU //TODO: add mode U\n\
      1229:       mstatusNew.ie.u := mstatusOld.pie.u\n1230:       privilegeMode :=
      ModeU\n1231:       mstatusNew.pie.u := true.B\n1232:       mstatus := mstatusNew.asUInt"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1266-1278
    context: "1266:     * Exception and Intr\n1267:     */\n1268:   val idelegS =\
      \  (mideleg & mip.asUInt)\n1269:   val idelegVS = (hideleg & mideleg & mip.asUInt)\n\
      1270:   def privilegedEnableDetect(idelegS: Bool, idelegVS: Bool): Bool = Mux(idelegS,\n\
      1271:     Mux(idelegVS, (virtMode && privilegeMode === ModeS && vsstatusStruct.ie.s)
      || (virtMode && privilegeMode < ModeS),\n1272:       ((privilegeMode === ModeS)
      && mstatusStruct.ie.s) || (privilegeMode < ModeS) || virtMode),\n1273:     ((privilegeMode
      === ModeM) && mstatusStruct.ie.m) || (privilegeMode < ModeM))\n1274: \n1275:\
      \   val debugIntr = csrio.externalInterrupt.debug & debugIntrEnable\n1276: \
      \  XSDebug(debugIntr, \"Debug Mode: debug interrupt is asserted and valid!\"\
      )\n1277:   // send interrupt information to ROB\n1278:   val intrVecEnable =
      Wire(Vec(13, Bool()))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1290-1300
    context: "1290:   mipWire.s.m := csrio.externalInterrupt.msip\n1291:   mipWire.e.m
      := csrio.externalInterrupt.meip\n1292:   mipWire.e.s := csrio.externalInterrupt.seip\n\
      1293: \n1294:   // interrupts\n1295:   val intrNO = IntPriority.foldRight(0.U)((i:
      Int, sum: UInt) => Mux(intrVec(i), i.U, sum))\n1296:   val hasIntr = csrio.exception.valid
      && csrio.exception.bits.isInterrupt\n1297:   val ivmEnable = tlbBundle.priv.imode
      < ModeM && satp.asTypeOf(new SatpStruct).mode === 8.U\n1298:   val iexceptionPC
      = Mux(ivmEnable, SignExt(csrio.exception.bits.pc, XLEN), csrio.exception.bits.pc)\n\
      1299:   val iexceptionGPAddr = Mux(ivmEnable, SignExt(csrio.exception.bits.gpaddr,
      XLEN), csrio.exception.bits.gpaddr)\n1300:   val dvmEnable = tlbBundle.priv.dmode
      < ModeM && satp.asTypeOf(new SatpStruct).mode === 8.U"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1459-1474
    context: "1459:       ((hasDebugTrap && !debugMode) || ebreakEnterParkLoop) ->
      debugTrapTarget\n1460:     )),\n1461:     isXRetFlag || csrio.exception.valid)\n\
      1462: \n1463:   when(hasExceptionIntr) {\n1464:     val mstatusOld = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1465:     val mstatusNew = WireInit(mstatus.asTypeOf(new MstatusStruct))\n\
      1466:     val hstatusOld = WireInit(hstatus.asTypeOf(new HstatusStruct))\n1467:\
      \     val hstatusNew = WireInit(hstatus.asTypeOf(new HstatusStruct))\n1468:\
      \     val vsstatusOld = WireInit(vsstatus.asTypeOf(new MstatusStruct))\n1469:\
      \     val vsstatusNew = WireInit(vsstatus.asTypeOf(new MstatusStruct))\n1470:\
      \     val dcsrNew = WireInit(dcsr.asTypeOf(new DcsrStruct))\n1471:     val debugModeNew
      = WireInit(debugMode)\n1472:     when(hasDebugTrap && !debugMode) {\n1473: \
      \      import DcsrStruct._\n1474:       debugModeNew := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 503-513
    context: "503:   val MBE  = CSRROField     (37).withReset(0.U)\n504:   val GVA\
      \  = CSRRWField     (38).withReset(0.U)\n505:   val MPV  = VirtMode       (39).withReset(0.U)\n\
      506:   val MDT  = CSRRWField     (42).withReset(mdtInit.U)\n507:   val SD  \
      \ = CSRROField     (63,\n508:     (_, _) => FS === ContextStatus.Dirty || VS
      === ContextStatus.Dirty\n509:   )\n510: }\n511: \n512: class MstatusModule(implicit
      override val p: Parameters) extends CSRModule(\"MStatus\", new MstatusBundle)\n\
      513:   with TrapEntryMEventSinkBundle"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 519-529
    context: "519:   with HasRobCommitBundle\n520:   with HasMachineEnvBundle\n521:
      {\n522:   val mstatus = IO(Output(bundle))\n523:   val sstatus = IO(Output(new
      SstatusBundle))\n524:   val sstatusRdata = IO(Output(UInt(64.W)))\n525: \n526:\
      \   val wAliasSstatus = IO(Input(new CSRAddrWriteBundle(new SstatusBundle)))\n\
      527:   for ((name, field) <- wAliasSstatus.wdataFields.elements) {\n528:   \
      \  reg.elements(name).asInstanceOf[CSREnumType].addOtherUpdate(\n529:      \
      \ wAliasSstatus.wen && field.asInstanceOf[CSREnumType].isLegal,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 532-549
    context: "532:   }\n533: \n534:   // write connection\n535:   reconnectReg()\n\
      536: \n537:   when (robCommit.fsDirty || writeFCSR) {\n538:     assert(reg.FS
      =/= ContextStatus.Off, \"The [m|s]status.FS should not be Off when set dirty,
      please check decode\")\n539:     reg.FS := ContextStatus.Dirty\n540:   }\n541:\
      \ \n542:   when (robCommit.vsDirty || writeVCSR || robCommit.vstart.valid &&
      robCommit.vstart.bits =/= 0.U) {\n543:     assert(reg.VS =/= ContextStatus.Off,
      \"The [m|s]status.VS should not be Off when set dirty, please check decode\"\
      )\n544:     reg.VS := ContextStatus.Dirty\n545:   }\n546:   // when MDT is explicitly
      written by 1, clear MIE\n547:   // only when reg.MDT is zero or wdata.MDT is
      zero , MIE can be explicitly written by 1\n548:   when (w.wdataFields.MDT &&
      w.wen) {\n549:     reg.MIE := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 569-579
    context: "569:   // read connection\n570:   mstatus :|= regOut\n571:   sstatus
      := mstatus\n572:   sstatus.SDT := regOut.SDT && menvcfg.DTE\n573:   rdata :=
      mstatus.asUInt\n574:   sstatusRdata := sstatus.asUInt\n575: }\n576: \n577: class
      MnstatusBundle extends CSRBundle {\n578:   val NMIE   = CSRRWField  (3).withReset(1.U)
      // as opensbi not support smrnmi, we init nmie open\n579:   val MNPV   = VirtMode\
      \    (7).withReset(0.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 208-218
    context: "208:       val vmxr = Bool()\n209:       val vsum = Bool()\n210:   \
      \    val spvp = Bool()\n211:       val imode = UInt(2.W)\n212:       val dmode
      = UInt(2.W)\n213:       val dvirt = Bool()\n214:       val mPBMTE = Bool()\n\
      215:       val hPBMTE = Bool()\n216:       val pmm = new Bundle {\n217:    \
      \     val mseccfg = UInt(2.W)\n218:         val menvcfg = UInt(2.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 294-306
    context: "294:   val sstcIRGen = Module(new SstcInterruptGen)\n295:   val commidIdMod
      = Module(new CommitIDModule(40, hartIdLen))\n296: \n297:   commidIdMod.io.hartId
      := io.fromTop.hartId\n298:   val gitCommitSHA = WireInit(commidIdMod.io.commitID)\n\
      299:   val gitDirty     = WireInit(commidIdMod.io.dirty)\n300:   dontTouch(gitCommitSHA)\n\
      301:   dontTouch(gitDirty)\n302: \n303:   private val wenLegal = permitMod.io.out.hasLegalWen\n\
      304: \n305:   val legalSret  = permitMod.io.out.hasLegalSret\n306:   val legalMret\
      \  = permitMod.io.out.hasLegalMret"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 599-610
    context: "599:     mod match {\n600:       case m: HasRobCommitBundle =>\n601:\
      \         // Todo: move RegNext from ROB to CSR\n602:         m.robCommit.instNum
      := io.fromRob.commit.instNum\n603:         m.robCommit.fflags  := RegNextWithEnable(io.fromRob.commit.fflags)\n\
      604:         m.robCommit.fsDirty := GatedValidRegNext(io.fromRob.commit.fsDirty)\n\
      605:         m.robCommit.vsDirty := GatedValidRegNext(io.fromRob.commit.vsDirty)\n\
      606:         m.robCommit.vxsat   := RegNextWithEnable(io.fromRob.commit.vxsat)\n\
      607:         m.robCommit.vtype   := RegNextWithEnable(io.fromRob.commit.vtype)\n\
      608:         m.robCommit.vl      := RegNext          (io.fromRob.commit.vl)\n\
      609:         m.robCommit.vstart  := RegNextWithEnable(io.fromRob.commit.vstart)\n\
      610:         m.writeFCSR         := writeFpLegal"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1428-1438
    context: "1428:   io.tlb.dmode := Mux(\n1429:     (debugMode && dcsr.regOut.MPRVEN
      || !debugMode) && mstatus.regOut.MPRV && mnstatus.regOut.NMIE,\n1430:     mstatus.regOut.MPP.asUInt,\n\
      1431:     PRVM.asUInt\n1432:   )\n1433:   io.tlb.dvirt := Mux(\n1434:     (debugMode
      && dcsr.regOut.MPRVEN || !debugMode) && mstatus.regOut.MPRV && mnstatus.regOut.NMIE
      && mstatus.regOut.MPP =/= PrivMode.M,\n1435:     mstatus.regOut.MPV.asUInt,\n\
      1436:     V.asUInt\n1437:   )\n1438:   io.tlb.mPBMTE := RegNext(menvcfg.regOut.PBMTE.asBool)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/SupervisorLevel.scala
    lines: 197-207
    context: "197:     sstateen3,\n198:     scontext,\n199:   )\n200: \n201:   val
      supervisorLevelCSRMap: SeqMap[Int, (CSRAddrWriteBundle[_], UInt)] = SeqMap(\n\
      202:     CSRs.sstatus -> (mstatus.wAliasSstatus, mstatus.sstatusRdata),\n203:\
      \   ) ++ SeqMap.from(\n204:     supervisorLevelCSRMods.map(csr => (csr.addr
      -> (csr.w, csr.rdata))).iterator\n205:   )\n206: \n207:   val supervisorLevelCSROutMap:
      SeqMap[Int, UInt] = SeqMap("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/SupervisorLevel.scala
    lines: 221-231
    context: "221:   val XS   = ContextStatusRO(16, 15).withReset(0.U)\n222:   val
      SUM  = CSRWARLField   (18, wNoFilter).withReset(0.U)\n223:   val MXR  = CSRWARLField\
      \   (19, wNoFilter).withReset(0.U)\n224:   val SDT  = CSRWARLField   (24, wNoFilter).withReset(0.U)\n\
      225:   val UXL  = XLENField      (33, 32).withReset(XLENField.XLEN64)\n226:\
      \   val SD   = CSRROField     (63, (_, _) => FS === ContextStatus.Dirty || VS
      === ContextStatus.Dirty)\n227: }\n228: \n229: class SieBundle extends InterruptEnableBundle
      {\n230:   this.getHS.foreach(_.setRW().withReset(0.U))\n231:   this.STIE.setRO().withReset(0.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptBundle.scala
    lines: 301-311
    context: "301:   val interruptDefaultPrio = Seq(\n302:     NMI_43, NMI_31\n303:\
      \   )\n304:   def getIRQHigherThan(irq: Int): Seq[Int] = {\n305:     val idx
      = this.interruptDefaultPrio.indexOf(irq, 0)\n306:     require(idx != -1, s\"\
      The irq($irq) does not exists in IntPriority Seq\")\n307:     this.interruptDefaultPrio.slice(0,
      idx)\n308:   }\n309: \n310: }\n311: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/DebugLevel.scala
    lines: 89-103
    context: "89: \n90:   val debugCSROutMap: SeqMap[Int, UInt] = SeqMap.from(\n91:\
      \     debugCSRMods.map(csr => csr.addr -> csr.regOut.asInstanceOf[CSRBundle].asUInt).iterator\n\
      92:   )\n93: \n94:   private val tdata1Rdata = Mux1H(\n95:     tdata1RegVec.zipWithIndex.map{case
      (mod, idx) => (tselect.rdata === idx.U) -> mod.rdata}\n96:   )\n97: \n98:  \
      \ private val tdata2Rdata = Mux1H(\n99:     tdata2RegVec.zipWithIndex.map{case
      (mod, idx) => (tselect.rdata === idx.U) -> mod.rdata}\n100:   )\n101: \n102:\
      \   debugCSRMods.foreach { mod =>\n103:     mod match {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/DebugLevel.scala
    lines: 100-111
    context: "100:   )\n101: \n102:   debugCSRMods.foreach { mod =>\n103:     mod
      match {\n104:       case m: HasTdataSink =>\n105:         m.tdataRead.tdata1
      := tdata1Rdata\n106:         m.tdataRead.tdata2 := tdata2Rdata\n107:       case
      _ =>\n108:     }\n109:   }\n110: \n111: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Unprivileged.scala
    lines: 66-76
    context: "66:   }) with HasRobCommitBundle {\n67:     // Todo make The use of
      vstart values greater than the largest element index for the current SEW setting
      is reserved.\n68:     // Not trap\n69:     when (wen) {\n70:       reg.vstart
      := this.w.wdata(VlWidth - 2, 0)\n71:     }.elsewhen (robCommit.vsDirty && !robCommit.vstart.valid)
      {\n72:       reg.vstart := 0.U\n73:     }.elsewhen (robCommit.vstart.valid)
      {\n74:       reg.vstart := robCommit.vstart.bits\n75:     }.otherwise {\n76:\
      \       reg := reg"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CommitIDModule.scala
    lines: 7-17
    context: "7: \n8: class PrintCommitIDModule(shaWidth: Int, hartIdlen: Int) extends
      BlackBox with HasBlackBoxInline {\n9:   val io = IO(new Bundle{\n10:     val
      hartID = Input(UInt(hartIdlen.W))\n11:     val commitID = Input(UInt(shaWidth.W))\n\
      12:     val dirty = Input(Bool())\n13:   })\n14: \n15:   setInline(\"PrintCommitIDModule.v\"\
      ,\n16:     s\"\"\"\n17:       |module PrintCommitIDModule("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CommitIDModule.scala
    lines: 15-30
    context: "15:   setInline(\"PrintCommitIDModule.v\",\n16:     s\"\"\"\n17:   \
      \    |module PrintCommitIDModule(\n18:       |  input [${hartIdlen-1}:0] hartID,\n\
      19:       |  input [${shaWidth-1}:0] commitID,\n20:       |  input dirty\n21:\
      \       |);\n22:       |  wire _dummy_unused = 1'b1;\n23:       |`ifndef SYNTHESIS\n\
      24:       |  initial begin\n25:       |    $$fwrite(32'h80000001, \"Core %d's
      Commit SHA is: %h, dirty: %d\\\\n\", hartID, commitID, dirty);\n26:       |\
      \  end\n27:       |`endif\n28:       |\n29:       |endmodule\n30:       |\"\"\
      \".stripMargin"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CommitIDModule.scala
    lines: 33-43
    context: "33: \n34: class CommitIDModule(shaWidth: Int, hartIdlen: Int) extends
      Module {\n35:   val io = IO(new Bundle {\n36:     val hartId = Input(UInt(hartIdlen.W))\n\
      37:     val commitID = Output(UInt(shaWidth.W))\n38:     val dirty    = Output(Bool())\n\
      39:   })\n40: \n41:   val props = new Properties()\n42:   props.load((os.resource
      / \"gitStatus\").getInputStream)\n43: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CommitIDModule.scala
    lines: 40-57
    context: "40: \n41:   val props = new Properties()\n42:   props.load((os.resource
      / \"gitStatus\").getInputStream)\n43: \n44:   val sha = props.get(\"SHA\").asInstanceOf[String].take(shaWidth
      / 4)\n45:   val dirty = props.get(\"dirty\").asInstanceOf[String].toInt\n46:\
      \ \n47:   println(s\"[CommitIDModule] SHA=$sha\")\n48:   println(s\"[CommitIDModule]
      dirty=$dirty\")\n49: \n50:   io.commitID := BigInt(sha, 16).U(shaWidth.W)\n\
      51:   io.dirty := dirty.U\n52: \n53:   val printCommitIDMod = Module(new PrintCommitIDModule(shaWidth,
      hartIdlen))\n54:   printCommitIDMod.io.hartID := io.hartId\n55:   printCommitIDMod.io.commitID
      := io.commitID\n56:   printCommitIDMod.io.dirty := io.dirty\n57: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRNamedConstant.scala
    lines: 3-13
    context: "3: import chisel3._\n4: import chisel3.util.Enum\n5: \n6: object CSRNamedConstant
      {\n7:   object ContextStatus {\n8:     val off :: initial :: clean :: dirty
      :: Nil = Enum(4)\n9:   }\n10: \n11:   object MXL {\n12:     val w = 2\n13: \
      \    val XLEN32 = 1.U(w.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/VirtualSupervisorLevel.scala
    lines: 26-43
    context: "26:       with DretEventSinkBundle\n27:       with TrapEntryVSEventSinkBundle\n\
      28:       with HasRobCommitBundle\n29:       with HasVirtualSupervisorEnvBundle\n\
      30:     {\n31:       when ((robCommit.fsDirty || writeFCSR) && isVirtMode) {\n\
      32:         assert(reg.FS =/= ContextStatus.Off, \"The vsstatus.FS should not
      be Off when set dirty, please check decode\")\n33:         reg.FS := ContextStatus.Dirty\n\
      34:       }\n35: \n36:       when ((robCommit.vsDirty || writeVCSR || robCommit.vstart.valid
      && robCommit.vstart.bits =/= 0.U) && isVirtMode) {\n37:         assert(reg.VS
      =/= ContextStatus.Off, \"The vsstatus.VS should not be Off when set dirty, please
      check decode\")\n38:         reg.VS := ContextStatus.Dirty\n39:       }\n40:\
      \       // when menvcfg or henvcfg.DTE close,  vsstatus.SDT is read-only\n41:\
      \       val writeSDT = Wire(Bool())\n42:       writeSDT := Mux(this.menvcfg.DTE
      && this.henvcfg.DTE, w.wdataFields.SDT.asBool, 0.U)\n43:       when (!(this.menvcfg.DTE
      && this.henvcfg.DTE)) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRBundles.scala
    lines: 160-172
    context: "160: \n161:   class RobCommitCSR(implicit p: Parameters) extends Bundle
      {\n162:     // need contain 8x8\n163:     val instNum = ValidIO(UInt(7.W))\n\
      164:     val fflags  = ValidIO(Fflags())\n165:     val fsDirty = Bool()\n166:\
      \     val vxsat   = ValidIO(Vxsat())\n167:     val vsDirty = Bool()\n168:  \
      \   val vtype   = ValidIO(new CSRVTypeBundle)\n169:     val vl      = Vl()\n\
      170:     val vstart  = ValidIO(Vstart())\n171:   }\n172: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRDefines.scala
    lines: 139-149
    context: "139:   object ContextStatusRO extends CSREnum with ContextStatusDef
      with ROApply\n140:   trait ContextStatusDef { this: CSREnum =>\n141:     val
      Off = Value(0.U)\n142:     val Initial = Value(1.U)\n143:     val Clean = Value(2.U)\n\
      144:     val Dirty = Value(3.U)\n145:   }\n146: \n147:   object BMAField extends
      CSREnum with WARLApply {\n148:     val ResetBMA = Value(0.U)\n149:     val TestBMA
      = Value(\"h4000000\".U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 581-591
    context: "581: \n582:   private val csrio = intExuBlock.io.csrio.get\n583:   csrio.hartId
      := io.fromTop.hartId\n584:   csrio.fpu.fflags := ctrlBlock.io.robio.csr.fflags\n\
      585:   csrio.fpu.isIllegal := false.B // Todo: remove it\n586:   csrio.fpu.dirty_fs
      := ctrlBlock.io.robio.csr.dirty_fs\n587:   csrio.vpu <> WireDefault(0.U.asTypeOf(csrio.vpu))
      // Todo\n588: \n589:   val fromIntExuVsetVType = intExuBlock.io.vtype.getOrElse(0.U.asTypeOf((Valid(new
      VType))))\n590:   val fromVfExuVsetVType = vfExuBlock.io.vtype.getOrElse(0.U.asTypeOf((Valid(new
      VType))))\n591:   val fromVsetVType = Mux(fromIntExuVsetVType.valid, fromIntExuVsetVType.bits,
      fromVfExuVsetVType.bits)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 607-617
    context: "607:   ctrlBlock.io.toDecode.vstart := csrio.vpu.vstart\n608:   //Todo
      here need change design\n609:   csrio.vpu.set_vtype.valid := commitVType.valid\n\
      610:   csrio.vpu.set_vtype.bits := ZeroExt(vtype, XLEN)\n611:   csrio.vpu.vl
      := ZeroExt(debugVl_s1, XLEN)\n612:   csrio.vpu.dirty_vs := ctrlBlock.io.robio.csr.dirty_vs\n\
      613:   csrio.exception := ctrlBlock.io.robio.exception\n614:   csrio.robDeqPtr
      := ctrlBlock.io.robio.robDeqPtr\n615:   csrio.memExceptionVAddr := io.mem.exceptionAddr.vaddr\n\
      616:   csrio.memExceptionGPAddr := io.mem.exceptionAddr.gpaddr\n617:   csrio.memExceptionIsForVSnonLeafPTE
      := io.mem.exceptionAddr.isForVSnonLeafPTE"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 694-704
    context: "694:   }\n695: \n696:   object BTBtype {\n697:     def B = \"b00\".U\
      \  // branch\n698:     def J = \"b01\".U  // jump\n699:     def I = \"b10\"\
      .U  // indirect\n700:     def R = \"b11\".U  // return\n701: \n702:     def
      apply() = UInt(2.W)\n703:   }\n704: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 764-774
    context: "764:     }\n765:   }\n766: \n767:   object UopSplitType {\n768:    \
      \ def SCA_SIM          = \"b000000\".U //\n769:     def VSET             = \"\
      b010001\".U // dirty: vset\n770:     def VEC_VVV          = \"b010010\".U //
      VEC_VVV\n771:     def VEC_VXV          = \"b010011\".U // VEC_VXV\n772:    \
      \ def VEC_0XV          = \"b010100\".U // VEC_0XV\n773:     def VEC_VVW    \
      \      = \"b010101\".U // VEC_VVW\n774:     def VEC_WVW          = \"b010110\"\
      .U // VEC_WVW"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 905-915
    context: "905:       hardwareError\n906:     )\n907: \n908:     def getHigherExcpThan(excp:
      Int): Seq[Int] = {\n909:       val idx = this.priorities.indexOf(excp, 0)\n\
      910:       require(idx != -1, s\"The irq($excp) does not exists in IntPriority
      Seq\")\n911:       this.priorities.slice(0, idx)\n912:     }\n913: \n914:  \
      \   def all = priorities.distinct.sorted\n915:     def frontendSet = Seq("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/Bundles.scala
    lines: 161-171
    context: "161:     // load inst replay informations\n162:     val rep_info = new
      LoadToLsqReplayIO\n163:     val nc_with_data = Bool() // nc access with data\n\
      164:     // queue entry data, except flag bits, will be updated if writeQueue
      is true,\n165:     // valid bit in LqWriteBundle will be ignored\n166:     val
      data_wen_dup = Vec(6, Bool()) // dirty reg dup\n167: \n168:     def fromLsPipelineBundle(input:
      LsPipelineBundle, latch: Boolean = false, enable: Bool = true.B) = {\n169: \
      \      val inputReg = latch match {\n170:         case true   => RegEnable(input,
      enable)\n171:         case false  => input"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/PrefetcherMonitor.scala
    lines: 37-47
    context: "37:     val late_hit_prefetch = Input(Bool())\n38:     val late_miss_prefetch
      = Input(Bool())\n39:     val prefetch_hit = Input(UInt(2.W))\n40:   }\n41: \n\
      42:   val validity = new XSBundle {\n43:     val good_prefetch = Input(Bool())\n\
      44:     val bad_prefetch = Input(Bool())\n45:   }\n46: \n47:   val pf_ctrl =
      Output(new PrefetchControlBundle)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/PrefetcherMonitor.scala
    lines: 86-97
    context: "86:   total_prefetch_cnt := Mux(timely_reset, 0.U, total_prefetch_cnt
      + io.timely.total_prefetch)\n87:   late_hit_prefetch_cnt := Mux(timely_reset,
      0.U, late_hit_prefetch_cnt + io.timely.late_hit_prefetch)\n88:   late_miss_prefetch_cnt
      := Mux(timely_reset, 0.U, late_miss_prefetch_cnt + io.timely.late_miss_prefetch)\n\
      89:   prefetch_hit_cnt := Mux(timely_reset, 0.U, prefetch_hit_cnt + io.timely.prefetch_hit)\n\
      90: \n91:   good_prefetch_cnt := Mux(validity_reset, 0.U, good_prefetch_cnt
      + io.validity.good_prefetch)\n92:   bad_prefetch_cnt := Mux(validity_reset,
      0.U, bad_prefetch_cnt + io.validity.bad_prefetch)\n93: \n94:   back_off_cnt
      := Mux(back_off_reset, 0.U, back_off_cnt + !enable)\n95:   low_conf_cnt := Mux(conf_reset,
      0.U, low_conf_cnt + !confidence.asBool)\n96: \n97:   val trigger_late_hit =
      timely_reset && (late_hit_prefetch_cnt >= LATE_HIT_THRESHOLD.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/PrefetcherMonitor.scala
    lines: 139-150
    context: "139:   }\n140: \n141:   XSPerfAccumulate(\"total_prefetch\", io.timely.total_prefetch)\n\
      142:   XSPerfAccumulate(\"late_hit_prefetch\", io.timely.late_hit_prefetch)\n\
      143:   XSPerfAccumulate(\"late_miss_prefetch\", io.timely.late_miss_prefetch)\n\
      144:   XSPerfAccumulate(\"good_prefetch\", io.validity.good_prefetch)\n145:\
      \   XSPerfAccumulate(\"bad_prefetch\", io.validity.bad_prefetch)\n146:   for(i
      <- (0 until DEPTH_BITS)) {\n147:     val t = (1 << i)\n148:     XSPerfAccumulate(s\"\
      depth${t}\", depth === t.U)\n149:   }\n150:   XSPerfAccumulate(\"trigger_disable\"\
      , trigger_disable)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 539-549
    context: "539:   val br_taken_mask = Vec(numBr, Bool())\n540: \n541:   val slot_valids
      = Vec(totalSlot, Bool())\n542: \n543:   val targets         = Vec(totalSlot,
      UInt(VAddrBits.W))\n544:   val jalr_target     = UInt(VAddrBits.W) // special
      path for indirect predictors\n545:   val offsets         = Vec(totalSlot, UInt(log2Ceil(PredictWidth).W))\n\
      546:   val fallThroughAddr = UInt(VAddrBits.W)\n547:   val fallThroughErr  =
      Bool()\n548:   val multiHit        = Bool()\n549: "
- sv_file: /code/XiangShan/build/rtl/NewIFU.sv
  diff_snippet: "--- a//code/XiangShan/build/rtl/NewIFU.sv\n+++ b//code/XiangShan/build/rtl/NewIFU.sv\n\
    @@ -663,12 +663,15 @@..."
  search_terms:
  - f3_req_is_mmio
  - io_ftqInter_fromFtq_redirect_valid
  - mmio_redirect_REG
  - f3_mmio_use_seq_pc
  - f3_mmio_req_commit
  - f3_ftq_req_ftqIdx_value
  - mmio_state
  - mmio_redirect
  - wb_redirect_probe
  - f3_ready
  - f3_itlb_pbmt
  - _mmio_redirect_T
  - f3_lastHalf_valid
  - f3_wb_not_flush
  - f2_flush
  - _mmio_state_T_14
  - fromFtqRedirectReg_bits_r_ftqIdx_value
  chisel_hints:
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLBMissQueue.scala
    lines: 39-45
    context: "39: \n40: class L2TlbMissQueue(implicit p: Parameters) extends XSModule
      with HasPtwConst {\n41:   require(MissQueueSize >= (l2tlbParams.ifilterSize
      + l2tlbParams.dfilterSize))\n42:   val io = IO(new L2TlbMQIO())\n43: \n44: \
      \  io.out <> Queue(io.in, MissQueueSize, flush = Some(io.sfence.valid || io.csr.satp.changed
      || io.csr.vsatp.changed || io.csr.hgatp.changed || io.csr.priv.virt_changed))\n\
      45: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 38-48
    context: "38: \n39: class PageCachePerPespBundle(implicit p: Parameters) extends
      PtwBundle {\n40:   val hit = Bool()\n41:   val pre = Bool()\n42:   val ppn =
      UInt(gvpnLen.W)\n43:   val pbmt = UInt(ptePbmtLen.W)\n44:   val perm = new PtePermBundle()\n\
      45:   val n = UInt(pteNLen.W)\n46:   val ecc = Bool()\n47:   val level = UInt(2.W)\n\
      48:   val v = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 49-59
    context: "49:   val bitmapCheck = Option.when(HasBitmapCheck)(new Bundle {\n50:\
      \     val jmp_bitmap_check = Bool()\n51:     val pte = UInt(XLEN.W) // Page
      Table Entry\n52:   })\n53: \n54:   def apply(hit: Bool, pre: Bool, ppn: UInt,
      pbmt: UInt = 0.U, n: UInt = 0.U,\n55:             perm: PtePermBundle = 0.U.asTypeOf(new
      PtePermBundle()),\n56:             ecc: Bool = false.B, level: UInt = 0.U, valid:
      Bool = true.B, jmp_bitmap_check: Bool = false.B,\n57:             pte: UInt
      = 0.U): Unit = {\n58:     this.hit := hit && !ecc\n59:     this.pre := pre"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 57-67
    context: "57:             pte: UInt = 0.U): Unit = {\n58:     this.hit := hit
      && !ecc\n59:     this.pre := pre\n60:     this.ppn := ppn\n61:     this.n :=
      n\n62:     this.pbmt := pbmt\n63:     this.perm := perm\n64:     this.ecc :=
      ecc && hit\n65:     this.level := level\n66:     this.v := valid\n67:     if
      (HasBitmapCheck) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 74-84
    context: "74: class PageCacheMergePespBundle(implicit p: Parameters) extends PtwBundle
      {\n75:   assert(tlbcontiguous == 8, \"Only support tlbcontiguous = 8!\")\n76:\
      \   val hit = Bool()\n77:   val pre = Bool()\n78:   val ppn = Vec(tlbcontiguous,
      UInt(gvpnLen.W))\n79:   val pbmt = Vec(tlbcontiguous, UInt(ptePbmtLen.W))\n\
      80:   val perm = Vec(tlbcontiguous, new PtePermBundle())\n81:   val ecc = Bool()\n\
      82:   val level = UInt(2.W)\n83:   val v = Vec(tlbcontiguous, Bool())\n84: \
      \  val bitmapCheck = Option.when(HasBitmapCheck)(new Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 86-96
    context: "86:     val hitway = UInt(l2tlbParams.l0nWays.W)\n87:     val ptes =
      Vec(tlbcontiguous, UInt(XLEN.W)) // Page Table Entry Vector\n88:     val cfs
      = Vec(tlbcontiguous, Bool()) // Bitmap Check Failed Vector\n89:   })\n90: \n\
      91:   def apply(hit: Bool, pre: Bool, ppn: Vec[UInt], pbmt: Vec[UInt] = Vec(tlbcontiguous,
      0.U),\n92:             perm: Vec[PtePermBundle] = Vec(tlbcontiguous, 0.U.asTypeOf(new
      PtePermBundle())),\n93:             ecc: Bool = false.B, level: UInt = 0.U,
      valid: Vec[Bool] = Vec(tlbcontiguous, true.B),\n94:             jmp_bitmap_check:
      Bool = false.B,\n95:             hitway: UInt = 0.U, ptes: Vec[UInt] , cfs:
      Vec[Bool]): Unit = {\n96:     this.hit := hit && !ecc"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 94-104
    context: "94:             jmp_bitmap_check: Bool = false.B,\n95:             hitway:
      UInt = 0.U, ptes: Vec[UInt] , cfs: Vec[Bool]): Unit = {\n96:     this.hit :=
      hit && !ecc\n97:     this.pre := pre\n98:     this.ppn := ppn\n99:     this.pbmt
      := pbmt\n100:     this.perm := perm\n101:     this.ecc := ecc && hit\n102: \
      \    this.level := level\n103:     this.v := valid\n104:     if (HasBitmapCheck)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 224-235
    context: "224: \n225:   val sfence_dup = io.sfence_dup\n226:   val refill = io.refill.bits\n\
      227:   val refill_prefetch_dup = io.refill.bits.req_info_dup.map(a => from_pre(a.source))\n\
      228:   val refill_h = io.refill.bits.req_info_dup.map(a => Mux(a.s2xlate ===
      allStage, onlyStage1, a.s2xlate))\n229:   val flush_dup = sfence_dup.zip(io.csr_dup).map(f
      => f._1.valid || f._2.satp.changed || f._2.vsatp.changed || f._2.hgatp.changed
      || f._2.priv.virt_changed)\n230:   val flush = flush_dup(0)\n231: \n232:   //
      when refill, refuce to accept new req\n233:   val rwHarzad = if (sramSinglePort)
      io.refill.valid else false.B\n234: \n235:   // handle hand signal and req_info"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 232-258
    context: "232:   // when refill, refuce to accept new req\n233:   val rwHarzad
      = if (sramSinglePort) io.refill.valid else false.B\n234: \n235:   // handle
      hand signal and req_info\n236:   // TODO: replace with FlushableQueue\n237:\
      \   val stageReq = Wire(Decoupled(new PtwCacheReq()))         // enq stage &
      read page cache valid\n238:   val stageDelay = Wire(Vec(2, Decoupled(new PtwCacheReq())))
      // page cache resp\n239:   val stageCheck = Wire(Vec(2, Decoupled(new PtwCacheReq())))
      // check hit & check ecc\n240:   val stageResp = Wire(Decoupled(new PtwCacheReq()))\
      \         // deq stage\n241: \n242:   val stageDelay_valid_1cycle = OneCycleValid(stageReq.fire,
      flush)      // catch ram data\n243:   val stageCheck_valid_1cycle = OneCycleValid(stageDelay(1).fire,
      flush) // replace & perf counter\n244:   val stageResp_valid_1cycle_dup = Wire(Vec(2,
      Bool()))\n245:   stageResp_valid_1cycle_dup.map(_ := OneCycleValid(stageCheck(1).fire,
      flush))  // ecc flush\n246: \n247:   stageReq <> io.req\n248:   PipelineConnect(stageReq,
      stageDelay(0), stageDelay(1).ready, flush, rwHarzad)\n249:   InsideStageConnect(stageDelay(0),
      stageDelay(1), stageDelay_valid_1cycle)\n250:   PipelineConnect(stageDelay(1),
      stageCheck(0), stageCheck(1).ready, flush)\n251:   InsideStageConnect(stageCheck(0),
      stageCheck(1), stageCheck_valid_1cycle)\n252:   PipelineConnect(stageCheck(1),
      stageResp, io.resp.ready, flush)\n253:   stageResp.ready := !stageResp.valid
      || io.resp.ready\n254: \n255:   // l3: level 3 non-leaf pte\n256:   val l3 =
      if (EnableSv48) Some(Reg(Vec(l2tlbParams.l3Size, new PtwEntry(tagLen = PtwL3TagLen))))
      else None\n257:   val l3v = if (EnableSv48) Some(RegInit(0.U(l2tlbParams.l3Size.W)))
      else None\n258:   val l3g = if (EnableSv48) Some(Reg(UInt(l2tlbParams.l3Size.W)))
      else None"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 274-284
    context: "274:     set = l2tlbParams.l1nSets,\n275:     way = l2tlbParams.l1nWays,\n\
      276:     waySplit = 1,\n277:     dataSplit = 4,\n278:     singlePort = sramSinglePort,\n\
      279:     readMCP2 = false,\n280:     hasMbist = hasMbist,\n281:     hasSramCtl
      = hasSramCtl\n282:   ))\n283:   val mbistPlL1 = MbistPipeline.PlaceMbistPipeline(1,
      s\"MbistPipePtwL1\", hasMbist)\n284:   val l1v = RegInit(0.U((l2tlbParams.l1nSets
      * l2tlbParams.l1nWays).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 313-323
    context: "313:     set = l2tlbParams.l0nSets,\n314:     way = l2tlbParams.l0nWays,\n\
      315:     waySplit = 2,\n316:     dataSplit = 4,\n317:     singlePort = sramSinglePort,\n\
      318:     readMCP2 = false,\n319:     hasMbist = hasMbist,\n320:     hasSramCtl
      = hasSramCtl\n321:   ))\n322:   val mbistPlL0 = MbistPipeline.PlaceMbistPipeline(1,
      s\"MbistPipePtwL0\", hasMbist)\n323:   val l0v = RegInit(0.U((l2tlbParams.l0nSets
      * l2tlbParams.l0nWays).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 407-417
    context: "407:   ))\n408: \n409:   // l3\n410:   val l3Hit = if(EnableSv48) Some(Wire(Bool()))
      else None\n411:   val l3HitPPN = if(EnableSv48) Some(Wire(UInt(gvpnLen.W)))
      else None\n412:   val l3HitPbmt = if(EnableSv48) Some(Wire(UInt(ptePbmtLen.W)))
      else None\n413:   val l3Pre = if(EnableSv48) Some(Wire(Bool())) else None\n\
      414:   val ptwl3replace = if(EnableSv48) Some(ReplacementPolicy.fromString(l2tlbParams.l3Replacer,
      l2tlbParams.l3Size)) else None\n415:   if (EnableSv48) {\n416:     val hitVecT
      = l3.get.zipWithIndex.map {\n417:         case (e, i) => (e.hit(vpn_search,
      io.csr_dup(2).satp.asid, io.csr_dup(2).vsatp.asid, io.csr_dup(2).hgatp.vmid,
      ignoreID = l3g.get(i), s2xlate = h_search)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 415-429
    context: "415:   if (EnableSv48) {\n416:     val hitVecT = l3.get.zipWithIndex.map
      {\n417:         case (e, i) => (e.hit(vpn_search, io.csr_dup(2).satp.asid, io.csr_dup(2).vsatp.asid,
      io.csr_dup(2).hgatp.vmid, ignoreID = l3g.get(i), s2xlate = h_search)\n418: \
      \          && l3v.get(i) && h_search === l3h.get(i))\n419:     }\n420:     val
      hitVec = hitVecT.map(RegEnable(_, stageReq.fire))\n421: \n422:     // stageDelay,
      but check for l3\n423:     val hitPPN = DataHoldBypass(ParallelPriorityMux(hitVec
      zip l3.get.map(_.ppn)), stageDelay_valid_1cycle)\n424:     val hitPbmt = DataHoldBypass(ParallelPriorityMux(hitVec
      zip l3.get.map(_.pbmt)), stageDelay_valid_1cycle)\n425:     val hitPre = DataHoldBypass(ParallelPriorityMux(hitVec
      zip l3.get.map(_.prefetch)), stageDelay_valid_1cycle)\n426:     val hit = DataHoldBypass(ParallelOR(hitVec),
      stageDelay_valid_1cycle)\n427: \n428:     when (hit && stageDelay_valid_1cycle)
      { ptwl3replace.get.access(OHToUInt(hitVec)) }\n429: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 427-439
    context: "427: \n428:     when (hit && stageDelay_valid_1cycle) { ptwl3replace.get.access(OHToUInt(hitVec))
      }\n429: \n430:     l3AccessPerf.get.zip(hitVec).map{ case (l, h) => l := h &&
      stageDelay_valid_1cycle}\n431:     for (i <- 0 until l2tlbParams.l3Size) {\n\
      432:       XSDebug(stageReq.fire, p\"[l3] l3(${i.U}) ${l3.get(i)} hit:${l3.get(i).hit(vpn_search,
      io.csr_dup(2).satp.asid, io.csr_dup(2).vsatp.asid, io.csr_dup(2).hgatp.vmid,
      ignoreID = l3g.get(i), s2xlate = h_search)}\\n\")\n433:     }\n434:     XSDebug(stageReq.fire,
      p\"[l3] l3v:${Binary(l3v.get)} hitVecT:${Binary(VecInit(hitVecT).asUInt)}\\\
      n\")\n435:     XSDebug(stageDelay(0).valid, p\"[l3] l3Hit:${hit} l3HitPPN:0x${Hexadecimal(hitPPN)}
      hitVec:${VecInit(hitVec).asUInt}\\n\")\n436: \n437:     VecInit(hitVecT).suggestName(s\"\
      l3_hitVecT\")\n438:     VecInit(hitVec).suggestName(s\"l3_hitVec\")\n439: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 436-463
    context: "436: \n437:     VecInit(hitVecT).suggestName(s\"l3_hitVecT\")\n438:\
      \     VecInit(hitVec).suggestName(s\"l3_hitVec\")\n439: \n440:     // synchronize
      with other entries with RegEnable\n441:     l3Hit.map(_ := RegEnable(hit, stageDelay(1).fire))\n\
      442:     l3HitPPN.map(_ := RegEnable(hitPPN, stageDelay(1).fire))\n443:    \
      \ l3HitPbmt.map(_ := RegEnable(hitPbmt, stageDelay(1).fire))\n444:     l3Pre.map(_
      := RegEnable(hitPre, stageDelay(1).fire))\n445:   }\n446: \n447:   // l2\n448:\
      \   val ptwl2replace = ReplacementPolicy.fromString(l2tlbParams.l2Replacer,
      l2tlbParams.l2Size)\n449:   val (l2Hit, l2HitPPN, l2HitPbmt, l2Pre) = {\n450:\
      \     val hitVecT = l2.zipWithIndex.map {\n451:       case (e, i) => (e.hit(vpn_search,
      io.csr_dup(2).satp.asid, io.csr_dup(2).vsatp.asid, io.csr_dup(2).hgatp.vmid,
      ignoreID = l2g(i), s2xlate = h_search)\n452:         && l2v(i) && h_search ===
      l2h(i))\n453:     }\n454:     val hitVec = hitVecT.map(RegEnable(_, stageReq.fire))\n\
      455: \n456:     // stageDelay, but check for l2\n457:     val hitPPN = DataHoldBypass(ParallelPriorityMux(hitVec
      zip l2.map(_.ppn)), stageDelay_valid_1cycle)\n458:     val hitPbmt = DataHoldBypass(ParallelPriorityMux(hitVec
      zip l2.map(_.pbmt)), stageDelay_valid_1cycle)\n459:     val hitPre = DataHoldBypass(ParallelPriorityMux(hitVec
      zip l2.map(_.prefetch)), stageDelay_valid_1cycle)\n460:     val hit = DataHoldBypass(ParallelOR(hitVec),
      stageDelay_valid_1cycle)\n461: \n462:     when (hit && stageDelay_valid_1cycle)
      { ptwl2replace.access(OHToUInt(hitVec)) }\n463: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 461-473
    context: "461: \n462:     when (hit && stageDelay_valid_1cycle) { ptwl2replace.access(OHToUInt(hitVec))
      }\n463: \n464:     l2AccessPerf.zip(hitVec).map{ case (l, h) => l := h && stageDelay_valid_1cycle}\n\
      465:     for (i <- 0 until l2tlbParams.l2Size) {\n466:       XSDebug(stageReq.fire,
      p\"[l2] l2(${i.U}) ${l2(i)} hit:${l2(i).hit(vpn_search, io.csr_dup(2).satp.asid,
      io.csr_dup(2).vsatp.asid, io.csr_dup(2).hgatp.vmid, ignoreID = l2g(i), s2xlate
      = h_search)}\\n\")\n467:     }\n468:     XSDebug(stageReq.fire, p\"[l2] l2v:${Binary(l2v)}
      hitVecT:${Binary(VecInit(hitVecT).asUInt)}\\n\")\n469:     XSDebug(stageDelay(0).valid,
      p\"[l2] l2Hit:${hit} l2HitPPN:0x${Hexadecimal(hitPPN)} hitVec:${VecInit(hitVec).asUInt}\\\
      n\")\n470: \n471:     VecInit(hitVecT).suggestName(s\"l2_hitVecT\")\n472:  \
      \   VecInit(hitVec).suggestName(s\"l2_hitVec\")\n473: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 470-490
    context: "470: \n471:     VecInit(hitVecT).suggestName(s\"l2_hitVecT\")\n472:\
      \     VecInit(hitVec).suggestName(s\"l2_hitVec\")\n473: \n474:     // synchronize
      with other entries with RegEnable\n475:     (RegEnable(hit, stageDelay(1).fire),\n\
      476:      RegEnable(hitPPN, stageDelay(1).fire),\n477:      RegEnable(hitPbmt,
      stageDelay(1).fire),\n478:      RegEnable(hitPre, stageDelay(1).fire))\n479:\
      \   }\n480: \n481:   // l1\n482:   val ptwl1replace = ReplacementPolicy.fromString(l2tlbParams.l1Replacer,l2tlbParams.l1nWays,l2tlbParams.l1nSets)\n\
      483:   val (l1Hit, l1HitPPN, l1HitPbmt, l1Pre, l1eccError) = {\n484:     val
      ridx = genPtwL1SetIdx(vpn_search)\n485:     l1.io.r.req.valid := stageReq.fire\n\
      486:     l1.io.r.req.bits.apply(setIdx = ridx)\n487:     val vVec_req = getl1vSet(vpn_search)\n\
      488:     val hVec_req = getl1hSet(vpn_search)\n489:     val gVec_req = getl1gSet(vpn_search)\n\
      490: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 494-506
    context: "494:       allStage -> onlyStage1,\n495:       onlyStage1 -> onlyStage1,\n\
      496:       onlyStage2 -> onlyStage2\n497:     ))\n498:     val data_resp = DataHoldBypass(l1.io.r.resp.data,
      stageDelay_valid_1cycle)\n499:     val vVec_delay = RegEnable(vVec_req, stageReq.fire)\n\
      500:     val hVec_delay = RegEnable(hVec_req, stageReq.fire)\n501:     val gVec_delay
      = RegEnable(gVec_req, stageReq.fire)\n502:     val hitVec_delay = VecInit(data_resp.zip(vVec_delay.asBools).zip(gVec_delay.asBools).zip(hVec_delay).map
      { case (((wayData, v), g), h) =>\n503:       wayData.entries.hit(delay_vpn,
      io.csr_dup(1).satp.asid, io.csr_dup(1).vsatp.asid, io.csr_dup(1).hgatp.vmid,
      ignoreID = g, s2xlate = delay_h) && v && (delay_h === h)})\n504: \n505:    \
      \ // check hit and ecc\n506:     val check_vpn = stageCheck(0).bits.req_info.vpn"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 502-515
    context: "502:     val hitVec_delay = VecInit(data_resp.zip(vVec_delay.asBools).zip(gVec_delay.asBools).zip(hVec_delay).map
      { case (((wayData, v), g), h) =>\n503:       wayData.entries.hit(delay_vpn,
      io.csr_dup(1).satp.asid, io.csr_dup(1).vsatp.asid, io.csr_dup(1).hgatp.vmid,
      ignoreID = g, s2xlate = delay_h) && v && (delay_h === h)})\n504: \n505:    \
      \ // check hit and ecc\n506:     val check_vpn = stageCheck(0).bits.req_info.vpn\n\
      507:     val ramDatas = RegEnable(data_resp, stageDelay(1).fire)\n508:     val
      vVec = RegEnable(vVec_delay, stageDelay(1).fire).asBools\n509: \n510:     val
      hitVec = RegEnable(hitVec_delay, stageDelay(1).fire)\n511:     val hitWayEntry
      = ParallelPriorityMux(hitVec zip ramDatas)\n512:     val hitWayData = hitWayEntry.entries\n\
      513:     val hit = ParallelOR(hitVec)\n514:     val hitWay = ParallelPriorityMux(hitVec
      zip (0 until l2tlbParams.l1nWays).map(_.U(log2Up(l2tlbParams.l1nWays).W)))\n\
      515:     val eccError = WireInit(false.B)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 535-546
    context: "535:     XSDebug(stageCheck_valid_1cycle, p\"[l1] l1Hit:${hit} l1HitPPN:0x${Hexadecimal(hitWayData.ppns(genPtwL1SectorIdx(check_vpn)))}
      hitVec:${Binary(hitVec.asUInt)} hitWay:${hitWay} vidx:${vVec}\\n\")\n536: \n\
      537:     (hit, hitWayData.ppns(genPtwL1SectorIdx(check_vpn)), hitWayData.pbmts(genPtwL1SectorIdx(check_vpn)),
      hitWayData.prefetch, eccError)\n538:   }\n539:   val te = ClockGate.genTeSink\n\
      540:   val l0_masked_clock = ClockGate(te.cgen, stageReq.fire | (!flush_dup(0)
      && refill.levelOH.l0) | mbistPlL0.map(_.mbist.req).getOrElse(false.B), clock)\n\
      541:   val l1_masked_clock = ClockGate(te.cgen, stageReq.fire | (!flush_dup(1)
      && refill.levelOH.l1) | mbistPlL1.map(_.mbist.req).getOrElse(false.B), clock)\n\
      542:   l0.clock := l0_masked_clock\n543:   l1.clock := l1_masked_clock\n544:\
      \   // l0\n545:   val ptwl0replace = ReplacementPolicy.fromString(l2tlbParams.l0Replacer,l2tlbParams.l0nWays,l2tlbParams.l0nSets)\n\
      546:   val (l0Hit, l0HitData, l0Pre, l0eccError, l0HitWay, l0BitmapCheckResult,
      l0JmpBitmapCheck) = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 543-553
    context: "543:   l1.clock := l1_masked_clock\n544:   // l0\n545:   val ptwl0replace
      = ReplacementPolicy.fromString(l2tlbParams.l0Replacer,l2tlbParams.l0nWays,l2tlbParams.l0nSets)\n\
      546:   val (l0Hit, l0HitData, l0Pre, l0eccError, l0HitWay, l0BitmapCheckResult,
      l0JmpBitmapCheck) = {\n547:     val ridx = genPtwL0SetIdx(vpn_search)\n548:\
      \     l0.io.r.req.valid := stageReq.fire\n549:     l0.io.r.req.bits.apply(setIdx
      = ridx)\n550:     val vVec_req = getl0vSet(vpn_search)\n551:     val hVec_req
      = getl0hSet(vpn_search)\n552: \n553:     // delay one cycle after sram read"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 556-567
    context: "556:       allStage -> onlyStage1,\n557:       onlyStage1 -> onlyStage1,\n\
      558:       onlyStage2 -> onlyStage2\n559:     ))\n560:     val data_resp = DataHoldBypass(l0.io.r.resp.data,
      stageDelay_valid_1cycle)\n561:     val vVec_delay = RegEnable(vVec_req, stageReq.fire)\n\
      562:     val hVec_delay = RegEnable(hVec_req, stageReq.fire)\n563:     val hitVec_delay
      = VecInit(data_resp.zip(vVec_delay.asBools).zip(hVec_delay).map { case ((wayData,
      v), h) =>\n564:       wayData.entries.hit(delay_vpn, io.csr_dup(0).satp.asid,
      io.csr_dup(0).vsatp.asid, io.csr_dup(0).hgatp.vmid, s2xlate = delay_h) && v
      && (delay_h === h)})\n565: \n566:     // check hit and ecc\n567:     val check_vpn
      = stageCheck(0).bits.req_info.vpn"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 563-576
    context: "563:     val hitVec_delay = VecInit(data_resp.zip(vVec_delay.asBools).zip(hVec_delay).map
      { case ((wayData, v), h) =>\n564:       wayData.entries.hit(delay_vpn, io.csr_dup(0).satp.asid,
      io.csr_dup(0).vsatp.asid, io.csr_dup(0).hgatp.vmid, s2xlate = delay_h) && v
      && (delay_h === h)})\n565: \n566:     // check hit and ecc\n567:     val check_vpn
      = stageCheck(0).bits.req_info.vpn\n568:     val ramDatas = RegEnable(data_resp,
      stageDelay(1).fire)\n569:     val vVec = RegEnable(vVec_delay, stageDelay(1).fire).asBools\n\
      570: \n571:     val hitVec = RegEnable(hitVec_delay, stageDelay(1).fire)\n572:\
      \     val hitWayEntry = ParallelPriorityMux(hitVec zip ramDatas)\n573:     val
      hitWayData = hitWayEntry.entries\n574:     val hitWayEcc = hitWayEntry.ecc\n\
      575:     val hitWay = ParallelPriorityMux(hitVec zip (0 until l2tlbParams.l0nWays).map(_.U(log2Up(l2tlbParams.l0nWays).W)))\n\
      576: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 572-589
    context: "572:     val hitWayEntry = ParallelPriorityMux(hitVec zip ramDatas)\n\
      573:     val hitWayData = hitWayEntry.entries\n574:     val hitWayEcc = hitWayEntry.ecc\n\
      575:     val hitWay = ParallelPriorityMux(hitVec zip (0 until l2tlbParams.l0nWays).map(_.U(log2Up(l2tlbParams.l0nWays).W)))\n\
      576: \n577:     val ishptw = RegEnable(stageDelay(0).bits.isHptwReq,stageDelay(1).fire)\n\
      578:     val s2x_info = RegEnable(stageDelay(0).bits.req_info.s2xlate,stageDelay(1).fire)\n\
      579:     val pte_index = RegEnable(stageDelay(0).bits.req_info.vpn(sectortlbwidth
      - 1, 0),stageDelay(1).fire)\n580:     val jmp_bitmap_check  = WireInit(false.B)\n\
      581:     val hit = WireInit(false.B)\n582:     val l0bitmapreg = WireInit((VecInit(Seq.fill(l2tlbParams.l0nWays)(VecInit(Seq.fill(tlbcontiguous)(0.U(1.W)))))))\n\
      583:     if (HasBitmapCheck) {\n584:       l0bitmapreg := RegEnable(RegNext(l0BitmapReg(ridx)),
      stageDelay(1).fire)\n585:       // cause llptw will trigger bitmapcheck\n586:\
      \       // add a coniditonal logic\n587:       // (s2x_info =/= allStage ||
      ishptw)\n588:       hit := Mux(bitmapEnable && (s2x_info =/= allStage || ishptw),
      ParallelOR(hitVec) && l0bitmapreg(hitWay)(pte_index) === 1.U, ParallelOR(hitVec))\n\
      589:       when (bitmapEnable && (s2x_info =/= allStage || ishptw) && ParallelOR(hitVec)
      && l0bitmapreg(hitWay)(pte_index) === 0.U) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 600-610
    context: "600:     }\n601: \n602:     when (hit && stageCheck_valid_1cycle) {
      ptwl0replace.access(genPtwL0SetIdx(check_vpn), hitWay) }\n603: \n604:     l0AccessPerf.zip(hitVec).map{
      case (l, h) => l := h && stageCheck_valid_1cycle }\n605:     XSDebug(stageReq.fire,
      p\"[l0] ridx:0x${Hexadecimal(ridx)}\\n\")\n606:     for (i <- 0 until l2tlbParams.l0nWays)
      {\n607:       XSDebug(stageCheck_valid_1cycle, p\"[l0] ramDatas(${i.U}) ${ramDatas(i)}\
      \  l0v:${vVec(i)}  hit:${hitVec(i)}\\n\")\n608:     }\n609:     XSDebug(stageCheck_valid_1cycle,
      p\"[l0] l0Hit:${hit} l0HitData:${hitWayData} hitVec:${Binary(hitVec.asUInt)}
      hitWay:${hitWay} v:${vVec}\\n\")\n610: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 614-631
    context: "614:     hitWay.suggestName(s\"l0_hitWay\")\n615: \n616:     (hit, hitWayData,
      hitWayData.prefetch, eccError, UIntToOH(hitWay), l0bitmapreg(hitWay), jmp_bitmap_check)\n\
      617:   }\n618:   val l0HitPPN = l0HitData.ppns\n619:   val l0HitPbmt = l0HitData.pbmts\n\
      620:   val l0HitPerm = l0HitData.perms.getOrElse(0.U.asTypeOf(Vec(PtwL0SectorSize,
      new PtePermBundle)))\n621:   val l0HitValid = VecInit(l0HitData.onlypf.map(!_))\n\
      622:   val l0Ptes = WireInit(VecInit(Seq.fill(tlbcontiguous)(0.U(XLEN.W))))
      // L0 lavel Page Table Entry Vector\n623:   val l0cfs = WireInit(VecInit(Seq.fill(tlbcontiguous)(false.B)))
      // L0 lavel Bitmap Check Failed Vector\n624:   if (HasBitmapCheck) {\n625: \
      \    for (i <- 0 until tlbcontiguous) {\n626:       l0Ptes(i) := Cat(l0HitData.pbmts(i).asUInt,l0HitPPN(i),
      0.U(2.W),l0HitPerm(i).asUInt,l0HitValid(i).asUInt)\n627:       l0cfs(i) := !l0BitmapCheckResult(i)\n\
      628:     }\n629:   }\n630: \n631:   // super page"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 630-643
    context: "630: \n631:   // super page\n632:   val spreplace = ReplacementPolicy.fromString(l2tlbParams.spReplacer,
      l2tlbParams.spSize)\n633:   val (spHit, spHitData, spPre, spValid, spJmpBitmapCheck)
      = {\n634:     val hitVecT = sp.zipWithIndex.map { case (e, i) => e.hit(vpn_search,
      io.csr_dup(0).satp.asid, io.csr_dup(0).vsatp.asid, io.csr_dup(0).hgatp.vmid,
      allType = true, s2xlate = h_search) && spv(i) && (sph(i) === h_search) }\n635:\
      \     val hitVec = hitVecT.map(RegEnable(_, stageReq.fire))\n636:     val hitData
      = ParallelPriorityMux(hitVec zip sp)\n637:     val ishptw = RegEnable(stageReq.bits.isHptwReq,
      stageReq.fire)\n638:     val s2x_info = RegEnable(stageReq.bits.req_info.s2xlate,
      stageReq.fire)\n639:     val jmp_bitmap_check  = WireInit(false.B)\n640:   \
      \  val hit = WireInit(false.B)\n641:     if (HasBitmapCheck) {\n642:       hit
      := Mux(bitmapEnable && (s2x_info =/= allStage || ishptw), ParallelOR(hitVec)
      && spBitmapReg(OHToUInt(hitVec)) === 1.U, ParallelOR(hitVec))\n643:       when
      (bitmapEnable && (s2x_info =/= allStage || ishptw) && ParallelOR(hitVec) &&
      spBitmapReg(OHToUInt(hitVec)) === 0.U) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 649-659
    context: "649: \n650:     when (hit && stageDelay_valid_1cycle) { spreplace.access(OHToUInt(hitVec))
      }\n651: \n652:     spAccessPerf.zip(hitVec).map{ case (s, h) => s := h && stageDelay_valid_1cycle
      }\n653:     for (i <- 0 until l2tlbParams.spSize) {\n654:       XSDebug(stageReq.fire,
      p\"[sp] sp(${i.U}) ${sp(i)} hit:${sp(i).hit(vpn_search, io.csr_dup(0).satp.asid,
      io.csr_dup(0).vsatp.asid, io.csr_dup(0).hgatp.vmid, allType = true, s2xlate
      = h_search)} spv:${spv(i)}\\n\")\n655:     }\n656:     XSDebug(stageDelay_valid_1cycle,
      p\"[sp] spHit:${hit} spHitData:${hitData} hitVec:${Binary(VecInit(hitVec).asUInt)}\\\
      n\")\n657: \n658:     VecInit(hitVecT).suggestName(s\"sp_hitVecT\")\n659:  \
      \   VecInit(hitVec).suggestName(s\"sp_hitVec\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 656-703
    context: "656:     XSDebug(stageDelay_valid_1cycle, p\"[sp] spHit:${hit} spHitData:${hitData}
      hitVec:${Binary(VecInit(hitVec).asUInt)}\\n\")\n657: \n658:     VecInit(hitVecT).suggestName(s\"\
      sp_hitVecT\")\n659:     VecInit(hitVec).suggestName(s\"sp_hitVec\")\n660: \n\
      661:     (RegEnable(hit, stageDelay(1).fire),\n662:      RegEnable(hitData,
      stageDelay(1).fire),\n663:      RegEnable(hitData.prefetch, stageDelay(1).fire),\n\
      664:      RegEnable(hitData.v, stageDelay(1).fire),\n665:      RegEnable(jmp_bitmap_check,
      stageDelay(1).fire))\n666:   }\n667:   val spHitPerm = spHitData.perm.getOrElse(0.U.asTypeOf(new
      PtePermBundle))\n668:   val spHitLevel = spHitData.level.getOrElse(0.U)\n669:\
      \   val spPte = Cat(spHitData.pbmt.asUInt,spHitData.ppn, 0.U(2.W), spHitPerm.asUInt,spHitData.v.asUInt)
      // Super-page Page Table Entry\n670: \n671:   val check_res = Wire(new PageCacheRespBundle)\n\
      672:   check_res.l3.map(_.apply(l3Hit.get, l3Pre.get, l3HitPPN.get, l3HitPbmt.get))\n\
      673:   check_res.l2.apply(l2Hit, l2Pre, l2HitPPN, l2HitPbmt)\n674:   check_res.l1.apply(l1Hit,
      l1Pre, l1HitPPN, l1HitPbmt, ecc = l1eccError)\n675:   check_res.l0.apply(l0Hit,
      l0Pre, l0HitPPN, l0HitPbmt, l0HitPerm, l0eccError, valid = l0HitValid, jmp_bitmap_check
      = l0JmpBitmapCheck, hitway = l0HitWay, ptes = l0Ptes, cfs = l0cfs)\n676:   check_res.sp.apply(spHit,
      spPre, spHitData.ppn, spHitData.pbmt, spHitData.n.getOrElse(0.U), spHitPerm,
      false.B, spHitLevel, spValid, spJmpBitmapCheck, spPte)\n677: \n678:   val resp_res
      = Reg(new PageCacheRespBundle)\n679:   when (stageCheck(1).fire) { resp_res
      := check_res }\n680: \n681:   // stageResp bypass\n682:   val bypassed = if
      (EnableSv48) Wire(Vec(4, Bool())) else Wire(Vec(3, Bool()))\n683:   bypassed.indices.foreach(i
      =>\n684:     bypassed(i) := stageResp.bits.bypassed(i) ||\n685:       ValidHoldBypass(refill_bypass(stageResp.bits.req_info.vpn,
      i, stageResp.bits.req_info.s2xlate),\n686:         OneCycleValid(stageCheck(1).fire,
      false.B) || io.refill.valid)\n687:   )\n688: \n689:   // stageResp bypass to
      hptw\n690:   val hptw_bypassed = if (EnableSv48) Wire(Vec(4, Bool())) else Wire(Vec(3,
      Bool()))\n691:   hptw_bypassed.indices.foreach(i =>\n692:     hptw_bypassed(i)
      := stageResp.bits.bypassed(i) ||\n693:       ValidHoldBypass(refill_bypass(stageResp.bits.req_info.vpn,
      i, stageResp.bits.req_info.s2xlate),\n694:         io.resp.fire)\n695:   )\n\
      696: \n697:   val isAllStage = stageResp.bits.req_info.s2xlate === allStage\n\
      698:   val isOnlyStage2 = stageResp.bits.req_info.s2xlate === onlyStage2\n699:\
      \   val stage1Hit = (resp_res.l0.hit || resp_res.sp.hit) && isAllStage\n700:\
      \   val idx = stageResp.bits.req_info.vpn(2, 0)\n701:   val stage1Pf = !Mux(resp_res.l0.hit,
      resp_res.l0.v(idx), resp_res.sp.v)\n702:   io.resp.bits.req_info   := stageResp.bits.req_info\n\
      703:   io.resp.bits.isFirst  := stageResp.bits.isFirst"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 706-718
    context: "706:     io.resp.bits.bypassed := ((bypassed(0) && !resp_res.l0.hit)
      || (bypassed(1) && !resp_res.l1.hit) || (bypassed(2) && !resp_res.l2.hit) ||
      (bypassed(3) && !resp_res.l3.get.hit)) && !isAllStage\n707:   } else {\n708:\
      \     io.resp.bits.bypassed := ((bypassed(0) && !resp_res.l0.hit) || (bypassed(1)
      && !resp_res.l1.hit) || (bypassed(2) && !resp_res.l2.hit)) && !isAllStage\n\
      709:   }\n710:   io.resp.bits.prefetch := resp_res.l0.pre && resp_res.l0.hit
      || resp_res.sp.pre && resp_res.sp.hit\n711:   io.resp.bits.toFsm.l3Hit.map(_
      := resp_res.l3.get.hit && !stage1Hit && !isOnlyStage2 && !stageResp.bits.isHptwReq)\n\
      712:   io.resp.bits.toFsm.l2Hit := resp_res.l2.hit && !stage1Hit && !isOnlyStage2
      && !stageResp.bits.isHptwReq\n713:   io.resp.bits.toFsm.l1Hit := resp_res.l1.hit
      && !stage1Hit && !isOnlyStage2 && !stageResp.bits.isHptwReq\n714:   io.resp.bits.toFsm.ppn\
      \   := Mux(resp_res.l1.hit, resp_res.l1.ppn, Mux(resp_res.l2.hit, resp_res.l2.ppn,
      resp_res.l3.getOrElse(0.U.asTypeOf(new PageCachePerPespBundle)).ppn))\n715:\
      \   io.resp.bits.toFsm.stage1Hit := stage1Hit\n716:   if (HasBitmapCheck) {\n\
      717:     io.resp.bits.toFsm.bitmapCheck.get.jmp_bitmap_check := resp_res.l0.bitmapCheck.get.jmp_bitmap_check
      || resp_res.sp.bitmapCheck.get.jmp_bitmap_check\n718:     io.resp.bits.toFsm.bitmapCheck.get.toLLPTW
      := resp_res.l0.bitmapCheck.get.jmp_bitmap_check && (stageResp.bits.req_info.s2xlate
      === noS2xlate || stageResp.bits.req_info.s2xlate === onlyStage1)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 738-748
    context: "738:   io.resp.bits.toHptw.resp.entry.asid := DontCare\n739:   io.resp.bits.toHptw.resp.entry.vmid.map(_
      := io.csr_dup(0).hgatp.vmid)\n740:   io.resp.bits.toHptw.resp.entry.level.map(_
      := Mux(resp_res.l0.hit, 0.U, resp_res.sp.level))\n741:   io.resp.bits.toHptw.resp.entry.prefetch
      := from_pre(stageResp.bits.req_info.source)\n742:   io.resp.bits.toHptw.resp.entry.ppn
      := Mux(resp_res.l0.hit, resp_res.l0.ppn(idx), resp_res.sp.ppn)(ppnLen - 1, 0)\n\
      743:   io.resp.bits.toHptw.resp.entry.pbmt := Mux(resp_res.l0.hit, resp_res.l0.pbmt(idx),
      resp_res.sp.pbmt)\n744:   io.resp.bits.toHptw.resp.entry.n.map(_ := Mux(resp_res.sp.hit,
      resp_res.sp.n, 0.U))\n745:   io.resp.bits.toHptw.resp.entry.perm.map(_ := Mux(resp_res.l0.hit,
      resp_res.l0.perm(idx), resp_res.sp.perm))\n746:   io.resp.bits.toHptw.resp.entry.v
      := Mux(resp_res.l0.hit, resp_res.l0.v(idx), resp_res.sp.v)\n747:   io.resp.bits.toHptw.resp.gpf
      := !io.resp.bits.toHptw.resp.entry.v\n748:   io.resp.bits.toHptw.resp.gaf :=
      false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 799-812
    context: "799:       io.resp.bits.stage1.entry(i).v := Mux(resp_res.l0.hit, resp_res.l0.v(i),\n\
      800:         Mux(resp_res.sp.hit, resp_res.sp.v,\n801:           Mux(resp_res.l1.hit,
      resp_res.l1.v,\n802:             resp_res.l2.v)))\n803:     }\n804:     io.resp.bits.stage1.entry(i).pbmt
      := Mux(resp_res.l0.hit, resp_res.l0.pbmt(i),\n805:       Mux(resp_res.sp.hit,
      resp_res.sp.pbmt,\n806:         Mux(resp_res.l1.hit, resp_res.l1.pbmt,\n807:\
      \           resp_res.l2.pbmt)))\n808:     io.resp.bits.stage1.entry(i).n.map(_
      := Mux(resp_res.sp.hit, resp_res.sp.n, 0.U))\n809:     io.resp.bits.stage1.entry(i).perm.map(_
      := Mux(resp_res.l0.hit, resp_res.l0.perm(i),  Mux(resp_res.sp.hit, resp_res.sp.perm,
      0.U.asTypeOf(new PtePermBundle))))\n810:     io.resp.bits.stage1.entry(i).pf
      := !io.resp.bits.stage1.entry(i).v\n811:     io.resp.bits.stage1.entry(i).af
      := false.B\n812:     io.resp.bits.stage1.entry(i).cf := l0cfs(i) // L0 lavel
      Bitmap Check Failed Vector"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 841-854
    context: "841:   val memPte = memSelData.map(a => a.asTypeOf(new PteBundle))\n\
      842:   val mPBMTE = io.csr.mPBMTE\n843:   val hPBMTE = io.csr.hPBMTE\n844: \
      \  val pbmte = Mux(refill.req_info_dup(0).s2xlate === onlyStage1 || refill.req_info_dup(0).s2xlate
      === allStage, hPBMTE, mPBMTE)\n845: \n846:   def Tran2D(flushMask: UInt): Vec[UInt]
      = {\n847:     val tran2D = Wire(Vec(l2tlbParams.l0nSets,UInt(l2tlbParams.l0nWays.W)))\n\
      848:     for (i <- 0 until l2tlbParams.l0nSets) {\n849:       tran2D(i) := flushMask((i
      + 1) * l2tlbParams.l0nWays - 1, i * l2tlbParams.l0nWays)\n850:     }\n851: \
      \    tran2D\n852:   }\n853:   def updateL0BitmapReg(l0BitmapReg: Vec[Vec[Vec[UInt]]],
      tran2D: Vec[UInt]) = {\n854:     for (i <- 0 until l2tlbParams.l0nSets) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 859-872
    context: "859:           }\n860:         }\n861:       }\n862:     }\n863:   }\n\
      864:   def TranVec(flushMask: UInt): Vec[UInt] = {\n865:     val vec = Wire(Vec(l2tlbParams.spSize,UInt(1.W)))\n\
      866:     for (i <- 0 until l2tlbParams.spSize) {\n867:       vec(i) := flushMask(i)\n\
      868:     }\n869:     vec\n870:   }\n871:   def updateSpBitmapReg(spBitmapReg:
      Vec[UInt], vec : Vec[UInt]) = {\n872:     for (i <- 0 until l2tlbParams.spSize)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 875-885
    context: "875:   }\n876: \n877:   // TODO: handle sfenceLatch outsize\n878:  \
      \ if (EnableSv48) {\n879:     val l3Refill =\n880:       !flush_dup(2) &&\n\
      881:       refill.levelOH.l3.get &&\n882:       !memPte(2).isLeaf() &&\n883:\
      \       memPte(2).canRefill(refill.level_dup(2), refill.req_info_dup(2).s2xlate,
      pbmte, io.csr_dup(2).hgatp.mode)\n884:     val l3RefillIdx = replaceWrapper(l3v.get,
      ptwl3replace.get.way).suggestName(s\"l3_refillIdx\")\n885:     val l3RfOH =
      UIntToOH(l3RefillIdx).asUInt.suggestName(s\"l3_rfOH\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 907-917
    context: "907:     XSDebug(l3Refill, p\"[l3 refill] l3v:${Binary(l3v.get)}->${Binary(l3v.get
      | l3RfOH)} l3g:${Binary(l3g.get)}->${Binary((l3g.get & ~l3RfOH) | Mux(memPte(2).perm.g,
      l3RfOH, 0.U))}\\n\")\n908:   }\n909: \n910:   // L2 refill\n911:   val l2Refill
      =\n912:     !flush_dup(2) &&\n913:     refill.levelOH.l2 &&\n914:     !memPte(2).isLeaf()
      &&\n915:     memPte(2).canRefill(refill.level_dup(2), refill.req_info_dup(2).s2xlate,
      pbmte, io.csr_dup(2).hgatp.mode)\n916:   val l2RefillIdx = replaceWrapper(l2v,
      ptwl2replace.way).suggestName(s\"l2_refillIdx\")\n917:   val l2RfOH = UIntToOH(l2RefillIdx).asUInt.suggestName(s\"\
      l2_rfOH\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 938-948
    context: "938:   }\n939:   XSDebug(l2Refill, p\"[l2 refill] refillIdx:${l2RefillIdx}
      refillEntry:${l2(l2RefillIdx).genPtwEntry(refill.req_info_dup(2).vpn, Mux(refill.req_info_dup(2).s2xlate
      =/= noS2xlate, io.csr_dup(2).vsatp.asid, io.csr_dup(2).satp.asid), memSelData(2),
      0.U, prefetch = refill_prefetch_dup(2), s2xlate = refill.req_info_dup(2).s2xlate)}\\\
      n\")\n940:   XSDebug(l2Refill, p\"[l2 refill] l2v:${Binary(l2v)}->${Binary(l2v
      | l2RfOH)} l2g:${Binary(l2g)}->${Binary((l2g & ~l2RfOH) | Mux(memPte(2).perm.g,
      l2RfOH, 0.U))}\\n\")\n941: \n942:   // L1 refill\n943:   val l1Refill = !flush_dup(1)
      && refill.levelOH.l1\n944:   val l1RefillIdx = genPtwL1SetIdx(refill.req_info_dup(1).vpn).suggestName(s\"\
      l1_refillIdx\")\n945:   val l1VictimWay = replaceWrapper(getl1vSet(refill.req_info_dup(1).vpn),
      ptwl1replace.way(l1RefillIdx)).suggestName(s\"l1_victimWay\")\n946:   val l1VictimWayOH
      = UIntToOH(l1VictimWay).suggestName(s\"l1_victimWayOH\")\n947:   val l1RfvOH
      = UIntToOH(Cat(l1RefillIdx, l1VictimWay)).asUInt.suggestName(s\"l1_rfvOH\")\n\
      948:   val l1Wdata = Wire(l1EntryType)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 981-991
    context: "981:   XSDebug(l1Refill, p\"[l1 refill] refilldata:0x${l1Wdata}\\n\"\
      )\n982:   XSDebug(l1Refill, p\"[l1 refill] l1v:${Binary(l1v)} -> ${Binary(l1v
      | l1RfvOH)}\\n\")\n983:   XSDebug(l1Refill, p\"[l1 refill] l1g:${Binary(l1g)}
      -> ${Binary(l1g & ~l1RfvOH | Mux(Cat(memPtes.map(_.perm.g)).andR, l1RfvOH, 0.U))}\\\
      n\")\n984: \n985:   // L0 refill\n986:   val l0Refill = !flush_dup(0) && refill.levelOH.l0
      && !memPte(0).isNapot(refill.level_dup(0))\n987:   val l0RefillIdx = genPtwL0SetIdx(refill.req_info_dup(0).vpn).suggestName(s\"\
      l0_refillIdx\")\n988:   val l0VictimWay = replaceWrapper(getl0vSet(refill.req_info_dup(0).vpn),
      ptwl0replace.way(l0RefillIdx)).suggestName(s\"l0_victimWay\")\n989:   val l0VictimWayOH
      = UIntToOH(l0VictimWay).asUInt.suggestName(s\"l0_victimWayOH\")\n990:   val
      l0RfvOH = UIntToOH(Cat(l0RefillIdx, l0VictimWay)).suggestName(s\"l0_rfvOH\"\
      )\n991:   val l0Wdata = Wire(l0EntryType)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1032-1042
    context: "1032:   XSDebug(l0Refill, p\"[l0 refill] l0g:${Binary(l0g)} -> ${Binary(l0g
      & ~l0RfvOH | Mux(Cat(memPtes.map(_.perm.g)).andR, l0RfvOH, 0.U))}\\n\")\n1033:\
      \ \n1034: \n1035:   // misc entries: super & invalid\n1036:   val spRefill =\n\
      1037:     !flush_dup(0) &&\n1038:     (refill.levelOH.sp || (refill.levelOH.l0
      && memPte(0).isNapot(refill.level_dup(0)))) &&\n1039:     ((memPte(0).isLeaf()
      && memPte(0).canRefill(refill.level_dup(0), refill.req_info_dup(0).s2xlate,
      pbmte, io.csr_dup(0).hgatp.mode)) ||\n1040:     memPte(0).onlyPf(refill.level_dup(0),
      refill.req_info_dup(0).s2xlate, pbmte))\n1041:   val spRefillIdx = spreplace.way.suggestName(s\"\
      sp_refillIdx\") // LFSR64()(log2Up(l2tlbParams.spSize)-1,0) // TODO: may be
      LRU\n1042:   val spRfOH = UIntToOH(spRefillIdx).asUInt.suggestName(s\"sp_rfOH\"\
      )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1062-1096
    context: "1062:     }\n1063:   }\n1064:   XSDebug(spRefill, p\"[sp refill] refillIdx:${spRefillIdx}
      refillEntry:${sp(spRefillIdx).genPtwEntry(refill.req_info_dup(0).vpn, Mux(refill.req_info_dup(0).s2xlate
      =/= noS2xlate, io.csr_dup(0).vsatp.asid, io.csr_dup(0).satp.asid), memSelData(0),
      refill.level_dup(0), refill_prefetch_dup(0), s2xlate = refill.req_info_dup(0).s2xlate)}\\\
      n\")\n1065:   XSDebug(spRefill, p\"[sp refill] spv:${Binary(spv)}->${Binary(spv
      | spRfOH)} spg:${Binary(spg)}->${Binary(spg & ~spRfOH | Mux(memPte(0).perm.g,
      spRfOH, 0.U))}\\n\")\n1066: \n1067:   val l1eccFlush = resp_res.l1.ecc && stageResp_valid_1cycle_dup(0)
      // RegNext(l1eccError, init = false.B)\n1068:   val l0eccFlush = resp_res.l0.ecc
      && stageResp_valid_1cycle_dup(1) // RegNext(l0eccError, init = false.B)\n1069:\
      \   val eccVpn = stageResp.bits.req_info.vpn\n1070: \n1071:   XSError(l1eccFlush,
      \"l2tlb.cache.l1 ecc error. Should not happen at sim stage\")\n1072:   XSError(l0eccFlush,
      \"l2tlb.cache.l0 ecc error. Should not happen at sim stage\")\n1073:   when
      (l1eccFlush) {\n1074:     val flushSetIdxOH = UIntToOH(genPtwL1SetIdx(eccVpn))\n\
      1075:     val flushMask = VecInit(flushSetIdxOH.asBools.map { a => Fill(l2tlbParams.l1nWays,
      a.asUInt) }).asUInt\n1076:     l1v := l1v & ~flushMask\n1077:     l1g := l1g
      & ~flushMask\n1078:   }\n1079: \n1080:   when (l0eccFlush) {\n1081:     val
      flushSetIdxOH = UIntToOH(genPtwL0SetIdx(eccVpn))\n1082:     val flushMask =
      VecInit(flushSetIdxOH.asBools.map { a => Fill(l2tlbParams.l0nWays, a.asUInt)
      }).asUInt\n1083:     l0v := l0v & ~flushMask\n1084:     l0g := l0g & ~flushMask\n\
      1085:   }\n1086: \n1087:   // sfence logic\n1088:   val l0hashAsid = XORFold(sfence_dup(0).bits.id,
      l2tlbParams.hashAsidWidth)\n1089:   val l1hashAsid = XORFold(sfence_dup(1).bits.id,
      l2tlbParams.hashAsidWidth)\n1090:   val l0asidhit = VecInit(l0asids.flatMap(_.map(_
      === l0hashAsid))).asUInt\n1091:   val l1asidhit = VecInit(l1asids.flatMap(_.map(_
      === l1hashAsid))).asUInt\n1092:   val l2asidhit = VecInit(l2asids.map(_ ===
      sfence_dup(2).bits.id)).asUInt\n1093:   val spasidhit = VecInit(spasids.map(_
      === sfence_dup(0).bits.id)).asUInt\n1094: \n1095:   val sfence_valid = sfence_dup(0).valid
      && !sfence_dup(0).bits.hg && !sfence_dup(0).bits.hv\n1096:   when (sfence_valid)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1092-1105
    context: "1092:   val l2asidhit = VecInit(l2asids.map(_ === sfence_dup(2).bits.id)).asUInt\n\
      1093:   val spasidhit = VecInit(spasids.map(_ === sfence_dup(0).bits.id)).asUInt\n\
      1094: \n1095:   val sfence_valid = sfence_dup(0).valid && !sfence_dup(0).bits.hg
      && !sfence_dup(0).bits.hv\n1096:   when (sfence_valid) {\n1097:     val l0hashVmid
      = XORFold(io.csr_dup(0).hgatp.vmid, l2tlbParams.hashAsidWidth)\n1098:     val
      l1hashVmid = XORFold(io.csr_dup(1).hgatp.vmid, l2tlbParams.hashAsidWidth)\n\
      1099:     val l0vmidhit = VecInit(l0vmids.flatMap(_.map(_ === l0hashVmid))).asUInt\n\
      1100:     val l1vmidhit = VecInit(l1vmids.flatMap(_.map(_ === l1hashVmid))).asUInt\n\
      1101:     val l2vmidhit = VecInit(l2vmids.map(_.getOrElse(0.U) === io.csr_dup(2).hgatp.vmid)).asUInt\n\
      1102:     val spvmidhit = VecInit(spvmids.map(_.getOrElse(0.U) === io.csr_dup(0).hgatp.vmid)).asUInt\n\
      1103: \n1104:     val l0hhit = VecInit(l0h.flatMap(_.map{a => io.csr_dup(0).priv.virt
      && a === onlyStage1 || !io.csr_dup(0).priv.virt && a === noS2xlate})).asUInt\n\
      1105:     val l1hhit = VecInit(l1h.flatMap(_.map{a => io.csr_dup(1).priv.virt
      && a === onlyStage1 || !io.csr_dup(1).priv.virt && a === noS2xlate})).asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1112-1122
    context: "1112: \n1113:     val sfence_vpn = sfence_dup(0).bits.addr(sfence_dup(0).bits.addr.getWidth-1,
      offLen)\n1114:     val l0hashVpn = XORFold(sfence_vpn(vpnLen - 1, vpnLen - PtwL0TagLen),
      l2tlbParams.hashVpnWidth)\n1115:     val l0vpnhit = VecInit(l0vpns.flatMap(_.map(_
      === l0hashVpn))).asUInt\n1116:     val l0flushSetIdx = UIntToOH(genPtwL0SetIdx(sfence_vpn))\n\
      1117:     val l0flushMask = VecInit(l0flushSetIdx.asBools.map{a => Fill(l2tlbParams.l0nWays,
      a.asUInt)}).asUInt\n1118: \n1119:     when (sfence_dup(0).bits.rs1/*va*/) {\n\
      1120:       when (sfence_dup(0).bits.rs2) {\n1121:         // all va && all
      asid\n1122:         l0v := l0v & ~l0virthit"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1131-1145
    context: "1131:         spv := spv & ~(spvirthit & ~spg & spasidhit)\n1132:  \
      \     }\n1133:     } .otherwise {\n1134:       when (sfence_dup(0).bits.rs2)
      {\n1135:         // specific leaf of addr && all asid\n1136:         l0v :=
      l0v & ~(l0virthit & l0vpnhit & l0flushMask)\n1137:         spv := spv & ~(sphhit
      & VecInit(sp.map(_.hit(sfence_vpn, sfence_dup(0).bits.id, sfence_dup(0).bits.id,
      io.csr_dup(0).hgatp.vmid, allType = true, ignoreID = true.B, sfence = Mux(io.csr_dup(0).priv.virt,
      isVSfence, isSfence)))).asUInt)\n1138:       } .otherwise {\n1139:         //
      specific leaf of addr && specific asid\n1140:         l0v := l0v & ~(l0virthit
      & ~l0g & l0asidhit & l0vpnhit & l0flushMask)\n1141:         spv := spv & ~(~spg
      & sphhit & VecInit(sp.map(_.hit(sfence_vpn, sfence_dup(0).bits.id, sfence_dup(0).bits.id,
      io.csr_dup(0).hgatp.vmid, allType = true, sfence = Mux(io.csr_dup(0).priv.virt,
      isVSfence, isSfence)))).asUInt)\n1142:       }\n1143:     }\n1144:   }\n1145: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1143-1156
    context: "1143:     }\n1144:   }\n1145: \n1146:   val hfencev_valid = sfence_dup(0).valid
      && sfence_dup(0).bits.hv\n1147:   when (hfencev_valid) {\n1148:     val l0hashVmid
      = XORFold(io.csr_dup(0).hgatp.vmid, l2tlbParams.hashAsidWidth)\n1149:     val
      l1hashVmid = XORFold(io.csr_dup(1).hgatp.vmid, l2tlbParams.hashAsidWidth)\n\
      1150:     val l0vmidhit = VecInit(l0vmids.flatMap(_.map(_ === l0hashVmid))).asUInt\n\
      1151:     val l1vmidhit = VecInit(l1vmids.flatMap(_.map(_ === l1hashVmid))).asUInt\n\
      1152:     val l2vmidhit = VecInit(l2vmids.map(_.getOrElse(0.U) === io.csr_dup(2).hgatp.vmid)).asUInt\n\
      1153:     val spvmidhit = VecInit(spvmids.map(_.getOrElse(0.U) === io.csr_dup(0).hgatp.vmid)).asUInt\n\
      1154: \n1155:     val l0hhit = VecInit(l0h.flatMap(_.map(_ === onlyStage1))).asUInt\n\
      1156:     val l1hhit = VecInit(l1h.flatMap(_.map(_ === onlyStage1))).asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1159-1169
    context: "1159: \n1160:     val hfencev_vpn = sfence_dup(0).bits.addr(sfence_dup(0).bits.addr.getWidth-1,
      offLen)\n1161:     val l0hashVpn = XORFold(hfencev_vpn(vpnLen - 1, vpnLen -
      PtwL0TagLen), l2tlbParams.hashVpnWidth)\n1162:     val l0vpnhit = VecInit(l0vpns.flatMap(_.map(_
      === l0hashVpn))).asUInt\n1163:     val l0flushSetIdx = UIntToOH(genPtwL0SetIdx(hfencev_vpn))\n\
      1164:     val l0flushMask = VecInit(l0flushSetIdx.asBools.map{a => Fill(l2tlbParams.l0nWays,
      a.asUInt)}).asUInt\n1165: \n1166:     when(sfence_dup(0).bits.rs1) {\n1167:\
      \       when(sfence_dup(0).bits.rs2) {\n1168:         l0v := l0v & ~(l0hhit
      & l0vmidhit)\n1169:         l1v := l1v & ~(l1hhit & l1vmidhit)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1175-1188
    context: "1175:         l2v := l2v & ~(l2hhit & l2vmidhit & ~l2g & l2asidhit)\n\
      1176:         spv := spv & ~(sphhit & spvmidhit & ~spg & spasidhit)\n1177: \
      \      }\n1178:     }.otherwise {\n1179:       when(sfence_dup(0).bits.rs2)
      {\n1180:         l0v := l0v & ~(l0hhit & l0vmidhit & l0vpnhit & l0flushMask)\n\
      1181:         spv := spv & ~(sphhit & VecInit(sp.map(_.hit(hfencev_vpn, sfence_dup(0).bits.id,
      sfence_dup(0).bits.id, io.csr_dup(0).hgatp.vmid, allType = true, ignoreID =
      true.B, sfence = isVSfence))).asUInt)\n1182:       }.otherwise {\n1183:    \
      \     l0v := l0v & ~(l0hhit & l0vmidhit & ~l0g & l0asidhit & l0vpnhit & l0flushMask)\n\
      1184:         spv := spv & ~(~spg & sphhit & VecInit(sp.map(_.hit(hfencev_vpn,
      sfence_dup(0).bits.id, sfence_dup(0).bits.id, io.csr_dup(0).hgatp.vmid, allType
      = true, sfence = isVSfence))).asUInt)\n1185:       }\n1186:     }\n1187:   }\n\
      1188: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1187-1200
    context: "1187:   }\n1188: \n1189: \n1190:   val hfenceg_valid = sfence_dup(0).valid
      && sfence_dup(0).bits.hg\n1191:   when(hfenceg_valid) {\n1192:     val l0hashVmid
      = XORFold(sfence_dup(0).bits.id, l2tlbParams.hashAsidWidth)\n1193:     val l1hashVmid
      = XORFold(sfence_dup(1).bits.id, l2tlbParams.hashAsidWidth)\n1194:     val l0vmidhit
      = VecInit(l0vmids.flatMap(_.map(_ === l0hashVmid))).asUInt\n1195:     val l1vmidhit
      = VecInit(l1vmids.flatMap(_.map(_ === l1hashVmid))).asUInt\n1196:     val l2vmidhit
      = VecInit(l2vmids.map(_.getOrElse(0.U) === sfence_dup(2).bits.id)).asUInt\n\
      1197:     val spvmidhit = VecInit(spvmids.map(_.getOrElse(0.U) === sfence_dup(0).bits.id)).asUInt\n\
      1198: \n1199:     val l0hhit = VecInit(l0h.flatMap(_.map(_ === onlyStage2))).asUInt\n\
      1200:     val l1hhit = VecInit(l1h.flatMap(_.map(_ === onlyStage2))).asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1203-1213
    context: "1203: \n1204:     val hfenceg_gvpn = (sfence_dup(0).bits.addr << 2)(sfence_dup(0).bits.addr.getWidth
      - 1, offLen)\n1205:     val l0hashVpn = XORFold(hfenceg_gvpn(vpnLen - 1, vpnLen
      - PtwL0TagLen), l2tlbParams.hashVpnWidth)\n1206:     val l0vpnhit = VecInit(l0vpns.flatMap(_.map(_
      === l0hashVpn))).asUInt\n1207:     val l0flushSetIdx = UIntToOH(genPtwL0SetIdx(hfenceg_gvpn))\n\
      1208:     val l0flushMask = VecInit(l0flushSetIdx.asBools.map{a => Fill(l2tlbParams.l0nWays,
      a.asUInt)}).asUInt\n1209: \n1210:     when(sfence_dup(0).bits.rs1) {\n1211:\
      \       when(sfence_dup(0).bits.rs2) {\n1212:         l0v := l0v & ~l0hhit\n\
      1213:         l1v := l1v & ~l1hhit"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1219-1232
    context: "1219:         l2v := l2v & ~(l2hhit & l2vmidhit)\n1220:         spv
      := spv & ~(sphhit & spvmidhit)\n1221:       }\n1222:     }.otherwise {\n1223:\
      \       when(sfence_dup(0).bits.rs2) {\n1224:         l0v := l0v & ~(l0hhit
      & l0vpnhit & l0flushMask)\n1225:         spv := spv & ~(sphhit & VecInit(sp.map(_.hit(hfenceg_gvpn,
      0.U, 0.U, sfence_dup(0).bits.id, allType = true, ignoreID = true.B, sfence =
      isGSfence))).asUInt)\n1226:       }.otherwise {\n1227:         l0v := l0v &
      ~(l0hhit & l0vmidhit & l0vpnhit & l0flushMask)\n1228:         spv := spv & ~(sphhit
      & VecInit(sp.map(_.hit(hfenceg_gvpn, 0.U, 0.U, sfence_dup(0).bits.id, allType
      = true, sfence = isGSfence))).asUInt)\n1229:       }\n1230:     }\n1231:   }\n\
      1232: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1277-1287
    context: "1277:       }\n1278:     }\n1279:   }\n1280: \n1281:   def InsideStageConnect(in:
      DecoupledIO[PtwCacheReq], out: DecoupledIO[PtwCacheReq], inFire: Bool): Unit
      = {\n1282:     in.ready := !in.valid || out.ready\n1283:     out.valid := in.valid\n\
      1284:     out.bits := in.bits\n1285:     out.bits.bypassed.zip(in.bits.bypassed).zipWithIndex.map{
      case (b, i) =>\n1286:       val bypassed_reg = Reg(Bool())\n1287:       val
      bypassed_wire = refill_bypass(in.bits.req_info.vpn, i, in.bits.req_info.s2xlate)
      && io.refill.valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1298-1308
    context: "1298:   val resp_l3_pre = if (EnableSv48) Some(resp_res.l3.get.pre)
      else None\n1299:   val resp_l2_pre = resp_res.l2.pre\n1300:   val resp_l1_pre
      = resp_res.l1.pre\n1301:   val resp_l0_pre = resp_res.l0.pre\n1302:   val resp_sp_pre
      = resp_res.sp.pre\n1303:   val base_valid_access_0 = !from_pre(io.resp.bits.req_info.source)
      && io.resp.fire\n1304:   XSPerfAccumulate(\"access\", base_valid_access_0)\n\
      1305:   if (EnableSv48) {\n1306:     XSPerfAccumulate(\"l3_hit\", base_valid_access_0
      && io.resp.bits.toFsm.l3Hit.get && !io.resp.bits.toFsm.l2Hit && !io.resp.bits.toFsm.l1Hit
      && !io.resp.bits.hit)\n1307:   }\n1308:   XSPerfAccumulate(\"l2_hit\", base_valid_access_0
      && io.resp.bits.toFsm.l2Hit && !io.resp.bits.toFsm.l1Hit && !io.resp.bits.hit)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1318-1328
    context: "1318:   XSPerfAccumulate(\"l1_hit_pre\", base_valid_access_0 && resp_l1_pre
      && io.resp.bits.toFsm.l1Hit && !io.resp.bits.hit)\n1319:   XSPerfAccumulate(\"\
      l0_hit_pre\", base_valid_access_0 && resp_l0_pre && resp_l0)\n1320:   XSPerfAccumulate(\"\
      sp_hit_pre\", base_valid_access_0 && resp_sp_pre && resp_sp)\n1321:   XSPerfAccumulate(\"\
      pte_hit_pre\",base_valid_access_0 && (resp_l0_pre && resp_l0 || resp_sp_pre
      && resp_sp) && io.resp.bits.hit)\n1322: \n1323:   val base_valid_access_1 =
      from_pre(io.resp.bits.req_info.source) && io.resp.fire\n1324:   XSPerfAccumulate(\"\
      pre_access\", base_valid_access_1)\n1325:   if (EnableSv48) {\n1326:     XSPerfAccumulate(\"\
      pre_l3_hit\", base_valid_access_1 && io.resp.bits.toFsm.l3Hit.get && !io.resp.bits.toFsm.l2Hit
      && !io.resp.bits.toFsm.l1Hit && !io.resp.bits.hit)\n1327:   }\n1328:   XSPerfAccumulate(\"\
      pre_l2_hit\", base_valid_access_1 && io.resp.bits.toFsm.l2Hit && !io.resp.bits.toFsm.l1Hit
      && !io.resp.bits.hit)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1338-1348
    context: "1338:   XSPerfAccumulate(\"pre_l1_hit_pre\", base_valid_access_1 &&
      resp_l1_pre && io.resp.bits.toFsm.l1Hit && !io.resp.bits.hit)\n1339:   XSPerfAccumulate(\"\
      pre_l0_hit_pre\", base_valid_access_1 && resp_l0_pre && resp_l0)\n1340:   XSPerfAccumulate(\"\
      pre_sp_hit_pre\", base_valid_access_1 && resp_sp_pre && resp_sp)\n1341:   XSPerfAccumulate(\"\
      pre_pte_hit_pre\",base_valid_access_1 && (resp_l0_pre && resp_l0 || resp_sp_pre
      && resp_sp) && io.resp.bits.hit)\n1342: \n1343:   val base_valid_access_2 =
      stageResp.bits.isFirst && !from_pre(io.resp.bits.req_info.source) && io.resp.fire\n\
      1344:   XSPerfAccumulate(\"access_first\", base_valid_access_2)\n1345:   if
      (EnableSv48) {\n1346:     XSPerfAccumulate(\"l3_hit_first\", base_valid_access_2
      && io.resp.bits.toFsm.l3Hit.get && !io.resp.bits.toFsm.l2Hit && !io.resp.bits.toFsm.l1Hit
      && !io.resp.bits.hit)\n1347:   }\n1348:   XSPerfAccumulate(\"l2_hit_first\"\
      , base_valid_access_2 && io.resp.bits.toFsm.l2Hit && !io.resp.bits.toFsm.l1Hit
      && !io.resp.bits.hit)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1358-1368
    context: "1358:   XSPerfAccumulate(\"l1_hit_pre_first\", base_valid_access_2 &&
      resp_l1_pre && io.resp.bits.toFsm.l1Hit && !io.resp.bits.hit)\n1359:   XSPerfAccumulate(\"\
      l0_hit_pre_first\", base_valid_access_2 && resp_l0_pre && resp_l0)\n1360:  \
      \ XSPerfAccumulate(\"sp_hit_pre_first\", base_valid_access_2 && resp_sp_pre
      && resp_sp)\n1361:   XSPerfAccumulate(\"pte_hit_pre_first\",base_valid_access_2
      && (resp_l0_pre && resp_l0 || resp_sp_pre && resp_sp) && io.resp.bits.hit)\n\
      1362: \n1363:   val base_valid_access_3 = stageResp.bits.isFirst && from_pre(io.resp.bits.req_info.source)
      && io.resp.fire\n1364:   XSPerfAccumulate(\"pre_access_first\", base_valid_access_3)\n\
      1365:   if (EnableSv48) {\n1366:     XSPerfAccumulate(\"pre_l3_hit_first\",
      base_valid_access_3 && io.resp.bits.toFsm.l3Hit.get && !io.resp.bits.toFsm.l2Hit
      && !io.resp.bits.toFsm.l1Hit && !io.resp.bits.hit)\n1367:   }\n1368:   XSPerfAccumulate(\"\
      pre_l2_hit_first\", base_valid_access_3 && io.resp.bits.toFsm.l2Hit && !io.resp.bits.toFsm.l1Hit
      && !io.resp.bits.hit)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1378-1389
    context: "1378:   XSPerfAccumulate(\"pre_l1_hit_pre_first\", base_valid_access_3
      && resp_l1_pre && io.resp.bits.toFsm.l1Hit && !io.resp.bits.hit)\n1379:   XSPerfAccumulate(\"\
      pre_l0_hit_pre_first\", base_valid_access_3 && resp_l0_pre && resp_l0)\n1380:\
      \   XSPerfAccumulate(\"pre_sp_hit_pre_first\", base_valid_access_3 && resp_sp_pre
      && resp_sp)\n1381:   XSPerfAccumulate(\"pre_pte_hit_pre_first\",base_valid_access_3
      && (resp_l0_pre && resp_l0 || resp_sp_pre && resp_sp) && io.resp.bits.hit)\n\
      1382: \n1383:   XSPerfAccumulate(\"rwHarzad\", io.req.valid && !io.req.ready)\n\
      1384:   XSPerfAccumulate(\"out_blocked\", io.resp.valid && !io.resp.ready)\n\
      1385:   if (EnableSv48) {\n1386:     l3AccessPerf.get.zipWithIndex.map{ case
      (l, i) => XSPerfAccumulate(s\"l3AccessIndex${i}\", l) }\n1387:   }\n1388:  \
      \ l2AccessPerf.zipWithIndex.map{ case (l, i) => XSPerfAccumulate(s\"l2AccessIndex${i}\"\
      , l) }\n1389:   l1AccessPerf.zipWithIndex.map{ case (l, i) => XSPerfAccumulate(s\"\
      l1AccessIndex${i}\", l) }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1437-1446
    context: "1437:     (\"l2_hit           \", l2Hit                           ),\n\
      1438:     (\"l1_hit           \", l1Hit                           ),\n1439:\
      \     (\"l0_hit           \", l0Hit                           ),\n1440:    \
      \ (\"sp_hit           \", spHit                           ),\n1441:     (\"\
      pte_hit          \", l0Hit || spHit                  ),\n1442:     (\"rwHarzad\
      \         \", io.req.valid && !io.req.ready   ),\n1443:     (\"out_blocked \
      \     \", io.resp.valid && !io.resp.ready ),\n1444:   )\n1445:   generatePerfEvent()\n\
      1446: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TlbPrefetch.scala
    lines: 39-53
    context: "39: \n40:   def already_have(vpn: UInt): Bool = {\n41:     Cat(old_reqs.zip(old_v).map{
      case (o,v) => dup(o,vpn) && v}).orR\n42:   }\n43: \n44:   val flush = io.sfence.valid
      || io.csr.satp.changed || io.csr.vsatp.changed || io.csr.hgatp.changed || io.csr.priv.virt_changed\n\
      45:   val next_line = get_next_line(io.in.bits.vpn)\n46:   val next_req = RegEnable(next_line,
      io.in.valid)\n47:   val input_valid = io.in.valid && !flush && !already_have(next_line)\n\
      48:   val v = ValidHold(input_valid, io.out.fire, flush)\n49:   val s2xlate
      = Wire(UInt(2.W))\n50:   s2xlate := MuxCase(noS2xlate, Seq(\n51:     (io.csr.priv.virt
      && io.csr.vsatp.mode =/= 0.U && io.csr.hgatp.mode =/= 0.U) -> allStage,\n52:\
      \     (io.csr.priv.virt && io.csr.vsatp.mode =/= 0.U) -> onlyStage1,\n53:  \
      \   (io.csr.priv.virt && io.csr.hgatp.mode =/= 0.U) -> onlyStage2"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TlbPrefetch.scala
    lines: 58-68
    context: "58:   io.out.bits.req_info.source := prefetchID.U\n59:   io.out.bits.isHptwReq
      := false.B\n60:   io.out.bits.isLLptw := false.B\n61:   io.out.bits.hptwId :=
      DontCare\n62: \n63:   when (io.out.fire) {\n64:     old_v(old_index) := true.B\n\
      65:     old_reqs(old_index) := next_req\n66:     old_index := Mux((old_index
      === (OldRecordSize-1).U), 0.U, old_index + 1.U)\n67:   }\n68: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TlbPrefetch.scala
    lines: 64-74
    context: "64:     old_v(old_index) := true.B\n65:     old_reqs(old_index) := next_req\n\
      66:     old_index := Mux((old_index === (OldRecordSize-1).U), 0.U, old_index
      + 1.U)\n67:   }\n68: \n69:   when (flush) {\n70:     old_v.map(_ := false.B)\n\
      71:   }\n72: \n73:   XSPerfAccumulate(\"l2tlb_prefetch_input_count\", io.in.valid)\n\
      74:   XSPerfAccumulate(\"l2tlb_prefetch_valid_count\", input_valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TlbPrefetch.scala
    lines: 70-76
    context: "70:     old_v.map(_ := false.B)\n71:   }\n72: \n73:   XSPerfAccumulate(\"\
      l2tlb_prefetch_input_count\", io.in.valid)\n74:   XSPerfAccumulate(\"l2tlb_prefetch_valid_count\"\
      , input_valid)\n75:   XSPerfAccumulate(\"l2tlb_prefetch_output_count\", io.out.fire)\n\
      76: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 190-200
    context: "190:      future sv57 extension should change level width\n191:   */\n\
      192:   val level = Some(UInt(2.W))\n193:   val ppn = UInt(sectorppnLen.W)\n\
      194:   val n = UInt(pteNLen.W)\n195:   val pbmt = UInt(ptePbmtLen.W)\n196: \
      \  val g_pbmt = UInt(ptePbmtLen.W)\n197:   val perm = new TlbSectorPermBundle\n\
      198:   val valididx = Vec(tlbcontiguous, Bool())\n199:   val pteidx = Vec(tlbcontiguous,
      Bool())\n200:   val ppn_low = Vec(tlbcontiguous, UInt(sectortlbwidth.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 294-304
    context: "294:       allStage -> (item.s1.entry.level.getOrElse(0.U) min item.s2.entry.level.getOrElse(0.U)),\n\
      295:       noS2xlate -> item.s1.entry.level.getOrElse(0.U)\n296:     ))\n297:\
      \     this.level.map(_ := inner_level)\n298:     this.perm.apply(item.s1)\n\
      299:     this.pbmt := item.s1.entry.pbmt\n300: \n301:     val s1tag = item.s1.entry.tag\n\
      302:     val s2tag = item.s2.entry.tag(gvpnLen - 1, sectortlbwidth)\n303:  \
      \   this.tag := Mux(item.s2xlate === onlyStage2, s2tag, s1tag)\n304:     //
      if stage2 page is larger than stage1 page, need to merge s2tag and s2ppn to
      get a new s2ppn."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 337-347
    context: "337:     val isSuperPage = inner_level =/= 0.U || inner_n =/= 0.U\n\
      338:     this.valididx := Mux(isSuperPage, VecInit(Seq.fill(tlbcontiguous)(true.B)),\n\
      339:       Mux(item.s2xlate === onlyStage2, VecInit(UIntToOH(item.s2.entry.tag(sectortlbwidth
      - 1, 0)).asBools), item.s1.valididx))\n340:     this.pteidx := Mux(item.s2xlate
      === onlyStage2, VecInit(UIntToOH(item.s2.entry.tag(sectortlbwidth - 1, 0)).asBools),
      item.s1.pteidx)\n341:     this.vmid := Mux(item.s2xlate === onlyStage2, item.s2.entry.vmid.getOrElse(0.U),
      item.s1.entry.vmid.getOrElse(0.U))\n342:     this.g_pbmt := item.s2.entry.pbmt\n\
      343:     this.g_perm.applyS2(item.s2)\n344:     this.s2xlate := item.s2xlate\n\
      345:     this\n346:   }\n347: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 378-388
    context: "378:   }\n379: \n380: }\n381: \n382: object TlbCmd {\n383:   def read\
      \  = \"b00\".U\n384:   def write = \"b01\".U\n385:   def exec  = \"b10\".U\n\
      386: \n387:   def atom_read  = \"b100\".U // lr\n388:   def atom_write = \"\
      b101\".U // sc / amo"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 386-396
    context: "386: \n387:   def atom_read  = \"b100\".U // lr\n388:   def atom_write
      = \"b101\".U // sc / amo\n389: \n390:   def apply() = UInt(3.W)\n391:   def
      isRead(a: UInt) = a(1,0)===read\n392:   def isWrite(a: UInt) = a(1,0)===write\n\
      393:   def isExec(a: UInt) = a(1,0)===exec\n394: \n395:   def isAmo(a: UInt)
      = a===atom_write // NOTE: sc mixed\n396: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 394-404
    context: "394: \n395:   def isAmo(a: UInt) = a===atom_write // NOTE: sc mixed\n\
      396: }\n397: \n398: // Svpbmt extension\n399: object Pbmt {\n400:   def pma:\
      \  UInt = \"b00\".U  // None\n401:   def nc:   UInt = \"b01\".U  // Non-cacheable,
      idempotent, weakly-ordered (RVWMO), main memory\n402:   def io:   UInt = \"\
      b10\".U  // Non-cacheable, non-idempotent, strongly-ordered (I/O ordering),
      I/O\n403:   def rsvd: UInt = \"b11\".U  // Reserved for future standard use\n\
      404:   def width: Int = 2"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 417-427
    context: "417:       val s2xlate = Output(UInt(2.W))\n418:     })))\n419:    \
      \ val resp = Vec(ports, ValidIO(new Bundle{\n420:       val hit = Output(Bool())\n\
      421:       val ppn = Vec(nDups, Output(UInt(ppnLen.W)))\n422:       val pbmt
      = Vec(nDups, Output(UInt(ptePbmtLen.W)))\n423:       val g_pbmt = Vec(nDups,
      Output(UInt(ptePbmtLen.W)))\n424:       val perm = Vec(nDups, Output(new TlbSectorPermBundle()))\n\
      425:       val g_perm = Vec(nDups, Output(new TlbPermBundle()))\n426:      \
      \ val s2xlate = Vec(nDups, Output(UInt(2.W)))\n427:     }))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 438-448
    context: "438:     this.r.req(i).bits.s2xlate := s2xlate\n439: \n440:   }\n441:\
      \ \n442:   def r_resp_apply(i: Int) = {\n443:     (this.r.resp(i).bits.hit,
      this.r.resp(i).bits.ppn, this.r.resp(i).bits.perm, this.r.resp(i).bits.g_perm,
      this.r.resp(i).bits.pbmt, this.r.resp(i).bits.g_pbmt)\n444:   }\n445: \n446:\
      \   def w_apply(valid: Bool, wayIdx: UInt, data: PtwRespS2): Unit = {\n447:\
      \     this.w.valid := valid\n448:     this.w.bits.wayIdx := wayIdx"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 458-468
    context: "458:       val s2xlate = Output(UInt(2.W))\n459:     })))\n460:    \
      \ val resp = Vec(ports, ValidIO(new Bundle{\n461:       val hit = Output(Bool())\n\
      462:       val ppn = Vec(nDups, Output(UInt(ppnLen.W)))\n463:       val pbmt
      = Vec(nDups, Output(UInt(ptePbmtLen.W)))\n464:       val g_pbmt = Vec(nDups,
      Output(UInt(ptePbmtLen.W)))\n465:       val perm = Vec(nDups, Output(new TlbPermBundle()))\n\
      466:       val g_perm = Vec(nDups, Output(new TlbPermBundle()))\n467:      \
      \ val s2xlate = Vec(nDups, Output(UInt(2.W)))\n468:     }))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 477-487
    context: "477:     this.r.req(i).bits.vpn := vpn\n478:     this.r.req(i).bits.s2xlate
      := s2xlate\n479:   }\n480: \n481:   def r_resp_apply(i: Int) = {\n482:     (this.r.resp(i).bits.hit,
      this.r.resp(i).bits.ppn, this.r.resp(i).bits.perm, this.r.resp(i).bits.g_perm,
      this.r.resp(i).bits.s2xlate, this.r.resp(i).bits.pbmt, this.r.resp(i).bits.g_pbmt)\n\
      483:   }\n484: \n485:   def w_apply(valid: Bool, data: PtwRespS2): Unit = {\n\
      486:     this.w.valid := valid\n487:     this.w.bits.data := data"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 558-568
    context: "558: \n559: class TlbResp(nDups: Int = 1)(implicit p: Parameters) extends
      TlbBundle {\n560:   val paddr = Vec(nDups, Output(UInt(PAddrBits.W)))\n561:\
      \   val gpaddr = Vec(nDups, Output(UInt(XLEN.W)))\n562:   val fullva = Output(UInt(XLEN.W))
      // For pointer masking\n563:   val pbmt = Vec(nDups, Output(UInt(ptePbmtLen.W)))\n\
      564:   val miss = Output(Bool())\n565:   val fastMiss = Output(Bool())\n566:\
      \   val isForVSnonLeafPTE = Output(Bool())\n567:   val excp = Vec(nDups, new
      Bundle {\n568:     val vaNeedExt = Output(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 569-579
    context: "569:     val isHyper = Output(Bool())\n570:     val gpf = new TlbExceptionBundle()\n\
      571:     val pf = new TlbExceptionBundle()\n572:     val af = new TlbExceptionBundle()\n\
      573:   })\n574:   val ptwBack = Output(Bool()) // when ptw back, wake up replay
      rs's state\n575:   val memidx = Output(new MemBlockidxBundle)\n576: \n577: \
      \  val debug = new Bundle {\n578:     val robIdx = Output(new RobPtr)\n579:\
      \     val isFirstIssue = Output(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 593-603
    context: "593:   val req = Vec(Width, DecoupledIO(new PtwReq))\n594:   val resp
      = Flipped(DecoupledIO(new PtwRespS2))\n595: \n596: \n597:   override def toPrintable:
      Printable = {\n598:     p\"req(0):${req(0).valid} ${req(0).ready} ${req(0).bits}
      | resp:${resp.valid} ${resp.ready} ${resp.bits}\"\n599:   }\n600: }\n601: \n\
      602: class TlbPtwIOwithMemIdx(Width: Int = 1)(implicit p: Parameters) extends
      TlbBundle {\n603:   val req = Vec(Width, DecoupledIO(new PtwReqwithMemIdx))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 603-613
    context: "603:   val req = Vec(Width, DecoupledIO(new PtwReqwithMemIdx))\n604:\
      \   val resp = Flipped(DecoupledIO(new PtwRespS2withMemIdx()))\n605: \n606:\
      \ \n607:   override def toPrintable: Printable = {\n608:     p\"req(0):${req(0).valid}
      ${req(0).ready} ${req(0).bits} | resp:${resp.valid} ${resp.ready} ${resp.bits}\"\
      \n609:   }\n610: }\n611: \n612: class TlbHintReq(implicit p: Parameters) extends
      TlbBundle {\n613:   val id = Output(UInt(log2Up(loadfiltersize).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 655-666
    context: "655: \n656: class TlbIO(Width: Int, nRespDups: Int = 1, q: TLBParameters)(implicit
      p: Parameters) extends\n657:   MMUIOBaseBundle {\n658:   val hartId = Input(UInt(hartIdLen.W))\n\
      659:   val requestor = Vec(Width, Flipped(new TlbRequestIO(nRespDups)))\n660:\
      \   val flushPipe = Vec(Width, Input(Bool()))\n661:   val redirect = Flipped(ValidIO(new
      Redirect)) // flush the signal need_gpa in tlb\n662:   val ptw = new TlbPtwIOwithMemIdx(Width)\n\
      663:   val refill_to_mem = Output(new TlbRefilltoMemIO())\n664:   val replace
      = if (q.outReplace) Flipped(new TlbReplaceIO(Width, q)) else null\n665:   val
      pmp = Vec(Width, ValidIO(new PMPReqBundle(q.lgMaxSize)))\n666:   val tlbreplay
      = Vec(Width, Output(Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 674-684
    context: "674:     val getGpa = Output(Vec(Width, Bool()))\n675:   }))\n676: \n\
      677:   def connect(normal: TlbPtwIOwithMemIdx): Unit = {\n678:     req <> normal.req\n\
      679:     resp.ready := normal.resp.ready\n680:     normal.resp.bits := resp.bits.data\n\
      681:     normal.resp.valid := resp.valid\n682:   }\n683: }\n684: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 687-697
    context: "687: abstract class PtwModule(outer: L2TLB) extends LazyModuleImp(outer)\n\
      688:   with HasXSParameter with HasPtwConst\n689: \n690: class PteBundle(implicit
      p: Parameters) extends PtwBundle{\n691:   val n = UInt(pteNLen.W)\n692:   val
      pbmt = UInt(ptePbmtLen.W)\n693:   val reserved  = UInt(pteResLen.W)\n694:  \
      \ val ppn_high = UInt(ppnHignLen.W)\n695:   val ppn  = UInt(ppnLen.W)\n696:\
      \   val rsw  = UInt(pteRswLen.W)\n697:   val perm = new Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 723-736
    context: "723: \n724:   def isPf(level: UInt, pbmte: Bool) = {\n725:     val pf
      = WireInit(false.B)\n726:     when (reserved =/= 0.U){\n727:       pf := true.B\n\
      728:     }.elsewhen(pbmt === 3.U || (!pbmte && pbmt =/= 0.U)){\n729:       pf
      := true.B\n730:     }.elsewhen (isNext()) {\n731:       pf := (perm.u || perm.a
      || perm.d || n =/= 0.U || pbmt =/= 0.U)\n732:     }.elsewhen (!perm.v || (!perm.r
      && perm.w)) {\n733:       pf := true.B\n734:     // 1. only support 64KB napot
      page now (ppn(3, 0) === 4'b1000)\n735:     // 2. n should always be 0 when superpage
      (when level =/= 0.U)\n736:     }.elsewhen (n =/= 0.U && (ppn(3, 0) =/= 8.U ||
      level =/= 0.U)) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 745-758
    context: "745:   // The check of D bit is in L1TLB\n746:   def isGpf(level: UInt,
      pbmte: Bool) = {\n747:     val gpf = WireInit(false.B)\n748:     when (reserved
      =/= 0.U){\n749:       gpf := true.B\n750:     }.elsewhen(pbmt === 3.U || (!pbmte
      && pbmt =/= 0.U)){\n751:       gpf := true.B\n752:     }.elsewhen (isNext())
      {\n753:       gpf := (perm.u || perm.a || perm.d || n =/= 0.U || pbmt =/= 0.U)\n\
      754:     }.elsewhen (!perm.v || (!perm.r && perm.w)) {\n755:       gpf := true.B\n\
      756:     }.elsewhen (!perm.u) {\n757:       gpf := true.B\n758:     }.elsewhen
      (n =/= 0.U && ppn(3, 0) =/= 8.U) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 827-837
    context: "827: class PtwEntry(tagLen: Int, hasPerm: Boolean = false, hasLevel:
      Boolean = false, hasNapot: Boolean = false)(implicit p: Parameters) extends
      PtwBundle {\n828:   val tag = UInt(tagLen.W)\n829:   val asid = UInt(asidLen.W)\n\
      830:   val vmid = if (HasHExtension) Some(UInt(vmidLen.W)) else None\n831: \
      \  val n = if (hasNapot) Some(UInt(pteNLen.W)) else None\n832:   val pbmt =
      UInt(ptePbmtLen.W)\n833:   val ppn = UInt(gvpnLen.W)\n834:   val perm = if (hasPerm)
      Some(new PtePermBundle) else None\n835:   val level = if (hasLevel) Some(UInt(log2Up(Level
      + 1).W)) else None\n836:   val prefetch = Bool()\n837:   val v = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 902-912
    context: "902: \n903:   def refill(vpn: UInt, asid: UInt, vmid: UInt, pte: UInt,
      level: UInt = 0.U, prefetch: Bool, valid: Bool = false.B, s2xlate: UInt): Unit
      = {\n904:     require(this.asid.getWidth <= asid.getWidth) // maybe equal is
      better, but ugly outside\n905: \n906:     tag := vpn(vpnLen - 1, vpnLen - tagLen)\n\
      907:     pbmt := pte.asTypeOf(new PteBundle().cloneType).pbmt\n908:     ppn
      := pte.asTypeOf(new PteBundle().cloneType).getPPN()\n909:     perm.map(_ :=
      pte.asTypeOf(new PteBundle().cloneType).perm)\n910:     when (s2xlate === onlyStage2)
      {\n911:       // g bit in G-stage PTEs should be ignored by hardware\n912: \
      \      perm.map(_.g := false.B)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 927-937
    context: "927: \n928: \n929: \n930:   override def toPrintable: Printable = {\n\
      931:     // p\"tag:0x${Hexadecimal(tag)} ppn:0x${Hexadecimal(ppn)} perm:${perm}\"\
      \n932:     p\"tag:0x${Hexadecimal(tag)} pbmt: ${pbmt} ppn:0x${Hexadecimal(ppn)}
      \" +\n933:       (if (hasPerm) p\"perm:${perm.getOrElse(0.U.asTypeOf(new PtePermBundle))}
      \" else p\"\") +\n934:       (if (hasLevel) p\"level:${level.getOrElse(0.U)}\"\
      \ else p\"\") +\n935:       p\"prefetch:${prefetch}\"\n936:   }\n937: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 1002-1012
    context: "1002:     ps.asid := asid\n1003:     ps.vmid.map(_ := vmid)\n1004: \
      \    ps.prefetch := prefetch\n1005:     for (i <- 0 until num) {\n1006:    \
      \   val pte = data((i+1)*XLEN-1, i*XLEN).asTypeOf(new PteBundle)\n1007:    \
      \   ps.pbmts(i) := pte.pbmt\n1008:       ps.ppns(i) := pte.getPPN()\n1009: \
      \      ps.vs(i)   := (pte.canRefill(levelUInt, s2xlate, pbmte, mode) && (if
      (hasPerm) pte.isLeaf() else !pte.isLeaf())) || (if (hasPerm) pte.onlyPf(levelUInt,
      s2xlate, pbmte) else false.B)\n1010:       ps.onlypf(i) := pte.onlyPf(levelUInt,
      s2xlate, pbmte)\n1011:       ps.perms.map(_(i) := pte.perm)\n1012:       when
      (s2xlate === onlyStage2) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 1020-1030
    context: "1020: \n1021:   override def toPrintable: Printable = {\n1022:     //
      require(num == 4, \"if num is not 4, please comment this toPrintable\")\n1023:\
      \     // NOTE: if num is not 4, please comment this toPrintable\n1024:     val
      permsInner = perms.getOrElse(0.U.asTypeOf(Vec(num, new PtePermBundle)))\n1025:\
      \     p\"asid: ${Hexadecimal(asid)} tag:0x${Hexadecimal(tag)} pbmt:${printVec(pbmts)}
      ppns:${printVec(ppns)} vs:${Binary(vs.asUInt)} \" +\n1026:       (if (hasPerm)
      p\"perms:${printVec(permsInner)}\" else p\"\")\n1027:   }\n1028: }\n1029: \n\
      1030: class PTWEntriesWithEcc(eccCode: Code, num: Int, tagLen: Int, level: Int,
      hasPerm: Boolean, ReservedBits: Int = 0)(implicit p: Parameters) extends PtwBundle
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 1083-1093
    context: "1083:   val vpn = UInt(vpnLen.W) //vpn or gvpn\n1084:   val s2xlate
      = UInt(2.W)\n1085:   def hasS2xlate(): Bool = {\n1086:     this.s2xlate =/=
      noS2xlate\n1087:   }\n1088:   def isOnlyStage2: Bool = {\n1089:     this.s2xlate
      === onlyStage2\n1090:   }\n1091:   override def toPrintable: Printable = {\n\
      1092:     p\"vpn:0x${Hexadecimal(vpn)}\"\n1093:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 1106-1116
    context: "1106:   def apply(pf: Bool, af: Bool, level: UInt, pte: PteBundle, vpn:
      UInt, asid: UInt) = {\n1107:     this.entry.level.map(_ := level)\n1108:   \
      \  this.entry.tag := vpn\n1109:     this.entry.perm.map(_ := pte.getPerm())\n\
      1110:     this.entry.ppn := pte.ppn\n1111:     this.entry.pbmt := pte.pbmt\n\
      1112:     this.entry.prefetch := DontCare\n1113:     this.entry.asid := asid\n\
      1114:     this.entry.v := !pf\n1115:     this.pf := pf\n1116:     this.af :=
      af"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 1131-1141
    context: "1131:     this.entry.level.map(_ := level)\n1132:     this.entry.tag
      := vpn\n1133:     this.entry.perm.map(_ := resp_pte.getPerm())\n1134:     this.entry.ppn
      := resp_pte.ppn\n1135:     this.entry.n.map(_ := resp_pte.n === true.B && resp_pte.ppn(3,
      0) === 8.U && level === 0.U)\n1136:     this.entry.pbmt := resp_pte.pbmt\n1137:\
      \     this.entry.prefetch := DontCare\n1138:     this.entry.asid := DontCare\n\
      1139:     this.entry.vmid.map(_ := vmid)\n1140:     this.entry.v := !gpf\n1141:\
      \     this.gpf := gpf"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 1245-1255
    context: "1245:     val resp_pte = pte\n1246:     val ptw_resp = Wire(new PtwMergeEntry(tagLen
      = sectorvpnLen, hasPerm = true, hasLevel = true, hasNapot = true))\n1247:  \
      \   ptw_resp.ppn := resp_pte.getPPN()(ptePPNLen - 1, sectortlbwidth)\n1248:\
      \     ptw_resp.ppn_low := resp_pte.getPPN()(sectortlbwidth - 1, 0)\n1249:  \
      \   ptw_resp.n.map(_ := resp_pte.n === true.B && ptw_resp.ppn(3, 0) === 8.U
      && level === 0.U)\n1250:     ptw_resp.pbmt := resp_pte.pbmt\n1251:     ptw_resp.level.map(_
      := level)\n1252:     ptw_resp.perm.map(_ := resp_pte.getPerm())\n1253:     ptw_resp.tag
      := vpn(vpnLen - 1, sectortlbwidth)\n1254:     ptw_resp.pf := pf\n1255:     ptw_resp.af
      := af"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 1288-1298
    context: "1288: \n1289:   def hasS2xlate: Bool = {\n1290:     this.s2xlate =/=
      noS2xlate\n1291:   }\n1292: \n1293:   def isOnlyStage2: Bool = {\n1294:    \
      \ this.s2xlate === onlyStage2\n1295:   }\n1296: \n1297:   def getVpn(vpn: UInt):
      UInt = {\n1298:     val level = MuxLookup(s2xlate, 0.U)(Seq("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 1392-1406
    context: "1392:   val isLLptw = Bool()\n1393:   val hptwId = UInt(log2Up(l2tlbParams.llptwsize).W)\n\
      1394: }\n1395: \n1396: object ValidHoldBypass{\n1397:   def apply(infire: Bool,
      outfire: Bool, flush: Bool = false.B) = {\n1398:     val valid = RegInit(false.B)\n\
      1399:     when (infire) { valid := true.B }\n1400:     when (outfire) { valid
      := false.B } // ATTENTION: order different with ValidHold\n1401:     when (flush)
      { valid := false.B } // NOTE: the flush will flush in & out, is that ok?\n1402:\
      \     valid || infire\n1403:   }\n1404: }\n1405: \n1406: class L1TlbDB(implicit
      p: Parameters) extends TlbBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUConst.scala
    lines: 38-48
    context: "38:   NWays: Int = 2,\n39:   Replacer: Option[String] = Some(\"plru\"\
      ),\n40:   Associative: String = \"fa\", // must be fa\n41:   outReplace: Boolean
      = false,\n42:   partialStaticPMP: Boolean = false, // partial static pmp result
      stored in entries\n43:   outsideRecvFlush: Boolean = false, // if outside moudle
      waiting for tlb recv flush pipe\n44:   saveLevel: Boolean = false,\n45:   lgMaxSize:
      Int = 3\n46: )\n47: \n48: case class L2TLBParameters"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUConst.scala
    lines: 102-112
    context: "102:   /*\n103:     Sv39 page table entry\n104:     +--+------+--------+----------------------+-----+--------+\n\
      105:     |63|62  61|60    54|53                  10|9   8|7      0|\n106:  \
      \   +--+------+--------+----------------------+-----+--------+\n107:     |N
      | PBMT |Reserved|        PPNs          | RSW |  FALG  |\n108:     +--+------+--------+----------------------+-----+--------+\n\
      109:   */\n110:   val pteFlagLen = 8\n111:   val pteRswLen = 2\n112:   val ptePPNLen
      = 44"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUConst.scala
    lines: 271-284
    context: "271:   val MemReqWidth = if (HasBitmapCheck) 2 *(l2tlbParams.llptwsize
      + 1 + 1) else (l2tlbParams.llptwsize + 1 + 1)\n272:   val HptwReqId = l2tlbParams.llptwsize
      + 1\n273:   val FsmReqID = l2tlbParams.llptwsize\n274:   val bMemID = log2Up(MemReqWidth)\n\
      275: \n276:   def ptwTranVec(flushMask: UInt): Vec[Bool] = {\n277:     val vec
      = Wire(Vec(tlbcontiguous, Bool()))\n278:     for (i <- 0 until tlbcontiguous)
      {\n279:       vec(i) := flushMask(i)\n280:     }\n281:     vec\n282:   }\n283:\
      \ \n284:   def dupBitmapPPN(ppn1: UInt, ppn2: UInt) : Bool = {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 46-56
    context: "46:   lazy val module = new L2TLBImp(this)\n47: }\n48: \n49: class L2TLBImp(outer:
      L2TLB)(implicit p: Parameters) extends PtwModule(outer) with HasCSRConst with
      HasPerfEvents {\n50: \n51:   val (mem, edge) = outer.node.out.head\n52: \n53:\
      \   val io = IO(new L2TLBIO)\n54:   val difftestIO = IO(new Bundle() {\n55:\
      \     val ptwResp = Output(Bool())\n56:     val ptwAddr = Output(UInt(64.W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 86-96
    context: "86:   val vsatp  = csr_dup(0).vsatp\n87:   val hgatp  = csr_dup(0).hgatp\n\
      88:   val priv   = csr_dup(0).priv\n89:   val mPBMTE = csr_dup(0).mPBMTE\n90:\
      \   val hPBMTE = csr_dup(0).hPBMTE\n91:   val flush  = sfence_dup(0).valid ||
      satp.changed || vsatp.changed || hgatp.changed || priv.virt_changed\n92: \n\
      93:   val pmp = Module(new PMP())\n94:   val pmp_check = VecInit(Seq.fill(if
      (HasBitmapCheck) 5 else 4)(Module(new PMPChecker(lgMaxSize = 3, sameCycle =
      true)).io))\n95:   pmp.io.distribute_csr := io.csr.distribute_csr\n96:   if
      (HasBitmapCheck) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 92-104
    context: "92: \n93:   val pmp = Module(new PMP())\n94:   val pmp_check = VecInit(Seq.fill(if
      (HasBitmapCheck) 5 else 4)(Module(new PMPChecker(lgMaxSize = 3, sameCycle =
      true)).io))\n95:   pmp.io.distribute_csr := io.csr.distribute_csr\n96:   if
      (HasBitmapCheck) {\n97:     pmp_check.foreach(_.check_env.apply(csr_dup(0).mbmc.CMODE.asBool,
      ModeS, pmp.io.pmp, pmp.io.pma))\n98:   } else {\n99:     pmp_check.foreach(_.check_env.apply(ModeS,
      pmp.io.pmp, pmp.io.pma))\n100:   }\n101: \n102:   // add bitmapcheck\n103: \
      \  val bitmap = Option.when(HasBitmapCheck)(Module(new Bitmap))\n104:   val
      bitmapcache = Option.when(HasBitmapCheck)(Module(new BitmapCache))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 102-115
    context: "102:   // add bitmapcheck\n103:   val bitmap = Option.when(HasBitmapCheck)(Module(new
      Bitmap))\n104:   val bitmapcache = Option.when(HasBitmapCheck)(Module(new BitmapCache))\n\
      105: \n106:   if (HasBitmapCheck) {\n107:     bitmap.foreach { Bitmap =>\n108:\
      \       Bitmap.io.csr := csr_dup(8)\n109:       Bitmap.io.sfence := sfence_dup(9)\n\
      110:       bitmapcache.foreach { BitmapCache =>\n111:         // connect bitmap
      and bitmapcache\n112:         BitmapCache.io.req <> Bitmap.io.cache.req\n113:\
      \         Bitmap.io.cache.resp <> BitmapCache.io.resp\n114:         BitmapCache.io.refill
      <> Bitmap.io.refill\n115:         BitmapCache.io.csr := csr_dup(9)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 159-169
    context: "159:   val InHptwArbLLPTWPort = 1\n160:   hptw_req_arb.io.in(InHptwArbPTWPort).valid
      := ptw.io.hptw.req.valid\n161:   hptw_req_arb.io.in(InHptwArbPTWPort).bits.gvpn
      := ptw.io.hptw.req.bits.gvpn\n162:   hptw_req_arb.io.in(InHptwArbPTWPort).bits.id
      := ptw.io.hptw.req.bits.id\n163:   hptw_req_arb.io.in(InHptwArbPTWPort).bits.source
      := ptw.io.hptw.req.bits.source\n164:   ptw.io.hptw.req.ready := hptw_req_arb.io.in(InHptwArbPTWPort).ready\n\
      165: \n166:   hptw_req_arb.io.in(InHptwArbLLPTWPort).valid := llptw.io.hptw.req.valid\n\
      167:   hptw_req_arb.io.in(InHptwArbLLPTWPort).bits.gvpn := llptw.io.hptw.req.bits.gvpn\n\
      168:   hptw_req_arb.io.in(InHptwArbLLPTWPort).bits.id := llptw.io.hptw.req.bits.id\n\
      169:   hptw_req_arb.io.in(InHptwArbLLPTWPort).bits.source := llptw.io.hptw.req.bits.source"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 165-175
    context: "165: \n166:   hptw_req_arb.io.in(InHptwArbLLPTWPort).valid := llptw.io.hptw.req.valid\n\
      167:   hptw_req_arb.io.in(InHptwArbLLPTWPort).bits.gvpn := llptw.io.hptw.req.bits.gvpn\n\
      168:   hptw_req_arb.io.in(InHptwArbLLPTWPort).bits.id := llptw.io.hptw.req.bits.id\n\
      169:   hptw_req_arb.io.in(InHptwArbLLPTWPort).bits.source := llptw.io.hptw.req.bits.source\n\
      170:   llptw.io.hptw.req.ready := hptw_req_arb.io.in(InHptwArbLLPTWPort).ready\n\
      171: \n172:   // arb2 input port\n173:   val InArbHPTWPort = 0\n174:   val InArbPTWPort
      = 1\n175:   val InArbMissQueuePort = 2"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 181-199
    context: "181:   val tlbCounter = RegInit(0.U(log2Ceil(MissQueueSize + 1).W))\n\
      182:   val reqVec = WireInit(VecInit(Seq.fill(PtwWidth)(false.B)))\n183:   val
      respVec = WireInit(VecInit(Seq.fill(PtwWidth)(false.B)))\n184: \n185:   for
      (i <- 0 until PtwWidth) {\n186:     when (io.tlb(i).req(0).fire) {\n187:   \
      \    reqVec(i) := true.B\n188:     }\n189:     when (io.tlb(i).resp.fire) {\n\
      190:       respVec(i) := true.B\n191:     }\n192:   }\n193: \n194:   when (flush)
      {\n195:     tlbCounter := 0.U\n196:   } .otherwise {\n197:     tlbCounter :=
      tlbCounter + PopCount(reqVec) - PopCount(respVec)\n198:   }\n199:   XSError(!(tlbCounter
      >= 0.U && tlbCounter <= MissQueueSize.U), s\"l2tlb full!\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 201-214
    context: "201:   arb2.io.in(InArbPTWPort).valid := ptw.io.llptw.valid\n202:  \
      \ arb2.io.in(InArbPTWPort).bits.req_info := ptw.io.llptw.bits.req_info\n203:\
      \   arb2.io.in(InArbPTWPort).bits.isHptwReq := false.B\n204:   arb2.io.in(InArbPTWPort).bits.isLLptw
      := false.B\n205:   arb2.io.in(InArbPTWPort).bits.hptwId := DontCare\n206:  \
      \ ptw.io.llptw.ready := arb2.io.in(InArbPTWPort).ready\n207:   block_decoupled(missQueue.io.out,
      arb2.io.in(InArbMissQueuePort), Mux(missQueue.io.out.bits.isLLptw, !llptw.io.in.ready,
      !ptw.io.req.ready))\n208: \n209:   arb2.io.in(InArbTlbPort).valid := arb1.io.out.fire\n\
      210:   arb2.io.in(InArbTlbPort).bits.req_info.vpn := arb1.io.out.bits.vpn\n\
      211:   arb2.io.in(InArbTlbPort).bits.req_info.s2xlate := arb1.io.out.bits.s2xlate\n\
      212:   arb2.io.in(InArbTlbPort).bits.req_info.source := arb1.io.chosen\n213:\
      \   arb2.io.in(InArbTlbPort).bits.isHptwReq := false.B\n214:   arb2.io.in(InArbTlbPort).bits.isLLptw
      := false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 214-224
    context: "214:   arb2.io.in(InArbTlbPort).bits.isLLptw := false.B\n215:   arb2.io.in(InArbTlbPort).bits.hptwId
      := DontCare\n216:   // 1. arb1 and arb2 are both comb logic, so ready can work
      just the same cycle\n217:   // 2. arb1 can send one req at most in a cycle,
      so do not need to write\n218:   //    \"tlbCounter <= (MissQueueSize - 2).U\"\
      \n219:   arb1.io.out.ready := arb2.io.in(InArbTlbPort).ready && tlbCounter <
      MissQueueSize.U\n220: \n221:   arb2.io.in(InArbHPTWPort).valid := hptw_req_arb.io.out.valid\n\
      222:   arb2.io.in(InArbHPTWPort).bits.req_info.vpn := hptw_req_arb.io.out.bits.gvpn\n\
      223:   arb2.io.in(InArbHPTWPort).bits.req_info.s2xlate := onlyStage2\n224: \
      \  arb2.io.in(InArbHPTWPort).bits.req_info.source := hptw_req_arb.io.out.bits.source"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 223-233
    context: "223:   arb2.io.in(InArbHPTWPort).bits.req_info.s2xlate := onlyStage2\n\
      224:   arb2.io.in(InArbHPTWPort).bits.req_info.source := hptw_req_arb.io.out.bits.source\n\
      225:   arb2.io.in(InArbHPTWPort).bits.isHptwReq := true.B\n226:   arb2.io.in(InArbHPTWPort).bits.isLLptw
      := false.B\n227:   arb2.io.in(InArbHPTWPort).bits.hptwId := hptw_req_arb.io.out.bits.id\n\
      228:   hptw_req_arb.io.out.ready := arb2.io.in(InArbHPTWPort).ready\n229:  \
      \ val hartId = p(XSCoreParamsKey).HartId\n230:   if (l2tlbParams.enablePrefetch)
      {\n231:     val prefetch = Module(new L2TlbPrefetch())\n232:     val recv =
      cache.io.resp\n233:     // NOTE: 1. prefetch doesn't gen prefetch 2. req from
      mq doesn't gen prefetch"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 230-240
    context: "230:   if (l2tlbParams.enablePrefetch) {\n231:     val prefetch = Module(new
      L2TlbPrefetch())\n232:     val recv = cache.io.resp\n233:     // NOTE: 1. prefetch
      doesn't gen prefetch 2. req from mq doesn't gen prefetch\n234:     // NOTE:
      1. miss req gen prefetch 2. hit but prefetched gen prefetch\n235:     prefetch.io.in.valid
      := recv.fire && !from_pre(recv.bits.req_info.source) && (!recv.bits.hit  ||\n\
      236:       recv.bits.prefetch) && recv.bits.isFirst\n237:     prefetch.io.in.bits.vpn
      := recv.bits.req_info.vpn\n238:     prefetch.io.sfence := sfence_dup(0)\n239:\
      \     prefetch.io.csr := csr_dup(0)\n240:     arb2.io.in(InArbPrefetchPort)
      <> prefetch.io.out"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 241-253
    context: "241: \n242:     val isWriteL2TlbPrefetchTable = Constantin.createRecord(s\"\
      isWriteL2TlbPrefetchTable$hartId\")\n243:     val L2TlbPrefetchTable = ChiselDB.createTable(s\"\
      L2TlbPrefetch_hart$hartId\", new L2TlbPrefetchDB)\n244:     val L2TlbPrefetchDB
      = Wire(new L2TlbPrefetchDB)\n245:     L2TlbPrefetchDB.vpn := prefetch.io.out.bits.req_info.vpn\n\
      246:     L2TlbPrefetchTable.log(L2TlbPrefetchDB, isWriteL2TlbPrefetchTable.orR
      && prefetch.io.out.fire, \"L2TlbPrefetch\", clock, reset)\n247:   }\n248:  \
      \ arb2.io.out.ready := cache.io.req.ready\n249: \n250:   // Instructs requests
      from cache need go to LLPTW for processing\n251:   val toFsm_toLLPTW = if (HasBitmapCheck)
      cache.io.resp.bits.toFsm.bitmapCheck.get.toLLPTW else false.B\n252: \n253: \
      \  val mq_arb = Module(new Arbiter(new L2TlbWithHptwIdBundle, 2))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 252-263
    context: "252: \n253:   val mq_arb = Module(new Arbiter(new L2TlbWithHptwIdBundle,
      2))\n254:   mq_arb.io.in(0).valid := cache.io.resp.valid && !cache.io.resp.bits.hit
      &&\n255:     !from_pre(cache.io.resp.bits.req_info.source) && !cache.io.resp.bits.isHptwReq
      && // hptw reqs are not sent to missqueue\n256:     (cache.io.resp.bits.bypassed
      || (\n257:       (((!cache.io.resp.bits.toFsm.l1Hit && !toFsm_toLLPTW) || cache.io.resp.bits.toFsm.stage1Hit)
      && !cache.io.resp.bits.isHptwReq && (cache.io.resp.bits.isFirst || !ptw.io.req.ready))
      // send to ptw, is first or ptw is busy;\n258:       || ((cache.io.resp.bits.toFsm.l1Hit
      || toFsm_toLLPTW) && !llptw.io.in.ready) // send to llptw, llptw is full\n259:\
      \     ))\n260: \n261:   mq_arb.io.in(0).bits.req_info :=  cache.io.resp.bits.req_info\n\
      262:   mq_arb.io.in(0).bits.isHptwReq := false.B\n263:   mq_arb.io.in(0).bits.hptwId
      :=  DontCare"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 265-281
    context: "265:   mq_arb.io.in(1).bits.req_info := llptw.io.cache.bits\n266:  \
      \ mq_arb.io.in(1).bits.isHptwReq := false.B\n267:   mq_arb.io.in(1).bits.hptwId
      := DontCare\n268:   mq_arb.io.in(1).bits.isLLptw := false.B\n269:   mq_arb.io.in(1).valid
      := llptw.io.cache.valid\n270:   llptw.io.cache.ready := mq_arb.io.in(1).ready\n\
      271:   missQueue.io.in <> mq_arb.io.out\n272:   missQueue.io.sfence  := sfence_dup(6)\n\
      273:   missQueue.io.csr := csr_dup(5)\n274: \n275:   blockmq.io.start := missQueue.io.out.fire\n\
      276:   blockmq.io.enable := ptw.io.req.fire\n277: \n278:   llptw.io.in.valid
      := cache.io.resp.valid &&\n279:     !cache.io.resp.bits.hit &&\n280:     (toFsm_toLLPTW
      || cache.io.resp.bits.toFsm.l1Hit) &&\n281:     !cache.io.resp.bits.bypassed
      &&"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 289-303
    context: "289:     llptw.io.in.bits.bitmapCheck.get.hitway := cache.io.resp.bits.toFsm.bitmapCheck.get.hitway\n\
      290:   }\n291:   llptw.io.sfence := sfence_dup(1)\n292:   llptw.io.csr := csr_dup(1)\n\
      293:   val llptw_stage1 = Reg(Vec(l2tlbParams.llptwsize, new PtwMergeResp()))\n\
      294:   when(llptw.io.in.fire){\n295:     llptw_stage1(llptw.io.mem.enq_ptr)
      := cache.io.resp.bits.stage1\n296:   }\n297: \n298:   cache.io.req.valid :=
      arb2.io.out.fire\n299:   cache.io.req.bits.req_info := arb2.io.out.bits.req_info\n\
      300:   cache.io.req.bits.isFirst := (arb2.io.chosen =/= InArbMissQueuePort.U
      && !arb2.io.out.bits.isHptwReq)\n301:   cache.io.req.bits.isHptwReq := arb2.io.out.bits.isHptwReq\n\
      302:   cache.io.req.bits.hptwId := arb2.io.out.bits.hptwId\n303:   cache.io.req.bits.bypassed.map(_
      := false.B)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 303-318
    context: "303:   cache.io.req.bits.bypassed.map(_ := false.B)\n304:   cache.io.sfence
      := sfence_dup(2)\n305:   cache.io.csr := csr_dup(2)\n306:   cache.io.sfence_dup.zip(sfence_dup.drop(2).take(4)).map(s
      => s._1 := s._2)\n307:   cache.io.csr_dup.zip(csr_dup.drop(2).take(3)).map(c
      => c._1 := c._2)\n308:   cache.io.resp.ready := MuxCase(mq_arb.io.in(0).ready
      || ptw.io.req.ready, Seq(\n309:     (!cache.io.resp.bits.hit && cache.io.resp.bits.isHptwReq)
      -> hptw.io.req.ready,\n310:     (cache.io.resp.bits.hit && cache.io.resp.bits.isHptwReq)
      -> hptw_resp_arb.io.in(HptwRespArbCachePort).ready,\n311:     cache.io.resp.bits.hit
      -> outReady(cache.io.resp.bits.req_info.source, outArbCachePort),\n312:    \
      \ ((toFsm_toLLPTW || cache.io.resp.bits.toFsm.l1Hit) && !cache.io.resp.bits.bypassed
      && llptw.io.in.ready) -> llptw.io.in.ready,\n313:     (cache.io.resp.bits.bypassed
      || cache.io.resp.bits.isFirst) -> mq_arb.io.in(0).ready\n314:   ))\n315: \n\
      316:   // NOTE: missQueue req has higher priority\n317:   ptw.io.req.valid :=
      cache.io.resp.valid && !cache.io.resp.bits.hit && !cache.io.resp.bits.toFsm.l1Hit
      &&\n318:     !cache.io.resp.bits.bypassed &&"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 333-343
    context: "333:     ptw.io.req.bits.bitmapCheck.get.cfs := cache.io.resp.bits.toFsm.bitmapCheck.get.cfs\n\
      334:     ptw.io.req.bits.bitmapCheck.get.SPlevel := cache.io.resp.bits.toFsm.bitmapCheck.get.SPlevel\n\
      335:   }\n336:   ptw.io.sfence := sfence_dup(7)\n337:   ptw.io.csr := csr_dup(6)\n\
      338:   ptw.io.resp.ready := outReady(ptw.io.resp.bits.source, outArbFsmPort)\n\
      339: \n340:   hptw.io.req.valid := cache.io.resp.valid && !cache.io.resp.bits.hit
      && cache.io.resp.bits.isHptwReq\n341:   hptw.io.req.bits.gvpn := cache.io.resp.bits.req_info.vpn\n\
      342:   hptw.io.req.bits.id := cache.io.resp.bits.toHptw.id\n343:   hptw.io.req.bits.source
      := cache.io.resp.bits.req_info.source"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 374-387
    context: "374:   }\n375:   def from_bitmap(id: UInt) = {\n376:     (id > l2tlbParams.llptwsize.U
      + 1.U) && (id < MemReqWidth.U)\n377:   }\n378:   val waiting_resp = RegInit(VecInit(Seq.fill(MemReqWidth)(false.B)))\n\
      379:   val flush_latch = RegInit(VecInit(Seq.fill(MemReqWidth)(false.B)))\n\
      380:   val hptw_bypassed = RegInit(false.B)\n381:   for (i <- waiting_resp.indices)
      {\n382:     assert(!flush_latch(i) || waiting_resp(i)) // when sfence_latch
      wait for mem resp, waiting_resp should be true\n383:   }\n384: \n385:   val
      wfiReq = DelayN(io.wfi.wfiReq, 1)\n386: \n387:   // When no left pending response
      from L2, can be safe to enter wfi"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 387-397
    context: "387:   // When no left pending response from L2, can be safe to enter
      wfi\n388:   io.wfi.wfiSafe := DelayN(wfiReq && !waiting_resp.reduce(_ || _),
      1)\n389: \n390:   val llptw_out = llptw.io.out\n391:   val llptw_mem = llptw.io.mem\n\
      392:   llptw_mem.flush_latch := flush_latch.take(l2tlbParams.llptwsize)\n393:\
      \   llptw_mem.req_mask := waiting_resp.take(l2tlbParams.llptwsize)\n394:   ptw.io.mem.mask
      := waiting_resp.apply(l2tlbParams.llptwsize)\n395:   hptw.io.mem.mask := waiting_resp.apply(l2tlbParams.llptwsize
      + 1)\n396:   if (HasBitmapCheck) {\n397:     bitmap.get.io.mem.req_mask := waiting_resp.slice(MemReqWidth
      - (l2tlbParams.llptwsize + 2), MemReqWidth)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 401-411
    context: "401:   mem_arb.io.in(1) <> llptw_mem.req\n402:   mem_arb.io.in(2) <>
      hptw.io.mem.req\n403:   if (HasBitmapCheck) {\n404:     mem_arb.io.in(3) <>
      bitmap.get.io.mem.req\n405:   }\n406:   mem_arb.io.out.ready := mem.a.ready
      && !flush && !wfiReq\n407: \n408:   // // assert, should not send mem access
      at same addr for twice.\n409:   // val last_resp_vpn = RegEnable(cache.io.refill.bits.req_info_dup(0).vpn,
      cache.io.refill.valid)\n410:   // val last_resp_s2xlate = RegEnable(cache.io.refill.bits.req_info_dup(0).s2xlate,
      cache.io.refill.valid)\n411:   // val last_resp_level = RegEnable(cache.io.refill.bits.level_dup(0),
      cache.io.refill.valid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 422-436
    context: "422:   // // but the current part is invalid, so one more mem access
      happened\n423:   // // If this happened, remove the assert.\n424: \n425:   val
      req_addr_low = Reg(Vec(MemReqWidth, UInt((log2Up(l2tlbParams.blockBytes)-log2Up(XLEN/8)).W)))\n\
      426: \n427:   when (llptw.io.in.fire) {\n428:     // when enq miss queue, set
      the req_addr_low to receive the mem resp data part\n429:     req_addr_low(llptw_mem.enq_ptr)
      := addr_low_from_vpn(llptw.io.in.bits.req_info.vpn)\n430:   }\n431:   when (mem_arb.io.out.fire)
      {\n432:     req_addr_low(mem_arb.io.out.bits.id) := addr_low_from_paddr(mem_arb.io.out.bits.addr)\n\
      433:     waiting_resp(mem_arb.io.out.bits.id) := true.B\n434:     hptw_bypassed
      := from_hptw(mem_arb.io.out.bits.id) && mem_arb.io.out.bits.hptw_bypassed\n\
      435:   }\n436:   // mem read"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 432-442
    context: "432:     req_addr_low(mem_arb.io.out.bits.id) := addr_low_from_paddr(mem_arb.io.out.bits.addr)\n\
      433:     waiting_resp(mem_arb.io.out.bits.id) := true.B\n434:     hptw_bypassed
      := from_hptw(mem_arb.io.out.bits.id) && mem_arb.io.out.bits.hptw_bypassed\n\
      435:   }\n436:   // mem read\n437:   val memRead =  edge.Get(\n438:     fromSource
      = mem_arb.io.out.bits.id,\n439:     // toAddress  = memAddr(log2Up(CacheLineSize
      / 2 / 8) - 1, 0),\n440:     toAddress  = blockBytes_align(mem_arb.io.out.bits.addr),\n\
      441:     lgSize     = log2Up(l2tlbParams.blockBytes).U\n442:   )._2"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 438-454
    context: "438:     fromSource = mem_arb.io.out.bits.id,\n439:     // toAddress\
      \  = memAddr(log2Up(CacheLineSize / 2 / 8) - 1, 0),\n440:     toAddress  = blockBytes_align(mem_arb.io.out.bits.addr),\n\
      441:     lgSize     = log2Up(l2tlbParams.blockBytes).U\n442:   )._2\n443:  \
      \ mem.a.bits := memRead\n444:   mem.a.valid := mem_arb.io.out.valid && !flush
      && !wfiReq\n445:   mem.a.bits.user.lift(ReqSourceKey).foreach(_ := MemReqSource.PTW.id.U)\n\
      446:   mem.d.ready := true.B\n447:   // mem -> data buffer\n448:   val refill_data
      = RegInit(VecInit.fill(blockBits / l1BusDataWidth)(0.U(l1BusDataWidth.W)))\n\
      449:   val refill_helper = edge.firstlastHelper(mem.d.bits, mem.d.fire)\n450:\
      \   val mem_resp_done = refill_helper._3\n451:   val mem_resp_from_llptw = from_llptw(mem.d.bits.source)\n\
      452:   val mem_resp_from_ptw = from_ptw(mem.d.bits.source)\n453:   val mem_resp_from_hptw
      = from_hptw(mem.d.bits.source)\n454:   val mem_resp_from_bitmap = from_bitmap(mem.d.bits.source)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 478-493
    context: "478:     // llptw could not use refill_data_tmp, because enq bypass's
      result works at next cycle\n479:   ))\n480: \n481:   if (HasBitmapCheck) {\n\
      482:     // add bitmap arb\n483:     bitmap.foreach { Bitmap =>\n484:      \
      \ val bitmap_arb = Module(new Arbiter(new bitmapReqBundle(), 3))\n485:     \
      \  bitmap_arb.io.in(0) <> ptw.io.bitmap.get.req\n486:       bitmap_arb.io.in(1)
      <> llptw.io.bitmap.get.req\n487:       bitmap_arb.io.in(2) <> hptw.io.bitmap.get.req\n\
      488:       bitmap_arb.io.out.ready := Bitmap.io.req.ready\n489: \n490:     \
      \  Bitmap.io.req <> bitmap_arb.io.out\n491: \n492:       // connect bitmap resp
      to PTW\n493:       val bitmapresp_to_llptw = from_llptw(Bitmap.io.resp.bits.id)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 492-502
    context: "492:       // connect bitmap resp to PTW\n493:       val bitmapresp_to_llptw
      = from_llptw(Bitmap.io.resp.bits.id)\n494:       val bitmapresp_to_hptw = from_hptw(Bitmap.io.resp.bits.id)\n\
      495:       val bitmapresp_to_ptw = from_ptw(Bitmap.io.resp.bits.id)\n496: \n\
      497:       Bitmap.io.resp.ready := (llptw.io.bitmap.get.resp.ready && bitmapresp_to_llptw)
      || (hptw.io.bitmap.get.resp.ready && bitmapresp_to_hptw) || (ptw.io.bitmap.get.resp.ready
      && bitmapresp_to_ptw)\n498: \n499:       // bitmap -> llptw ptw hptw\n500: \
      \      llptw.io.bitmap.get.resp.valid := Bitmap.io.resp.valid && bitmapresp_to_llptw\n\
      501:       hptw.io.bitmap.get.resp.valid := Bitmap.io.resp.valid && bitmapresp_to_hptw\n\
      502:       ptw.io.bitmap.get.resp.valid := Bitmap.io.resp.valid && bitmapresp_to_ptw"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 529-547
    context: "529:   hptw.io.mem.resp.bits := resp_pte.apply(l2tlbParams.llptwsize
      + 1)\n530:   // mem -> cache\n531:   val refill_from_llptw = mem_resp_from_llptw\n\
      532:   val refill_from_ptw = mem_resp_from_ptw\n533:   val refill_from_hptw
      = mem_resp_from_hptw\n534:   val refill_level = Mux(refill_from_llptw, 0.U,
      Mux(refill_from_ptw, RegEnable(ptw.io.refill.level, 0.U, ptw.io.mem.req.fire),
      RegEnable(hptw.io.refill.level, 0.U, hptw.io.mem.req.fire)))\n535:   val refill_valid
      = mem_resp_done && (if (HasBitmapCheck) !mem_resp_from_bitmap else true.B) &&
      !flush && !flush_latch(mem.d.bits.source) && !(from_hptw(mem.d.bits.source)
      && hptw_bypassed)\n536: \n537:   cache.io.refill.valid := GatedValidRegNext(refill_valid,
      false.B)\n538:   cache.io.refill.bits.ptes := refill_data.asUInt\n539:   cache.io.refill.bits.req_info_dup.map(_
      := RegEnable(Mux(refill_from_llptw, llptw_mem.refill, Mux(refill_from_ptw, ptw.io.refill.req_info,
      hptw.io.refill.req_info)), refill_valid))\n540:   cache.io.refill.bits.level_dup.map(_
      := RegEnable(refill_level, refill_valid))\n541:   cache.io.refill.bits.levelOH(refill_level,
      refill_valid)\n542:   cache.io.refill.bits.sel_pte_dup.map(_ := RegEnable(sel_data(refill_data_tmp.asUInt,
      req_addr_low(mem.d.bits.source)), refill_valid))\n543: \n544:   if (env.EnableDifftest)
      {\n545:     val difftest_ptw_addr = RegInit(VecInit(Seq.fill(MemReqWidth)(0.U(PAddrBits.W))))\n\
      546:     when (mem.a.valid) {\n547:       difftest_ptw_addr(mem.a.bits.source)
      := mem.a.bits.address"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 558-572
    context: "558: \n559:   if (env.EnableDifftest) {\n560:     for (i <- 0 until
      PtwWidth) {\n561:       val difftest = DifftestModule(new DiffL2TLBEvent)\n\
      562:       difftest.coreid := io.hartId\n563:       difftest.valid := io.tlb(i).resp.fire
      && !io.tlb(i).resp.bits.s1.af && !io.tlb(i).resp.bits.s2.gaf\n564:       difftest.index
      := i.U\n565:       difftest.vpn := Cat(io.tlb(i).resp.bits.s1.entry.tag, 0.U(sectortlbwidth.W))\n\
      566:       difftest.pbmt := io.tlb(i).resp.bits.s1.entry.pbmt\n567:       difftest.g_pbmt
      := io.tlb(i).resp.bits.s2.entry.pbmt\n568:       for (j <- 0 until tlbcontiguous)
      {\n569:         difftest.ppn(j) := Cat(io.tlb(i).resp.bits.s1.entry.ppn, io.tlb(i).resp.bits.s1.ppn_low(j))\n\
      570:         difftest.valididx(j) := io.tlb(i).resp.bits.s1.valididx(j)\n571:\
      \         difftest.pteidx(j) := io.tlb(i).resp.bits.s1.pteidx(j)\n572:     \
      \  }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 597-607
    context: "597:   if (HasBitmapCheck) {\n598:     pmp_check(4).req <> bitmap.get.io.pmp.req\n\
      599:     bitmap.get.io.pmp.resp <> pmp_check(4).resp\n600:   }\n601: \n602:\
      \   llptw_out.ready := outReady(llptw_out.bits.req_info.source, outArbMqPort)\n\
      603: \n604:   // hptw and page cache -> ptw and llptw\n605:   val HptwRespArbCachePort
      = 0\n606:   val HptwRespArbHptw = 1\n607:   hptw_resp_arb.io.in(HptwRespArbCachePort).valid
      := cache.io.resp.valid && cache.io.resp.bits.hit && cache.io.resp.bits.isHptwReq"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 608-618
    context: "608:   hptw_resp_arb.io.in(HptwRespArbCachePort).bits.id := cache.io.resp.bits.toHptw.id\n\
      609:   hptw_resp_arb.io.in(HptwRespArbCachePort).bits.resp := cache.io.resp.bits.toHptw.resp\n\
      610:   hptw_resp_arb.io.in(HptwRespArbHptw).valid := hptw.io.resp.valid\n611:\
      \   hptw_resp_arb.io.in(HptwRespArbHptw).bits.id := hptw.io.resp.bits.id\n612:\
      \   hptw_resp_arb.io.in(HptwRespArbHptw).bits.resp := hptw.io.resp.bits.resp\n\
      613:   hptw.io.resp.ready := hptw_resp_arb.io.in(HptwRespArbHptw).ready\n614:\
      \ \n615:   ptw.io.hptw.resp.valid := hptw_resp_arb.io.out.valid && hptw_resp_arb.io.out.bits.id
      === FsmReqID.U\n616:   ptw.io.hptw.resp.bits.h_resp := hptw_resp_arb.io.out.bits.resp\n\
      617:   llptw.io.hptw.resp.valid := hptw_resp_arb.io.out.valid && hptw_resp_arb.io.out.bits.id
      =/= FsmReqID.U\n618:   llptw.io.hptw.resp.bits.id := hptw_resp_arb.io.out.bits.id"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 615-625
    context: "615:   ptw.io.hptw.resp.valid := hptw_resp_arb.io.out.valid && hptw_resp_arb.io.out.bits.id
      === FsmReqID.U\n616:   ptw.io.hptw.resp.bits.h_resp := hptw_resp_arb.io.out.bits.resp\n\
      617:   llptw.io.hptw.resp.valid := hptw_resp_arb.io.out.valid && hptw_resp_arb.io.out.bits.id
      =/= FsmReqID.U\n618:   llptw.io.hptw.resp.bits.id := hptw_resp_arb.io.out.bits.id\n\
      619:   llptw.io.hptw.resp.bits.h_resp := hptw_resp_arb.io.out.bits.resp\n620:\
      \   hptw_resp_arb.io.out.ready := true.B\n621: \n622:   val cfsValue = Option.when(HasBitmapCheck)(llptw_out.bits.bitmapCheck.get.cfs)\n\
      623: \n624:   // Timing: Maybe need to do some optimization or even add one
      more cycle\n625:   for (i <- 0 until PtwWidth) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 642-652
    context: "642:         true, s2xlate = llptw_out.bits.req_info.s2xlate, mPBMTE
      = mPBMTE, hPBMTE = hPBMTE, gpf = llptw_out.bits.h_resp.gpf,\n643:         cfs
      = cfsValue.getOrElse(VecInit(Seq.fill(tlbcontiguous)(false.B)))\n644:      \
      \ )\n645:     )\n646:     mergeArb(i).in(outArbMqPort).bits.s2 := llptw_out.bits.h_resp\n\
      647:     mergeArb(i).out.ready := outArb(i).in(0).ready\n648:   }\n649: \n650:\
      \   for (i <- 0 until PtwWidth) {\n651:     outArb(i).in(0).valid := mergeArb(i).out.valid\n\
      652:     outArb(i).in(0).bits.s2xlate := mergeArb(i).out.bits.s2xlate"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 658-671
    context: "658:   io.tlb.map(_.resp).zip(outArb.map(_.out)).map{\n659:     case
      (resp, out) => resp <> out\n660:   }\n661: \n662:   // sfence\n663:   when (flush)
      {\n664:     for (i <- 0 until MemReqWidth) {\n665:       when (waiting_resp(i))
      {\n666:         flush_latch(i) := true.B\n667:       }\n668:     }\n669:   }\n\
      670:   // mem -> control signal\n671:   // waiting_resp and sfence_latch will
      be reset when mem_resp_done"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 669-684
    context: "669:   }\n670:   // mem -> control signal\n671:   // waiting_resp and
      sfence_latch will be reset when mem_resp_done\n672:   when (mem_resp_done) {\n\
      673:     waiting_resp(mem.d.bits.source) := false.B\n674:     flush_latch(mem.d.bits.source)
      := false.B\n675:   }\n676: \n677:   def block_decoupled[T <: Data](source: DecoupledIO[T],
      sink: DecoupledIO[T], block_signal: Bool) = {\n678:     sink.valid   := source.valid
      && !block_signal\n679:     source.ready := sink.ready   && !block_signal\n680:\
      \     sink.bits    := source.bits\n681:   }\n682: \n683:   def get_part(data:
      Vec[UInt], index: UInt): UInt = {\n684:     val inner_data = data.asTypeOf(Vec(data.getWidth
      / XLEN, UInt(XLEN.W)))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 696-706
    context: "696:       val pte_in = pte(64 * i + 63, 64 * i).asTypeOf(new PteBundle())\n\
      697:       val ptw_resp = Wire(new PtwMergeEntry(tagLen = sectorvpnLen, hasPerm
      = true, hasLevel = true, hasNapot = true))\n698:       ptw_resp.ppn := pte_in.getPPN()(ptePPNLen
      - 1, sectortlbwidth)\n699:       ptw_resp.ppn_low := pte_in.getPPN()(sectortlbwidth
      - 1, 0)\n700:       ptw_resp.level.map(_ := 0.U)\n701:       ptw_resp.pbmt :=
      pte_in.pbmt\n702:       ptw_resp.n.map(_ := pte_in.n === true.B && ptw_resp.ppn(3,
      0) === 8.U)\n703:       ptw_resp.perm.map(_ := pte_in.getPerm())\n704:     \
      \  ptw_resp.tag := vpn(vpnLen - 1, sectortlbwidth)\n705:       // LLPTW will
      not handle onlyS2 situations\n706:       // noS2xlate. pf: allStagePf; af: af(pmp_af)
      || pte_in.isAf(ppn_af); gpf: never"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 730-740
    context: "730:     val ptw_sector_resp = Wire(new PtwSectorResp)\n731:     ptw_sector_resp.entry.tag
      := pte.entry(OHToUInt(pte.pteidx)).tag\n732:     ptw_sector_resp.entry.asid
      := pte.entry(OHToUInt(pte.pteidx)).asid\n733:     ptw_sector_resp.entry.vmid.map(_
      := pte.entry(OHToUInt(pte.pteidx)).vmid.getOrElse(0.U))\n734:     ptw_sector_resp.entry.ppn
      := pte.entry(OHToUInt(pte.pteidx)).ppn\n735:     ptw_sector_resp.entry.pbmt
      := pte.entry(OHToUInt(pte.pteidx)).pbmt\n736:     ptw_sector_resp.entry.n.map(_
      := pte.entry(OHToUInt(pte.pteidx)).n.getOrElse(0.U))\n737:     ptw_sector_resp.entry.perm.map(_
      := pte.entry(OHToUInt(pte.pteidx)).perm.getOrElse(0.U.asTypeOf(new PtePermBundle)))\n\
      738:     ptw_sector_resp.entry.level.map(_ := pte.entry(OHToUInt(pte.pteidx)).level.getOrElse(0.U(log2Up(Level
      + 1).W)))\n739:     ptw_sector_resp.entry.prefetch := pte.entry(OHToUInt(pte.pteidx)).prefetch\n\
      740:     ptw_sector_resp.entry.v := pte.entry(OHToUInt(pte.pteidx)).v"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 742-752
    context: "742:     ptw_sector_resp.pf := pte.entry(OHToUInt(pte.pteidx)).pf\n\
      743:     ptw_sector_resp.addr_low := OHToUInt(pte.pteidx)\n744:     ptw_sector_resp.pteidx
      := pte.pteidx\n745:     for (i <- 0 until tlbcontiguous) {\n746:       val ppn_equal
      = pte.entry(i).ppn === pte.entry(OHToUInt(pte.pteidx)).ppn\n747:       val pbmt_equal
      = pte.entry(i).pbmt === pte.entry(OHToUInt(pte.pteidx)).pbmt\n748:       val
      perm_equal = pte.entry(i).perm.getOrElse(0.U.asTypeOf(new PtePermBundle)).asUInt
      === pte.entry(OHToUInt(pte.pteidx)).perm.getOrElse(0.U.asTypeOf(new PtePermBundle)).asUInt\n\
      749:       val v_equal = pte.entry(i).v === pte.entry(OHToUInt(pte.pteidx)).v\n\
      750:       val af_equal = pte.entry(i).af === pte.entry(OHToUInt(pte.pteidx)).af\n\
      751:       val pf_equal = pte.entry(i).pf === pte.entry(OHToUInt(pte.pteidx)).pf\n\
      752:       val cf_equal = if (HasBitmapCheck) pte.entry(i).cf === pte.entry(OHToUInt(pte.pteidx)).cf
      else true.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 755-766
    context: "755:     }\n756:     ptw_sector_resp.valididx(OHToUInt(pte.pteidx))
      := true.B\n757:     ptw_sector_resp\n758:   }\n759: \n760:   def outReady(source:
      UInt, port: Int): Bool = {\n761:     MuxLookup(source, true.B)((0 until PtwWidth).map(i
      => i.U -> mergeArb(i).in(port).ready))\n762:   }\n763: \n764:   // debug info\n\
      765:   for (i <- 0 until PtwWidth) {\n766:     XSDebug(p\"[io.tlb(${i.U})] ${io.tlb(i)}\\\
      n\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 767-778
    context: "767:   }\n768:   XSDebug(p\"[sfence] ${io.sfence}\\n\")\n769:   XSDebug(p\"\
      [io.csr.tlb] ${io.csr.tlb}\\n\")\n770: \n771:   for (i <- 0 until PtwWidth)
      {\n772:     XSPerfAccumulate(s\"req_count${i}\", io.tlb(i).req(0).fire)\n773:\
      \     XSPerfAccumulate(s\"req_blocked_count_${i}\", io.tlb(i).req(0).valid &&
      !io.tlb(i).req(0).ready)\n774:   }\n775:   XSPerfAccumulate(s\"req_blocked_by_mq\"\
      , arb1.io.out.valid && missQueue.io.out.valid)\n776:   for (i <- 0 until (MemReqWidth
      + 1)) {\n777:     XSPerfAccumulate(s\"mem_req_util${i}\", PopCount(waiting_resp)
      === i.U)\n778:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 775-788
    context: "775:   XSPerfAccumulate(s\"req_blocked_by_mq\", arb1.io.out.valid &&
      missQueue.io.out.valid)\n776:   for (i <- 0 until (MemReqWidth + 1)) {\n777:\
      \     XSPerfAccumulate(s\"mem_req_util${i}\", PopCount(waiting_resp) === i.U)\n\
      778:   }\n779:   XSPerfAccumulate(\"mem_cycle\", PopCount(waiting_resp) =/=
      0.U)\n780:   XSPerfAccumulate(\"mem_count\", mem.a.fire)\n781:   for (i <- 0
      until PtwWidth) {\n782:     XSPerfAccumulate(s\"llptw_ppn_af${i}\", mergeArb(i).in(outArbMqPort).valid
      && mergeArb(i).in(outArbMqPort).bits.s1.entry(OHToUInt(mergeArb(i).in(outArbMqPort).bits.s1.pteidx)).af
      && !llptw_out.bits.af)\n783:     XSPerfAccumulate(s\"access_fault${i}\", io.tlb(i).resp.fire
      && io.tlb(i).resp.bits.s1.af)\n784:   }\n785: \n786:   // print configs\n787:\
      \   println(s\"${l2tlbParams.name}: a ptw, a llptw with size ${l2tlbParams.llptwsize},
      miss queue size ${MissQueueSize} l2:${l2tlbParams.l2Size} fa l1: nSets ${l2tlbParams.l1nSets}
      nWays ${l2tlbParams.l1nWays} l0: ${l2tlbParams.l0nSets} nWays ${l2tlbParams.l0nWays}
      blockBytes:${l2tlbParams.blockBytes}\")\n788: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 789-807
    context: "789:   val perfEvents  = Seq(llptw, cache, ptw).flatMap(_.getPerfEvents)\n\
      790:   generatePerfEvent()\n791: \n792:   val isWriteL1TlbTable = Constantin.createRecord(s\"\
      isWriteL1TlbTable$hartId\")\n793:   val L1TlbTable = ChiselDB.createTable(s\"\
      L1Tlb_hart$hartId\", new L1TlbDB)\n794:   val ITlbReqDB, DTlbReqDB, ITlbRespDB,
      DTlbRespDB = Wire(new L1TlbDB)\n795:   ITlbReqDB.vpn := io.tlb(0).req(0).bits.vpn\n\
      796:   DTlbReqDB.vpn := io.tlb(1).req(0).bits.vpn\n797:   ITlbRespDB.vpn :=
      Cat(io.tlb(0).resp.bits.s1.entry.tag, OHToUInt(io.tlb(0).resp.bits.s1.pteidx))\n\
      798:   DTlbRespDB.vpn := Cat(io.tlb(1).resp.bits.s1.entry.tag, OHToUInt(io.tlb(1).resp.bits.s1.pteidx))\n\
      799:   L1TlbTable.log(ITlbReqDB, isWriteL1TlbTable.orR && io.tlb(0).req(0).fire,
      \"ITlbReq\", clock, reset)\n800:   L1TlbTable.log(DTlbReqDB, isWriteL1TlbTable.orR
      && io.tlb(1).req(0).fire, \"DTlbReq\", clock, reset)\n801:   L1TlbTable.log(ITlbRespDB,
      isWriteL1TlbTable.orR && io.tlb(0).resp.fire, \"ITlbResp\", clock, reset)\n\
      802:   L1TlbTable.log(DTlbRespDB, isWriteL1TlbTable.orR && io.tlb(1).resp.fire,
      \"DTlbResp\", clock, reset)\n803: \n804:   val isWritePageCacheTable = Constantin.createRecord(s\"\
      isWritePageCacheTable$hartId\")\n805:   val PageCacheTable = ChiselDB.createTable(s\"\
      PageCache_hart$hartId\", new PageCacheDB)\n806:   val PageCacheDB = Wire(new
      PageCacheDB)\n807:   PageCacheDB.vpn := Cat(cache.io.resp.bits.stage1.entry(0).tag,
      OHToUInt(cache.io.resp.bits.stage1.pteidx))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 811-821
    context: "811:   PageCacheDB.prefetched := cache.io.resp.bits.stage1.entry(0).prefetch\n\
      812:   PageCacheDB.prefetch := cache.io.resp.bits.prefetch\n813:   PageCacheDB.l2Hit
      := cache.io.resp.bits.toFsm.l2Hit\n814:   PageCacheDB.l1Hit := cache.io.resp.bits.toFsm.l1Hit\n\
      815:   PageCacheDB.hit := cache.io.resp.bits.hit\n816:   PageCacheTable.log(PageCacheDB,
      isWritePageCacheTable.orR && cache.io.resp.fire, \"PageCache\", clock, reset)\n\
      817: \n818:   val isWritePTWTable = Constantin.createRecord(s\"isWritePTWTable$hartId\"\
      )\n819:   val PTWTable = ChiselDB.createTable(s\"PTW_hart$hartId\", new PTWDB)\n\
      820:   val PTWReqDB, PTWRespDB, LLPTWReqDB, LLPTWRespDB = Wire(new PTWDB)\n\
      821:   PTWReqDB.vpn := ptw.io.req.bits.req_info.vpn"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 824-837
    context: "824:   PTWRespDB.source := ptw.io.refill.req_info.source\n825:   LLPTWReqDB.vpn
      := llptw.io.in.bits.req_info.vpn\n826:   LLPTWReqDB.source := llptw.io.in.bits.req_info.source\n\
      827:   LLPTWRespDB.vpn := llptw.io.mem.refill.vpn\n828:   LLPTWRespDB.source
      := llptw.io.mem.refill.source\n829:   PTWTable.log(PTWReqDB, isWritePTWTable.orR
      && ptw.io.req.fire, \"PTWReq\", clock, reset)\n830:   PTWTable.log(PTWRespDB,
      isWritePTWTable.orR && ptw.io.mem.resp.fire, \"PTWResp\", clock, reset)\n831:\
      \   PTWTable.log(LLPTWReqDB, isWritePTWTable.orR && llptw.io.in.fire, \"LLPTWReq\"\
      , clock, reset)\n832:   PTWTable.log(LLPTWRespDB, isWritePTWTable.orR && llptw.io.mem.resp.fire,
      \"LLPTWResp\", clock, reset)\n833: \n834:   val isWriteL2TlbMissQueueTable =
      Constantin.createRecord(s\"isWriteL2TlbMissQueueTable$hartId\")\n835:   val
      L2TlbMissQueueTable = ChiselDB.createTable(s\"L2TlbMissQueue_hart$hartId\",
      new L2TlbMissQueueDB)\n836:   val L2TlbMissQueueInDB, L2TlbMissQueueOutDB =
      Wire(new L2TlbMissQueueDB)\n837:   L2TlbMissQueueInDB.vpn := missQueue.io.in.bits.req_info.vpn"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 834-845
    context: "834:   val isWriteL2TlbMissQueueTable = Constantin.createRecord(s\"\
      isWriteL2TlbMissQueueTable$hartId\")\n835:   val L2TlbMissQueueTable = ChiselDB.createTable(s\"\
      L2TlbMissQueue_hart$hartId\", new L2TlbMissQueueDB)\n836:   val L2TlbMissQueueInDB,
      L2TlbMissQueueOutDB = Wire(new L2TlbMissQueueDB)\n837:   L2TlbMissQueueInDB.vpn
      := missQueue.io.in.bits.req_info.vpn\n838:   L2TlbMissQueueOutDB.vpn := missQueue.io.out.bits.req_info.vpn\n\
      839:   L2TlbMissQueueTable.log(L2TlbMissQueueInDB, isWriteL2TlbMissQueueTable.orR
      && missQueue.io.in.fire, \"L2TlbMissQueueIn\", clock, reset)\n840:   L2TlbMissQueueTable.log(L2TlbMissQueueOutDB,
      isWriteL2TlbMissQueueTable.orR && missQueue.io.out.fire, \"L2TlbMissQueueOut\"\
      , clock, reset)\n841: }\n842: \n843: /** BlockHelper, block missqueue, not to
      send too many req to cache\n844:  *  Parameter:\n845:  *    enable: enable BlockHelper,
      mq should not send too many reqs"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 877-891
    context: "877:   val pte    = IO(Output(UInt(64.W)))\n878:   val level  = IO(Output(UInt(8.W)))\n\
      879:   val pf     = IO(Output(UInt(8.W)))\n880: }\n881: \n882: class PTWDelayN[T
      <: Data](gen: T, n: Int, flush: Bool) extends Module {\n883:   val io = IO(new
      Bundle() {\n884:     val in = Input(gen)\n885:     val out = Output(gen)\n886:\
      \     val ptwflush = Input(flush.cloneType)\n887:   })\n888:   val out = RegInit(VecInit(Seq.fill(n)(0.U.asTypeOf(gen))))\n\
      889:   val t = RegInit(VecInit(Seq.fill(n)(0.U.asTypeOf(gen))))\n890:   out(0)
      := io.in\n891:   if (n == 1) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 889-899
    context: "889:   val t = RegInit(VecInit(Seq.fill(n)(0.U.asTypeOf(gen))))\n890:\
      \   out(0) := io.in\n891:   if (n == 1) {\n892:     io.out := out(0)\n893: \
      \  } else {\n894:     when (io.ptwflush) {\n895:       for (i <- 0 until n)
      {\n896:         t(i) := 0.U.asTypeOf(gen)\n897:         out(i) := 0.U.asTypeOf(gen)\n\
      898:       }\n899:       io.out := 0.U.asTypeOf(gen)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 906-919
    context: "906:     }\n907:   }\n908: }\n909: \n910: object PTWDelayN {\n911: \
      \  def apply[T <: Data](in: T, n: Int, flush: Bool): T = {\n912:     val delay
      = Module(new PTWDelayN(in.cloneType, n, flush))\n913:     delay.io.in := in\n\
      914:     delay.io.ptwflush := flush\n915:     delay.io.out\n916:   }\n917: }\n\
      918: \n919: class FakePTW()(implicit p: Parameters) extends XSModule with HasPtwConst
      {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 916-928
    context: "916:   }\n917: }\n918: \n919: class FakePTW()(implicit p: Parameters)
      extends XSModule with HasPtwConst {\n920:   val io = IO(new L2TLBIO)\n921: \
      \  val flush = VecInit(Seq.fill(PtwWidth)(false.B))\n922:   flush(0) := DelayN(io.sfence.valid
      || io.csr.tlb.satp.changed || io.csr.tlb.vsatp.changed || io.csr.tlb.hgatp.changed
      || io.csr.tlb.priv.virt_changed, itlbParams.fenceDelay)\n923:   flush(1) :=
      DelayN(io.sfence.valid || io.csr.tlb.satp.changed || io.csr.tlb.vsatp.changed
      || io.csr.tlb.hgatp.changed || io.csr.tlb.priv.virt_changed, ldtlbParams.fenceDelay)\n\
      924:   for (i <- 0 until PtwWidth) {\n925:     val helper = Module(new PTEHelper())\n\
      926:     helper.clock := clock\n927:     helper.satp := io.csr.tlb.satp.ppn\n\
      928: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 925-939
    context: "925:     val helper = Module(new PTEHelper())\n926:     helper.clock
      := clock\n927:     helper.satp := io.csr.tlb.satp.ppn\n928: \n929:     if (coreParams.softPTWDelay
      == 1) {\n930:       helper.enable := io.tlb(i).req(0).fire\n931:       helper.vpn
      := io.tlb(i).req(0).bits.vpn\n932:     } else {\n933:       helper.enable :=
      PTWDelayN(io.tlb(i).req(0).fire, coreParams.softPTWDelay - 1, flush(i))\n934:\
      \       helper.vpn := PTWDelayN(io.tlb(i).req(0).bits.vpn, coreParams.softPTWDelay
      - 1, flush(i))\n935:     }\n936: \n937:     val pte = helper.pte.asTypeOf(new
      PteBundle)\n938:     val level = helper.level\n939:     val pf = helper.pf"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 936-956
    context: "936: \n937:     val pte = helper.pte.asTypeOf(new PteBundle)\n938: \
      \    val level = helper.level\n939:     val pf = helper.pf\n940:     val empty
      = RegInit(true.B)\n941:     when (io.tlb(i).req(0).fire) {\n942:       empty
      := false.B\n943:     } .elsewhen (io.tlb(i).resp.fire || flush(i)) {\n944: \
      \      empty := true.B\n945:     }\n946: \n947:     io.tlb(i).req(0).ready :=
      empty || io.tlb(i).resp.fire\n948:     io.tlb(i).resp.valid := PTWDelayN(io.tlb(i).req(0).fire,
      coreParams.softPTWDelay, flush(i))\n949:     assert(!io.tlb(i).resp.valid ||
      io.tlb(i).resp.ready)\n950:     io.tlb(i).resp.bits.s1.entry.tag := PTWDelayN(io.tlb(i).req(0).bits.vpn,
      coreParams.softPTWDelay, flush(i))\n951:     io.tlb(i).resp.bits.s1.entry.pbmt
      := pte.pbmt\n952:     io.tlb(i).resp.bits.s1.entry.ppn := pte.ppn\n953:    \
      \ io.tlb(i).resp.bits.s1.entry.perm.map(_ := pte.getPerm())\n954:     io.tlb(i).resp.bits.s1.entry.level.map(_
      := level)\n955:     io.tlb(i).resp.bits.s1.pf := pf\n956:     io.tlb(i).resp.bits.s1.af
      := DontCare // TODO: implement it"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 65-88
    context: "65:     * it should not drop reqs from pipe and should return right
      resp\n66:     */\n67:   val sfence = DelayN(io.sfence, q.fenceDelay)\n68:  \
      \ val csr = DelayN(io.csr, q.fenceDelay)\n69: \n70:   val flush_mmu = sfence.valid
      || csr.satp.changed || csr.vsatp.changed || csr.hgatp.changed || csr.priv.virt_changed\n\
      71:   val mmu_flush_pipe = sfence.valid && sfence.bits.flushPipe // for svinval,
      won't flush pipe\n72:   val flush_pipe = io.flushPipe\n73:   val redirect =
      io.redirect\n74:   val EffectiveVa = Wire(Vec(Width, UInt(XLEN.W)))\n75:   val
      req_in = req\n76:   val req_out = Reg(Vec(Width, new TlbReq))\n77:   for (i
      <- 0 until Width) {\n78:     when (req(i).fire) {\n79:       req_out(i) := req(i).bits\n\
      80:       req_out(i).fullva := EffectiveVa(i)\n81:     }\n82:   }\n83:   val
      req_out_v = (0 until Width).map(i => ValidHold(req_in(i).fire && !req_in(i).bits.kill,
      resp(i).fire, flush_pipe(i)))\n84: \n85:   val isHyperInst = (0 until Width).map(i
      => req_out_v(i) && req_out(i).hyperinst)\n86: \n87:   // ATTENTION: csr and
      flush from backend are delayed. csr should not be later than flush.\n88:   //
      because, csr will influence tlb behavior."
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 88-98
    context: "88:   // because, csr will influence tlb behavior.\n89:   val ifetch
      = if (q.fetchi) true.B else false.B\n90:   val mode_tmp = if (q.useDmode) csr.priv.dmode
      else csr.priv.imode\n91:   val mode = (0 until Width).map(i => Mux(isHyperInst(i),
      csr.priv.spvp, mode_tmp))\n92:   val virt_in = csr.priv.virt\n93:   val virt_out
      = req.map(a => RegEnable(csr.priv.virt, a.fire))\n94:   val sum = (0 until Width).map(i
      => Mux(virt_out(i) || isHyperInst(i), csr.priv.vsum, csr.priv.sum))\n95:   val
      mxr = (0 until Width).map(i => Mux(virt_out(i) || isHyperInst(i), csr.priv.vmxr
      || csr.priv.mxr, csr.priv.mxr))\n96:   val req_in_s2xlate = (0 until Width).map(i
      => MuxCase(noS2xlate, Seq(\n97:       (!(virt_in || req_in(i).bits.hyperinst))
      -> noS2xlate,\n98:       (csr.vsatp.mode =/= 0.U && csr.hgatp.mode =/= 0.U)
      -> allStage,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 150-160
    context: "150:     (virt_in || req_in(i).bits.hyperinst) &&\n151:     (Sv39vsEnable
      || Sv48vsEnable || Sv39x4Enable || Sv48x4Enable) &&\n152:     (premode(i) <
      ModeM)\n153:   )\n154: \n155:   (0 until Width).foreach{i =>\n156: \n157:  \
      \   val pmm = WireInit(0.U(2.W))\n158: \n159:     when (ifetch || req(i).bits.hlvx)
      {\n160:       pmm := 0.U"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 218-228
    context: "218:         preaf(i) := af\n219:       }\n220:     }\n221:   }\n222:\
      \ \n223:   val refill = ptw.resp.fire && !(ptw.resp.bits.getGpa) && !need_gpa
      && !need_gpa_wire && !flush_mmu\n224:   // prevent ptw refill when: 1) it's
      a getGpa request; 2) l1tlb is in need_gpa state; 3) mmu is being flushed.\n\
      225: \n226:   refill_to_mem := DontCare\n227:   val entries = Module(new TlbStorageWrapper(Width,
      q, nRespDups))\n228:   entries.io.base_connect(sfence, csr, csr.satp)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 234-259
    context: "234:     resp(i).bits.debug.isFirstIssue := RegEnable(req(i).bits.debug.isFirstIssue,
      req(i).valid)\n235:     resp(i).bits.debug.robIdx := RegEnable(req(i).bits.debug.robIdx,
      req(i).valid)\n236:   }\n237: \n238:   // read TLB, get hit/miss, paddr, perm
      bits\n239:   val readResult = (0 until Width).map(TLBRead(_))\n240:   val hitVec
      = readResult.map(_._1)\n241:   val missVec = readResult.map(_._2)\n242:   val
      pmp_addr = readResult.map(_._3)\n243:   val perm = readResult.map(_._4)\n244:\
      \   val g_perm = readResult.map(_._5)\n245:   val pbmt = readResult.map(_._6)\n\
      246:   val g_pbmt = readResult.map(_._7)\n247:   // check pmp use paddr (for
      timing optization, use pmp_addr here)\n248:   // check permisson\n249:   (0
      until Width).foreach{i =>\n250:     val noTranslateReg = RegNext(req(i).bits.no_translate)\n\
      251:     val addr = Mux(noTranslateReg, req(i).bits.pmp_addr, pmp_addr(i))\n\
      252:     pmp_check(addr, req_out(i).size, req_out(i).cmd, noTranslateReg, i)\n\
      253:     for (d <- 0 until nRespDups) {\n254:       pbmt_check(i, d, pbmt(i)(d),
      g_pbmt(i)(d), req_out_s2xlate(i))\n255:       perm_check(perm(i)(d), req_out(i).cmd,
      i, d, g_perm(i)(d), req_out(i).hlvx, req_out_s2xlate(i), prepf(i), pregpf(i),
      preaf(i))\n256:     }\n257:     hasGpf(i) := hitVec(i) && (resp(i).bits.excp(0).gpf.ld
      || resp(i).bits.excp(0).gpf.st || resp(i).bits.excp(0).gpf.instr)\n258:   }\n\
      259: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 259-276
    context: "259: \n260:   // handle block or non-block io\n261:   // for non-block
      io, just return the above result, send miss to ptw\n262:   // for block io,
      hold the request, send miss to ptw,\n263:   //   when ptw back, return the result\n\
      264:   (0 until Width) foreach {i =>\n265:     if (Block(i)) handle_block(i)\n\
      266:     else handle_nonblock(i)\n267:   }\n268:   io.ptw.resp.ready := true.B\n\
      269: \n270:   /************************  main body above | method/log/perf below
      ****************************/\n271:   def TLBRead(i: Int) = {\n272:     val
      (e_hit, e_ppn, e_perm, e_g_perm, e_s2xlate, e_pbmt, e_g_pbmt) = entries.io.r_resp_apply(i)\n\
      273:     val (p_hit, p_ppn, p_pbmt, p_perm, p_gvpn, p_g_pbmt, p_g_perm, p_s2xlate,
      p_s1_level, p_s1_isLeaf, p_s1_isFakePte) = ptw_resp_bypass(get_pn(req_in(i).bits.vaddr),
      req_in_s2xlate(i))\n274:     val enable = portTranslateEnable(i)\n275:     val
      isOnlys2xlate = req_out_s2xlate(i) === onlyStage2\n276:     val need_gpa_vpn_hit
      = need_gpa_vpn === get_pn(req_out(i).vaddr)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 274-287
    context: "274:     val enable = portTranslateEnable(i)\n275:     val isOnlys2xlate
      = req_out_s2xlate(i) === onlyStage2\n276:     val need_gpa_vpn_hit = need_gpa_vpn
      === get_pn(req_out(i).vaddr)\n277:     val isitlb = TlbCmd.isExec(req_out(i).cmd)\n\
      278:     val isPrefetch = req_out(i).isPrefetch\n279:     val currentRedirect
      = req_out(i).debug.robIdx.needFlush(redirect)\n280:     val lastCycleRedirect
      = req_out(i).debug.robIdx.needFlush(RegNext(redirect))\n281: \n282:     when
      (!isitlb && need_gpa_robidx.needFlush(redirect) || isitlb && flush_pipe(i)){\n\
      283:       need_gpa := false.B\n284:       resp_gpa_refill := false.B\n285:\
      \       need_gpa_vpn := 0.U\n286:     }.elsewhen (req_out_v(i) && !p_hit &&
      !(resp_gpa_refill && need_gpa_vpn_hit) && !isOnlys2xlate && hasGpf(i) && need_gpa
      === false.B && !io.requestor(i).req_kill && !isPrefetch && !currentRedirect
      && !lastCycleRedirect) {\n287:       need_gpa_wire := true.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 287-297
    context: "287:       need_gpa_wire := true.B\n288:       need_gpa := true.B\n\
      289:       need_gpa_vpn := get_pn(req_out(i).vaddr)\n290:       resp_gpa_refill
      := false.B\n291:       need_gpa_robidx := req_out(i).debug.robIdx\n292:    \
      \ }.elsewhen (ptw.resp.fire && need_gpa && need_gpa_vpn === ptw.resp.bits.getVpn(need_gpa_vpn))
      {\n293:       resp_gpa_gvpn := Mux(ptw.resp.bits.s2xlate === onlyStage2, ptw.resp.bits.s2.entry.tag,
      ptw.resp.bits.s1.genGVPN(need_gpa_vpn))\n294:       resp_s1_level := ptw.resp.bits.s1.entry.level.get\n\
      295:       resp_s1_isLeaf := ptw.resp.bits.s1.isLeaf()\n296:       resp_s1_isFakePte
      := ptw.resp.bits.s1.isFakePte()\n297:       resp_gpa_refill := true.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 301-321
    context: "301:       need_gpa := false.B\n302:     }\n303: \n304:     val hit
      = e_hit || p_hit\n305:     val miss = (!hit && enable) || hasGpf(i) && !p_hit
      && !(resp_gpa_refill && need_gpa_vpn_hit) && !isOnlys2xlate && !isPrefetch &&
      !lastCycleRedirect\n306:     hit.suggestName(s\"hit_read_${i}\")\n307:     miss.suggestName(s\"\
      miss_read_${i}\")\n308: \n309:     val vaddr = SignExt(req_out(i).vaddr, PAddrBits)\n\
      310:     resp(i).bits.miss := miss\n311:     resp(i).bits.ptwBack := ptw.resp.fire\n\
      312:     resp(i).bits.memidx := RegEnable(req_in(i).bits.memidx, req_in(i).valid)\n\
      313:     resp(i).bits.fastMiss := !hit && enable\n314: \n315:     val ppn =
      WireInit(VecInit(Seq.fill(nRespDups)(0.U(ppnLen.W))))\n316:     val pbmt = WireInit(VecInit(Seq.fill(nRespDups)(0.U(ptePbmtLen.W))))\n\
      317:     val perm = WireInit(VecInit(Seq.fill(nRespDups)(0.U.asTypeOf(new TlbPermBundle))))\n\
      318:     val gvpn = WireInit(VecInit(Seq.fill(nRespDups)(0.U(ptePPNLen.W))))\n\
      319:     val level = WireInit(VecInit(Seq.fill(nRespDups)(0.U(log2Up(Level +
      1).W))))\n320:     val isLeaf = WireInit(VecInit(Seq.fill(nRespDups)(false.B)))\n\
      321:     val isFakePte = WireInit(VecInit(Seq.fill(nRespDups)(false.B)))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 322-332
    context: "322:     val g_pbmt = WireInit(VecInit(Seq.fill(nRespDups)(0.U(ptePbmtLen.W))))\n\
      323:     val g_perm = WireInit(VecInit(Seq.fill(nRespDups)(0.U.asTypeOf(new
      TlbPermBundle))))\n324:     val r_s2xlate = WireInit(VecInit(Seq.fill(nRespDups)(0.U(2.W))))\n\
      325:     for (d <- 0 until nRespDups) {\n326:       ppn(d) := Mux(p_hit, p_ppn,
      e_ppn(d))\n327:       pbmt(d) := Mux(p_hit, p_pbmt, e_pbmt(d))\n328:       perm(d)
      := Mux(p_hit, p_perm, e_perm(d))\n329:       gvpn(d) :=  Mux(p_hit, p_gvpn,
      resp_gpa_gvpn)\n330:       level(d) := Mux(p_hit, p_s1_level, resp_s1_level)\n\
      331:       isLeaf(d) := Mux(p_hit, p_s1_isLeaf, resp_s1_isLeaf)\n332:      \
      \ isFakePte(d) := Mux(p_hit, p_s1_isFakePte, resp_s1_isFakePte)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 357-367
    context: "357: \n358:     XSDebug(req_out_v(i), p\"(${i.U}) hit:${hit} miss:${miss}
      ppn:${Hexadecimal(ppn(0))} perm:${perm(0)}\\n\")\n359: \n360:     val pmp_paddr
      = resp(i).bits.paddr(0)\n361: \n362:     (hit, miss, pmp_paddr, perm, g_perm,
      pbmt, g_pbmt)\n363:   }\n364: \n365:   def getVpnn(vpn: UInt, idx: UInt): UInt
      = {\n366:     MuxLookup(idx, 0.U)(Seq(\n367:       0.U -> vpn(vpnnLen - 1, 0),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 376-388
    context: "376:     pmp(idx).bits.addr := addr\n377:     pmp(idx).bits.size :=
      size\n378:     pmp(idx).bits.cmd := cmd\n379:   }\n380: \n381:   def pbmt_check(idx:
      Int, d: Int, pbmt: UInt, g_pbmt: UInt, s2xlate: UInt):Unit = {\n382:     val
      onlyS1 = s2xlate === onlyStage1 || s2xlate === noS2xlate\n383:     val pbmtRes
      = pbmt\n384:     val gpbmtRes = g_pbmt\n385:     val res = MuxLookup(s2xlate,
      0.U)(Seq(\n386:       onlyStage1 -> pbmtRes,\n387:       onlyStage2 -> gpbmtRes,\n\
      388:       allStage -> Mux(pbmtRes =/= 0.U, pbmtRes, gpbmtRes),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 386-396
    context: "386:       onlyStage1 -> pbmtRes,\n387:       onlyStage2 -> gpbmtRes,\n\
      388:       allStage -> Mux(pbmtRes =/= 0.U, pbmtRes, gpbmtRes),\n389:      \
      \ noS2xlate -> pbmtRes\n390:     ))\n391:     resp(idx).bits.pbmt(d) := Mux(portTranslateEnable(idx),
      res, 0.U)\n392:   }\n393: \n394:   // for timing optimization, pmp check is
      divided into dynamic and static\n395:   def perm_check(perm: TlbPermBundle,
      cmd: UInt, idx: Int, nDups: Int, g_perm: TlbPermBundle, hlvx: Bool, s2xlate:
      UInt, prepf: Bool = false.B, pregpf: Bool = false.B, preaf: Bool = false.B)
      = {\n396:     // dynamic: superpage (or full-connected reg entries) -> check
      pmp when translation done"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 404-419
    context: "404:     // allS2xlate -> perm.af || g_perm.af\n405:     val af = (!onlyS2
      && perm.af) || ((onlyS2 || allS2xlate) && g_perm.af)\n406: \n407:     // Stage
      1 perm check\n408:     val pf = perm.pf\n409:     val isLd = TlbCmd.isRead(cmd)
      && !TlbCmd.isAmo(cmd)\n410:     val isSt = TlbCmd.isWrite(cmd) || TlbCmd.isAmo(cmd)\n\
      411:     val isInst = TlbCmd.isExec(cmd)\n412:     val ldUpdate = !perm.a &&
      isLd // update A/D through exception\n413:     val stUpdate = (!perm.a || !perm.d)
      && isSt // update A/D through exception\n414:     val instrUpdate = !perm.a
      && isInst // update A/D through exception\n415:     val modeCheck = !(mode(idx)
      === ModeU && !perm.u || mode(idx) === ModeS && perm.u && (!sum(idx) || ifetch))\n\
      416:     val ldPermFail = !(modeCheck && Mux(hlvx, perm.x, perm.r || mxr(idx)
      && perm.x))\n417:     val stPermFail = !(modeCheck && perm.w)\n418:     val
      instrPermFail = !(modeCheck && perm.x)\n419:     val ldPf = (ldPermFail || pf)
      && isLd"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 419-429
    context: "419:     val ldPf = (ldPermFail || pf) && isLd\n420:     val stPf =
      (stPermFail || pf) && isSt\n421:     val instrPf = (instrPermFail || pf) &&
      isInst\n422:     val isFakePte = !perm.v && !perm.pf && !perm.af && !onlyS2\n\
      423:     val isNonLeaf = !(perm.r || perm.w || perm.x) && perm.v && !perm.pf
      && !perm.af\n424:     val s1_valid = portTranslateEnable(idx) && !onlyS2\n425:\
      \ \n426:     // Stage 2 perm check\n427:     val gpf = g_perm.pf\n428:     val
      g_ldUpdate = !g_perm.a && isLd\n429:     val g_stUpdate = (!g_perm.a || !g_perm.d)
      && isSt"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 432-447
    context: "432:     val g_stPermFail = !g_perm.w\n433:     val g_instrPermFail
      = !g_perm.x\n434:     val ldGpf = (g_ldPermFail || gpf) && isLd\n435:     val
      stGpf = (g_stPermFail || gpf) && isSt\n436:     val instrGpf = (g_instrPermFail
      || gpf) && isInst\n437:     val s2_valid = portTranslateEnable(idx) && (onlyS2
      || allS2xlate)\n438: \n439:     val fault_valid = s1_valid || s2_valid\n440:\
      \ \n441:     // when pf and gpf can't happens simultaneously\n442:     val hasPf
      = (ldPf || ldUpdate || stPf || stUpdate || instrPf || instrUpdate) && s1_valid
      && !af && !isFakePte && !isNonLeaf\n443:     // Only lsu need check related
      to high address truncation\n444:     when (RegNext(prepf || pregpf || preaf))
      {\n445:       resp(idx).bits.isForVSnonLeafPTE := false.B\n446:       resp(idx).bits.excp(nDups).pf.ld
      := RegNext(prepf) && isLd\n447:       resp(idx).bits.excp(nDups).pf.st := RegNext(prepf)
      && isSt"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 449-459
    context: "449: \n450:       resp(idx).bits.excp(nDups).gpf.ld := RegNext(pregpf)
      && isLd\n451:       resp(idx).bits.excp(nDups).gpf.st := RegNext(pregpf) &&
      isSt\n452:       resp(idx).bits.excp(nDups).gpf.instr := false.B\n453: \n454:\
      \       resp(idx).bits.excp(nDups).af.ld := RegNext(preaf) && TlbCmd.isRead(cmd)\n\
      455:       resp(idx).bits.excp(nDups).af.st := RegNext(preaf) && TlbCmd.isWrite(cmd)\n\
      456:       resp(idx).bits.excp(nDups).af.instr := false.B\n457: \n458:     \
      \  resp(idx).bits.excp(nDups).vaNeedExt := false.B\n459:       // overwrite
      miss & gpaddr when exception related to high address truncation happens"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 463-486
    context: "463:       // isForVSnonLeafPTE is used only when gpf happens and it
      caused by a G-stage translation which supports VS-stage translation\n464:  \
      \     // it will be sent to CSR in order to modify the m/htinst.\n465:     \
      \  // Ref: The RISC-V Instruction Set Manual: Volume II: Privileged Architecture
      - 19.6.3. Transformed Instruction or Pseudoinstruction for mtinst or htinst\n\
      466:       val isForVSnonLeafPTE = isNonLeaf || isFakePte\n467:       resp(idx).bits.isForVSnonLeafPTE
      := isForVSnonLeafPTE\n468:       resp(idx).bits.excp(nDups).pf.ld := (ldPf ||
      ldUpdate) && s1_valid && !af && !isFakePte && !isNonLeaf\n469:       resp(idx).bits.excp(nDups).pf.st
      := (stPf || stUpdate) && s1_valid && !af && !isFakePte && !isNonLeaf\n470: \
      \      resp(idx).bits.excp(nDups).pf.instr := (instrPf || instrUpdate) && s1_valid
      && !af && !isFakePte && !isNonLeaf\n471:       // NOTE: pf need && with !af,
      page fault has higher priority than access fault\n472:       // but ptw may
      also have access fault, then af happens, the translation is wrong.\n473:   \
      \    // In this case, pf has lower priority than af\n474: \n475:       resp(idx).bits.excp(nDups).gpf.ld
      := (ldGpf || g_ldUpdate) && s2_valid && !af && !hasPf\n476:       resp(idx).bits.excp(nDups).gpf.st
      := (stGpf || g_stUpdate) && s2_valid && !af && !hasPf\n477:       resp(idx).bits.excp(nDups).gpf.instr
      := (instrGpf || g_instrUpdate) && s2_valid && !af && !hasPf\n478: \n479:   \
      \    resp(idx).bits.excp(nDups).af.ld    := af && TlbCmd.isRead(cmd) && fault_valid\n\
      480:       resp(idx).bits.excp(nDups).af.st    := af && TlbCmd.isWrite(cmd)
      && fault_valid\n481:       resp(idx).bits.excp(nDups).af.instr := af && TlbCmd.isExec(cmd)
      && fault_valid\n482: \n483:       resp(idx).bits.excp(nDups).vaNeedExt := true.B\n\
      484:     }\n485: \n486:     resp(idx).bits.excp(nDups).isHyper := isHyperInst(idx)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 486-497
    context: "486:     resp(idx).bits.excp(nDups).isHyper := isHyperInst(idx)\n487:\
      \   }\n488: \n489:   def handle_nonblock(idx: Int): Unit = {\n490:     io.requestor(idx).resp.valid
      := req_out_v(idx)\n491:     io.requestor(idx).req.ready := io.requestor(idx).resp.ready
      // should always be true\n492:     XSError(!io.requestor(idx).resp.ready, s\"\
      ${q.name} port ${idx} is non-block, resp.ready must be true.B\")\n493: \n494:\
      \     val req_need_gpa = hasGpf(idx)\n495:     val req_s2xlate = Wire(UInt(2.W))\n\
      496:     req_s2xlate := MuxCase(noS2xlate, Seq(\n497:       (!(virt_out(idx)
      || req_out(idx).hyperinst)) -> noS2xlate,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 498-511
    context: "498:       (csr.vsatp.mode =/= 0.U && csr.hgatp.mode =/= 0.U) -> allStage,\n\
      499:       (csr.vsatp.mode === 0.U) -> onlyStage2,\n500:       (csr.hgatp.mode
      === 0.U) -> onlyStage1\n501:     ))\n502: \n503:     val ptw_just_back = ptw.resp.fire
      && req_s2xlate === ptw.resp.bits.s2xlate && ptw.resp.bits.hit(get_pn(req_out(idx).vaddr),
      csr.satp.asid, csr.vsatp.asid, csr.hgatp.vmid, allType = true)\n504:     //
      TODO: RegNext enable: ptw.resp.valid ? req.valid\n505:     val ptw_resp_bits_reg
      = RegEnable(ptw.resp.bits, ptw.resp.valid)\n506:     val ptw_already_back =
      GatedValidRegNext(ptw.resp.fire) && req_s2xlate === ptw_resp_bits_reg.s2xlate
      && ptw_resp_bits_reg.hit(get_pn(req_out(idx).vaddr), csr.satp.asid, csr.vsatp.asid,
      csr.hgatp.vmid, allType = true)\n507:     val ptw_getGpa = req_need_gpa && hitVec(idx)\n\
      508:     val need_gpa_vpn_hit = need_gpa_vpn === get_pn(req_out(idx).vaddr)\n\
      509: \n510:     io.ptw.req(idx).valid := false.B;\n511:     io.tlbreplay(idx)
      := false.B;"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 508-518
    context: "508:     val need_gpa_vpn_hit = need_gpa_vpn === get_pn(req_out(idx).vaddr)\n\
      509: \n510:     io.ptw.req(idx).valid := false.B;\n511:     io.tlbreplay(idx)
      := false.B;\n512: \n513:     when (req_out_v(idx) && missVec(idx)) {\n514: \
      \      // NOTE: for an miss tlb request: either send a ptw request, or ask for
      a replay\n515:       when (ptw_just_back || ptw_already_back) {\n516:      \
      \   io.tlbreplay(idx) := true.B;\n517:       } .elsewhen (need_gpa && !need_gpa_vpn_hit
      && !resp_gpa_refill) {\n518:         // not send any unrelated ptw request when
      l1tlb is in need_gpa state"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 520-530
    context: "520:       } .otherwise {\n521:         io.ptw.req(idx).valid := true.B;\n\
      522:       }\n523:     }\n524: \n525:     when (io.requestor(idx).req_kill &&
      GatedValidRegNext(io.requestor(idx).req.fire)) {\n526:       io.ptw.req(idx).valid
      := false.B\n527:       io.tlbreplay(idx) := true.B\n528:     }\n529: \n530:\
      \     io.ptw.req(idx).bits.vpn := get_pn(req_out(idx).vaddr)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 533-548
    context: "533:     io.ptw.req(idx).bits.memidx := req_out(idx).memidx\n534:  \
      \ }\n535: \n536:   def handle_block(idx: Int): Unit = {\n537:     // three valid:
      1.if exist a entry; 2.if sent to ptw; 3.unset resp.valid\n538:     io.requestor(idx).req.ready
      := !req_out_v(idx) || io.requestor(idx).resp.fire\n539:     // req_out_v for
      if there is a request, may long latency, fixme\n540: \n541:     // miss request
      entries\n542:     val req_need_gpa = hasGpf(idx)\n543:     val miss_req_vpn
      = get_pn(req_out(idx).vaddr)\n544:     val miss_req_memidx = req_out(idx).memidx\n\
      545:     val miss_req_s2xlate = Wire(UInt(2.W))\n546:     miss_req_s2xlate :=
      MuxCase(noS2xlate, Seq(\n547:       (!(virt_out(idx) || req_out(idx).hyperinst))
      -> noS2xlate,\n548:       (csr.vsatp.mode =/= 0.U && csr.hgatp.mode =/= 0.U)
      -> allStage,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 547-570
    context: "547:       (!(virt_out(idx) || req_out(idx).hyperinst)) -> noS2xlate,\n\
      548:       (csr.vsatp.mode =/= 0.U && csr.hgatp.mode =/= 0.U) -> allStage,\n\
      549:       (csr.vsatp.mode === 0.U) -> onlyStage2,\n550:       (csr.hgatp.mode
      === 0.U) -> onlyStage1\n551:     ))\n552:     val miss_req_s2xlate_reg = RegEnable(miss_req_s2xlate,
      io.ptw.req(idx).fire)\n553:     val hit = io.ptw.resp.bits.hit(miss_req_vpn,
      csr.satp.asid, csr.vsatp.asid, csr.hgatp.vmid, allType = true, ignoreAsid =
      false) && io.ptw.resp.valid && miss_req_s2xlate_reg === io.ptw.resp.bits.s2xlate\n\
      554: \n555:     val new_coming_valid = WireInit(false.B)\n556:     new_coming_valid
      := req_in(idx).fire && !req_in(idx).bits.kill && !flush_pipe(idx)\n557:    \
      \ val new_coming = GatedValidRegNext(new_coming_valid)\n558:     val miss_wire
      = new_coming && missVec(idx)\n559:     val miss_v = ValidHoldBypass(miss_wire,
      resp(idx).fire, flush_pipe(idx))\n560:     val miss_req_v = ValidHoldBypass(miss_wire
      || (miss_v && flush_mmu && !mmu_flush_pipe),\n561:       io.ptw.req(idx).fire
      || resp(idx).fire, flush_pipe(idx))\n562: \n563:     // when ptw resp, check
      if hit, reset miss_v, resp to lsu/ifu\n564:     resp(idx).valid := req_out_v(idx)
      && !(miss_v && portTranslateEnable(idx))\n565:     when (io.ptw.resp.fire &&
      hit && req_out_v(idx) && portTranslateEnable(idx)) {\n566:       val stage1
      = io.ptw.resp.bits.s1\n567:       val stage2 = io.ptw.resp.bits.s2\n568:   \
      \    val s2xlate = io.ptw.resp.bits.s2xlate\n569:       resp(idx).valid := true.B\n\
      570:       resp(idx).bits.miss := false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 588-598
    context: "588:       val s1_gpaddr = Cat(stage1.genGVPN(vpn), s1_gpaddr_offset)\n\
      589: \n590:       for (d <- 0 until nRespDups) {\n591:         resp(idx).bits.paddr(d)
      := Mux(s2xlate === onlyStage2 || s2xlate === allStage, s2_paddr, s1_paddr)\n\
      592:         resp(idx).bits.gpaddr(d) := Mux(s2xlate === onlyStage2, req_out(idx).vaddr,
      s1_gpaddr)\n593:         pbmt_check(idx, d, io.ptw.resp.bits.s1.entry.pbmt,
      io.ptw.resp.bits.s2.entry.pbmt, s2xlate)\n594:         perm_check(stage1, req_out(idx).cmd,
      idx, d, stage2, req_out(idx).hlvx, s2xlate)\n595:       }\n596:       pmp_check(resp(idx).bits.paddr(0),
      req_out(idx).size, req_out(idx).cmd, false.B, idx)\n597: \n598:       // NOTE:
      the unfiltered req would be handled by Repeater"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 595-610
    context: "595:       }\n596:       pmp_check(resp(idx).bits.paddr(0), req_out(idx).size,
      req_out(idx).cmd, false.B, idx)\n597: \n598:       // NOTE: the unfiltered req
      would be handled by Repeater\n599:     }\n600:     assert(RegNext(!resp(idx).valid
      || resp(idx).ready, true.B), \"when tlb resp valid, ready should be true, must\"\
      )\n601:     assert(RegNext(req_out_v(idx) || !(miss_v || miss_req_v), true.B),
      \"when not req_out_v, should not set miss_v/miss_req_v\")\n602: \n603:     val
      ptw_req = io.ptw.req(idx)\n604:     ptw_req.valid := miss_req_v\n605:     ptw_req.bits.vpn
      := miss_req_vpn\n606:     ptw_req.bits.s2xlate := miss_req_s2xlate\n607:   \
      \  ptw_req.bits.getGpa := req_need_gpa && hitVec(idx)\n608:     ptw_req.bits.memidx
      := miss_req_memidx\n609: \n610:     io.tlbreplay(idx) := false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 611-624
    context: "611: \n612:     // NOTE: when flush pipe, tlb should abandon last req\n\
      613:     // however, some outside modules like icache, dont care flushPipe,
      and still waiting for tlb resp\n614:     // just resp valid and raise page fault
      to go through. The pipe(ifu) will abandon it.\n615:     if (!q.outsideRecvFlush)
      {\n616:       when (req_out_v(idx) && flush_pipe(idx) && portTranslateEnable(idx))
      {\n617:         resp(idx).valid := true.B\n618:         for (d <- 0 until nRespDups)
      {\n619:           resp(idx).bits.pbmt(d) := 0.U\n620:           resp(idx).bits.excp(d).pf.ld
      := true.B // sfence happened, pf for not to use this addr\n621:           resp(idx).bits.excp(d).pf.st
      := true.B\n622:           resp(idx).bits.excp(d).pf.instr := true.B\n623:  \
      \       }\n624:       }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 632-664
    context: "632:     val hasS2xlate = s2xlate =/= noS2xlate\n633:     val onlyS2
      = s2xlate === onlyStage2\n634:     val onlyS1 = s2xlate === onlyStage1\n635:\
      \     val s2xlate_hit = s2xlate === ptw.resp.bits.s2xlate\n636:     val resp_hit
      = ptw.resp.bits.hit(vpn, csr.satp.asid, csr.vsatp.asid, csr.hgatp.vmid, allType
      = true)\n637:     val p_hit = GatedValidRegNext(resp_hit && io.ptw.resp.fire
      && s2xlate_hit)\n638:     val ppn_s1 = ptw.resp.bits.s1.genPPN(vpn)(ppnLen -
      1, 0)\n639:     val gvpn = Mux(onlyS2, vpn, ppn_s1)\n640:     val ppn_s2 = ptw.resp.bits.s2.genPPNS2(gvpn)(ppnLen
      - 1, 0)\n641:     val p_ppn = RegEnable(Mux(s2xlate === onlyStage2 || s2xlate
      === allStage, ppn_s2, ppn_s1), io.ptw.resp.fire)\n642:     val p_pbmt = RegEnable(ptw.resp.bits.s1.entry.pbmt,io.ptw.resp.fire)\n\
      643:     val p_perm = RegEnable(ptwresp_to_tlbperm(ptw.resp.bits.s1), io.ptw.resp.fire)\n\
      644:     val p_gvpn = RegEnable(Mux(onlyS2, ptw.resp.bits.s2.entry.tag, ptw.resp.bits.s1.genGVPN(vpn)),
      io.ptw.resp.fire)\n645:     val p_g_pbmt = RegEnable(ptw.resp.bits.s2.entry.pbmt,io.ptw.resp.fire)\n\
      646:     val p_g_perm = RegEnable(hptwresp_to_tlbperm(ptw.resp.bits.s2), io.ptw.resp.fire)\n\
      647:     val p_s2xlate = RegEnable(ptw.resp.bits.s2xlate, io.ptw.resp.fire)\n\
      648:     val p_s1_level = RegEnable(ptw.resp.bits.s1.entry.level.get, io.ptw.resp.fire)\n\
      649:     val p_s1_isLeaf = RegEnable(ptw.resp.bits.s1.isLeaf(), io.ptw.resp.fire)\n\
      650:     val p_s1_isFakePte = RegEnable(ptw.resp.bits.s1.isFakePte(), io.ptw.resp.fire)\n\
      651:     (p_hit, p_ppn, p_pbmt, p_perm, p_gvpn, p_g_pbmt, p_g_perm, p_s2xlate,
      p_s1_level, p_s1_isLeaf, p_s1_isFakePte)\n652:   }\n653: \n654:   // perf event\n\
      655:   val result_ok = req_in.map(a => GatedValidRegNext(a.fire))\n656:   val
      perfEvents =\n657:     Seq(\n658:       (\"access\", PopCount((0 until Width).map{i
      => if (Block(i)) io.requestor(i).req.fire else portTranslateEnable(i) && result_ok(i)
      })),\n659:       (\"miss  \", PopCount((0 until Width).map{i => if (Block(i))
      portTranslateEnable(i) && result_ok(i) && missVec(i) else ptw.req(i).fire })),\n\
      660:     )\n661:   generatePerfEvent()\n662: \n663:   // perf log\n664:   for
      (i <- 0 until Width) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 662-694
    context: "662: \n663:   // perf log\n664:   for (i <- 0 until Width) {\n665: \
      \    if (Block(i)) {\n666:       XSPerfAccumulate(s\"access${i}\",result_ok(i)
      && portTranslateEnable(i))\n667:       XSPerfAccumulate(s\"miss${i}\", result_ok(i)
      && missVec(i))\n668:     } else {\n669:       XSPerfAccumulate(\"first_access\"\
      \ + Integer.toString(i, 10), result_ok(i) && portTranslateEnable(i) && RegEnable(req(i).bits.debug.isFirstIssue,
      req(i).valid))\n670:       XSPerfAccumulate(\"access\" + Integer.toString(i,
      10), result_ok(i) && portTranslateEnable(i))\n671:       XSPerfAccumulate(\"\
      first_miss\" + Integer.toString(i, 10), result_ok(i) && portTranslateEnable(i)
      && missVec(i) && RegEnable(req(i).bits.debug.isFirstIssue, req(i).valid))\n\
      672:       XSPerfAccumulate(\"miss\" + Integer.toString(i, 10), result_ok(i)
      && portTranslateEnable(i) && missVec(i))\n673:     }\n674:   }\n675:   XSPerfAccumulate(\"\
      ptw_resp_count\", ptw.resp.fire)\n676:   XSPerfAccumulate(\"ptw_resp_pf_count\"\
      , ptw.resp.fire && ptw.resp.bits.s1.pf)\n677: \n678:   // Log\n679:   for(i
      <- 0 until Width) {\n680:     XSDebug(req(i).valid, p\"req(${i.U}): (${req(i).valid}
      ${req(i).ready}) ${req(i).bits}\\n\")\n681:     XSDebug(resp(i).valid, p\"resp(${i.U}):
      (${resp(i).valid} ${resp(i).ready}) ${resp(i).bits}\\n\")\n682:   }\n683: \n\
      684:   XSDebug(io.sfence.valid, p\"Sfence: ${io.sfence}\\n\")\n685:   XSDebug(ParallelOR(req_out_v)
      || ptw.resp.valid, p\"vmEnable:${vmEnable} hit:${Binary(VecInit(hitVec).asUInt)}
      miss:${Binary(VecInit(missVec).asUInt)}\\n\")\n686:   for (i <- ptw.req.indices)
      {\n687:     XSDebug(ptw.req(i).fire, p\"L2TLB req:${ptw.req(i).bits}\\n\")\n\
      688:   }\n689:   XSDebug(ptw.resp.valid, p\"L2TLB resp:${ptw.resp.bits} (v:${ptw.resp.valid}r:${ptw.resp.ready})
      \\n\")\n690: \n691:   println(s\"${q.name}: page: ${q.NWays} ${q.Associative}
      ${q.Replacer.get}\")\n692: \n693:   if (env.EnableDifftest) {\n694:     for
      (i <- 0 until Width) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 695-706
    context: "695:       val pf = io.requestor(i).resp.bits.excp(0).pf.instr || io.requestor(i).resp.bits.excp(0).pf.st
      || io.requestor(i).resp.bits.excp(0).pf.ld\n696:       val gpf = io.requestor(i).resp.bits.excp(0).gpf.instr
      || io.requestor(i).resp.bits.excp(0).gpf.st || io.requestor(i).resp.bits.excp(0).gpf.ld\n\
      697:       val af = io.requestor(i).resp.bits.excp(0).af.instr || io.requestor(i).resp.bits.excp(0).af.st
      || io.requestor(i).resp.bits.excp(0).af.ld\n698:       val difftest = DifftestModule(new
      DiffL1TLBEvent)\n699:       difftest.coreid := io.hartId\n700:       difftest.valid
      := RegNext(io.requestor(i).req.fire) && !io.requestor(i).req_kill && io.requestor(i).resp.fire
      && !io.requestor(i).resp.bits.miss && !pf && !af && !gpf && portTranslateEnable(i)\n\
      701:       if (!Seq(\"itlb\", \"ldtlb\", \"sttlb\").contains(q.name)) {\n702:\
      \         difftest.valid := false.B\n703:       }\n704:       difftest.index
      := TLBDiffId(p(XSCoreParamsKey).HartId).U\n705:       difftest.vpn := RegEnable(get_pn(req_in(i).bits.vaddr),
      req_in(i).valid)\n706:       difftest.ppn := get_pn(io.requestor(i).resp.bits.paddr(0))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 720-734
    context: "720:   }\n721: }\n722: \n723: object TLBDiffId {\n724:   var i: Int
      = 0\n725:   var lastHartId: Int = -1\n726:   def apply(hartId: Int): Int = {\n\
      727:     if (lastHartId != hartId) {\n728:       i = 0\n729:       lastHartId
      = hartId\n730:     }\n731:     i += 1\n732:     i - 1\n733:   }\n734: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 53-70
    context: "53:   } else {\n54:     val arb = Module(new RRArbiterInit(io.tlb.req(0).bits.cloneType,
      Width))\n55:     arb.io.in <> io.tlb.req\n56:     arb.io.out\n57:   }\n58: \
      \  val (tlb, ptw, flush) = (io.tlb, io.ptw, DelayN(io.sfence.valid || io.csr.satp.changed
      || io.csr.vsatp.changed || io.csr.hgatp.changed || io.csr.priv.virt_changed,
      FenceDelay))\n59:   val req = RegEnable(req_in.bits, req_in.fire)\n60:   val
      resp = RegEnable(ptw.resp.bits, ptw.resp.fire)\n61:   val haveOne = BoolStopWatch(req_in.fire,
      tlb.resp.fire || flush)\n62:   val sent = BoolStopWatch(ptw.req(0).fire, req_in.fire
      || flush)\n63:   val recv = BoolStopWatch(ptw.resp.fire && haveOne, req_in.fire
      || flush)\n64: \n65:   req_in.ready := !haveOne\n66:   ptw.req(0).valid := haveOne
      && !sent\n67:   ptw.req(0).bits := req\n68: \n69:   tlb.resp.bits := resp\n\
      70:   tlb.resp.valid := haveOne && recv"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 66-88
    context: "66:   ptw.req(0).valid := haveOne && !sent\n67:   ptw.req(0).bits :=
      req\n68: \n69:   tlb.resp.bits := resp\n70:   tlb.resp.valid := haveOne && recv\n\
      71:   ptw.resp.ready := !recv\n72: \n73:   XSPerfAccumulate(\"req_count\", ptw.req(0).fire)\n\
      74:   XSPerfAccumulate(\"tlb_req_cycle\", BoolStopWatch(req_in.fire, tlb.resp.fire
      || flush))\n75:   XSPerfAccumulate(\"ptw_req_cycle\", BoolStopWatch(ptw.req(0).fire,
      ptw.resp.fire || flush))\n76: \n77:   XSDebug(haveOne, p\"haveOne:${haveOne}
      sent:${sent} recv:${recv} sfence:${flush} req:${req} resp:${resp}\")\n78:  \
      \ XSDebug(req_in.valid || io.tlb.resp.valid, p\"tlb: ${tlb}\\n\")\n79:   XSDebug(io.ptw.req(0).valid
      || io.ptw.resp.valid, p\"ptw: ${ptw}\\n\")\n80:   assert(!RegNext(recv && io.ptw.resp.valid,
      init = false.B), \"re-receive ptw.resp\")\n81:   XSError(io.ptw.req(0).valid
      && io.ptw.resp.valid && !flush, \"ptw repeater recv resp when sending\")\n82:\
      \   XSError(io.ptw.resp.valid && (req.vpn =/= io.ptw.resp.bits.s1.entry.tag),
      \"ptw repeater recv resp with wrong tag\")\n83:   XSError(io.ptw.resp.valid
      && !io.ptw.resp.ready, \"ptw repeater's ptw resp back, but not ready\")\n84:
      }\n85: \n86: /* dtlb\n87:  *\n88:  */"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 85-95
    context: "85: \n86: /* dtlb\n87:  *\n88:  */\n89: \n90: class PTWRepeaterNB(Width:
      Int = 1, passReady: Boolean = false, FenceDelay: Int)(implicit p: Parameters)
      extends XSModule with HasPtwConst {\n91:   val io = IO(new PTWReapterIO(Width))\n\
      92: \n93:   val req_in = if (Width == 1) {\n94:     io.tlb.req(0)\n95:   } else
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 95-105
    context: "95:   } else {\n96:     val arb = Module(new RRArbiterInit(io.tlb.req(0).bits.cloneType,
      Width))\n97:     arb.io.in <> io.tlb.req\n98:     arb.io.out\n99:   }\n100:\
      \   val (tlb, ptw, flush) = (io.tlb, io.ptw, DelayN(io.sfence.valid || io.csr.satp.changed
      || io.csr.vsatp.changed || io.csr.hgatp.changed || io.csr.priv.virt_changed,
      FenceDelay))\n101:   /* sent: tlb -> repeater -> ptw\n102:    * recv: ptw ->
      repeater -> tlb\n103:    * different from PTWRepeater\n104:    */\n105: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 102-129
    context: "102:    * recv: ptw -> repeater -> tlb\n103:    * different from PTWRepeater\n\
      104:    */\n105: \n106:   // tlb -> repeater -> ptw\n107:   val req = RegEnable(req_in.bits,
      req_in.fire)\n108:   val sent = BoolStopWatch(req_in.fire, ptw.req(0).fire ||
      flush)\n109:   req_in.ready := !sent || { if (passReady) ptw.req(0).ready else
      false.B }\n110:   ptw.req(0).valid := sent\n111:   ptw.req(0).bits := req\n\
      112: \n113:   // ptw -> repeater -> tlb\n114:   val resp = RegEnable(ptw.resp.bits,
      ptw.resp.fire)\n115:   val recv = BoolStopWatch(ptw.resp.fire, tlb.resp.fire
      || flush)\n116:   ptw.resp.ready := !recv || { if (passReady) tlb.resp.ready
      else false.B }\n117:   tlb.resp.valid := recv\n118:   tlb.resp.bits := resp\n\
      119: \n120:   XSPerfAccumulate(\"req\", req_in.fire)\n121:   XSPerfAccumulate(\"\
      resp\", tlb.resp.fire)\n122:   if (!passReady) {\n123:     XSPerfAccumulate(\"\
      req_blank\", req_in.valid && sent && ptw.req(0).ready)\n124:     XSPerfAccumulate(\"\
      resp_blank\", ptw.resp.valid && recv && tlb.resp.ready)\n125:     XSPerfAccumulate(\"\
      req_blank_ignore_ready\", req_in.valid && sent)\n126:     XSPerfAccumulate(\"\
      resp_blank_ignore_ready\", ptw.resp.valid && recv)\n127:   }\n128:   XSDebug(req_in.valid
      || io.tlb.resp.valid, p\"tlb: ${tlb}\\n\")\n129:   XSDebug(io.ptw.req(0).valid
      || io.ptw.resp.valid, p\"ptw: ${ptw}\\n\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 152-162
    context: "152:   }\n153: \n154: }\n155: \n156: class PTWFilterEntryIO(Width: Int,
      hasHint: Boolean = false)(implicit p: Parameters) extends PTWFilterIO(Width,
      hasHint){\n157:   val flush = Input(Bool())\n158:   val refill = Output(Bool())\n\
      159:   val getGpa = Output(Bool())\n160:   val memidx = Output(new MemBlockidxBundle)\n\
      161: }\n162: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 193-206
    context: "193:   val entryMatchIndexVec = WireInit(VecInit(Seq.fill(Width)(0.U(log2Up(Size).W))))\n\
      194:   val ptwResp_EntryMatchVec = vpn.zip(v).zip(s2xlate).map{ case ((pi, vi),
      s2xlatei) => vi && s2xlatei === io.ptw.resp.bits.s2xlate && io.ptw.resp.bits.hit(pi,
      io.csr.satp.asid, io.csr.vsatp.asid, io.csr.hgatp.vmid, allType = true)}\n195:\
      \   val ptwResp_EntryMatchFirst = firstValidIndex(ptwResp_EntryMatchVec, true.B)\n\
      196:   val ptwResp_ReqMatchVec = io.tlb.req.map(a => io.ptw.resp.valid && a.bits.s2xlate
      === io.ptw.resp.bits.s2xlate && io.ptw.resp.bits.hit(a.bits.vpn, io.csr.satp.asid,
      io.csr.vsatp.asid, io.csr.hgatp.vmid, allType = true))\n197: \n198:   io.refill
      := Cat(ptwResp_EntryMatchVec).orR && io.ptw.resp.fire\n199:   io.ptw.resp.ready
      := true.B\n200:   // DontCare\n201:   io.tlb.req.map(_.ready := true.B)\n202:\
      \   io.tlb.resp.valid := false.B\n203:   io.tlb.resp.bits.data := 0.U.asTypeOf(new
      PtwRespS2withMemIdx)\n204:   io.tlb.resp.bits.vector := 0.U.asTypeOf(Vec(Width,
      Bool()))\n205:   io.tlb.resp.bits.getGpa := 0.U.asTypeOf(Vec(Width, Bool()))\n\
      206:   io.memidx := 0.U.asTypeOf(new MemBlockidxBundle)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 272-286
    context: "272:   for (i <- 0 until Size) {\n273:     io.ptw.req(0).valid := canissue\n\
      274:     io.ptw.req(0).bits.vpn := vpn(issueindex)\n275:     io.ptw.req(0).bits.s2xlate
      := s2xlate(issueindex)\n276:   }\n277:   when (io.ptw.req(0).fire) {\n278: \
      \    sent(issueindex) := true.B\n279:   }\n280: \n281:   when (io.ptw.resp.fire)
      {\n282:     v.zip(ptwResp_EntryMatchVec).map{ case (vi, mi) => when (mi) { vi
      := false.B }}\n283:     io.memidx := memidx(ptwResp_EntryMatchFirst)\n284: \
      \    io.getGpa := getGpa(ptwResp_EntryMatchFirst)\n285:   }\n286: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 282-292
    context: "282:     v.zip(ptwResp_EntryMatchVec).map{ case (vi, mi) => when (mi)
      { vi := false.B }}\n283:     io.memidx := memidx(ptwResp_EntryMatchFirst)\n\
      284:     io.getGpa := getGpa(ptwResp_EntryMatchFirst)\n285:   }\n286: \n287:\
      \   when (io.flush) {\n288:     v.map(_ := false.B)\n289:   }\n290: \n291: \
      \  if (hasHint) {\n292:     val hintIO = io.hint.getOrElse(new TlbHintIO)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 306-325
    context: "306: \n307:   // Perf Counter\n308:   val counter = PopCount(v)\n309:\
      \   val inflight_counter = RegInit(0.U(log2Up(Size).W))\n310:   val inflight_full
      = inflight_counter === Size.U\n311:   when (io.ptw.req(0).fire =/= io.ptw.resp.fire)
      {\n312:     inflight_counter := Mux(io.ptw.req(0).fire, inflight_counter + 1.U,
      inflight_counter - 1.U)\n313:   }\n314: \n315:   assert(inflight_counter <=
      Size.U, \"inflight should be no more than Size\")\n316:   when (counter ===
      0.U) {\n317:     assert(!io.ptw.req(0).fire, \"when counter is 0, should not
      req\")\n318:   }\n319: \n320:   when (io.flush) {\n321:     inflight_counter
      := 0.U\n322:   }\n323: \n324:   XSPerfAccumulate(\"tlb_req_count\", PopCount(Cat(io.tlb.req.map(_.valid))))\n\
      325:   XSPerfAccumulate(\"tlb_req_count_filtered\", PopCount(enqvalid))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 321-334
    context: "321:     inflight_counter := 0.U\n322:   }\n323: \n324:   XSPerfAccumulate(\"\
      tlb_req_count\", PopCount(Cat(io.tlb.req.map(_.valid))))\n325:   XSPerfAccumulate(\"\
      tlb_req_count_filtered\", PopCount(enqvalid))\n326:   XSPerfAccumulate(\"ptw_req_count\"\
      , io.ptw.req(0).fire)\n327:   XSPerfAccumulate(\"ptw_req_cycle\", inflight_counter)\n\
      328:   XSPerfAccumulate(\"tlb_resp_count\", io.tlb.resp.fire)\n329:   XSPerfAccumulate(\"\
      ptw_resp_count\", io.ptw.resp.fire)\n330:   XSPerfAccumulate(\"inflight_cycle\"\
      , Cat(sent).orR)\n331: \n332:   for (i <- 0 until Size + 1) {\n333:     XSPerfAccumulate(s\"\
      counter${i}\", counter === i.U)\n334:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 367-388
    context: "367: \n368:   load_filter.map(_.tlb.req := io.tlb.req.take(LdExuCnt
      + 1))\n369:   store_filter.map(_.tlb.req := io.tlb.req.drop(LdExuCnt + 1).take(StaCnt))\n\
      370:   prefetch_filter.map(_.tlb.req := io.tlb.req.drop(LdExuCnt + 1 + StaCnt))\n\
      371: \n372:   val flush = DelayN(io.sfence.valid || io.csr.satp.changed || io.csr.vsatp.changed
      || io.csr.hgatp.changed || io.csr.priv.virt_changed, FenceDelay)\n373:   val
      ptwResp = RegEnable(io.ptw.resp.bits, io.ptw.resp.fire)\n374:   val ptwResp_valid
      = Cat(filter.map(_.refill)).orR\n375:   filter.map(_.tlb.resp.ready := true.B)\n\
      376:   filter.map(_.ptw.resp.valid := GatedValidRegNext(io.ptw.resp.fire, init
      = false.B))\n377:   filter.map(_.ptw.resp.bits := ptwResp)\n378:   filter.map(_.flush
      := flush)\n379:   filter.map(_.sfence := io.sfence)\n380:   filter.map(_.csr
      := io.csr)\n381:   filter.map(_.debugTopDown.robHeadVaddr := io.debugTopDown.robHeadVaddr)\n\
      382: \n383:   io.tlb.req.map(_.ready := true.B)\n384:   io.tlb.resp.valid :=
      ptwResp_valid\n385:   io.tlb.resp.bits.data.s2xlate := ptwResp.s2xlate\n386:\
      \   io.tlb.resp.bits.data.getGpa := DontCare // not used\n387:   io.tlb.resp.bits.data.s1
      := ptwResp.s1\n388:   io.tlb.resp.bits.data.s2 := ptwResp.s2"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 425-441
    context: "425:   val ptw_arb = Module(new RRArbiterInit(new PtwReq, 3))\n426:\
      \   for (i <- 0 until 3) {\n427:     ptw_arb.io.in(i).valid := filter(i).ptw.req(0).valid\n\
      428:     ptw_arb.io.in(i).bits.vpn := filter(i).ptw.req(0).bits.vpn\n429:  \
      \   ptw_arb.io.in(i).bits.s2xlate := filter(i).ptw.req(0).bits.s2xlate\n430:\
      \     filter(i).ptw.req(0).ready := ptw_arb.io.in(i).ready\n431:   }\n432: \
      \  ptw_arb.io.out.ready := io.ptw.req(0).ready\n433:   io.ptw.req(0).valid :=
      ptw_arb.io.out.valid\n434:   io.ptw.req(0).bits.vpn := ptw_arb.io.out.bits.vpn\n\
      435:   io.ptw.req(0).bits.s2xlate := ptw_arb.io.out.bits.s2xlate\n436:   io.ptw.resp.ready
      := true.B\n437: \n438:   io.rob_head_miss_in_tlb := Cat(filter.map(_.rob_head_miss_in_tlb)).orR\n\
      439: }\n440: \n441: class PTWFilter(Width: Int, Size: Int, FenceDelay: Int)(implicit
      p: Parameters) extends XSModule with HasPtwConst {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 453-463
    context: "453:   val issPtr = RegInit(0.U(log2Up(Size).W)) // Iss to Ptw\n454:\
      \   val deqPtr = RegInit(0.U(log2Up(Size).W)) // Deq\n455:   val mayFullDeq
      = RegInit(false.B)\n456:   val mayFullIss = RegInit(false.B)\n457:   val counter
      = RegInit(0.U(log2Up(Size+1).W))\n458:   val flush = DelayN(io.sfence.valid
      || io.csr.satp.changed || io.csr.vsatp.changed || io.csr.hgatp.changed || io.csr.priv.virt_changed,
      FenceDelay)\n459:   val tlb_req = WireInit(io.tlb.req) // NOTE: tlb_req is not
      io.tlb.req, see below codes, just use cloneType\n460:   tlb_req.suggestName(\"\
      tlb_req\")\n461: \n462:   val inflight_counter = RegInit(0.U(log2Up(Size + 1).W))\n\
      463:   val inflight_full = inflight_counter === Size.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 464-484
    context: "464: \n465:   def ptwResp_hit(vpn: UInt, s2xlate: UInt, resp: PtwRespS2):
      Bool = {\n466:     s2xlate === resp.s2xlate && resp.hit(vpn, io.csr.satp.asid,
      io.csr.vsatp.asid, io.csr.hgatp.vmid, allType = true)\n467:   }\n468: \n469:\
      \   when (io.ptw.req(0).fire =/= io.ptw.resp.fire) {\n470:     inflight_counter
      := Mux(io.ptw.req(0).fire, inflight_counter + 1.U, inflight_counter - 1.U)\n\
      471:   }\n472: \n473:   val canEnqueue = Wire(Bool()) // NOTE: actually enqueue\n\
      474:   val ptwResp = RegEnable(io.ptw.resp.bits, io.ptw.resp.fire)\n475:   val
      ptwResp_OldMatchVec = vpn.zip(v).zip(s2xlate).map { case (((vpn, v), s2xlate))
      =>{\n476:     v && ptwResp_hit(vpn, s2xlate, io.ptw.resp.bits)\n477:   }\n478:\
      \   }\n479:   val ptwResp_valid = GatedValidRegNext(io.ptw.resp.fire && Cat(ptwResp_OldMatchVec).orR,
      init = false.B)\n480:   // May send repeated requests to L2 tlb with same vpn(26,
      3) when sector tlb\n481:   val oldMatchVec_early = io.tlb.req.map(a => vpn.zip(v).zip(s2xlate).map{
      case ((pi, vi), s2xlate) => vi && pi === a.bits.vpn && s2xlate === a.bits.s2xlate
      })\n482:   val lastReqMatchVec_early = io.tlb.req.map(a => tlb_req.map{ b =>
      b.valid && b.bits.vpn === a.bits.vpn && canEnqueue && b.bits.s2xlate === a.bits.s2xlate})\n\
      483:   val newMatchVec_early = io.tlb.req.map(a => io.tlb.req.map(b => a.bits.vpn
      === b.bits.vpn && a.bits.s2xlate === b.bits.s2xlate))\n484: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 480-490
    context: "480:   // May send repeated requests to L2 tlb with same vpn(26, 3)
      when sector tlb\n481:   val oldMatchVec_early = io.tlb.req.map(a => vpn.zip(v).zip(s2xlate).map{
      case ((pi, vi), s2xlate) => vi && pi === a.bits.vpn && s2xlate === a.bits.s2xlate
      })\n482:   val lastReqMatchVec_early = io.tlb.req.map(a => tlb_req.map{ b =>
      b.valid && b.bits.vpn === a.bits.vpn && canEnqueue && b.bits.s2xlate === a.bits.s2xlate})\n\
      483:   val newMatchVec_early = io.tlb.req.map(a => io.tlb.req.map(b => a.bits.vpn
      === b.bits.vpn && a.bits.s2xlate === b.bits.s2xlate))\n484: \n485:   (0 until
      Width) foreach { i =>\n486:     tlb_req(i).valid := GatedValidRegNext(io.tlb.req(i).valid
      &&\n487:       !(ptwResp_valid && ptwResp_hit(io.tlb.req(i).bits.vpn, io.tlb.req(i).bits.s2xlate,
      ptwResp)) &&\n488:       !Cat(lastReqMatchVec_early(i)).orR,\n489:       init
      = false.B)\n490:     tlb_req(i).bits := RegEnable(io.tlb.req(i).bits, io.tlb.req(i).valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 500-511
    context: "500: \n501:   val oldMatchVec2 = (0 until Width).map(i => oldMatchVec_early(i).map(GatedValidRegNext(_)).map(_
      & tlb_req(i).valid))\n502:   val update_ports = v.indices.map(i => oldMatchVec2.map(j
      => j(i)))\n503:   val ports_init = (0 until Width).map(i => (1 << i).U(Width.W))\n\
      504:   val filter_ports = (0 until Width).map(i => ParallelMux(newMatchVec(i).zip(ports_init).drop(i)))\n\
      505:   val resp_vector = RegEnable(ParallelMux(ptwResp_OldMatchVec zip ports),
      io.ptw.resp.fire)\n506:   val resp_getGpa = RegEnable(ParallelMux(ptwResp_OldMatchVec
      zip getGpa), io.ptw.resp.fire)\n507: \n508:   def canMerge(index: Int) : Bool
      = {\n509:     ptwResp_newMatchVec(index) || oldMatchVec(index) ||\n510:    \
      \ Cat(newMatchVec(index).take(index)).orR\n511:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 533-543
    context: "533:   canEnqueue := counter +& enqNum <= Size.U\n534: \n535:   // the
      req may recv false ready, but actually received. Filter and TLB will handle
      it.\n536:   val enqNum_fake = PopCount(io.tlb.req.map(_.valid))\n537:   val
      canEnqueue_fake = counter +& enqNum_fake <= Size.U\n538:   io.tlb.req.map(_.ready
      := canEnqueue_fake) // NOTE: just drop un-fire reqs\n539: \n540:   // tlb req
      flushed by ptw resp: last ptw resp && current ptw resp\n541:   // the flushed
      tlb req will fakely enq, with a false valid\n542:   val tlb_req_flushed = reqs.map(a
      => io.ptw.resp.valid && ptwResp_hit(a.bits.vpn, a.bits.s2xlate, io.ptw.resp.bits))\n\
      543: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 550-564
    context: "550:   io.tlb.resp.bits.data.getGpa := RegNext(PriorityMux(ptwResp_OldMatchVec,
      getGpa))\n551:   io.tlb.resp.bits.getGpa := DontCare\n552: \n553:   val issue_valid
      = v(issPtr) && !isEmptyIss && !inflight_full\n554:   val issue_filtered = ptwResp_valid
      && ptwResp_hit(io.ptw.req(0).bits.vpn, io.ptw.req(0).bits.s2xlate, ptwResp)\n\
      555:   val issue_fire_fake = issue_valid && io.ptw.req(0).ready\n556:   io.ptw.req(0).valid
      := issue_valid && !issue_filtered\n557:   io.ptw.req(0).bits.vpn := vpn(issPtr)\n\
      558:   io.ptw.req(0).bits.s2xlate := s2xlate(issPtr)\n559:   io.ptw.resp.ready
      := true.B\n560: \n561:   reqs.zipWithIndex.map{\n562:     case (req, i) =>\n\
      563:       when (req.valid && canEnqueue) {\n564:         v(enqPtrVec(i)) :=
      !tlb_req_flushed(i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 595-605
    context: "595:   }\n596:   when (do_enq =/= do_iss) {\n597:     mayFullIss :=
      do_enq\n598:   }\n599: \n600:   when (io.ptw.resp.fire) {\n601:     v.zip(ptwResp_OldMatchVec).map{
      case (vi, mi) => when (mi) { vi := false.B }}\n602:   }\n603: \n604:   counter
      := counter - do_deq + Mux(do_enq, enqNum, 0.U)\n605:   assert(counter <= Size.U,
      \"counter should be no more than Size\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 603-613
    context: "603: \n604:   counter := counter - do_deq + Mux(do_enq, enqNum, 0.U)\n\
      605:   assert(counter <= Size.U, \"counter should be no more than Size\")\n\
      606:   assert(inflight_counter <= Size.U, \"inflight should be no more than
      Size\")\n607:   when (counter === 0.U) {\n608:     assert(!io.ptw.req(0).fire,
      \"when counter is 0, should not req\")\n609:     assert(isEmptyDeq && isEmptyIss,
      \"when counter is 0, should be empty\")\n610:   }\n611:   when (counter ===
      Size.U) {\n612:     assert(mayFullDeq, \"when counter is Size, should be full\"\
      )\n613:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 610-620
    context: "610:   }\n611:   when (counter === Size.U) {\n612:     assert(mayFullDeq,
      \"when counter is Size, should be full\")\n613:   }\n614: \n615:   when (flush)
      {\n616:     v.map(_ := false.B)\n617:     deqPtr := 0.U\n618:     enqPtr :=
      0.U\n619:     issPtr := 0.U\n620:     ptwResp_valid := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 630-643
    context: "630:   }}).asUInt.orR\n631: \n632:   // perf\n633:   XSPerfAccumulate(\"\
      tlb_req_count\", PopCount(Cat(io.tlb.req.map(_.valid))))\n634:   XSPerfAccumulate(\"\
      tlb_req_count_filtered\", Mux(do_enq, accumEnqNum(Width - 1), 0.U))\n635:  \
      \ XSPerfAccumulate(\"ptw_req_count\", io.ptw.req(0).fire)\n636:   XSPerfAccumulate(\"\
      ptw_req_cycle\", inflight_counter)\n637:   XSPerfAccumulate(\"tlb_resp_count\"\
      , io.tlb.resp.fire)\n638:   XSPerfAccumulate(\"ptw_resp_count\", io.ptw.resp.fire)\n\
      639:   XSPerfAccumulate(\"inflight_cycle\", !isEmptyDeq)\n640:   for (i <- 0
      until Size + 1) {\n641:     XSPerfAccumulate(s\"counter${i}\", counter === i.U)\n\
      642:   }\n643: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 666-676
    context: "666:     repeater\n667:   }\n668: }\n669: \n670: object PTWRepeaterNB
      {\n671:   def apply(passReady: Boolean, fenceDelay: Int,\n672:     tlb: TlbPtwIO,\n\
      673:     sfence: SfenceBundle,\n674:     csr: TlbCsrBundle\n675:   )(implicit
      p: Parameters) = {\n676:     val width = tlb.req.size"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 672-687
    context: "672:     tlb: TlbPtwIO,\n673:     sfence: SfenceBundle,\n674:     csr:
      TlbCsrBundle\n675:   )(implicit p: Parameters) = {\n676:     val width = tlb.req.size\n\
      677:     val repeater = Module(new PTWRepeaterNB(width, passReady,fenceDelay))\n\
      678:     repeater.io.apply(tlb, sfence, csr)\n679:     repeater\n680:   }\n\
      681: \n682:   def apply(passReady: Boolean, fenceDelay: Int,\n683:     tlb:
      TlbPtwIO,\n684:     ptw: TlbPtwIO,\n685:     sfence: SfenceBundle,\n686:   \
      \  csr: TlbCsrBundle\n687:   )(implicit p: Parameters) = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/Repeater.scala
    lines: 684-694
    context: "684:     ptw: TlbPtwIO,\n685:     sfence: SfenceBundle,\n686:     csr:
      TlbCsrBundle\n687:   )(implicit p: Parameters) = {\n688:     val width = tlb.req.size\n\
      689:     val repeater = Module(new PTWRepeaterNB(width, passReady, fenceDelay))\n\
      690:     repeater.io.apply(tlb, ptw, sfence, csr)\n691:     repeater\n692: \
      \  }\n693: }\n694: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 28-44
    context: "28: \n29: // For Direct-map TLBs, we do not use it now\n30: class BankedAsyncDataModuleTemplateWithDup[T
      <: Data](\n31:   gen: T,\n32:   numEntries: Int,\n33:   numRead: Int,\n34: \
      \  numDup: Int,\n35:   numBanks: Int\n36: ) extends Module {\n37:   val io =
      IO(new Bundle {\n38:     val raddr = Vec(numRead, Input(UInt(log2Ceil(numEntries).W)))\n\
      39:     val rdata = Vec(numRead, Vec(numDup, Output(gen)))\n40:     val wen\
      \   = Input(Bool())\n41:     val waddr = Input(UInt(log2Ceil(numEntries).W))\n\
      42:     val wdata = Input(gen)\n43:   })\n44:   require(numBanks > 1)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 57-67
    context: "57:     val bankEntries = if (i < numBanks - 1) numBankEntries else
      (numEntries - (i * numBankEntries))\n58:     Mem(bankEntries, gen)\n59:   })\n\
      60: \n61:   // async read, but regnext\n62:   for (i <- 0 until numRead) {\n\
      63:     val data_read = Reg(Vec(numDup, Vec(numBanks, gen)))\n64:     val bank_index
      = Reg(Vec(numDup, UInt(numBanks.W)))\n65:     for (j <- 0 until numDup) {\n\
      66:       bank_index(j) := UIntToOH(bankIndex(io.raddr(i)))\n67:       for (k
      <- 0 until numBanks) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 93-103
    context: "93:   normalPage: Boolean,\n94:   superPage: Boolean\n95: )(implicit
      p: Parameters) extends TlbModule with HasPerfEvents {\n96: \n97:   val io =
      IO(new TlbStorageIO(nSets, nWays, ports, nDups))\n98:   io.r.req.map(_.ready
      := true.B)\n99: \n100:   val v = RegInit(VecInit(Seq.fill(nWays)(false.B)))\n\
      101:   val entries = Reg(Vec(nWays, new TlbSectorEntry(normalPage, superPage)))\n\
      102:   val g = entries.map(_.perm.g)\n103: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 105-115
    context: "105:     val req = io.r.req(i)\n106:     val resp = io.r.resp(i)\n107:\
      \     val access = io.access(i)\n108: \n109:     val vpn = req.bits.vpn\n110:\
      \     val vpn_reg = RegEnable(vpn, req.fire)\n111:     val hasS2xlate = req.bits.s2xlate
      =/= noS2xlate\n112:     val OnlyS2 = req.bits.s2xlate === onlyStage2\n113: \
      \    val OnlyS1 = req.bits.s2xlate === onlyStage1\n114:     val refill_mask
      = Mux(io.w.valid, UIntToOH(io.w.bits.wayIdx), 0.U(nWays.W))\n115:     val hitVec
      = VecInit((entries.zipWithIndex).zip(v zip refill_mask.asBools).map{"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 120-130
    context: "120:       }\n121:     })\n122: \n123:     hitVec.suggestName(\"hitVec\"\
      )\n124: \n125:     val hitVecReg = RegEnable(hitVec, req.fire)\n126:     //
      Sector tlb may trigger multi-hit, see def \"wbhit\"\n127:     XSPerfAccumulate(s\"\
      port${i}_multi_hit\", !(!resp.valid || (PopCount(hitVecReg) === 0.U || PopCount(hitVecReg)
      === 1.U)))\n128: \n129:     resp.valid := GatedValidRegNext(req.valid)\n130:\
      \     resp.bits.hit := Cat(hitVecReg).orR"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 126-137
    context: "126:     // Sector tlb may trigger multi-hit, see def \"wbhit\"\n127:\
      \     XSPerfAccumulate(s\"port${i}_multi_hit\", !(!resp.valid || (PopCount(hitVecReg)
      === 0.U || PopCount(hitVecReg) === 1.U)))\n128: \n129:     resp.valid := GatedValidRegNext(req.valid)\n\
      130:     resp.bits.hit := Cat(hitVecReg).orR\n131:     val reqVpn   = RegEnable(vpn,
      0.U, req.fire)\n132:     val pbmt     = entries.map(_.pbmt)\n133:     val gpbmt\
      \    = entries.map(_.g_pbmt)\n134:     val perm     = entries.map(_.perm)\n\
      135:     val gPerm    = entries.map(_.g_perm)\n136:     val s2xLate  = entries.map(_.s2xlate)\n\
      137:     if (nWays == 1) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 135-145
    context: "135:     val gPerm    = entries.map(_.g_perm)\n136:     val s2xLate\
      \  = entries.map(_.s2xlate)\n137:     if (nWays == 1) {\n138:       for (d <-
      0 until nDups) {\n139:         resp.bits.ppn(d) := entries(0).genPPN(saveLevel,
      resp.valid)(reqVpn)\n140:         resp.bits.pbmt(d) := pbmt(0)\n141:       \
      \  resp.bits.g_pbmt(d) := gpbmt(0)\n142:         resp.bits.perm(d) := perm(0)\n\
      143:         resp.bits.g_perm(d) := gPerm(0)\n144:         resp.bits.s2xlate(d)
      := s2xLate(0)\n145:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 144-154
    context: "144:         resp.bits.s2xlate(d) := s2xLate(0)\n145:       }\n146:\
      \     } else {\n147:       for (d <- 0 until nDups) {\n148:         resp.bits.ppn(d)
      := Mux1H(hitVecReg zip entries.map(_.genPPN(saveLevel, resp.valid)(reqVpn)))\n\
      149:         resp.bits.pbmt(d) := Mux1H(hitVecReg zip pbmt)\n150:         resp.bits.g_pbmt(d)
      := Mux1H(hitVecReg zip gpbmt)\n151:         resp.bits.perm(d) := Mux1H(hitVecReg
      zip perm)\n152:         resp.bits.g_perm(d) := Mux1H(hitVecReg zip gPerm)\n\
      153:         resp.bits.s2xlate(d) := Mux1H(hitVecReg zip s2xLate)\n154:    \
      \   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 158-168
    context: "158:     access.touch_ways.valid := resp.valid && Cat(hitVecReg).orR\n\
      159:     access.touch_ways.bits := OHToUInt(hitVecReg)\n160: \n161:     resp.bits.hit.suggestName(\"\
      hit\")\n162:     resp.bits.ppn.suggestName(\"ppn\")\n163:     resp.bits.pbmt.suggestName(\"\
      pbmt\")\n164:     resp.bits.g_pbmt.suggestName(\"g_pbmt\")\n165:     resp.bits.perm.suggestName(\"\
      perm\")\n166:     resp.bits.g_perm.suggestName(\"g_perm\")\n167:   }\n168: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 277-287
    context: "277:              nWays: Int,\n278:              useDmode: Boolean =
      false\n279:            )(implicit p: Parameters) extends TlbModule with HasCSRConst{\n\
      280: \n281:   val io = IO(new TlbStorageIO(nSets, nWays, ports, nDups))\n282:\
      \   io.r.req.map(_.ready := true.B)\n283:   val mode = if (useDmode) io.csr.priv.dmode
      else io.csr.priv.imode\n284:   val vmEnable = if (EnbaleTlbDebug) (io.csr.satp.mode
      === 8.U)\n285:     else (io.csr.satp.mode === 8.U && (mode < ModeM))\n286: \n\
      287:   for (i <- 0 until ports) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 289-299
    context: "289:     val resp = io.r.resp(i)\n290: \n291:     val helper = Module(new
      PTEHelper())\n292:     helper.clock := clock\n293:     helper.satp := io.csr.satp.ppn\n\
      294:     helper.enable := req.fire && vmEnable\n295:     helper.vpn := req.bits.vpn\n\
      296: \n297:     val pte = helper.pte.asTypeOf(new PteBundle)\n298:     val ppn
      = pte.ppn\n299:     val vpn_reg = RegEnable(req.bits.vpn, req.valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 310-320
    context: "310:       resp.bits.perm(d).g := pte.perm.g\n311:       resp.bits.perm(d).u
      := pte.perm.u\n312:       resp.bits.perm(d).x := pte.perm.x\n313:       resp.bits.perm(d).w
      := pte.perm.w\n314:       resp.bits.perm(d).r := pte.perm.r\n315:       resp.bits.pbmt(d)
      := pte.pbmt\n316:       resp.bits.ppn(d) := MuxLookup(level, 0.U)(Seq(\n317:\
      \         0.U -> Cat(ppn(ppn.getWidth-1, vpnnLen*2), vpn_reg(vpnnLen*2-1, 0)),\n\
      318:         1.U -> Cat(ppn(ppn.getWidth-1, vpnnLen), vpn_reg(vpnnLen-1, 0)),\n\
      319:         2.U -> ppn)\n320:       )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 379-389
    context: "379:   for (i <- 0 until ports) {\n380:     val q = page.r.req(i)\n\
      381:     val p = page.r.resp(i)\n382:     val rq = io.r.req(i)\n383:     val
      rp = io.r.resp(i)\n384:     rq.ready := q.ready // actually, not used\n385:\
      \     rp.valid := p.valid // actually, not used\n386:     rp.bits.hit := p.bits.hit\n\
      387:     for (d <- 0 until nDups) {\n388:       rp.bits.ppn(d) := p.bits.ppn(d)\n\
      389:       rp.bits.perm(d).pf := p.bits.perm(d).pf"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 396-406
    context: "396:       rp.bits.perm(d).x := p.bits.perm(d).x\n397:       rp.bits.perm(d).w
      := p.bits.perm(d).w\n398:       rp.bits.perm(d).r := p.bits.perm(d).r\n399:\
      \       rp.bits.s2xlate(d) := p.bits.s2xlate(d)\n400:       rp.bits.g_perm(d)
      := p.bits.g_perm(d)\n401:       rp.bits.pbmt(d) := p.bits.pbmt(d)\n402:    \
      \   rp.bits.g_pbmt(d) := p.bits.g_pbmt(d)\n403:     }\n404:   }\n405: \n406:\
      \   page.sfence <> io.sfence"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 108-118
    context: "108:   // mbmc:bitmap csr\n109:   val mbmc = io.csr.mbmc\n110:   val
      bitmap_enable = (if (HasBitmapCheck) true.B else false.B) && mbmc.BME === 1.U
      && mbmc.CMODE === 0.U\n111: \n112:   val satp = Wire(new TlbSatpBundle())\n\
      113:   when (io.req.fire) {\n114:     satp := Mux(io.req.bits.req_info.s2xlate
      =/= noS2xlate, io.csr.vsatp, io.csr.satp)\n115:   } .otherwise {\n116:     satp
      := Mux(enableS2xlate, io.csr.vsatp, io.csr.satp)\n117:   }\n118:   val s1Pbmte
      = Mux(req_s2xlate =/= noS2xlate, io.csr.hPBMTE, io.csr.mPBMTE)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 117-127
    context: "117:   }\n118:   val s1Pbmte = Mux(req_s2xlate =/= noS2xlate, io.csr.hPBMTE,
      io.csr.mPBMTE)\n119: \n120:   val mode = satp.mode\n121:   val hgatp = io.csr.hgatp\n\
      122:   val flush = io.sfence.valid || io.csr.satp.changed || io.csr.vsatp.changed
      || io.csr.hgatp.changed || io.csr.priv.virt_changed\n123:   val s2xlate = enableS2xlate
      && !onlyS1xlate\n124:   val level = RegInit(3.U(log2Up(Level + 1).W))\n125:\
      \   val af_level = RegInit(3.U(log2Up(Level + 1).W)) // access fault return
      this level\n126:   val gpf_level = RegInit(3.U(log2Up(Level + 1).W))\n127: \
      \  val ppn = Reg(UInt(ptePPNLen.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 128-139
    context: "128:   val vpn = Reg(UInt(vpnLen.W)) // vpn or gvpn(onlyS2xlate)\n129:\
      \   val levelNext = level - 1.U\n130:   val l3Hit = Reg(Bool())\n131:   val
      l2Hit = Reg(Bool())\n132:   val jmp_bitmap_check_w = if (HasBitmapCheck) { io.req.bits.bitmapCheck.get.jmp_bitmap_check
      && io.req.bits.req_info.s2xlate =/= onlyStage2 } else { false.B }\n133:   val
      jmp_bitmap_check_r = if (HasBitmapCheck) { RegEnable(jmp_bitmap_check_w, io.req.fire)
      } else { false.B }\n134:   val cache_pte = Option.when(HasBitmapCheck)(RegEnable(io.req.bits.bitmapCheck.get.pte.asTypeOf(new
      PteBundle().cloneType), io.req.fire))\n135:   val pte = if (HasBitmapCheck)
      { Mux(jmp_bitmap_check_r, cache_pte.get, io.mem.resp.bits.asTypeOf(new PteBundle().cloneType))
      } else { mem.resp.bits.asTypeOf(new PteBundle()) }\n136: \n137:   // s/w register\n\
      138:   val s_pmp_check = RegInit(true.B)\n139:   val s_mem_req = RegInit(true.B)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 158-169
    context: "158:   dontTouch(vs_finish)\n159: \n160:   val hptw_pageFault = RegInit(false.B)\n\
      161:   val hptw_accessFault = RegInit(false.B)\n162:   val need_last_s2xlate
      = RegInit(false.B)\n163:   val stage1Hit = RegEnable(io.req.bits.stage1Hit,
      io.req.fire)\n164:   val stage1 = RegEnable(io.req.bits.stage1, io.req.fire)\n\
      165:   val hptw_resp_stage2 = Reg(Bool())\n166:   val first_gvpn_check_fail
      = RegInit(false.B)\n167: \n168:   // use accessfault repersent bitmap check
      failed\n169:   val pte_isAf = Mux(bitmap_enable, pte.isAf() || bitmap_checkfailed,
      pte.isAf())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 175-188
    context: "175:   val pte_valid = RegInit(false.B)  // avoid l1tlb pf from stage1
      when gpf happens in the first s2xlate in PTW\n176: \n177:   val pageFault =
      pte.isPf(level, s1Pbmte)\n178:   val find_pte = pte.isLeaf() || ppn_af || pageFault\n\
      179:   val to_find_pte = level === 1.U && find_pte === false.B\n180:   val source
      = RegEnable(io.req.bits.req_info.source, io.req.fire)\n181: \n182:   val sent_to_pmp
      = idle === false.B && (s_pmp_check === false.B || mem_addr_update) && !finish
      && !vs_finish && !first_gvpn_check_fail && !(find_pte && pte_valid)\n183:  \
      \ val accessFault = RegEnable(io.pmp.resp.ld || io.pmp.resp.mmio, false.B, sent_to_pmp)\n\
      184: \n185:   val l3addr = Wire(UInt(ptePaddrLen.W))\n186:   val l2addr = Wire(UInt(ptePaddrLen.W))\n\
      187:   val l1addr = Wire(UInt(ptePaddrLen.W))\n188:   val hptw_addr = Wire(UInt(ptePaddrLen.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 240-250
    context: "240:   val fake_pte = WireInit(0.U.asTypeOf(new PteBundle()))\n241:\
      \   fake_pte.perm.v := false.B // tell L1TLB this is fake pte\n242:   fake_pte.ppn
      := ppn(ppnLen - 1, 0)\n243:   fake_pte.ppn_high := ppn(ptePPNLen - 1, ppnLen)\n\
      244: \n245:   io.req.ready := idle\n246:   val ptw_resp = Wire(new PtwMergeResp)\n\
      247:   // pageFault is always valid when pte_valid\n248:   val resp_pf = pte_valid
      && pageFault\n249:   // when (pte_valid && (pageFault || guestFault), should
      not report accessFault or ppn_af\n250:   val resp_af = (accessFault || ppn_af)
      && !((pte_valid && pageFault) || guestFault)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 275-288
    context: "275:   }\n276: \n277:   io.pmp.req.valid := DontCare // samecycle, do
      not use valid\n278:   io.pmp.req.bits.addr := Mux(s2xlate, hpaddr, mem_addr)\n\
      279:   io.pmp.req.bits.size := 3.U // TODO: fix it\n280:   io.pmp.req.bits.cmd
      := TlbCmd.read\n281: \n282:   if (HasBitmapCheck) {\n283:     val cache_level
      = RegEnable(io.req.bits.bitmapCheck.get.SPlevel, io.req.fire)\n284:     io.bitmap.get.req.valid
      := !s_bitmap_check\n285:     io.bitmap.get.req.bits.bmppn := pte.ppn\n286: \
      \    io.bitmap.get.req.bits.id := FsmReqID.U(bMemID.W)\n287:     io.bitmap.get.req.bits.vpn
      := vpn\n288:     io.bitmap.get.req.bits.level := Mux(jmp_bitmap_check_r, cache_level,
      level)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 286-296
    context: "286:     io.bitmap.get.req.bits.id := FsmReqID.U(bMemID.W)\n287:   \
      \  io.bitmap.get.req.bits.vpn := vpn\n288:     io.bitmap.get.req.bits.level
      := Mux(jmp_bitmap_check_r, cache_level, level)\n289:     io.bitmap.get.req.bits.way_info
      := DontCare\n290:     io.bitmap.get.req.bits.hptw_bypassed := false.B\n291:\
      \     io.bitmap.get.resp.ready := !w_bitmap_resp\n292:   }\n293:   mem.req.valid
      := s_mem_req === false.B && !mem.mask && !accessFault && s_pmp_check\n294: \
      \  mem.req.bits.addr := Mux(s2xlate, hpaddr, mem_addr)\n295:   mem.req.bits.id
      := FsmReqID.U(bMemID.W)\n296:   mem.req.bits.hptw_bypassed := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 304-314
    context: "304:   io.hptw.req.bits.id := FsmReqID.U(bMemID.W)\n305:   io.hptw.req.bits.gvpn
      := get_pn(gpaddr)\n306:   io.hptw.req.bits.source := source\n307: \n308:   if
      (HasBitmapCheck) {\n309:     when (io.req.fire && jmp_bitmap_check_w) {\n310:\
      \       idle := false.B\n311:       req_s2xlate := io.req.bits.req_info.s2xlate\n\
      312:       vpn := io.req.bits.req_info.vpn\n313:       s_bitmap_check := false.B\n\
      314:       need_last_s2xlate := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 318-328
    context: "318:       pte_valid := true.B\n319:       accessFault := false.B\n\
      320:     }\n321:   }\n322: \n323:   when (io.req.fire && io.req.bits.stage1Hit
      && (if (HasBitmapCheck) !jmp_bitmap_check_w else true.B)) {\n324:     idle :=
      false.B\n325:     req_s2xlate := io.req.bits.req_info.s2xlate\n326:     s_last_hptw_req
      := false.B\n327:     hptw_resp_stage2 := false.B\n328:     need_last_s2xlate
      := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 329-343
    context: "329:     hptw_pageFault := false.B\n330:     hptw_accessFault := false.B\n\
      331:     full_gvpn_reg := io.req.bits.stage1.genPPN()\n332:   }\n333: \n334:\
      \   when (io.resp.fire && stage1Hit){\n335:     idle := true.B\n336:   }\n337:\
      \ \n338:   when (io.req.fire && !io.req.bits.stage1Hit && (if (HasBitmapCheck)
      !jmp_bitmap_check_w else true.B)) {\n339:     val req = io.req.bits\n340:  \
      \   val gvpn_wire = Wire(UInt(ptePPNLen.W))\n341:     if (EnableSv48) {\n342:\
      \       when (mode === Sv48) {\n343:         level := Mux(req.l2Hit, 1.U, Mux(req.l3Hit.get,
      2.U, 3.U))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 397-412
    context: "397:       need_last_s2xlate := false.B\n398:       s_pmp_check := false.B\n\
      399:     }\n400:   }\n401: \n402:   when(io.hptw.req.fire && s_hptw_req ===
      false.B){\n403:     s_hptw_req := true.B\n404:     w_hptw_resp := false.B\n\
      405:   }\n406: \n407:   when(io.hptw.resp.fire && w_hptw_resp === false.B) {\n\
      408:     w_hptw_resp := true.B\n409:     val g_perm_fail = !io.hptw.resp.bits.h_resp.gaf
      && (!io.hptw.resp.bits.h_resp.entry.perm.get.r && !(io.csr.priv.mxr && io.hptw.resp.bits.h_resp.entry.perm.get.x))\n\
      410:     hptw_pageFault := io.hptw.resp.bits.h_resp.gpf || g_perm_fail\n411:\
      \     hptw_accessFault := io.hptw.resp.bits.h_resp.gaf\n412:     hptw_resp :=
      io.hptw.resp.bits.h_resp"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 417-432
    context: "417:       mem_addr_update := true.B\n418:       need_last_s2xlate :=
      false.B\n419:     }\n420:   }\n421: \n422:   when(io.hptw.req.fire && s_last_hptw_req
      === false.B) {\n423:     w_last_hptw_resp := false.B\n424:     s_last_hptw_req
      := true.B\n425:   }\n426: \n427:   when (io.hptw.resp.fire && w_last_hptw_resp
      === false.B && stage1Hit){\n428:     w_last_hptw_resp := true.B\n429:     hptw_resp_stage2
      := true.B\n430:     hptw_resp := io.hptw.resp.bits.h_resp\n431:   }\n432: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 428-438
    context: "428:     w_last_hptw_resp := true.B\n429:     hptw_resp_stage2 := true.B\n\
      430:     hptw_resp := io.hptw.resp.bits.h_resp\n431:   }\n432: \n433:   when(io.hptw.resp.fire
      && w_last_hptw_resp === false.B && !stage1Hit){\n434:     hptw_pageFault :=
      io.hptw.resp.bits.h_resp.gpf\n435:     hptw_accessFault := io.hptw.resp.bits.h_resp.gaf\n\
      436:     hptw_resp := io.hptw.resp.bits.h_resp\n437:     w_last_hptw_resp :=
      true.B\n438:     mem_addr_update := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 479-494
    context: "479:       whether_need_bitmap_check := false.B\n480:       bitmap_checkfailed
      := false.B\n481:     }\n482:   }\n483: \n484:   when (mem.req.fire){\n485: \
      \    s_mem_req := true.B\n486:     w_mem_resp := false.B\n487:   }\n488: \n\
      489:   when(mem.resp.fire && w_mem_resp === false.B){\n490:     w_mem_resp :=
      true.B\n491:     af_level := af_level - 1.U\n492:     gpf_level := Mux(mode
      === Sv39 && !pte_valid && !l2Hit, gpf_level - 2.U, gpf_level - 1.U)\n493:  \
      \   pte_valid := true.B\n494:     update_full_gvpn_mem_resp := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 521-535
    context: "521:         s_llptw_req := false.B\n522:         whether_need_bitmap_check
      := false.B\n523:       }\n524:     }\n525:     // bitmapcheck\n526:     when
      (io.bitmap.get.req.fire) {\n527:       s_bitmap_check := true.B\n528:      \
      \ w_bitmap_resp := false.B\n529:     }\n530:     when (io.bitmap.get.resp.fire)
      {\n531:       w_bitmap_resp := true.B\n532:       mem_addr_update := true.B\n\
      533:       bitmap_checkfailed := io.bitmap.get.resp.bits.cf\n534:     }\n535:\
      \   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 544-554
    context: "544:         s_mem_req := false.B\n545:       }\n546:       s_llptw_req
      := true.B\n547:       mem_addr_update := false.B\n548:     }.elsewhen(io.llptw.valid){\n\
      549:       when(io.llptw.fire) {\n550:         idle := true.B\n551:        \
      \ s_llptw_req := true.B\n552:         mem_addr_update := false.B\n553:     \
      \    need_last_s2xlate := false.B\n554:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 558-568
    context: "558:       when(!(guestFault || accessFault || pageFault || ppn_af)){\n\
      559:         s_last_hptw_req := false.B\n560:         mem_addr_update := false.B\n\
      561:       }\n562:     }.elsewhen(io.resp.valid){\n563:       when(io.resp.fire)
      {\n564:         idle := true.B\n565:         s_llptw_req := true.B\n566:   \
      \      mem_addr_update := false.B\n567:         accessFault := false.B\n568:\
      \         first_gvpn_check_fail := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 570-580
    context: "570:       finish := true.B\n571:     }\n572:   }\n573: \n574: \n575:\
      \   when (flush) {\n576:     idle := true.B\n577:     s_pmp_check := true.B\n\
      578:     s_mem_req := true.B\n579:     s_llptw_req := true.B\n580:     w_mem_resp
      := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 595-624
    context: "595: \n596: \n597:   XSDebug(p\"[ptw] level:${level} notFound:${pageFault}\\\
      n\")\n598: \n599:   // perf\n600:   XSPerfAccumulate(\"fsm_count\", io.req.fire)\n\
      601:   for (i <- 0 until PtwWidth) {\n602:     XSPerfAccumulate(s\"fsm_count_source${i}\"\
      , io.req.fire && io.req.bits.req_info.source === i.U)\n603:   }\n604:   XSPerfAccumulate(\"\
      fsm_busy\", !idle)\n605:   XSPerfAccumulate(\"fsm_idle\", idle)\n606:   XSPerfAccumulate(\"\
      resp_blocked\", io.resp.valid && !io.resp.ready)\n607:   XSPerfAccumulate(\"\
      ptw_ppn_af\", io.resp.fire && ppn_af)\n608:   XSPerfAccumulate(\"mem_count\"\
      , mem.req.fire)\n609:   XSPerfAccumulate(\"mem_cycle\", BoolStopWatch(mem.req.fire,
      mem.resp.fire, true))\n610:   XSPerfAccumulate(\"mem_blocked\", mem.req.valid
      && !mem.req.ready)\n611: \n612:   val perfEvents = Seq(\n613:     (\"fsm_count\
      \         \", io.req.fire                                     ),\n614:     (\"\
      fsm_busy          \", !idle                                           ),\n615:\
      \     (\"fsm_idle          \", idle                                        \
      \    ),\n616:     (\"resp_blocked      \", io.resp.valid && !io.resp.ready \
      \                ),\n617:     (\"mem_count         \", mem.req.fire        \
      \                            ),\n618:     (\"mem_cycle         \", BoolStopWatch(mem.req.fire,
      mem.resp.fire, true)),\n619:     (\"mem_blocked       \", mem.req.valid && !mem.req.ready\
      \                 ),\n620:   )\n621:   generatePerfEvent()\n622: }\n623: \n\
      624: /*========================= LLPTW ==============================*/"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 660-670
    context: "660:     }))\n661:     val enq_ptr = Output(UInt(log2Ceil(l2tlbParams.llptwsize).W))\n\
      662:     val buffer_it = Output(Vec(l2tlbParams.llptwsize, Bool()))\n663:  \
      \   val refill = Output(new L2TlbInnerBundle())\n664:     val req_mask = Input(Vec(l2tlbParams.llptwsize,
      Bool()))\n665:     val flush_latch = Input(Vec(l2tlbParams.llptwsize, Bool()))\n\
      666:   }\n667:   val cache = DecoupledIO(new L2TlbInnerBundle())\n668:   val
      pmp = Vec(2, new Bundle {\n669:     val req  = Valid(new PMPReqBundle())\n670:\
      \     val resp = Flipped(new PMPRespBundle())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 709-734
    context: "709: \n710:   // mbmc:bitmap csr\n711:   val mbmc = io.csr.mbmc\n712:\
      \   val bitmap_enable = (if (HasBitmapCheck) true.B else false.B) && mbmc.BME
      === 1.U && mbmc.CMODE === 0.U\n713: \n714:   val flush = io.sfence.valid ||
      io.csr.satp.changed || io.csr.vsatp.changed || io.csr.hgatp.changed || io.csr.priv.virt_changed\n\
      715:   val entries = RegInit(VecInit(Seq.fill(l2tlbParams.llptwsize)(0.U.asTypeOf(new
      LLPTWEntry()))))\n716:   val state_idle :: state_hptw_req :: state_hptw_resp
      :: state_addr_check :: state_mem_req :: state_mem_waiting :: state_mem_out ::
      state_last_hptw_req :: state_last_hptw_resp :: state_cache :: state_bitmap_check
      :: state_bitmap_resp :: Nil = Enum(12)\n717:   val state = RegInit(VecInit(Seq.fill(l2tlbParams.llptwsize)(state_idle)))\n\
      718: \n719:   val is_emptys = state.map(_ === state_idle)\n720:   val is_mems
      = state.map(_ === state_mem_req)\n721:   val is_waiting = state.map(_ === state_mem_waiting)\n\
      722:   val is_having = state.map(_ === state_mem_out)\n723:   val is_cache =
      state.map(_ === state_cache)\n724:   val is_hptw_req = state.map(_ === state_hptw_req)\n\
      725:   val is_last_hptw_req = state.map(_ === state_last_hptw_req)\n726:   val
      is_hptw_resp = state.map(_ === state_hptw_resp)\n727:   val is_last_hptw_resp
      = state.map(_ === state_last_hptw_resp)\n728:   val is_bitmap_req = state.map(_
      === state_bitmap_check)\n729:   val is_bitmap_resp = state.map(_ === state_bitmap_resp)\n\
      730: \n731:   val full = !ParallelOR(is_emptys).asBool\n732:   val enq_ptr =
      ParallelPriorityEncoder(is_emptys)\n733: \n734:   val mem_ptr = ParallelPriorityEncoder(is_having)
      // TODO: optimize timing, bad: entries -> ptr -> entry"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 772-791
    context: "772:   val cache_ptr = ParallelMux(is_cache, (0 until l2tlbParams.llptwsize).map(_.U(log2Up(l2tlbParams.llptwsize).W)))\n\
      773: \n774:   // duplicate req\n775:   // to_wait: wait for the last to access
      mem, set to mem_resp\n776:   // to_cache: the last is back just right now, set
      to mem_cache\n777:   val dup_vec = state.indices.map(i =>\n778:     dup(io.in.bits.req_info.vpn,
      entries(i).req_info.vpn) && io.in.bits.req_info.s2xlate === entries(i).req_info.s2xlate\n\
      779:   )\n780:   val dup_req_fire = mem_arb.io.out.fire && dup(io.in.bits.req_info.vpn,
      mem_arb.io.out.bits.req_info.vpn) && io.in.bits.req_info.s2xlate === mem_arb.io.out.bits.req_info.s2xlate
      // dup with the req fire entry\n781:   val dup_vec_wait = dup_vec.zip(is_waiting).map{case
      (d, w) => d && w} // dup with \"mem_waiting\" entries, sending mem req already\n\
      782:   val dup_vec_having = dup_vec.zipWithIndex.map{case (d, i) => d && is_having(i)}
      // dup with the \"mem_out\" entry recv the data just now\n783:   val dup_vec_bitmap
      = dup_vec.zipWithIndex.map{case (d, i) => d && (is_bitmap_req(i) || is_bitmap_resp(i))}\n\
      784:   val dup_vec_last_hptw = dup_vec.zipWithIndex.map{case (d, i) => d &&
      (is_last_hptw_req(i) || is_last_hptw_resp(i))}\n785:   val wait_id = Mux(dup_req_fire,
      mem_arb.io.chosen, ParallelMux(dup_vec_wait zip entries.map(_.wait_id)))\n786:\
      \   val dup_wait_resp = io.mem.resp.fire && VecInit(dup_vec_wait)(io.mem.resp.bits.id)
      && !io.mem.flush_latch(io.mem.resp.bits.id) // dup with the entry that data
      coming next cycle\n787:   val to_wait = Cat(dup_vec_wait).orR || dup_req_fire\n\
      788: \n789:   val last_hptw_req_id = io.mem.resp.bits.id\n790:   val req_paddr
      = MakeAddr(io.in.bits.ppn(ppnLen-1, 0), getVpnn(io.in.bits.req_info.vpn, 0))\n\
      791:   val req_hpaddr = MakeAddr(entries(last_hptw_req_id).hptw_resp.genPPNS2(get_pn(req_paddr)),
      getVpnn(io.in.bits.req_info.vpn, 0))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 795-808
    context: "795:   // in `to_last_hptw_req`, we have already judged whether s2xlate
      === allStage\n796:   val last_hptw_vsStagePf = last_hptw_req_pte.isPf(0.U, io.csr.hPBMTE)
      || !last_hptw_req_pte.isLeaf()\n797:   val last_hptw_gStagePf = last_hptw_req_pte.isStage1Gpf(io.csr.hgatp.mode)
      && !last_hptw_vsStagePf\n798: \n799:   // noS2xlate || onlyStage1 || allStage
      but exception; do not need Stage2 translate\n800:   val noStage2 = ((entries(io.mem.resp.bits.id).req_info.s2xlate
      === noS2xlate) || (entries(io.mem.resp.bits.id).req_info.s2xlate === onlyStage1))
      ||\n801:     (entries(io.mem.resp.bits.id).req_info.s2xlate === allStage &&
      (last_hptw_vsStagePf || last_hptw_gStagePf))\n802:   val to_mem_out = dup_wait_resp
      && noStage2 && !bitmap_enable\n803:   val to_bitmap_req = (if (HasBitmapCheck)
      true.B else false.B) && dup_wait_resp && noStage2 && bitmap_enable\n804:   val
      to_cache = if (HasBitmapCheck) Cat(dup_vec_bitmap).orR || Cat(dup_vec_having).orR
      || Cat(dup_vec_last_hptw).orR\n805:                  else Cat(dup_vec_having).orR
      || Cat(dup_vec_last_hptw).orR\n806:   val to_hptw_req = io.in.bits.req_info.s2xlate
      === allStage\n807:   val to_last_hptw_req = dup_wait_resp && entries(io.mem.resp.bits.id).req_info.s2xlate
      === allStage && !(last_hptw_vsStagePf || last_hptw_gStagePf)\n808:   val last_hptw_excp
      = dup_wait_resp && entries(io.mem.resp.bits.id).req_info.s2xlate === allStage
      && (last_hptw_vsStagePf || last_hptw_gStagePf)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 805-817
    context: "805:                  else Cat(dup_vec_having).orR || Cat(dup_vec_last_hptw).orR\n\
      806:   val to_hptw_req = io.in.bits.req_info.s2xlate === allStage\n807:   val
      to_last_hptw_req = dup_wait_resp && entries(io.mem.resp.bits.id).req_info.s2xlate
      === allStage && !(last_hptw_vsStagePf || last_hptw_gStagePf)\n808:   val last_hptw_excp
      = dup_wait_resp && entries(io.mem.resp.bits.id).req_info.s2xlate === allStage
      && (last_hptw_vsStagePf || last_hptw_gStagePf)\n809: \n810:   XSError(RegNext(dup_req_fire
      && Cat(dup_vec_wait).orR, init = false.B), \"mem req but some entries already
      waiting, should not happed\")\n811: \n812:   XSError(io.in.fire && ((to_mem_out
      && to_cache) || (to_wait && to_cache)), \"llptw enq, to cache conflict with
      to mem\")\n813:   val mem_resp_hit = RegInit(VecInit(Seq.fill(l2tlbParams.llptwsize)(false.B)))\n\
      814:   val enq_state_normal = MuxCase(state_addr_check, Seq(\n815:     to_mem_out
      -> state_mem_out, // same to the blew, but the mem resp now\n816:     to_bitmap_req
      -> state_bitmap_check,\n817:     to_last_hptw_req -> state_last_hptw_req,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 818-832
    context: "818:     to_wait -> state_mem_waiting,\n819:     to_cache -> state_cache,\n\
      820:     to_hptw_req -> state_hptw_req\n821:   ))\n822:   val enq_state = Mux(from_pre(io.in.bits.req_info.source)
      && enq_state_normal =/= state_addr_check, state_idle, enq_state_normal)\n823:\
      \   when (io.in.fire  && (if (HasBitmapCheck) !io.in.bits.bitmapCheck.get.jmp_bitmap_check
      else true.B)) {\n824:     // if prefetch req does not need mem access, just
      give it up.\n825:     // so there will be at most 1 + FilterSize entries that
      needs re-access page cache\n826:     // so 2 + FilterSize is enough to avoid
      dead-lock\n827:     state(enq_ptr) := enq_state\n828:     entries(enq_ptr).req_info
      := io.in.bits.req_info\n829:     entries(enq_ptr).ppn := Mux(to_last_hptw_req
      || last_hptw_excp, last_hptw_req_ppn, io.in.bits.ppn)\n830:     entries(enq_ptr).wait_id
      := Mux(to_wait, wait_id, enq_ptr)\n831:     entries(enq_ptr).af := false.B\n\
      832:     if (HasBitmapCheck) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 844-855
    context: "844:     entries(enq_ptr).first_s2xlate_fault := false.B\n845:     mem_resp_hit(enq_ptr)
      := to_bitmap_req || to_mem_out || to_last_hptw_req\n846:   }\n847: \n848:  \
      \ if (HasBitmapCheck) {\n849:     when (io.in.bits.bitmapCheck.get.jmp_bitmap_check
      && io.in.fire) {\n850:       state(enq_ptr) := state_bitmap_check\n851:    \
      \   entries(enq_ptr).req_info := io.in.bits.req_info\n852:       entries(enq_ptr).ppn
      := io.in.bits.bitmapCheck.get.ptes(io.in.bits.req_info.vpn(sectortlbwidth -
      1, 0)).asTypeOf(new PteBundle().cloneType).ppn\n853:       entries(enq_ptr).wait_id
      := enq_ptr\n854:       entries(enq_ptr).af := false.B\n855:       entries(enq_ptr).cf
      := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 861-875
    context: "861:       mem_resp_hit(enq_ptr) := false.B\n862:     }\n863:   }\n\
      864: \n865:   val enq_ptr_reg = RegNext(enq_ptr)\n866:   val need_addr_check
      = GatedValidRegNext(enq_state === state_addr_check && io.in.fire && !flush &&
      (if (HasBitmapCheck) !io.in.bits.bitmapCheck.get.jmp_bitmap_check else true.B))\n\
      867: \n868:   val hasHptwResp = ParallelOR(state.map(_ === state_hptw_resp)).asBool\n\
      869:   val hptw_resp_ptr_reg = RegNext(io.hptw.resp.bits.id)\n870:   val hptw_need_addr_check
      = RegNext(hasHptwResp && io.hptw.resp.fire && !flush) && state(hptw_resp_ptr_reg)
      === state_addr_check\n871: \n872:   val ptes = io.mem.resp.bits.value.asTypeOf(Vec(blockBits
      / XLEN, new PteBundle()))\n873:   val gpaddr = MakeGPAddr(entries(hptw_resp_ptr_reg).ppn,
      getVpnn(entries(hptw_resp_ptr_reg).req_info.vpn, 0))\n874:   val hptw_resp =
      entries(hptw_resp_ptr_reg).hptw_resp\n875:   val hpaddr = Cat(hptw_resp.genPPNS2(get_pn(gpaddr)),
      get_off(gpaddr))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 871-912
    context: "871: \n872:   val ptes = io.mem.resp.bits.value.asTypeOf(Vec(blockBits
      / XLEN, new PteBundle()))\n873:   val gpaddr = MakeGPAddr(entries(hptw_resp_ptr_reg).ppn,
      getVpnn(entries(hptw_resp_ptr_reg).req_info.vpn, 0))\n874:   val hptw_resp =
      entries(hptw_resp_ptr_reg).hptw_resp\n875:   val hpaddr = Cat(hptw_resp.genPPNS2(get_pn(gpaddr)),
      get_off(gpaddr))\n876:   val addr = RegEnable(MakeAddr(io.in.bits.ppn(ppnLen
      - 1, 0), getVpnn(io.in.bits.req_info.vpn, 0)), io.in.fire)\n877: \n878:   io.pmp(0).req.valid
      := need_addr_check\n879:   io.pmp(0).req.bits.addr := addr\n880:   io.pmp(0).req.bits.cmd
      := TlbCmd.read\n881:   io.pmp(0).req.bits.size := 3.U // TODO: fix it\n882:\
      \   when (io.pmp(0).req.valid) {  // same cycle\n883:     val ptr = enq_ptr_reg\n\
      884:     val accessFault = io.pmp(0).resp.ld || io.pmp(0).resp.mmio\n885:  \
      \   entries(ptr).af := accessFault\n886:     state(ptr) := Mux(accessFault,
      state_mem_out, state_mem_req)\n887:   }\n888: \n889:   io.pmp(1).req.valid :=
      hptw_need_addr_check\n890:   io.pmp(1).req.bits.addr := hpaddr\n891:   io.pmp(1).req.bits.cmd
      := TlbCmd.read\n892:   io.pmp(1).req.bits.size := 3.U // TODO: fix it\n893:\
      \   when (io.pmp(1).req.valid) {  // same cycle\n894:     val ptr = hptw_resp_ptr_reg\n\
      895:     val accessFault = io.pmp(1).resp.ld || io.pmp(1).resp.mmio\n896:  \
      \   entries(ptr).af := accessFault\n897:     state(ptr) := Mux(accessFault,
      state_mem_out, state_mem_req)\n898:   }\n899: \n900:   when (mem_arb.io.out.fire)
      {\n901:     for (i <- state.indices) {\n902:       when (state(i) =/= state_idle
      && state(i) =/= state_mem_out && state(i) =/= state_last_hptw_req && state(i)
      =/= state_last_hptw_resp\n903:       && (if (HasBitmapCheck) state(i) =/= state_bitmap_check
      && state(i) =/= state_bitmap_resp else true.B)\n904:       && entries(i).req_info.s2xlate
      === mem_arb.io.out.bits.req_info.s2xlate\n905:       && dup(entries(i).req_info.vpn,
      mem_arb.io.out.bits.req_info.vpn)) {\n906:         // NOTE: \"dup enq set state
      to mem_wait\" -> \"sending req set other dup entries to mem_wait\"\n907:   \
      \      state(i) := state_mem_waiting\n908:         entries(i).hptw_resp := entries(mem_arb.io.chosen).hptw_resp\n\
      909:         entries(i).wait_id := mem_arb.io.chosen\n910:         block_hptw_req(i)
      := true.B\n911:       }\n912:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 909-921
    context: "909:         entries(i).wait_id := mem_arb.io.chosen\n910:         block_hptw_req(i)
      := true.B\n911:       }\n912:     }\n913:   }\n914:   when (io.mem.resp.fire)
      {\n915:     state.indices.map{i =>\n916:       when (state(i) === state_mem_waiting
      && io.mem.resp.bits.id === entries(i).wait_id) {\n917:         val req_paddr
      = MakeAddr(entries(i).ppn, getVpnn(entries(i).req_info.vpn, 0))\n918:      \
      \   val req_hpaddr = MakeAddr(entries(i).hptw_resp.genPPNS2(get_pn(req_paddr)),
      getVpnn(entries(i).req_info.vpn, 0))\n919:         val index =  Mux(entries(i).req_info.s2xlate
      === allStage, req_hpaddr, req_paddr)(log2Up(l2tlbParams.blockBytes)-1, log2Up(XLEN/8))\n\
      920:         val enableS2xlate = entries(i).req_info.s2xlate =/= noS2xlate\n\
      921:         val s1Pbmte = Mux(enableS2xlate, io.csr.hPBMTE, io.csr.mPBMTE)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 920-930
    context: "920:         val enableS2xlate = entries(i).req_info.s2xlate =/= noS2xlate\n\
      921:         val s1Pbmte = Mux(enableS2xlate, io.csr.hPBMTE, io.csr.mPBMTE)\n\
      922:         val vsStagePf = ptes(index).isPf(0.U, s1Pbmte) || !ptes(index).isLeaf()
      // Pagefault in vs-Stage\n923:         // Pagefault in g-Stage; when vsStagePf
      valid, should not check gStagepf\n924:         val gStagePf = ptes(index).isStage1Gpf(io.csr.hgatp.mode)
      && !vsStagePf\n925:         state(i) := Mux(entries(i).req_info.s2xlate ===
      allStage && !(vsStagePf || gStagePf),\n926:                         state_last_hptw_req,\n\
      927:                         Mux(bitmap_enable, state_bitmap_check, state_mem_out))\n\
      928:         mem_resp_hit(i) := true.B\n929:         entries(i).ppn := Mux(ptes(index).n
      === 0.U, ptes(index).getPPN(), Cat(ptes(index).getPPN()(ptePPNLen - 1, pteNapotBits),
      entries(i).req_info.vpn(pteNapotBits - 1, 0))) // for last stage 2 translation\n\
      930:         // af will be judged in L2 TLB `contiguous_pte_to_merge_ptwResp`"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 937-950
    context: "937:     for (i <- 0 until l2tlbParams.llptwsize) {\n938:       way_info.get(i)
      := DataHoldBypass(io.l0_way_info.get, mem_resp_hit(i))\n939:     }\n940:   }\n\
      941: \n942:   when (hyper_arb1.io.out.fire) {\n943:     for (i <- state.indices)
      {\n944:       when (state(i) === state_hptw_req && entries(i).ppn === hyper_arb1.io.out.bits.ppn
      && entries(i).req_info.s2xlate === allStage && hyper_arb1.io.chosen === i.U)
      {\n945:         state(i) := state_hptw_resp\n946:         entries(i).wait_id
      := hyper_arb1.io.chosen\n947:       }\n948:     }\n949:   }\n950: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 946-959
    context: "946:         entries(i).wait_id := hyper_arb1.io.chosen\n947:      \
      \ }\n948:     }\n949:   }\n950: \n951:   when (hyper_arb2.io.out.fire) {\n952:\
      \     for (i <- state.indices) {\n953:       when (state(i) === state_last_hptw_req
      && entries(i).ppn === hyper_arb2.io.out.bits.ppn && entries(i).req_info.s2xlate
      === allStage && hyper_arb2.io.chosen === i.U) {\n954:         state(i) := state_last_hptw_resp\n\
      955:         entries(i).wait_id := hyper_arb2.io.chosen\n956:       }\n957:\
      \     }\n958:   }\n959: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 956-969
    context: "956:       }\n957:     }\n958:   }\n959: \n960:   if (HasBitmapCheck)
      {\n961:     when (bitmap_arb.get.io.out.fire) {\n962:       for (i <- state.indices)
      {\n963:         when (is_bitmap_req(i) && bitmap_arb.get.io.out.bits.bmppn ===
      entries(i).ppn(ppnLen - 1, 0)) {\n964:           state(i) := state_bitmap_resp\n\
      965:           entries(i).wait_id := bitmap_arb.get.io.chosen\n966:        \
      \ }\n967:       }\n968:     }\n969: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 965-980
    context: "965:           entries(i).wait_id := bitmap_arb.get.io.chosen\n966:\
      \         }\n967:       }\n968:     }\n969: \n970:     when (io.bitmap.get.resp.fire)
      {\n971:       for (i <- state.indices) {\n972:         when (is_bitmap_resp(i)
      && io.bitmap.get.resp.bits.id === entries(i).wait_id) {\n973:           entries(i).cfs
      := io.bitmap.get.resp.bits.cfs\n974:           entries(i).cf := io.bitmap.get.resp.bits.cf\n\
      975:           state(i) := state_mem_out\n976:         }\n977:       }\n978:\
      \     }\n979:   }\n980: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 976-1000
    context: "976:         }\n977:       }\n978:     }\n979:   }\n980: \n981:   when
      (io.hptw.resp.fire) {\n982:     for (i <- state.indices) {\n983:       when
      (state(i) === state_hptw_resp && io.hptw.resp.bits.id === entries(i).wait_id
      && io.hptw.resp.bits.h_resp.entry.tag === entries(i).ppn) {\n984:         val
      check_g_perm_fail = !io.hptw.resp.bits.h_resp.gaf && (!io.hptw.resp.bits.h_resp.entry.perm.get.r
      && !(io.csr.priv.mxr && io.hptw.resp.bits.h_resp.entry.perm.get.x))\n985:  \
      \       when (check_g_perm_fail || io.hptw.resp.bits.h_resp.gaf || io.hptw.resp.bits.h_resp.gpf)
      {\n986:           state(i) := state_mem_out\n987:           entries(i).hptw_resp
      := io.hptw.resp.bits.h_resp\n988:           entries(i).hptw_resp.gpf := io.hptw.resp.bits.h_resp.gpf
      || check_g_perm_fail\n989:           entries(i).first_s2xlate_fault := io.hptw.resp.bits.h_resp.gaf
      || io.hptw.resp.bits.h_resp.gpf || check_g_perm_fail\n990:         }.otherwise{
      // change the entry that is waiting hptw resp\n991:           val need_to_waiting_vec
      = state.indices.map(i => state(i) === state_mem_waiting &&\n992:           \
      \  dup(entries(i).req_info.vpn, entries(io.hptw.resp.bits.id).req_info.vpn)
      &&\n993:             entries(i).req_info.s2xlate === entries(io.hptw.resp.bits.id).req_info.s2xlate)\n\
      994:           val waiting_index = ParallelMux(need_to_waiting_vec zip entries.map(_.wait_id))\n\
      995:           state(i) := Mux(Cat(need_to_waiting_vec).orR, state_mem_waiting,
      state_addr_check)\n996:           entries(i).hptw_resp := io.hptw.resp.bits.h_resp\n\
      997:           entries(i).wait_id := Mux(Cat(need_to_waiting_vec).orR, waiting_index,
      entries(i).wait_id)\n998:           //To do: change the entry that is having
      the same hptw req\n999:         }\n1000:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 996-1007
    context: "996:           entries(i).hptw_resp := io.hptw.resp.bits.h_resp\n997:\
      \           entries(i).wait_id := Mux(Cat(need_to_waiting_vec).orR, waiting_index,
      entries(i).wait_id)\n998:           //To do: change the entry that is having
      the same hptw req\n999:         }\n1000:       }\n1001:       when (state(i)
      === state_last_hptw_resp && io.hptw.resp.bits.id === entries(i).wait_id && io.hptw.resp.bits.h_resp.entry.tag
      === entries(i).ppn) {\n1002:         state(i) := state_mem_out\n1003:      \
      \   entries(i).hptw_resp := io.hptw.resp.bits.h_resp\n1004:         //To do:
      change the entry that is having the same hptw req\n1005:       }\n1006:    \
      \ }\n1007:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1003-1028
    context: "1003:         entries(i).hptw_resp := io.hptw.resp.bits.h_resp\n1004:\
      \         //To do: change the entry that is having the same hptw req\n1005:\
      \       }\n1006:     }\n1007:   }\n1008:   when (io.out.fire) {\n1009:     assert(state(mem_ptr)
      === state_mem_out)\n1010:     state(mem_ptr) := state_idle\n1011:   }\n1012:\
      \   mem_resp_hit.map(a => when (a) { a := false.B } )\n1013: \n1014:   when
      (io.cache.fire) {\n1015:     state(cache_ptr) := state_idle\n1016:   }\n1017:\
      \   XSError(io.out.fire && io.cache.fire && (mem_ptr === cache_ptr), \"mem resp
      and cache fire at the same time at same entry\")\n1018: \n1019:   when (flush)
      {\n1020:     state.map(_ := state_idle)\n1021:   }\n1022: \n1023:   io.in.ready
      := !full\n1024: \n1025:   io.out.valid := ParallelOR(is_having).asBool\n1026:\
      \   io.out.bits.req_info := entries(mem_ptr).req_info\n1027:   io.out.bits.id
      := mem_ptr\n1028:   if (HasBitmapCheck) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1045-1055
    context: "1045:   // first stage 2 translation\n1046:   hptw_req_arb.io.in(0).valid
      := hyper_arb1.io.out.valid\n1047:   hptw_req_arb.io.in(0).bits.source := hyper_arb1.io.out.bits.req_info.source\n\
      1048:   hptw_req_arb.io.in(0).bits.ppn := hyper_arb1.io.out.bits.ppn\n1049:\
      \   hptw_req_arb.io.in(0).bits.id := hyper_arb1.io.chosen\n1050:   hyper_arb1.io.out.ready
      := hptw_req_arb.io.in(0).ready\n1051:   // last stage 2 translation\n1052: \
      \  hptw_req_arb.io.in(1).valid := hyper_arb2.io.out.valid\n1053:   hptw_req_arb.io.in(1).bits.source
      := hyper_arb2.io.out.bits.req_info.source\n1054:   hptw_req_arb.io.in(1).bits.ppn
      := hyper_arb2.io.out.bits.ppn\n1055:   hptw_req_arb.io.in(1).bits.id := hyper_arb2.io.chosen"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1051-1068
    context: "1051:   // last stage 2 translation\n1052:   hptw_req_arb.io.in(1).valid
      := hyper_arb2.io.out.valid\n1053:   hptw_req_arb.io.in(1).bits.source := hyper_arb2.io.out.bits.req_info.source\n\
      1054:   hptw_req_arb.io.in(1).bits.ppn := hyper_arb2.io.out.bits.ppn\n1055:\
      \   hptw_req_arb.io.in(1).bits.id := hyper_arb2.io.chosen\n1056:   hyper_arb2.io.out.ready
      := hptw_req_arb.io.in(1).ready\n1057:   hptw_req_arb.io.out.ready := io.hptw.req.ready\n\
      1058:   io.hptw.req.valid := hptw_req_arb.io.out.fire && !flush\n1059:   io.hptw.req.bits.gvpn
      := hptw_req_arb.io.out.bits.ppn\n1060:   io.hptw.req.bits.id := hptw_req_arb.io.out.bits.id\n\
      1061:   io.hptw.req.bits.source := hptw_req_arb.io.out.bits.source\n1062: \n\
      1063:   io.mem.req.valid := mem_arb.io.out.valid && !flush\n1064:   val mem_paddr
      = MakeAddr(mem_arb.io.out.bits.ppn, getVpnn(mem_arb.io.out.bits.req_info.vpn,
      0))\n1065:   val mem_hpaddr = MakeAddr(mem_arb.io.out.bits.hptw_resp.genPPNS2(get_pn(mem_paddr)),
      getVpnn(mem_arb.io.out.bits.req_info.vpn, 0))\n1066:   io.mem.req.bits.addr
      := Mux(mem_arb.io.out.bits.req_info.s2xlate === allStage, mem_hpaddr, mem_paddr)\n\
      1067:   io.mem.req.bits.id := mem_arb.io.chosen\n1068:   io.mem.req.bits.hptw_bypassed
      := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1064-1074
    context: "1064:   val mem_paddr = MakeAddr(mem_arb.io.out.bits.ppn, getVpnn(mem_arb.io.out.bits.req_info.vpn,
      0))\n1065:   val mem_hpaddr = MakeAddr(mem_arb.io.out.bits.hptw_resp.genPPNS2(get_pn(mem_paddr)),
      getVpnn(mem_arb.io.out.bits.req_info.vpn, 0))\n1066:   io.mem.req.bits.addr
      := Mux(mem_arb.io.out.bits.req_info.s2xlate === allStage, mem_hpaddr, mem_paddr)\n\
      1067:   io.mem.req.bits.id := mem_arb.io.chosen\n1068:   io.mem.req.bits.hptw_bypassed
      := false.B\n1069:   mem_arb.io.out.ready := io.mem.req.ready\n1070:   val mem_refill_id
      = RegNext(io.mem.resp.bits.id(log2Up(l2tlbParams.llptwsize)-1, 0))\n1071:  \
      \ io.mem.refill := entries(mem_refill_id).req_info\n1072:   io.mem.refill.s2xlate
      := entries(mem_refill_id).req_info.s2xlate\n1073:   io.mem.buffer_it := mem_resp_hit\n\
      1074:   io.mem.enq_ptr := enq_ptr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1076-1086
    context: "1076:   io.cache.valid := Cat(is_cache).orR\n1077:   io.cache.bits :=
      ParallelMux(is_cache, entries.map(_.req_info))\n1078: \n1079:   val has_bitmap_resp
      = ParallelOR(is_bitmap_resp).asBool\n1080:   if (HasBitmapCheck) {\n1081:  \
      \   io.bitmap.get.req.valid := bitmap_arb.get.io.out.valid && !flush\n1082:\
      \     io.bitmap.get.req.bits.bmppn := bitmap_arb.get.io.out.bits.bmppn\n1083:\
      \     io.bitmap.get.req.bits.id := bitmap_arb.get.io.chosen\n1084:     io.bitmap.get.req.bits.vpn
      := bitmap_arb.get.io.out.bits.vpn\n1085:     io.bitmap.get.req.bits.level :=
      0.U\n1086:     io.bitmap.get.req.bits.way_info := bitmap_arb.get.io.out.bits.way_info"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1083-1100
    context: "1083:     io.bitmap.get.req.bits.id := bitmap_arb.get.io.chosen\n1084:\
      \     io.bitmap.get.req.bits.vpn := bitmap_arb.get.io.out.bits.vpn\n1085:  \
      \   io.bitmap.get.req.bits.level := 0.U\n1086:     io.bitmap.get.req.bits.way_info
      := bitmap_arb.get.io.out.bits.way_info\n1087:     io.bitmap.get.req.bits.hptw_bypassed
      := bitmap_arb.get.io.out.bits.hptw_bypassed\n1088:     bitmap_arb.get.io.out.ready
      := io.bitmap.get.req.ready\n1089:     io.bitmap.get.resp.ready := has_bitmap_resp\n\
      1090:   }\n1091: \n1092:   XSPerfAccumulate(\"llptw_in_count\", io.in.fire)\n\
      1093:   XSPerfAccumulate(\"llptw_in_block\", io.in.valid && !io.in.ready)\n\
      1094:   for (i <- 0 until 7) {\n1095:     XSPerfAccumulate(s\"enq_state${i}\"\
      , io.in.fire && enq_state === i.U)\n1096:   }\n1097:   for (i <- 0 until (l2tlbParams.llptwsize
      + 1)) {\n1098:     XSPerfAccumulate(s\"util${i}\", PopCount(is_emptys.map(!_))
      === i.U)\n1099:     XSPerfAccumulate(s\"mem_util${i}\", PopCount(is_mems) ===
      i.U)\n1100:     XSPerfAccumulate(s\"waiting_util${i}\", PopCount(is_waiting)
      === i.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1097-1114
    context: "1097:   for (i <- 0 until (l2tlbParams.llptwsize + 1)) {\n1098:    \
      \ XSPerfAccumulate(s\"util${i}\", PopCount(is_emptys.map(!_)) === i.U)\n1099:\
      \     XSPerfAccumulate(s\"mem_util${i}\", PopCount(is_mems) === i.U)\n1100:\
      \     XSPerfAccumulate(s\"waiting_util${i}\", PopCount(is_waiting) === i.U)\n\
      1101:   }\n1102:   XSPerfAccumulate(\"mem_count\", io.mem.req.fire)\n1103: \
      \  XSPerfAccumulate(\"mem_cycle\", PopCount(is_waiting) =/= 0.U)\n1104:   XSPerfAccumulate(\"\
      blocked_in\", io.in.valid && !io.in.ready)\n1105: \n1106:   val perfEvents =
      Seq(\n1107:     (\"tlbllptw_incount           \", io.in.fire               ),\n\
      1108:     (\"tlbllptw_inblock           \", io.in.valid && !io.in.ready),\n\
      1109:     (\"tlbllptw_memcount          \", io.mem.req.fire          ),\n1110:\
      \     (\"tlbllptw_memcycle          \", PopCount(is_waiting)       ),\n1111:\
      \   )\n1112:   generatePerfEvent()\n1113: }\n1114: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1168-1178
    context: "1168: class HPTW()(implicit p: Parameters) extends XSModule with HasPtwConst
      {\n1169:   val io = IO(new HPTWIO)\n1170:   val hgatp = io.csr.hgatp\n1171:\
      \   val mpbmte = io.csr.mPBMTE\n1172:   val sfence = io.sfence\n1173:   val
      flush = sfence.valid || hgatp.changed || io.csr.satp.changed || io.csr.vsatp.changed
      || io.csr.priv.virt_changed\n1174:   val mode = hgatp.mode\n1175: \n1176:  \
      \ // mbmc:bitmap csr\n1177:   val mbmc = io.csr.mbmc\n1178:   val bitmap_enable
      = (if (HasBitmapCheck) true.B else false.B) && mbmc.BME === 1.U && mbmc.CMODE
      === 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1186-1198
    context: "1186:   val l3Hit = Reg(Bool())\n1187:   val l2Hit = Reg(Bool())\n1188:\
      \   val l1Hit = Reg(Bool())\n1189:   val bypassed = Reg(Bool())\n1190: //  val
      pte = io.mem.resp.bits.MergeRespToPte()\n1191:   val jmp_bitmap_check = if (HasBitmapCheck)
      RegEnable(io.req.bits.bitmapCheck.get.jmp_bitmap_check, io.req.fire) else false.B\n\
      1192:   val fromSP = if (HasBitmapCheck) RegEnable(io.req.bits.bitmapCheck.get.fromSP,
      io.req.fire) else false.B\n1193:   val cache_pte = Option.when(HasBitmapCheck)(RegEnable(Mux(io.req.bits.bitmapCheck.get.fromSP,
      io.req.bits.bitmapCheck.get.pte.asTypeOf(new PteBundle().cloneType), io.req.bits.bitmapCheck.get.ptes(io.req.bits.gvpn(sectortlbwidth
      - 1, 0)).asTypeOf(new PteBundle().cloneType)), io.req.fire))\n1194:   val pte
      = if (HasBitmapCheck) Mux(jmp_bitmap_check, cache_pte.get, io.mem.resp.bits.asTypeOf(new
      PteBundle().cloneType)) else io.mem.resp.bits.asTypeOf(new PteBundle().cloneType)\n\
      1195:   val ppn_l3 = Mux(l3Hit, req_ppn, pte.ppn)\n1196:   val ppn_l2 = Mux(l2Hit,
      req_ppn, pte.ppn)\n1197:   val ppn_l1 = Mux(l1Hit, req_ppn, pte.ppn)\n1198:\
      \   val ppn = Wire(UInt(PAddrBits.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1227-1237
    context: "1227:   val whether_need_bitmap_check = RegInit(false.B)\n1228:   val
      bitmap_checkfailed = RegInit(false.B)\n1229: \n1230:   val sent_to_pmp = !idle
      && (!s_pmp_check || mem_addr_update) && !finish\n1231:   val pageFault = pte.isGpf(level,
      mpbmte) || (!pte.isLeaf() && level === 0.U)\n1232:   val accessFault = RegEnable(io.pmp.resp.ld
      || io.pmp.resp.mmio, sent_to_pmp)\n1233: \n1234:   // use access fault when
      bitmap check failed\n1235:   val ppn_af = if (HasBitmapCheck) {\n1236:     Mux(bitmap_enable,
      pte.isAf() || bitmap_checkfailed, pte.isAf())\n1237:   } else {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1239-1251
    context: "1239:   }\n1240:   val find_pte = pte.isLeaf() || ppn_af || pageFault\n\
      1241: \n1242:   val resp_valid = !idle && mem_addr_update && ((w_mem_resp &&
      find_pte) || (s_pmp_check && accessFault))\n1243:   val id = Reg(UInt(log2Up(l2tlbParams.llptwsize).W))\n\
      1244:   val source = RegEnable(io.req.bits.source, io.req.fire)\n1245: \n1246:\
      \   io.req.ready := idle\n1247:   val resp = Wire(new HptwResp())\n1248:   //
      accessFault > pageFault > ppn_af\n1249:   resp.apply(\n1250:     gpf = pageFault
      && !accessFault,\n1251:     gaf = accessFault || (ppn_af && !pageFault),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1260-1275
    context: "1260:   io.resp.bits.source := source\n1261: \n1262:   io.pmp.req.valid
      := DontCare\n1263:   io.pmp.req.bits.addr := mem_addr\n1264:   io.pmp.req.bits.size
      := 3.U\n1265:   io.pmp.req.bits.cmd := TlbCmd.read\n1266: \n1267:   if (HasBitmapCheck)
      {\n1268:     val way_info = DataHoldBypass(io.l0_way_info.get, RegNext(io.mem.resp.fire,
      init=false.B))\n1269:     val cache_hitway = RegEnable(io.req.bits.bitmapCheck.get.hitway,
      io.req.fire)\n1270:     val cache_level = RegEnable(io.req.bits.bitmapCheck.get.SPlevel,
      io.req.fire)\n1271:     io.bitmap.get.req.valid := !s_bitmap_check\n1272:  \
      \   io.bitmap.get.req.bits.bmppn := pte.ppn\n1273:     io.bitmap.get.req.bits.id
      := HptwReqId.U(bMemID.W)\n1274:     io.bitmap.get.req.bits.vpn := vpn\n1275:\
      \     io.bitmap.get.req.bits.level := Mux(jmp_bitmap_check, Mux(fromSP,cache_level,0.U),
      level)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1273-1283
    context: "1273:     io.bitmap.get.req.bits.id := HptwReqId.U(bMemID.W)\n1274:\
      \     io.bitmap.get.req.bits.vpn := vpn\n1275:     io.bitmap.get.req.bits.level
      := Mux(jmp_bitmap_check, Mux(fromSP,cache_level,0.U), level)\n1276:     io.bitmap.get.req.bits.way_info
      := Mux(jmp_bitmap_check, cache_hitway, way_info)\n1277:     io.bitmap.get.req.bits.hptw_bypassed
      := bypassed\n1278:     io.bitmap.get.resp.ready := !w_bitmap_resp\n1279:   }\n\
      1280: \n1281:   io.mem.req.valid := !s_mem_req && !io.mem.mask && !accessFault
      && s_pmp_check\n1282:   io.mem.req.bits.addr := mem_addr\n1283:   io.mem.req.bits.id
      := HptwReqId.U(bMemID.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1288-1298
    context: "1288:   io.refill.req_info.source := source\n1289:   io.refill.req_info.s2xlate
      := onlyStage2\n1290: \n1291:   when (idle){\n1292:     if (HasBitmapCheck) {\n\
      1293:       when (io.req.bits.bitmapCheck.get.jmp_bitmap_check && io.req.fire)
      {\n1294:         idle := false.B\n1295:         gpaddr := Cat(io.req.bits.gvpn,
      0.U(offLen.W))\n1296:         s_bitmap_check := false.B\n1297:         id :=
      io.req.bits.id\n1298:         level := Mux(io.req.bits.bitmapCheck.get.fromSP,
      io.req.bits.bitmapCheck.get.SPlevel, 0.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1296-1306
    context: "1296:         s_bitmap_check := false.B\n1297:         id := io.req.bits.id\n\
      1298:         level := Mux(io.req.bits.bitmapCheck.get.fromSP, io.req.bits.bitmapCheck.get.SPlevel,
      0.U)\n1299:       }\n1300:     }\n1301:     when (io.req.fire && (if (HasBitmapCheck)
      !io.req.bits.bitmapCheck.get.jmp_bitmap_check else true.B)) {\n1302:       bypassed
      := io.req.bits.bypassed\n1303:       idle := false.B\n1304:       gpaddr :=
      Cat(io.req.bits.gvpn, 0.U(offLen.W))\n1305:       accessFault := false.B\n1306:\
      \       s_pmp_check := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1342-1357
    context: "1342:       whether_need_bitmap_check := false.B\n1343:       bitmap_checkfailed
      := false.B\n1344:     }\n1345:   }\n1346: \n1347:   when(io.mem.req.fire){\n\
      1348:     s_mem_req := true.B\n1349:     w_mem_resp := false.B\n1350:   }\n\
      1351: \n1352:   when(io.mem.resp.fire && !w_mem_resp){\n1353:     w_mem_resp
      := true.B\n1354:     af_level := af_level - 1.U\n1355:     if (HasBitmapCheck)
      {\n1356:       when (bitmap_enable) {\n1357:         whether_need_bitmap_check
      := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1373-1387
    context: "1373:         mem_addr_update := true.B\n1374:         whether_need_bitmap_check
      := false.B\n1375:       }\n1376:     }\n1377:     // bitmapcheck\n1378:    \
      \ when (io.bitmap.get.req.fire) {\n1379:       s_bitmap_check := true.B\n1380:\
      \       w_bitmap_resp := false.B\n1381:     }\n1382:     when (io.bitmap.get.resp.fire)
      {\n1383:       w_bitmap_resp := true.B\n1384:       mem_addr_update := true.B\n\
      1385:       bitmap_checkfailed := io.bitmap.get.resp.bits.cf\n1386:     }\n\
      1387:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1390-1400
    context: "1390:     when(!(find_pte || accessFault)){\n1391:       level := levelNext\n\
      1392:       s_mem_req := false.B\n1393:       mem_addr_update := false.B\n1394:\
      \     }.elsewhen(resp_valid){\n1395:       when(io.resp.fire){\n1396:      \
      \   idle := true.B\n1397:         mem_addr_update := false.B\n1398:        \
      \ accessFault := false.B\n1399:       }\n1400:       finish := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 1398-1408
    context: "1398:         accessFault := false.B\n1399:       }\n1400:       finish
      := true.B\n1401:     }\n1402:   }\n1403:   when (flush) {\n1404:     idle :=
      true.B\n1405:     s_pmp_check := true.B\n1406:     s_mem_req := true.B\n1407:\
      \     w_mem_resp := true.B\n1408:     accessFault := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 101-111
    context: "101: \n102:   val io = IO(new bitmapIO)\n103: \n104:   val csr = io.csr\n\
      105:   val sfence = io.sfence\n106:   val flush = sfence.valid || csr.satp.changed
      || csr.vsatp.changed || csr.hgatp.changed || csr.priv.virt_changed\n107:   val
      bitmap_base = csr.mbmc.BMA << 6\n108: \n109:   val entries = Reg(Vec(l2tlbParams.llptwsize+2,
      new bitmapEntry()))\n110:   // add pmp check\n111:   val state_idle :: state_addr_check
      :: state_cache_req :: state_cache_resp  ::state_mem_req :: state_mem_waiting
      :: state_mem_out :: Nil = Enum(7)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 107-124
    context: "107:   val bitmap_base = csr.mbmc.BMA << 6\n108: \n109:   val entries
      = Reg(Vec(l2tlbParams.llptwsize+2, new bitmapEntry()))\n110:   // add pmp check\n\
      111:   val state_idle :: state_addr_check :: state_cache_req :: state_cache_resp\
      \  ::state_mem_req :: state_mem_waiting :: state_mem_out :: Nil = Enum(7)\n\
      112:   val state = RegInit(VecInit(Seq.fill(l2tlbParams.llptwsize+2)(state_idle)))\n\
      113: \n114:   val is_emptys = state.map(_ === state_idle)\n115:   val is_cache_req
      = state.map (_ === state_cache_req)\n116:   val is_cache_resp = state.map (_
      === state_cache_resp)\n117:   val is_mems = state.map(_ === state_mem_req)\n\
      118:   val is_waiting = state.map(_ === state_mem_waiting)\n119:   val is_having
      = state.map(_ === state_mem_out)\n120: \n121:   val full = !ParallelOR(is_emptys).asBool\n\
      122:   val waiting = ParallelOR(is_waiting).asBool\n123:   val enq_ptr = ParallelPriorityEncoder(is_emptys)\n\
      124: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 144-159
    context: "144:     cache_req_arb.io.in(i).valid := is_cache_req(i)\n145:     cache_req_arb.io.in(i).bits.tag
      := entries(i).ppn\n146:     cache_req_arb.io.in(i).bits.order := i.U;\n147:\
      \   }\n148: \n149:   val dup_vec = state.indices.map(i =>\n150:     dupBitmapPPN(io.req.bits.bmppn,
      entries(i).ppn)\n151:   )\n152:   val dup_req_fire = mem_arb.io.out.fire &&
      dupBitmapPPN(io.req.bits.bmppn, mem_arb.io.out.bits.ppn)\n153:   val dup_vec_wait
      = dup_vec.zip(is_waiting).map{case (d, w) => d && w}\n154:   val dup_wait_resp
      = io.mem.resp.fire && VecInit(dup_vec_wait)(io.mem.resp.bits.id - (l2tlbParams.llptwsize
      + 2).U)\n155:   val wait_id = Mux(dup_req_fire, mem_arb.io.chosen, ParallelMux(dup_vec_wait
      zip entries.map(_.wait_id)))\n156: \n157:   val to_wait = Cat(dup_vec_wait).orR
      || dup_req_fire\n158:   val to_mem_out = dup_wait_resp\n159: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 162-181
    context: "162:     to_wait -> state_mem_waiting\n163:   ))\n164:   val enq_state
      =  enq_state_normal\n165:   val enq_ptr_reg = RegNext(enq_ptr)\n166: \n167:\
      \   val need_addr_check = RegNext(enq_state === state_addr_check && io.req.fire
      && !flush)\n168: \n169:   io.pmp.req.valid := need_addr_check\n170:   io.pmp.req.bits.addr
      := RegEnable(getBitmapAddr(io.req.bits.bmppn),io.req.fire)\n171:   io.pmp.req.bits.cmd
      := TlbCmd.read\n172:   io.pmp.req.bits.size := 3.U\n173:   val pmp_resp_valid
      = io.pmp.req.valid\n174: \n175:   when (io.req.fire) {\n176:     state(enq_ptr)
      := enq_state\n177:     entries(enq_ptr).ppn := io.req.bits.bmppn\n178:     entries(enq_ptr).vpn
      := io.req.bits.vpn\n179:     entries(enq_ptr).id := io.req.bits.id\n180:   \
      \  entries(enq_ptr).wait_id := Mux(to_wait, wait_id, enq_ptr)\n181:     entries(enq_ptr).cf
      := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 189-199
    context: "189:   }\n190: \n191:   // when pmp check failed, use cf bit represent\n\
      192:   when (pmp_resp_valid) {\n193:     val ptr = enq_ptr_reg\n194:     val
      accessFault = io.pmp.resp.ld || io.pmp.resp.mmio\n195:     entries(ptr).cf :=
      accessFault\n196:     for (i <- 0 until tlbcontiguous) {\n197:       entries(ptr).cfs(i)
      := accessFault\n198:     }\n199:     // firstly req bitmap cache"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 195-233
    context: "195:     entries(ptr).cf := accessFault\n196:     for (i <- 0 until
      tlbcontiguous) {\n197:       entries(ptr).cfs(i) := accessFault\n198:     }\n\
      199:     // firstly req bitmap cache\n200:     state(ptr) := Mux(accessFault,
      state_mem_out, state_cache_req)\n201:   }\n202: \n203:   val cache_wait = ParallelOR(is_cache_resp).asBool\n\
      204:   io.cache.resp.ready := !flush && cache_wait\n205: \n206:   val hit =
      WireInit(false.B)\n207:   io.cache.req.valid := cache_req_arb.io.out.valid &&
      !flush\n208:   io.cache.req.bits.tag := cache_req_arb.io.out.bits.tag\n209:\
      \   io.cache.req.bits.order := cache_req_arb.io.out.bits.order\n210:   cache_req_arb.io.out.ready
      := io.cache.req.ready\n211: \n212: \n213:   when (cache_req_arb.io.out.fire)
      {\n214:     for (i <- state.indices) {\n215:       when (state(i) === state_cache_req
      && cache_req_arb.io.chosen === i.U) {\n216:         state(i) := state_cache_resp\n\
      217:       }\n218:     }\n219:   }\n220: \n221:   when (io.cache.resp.fire)
      {\n222:     for (i <- state.indices) {\n223:       val cm_dup_vec = state.indices.map(j
      =>\n224:         dupBitmapPPN(entries(i).ppn, entries(j).ppn)\n225:       )\n\
      226:       val cm_dup_req_fire = mem_arb.io.out.fire && dupBitmapPPN(entries(i).ppn,
      mem_arb.io.out.bits.ppn)\n227:       val cm_dup_vec_wait = cm_dup_vec.zip(is_waiting).map{case
      (d, w) => d && w}\n228:       val cm_dup_wait_resp = io.mem.resp.fire && VecInit(cm_dup_vec_wait)(io.mem.resp.bits.id
      - (l2tlbParams.llptwsize + 2).U)\n229:       val cm_wait_id = Mux(cm_dup_req_fire,
      mem_arb.io.chosen, ParallelMux(cm_dup_vec_wait zip entries.map(_.wait_id)))\n\
      230:       val cm_to_wait = Cat(cm_dup_vec_wait).orR || cm_dup_req_fire\n231:\
      \       val cm_to_mem_out = cm_dup_wait_resp\n232:       val cm_next_state_normal
      = MuxCase(state_mem_req, Seq(\n233:         cm_to_mem_out -> state_mem_out,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 231-241
    context: "231:       val cm_to_mem_out = cm_dup_wait_resp\n232:       val cm_next_state_normal
      = MuxCase(state_mem_req, Seq(\n233:         cm_to_mem_out -> state_mem_out,\n\
      234:         cm_to_wait -> state_mem_waiting\n235:       ))\n236:       when
      (state(i) === state_cache_resp && io.cache.resp.bits.order === i.U) {\n237:\
      \           hit := io.cache.resp.bits.hit\n238:           when (hit) {\n239:\
      \             entries(i).cf := io.cache.resp.bits.cfs(entries(i).ppn(5,0))\n\
      240:             entries(i).hit := true.B\n241:             entries(i).cfs :=
      io.cache.resp.bits.cfs"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 237-249
    context: "237:           hit := io.cache.resp.bits.hit\n238:           when (hit)
      {\n239:             entries(i).cf := io.cache.resp.bits.cfs(entries(i).ppn(5,0))\n\
      240:             entries(i).hit := true.B\n241:             entries(i).cfs :=
      io.cache.resp.bits.cfs\n242:             state(i) := state_mem_out\n243:   \
      \        } .otherwise {\n244:             state(i) := cm_next_state_normal\n\
      245:             entries(i).wait_id := Mux(cm_to_wait, cm_wait_id, entries(i).wait_id)\n\
      246:             entries(i).hit := cm_to_wait\n247:           }\n248:      \
      \ }\n249:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 247-260
    context: "247:           }\n248:       }\n249:     }\n250:   }\n251: \n252:  \
      \ when (mem_arb.io.out.fire) {\n253:     for (i <- state.indices) {\n254:  \
      \     when (state(i) === state_mem_req && dupBitmapPPN(entries(i).ppn, mem_arb.io.out.bits.ppn))
      {\n255:         state(i) := state_mem_waiting\n256:         entries(i).wait_id
      := mem_arb.io.chosen\n257:       }\n258:     }\n259:   }\n260: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 256-269
    context: "256:         entries(i).wait_id := mem_arb.io.chosen\n257:       }\n\
      258:     }\n259:   }\n260: \n261:   when (io.mem.resp.fire) {\n262:     state.indices.map{i
      =>\n263:       when (state(i) === state_mem_waiting && io.mem.resp.bits.id ===
      entries(i).wait_id + (l2tlbParams.llptwsize + 2).U) {\n264:         state(i)
      := state_mem_out\n265:         val index = getBitmapAddr(entries(i).ppn)(log2Up(l2tlbParams.blockBytes)-1,
      log2Up(XLEN/8))\n266:         entries(i).data := bitmapdata(index)\n267:   \
      \      entries(i).cf := bitmapdata(index)(entries(i).ppn(5,0))\n268:       \
      \  val ppnPart = entries(i).ppn(5,3)\n269:         val start = (ppnPart << 3.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 275-293
    context: "275:         }\n276:       }\n277:     }\n278:   }\n279: \n280:   when
      (io.resp.fire) {\n281:     state(mem_ptr) := state_idle\n282:   }\n283: \n284:\
      \   when (flush) {\n285:     state.map(_ := state_idle)\n286:   }\n287: \n288:\
      \   io.req.ready := !full\n289: \n290:   io.resp.valid := ParallelOR(is_having).asBool\n\
      291:   // if cache hit, resp the cache's resp\n292:   io.resp.bits.cf := entries(mem_ptr).cf\n\
      293:   io.resp.bits.cfs := entries(mem_ptr).cfs"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 291-306
    context: "291:   // if cache hit, resp the cache's resp\n292:   io.resp.bits.cf
      := entries(mem_ptr).cf\n293:   io.resp.bits.cfs := entries(mem_ptr).cfs\n294:\
      \   io.resp.bits.id := entries(mem_ptr).id\n295: \n296:   io.mem.req.valid :=
      mem_arb.io.out.valid && !flush\n297:   io.mem.req.bits.addr := getBitmapAddr(mem_arb.io.out.bits.ppn)\n\
      298:   io.mem.req.bits.id := mem_arb.io.chosen + (l2tlbParams.llptwsize + 2).U\n\
      299:   mem_arb.io.out.ready := io.mem.req.ready\n300: \n301:   io.mem.resp.ready
      := waiting\n302: \n303:   io.mem.req.bits.hptw_bypassed := false.B\n304: \n\
      305:   io.wakeup.valid := io.resp.valid && !entries(mem_ptr).hptw_bypassed\n\
      306:   io.wakeup.bits.setIndex := genPtwL0SetIdx(entries(mem_ptr).vpn)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 313-324
    context: "313:   // when don't hit, refill the data to bitmap cache\n314:   io.refill.valid
      := io.resp.valid && !entries(mem_ptr).hit\n315:   io.refill.bits.tag := entries(mem_ptr).ppn\n\
      316:   io.refill.bits.data := entries(mem_ptr).data\n317: \n318:   XSPerfAccumulate(\"\
      bitmap_req\", io.req.fire)\n319:   XSPerfAccumulate(\"bitmap_mem_req\", io.mem.req.fire)\n\
      320: }\n321: \n322: // add bitmap cache\n323: class bitmapCacheReqBundle(implicit
      p: Parameters) extends PtwBundle{\n324:   val order = UInt((l2tlbParams.llptwsize
      + 2).W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 359-369
    context: "359: class BitmapCache(implicit p: Parameters) extends XSModule with
      HasPtwConst {\n360:   val io = IO(new bitmapCacheIO)\n361: \n362:   val csr
      = io.csr\n363:   val sfence = io.sfence\n364:   val flush = sfence.valid ||
      csr.satp.changed || csr.vsatp.changed || csr.hgatp.changed || csr.priv.virt_changed\n\
      365:   val bitmap_cache_clear = csr.mbmc.BCLEAR\n366: \n367:   val bitmapCachesize
      = 16\n368:   val bitmapcache = Reg(Vec(bitmapCachesize,new bitmapCacheEntry()))\n\
      369:   val bitmapReplace = ReplacementPolicy.fromString(l2tlbParams.l3Replacer,
      bitmapCachesize)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 375-388
    context: "375:   val hitVecT = bitmapcache.map(_.hit(addr_search))\n376: \n377:\
      \   // -----\n378:   // -S1--\n379:   // -----\n380:   val index = RegEnable(addr_search(log2Up(XLEN)-1,0),
      io.req.fire)\n381:   val order = RegEnable(io.req.bits.order, io.req.fire)\n\
      382:   val hitVec = RegEnable(VecInit(hitVecT), io.req.fire)\n383:   val CacheData
      = RegEnable(ParallelPriorityMux(hitVecT zip bitmapcache.map(_.data)), io.req.fire)\n\
      384:   val cfs = Wire(Vec(tlbcontiguous, Bool()))\n385: \n386:   val start =
      (index(5, 3) << 3.U)\n387:   val end = start + 7.U\n388:   val mask = (1.U <<
      8) - 1.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 394-408
    context: "394: \n395:   val resp_res = Wire(new bitmapCacheRespBundle())\n396:\
      \   resp_res.apply(hit,cfs,order)\n397: \n398:   val resp_valid_reg = RegInit(false.B)\n\
      399:   when (flush) {\n400:     resp_valid_reg := false.B\n401:   } .elsewhen(io.req.fire)
      {\n402:     resp_valid_reg := true.B\n403:   } .elsewhen(io.resp.fire) {\n404:\
      \     resp_valid_reg := false.B\n405:   } .otherwise {\n406:     resp_valid_reg
      := resp_valid_reg\n407:   }\n408: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 404-418
    context: "404:     resp_valid_reg := false.B\n405:   } .otherwise {\n406:    \
      \ resp_valid_reg := resp_valid_reg\n407:   }\n408: \n409:   io.req.ready :=
      !resp_valid_reg || io.resp.fire\n410:   io.resp.valid := resp_valid_reg\n411:\
      \   io.resp.bits := resp_res\n412: \n413:   when (!flush && hit && io.resp.fire)
      {\n414:     bitmapReplace.access(OHToUInt(hitVec))\n415:   }\n416: \n417:  \
      \ // -----\n418:   // refill"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 418-428
    context: "418:   // refill\n419:   // -----\n420:   val rf_addr = io.refill.bits.tag\n\
      421:   val rf_data = io.refill.bits.data\n422:   val rf_vd = io.refill.valid\n\
      423:   when (!flush && rf_vd) {\n424:     val refillindex = bitmapReplace.way\n\
      425:     dontTouch(refillindex)\n426:     bitmapcache(refillindex).refill(rf_addr,rf_data,true.B)\n\
      427:     bitmapReplace.access(refillindex)\n428:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 425-435
    context: "425:     dontTouch(refillindex)\n426:     bitmapcache(refillindex).refill(rf_addr,rf_data,true.B)\n\
      427:     bitmapReplace.access(refillindex)\n428:   }\n429:   when (bitmap_cache_clear
      === 1.U) {\n430:     bitmapcache.foreach(_.valid := false.B)\n431:   }\n432:\
      \ \n433:   XSPerfAccumulate(\"bitmap_cache_resp\", io.resp.fire)\n434:   XSPerfAccumulate(\"\
      bitmap_cache_resp_miss\", io.resp.fire && !io.resp.bits.hit)\n435: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/wpu/WPUWrapper.scala
    lines: 70-80
    context: "70: \n71: class DwpuBaseIO(nWays:Int, nPorts: Int)(implicit p:Parameters)
      extends BaseWPUBundle{\n72:   val req = Vec(nPorts, Flipped(Decoupled(new WPUReplayedReq(nWays))))\n\
      73:   val resp = Vec(nPorts, ValidIO(new WPUResp(nWays)))\n74:   val lookup_upd
      = Vec(nPorts, Flipped(ValidIO(new WPUUpdateLookup(nWays))))\n75:   val cfpred
      = Vec(nPorts, new ConflictPredictIO(nWays))\n76: }\n77: \n78: class DwpuIO(nWays:Int,
      nPorts:Int)(implicit p:Parameters) extends DwpuBaseIO(nWays, nPorts){\n79: \
      \  val tagwrite_upd = Flipped(ValidIO(new WPUUpdate(nWays)))\n80: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/wpu/WPUWrapper.scala
    lines: 129-139
    context: "129: \n130:     // replace / tag write\n131:     wpu.io.updTagwrite(i)
      := DontCare\n132: \n133:     /** predict and response in s0 */\n134:     io.req(i).ready
      := true.B\n135:     if (dwpuParam.enWPU) {\n136:       io.resp(i).valid := io.req(i).valid\n\
      137:     } else {\n138:       io.resp(i).valid := false.B\n139:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/wpu/WPUWrapper.scala
    lines: 157-169
    context: "157:   /* selective direct mapping */\n158:   if(dwpuParam.enCfPred){\n\
      159:     val wayConflictPredictor = Module(new WayConflictPredictor(nPorts))\n\
      160:     val s0_pred_way_conflict = Wire(Vec(nPorts, Bool()))\n161:     for(i
      <- 0 until nPorts){\n162:       wayConflictPredictor.io.pred(i).en := io.req(i).valid\n\
      163:       wayConflictPredictor.io.pred(i).vaddr := io.cfpred(i).s0_vaddr\n\
      164:       s0_pred_way_conflict(i) := wayConflictPredictor.io.pred(i).way_conflict\n\
      165:       when(!s0_pred_way_conflict(i)) {\n166:         s0_pred_way_en(i)
      := UIntToOH(get_direct_map_way(io.req(i).bits.vaddr))\n167:         s0_dmSel(i)
      := true.B\n168:       }\n169:       wayConflictPredictor.io.update(i).en :=
      io.lookup_upd(i).valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/wpu/WPUWrapper.scala
    lines: 165-176
    context: "165:       when(!s0_pred_way_conflict(i)) {\n166:         s0_pred_way_en(i)
      := UIntToOH(get_direct_map_way(io.req(i).bits.vaddr))\n167:         s0_dmSel(i)
      := true.B\n168:       }\n169:       wayConflictPredictor.io.update(i).en :=
      io.lookup_upd(i).valid\n170:       wayConflictPredictor.io.update(i).vaddr :=
      io.cfpred(i).s1_vaddr\n171:       wayConflictPredictor.io.update(i).dm_hit :=
      s1_dmSel(i) && io.cfpred(i).s1_dm_hit\n172:       wayConflictPredictor.io.update(i).sa_hit
      := !s1_dmSel(i) && s1_hit(i)\n173:     }\n174:     XSPerfAccumulate(\"wpu_pred_from_prediction\"\
      , PopCount((0 until nPorts).map(i => io.req(i).valid && !io.req(i).bits.replayCarry.valid
      && s0_pred_way_conflict(i))))\n175:     XSPerfAccumulate(\"wpu_pred_from_directMap\"\
      , PopCount((0 until nPorts).map(i => io.req(i).valid && !io.req(i).bits.replayCarry.valid
      && !s0_pred_way_conflict(i))))\n176:     // dm situation"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/wpu/WPUWrapper.scala
    lines: 173-183
    context: "173:     }\n174:     XSPerfAccumulate(\"wpu_pred_from_prediction\",
      PopCount((0 until nPorts).map(i => io.req(i).valid && !io.req(i).bits.replayCarry.valid
      && s0_pred_way_conflict(i))))\n175:     XSPerfAccumulate(\"wpu_pred_from_directMap\"\
      , PopCount((0 until nPorts).map(i => io.req(i).valid && !io.req(i).bits.replayCarry.valid
      && !s0_pred_way_conflict(i))))\n176:     // dm situation\n177:     XSPerfAccumulate(\"\
      direct_map_all\", PopCount((0 until nPorts).map(i => io.lookup_upd(i).valid)))\n\
      178:     XSPerfAccumulate(\"direct_map_ok\", PopCount((0 until nPorts).map(i
      => io.lookup_upd(i).valid && io.cfpred(i).s1_dm_hit)))\n179:   }\n180: }\n181:\
      \ \n182: \n183: class ICacheWpuWrapper (nPorts: Int) (implicit p:Parameters)
      extends WPUModule with HasICacheParameters {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/wpu/WPUWrapper.scala
    lines: 192-202
    context: "192:   for (i <- 0 until nPorts){\n193:     wpu.io.predVec(i).en :=
      io.req(i).valid\n194:     wpu.io.predVec(i).vaddr := io.req(i).bits.vaddr\n\
      195:     s0_pred_way_en(i) := wpu.io.predVec(i).way_en\n196:     // io\n197:\
      \     io.req(i).ready := true.B\n198:     if (iwpuParam.enWPU) {\n199:     \
      \  io.resp(i).valid := io.req(i).valid\n200:     } else {\n201:       io.resp(i).valid
      := false.B\n202:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/wpu/WPUWrapper.scala
    lines: 215-227
    context: "215:     // which will update in look up pred fail\n216:     wpu.io.updReplaycarry
      := DontCare\n217:     // replace / tag write\n218:     wpu.io.updTagwrite :=
      DontCare\n219:   }\n220:   wpu.io.updTagwrite.head.en := io.tagwrite_upd.valid\n\
      221:   wpu.io.updTagwrite.head.vaddr := io.tagwrite_upd.bits.vaddr\n222:   wpu.io.updTagwrite.head.way_en
      := io.tagwrite_upd.bits.s1_real_way_en\n223: \n224:   XSPerfAccumulate(\"wpu_pred_total\"\
      , PopCount((0 until nPorts).map{i => RegNext(io.req(i).valid) && io.lookup_upd(i).valid}))\n\
      225:   XSPerfAccumulate(\"wpu_pred_succ\",  PopCount((0 until nPorts).map{i
      => RegNext(io.req(i).valid) && io.lookup_upd(i).valid && !s1_pred_fail(i)}))\n\
      226:   XSPerfAccumulate(\"wpu_pred_fail\",  PopCount((0 until nPorts).map{i
      => RegNext(io.req(i).valid) && io.lookup_upd(i).valid && s1_pred_fail(i)}))\n\
      227:   XSPerfAccumulate(\"wpu_pred_miss\",  PopCount((0 until nPorts).map{i
      => RegNext(io.req(i).valid) && io.lookup_upd(i).valid && !RegNext(s0_pred_way_en(i)).orR}))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/wpu/WPU.scala
    lines: 9-19
    context: "9: \n10: /*\n11: // TODO: need to learn the specific grammar\n12: abstract
      class WPUBaseModule[T <: Data](implicit P: Parameters) extends XSModule with
      HasWPUParameters{\n13:   def apply[T <: Data]\n14:   def pred(vaddr: UInt, en:
      Bool) : T\n15:   def update(vaddr: UInt, data: T ,en: Bool)\n16: }\n17: */\n\
      18: \n19: case object WPUParamsKey extends Field[WPUParameters]"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/wpu/WPU.scala
    lines: 80-109
    context: "80:   }\n81: }\n82: \n83: class MruWPU(wpuParam: WPUParameters, nPorts:
      Int)(implicit p:Parameters) extends BaseWPU(wpuParam, nPorts){\n84:   println(\"\
      \  WpuType: MruWPU\")\n85:   val predict_regs = RegInit(VecInit(Seq.fill(setSize)(0.U(wayBits.W))))\n\
      86: \n87:   def write(upd: BaseWpuUpdateBundle): Unit = {\n88:     when(upd.en)
      {\n89:       val upd_setIdx = get_wpu_idx(upd.vaddr)\n90:       predict_regs(upd_setIdx)
      := OHToUInt(upd.way_en)\n91:     }\n92:   }\n93: \n94:   def predict(pred: BaseWpuPredictIO):
      Unit = {\n95:     val predSetIdx = get_wpu_idx(pred.vaddr)\n96:     when(pred.en)
      {\n97:       pred.way_en := UIntToOH(predict_regs(predSetIdx))\n98:     }.otherwise
      {\n99:       pred.way_en := 0.U(nWays.W)\n100:     }\n101:   }\n102: \n103:\
      \   for(i <- 0 until nPorts){\n104:     predict(io.predVec(i))\n105:     write(io.updLookup(i))\n\
      106:     write(io.updReplaycarry(i))\n107:     write(io.updTagwrite(i))\n108:\
      \   }\n109: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/wpu/WPU.scala
    lines: 109-119
    context: "109: \n110: }\n111: \n112: class MmruWPU(wpuParam: WPUParameters, nPorts:
      Int)(implicit p:Parameters) extends BaseWPU(wpuParam, nPorts){\n113:   println(\"\
      \  WpuType: MmruWPU\")\n114:   val predict_regs = RegInit(VecInit(Seq.fill(setSize)(VecInit(Seq.fill(nTagIdx)(0.U(auxWayBits.W))))))\n\
      115: \n116:   def write(upd: BaseWpuUpdateBundle): Unit = {\n117:     when(upd.en)
      {\n118:       val updSetIdx = get_wpu_idx(upd.vaddr)\n119:       val updTagIdx
      = get_vir_tag(upd.vaddr)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/wpu/WPU.scala
    lines: 115-142
    context: "115: \n116:   def write(upd: BaseWpuUpdateBundle): Unit = {\n117:  \
      \   when(upd.en) {\n118:       val updSetIdx = get_wpu_idx(upd.vaddr)\n119:\
      \       val updTagIdx = get_vir_tag(upd.vaddr)\n120:       predict_regs(updSetIdx)(updTagIdx)
      := OHToUInt(upd.way_en)\n121:     }\n122:   }\n123: \n124:   def predict(pred:
      BaseWpuPredictIO): Unit = {\n125:     val predSetIdx = get_wpu_idx(pred.vaddr)\n\
      126:     val predTagIdx = get_vir_tag(pred.vaddr)\n127:     when(pred.en) {\n\
      128:       //UIntToOH(8.U(4.W))=100000000.U(16.W)=00000000.U(8.W)\n129:    \
      \   //UIntToOH(8.U(4.W), 8)=00000001.U(8.W)\n130:       pred.way_en := UIntToOH(predict_regs(predSetIdx)(predTagIdx))\n\
      131:     }.otherwise {\n132:       pred.way_en := 0.U(nWays.W)\n133:     }\n\
      134:   }\n135: \n136:   for(i <- 0 until nPorts){\n137:     predict(io.predVec(i))\n\
      138:     write(io.updLookup(i))\n139:     write(io.updReplaycarry(i))\n140:\
      \     write(io.updTagwrite(i))\n141:   }\n142: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/wpu/WPU.scala
    lines: 183-197
    context: "183:       val upd_way = OHToUInt(upd.pred_way_en)\n184:       valid_regs(upd_setIdx)(upd_way)
      := false.B\n185:     }\n186:   }\n187: \n188:   def predict(pred: BaseWpuPredictIO):
      Unit = {\n189:     val req_setIdx = get_wpu_idx(pred.vaddr)\n190:     val req_utag
      = get_hash_utag(pred.vaddr)\n191:     val pred_way_en = Wire(UInt(nWays.W))\n\
      192:     when(pred.en) {\n193:       pred_way_en := VecInit((0 until nWays).map(i
      =>\n194:         req_utag === utag_regs(req_setIdx)(i) && valid_regs(req_setIdx)(i)\n\
      195:       )).asUInt\n196:     }.otherwise {\n197:       pred_way_en := 0.U(nWays.W)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/wpu/WPU.scala
    lines: 195-210
    context: "195:       )).asUInt\n196:     }.otherwise {\n197:       pred_way_en
      := 0.U(nWays.W)\n198:     }\n199:     // avoid hash conflict\n200:     pred.way_en
      := UIntToOH(OHToUInt(pred_way_en))\n201:   }\n202: \n203:   val hash_conflict
      = Wire(Vec(nPorts, Bool()))\n204:   for(i <- 0 until nPorts){\n205:     predict(io.predVec(i))\n\
      206:     val real_way_en = io.updLookup(i).way_en\n207:     val pred_way_en
      = io.updLookup(i).pred_way_en\n208:     val pred_miss = io.updLookup(i).en &&
      !pred_way_en.orR\n209:     val real_miss = io.updLookup(i).en && !real_way_en.orR\n\
      210:     val way_match = io.updLookup(i).en && pred_way_en === real_way_en"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/wpu/VictimList.scala
    lines: 44-54
    context: "44:   val sa_hit = Input(Bool())\n45: }\n46: \n47: class WayConflictPredictor
      (nPorts: Int) (implicit p: Parameters) extends WayConflictPredictorModule{\n\
      48:   val io = IO(new Bundle() {\n49:     val pred = Vec(nPorts, new WayConflictPredIO)\n\
      50:     val update = Vec(nPorts, new WayConflictUpdIO)\n51:   })\n52:   val
      PredTable = RegInit(VecInit(Seq.fill(WCPSize)(0.U(CounterSize.W))))\n53: \n\
      54:   for (i <- 0 until nPorts){"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/wpu/VictimList.scala
    lines: 50-60
    context: "50:     val update = Vec(nPorts, new WayConflictUpdIO)\n51:   })\n52:\
      \   val PredTable = RegInit(VecInit(Seq.fill(WCPSize)(0.U(CounterSize.W))))\n\
      53: \n54:   for (i <- 0 until nPorts){\n55:     io.pred(i).way_conflict := io.pred(i).en
      & PredTable(get_addr_idx(io.pred(i).vaddr))(CounterSize-1)\n56:     val ptVal
      = PredTable(get_addr_idx(io.update(i).vaddr))\n57:     when(io.update(i).en
      && io.update(i).sa_hit && ptVal =/= Fill(CounterSize, 1.U)) {\n58:       PredTable(get_addr_idx(io.update(i).vaddr))
      := ptVal + 1.U\n59:     }.elsewhen(io.update(i).en && io.update(i).dm_hit &&
      ptVal =/= Fill(CounterSize, 0.U)) {\n60:       PredTable(get_addr_idx(io.update(i).vaddr))
      := ptVal - 1.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/CacheConstants.scala
    lines: 26-39
    context: "26:   val NUM_XA_OPS = 9\n27:   val M_SZ      = 5\n28:   def M_X   \
      \    = BitPat(\"b?????\")\n29:   def M_XRD     = \"b00000\".U // int load\n\
      30:   def M_XWR     = \"b00001\".U // int store\n31:   def M_PFR     = \"b00010\"\
      .U // prefetch with intent to read\n32:   def M_PFW     = \"b00011\".U // prefetch
      with intent to write\n33:   def M_XA_SWAP = \"b00100\".U\n34:   def M_FLUSH_ALL
      = \"b00101\".U  // flush all lines\n35:   def M_XLR     = \"b00110\".U\n36:\
      \   def M_XSC     = \"b00111\".U\n37:   def M_XA_ADD  = \"b01000\".U\n38:  \
      \ def M_XA_XOR  = \"b01001\".U\n39:   def M_XA_OR   = \"b01010\".U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/CacheConstants.scala
    lines: 40-54
    context: "40:   def M_XA_AND  = \"b01011\".U\n41:   def M_XA_MIN  = \"b01100\"\
      .U\n42:   def M_XA_MAX  = \"b01101\".U\n43:   def M_XA_MINU = \"b01110\".U\n\
      44:   def M_XA_MAXU = \"b01111\".U\n45:   def M_FLUSH   = \"b10000\".U // write
      back dirty data and cede R/W permissions\n46:   def M_PWR     = \"b10001\".U
      // partial (masked.U store\n47:   def M_PRODUCE = \"b10010\".U // write back
      dirty data and cede W permissions\n48:   def M_CLEAN   = \"b10011\".U // write
      back dirty data and retain R/W permissions\n49:   def M_SFENCE  = \"b10100\"\
      .U // flush TLB\n50:   def M_WOK     = \"b10111\".U // check write permissions
      but don't perform a write\n51:   def M_XA_CASQ = \"b11000\".U // AMOCAS.Q\n\
      52:   def M_XA_CASW = \"b11010\".U // AMOCAS.W\n53:   def M_XA_CASD = \"b11011\"\
      .U // AMOCAS.D\n54: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/CacheConstants.scala
    lines: 56-66
    context: "56:   def isAMOArithmetic(cmd: UInt) = cmd === M_XA_ADD || cmd === M_XA_MIN
      || cmd === M_XA_MAX || cmd === M_XA_MINU || cmd === M_XA_MAXU\n57:   def isAMOCAS(cmd:
      UInt) = cmd === M_XA_CASW || cmd === M_XA_CASD || cmd === M_XA_CASQ\n58:   def
      isAMOCASQ(cmd: UInt) = cmd === M_XA_CASQ\n59:   def isAMO(cmd: UInt) = isAMOLogical(cmd)
      || isAMOArithmetic(cmd) || isAMOCAS(cmd)\n60:   def isPrefetch(cmd: UInt) =
      cmd === M_PFR || cmd === M_PFW\n61:   def isRead(cmd: UInt) = cmd === M_XRD
      || cmd === M_XLR || cmd === M_XSC || isAMO(cmd)\n62:   def isWrite(cmd: UInt)
      = cmd === M_XWR || cmd === M_PWR || cmd === M_XSC || isAMO(cmd)\n63:   def isWriteIntent(cmd:
      UInt) = isWrite(cmd) || cmd === M_PFW || cmd === M_XLR\n64: }\n65: \n66: object
      MemoryOpConstants extends MemoryOpConstants"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/CacheInstruction.scala
    lines: 36-46
    context: "36: \n37: object CacheInstrucion{\n38:   def CacheOperation = List(\n\
      39:     CacheOpMap(\"b00000\", \"CHECK\",  \"READ_TAG_ECC\"),\n40:     CacheOpMap(\"\
      b00001\", \"CHECK\",  \"READ_DATA_ECC\"),\n41:     CacheOpMap(\"b00010\", \"\
      LOAD\",   \"READ_TAG\"),\n42:     CacheOpMap(\"b00011\", \"LOAD\",   \"READ_DATA\"\
      ),\n43:     CacheOpMap(\"b00100\", \"STORE\",  \"WRITE_TAG_ECC\"),\n44:    \
      \ CacheOpMap(\"b00101\", \"STORE\",  \"WRITE_DATA_ECC\"),\n45:     CacheOpMap(\"\
      b00110\", \"STORE\",  \"WRITE_TAG\"),\n46:     CacheOpMap(\"b00111\", \"STORE\"\
      ,  \"WRITE_DATA\"),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/CacheInstruction.scala
    lines: 42-52
    context: "42:     CacheOpMap(\"b00011\", \"LOAD\",   \"READ_DATA\"),\n43:    \
      \ CacheOpMap(\"b00100\", \"STORE\",  \"WRITE_TAG_ECC\"),\n44:     CacheOpMap(\"\
      b00101\", \"STORE\",  \"WRITE_DATA_ECC\"),\n45:     CacheOpMap(\"b00110\", \"\
      STORE\",  \"WRITE_TAG\"),\n46:     CacheOpMap(\"b00111\", \"STORE\",  \"WRITE_DATA\"\
      ),\n47:     CacheOpMap(\"b01000\", \"FLUSH\",  \"FLUSH_BLOCK\")\n48:   )\n49:\
      \ \n50:   def CacheInsRegisterList = Map(\n51:     //         offset     width\
      \    authority  name\n52:     CacheRegMap(\"0\",      \"64\",    \"RW\",   \
      \   \"CACHE_OP\"),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/CacheInstruction.scala
    lines: 78-88
    context: "78:   // }}\n79: \n80:   def COP_CHECK = 0.U\n81:   def COP_LOAD  =
      1.U\n82:   def COP_STORE = 2.U\n83:   def COP_FLUSH = 3.U\n84: \n85:   def COP_ID_ICACHE
      = 0\n86:   def COP_ID_DCACHE = 1\n87: \n88:   def COP_RESULT_CODE_IDLE = 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/CacheInstruction.scala
    lines: 95-105
    context: "95:   def isReadData(opcode: UInt)              = opcode === \"b00011\"\
      .U\n96:   def isWriteTagECC(opcode: UInt)           = opcode === \"b00100\"\
      .U\n97:   def isWriteDataECC(opcode: UInt)          = opcode === \"b00101\"\
      .U\n98:   def isWriteTag(opcode: UInt)              = opcode === \"b00110\"\
      .U\n99:   def isWriteData(opcode: UInt)             = opcode === \"b00111\"\
      .U\n100:   def isFlush(opcode: UInt)                 = opcode === \"b01000\"\
      .U\n101: \n102:   def isReadOp(opcode: UInt) = isReadTagECC(opcode) ||\n103:\
      \     isReadDataECC(opcode) ||\n104:     isReadTag(opcode) ||\n105:     isReadData(opcode)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/CacheInstruction.scala
    lines: 147-158
    context: "147:   })\n148: \n149:   // CSRCacheOpDecoder state\n150:   val wait_csr_op_req
      = RegInit(true.B) // waiting for csr \"CACHE_OP\" being write\n151:   val wait_cache_op_resp
      = RegInit(false.B) // waiting for dcache to finish dcache op\n152:   val schedule_csr_op_resp_data
      = RegInit(false.B) // ready to write data readed from cache back to csr\n153:\
      \   val schedule_csr_op_resp_finish = RegInit(false.B) // ready to write \"\
      OP_FINISH\" csr\n154:   // val cache_op_resp_timer = RegInit(0.U(4.W))\n155:\
      \   val data_transfer_finished = WireInit(false.B)\n156:   val data_transfer_cnt
      = RegInit(0.U(log2Up(maxDataRowSupport).W))\n157: \n158:   // Translate CSR
      write to cache op"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/CacheInstruction.scala
    lines: 205-215
    context: "205:   // Send cache op to cache\n206:   io.cache.req.valid := RegNext(cache_op_start)\n\
      207:   io.cache_req_dup.map( dup => dup.valid := RegNext(cache_op_start) )\n\
      208:   io.cache.req.bits := translated_cache_req\n209:   io.cache_req_dup.map(
      dup => dup.bits := translated_cache_req )\n210:   when(io.cache.req.fire){\n\
      211:     wait_cache_op_resp := true.B\n212:   }\n213: \n214:   io.cacheOp_req_bits_opCode_dup.zipWithIndex.map{
      case (dup, i) => dup := translated_cache_req_opCode_dup(i) }\n215: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/CacheInstruction.scala
    lines: 213-223
    context: "213: \n214:   io.cacheOp_req_bits_opCode_dup.zipWithIndex.map{ case
      (dup, i) => dup := translated_cache_req_opCode_dup(i) }\n215: \n216:   // Receive
      cache op resp from cache\n217:   val raw_cache_resp = Reg(new CacheCtrlRespInfo)\n\
      218:   when(io.cache.resp.fire){\n219:     wait_cache_op_resp := false.B\n220:\
      \     raw_cache_resp := io.cache.resp.bits\n221:     when(CacheInstrucion.isReadOp(translated_cache_req.opCode)){\n\
      222:       schedule_csr_op_resp_data := true.B\n223:       schedule_csr_op_resp_finish
      := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/CacheInstruction.scala
    lines: 227-241
    context: "227:       schedule_csr_op_resp_finish := true.B\n228:     }\n229: \
      \  }\n230: \n231:   // Translate cache op resp to CSR write, send it back to
      CSR\n232:   when(io.csr.update.w.fire && schedule_csr_op_resp_data && data_transfer_finished){\n\
      233:     schedule_csr_op_resp_data := false.B\n234:     schedule_csr_op_resp_finish
      := true.B\n235:   }\n236:   when(io.csr.update.w.fire && schedule_csr_op_resp_finish){\n\
      237:     schedule_csr_op_resp_finish := false.B\n238:     wait_csr_op_req :=
      true.B\n239:   }\n240: \n241:   io.csr.update.w.valid := schedule_csr_op_resp_data
      || schedule_csr_op_resp_finish"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/CacheInstruction.scala
    lines: 270-280
    context: "270:     io.csr.update.w.bits.addr := (CacheInstrucion.CacheInsRegisterList(\"\
      OP_FINISH\")(\"offset\").toInt + Scachebase).U\n271:     io.csr.update.w.bits.data
      := CacheInstrucion.COP_RESULT_CODE_OK\n272:     data_transfer_cnt := 0.U\n273:\
      \   }\n274: \n275:   val error = DelayNWithValid(io.error, 1)\n276:   when(error.bits.report_to_beu
      && error.valid) {\n277:     io.csr.update.w.bits.addr := (CacheInstrucion.CacheInsRegisterList(\"\
      CACHE_ERROR\")(\"offset\").toInt + Scachebase).U\n278:     io.csr.update.w.bits.data
      := error.asUInt\n279:     io.csr.update.w.valid := true.B\n280:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/AtomicsReplayUnit.scala
    lines: 31-46
    context: "31: \n32:     val block_addr  = Output(Valid(UInt()))\n33:   })\n34:\
      \ \n35:   val s_invalid :: s_pipe_req :: s_pipe_resp :: s_resp :: Nil = Enum(4)\n\
      36:   val state = RegInit(s_invalid)\n37: \n38:   val req = Reg(new DCacheWordReqWithVaddr)\n\
      39: \n40:   // assign default values to output signals\n41:   io.lsu.req.ready\
      \     := state === s_invalid\n42:   io.lsu.resp.valid    := false.B\n43:   io.lsu.resp.bits\
      \     := DontCare\n44: \n45:   io.pipe_req.valid    := false.B\n46:   io.pipe_req.bits\
      \     := DontCare"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/AtomicsReplayUnit.scala
    lines: 43-64
    context: "43:   io.lsu.resp.bits     := DontCare\n44: \n45:   io.pipe_req.valid\
      \    := false.B\n46:   io.pipe_req.bits     := DontCare\n47: \n48:   io.block_addr.valid
      := state =/= s_invalid\n49:   io.block_addr.bits  := req.addr\n50: \n51: \n\
      52:   XSDebug(state =/= s_invalid, \"AtomicsReplayEntry: state: %d block_addr:
      %x\\n\", state, io.block_addr.bits)\n53: \n54:   // --------------------------------------------\n\
      55:   // s_invalid: receive requests\n56:   when (state === s_invalid) {\n57:\
      \     when (io.lsu.req.fire) {\n58:       req   := io.lsu.req.bits\n59:    \
      \   state := s_pipe_req\n60:     }\n61:   }\n62: \n63:   // --------------------------------------------\n\
      64:   // replay"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/AtomicsReplayUnit.scala
    lines: 60-70
    context: "60:     }\n61:   }\n62: \n63:   // --------------------------------------------\n\
      64:   // replay\n65:   when (state === s_pipe_req) {\n66:     io.pipe_req.valid
      := Mux(\n67:       io.pipe_req.bits.cmd === M_XLR,\n68:       !io.block_lr,
      // block lr to survive in lr storm\n69:       true.B\n70:     )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/AtomicsReplayUnit.scala
    lines: 80-91
    context: "80:     pipe_req.vaddr  := get_block_addr(req.vaddr)\n81:     pipe_req.word_idx\
      \  := get_word(req.addr)\n82:     pipe_req.amo_data  := req.data\n83:     pipe_req.amo_mask\
      \  := req.mask\n84: \n85:     when (io.pipe_req.fire) {\n86:       state :=
      s_pipe_resp\n87:       assert(!io.pipe_req.bits.vaddr === 0.U)\n88:     }\n\
      89:   }\n90: \n91:   val resp_data  = Reg(UInt())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/AtomicsReplayUnit.scala
    lines: 89-99
    context: "89:   }\n90: \n91:   val resp_data  = Reg(UInt())\n92:   val resp_id\
      \    = Reg(UInt())\n93:   val resp_error = Reg(Bool())\n94:   when (state ===
      s_pipe_resp) {\n95:     // when not miss\n96:     // everything is OK, simply
      send response back to sbuffer\n97:     // when miss and not replay\n98:    \
      \ // wait for missQueue to handling miss and replaying our request\n99:    \
      \ // when miss and replay"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/AtomicsReplayUnit.scala
    lines: 99-112
    context: "99:     // when miss and replay\n100:     // req missed and fail to
      enter missQueue, manually replay it later\n101:     // TODO: add assertions:\n\
      102:     // 1. add a replay delay counter?\n103:     // 2. when req gets into
      MissQueue, it should not miss any more\n104:     when (io.pipe_resp.fire) {\n\
      105:       when (io.pipe_resp.bits.miss) {\n106:         when (io.pipe_resp.bits.replay)
      {\n107:           state := s_pipe_req\n108:         }\n109:       } .otherwise
      {\n110:         resp_data  := io.pipe_resp.bits.data\n111:         resp_id \
      \   := io.pipe_resp.bits.id\n112:         resp_error := io.pipe_resp.bits.error"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/AtomicsReplayUnit.scala
    lines: 108-118
    context: "108:         }\n109:       } .otherwise {\n110:         resp_data  :=
      io.pipe_resp.bits.data\n111:         resp_id    := io.pipe_resp.bits.id\n112:\
      \         resp_error := io.pipe_resp.bits.error\n113:         state := s_resp\n\
      114:       }\n115:     }\n116:   }\n117: \n118:   // --------------------------------------------"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/AtomicsReplayUnit.scala
    lines: 114-124
    context: "114:       }\n115:     }\n116:   }\n117: \n118:   // --------------------------------------------\n\
      119:   when (state === s_resp) {\n120:     io.lsu.resp.valid := true.B\n121:\
      \     io.lsu.resp.bits  := DontCare\n122:     io.lsu.resp.bits.data  := resp_data\n\
      123:     io.lsu.resp.bits.id    := resp_id\n124:     io.lsu.resp.bits.error
      := resp_error"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/AtomicsReplayUnit.scala
    lines: 121-132
    context: "121:     io.lsu.resp.bits  := DontCare\n122:     io.lsu.resp.bits.data\
      \  := resp_data\n123:     io.lsu.resp.bits.id    := resp_id\n124:     io.lsu.resp.bits.error
      := resp_error\n125: \n126:     when (io.lsu.resp.fire) {\n127:       state :=
      s_invalid\n128:     }\n129:   }\n130: \n131:   // debug output\n132:   // when
      (io.lsu.req.fire) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 82-92
    context: "82:   //\n83:   // cancel may come from the following sources:\n84:\
      \   // 1. miss req blocked by writeback queue:\n85:   //      a writeback req
      of the same address is in progress\n86:   // 2. pmp check failed\n87:   val
      cancel = Bool() // cancel is slow to generate, it will cancel missreq.valid\n\
      88: \n89:   // Req source decode\n90:   // Note that req source is NOT cmd type\n\
      91:   // For instance, a req which isFromPrefetch may have R or W cmd\n92: \
      \  def isFromLoad = source === LOAD_SOURCE.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 110-120
    context: "110:   val miss_param = UInt(TLPermissions.bdWidth.W)\n111:   val miss_dirty
      = Bool()\n112:   val error      = Bool()\n113: }\n114: \n115: class MissReq(implicit
      p: Parameters) extends MissReqWoStoreData {\n116:   // store data and store
      mask will be written to miss queue entry\n117:   // 1 cycle after req.fire()
      and meta write\n118:   val store_data = UInt((cfg.blockBytes * 8).W)\n119: \
      \  val store_mask = UInt(cfg.blockBytes.W)\n120: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 163-173
    context: "163: \n164: // a pipeline reg between MissReq and MissEntry\n165: class
      MissReqPipeRegBundle(edge: TLEdgeOut)(implicit p: Parameters) extends DCacheBundle\n\
      166:  with HasCircularQueuePtrHelper\n167:  {\n168:   val req           = new
      MissReq\n169:   // this request is about to merge to an existing mshr\n170:\
      \   val merge         = Bool()\n171:   // this request is about to allocate
      a new mshr\n172:   val alloc         = Bool()\n173:   val cancel        = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 175-185
    context: "175: \n176:   def reg_valid(): Bool = {\n177:     (merge || alloc)\n\
      178:   }\n179: \n180:   def matched(new_req: MissReq): Bool = {\n181:     val
      block_match = get_block(req.addr) === get_block(new_req.addr)\n182:     block_match
      && reg_valid() && !(req.isFromPrefetch)\n183:   }\n184: \n185:   def prefetch_late_en(new_req:
      MissReqWoStoreData, new_req_valid: Bool): Bool = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 185-195
    context: "185:   def prefetch_late_en(new_req: MissReqWoStoreData, new_req_valid:
      Bool): Bool = {\n186:     val block_match = get_block(req.addr) === get_block(new_req.addr)\n\
      187:     new_req_valid && alloc && block_match && (req.isFromPrefetch) && !(new_req.isFromPrefetch)\n\
      188:   }\n189: \n190:   def reject_req(new_req: MissReq): Bool = {\n191:   \
      \  val block_match = get_block(req.addr) === get_block(new_req.addr)\n192: \
      \    val alias_match = is_alias_match(req.vaddr, new_req.vaddr)\n193:     val
      merge_load = (req.isFromLoad || req.isFromStore || req.isFromPrefetch) && new_req.isFromLoad\n\
      194:     // store merge to a store is disabled, sbuffer should avoid this situation,
      as store to same address should preserver their program order to match memory
      model\n195:     val merge_store = (req.isFromLoad || req.isFromPrefetch) &&
      new_req.isFromStore"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 201-211
    context: "201:         block_match && (!alias_match || !(merge_load || merge_store)),\n\
      202:         false.B\n203:       )\n204:   }\n205: \n206:   def merge_req(new_req:
      MissReq): Bool = {\n207:     val block_match = get_block(req.addr) === get_block(new_req.addr)\n\
      208:     val alias_match = is_alias_match(req.vaddr, new_req.vaddr)\n209:  \
      \   val merge_load = (req.isFromLoad || req.isFromStore || req.isFromPrefetch)
      && new_req.isFromLoad\n210:     // store merge to a store is disabled, sbuffer
      should avoid this situation, as store to same address should preserver their
      program order to match memory model\n211:     val merge_store = (req.isFromLoad
      || req.isFromPrefetch) && new_req.isFromStore"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 214-227
    context: "214:         block_match && alias_match && (merge_load || merge_store),\n\
      215:         false.B\n216:       )\n217:   }\n218: \n219:   def merge_isKeyword(new_req:
      MissReq): Bool = {\n220:     val load_merge_load  = merge_req(new_req) && req.isFromLoad\
      \  && new_req.isFromLoad\n221:     val store_merge_load = merge_req(new_req)
      && req.isFromStore && new_req.isFromLoad\n222:     val load_merge_load_use_new_req_isKeyword
      = isAfter(req.lqIdx, new_req.lqIdx)\n223:     val use_new_req_isKeyword = (load_merge_load
      && load_merge_load_use_new_req_isKeyword) || store_merge_load\n224:     Mux
      (\n225:       use_new_req_isKeyword,\n226:         new_req.vaddr(5).asBool,\n\
      227:         req.vaddr(5).asBool"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 242-252
    context: "242:       alloc_isKeyword\n243:     )\n244:   }\n245:   // send out
      acquire as soon as possible\n246:   // if a new store miss req is about to merge
      into this pipe reg, don't send acquire now\n247:   def can_send_acquire(valid:
      Bool, new_req: MissReq): Bool = {\n248:     alloc && !(valid && merge_req(new_req)
      && new_req.isFromStore)\n249:   }\n250: \n251:   def get_acquire(l2_pf_store_only:
      Bool): TLBundleA = {\n252:     val acquire = Wire(new TLBundleA(edge.bundle))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 263-290
    context: "263:       lgSize = (log2Up(cfg.blockBytes)).U,\n264:       growPermissions
      = grow_param\n265:     )._2\n266:     acquire := Mux(req.full_overwrite, acquirePerm,
      acquireBlock)\n267:     // resolve cache alias by L2\n268:     acquire.user.lift(AliasKey).foreach(_
      := req.vaddr(13, 12))\n269:     // pass vaddr to l2\n270:     acquire.user.lift(VaddrKey).foreach(_
      := req.vaddr(VAddrBits - 1, blockOffBits))\n271: \n272:     // miss req pipe
      reg pass keyword to L2, is priority\n273:     acquire.echo.lift(IsKeywordKey).foreach(_
      := isKeyword())\n274: \n275:     // trigger prefetch\n276:     acquire.user.lift(PrefetchKey).foreach(_
      := Mux(l2_pf_store_only, req.isFromStore, true.B))\n277:     // req source\n\
      278:     when(req.isFromLoad) {\n279:       acquire.user.lift(ReqSourceKey).foreach(_
      := MemReqSource.CPULoadData.id.U)\n280:     }.elsewhen(req.isFromStore) {\n\
      281:       acquire.user.lift(ReqSourceKey).foreach(_ := MemReqSource.CPUStoreData.id.U)\n\
      282:     }.elsewhen(req.isFromAMO) {\n283:       acquire.user.lift(ReqSourceKey).foreach(_
      := MemReqSource.CPUAtomicData.id.U)\n284:     }.otherwise {\n285:       acquire.user.lift(ReqSourceKey).foreach(_
      := MemReqSource.L1DataPrefetch.id.U)\n286:     }\n287: \n288:     acquire\n\
      289:   }\n290: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 305-338
    context: "305:     val resp_to_lsq = DecoupledIO(new CMOResp)\n306:     val wfi
      = Flipped(new WfiReqBundle)\n307:   })\n308: \n309:   val s_idle :: s_sreq ::
      s_wresp :: s_lsq_resp :: Nil = Enum(4)\n310:   val state = RegInit(s_idle)\n\
      311:   val state_next = WireInit(state)\n312:   val req = RegEnable(io.req.bits,
      io.req.fire)\n313:   val nderr = RegInit(false.B)\n314:   val no_pending = RegInit(true.B)\n\
      315: \n316:   state := state_next\n317: \n318:   switch (state) {\n319:    \
      \ is(s_idle) {\n320:       when (io.req.fire) {\n321:         state_next :=
      s_sreq\n322:         nderr := false.B\n323:       }\n324:     }\n325:     is(s_sreq)
      {\n326:       when (io.req_chanA.fire) {\n327:         state_next := s_wresp\n\
      328:         no_pending := false.B\n329:       }\n330:     }\n331:     is(s_wresp)
      {\n332:       when (io.resp_chanD.fire) {\n333:         state_next := s_lsq_resp\n\
      334:         nderr := io.resp_chanD.bits.denied || io.resp_chanD.bits.corrupt\n\
      335:         no_pending := true.B\n336:       }\n337:     }\n338:     is(s_lsq_resp)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 334-352
    context: "334:         nderr := io.resp_chanD.bits.denied || io.resp_chanD.bits.corrupt\n\
      335:         no_pending := true.B\n336:       }\n337:     }\n338:     is(s_lsq_resp)
      {\n339:       when (io.resp_to_lsq.fire) {\n340:         state_next := s_idle\n\
      341:       }\n342:     }\n343:   }\n344: \n345:   io.req.ready := state ===
      s_idle\n346: \n347:   io.req_chanA.valid := state === s_sreq && !io.wfi.wfiReq\n\
      348:   io.req_chanA.bits := edge.CacheBlockOperation(\n349:     fromSource =
      (cfg.nMissEntries + 1).U,\n350:     toAddress = req.address,\n351:     lgSize
      = (log2Up(cfg.blockBytes)).U,\n352:     opcode = req.opcode"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 350-368
    context: "350:     toAddress = req.address,\n351:     lgSize = (log2Up(cfg.blockBytes)).U,\n\
      352:     opcode = req.opcode\n353:   )._2\n354: \n355:   io.resp_chanD.ready
      := state === s_wresp\n356:   io.wfi.wfiSafe := GatedValidRegNext(no_pending
      && io.wfi.wfiReq)\n357: \n358:   io.resp_to_lsq.valid := state === s_lsq_resp\n\
      359:   io.resp_to_lsq.bits.address := req.address\n360:   io.resp_to_lsq.bits.nderr\
      \   := nderr\n361: \n362:   assert(!(state =/= s_idle && io.req.valid))\n363:\
      \   assert(!(state =/= s_wresp && io.resp_chanD.valid))\n364: }\n365: \n366:
      class MissEntry(edge: TLEdgeOut, reqNum: Int)(implicit p: Parameters) extends
      DCacheModule\n367:   with HasCircularQueuePtrHelper\n368:  {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 373-383
    context: "373:     // client requests\n374:     // MSHR update request, MSHR state
      and addr will be updated when req.fire\n375:     val req = Flipped(ValidIO(new
      MissReqWoStoreData))\n376:     val wbq_block_miss_req = Input(Bool())\n377:\
      \     // pipeline reg\n378:     val miss_req_pipe_reg = Input(new MissReqPipeRegBundle(edge))\n\
      379:     // allocate this entry for new req\n380:     val primary_valid = Input(Bool())\n\
      381:     // this entry is free and can be allocated to new reqs\n382:     val
      primary_ready = Output(Bool())\n383:     // this entry is busy, but it can merge
      the new req"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 415-427
    context: "415:     val probe = Flipped(new MissQueueBlockIO)\n416: \n417:    \
      \ // block replace when release an addr valid in mshr\n418:     val replace
      = Flipped(new MissQueueBlockIO)\n419: \n420:     val req_addr = ValidIO(UInt(PAddrBits.W))\n\
      421:     val req_vaddr = ValidIO(UInt(VAddrBits.W))\n422:     val req_isBtoT
      = Output(Bool())\n423: \n424:     val req_handled_by_this_entry = Output(Bool())\n\
      425: \n426:     val forwardInfo = Output(new MissEntryForwardIO)\n427:     val
      l2_pf_store_only = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 471-481
    context: "471:   val set = addr_to_dcache_set(req.vaddr)\n472:   val evict_BtoT_way
      = RegInit(false.B)\n473:   // initial keyword\n474:   val isKeyword = RegInit(false.B)\n\
      475: \n476:   val miss_req_pipe_reg_bits = io.miss_req_pipe_reg.req\n477: \n\
      478:   val input_req_is_prefetch = isPrefetch(miss_req_pipe_reg_bits.cmd)\n\
      479: \n480:   val s_acquire = RegInit(true.B)\n481:   val s_grantack = RegInit(true.B)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 491-501
    context: "491: \n492:   val mainpipe_req_fired = RegInit(true.B)\n493: \n494:\
      \   val release_entry = s_grantack && w_mainpipe_resp && w_refill_resp\n495:\
      \ \n496:   val acquire_not_sent = !s_acquire && !io.mem_acquire.ready\n497:\
      \   val data_not_refilled = !w_grantfirst\n498: \n499:   val error = RegInit(false.B)\n\
      500:   val prefetch = RegInit(false.B)\n501:   val access = RegInit(false.B)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 538-548
    context: "538: \n539:   when (release_entry && req_valid) {\n540:     req_valid
      := false.B\n541:   }\n542: \n543:   when (io.miss_req_pipe_reg.alloc && !io.miss_req_pipe_reg.cancel)
      {\n544:     assert(RegNext(primary_fire), \"after 1 cycle of primary_fire, entry
      will be allocated\")\n545:     req_valid := true.B\n546: \n547:     req := miss_req_pipe_reg_bits.toMissReqWoStoreData()\n\
      548:     req.isBtoT := miss_req_pipe_reg_bits.isBtoT"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 580-597
    context: "580:       w_mainpipe_resp := false.B\n581:     }\n582: \n583:     should_refill_data_reg
      := miss_req_pipe_reg_bits.isFromLoad\n584:     error := false.B\n585:     prefetch
      := input_req_is_prefetch && !io.miss_req_pipe_reg.prefetch_late_en(io.req.bits,
      io.req.valid)\n586:     access := false.B\n587:     secondary_fired := false.B\n\
      588:   }\n589: \n590:   when (io.miss_req_pipe_reg.merge && !io.miss_req_pipe_reg.cancel)
      {\n591:     assert(RegNext(secondary_fire) || RegNext(RegNext(primary_fire)),
      \"after 1 cycle of secondary_fire or 2 cycle of primary_fire, entry will be
      merged\")\n592:     assert(miss_req_pipe_reg_bits.req_coh.state <= req.req_coh.state
      || (prefetch && !access))\n593:     assert(!(miss_req_pipe_reg_bits.isFromAMO
      || req.isFromAMO))\n594:     // use the most uptodate meta\n595:     req.req_coh
      := miss_req_pipe_reg_bits.req_coh\n596: \n597:     isKeyword := Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 620-630
    context: "620:       access := true.B // when merge non-prefetch req, set access
      bit\n621:     }\n622:     secondary_fired := true.B\n623:   }\n624: \n625: \
      \  when (io.mem_acquire.fire) {\n626:     s_acquire := true.B\n627:     no_pending
      := false.B\n628:   }\n629: \n630:   // merge data refilled by l2 and store data,
      update miss queue entry, gen refill_req"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 643-653
    context: "643:   }\n644: \n645:   val hasData = RegInit(true.B)\n646:   val isDirty
      = RegInit(false.B)\n647:   io.wfi.wfiSafe := GatedValidRegNext(no_pending &&
      io.wfi.wfiReq)\n648:   when (io.mem_grant.fire) {\n649:     w_grantfirst :=
      true.B\n650:     grant_param := io.mem_grant.bits.param\n651:     when (edge.hasData(io.mem_grant.bits))
      {\n652:       // GrantData\n653:       when (isKeyword) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 682-696
    context: "682: \n683:     refill_data_raw(refill_count ^ isKeyword) := io.mem_grant.bits.data\n\
      684:     isDirty := io.mem_grant.bits.echo.lift(DirtyKey).getOrElse(false.B)\n\
      685:   }\n686: \n687:   when (io.mem_finish.fire) {\n688:     s_grantack :=
      true.B\n689:   }\n690: \n691:   when (io.main_pipe_req.fire) {\n692:     s_mainpipe_req
      := true.B\n693:     mainpipe_req_fired := true.B\n694:   }\n695: \n696:   when
      (io.main_pipe_replay || io.main_pipe_evict_BtoT_way) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 741-751
    context: "741:     )\n742:   }\n743: \n744:   def before_req_sent_merge_iskeyword(new_req:
      MissReqWoStoreData): Bool = {\n745:     val need_check_isKeyword = acquire_not_sent
      && req.isFromLoad && new_req.isFromLoad && should_merge(new_req)\n746:     val
      use_new_req_isKeyword = isAfter(req.lqIdx, new_req.lqIdx)\n747:     Mux(\n748:\
      \       need_check_isKeyword,\n749:       Mux(\n750:         use_new_req_isKeyword,\n\
      751:         new_req.vaddr(5).asBool,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 802-817
    context: "802:   val refill_data_splited = WireInit(VecInit(Seq.tabulate(cfg.blockBytes
      * 8 / l1BusDataWidth)(i => {\n803:     val data = refill_and_store_data.asUInt\n\
      804:     data((i + 1) * l1BusDataWidth - 1, i * l1BusDataWidth)\n805:   })))\n\
      806:   // when granted data is all ready, wakeup lq's miss load\n807:   val
      refill_to_ldq_en = !w_grantlast && io.mem_grant.fire\n808:   io.refill_to_ldq.valid
      := GatedValidRegNext(refill_to_ldq_en)\n809:   io.refill_to_ldq.bits.addr :=
      RegEnable(req.addr + ((refill_count ^ isKeyword) << refillOffBits), refill_to_ldq_en)\n\
      810:   io.refill_to_ldq.bits.data := refill_data_splited(RegEnable(refill_count
      ^ isKeyword, refill_to_ldq_en))\n811:   io.refill_to_ldq.bits.error := RegEnable(io.mem_grant.bits.corrupt
      || io.mem_grant.bits.denied, refill_to_ldq_en)\n812:   io.refill_to_ldq.bits.refill_done
      := RegEnable(refill_done && io.mem_grant.fire, refill_to_ldq_en)\n813:   io.refill_to_ldq.bits.hasdata
      := hasData\n814:   io.refill_to_ldq.bits.data_raw := refill_data_raw.asUInt\n\
      815:   io.refill_to_ldq.bits.id := io.id\n816: \n817:   // if the entry has
      a pending merge req, wait for it"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 815-825
    context: "815:   io.refill_to_ldq.bits.id := io.id\n816: \n817:   // if the entry
      has a pending merge req, wait for it\n818:   // Note: now, only wait for store,
      because store may acquire T\n819:   io.mem_acquire.valid := !s_acquire &&\n\
      820:     !(io.miss_req_pipe_reg.merge && !io.miss_req_pipe_reg.cancel && miss_req_pipe_reg_bits.isFromStore)
      &&\n821:     !io.wfi.wfiReq\n822:   val grow_param = req.req_coh.onAccess(req.cmd)._2\n\
      823:   val acquireBlock = edge.AcquireBlock(\n824:     fromSource = io.id,\n\
      825:     toAddress = req.addr,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 832-860
    context: "832:     lgSize = (log2Up(cfg.blockBytes)).U,\n833:     growPermissions
      = grow_param\n834:   )._2\n835:   io.mem_acquire.bits := Mux(full_overwrite,
      acquirePerm, acquireBlock)\n836:   // resolve cache alias by L2\n837:   io.mem_acquire.bits.user.lift(AliasKey).foreach(
      _ := req.vaddr(13, 12))\n838:   // pass vaddr to l2\n839:   io.mem_acquire.bits.user.lift(VaddrKey).foreach(
      _ := req.vaddr(VAddrBits-1, blockOffBits))\n840:   // pass keyword to L2\n841:\
      \   io.mem_acquire.bits.echo.lift(IsKeywordKey).foreach(_ := isKeyword)\n842:\
      \   // trigger prefetch\n843:   io.mem_acquire.bits.user.lift(PrefetchKey).foreach(_
      := Mux(io.l2_pf_store_only, req.isFromStore, true.B))\n844:   // req source\n\
      845:   when(prefetch && !secondary_fired) {\n846:     io.mem_acquire.bits.user.lift(ReqSourceKey).foreach(_
      := MemReqSource.L1DataPrefetch.id.U)\n847:   }.otherwise {\n848:     when(req.isFromStore)
      {\n849:       io.mem_acquire.bits.user.lift(ReqSourceKey).foreach(_ := MemReqSource.CPUStoreData.id.U)\n\
      850:     }.elsewhen(req.isFromLoad) {\n851:       io.mem_acquire.bits.user.lift(ReqSourceKey).foreach(_
      := MemReqSource.CPULoadData.id.U)\n852:     }.elsewhen(req.isFromAMO) {\n853:\
      \       io.mem_acquire.bits.user.lift(ReqSourceKey).foreach(_ := MemReqSource.CPUAtomicData.id.U)\n\
      854:     }.otherwise {\n855:       io.mem_acquire.bits.user.lift(ReqSourceKey).foreach(_
      := MemReqSource.L1DataPrefetch.id.U)\n856:     }\n857:   }\n858:   require(nSets
      <= 256)\n859: \n860:   // io.mem_grant.ready := !w_grantlast && s_acquire"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 856-870
    context: "856:     }\n857:   }\n858:   require(nSets <= 256)\n859: \n860:   //
      io.mem_grant.ready := !w_grantlast && s_acquire\n861:   io.mem_grant.ready :=
      true.B\n862:   assert(!(io.mem_grant.valid && !(!w_grantlast && s_acquire)),
      \"dcache should always be ready for mem_grant now\")\n863: \n864:   val grantack
      = RegEnable(edge.GrantAck(io.mem_grant.bits), io.mem_grant.fire)\n865:   assert(RegNext(!io.mem_grant.fire
      || edge.isRequest(io.mem_grant.bits)))\n866:   io.mem_finish.valid := !s_grantack
      && w_grantfirst\n867:   io.mem_finish.bits := grantack\n868: \n869:   // Send
      mainpipe_req when receive hint from L2 or receive data without hint\n870:  \
      \ io.main_pipe_req.valid := !s_mainpipe_req && (w_l2hint || w_grantlast)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 892-906
    context: "892: \n893:   io.replace.block := req_valid &&\n894:     get_block_addr(req.addr)
      === get_block_addr(io.replace.req.bits.addr) &&\n895:     is_alias_match(req.vaddr,
      io.replace.req.bits.vaddr)\n896: \n897:   io.req_addr.valid := req_valid\n898:\
      \   io.req_addr.bits:= req.addr\n899:   io.req_vaddr.valid := req_valid\n900:\
      \   io.req_vaddr.bits := req.vaddr\n901:   io.req_isBtoT := req.isBtoT\n902:\
      \ \n903:   io.occupy_way := req.occupy_way\n904: \n905:   io.refill_info.valid
      := req_valid && w_grantlast\n906:   io.refill_info.bits.store_data := refill_and_store_data.asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 907-918
    context: "907:   io.refill_info.bits.store_mask := ~0.U(blockBytes.W)\n908:  \
      \ io.refill_info.bits.miss_param := grant_param\n909:   io.refill_info.bits.miss_dirty
      := isDirty\n910:   io.refill_info.bits.error      := error\n911: \n912:   XSPerfAccumulate(\"\
      miss_refill_mainpipe_req\", io.main_pipe_req.fire)\n913:   XSPerfAccumulate(\"\
      miss_refill_without_hint\", io.main_pipe_req.fire && !mainpipe_req_fired &&
      !w_l2hint)\n914:   XSPerfAccumulate(\"miss_refill_replay\", io.main_pipe_replay)\n\
      915:   XSPerfAccumulate(\"miss_refill_evict_BtoT_way\", io.main_pipe_evict_BtoT_way)\n\
      916: \n917:   val w_grantfirst_forward_info = Mux(isKeyword, w_grantlast, w_grantfirst)\n\
      918:   val w_grantlast_forward_info = Mux(isKeyword, w_grantfirst, w_grantlast)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 917-928
    context: "917:   val w_grantfirst_forward_info = Mux(isKeyword, w_grantlast, w_grantfirst)\n\
      918:   val w_grantlast_forward_info = Mux(isKeyword, w_grantfirst, w_grantlast)\n\
      919:   io.forwardInfo.inflight := req_valid\n920:   io.forwardInfo.paddr :=
      req.addr\n921:   io.forwardInfo.raw_data := refill_and_store_data\n922:   io.forwardInfo.firstbeat_valid
      := w_grantfirst_forward_info\n923:   io.forwardInfo.lastbeat_valid := w_grantlast_forward_info\n\
      924:   io.forwardInfo.corrupt := error\n925: \n926:   io.matched := req_valid
      && (get_block(req.addr) === get_block(io.req.bits.addr)) && !prefetch\n927:\
      \   io.prefetch_info.late_prefetch := io.req.valid && !(io.req.bits.isFromPrefetch)
      && req_valid && (get_block(req.addr) === get_block(io.req.bits.addr)) && prefetch\n\
      928: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 930-944
    context: "930:     prefetch := false.B\n931:   }\n932: \n933:   io.l1Miss := req_valid\n\
      934:   // refill latency monitor\n935:   val start_counting = GatedValidRegNext(io.mem_acquire.fire)
      || (GatedValidRegNextN(primary_fire, 2) && s_acquire)\n936:   io.latency_monitor.load_miss_refilling\
      \  := req_valid && req_primary_fire.isFromLoad     && BoolStopWatch(start_counting,
      io.mem_grant.fire && !refill_done, true, true)\n937:   io.latency_monitor.store_miss_refilling
      := req_valid && req_primary_fire.isFromStore    && BoolStopWatch(start_counting,
      io.mem_grant.fire && !refill_done, true, true)\n938:   io.latency_monitor.amo_miss_refilling\
      \   := req_valid && req_primary_fire.isFromAMO      && BoolStopWatch(start_counting,
      io.mem_grant.fire && !refill_done, true, true)\n939:   io.latency_monitor.pf_miss_refilling\
      \    := req_valid && req_primary_fire.isFromPrefetch && BoolStopWatch(start_counting,
      io.mem_grant.fire && !refill_done, true, true)\n940: \n941:   XSPerfAccumulate(\"\
      miss_req_primary\", primary_fire)\n942:   XSPerfAccumulate(\"miss_req_merged\"\
      , secondary_fire)\n943:   XSPerfAccumulate(\"load_miss_penalty_to_use\",\n944:\
      \     should_refill_data &&"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 945-961
    context: "945:       BoolStopWatch(primary_fire, io.refill_to_ldq.valid, true)\n\
      946:   )\n947:   XSPerfAccumulate(\"penalty_between_grantlast_and_release\"\
      ,\n948:     BoolStopWatch(!RegNext(w_grantlast) && w_grantlast, release_entry,
      true)\n949:   )\n950:   XSPerfAccumulate(\"main_pipe_penalty\", BoolStopWatch(io.main_pipe_req.fire,
      io.main_pipe_resp))\n951:   XSPerfAccumulate(\"penalty_blocked_by_channel_A\"\
      , io.mem_acquire.valid && !io.mem_acquire.ready)\n952:   XSPerfAccumulate(\"\
      penalty_waiting_for_channel_D\", s_acquire && !w_grantlast && !io.mem_grant.valid)\n\
      953:   XSPerfAccumulate(\"penalty_waiting_for_channel_E\", io.mem_finish.valid
      && !io.mem_finish.ready)\n954:   XSPerfAccumulate(\"prefetch_req_primary\",
      primary_fire && io.req.bits.source === DCACHE_PREFETCH_SOURCE.U)\n955:   XSPerfAccumulate(\"\
      prefetch_req_merged\", secondary_fire && io.req.bits.source === DCACHE_PREFETCH_SOURCE.U)\n\
      956:   XSPerfAccumulate(\"can_not_send_acquire_because_of_merging_store\", !s_acquire
      && io.miss_req_pipe_reg.merge && io.miss_req_pipe_reg.cancel && miss_req_pipe_reg_bits.isFromStore)\n\
      957: \n958:   val (mshr_penalty_sample, mshr_penalty) = TransactionLatencyCounter(GatedValidRegNextN(primary_fire,
      2), release_entry)\n959:   XSPerfHistogram(\"miss_penalty\", mshr_penalty, mshr_penalty_sample,
      0, 20, 1, true, true)\n960:   XSPerfHistogram(\"miss_penalty\", mshr_penalty,
      mshr_penalty_sample, 20, 100, 10, true, false)\n961: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 959-974
    context: "959:   XSPerfHistogram(\"miss_penalty\", mshr_penalty, mshr_penalty_sample,
      0, 20, 1, true, true)\n960:   XSPerfHistogram(\"miss_penalty\", mshr_penalty,
      mshr_penalty_sample, 20, 100, 10, true, false)\n961: \n962:   val load_miss_begin
      = primary_fire && io.req.bits.isFromLoad\n963:   val refill_finished = GatedValidRegNext(!w_grantlast
      && refill_done) && should_refill_data\n964:   val (load_miss_penalty_sample,
      load_miss_penalty) = TransactionLatencyCounter(load_miss_begin, refill_finished)
      // not real refill finish time\n965:   XSPerfHistogram(\"load_miss_penalty_to_use\"\
      , load_miss_penalty, load_miss_penalty_sample, 0, 20, 1, true, true)\n966: \
      \  XSPerfHistogram(\"load_miss_penalty_to_use\", load_miss_penalty, load_miss_penalty_sample,
      20, 100, 10, true, false)\n967:   XSPerfHistogram(\"load_miss_penalty_to_use\"\
      , load_miss_penalty, load_miss_penalty_sample, 100, 400, 30, true, false)\n\
      968: \n969:   val (a_to_d_penalty_sample, a_to_d_penalty) = TransactionLatencyCounter(start_counting,
      GatedValidRegNext(io.mem_grant.fire && refill_done))\n970:   XSPerfHistogram(\"\
      a_to_d_penalty\", a_to_d_penalty, a_to_d_penalty_sample, 0, 20, 1, true, true)\n\
      971:   XSPerfHistogram(\"a_to_d_penalty\", a_to_d_penalty, a_to_d_penalty_sample,
      20, 100, 10, true, false)\n972: }\n973: \n974: class MissQueue(edge: TLEdgeOut,
      reqNum: Int)(implicit p: Parameters) extends DCacheModule"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 974-984
    context: "974: class MissQueue(edge: TLEdgeOut, reqNum: Int)(implicit p: Parameters)
      extends DCacheModule\n975:   with HasPerfEvents\n976:   {\n977:   val io = IO(new
      Bundle {\n978:     val hartId = Input(UInt(hartIdLen.W))\n979:     val req =
      Flipped(DecoupledIO(new MissReq))\n980:     val resp = Output(new MissResp)\n\
      981:     val refill_to_ldq = ValidIO(new Refill)\n982: \n983:     // cmo req\n\
      984:     val cmo_req = Flipped(DecoupledIO(new CMOReq))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1016-1026
    context: "1016:     val wbq_block_miss_req = Input(Bool())\n1017: \n1018:    \
      \ val full = Output(Bool())\n1019: \n1020:     // forward missqueue\n1021: \
      \    val forward = Vec(LoadPipelineWidth, new LduToMissqueueForwardIO)\n1022:\
      \     val l2_pf_store_only = Input(Bool())\n1023: \n1024:     val memSetPattenDetected
      = Output(Bool())\n1025:     val lqEmpty = Input(Bool())\n1026: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1045-1055
    context: "1045:   // 128KBL1: FIXME: provide vaddr for l2\n1046: \n1047:   val
      entries = Seq.fill(cfg.nMissEntries)(Module(new MissEntry(edge, reqNum)))\n\
      1048:   val cmo_unit = Module(new CMOUnit(edge))\n1049: \n1050:   val miss_req_pipe_reg
      = RegInit(0.U.asTypeOf(new MissReqPipeRegBundle(edge)))\n1051:   val acquire_from_pipereg
      = Wire(chiselTypeOf(io.mem_acquire))\n1052: \n1053:   val primary_ready_vec
      = entries.map(_.io.primary_ready)\n1054:   val secondary_ready_vec = entries.map(_.io.secondary_ready)\n\
      1055:   val secondary_reject_vec = entries.map(_.io.secondary_reject)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1057-1068
    context: "1057:     case e =>\n1058:       e.io.probe.req <> io.probe.req\n1059:\
      \       e.io.probe.block\n1060:   }\n1061: \n1062:   val merge = ParallelORR(Cat(secondary_ready_vec
      ++ Seq(miss_req_pipe_reg.merge_req(io.req.bits))))\n1063:   val reject = ParallelORR(Cat(secondary_reject_vec
      ++ Seq(miss_req_pipe_reg.reject_req(io.req.bits))))\n1064:   val alloc = !reject
      && !merge && ParallelORR(Cat(primary_ready_vec))\n1065:   val accept = alloc
      || merge\n1066: \n1067:   // generate req_ready for each miss request for better
      timing\n1068:   for (i <- 0 until reqNum) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1067-1090
    context: "1067:   // generate req_ready for each miss request for better timing\n\
      1068:   for (i <- 0 until reqNum) {\n1069:     val _primary_ready_vec = entries.map(_.io.queryME(i).primary_ready)\n\
      1070:     val _secondary_ready_vec = entries.map(_.io.queryME(i).secondary_ready)\n\
      1071:     val _secondary_reject_vec = entries.map(_.io.queryME(i).secondary_reject)\n\
      1072:     val _merge = ParallelORR(Cat(_secondary_ready_vec ++ Seq(miss_req_pipe_reg.merge_req(io.queryMQ(i).req.bits))))\n\
      1073:     val _reject = ParallelORR(Cat(_secondary_reject_vec ++ Seq(miss_req_pipe_reg.reject_req(io.queryMQ(i).req.bits))))\n\
      1074:     val _alloc = !_reject && !_merge && ParallelORR(Cat(_primary_ready_vec))\n\
      1075:     val _accept = _alloc || _merge\n1076: \n1077:     io.queryMQ(i).ready
      := _accept\n1078:   }\n1079: \n1080:   val req_mshr_handled_vec = entries.map(_.io.req_handled_by_this_entry)\n\
      1081:   // merged to pipeline reg\n1082:   val req_pipeline_reg_handled = miss_req_pipe_reg.merge_req(io.req.bits)
      && io.req.valid\n1083:   assert(PopCount(Seq(req_pipeline_reg_handled, VecInit(req_mshr_handled_vec).asUInt.orR))
      <= 1.U, \"miss req will either go to mshr or pipeline reg\")\n1084:   assert(PopCount(req_mshr_handled_vec)
      <= 1.U, \"Only one mshr can handle a req\")\n1085:   io.resp.id := Mux(!req_pipeline_reg_handled,
      OHToUInt(req_mshr_handled_vec), miss_req_pipe_reg.mshr_id)\n1086:   io.resp.handled
      := Cat(req_mshr_handled_vec).orR || req_pipeline_reg_handled\n1087:   io.resp.merged
      := merge\n1088: \n1089:   /*  MissQueue enq logic is now splitted into 2 cycles\n\
      1090:    *"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1088-1104
    context: "1088: \n1089:   /*  MissQueue enq logic is now splitted into 2 cycles\n\
      1090:    *\n1091:    */\n1092:   when(io.req.valid){\n1093:     miss_req_pipe_reg.req\
      \     := io.req.bits\n1094:   }\n1095:   // miss_req_pipe_reg.req     := io.req.bits\n\
      1096:   miss_req_pipe_reg.alloc   := alloc && io.req.valid && !io.req.bits.cancel
      && !io.wbq_block_miss_req\n1097:   miss_req_pipe_reg.merge   := merge && io.req.valid
      && !io.req.bits.cancel && !io.wbq_block_miss_req\n1098:   miss_req_pipe_reg.cancel\
      \  := io.wbq_block_miss_req\n1099:   miss_req_pipe_reg.mshr_id := io.resp.id\n\
      1100: \n1101:   assert(PopCount(Seq(alloc && io.req.valid, merge && io.req.valid))
      <= 1.U, \"allocate and merge a mshr in same cycle!\")\n1102: \n1103:   val source_except_load_cnt
      = RegInit(0.U(10.W))\n1104:   when(VecInit(req_mshr_handled_vec).asUInt.orR
      || req_pipeline_reg_handled) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1115-1133
    context: "1115: \n1116:   io.memSetPattenDetected := memSetPattenDetected\n1117:\
      \ \n1118:   val forwardInfo_vec = VecInit(entries.map(_.io.forwardInfo))\n1119:\
      \   (0 until LoadPipelineWidth).map(i => {\n1120:     val id = io.forward(i).mshrid\n\
      1121:     val req_valid = io.forward(i).valid\n1122:     val paddr = io.forward(i).paddr\n\
      1123: \n1124:     val (forward_mshr, forwardData) = forwardInfo_vec(id).forward(req_valid,
      paddr)\n1125:     io.forward(i).forward_result_valid := forwardInfo_vec(id).check(req_valid,
      paddr)\n1126:     io.forward(i).forward_mshr := forward_mshr\n1127:     io.forward(i).forwardData
      := forwardData\n1128:     io.forward(i).corrupt := RegNext(forwardInfo_vec(id).corrupt)\n\
      1129:   })\n1130: \n1131:   assert(RegNext(PopCount(secondary_ready_vec) <=
      1.U || !io.req.valid))\n1132: //  assert(RegNext(PopCount(secondary_reject_vec)
      <= 1.U))\n1133:   // It is possible that one mshr wants to merge a req, while
      another mshr wants to reject it."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1142-1159
    context: "1142:     name: Option[String] = None): Unit = {\n1143: \n1144:    \
      \ if (name.nonEmpty) { out.suggestName(s\"${name.get}_select\") }\n1145:   \
      \  out.valid := Cat(in.map(_.valid)).orR\n1146:     out.bits := ParallelMux(in.map(_.valid)
      zip in.map(_.bits))\n1147:     in.map(_.ready := out.ready)\n1148:     assert(!RegNext(out.valid
      && PopCount(Cat(in.map(_.valid))) > 1.U))\n1149:   }\n1150: \n1151:   io.mem_grant.ready
      := false.B\n1152: \n1153:   val nMaxPrefetchEntry = Constantin.createRecord(s\"\
      nMaxPrefetchEntry${p(XSCoreParamsKey).HartId}\", initValue = 14)\n1154:   entries.zipWithIndex.foreach
      {\n1155:     case (e, i) =>\n1156:       val former_primary_ready = if(i ==
      0)\n1157:         false.B\n1158:       else\n1159:         Cat((0 until i).map(j
      => entries(j).io.primary_ready)).orR"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1174-1203
    context: "1174:       e.io.mem_grant.bits := DontCare\n1175:       when (io.mem_grant.bits.source
      === i.U) {\n1176:         e.io.mem_grant <> io.mem_grant\n1177:       }\n1178:\
      \ \n1179:       when(miss_req_pipe_reg.reg_valid() && miss_req_pipe_reg.mshr_id
      === i.U) {\n1180:         e.io.miss_req_pipe_reg := miss_req_pipe_reg\n1181:\
      \       }.otherwise {\n1182:         e.io.miss_req_pipe_reg       := DontCare\n\
      1183:         e.io.miss_req_pipe_reg.merge := false.B\n1184:         e.io.miss_req_pipe_reg.alloc
      := false.B\n1185:       }\n1186: \n1187:       e.io.acquire_fired_by_pipe_reg
      := acquire_from_pipereg.fire\n1188: \n1189:       e.io.main_pipe_resp := io.main_pipe_resp.valid
      && io.main_pipe_resp.bits.ack_miss_queue && io.main_pipe_resp.bits.miss_id ===
      i.U\n1190:       e.io.main_pipe_replay := io.mainpipe_info.s2_valid && io.mainpipe_info.s2_replay_to_mq
      && io.mainpipe_info.s2_miss_id === i.U\n1191:       e.io.main_pipe_evict_BtoT_way
      := io.mainpipe_info.s2_valid && io.mainpipe_info.s2_evict_BtoT_way && io.mainpipe_info.s2_miss_id
      === i.U\n1192:       e.io.main_pipe_next_evict_way := io.mainpipe_info.s2_next_evict_way\n\
      1193:       e.io.main_pipe_refill_resp := io.mainpipe_info.s3_valid && io.mainpipe_info.s3_refill_resp
      && io.mainpipe_info.s3_miss_id === i.U\n1194: \n1195:       e.io.memSetPattenDetected
      := memSetPattenDetected\n1196:       e.io.nMaxPrefetchEntry := nMaxPrefetchEntry\n\
      1197: \n1198:       e.io.main_pipe_req.ready := io.main_pipe_req.ready\n1199:\
      \ \n1200:       for (j <- 0 until reqNum) {\n1201:         e.io.queryME(j).req.valid
      := io.queryMQ(j).req.valid\n1202:         e.io.queryME(j).req.bits  := io.queryMQ(j).req.bits.toMissReqWoStoreData()\n\
      1203:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1221-1242
    context: "1221:     cmo_unit.io.resp_chanD.valid := false.B\n1222:     cmo_unit.io.resp_chanD.bits
      := DontCare\n1223:   }\n1224:   io.wfi.wfiSafe := (Seq(cmo_unit.io.wfi.wfiSafe)
      ++ entries.map(_.io.wfi.wfiSafe)).reduce(_&&_)\n1225: \n1226:   io.req.ready
      := accept\n1227:   io.refill_to_ldq.valid := Cat(entries.map(_.io.refill_to_ldq.valid)).orR\n\
      1228:   io.refill_to_ldq.bits := ParallelMux(entries.map(_.io.refill_to_ldq.valid)
      zip entries.map(_.io.refill_to_ldq.bits))\n1229: \n1230:   io.refill_info.valid
      := VecInit(entries.zipWithIndex.map{ case(e,i) => e.io.refill_info.valid &&
      io.mainpipe_info.s2_valid && io.mainpipe_info.s2_miss_id === i.U}).asUInt.orR\n\
      1231:   io.refill_info.bits := Mux1H(entries.zipWithIndex.map{ case(e,i) =>
      (io.mainpipe_info.s2_miss_id === i.U) -> e.io.refill_info.bits })\n1232: \n\
      1233:   acquire_from_pipereg.valid := miss_req_pipe_reg.can_send_acquire(io.req.valid,
      io.req.bits) && !io.wfi.wfiReq\n1234:   acquire_from_pipereg.bits := miss_req_pipe_reg.get_acquire(io.l2_pf_store_only)\n\
      1235: \n1236:   XSPerfAccumulate(\"acquire_fire_from_pipereg\", acquire_from_pipereg.fire)\n\
      1237:   XSPerfAccumulate(\"pipereg_valid\", miss_req_pipe_reg.reg_valid())\n\
      1238: \n1239:   val acquire_sources = Seq(cmo_unit.io.req_chanA, acquire_from_pipereg)
      ++ entries.map(_.io.mem_acquire)\n1240:   TLArbiter.lowest(edge, io.mem_acquire,
      acquire_sources:_*)\n1241:   TLArbiter.lowest(edge, io.mem_finish, entries.map(_.io.mem_finish):_*)\n\
      1242: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1246-1260
    context: "1246:   io.probe.block := Cat(probe_block_vec).orR\n1247:   io.replace.block
      := Cat(entries.map {\n1248:     case e =>\n1249:       e.io.replace.req <> io.replace.req\n\
      1250:       e.io.replace.block\n1251:   } :+ miss_req_pipe_reg.block_and_alias_match(io.replace.req.bits)).orR\n\
      1252: \n1253:   val btot_evict_set_hit = entries.map(e => e.io.req_isBtoT &&
      e.io.req_vaddr.valid && addr_to_dcache_set(e.io.req_vaddr.bits) === io.evict_set)
      ++\n1254:     Seq(miss_req_pipe_reg.evict_set_match(io.evict_set))\n1255:  \
      \ val btot_occupy_ways = entries.map(e => e.io.occupy_way) ++ Seq(miss_req_pipe_reg.req.occupy_way)\n\
      1256:   io.btot_ways_for_set := btot_evict_set_hit.zip(btot_occupy_ways).map
      {\n1257:     case (hit, way) => Fill(nWays, hit) & way\n1258:   }.reduce(_|_)\n\
      1259: \n1260:   // LoadPipe occupy check"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1258-1269
    context: "1258:   }.reduce(_|_)\n1259: \n1260:   // LoadPipe occupy check\n1261:\
      \   for (i <- 0 until LoadPipelineWidth) {\n1262:     val occupy_set_hits =
      entries.map(\n1263:       e => e.io.req_isBtoT && e.io.req_vaddr.valid && addr_to_dcache_set(e.io.req_vaddr.bits)
      === io.occupy_set(i)\n1264:     ) ++ Seq(miss_req_pipe_reg.evict_set_match(io.occupy_set(i)))\n\
      1265:     val occupy_ways = occupy_set_hits.zip(btot_occupy_ways).map {\n1266:\
      \       case (hit, way) => Fill(nWays, hit) & way\n1267:     }.reduce(_|_)\n\
      1268:     io.occupy_fail(i) := PopCount(occupy_ways) > (nWays-2).U\n1269:  \
      \ }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1269-1286
    context: "1269:   }\n1270: \n1271:   io.full := ~Cat(entries.map(_.io.primary_ready)).andR\n\
      1272: \n1273:   // prefetch related\n1274:   io.prefetch_info.naive.late_miss_prefetch
      := io.req.valid && io.req.bits.isPrefetchRead && (miss_req_pipe_reg.matched(io.req.bits)
      || Cat(entries.map(_.io.matched)).orR)\n1275: \n1276:   io.prefetch_info.fdp.late_miss_prefetch
      := (miss_req_pipe_reg.prefetch_late_en(io.req.bits.toMissReqWoStoreData(), io.req.valid)
      || Cat(entries.map(_.io.prefetch_info.late_prefetch)).orR)\n1277:   io.prefetch_info.fdp.prefetch_monitor_cnt
      := io.main_pipe_req.fire\n1278:   io.prefetch_info.fdp.total_prefetch := alloc
      && io.req.valid && !io.req.bits.cancel && isFromL1Prefetch(io.req.bits.pf_source)\n\
      1279: \n1280:   // L1MissTrace Chisel DB\n1281:   val debug_miss_trace = Wire(new
      L1MissTrace)\n1282:   debug_miss_trace.vaddr := io.req.bits.vaddr\n1283:   debug_miss_trace.paddr
      := io.req.bits.addr\n1284:   debug_miss_trace.source := io.req.bits.source\n\
      1285:   debug_miss_trace.pc := io.req.bits.pc\n1286: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1283-1293
    context: "1283:   debug_miss_trace.paddr := io.req.bits.addr\n1284:   debug_miss_trace.source
      := io.req.bits.source\n1285:   debug_miss_trace.pc := io.req.bits.pc\n1286:\
      \ \n1287:   val isWriteL1MissQMissTable = Constantin.createRecord(s\"isWriteL1MissQMissTable${p(XSCoreParamsKey).HartId}\"\
      )\n1288:   val table = ChiselDB.createTable(s\"L1MissQMissTrace_hart${p(XSCoreParamsKey).HartId}\"\
      , new L1MissTrace)\n1289:   table.log(debug_miss_trace, isWriteL1MissQMissTable.orR
      && io.req.valid && !io.req.bits.cancel && alloc, \"MissQueue\", clock, reset)\n\
      1290: \n1291:   // Difftest\n1292:   if (env.EnableDifftest) {\n1293:     val
      difftest = DifftestModule(new DiffRefillEvent, dontCare = true)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1298-1318
    context: "1298:     difftest.data := io.refill_to_ldq.bits.data_raw.asTypeOf(difftest.data)\n\
      1299:     difftest.idtfr := DontCare\n1300:   }\n1301: \n1302:   // Perf count\n\
      1303:   XSPerfAccumulate(\"miss_req\", io.req.fire && !io.req.bits.cancel)\n\
      1304:   XSPerfAccumulate(\"miss_req_allocate\", io.req.fire && !io.req.bits.cancel
      && alloc)\n1305:   XSPerfAccumulate(\"miss_req_load_allocate\", io.req.fire
      && !io.req.bits.cancel && alloc && io.req.bits.isFromLoad)\n1306:   XSPerfAccumulate(\"\
      miss_req_store_allocate\", io.req.fire && !io.req.bits.cancel && alloc && io.req.bits.isFromStore)\n\
      1307:   XSPerfAccumulate(\"miss_req_amo_allocate\", io.req.fire && !io.req.bits.cancel
      && alloc && io.req.bits.isFromAMO)\n1308:   XSPerfAccumulate(\"miss_req_prefetch_allocate\"\
      , io.req.fire && !io.req.bits.cancel && alloc && io.req.bits.isFromPrefetch)\n\
      1309:   XSPerfAccumulate(\"miss_req_merge_load\", io.req.fire && !io.req.bits.cancel
      && merge && io.req.bits.isFromLoad)\n1310:   XSPerfAccumulate(\"miss_req_reject_load\"\
      , io.req.valid && !io.req.bits.cancel && reject && io.req.bits.isFromLoad)\n\
      1311:   XSPerfAccumulate(\"probe_blocked_by_miss\", io.probe.block)\n1312: \
      \  XSPerfAccumulate(\"prefetch_primary_fire\", io.req.fire && !io.req.bits.cancel
      && alloc && io.req.bits.isFromPrefetch)\n1313:   XSPerfAccumulate(\"prefetch_secondary_fire\"\
      , io.req.fire && !io.req.bits.cancel && merge && io.req.bits.isFromPrefetch)\n\
      1314:   XSPerfAccumulate(\"memSetPattenDetected\", memSetPattenDetected)\n1315:\
      \   val max_inflight = RegInit(0.U((log2Up(cfg.nMissEntries) + 1).W))\n1316:\
      \   val num_valids = PopCount(~Cat(primary_ready_vec).asUInt)\n1317:   when
      (num_valids > max_inflight) {\n1318:     max_inflight := num_valids"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1333-1343
    context: "1333:   XSPerfAccumulate(\"miss_amo_refill_latency\", PopCount(entries.map(_.io.latency_monitor.amo_miss_refilling)))\n\
      1334:   XSPerfAccumulate(\"miss_pf_refill_latency\", PopCount(entries.map(_.io.latency_monitor.pf_miss_refilling)))\n\
      1335: \n1336:   val rob_head_miss_in_dcache = VecInit(entries.map(_.io.rob_head_query.resp)).asUInt.orR\n\
      1337: \n1338:   entries.foreach {\n1339:     case e => {\n1340:       e.io.rob_head_query.query_valid
      := io.debugTopDown.robHeadVaddr.valid\n1341:       e.io.rob_head_query.vaddr
      := io.debugTopDown.robHeadVaddr.bits\n1342:     }\n1343:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 1344-1354
    context: "1344: \n1345:   io.debugTopDown.robHeadMissInDCache := rob_head_miss_in_dcache\n\
      1346: \n1347:   val perfValidCount = RegNext(PopCount(entries.map(entry => (!entry.io.primary_ready))))\n\
      1348:   val perfEvents = Seq(\n1349:     (\"dcache_missq_req      \", io.req.fire),\n\
      1350:     (\"dcache_missq_1_4_valid\", (perfValidCount < (cfg.nMissEntries.U/4.U))),\n\
      1351:     (\"dcache_missq_2_4_valid\", (perfValidCount > (cfg.nMissEntries.U/4.U))
      & (perfValidCount <= (cfg.nMissEntries.U/2.U))),\n1352:     (\"dcache_missq_3_4_valid\"\
      , (perfValidCount > (cfg.nMissEntries.U/2.U)) & (perfValidCount <= (cfg.nMissEntries.U*3.U/4.U))),\n\
      1353:     (\"dcache_missq_4_4_valid\", (perfValidCount > (cfg.nMissEntries.U*3.U/4.U))),\n\
      1354:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 106-121
    context: "106:   val set = UInt(idxBits.W)\n107:   val way_en = UInt(nWays.W)\n\
      108: }\n109: \n110: class MainPipeInfoToMQ(implicit p:Parameters) extends DCacheBundle
      {\n111:   val s2_valid = Bool()\n112:   val s2_miss_id = UInt(log2Up(cfg.nMissEntries).W)
      // For refill data selection\n113:   val s2_replay_to_mq = Bool()\n114:   val
      s2_evict_BtoT_way = Bool()\n115:   val s2_next_evict_way = UInt(nWays.W)\n116:\
      \   val s3_valid = Bool()\n117:   val s3_miss_id = UInt(log2Up(cfg.nMissEntries).W)
      // For mshr release\n118:   val s3_refill_resp = Bool()\n119: }\n120: \n121:
      class MainPipe(implicit p: Parameters) extends DCacheModule with HasPerfEvents
      with HasL1PrefetchSourceParameter {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 121-131
    context: "121: class MainPipe(implicit p: Parameters) extends DCacheModule with
      HasPerfEvents with HasL1PrefetchSourceParameter {\n122:   val io = IO(new Bundle()
      {\n123:     // probe queue\n124:     val probe_req = Flipped(DecoupledIO(new
      MainPipeReq))\n125:     // store miss go to miss queue\n126:     val miss_req
      = DecoupledIO(new MissReq)\n127:     val miss_resp = Input(new MissResp) //
      miss resp is used to support plru update\n128:     val refill_req = Flipped(DecoupledIO(new
      MainPipeReq))\n129:     // send miss request to wbq\n130:     val wbq_conflict_check
      = Valid(UInt())\n131:     val wbq_block_miss_req = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 140-150
    context: "140:     val mainpipe_info = Output(new MainPipeInfoToMQ)\n141:    \
      \ // missqueue refill data\n142:     val refill_info = Flipped(ValidIO(new MissQueueRefillInfo))\n\
      143:     // write-back queue\n144:     val wb = DecoupledIO(new WritebackReq)\n\
      145:     val wb_ready_dup = Vec(nDupWbReady, Input(Bool()))\n146: \n147:   \
      \  // data sram\n148:     val data_read = Vec(LoadPipelineWidth, Input(Bool()))\n\
      149:     val data_read_intend = Output(Bool())\n150:     val data_readline =
      DecoupledIO(new L1BankedDataReadLineReq)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 166-176
    context: "166:     val error_flag_write = DecoupledIO(new FlagMetaWriteReq)\n\
      167:     val prefetch_flag_write = DecoupledIO(new SourceMetaWriteReq)\n168:\
      \     val access_flag_write = DecoupledIO(new FlagMetaWriteReq)\n169: \n170:\
      \     // tag sram\n171:     val tag_read = DecoupledIO(new TagReadReq)\n172:\
      \     val tag_resp = Input(Vec(nWays, UInt(encTagBits.W)))\n173:     val tag_write
      = DecoupledIO(new TagWriteReq)\n174:     val tag_write_ready_dup = Vec(nDupTagWriteReady,
      Input(Bool()))\n175:     val tag_write_intend = Output(new Bool())\n176: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 215-226
    context: "215:       val clr = ValidIO(new BloomQueryBundle(BLOOM_FILTER_ENTRY_NUM))\n\
      216:     }\n217:   })\n218: \n219:   // meta array is made of regs, so meta
      write or read should always be ready\n220:   assert(RegNext(io.meta_read.ready))\n\
      221:   assert(RegNext(io.meta_write.ready))\n222: \n223:   val s1_s0_set_conflict,
      s2_s0_set_conlict, s3_s0_set_conflict = Wire(Bool())\n224:   val set_conflict
      = s1_s0_set_conflict || s2_s0_set_conlict || s3_s0_set_conflict\n225:   // check
      sbuffer store req set_conflict in parallel with req arbiter\n226:   // it will
      speed up the generation of store_req.ready, which is in crit. path"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 224-234
    context: "224:   val set_conflict = s1_s0_set_conflict || s2_s0_set_conlict ||
      s3_s0_set_conflict\n225:   // check sbuffer store req set_conflict in parallel
      with req arbiter\n226:   // it will speed up the generation of store_req.ready,
      which is in crit. path\n227:   val s1_s0_set_conflict_store, s2_s0_set_conlict_store,
      s3_s0_set_conflict_store = Wire(Bool())\n228:   val store_set_conflict = s1_s0_set_conflict_store
      || s2_s0_set_conlict_store || s3_s0_set_conflict_store\n229:   val s1_ready,
      s2_ready, s3_ready = Wire(Bool())\n230: \n231:   // convert store req to main
      pipe req, and select a req from store and probe\n232:   val storeWaitCycles
      = RegInit(0.U(4.W))\n233:   val StoreWaitThreshold = Wire(UInt(4.W))\n234: \
      \  StoreWaitThreshold := Constantin.createRecord(s\"StoreWaitThreshold_${p(XSCoreParamsKey).HartId}\"\
      , initValue = 0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 237-252
    context: "237:   val storeCanAccept = storeWaitTooLong || !loadsAreComing || io.force_write\n\
      238: \n239:   val store_req = Wire(DecoupledIO(new MainPipeReq))\n240:   store_req.bits
      := (new MainPipeReq).convertStoreReq(io.store_req.bits)\n241:   store_req.valid
      := io.store_req.valid && storeCanAccept\n242:   io.store_req.ready := store_req.ready
      && storeCanAccept\n243: \n244: \n245:   when (store_req.fire) { // if wait too
      long and write success, reset counter.\n246:     storeWaitCycles := 0.U\n247:\
      \   } .elsewhen (storeWaitCycles < StoreWaitThreshold && io.store_req.valid
      && !store_req.ready) { // if block store, increase counter.\n248:     storeWaitCycles
      := storeWaitCycles + 1.U\n249:   }\n250: \n251:   // s0: read meta and tag\n\
      252:   val req = Wire(DecoupledIO(new MainPipeReq))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 252-262
    context: "252:   val req = Wire(DecoupledIO(new MainPipeReq))\n253:   arbiter(\n\
      254:     in = Seq(\n255:       io.probe_req,\n256:       io.refill_req,\n257:\
      \       store_req, // Note: store_req.ready is now manually assigned for better
      timing\n258:       io.atomic_req,\n259:     ),\n260:     out = req,\n261:  \
      \   name = Some(\"main_pipe_req\")\n262:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 262-280
    context: "262:   )\n263: \n264:   val store_idx = get_idx(io.store_req.bits.vaddr)\n\
      265:   // manually assign store_req.ready for better timing\n266:   // now store_req
      set conflict check is done in parallel with req arbiter\n267:   store_req.ready
      := io.meta_read.ready && io.tag_read.ready && s1_ready && !store_set_conflict
      &&\n268:     !io.probe_req.valid && !io.refill_req.valid && !io.atomic_req.valid\n\
      269:   val s0_req = req.bits\n270:   val s0_idx = get_idx(s0_req.vaddr)\n271:\
      \   val s0_need_tag = io.tag_read.valid\n272:   val s0_can_go = io.meta_read.ready
      && io.tag_read.ready && s1_ready && !set_conflict\n273:   val s0_fire = req.valid
      && s0_can_go\n274: \n275:   req.ready := s0_can_go\n276: \n277:   val bank_write
      = VecInit((0 until DCacheBanks).map(i => get_mask_of_bank(i, s0_req.store_mask).orR)).asUInt\n\
      278:   val bank_full_write = VecInit((0 until DCacheBanks).map(i => get_mask_of_bank(i,
      s0_req.store_mask).andR)).asUInt\n279:   val banks_full_overwrite = bank_full_write.andR\n\
      280: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 300-310
    context: "300:   val banked_store_wmask = bank_write\n301:   val banked_full_wmask
      = ~0.U(DCacheBanks.W)\n302:   val banked_none_wmask = 0.U(DCacheBanks.W)\n303:\
      \ \n304:   // s1: read data\n305:   val s1_valid = RegInit(false.B)\n306:  \
      \ val s1_need_data = RegEnable(banked_need_data, s0_fire)\n307:   val s1_req
      = RegEnable(s0_req, s0_fire)\n308:   val s1_banked_rmask = RegEnable(s0_banked_rmask,
      s0_fire)\n309:   val s1_banked_store_wmask = RegEnable(banked_store_wmask, s0_fire)\n\
      310:   val s1_need_tag = RegEnable(s0_need_tag, s0_fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 306-332
    context: "306:   val s1_need_data = RegEnable(banked_need_data, s0_fire)\n307:\
      \   val s1_req = RegEnable(s0_req, s0_fire)\n308:   val s1_banked_rmask = RegEnable(s0_banked_rmask,
      s0_fire)\n309:   val s1_banked_store_wmask = RegEnable(banked_store_wmask, s0_fire)\n\
      310:   val s1_need_tag = RegEnable(s0_need_tag, s0_fire)\n311:   val s1_can_go
      = s2_ready && (io.data_readline.ready || !s1_need_data)\n312:   val s1_fire
      = s1_valid && s1_can_go\n313:   val s1_idx = get_idx(s1_req.vaddr)\n314:   val
      s1_dmWay = RegEnable(get_direct_map_way(s0_req.vaddr), s0_fire)\n315: \n316:\
      \   when (s0_fire) {\n317:     s1_valid := true.B\n318:   }.elsewhen (s1_fire)
      {\n319:     s1_valid := false.B\n320:   }\n321:   s1_ready := !s1_valid || s1_can_go\n\
      322:   s1_s0_set_conflict := s1_valid && s0_idx === s1_idx\n323:   s1_s0_set_conflict_store
      := s1_valid && store_idx === s1_idx\n324: \n325:   def wayMap[T <: Data](f:
      Int => T) = VecInit((0 until nWays).map(f))\n326:   val meta_resp = Wire(Vec(nWays,
      (new Meta).asUInt))\n327:   meta_resp := Mux(GatedValidRegNext(s0_fire), VecInit(io.meta_resp.map(_.asUInt)),
      RegEnable(meta_resp, s1_valid))\n328:   // pseudo ecc enc tag\n329:   val pseudo_tag_toggle_mask
      = Mux(\n330:                                   io.pseudo_error.valid && io.pseudo_error.bits(0).valid,\n\
      331:                                   io.pseudo_error.bits(0).mask(tagBits
      - 1, 0),\n332:                                   0.U(tagBits.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 340-358
    context: "340:       } else {\n341:         real_enc\n342:       }\n343:   }\n\
      344:   val encTag_resp = Wire(io.tag_resp.cloneType)\n345:   encTag_resp :=
      Mux(GatedValidRegNext(s0_fire), VecInit(pseudo_encTag_resp), RegEnable(encTag_resp,
      s1_valid))\n346:   val tag_resp = encTag_resp.map(encTag => encTag(tagBits -
      1, 0))\n347:   val s1_meta_valids = wayMap((w: Int) => Meta(meta_resp(w)).coh.isValid()).asUInt\n\
      348:   val s1_tag_errors = wayMap((w: Int) => s1_meta_valids(w) && dcacheParameters.tagCode.decode(encTag_resp(w)).error).asUInt\n\
      349:   val s1_tag_eq_way = wayMap((w: Int) => tag_resp(w) === get_tag(s1_req.addr)).asUInt\n\
      350:   val s1_tag_ecc_eq_way = wayMap((w: Int) => s1_tag_eq_way(w) && !s1_tag_errors(w)).asUInt\n\
      351:   val s1_tag_ecc_match_way = wayMap((w: Int) => s1_tag_ecc_eq_way(w) &&
      s1_meta_valids(w)).asUInt\n352:   val s1_tag_match = ParallelORR(s1_tag_ecc_match_way)\n\
      353:   val s1_real_tag_eq_way = wayMap((w: Int) => io.tag_resp(w)(tagBits -
      1, 0) === get_tag(s1_req.addr) && s1_meta_valids(w)).asUInt\n354:   val s1_has_real_tag_eq_way
      = ParallelORR(s1_real_tag_eq_way)\n355:   val s1_real_tag_match_way = PriorityEncoderOH(s1_real_tag_eq_way)\n\
      356: \n357:   val s1_hit_tag = get_tag(s1_req.addr)\n358:   val s1_hit_coh =
      ClientMetadata(ParallelMux(s1_tag_ecc_match_way.asBools, (0 until nWays).map(w
      => meta_resp(w))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 354-371
    context: "354:   val s1_has_real_tag_eq_way = ParallelORR(s1_real_tag_eq_way)\n\
      355:   val s1_real_tag_match_way = PriorityEncoderOH(s1_real_tag_eq_way)\n356:\
      \ \n357:   val s1_hit_tag = get_tag(s1_req.addr)\n358:   val s1_hit_coh = ClientMetadata(ParallelMux(s1_tag_ecc_match_way.asBools,
      (0 until nWays).map(w => meta_resp(w))))\n359:   val s1_extra_meta = Wire(io.extra_meta_resp.head.cloneType)\n\
      360:   s1_extra_meta := Mux(\n361:     GatedValidRegNext(s0_fire),\n362:   \
      \  ParallelMux(s1_tag_ecc_match_way.asBools, (0 until nWays).map(w => io.extra_meta_resp(w))),\n\
      363:     RegEnable(s1_extra_meta, s1_valid)\n364:   )\n365:   val s1_flag_error
      = s1_extra_meta.error\n366:   io.pseudo_tag_error_inj_done := s1_fire && s1_meta_valids.orR\n\
      367: \n368:   XSPerfAccumulate(\"probe_unused_prefetch\", s1_req.probe && isFromL1Prefetch(s1_extra_meta.prefetch)
      && !s1_extra_meta.access) // may not be accurate\n369:   XSPerfAccumulate(\"\
      replace_unused_prefetch\", s1_req.replace && isFromL1Prefetch(s1_extra_meta.prefetch)
      && !s1_extra_meta.access) // may not be accurate\n370: \n371:   // replacement
      policy"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 378-388
    context: "378:     Mux(\n379:       io.pseudo_error.valid && s1_has_real_tag_eq_way,\n\
      380:       s1_real_tag_match_way,\n381:       Mux(s1_req.miss_fail_cause_evict_btot,
      s1_req.occupy_way, UIntToOH(io.replace_way.way)\n382:     )),\n383:     RegEnable(s1_repl_way_en,
      s1_valid)\n384:   )\n385:   val s1_repl_tag = ParallelMux(s1_repl_way_en.asBools,
      (0 until nWays).map(w => tag_resp(w)))\n386:   val s1_repl_coh = ParallelMux(s1_repl_way_en.asBools,
      (0 until nWays).map(w => meta_resp(w))).asTypeOf(new ClientMetadata)\n387: \
      \  val s1_repl_pf  = ParallelMux(s1_repl_way_en.asBools, (0 until nWays).map(w
      => io.extra_meta_resp(w).prefetch))\n388: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 387-397
    context: "387:   val s1_repl_pf  = ParallelMux(s1_repl_way_en.asBools, (0 until
      nWays).map(w => io.extra_meta_resp(w).prefetch))\n388: \n389:   val s1_real_tag
      = ParallelMux(s1_repl_way_en.asBools, (0 until nWays).map(w => io.tag_resp(w)))\n\
      390: \n391:   val s1_need_replacement = s1_req.miss && !s1_tag_match\n392: \
      \  val s1_need_eviction = s1_req.miss && !s1_tag_match && s1_repl_coh.state
      =/= ClientStates.Nothing\n393: \n394:   val s1_way_en = Mux(io.pseudo_error.valid
      || s1_need_replacement, s1_repl_way_en, s1_tag_ecc_match_way)\n395:   assert(!RegNext(s1_fire
      && PopCount(s1_way_en) > 1.U))\n396: \n397:   val s1_tag = s1_hit_tag"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 406-416
    context: "406:   val s1_isAMO = !s1_req.replace && !s1_req.probe && !s1_req.miss
      && s1_req.isAMO && s1_req.cmd =/= M_XSC\n407:   val s1_pregen_can_go_to_mq =
      (s1_isStore || s1_isAMO) && !s1_hit\n408:   val s1_grow_perm = s1_shrink_perm
      === BtoT && !s1_has_permission\n409: \n410:   // s2: select data, return resp
      if this is a store miss\n411:   val s2_valid = RegInit(false.B)\n412:   val
      s2_req = RegEnable(s1_req, s1_fire)\n413:   val s2_tag_errors = RegEnable(s1_tag_errors,
      s1_fire)\n414:   val s2_tag_match = RegEnable(s1_tag_match, s1_fire)\n415: \
      \  val s2_has_real_tag_eq_way = RegEnable(s1_has_real_tag_eq_way, s1_fire)\n\
      416:   val s2_tag_ecc_match_way = RegEnable(s1_tag_ecc_match_way, s1_fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 440-450
    context: "440:   val s2_flag_error = RegEnable(s1_flag_error, s1_fire)\n441: \
      \  val s2_tag_error = WireInit(false.B)\n442:   val s2_l2_error = Mux(io.refill_info.valid,
      io.refill_info.bits.error, s2_req.error)\n443:   val s2_error = s2_flag_error
      || s2_tag_error || s2_l2_error // data_error not included\n444: \n445:   val
      s2_may_report_data_error = s2_need_data && s2_coh.state =/= ClientStates.Nothing\n\
      446: \n447:   val s2_hit = (s2_tag_match || s2_refill_tag_eq_way) && s2_has_permission\n\
      448:   val s2_sc = s2_req.cmd === M_XSC\n449:   val s2_lr = s2_req.cmd === M_XLR\n\
      450:   val s2_amo_hit = s2_hit && !s2_req.probe && !s2_req.miss && s2_req.isAMO"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 456-467
    context: "456:     val s2_probe_atomic_tag_error = s2_probe_or_atomic && !s2_tag_match
      && s2_tag_errors.orR\n457:     val s2_evict_tag_error = !s2_probe_or_atomic
      && (s2_tag_errors & s2_way_en).orR\n458:     s2_tag_error := (s2_probe_atomic_tag_error
      || s2_evict_tag_error) && s2_need_tag\n459:   }\n460: \n461:   s2_s0_set_conlict
      := s2_valid && s0_idx === s2_idx\n462:   s2_s0_set_conlict_store := s2_valid
      && store_idx === s2_idx\n463: \n464:   // Grow permission fail\n465:   // Only
      in case BtoT will both cache and missqueue be occupied\n466:   val s2_has_more_then_3_ways_BtoT
      = PopCount(io.btot_ways_for_set) > (nWays-2).U\n467:   val s2_grow_perm_fail
      = s2_has_more_then_3_ways_BtoT && s2_grow_perm"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 463-473
    context: "463: \n464:   // Grow permission fail\n465:   // Only in case BtoT will
      both cache and missqueue be occupied\n466:   val s2_has_more_then_3_ways_BtoT
      = PopCount(io.btot_ways_for_set) > (nWays-2).U\n467:   val s2_grow_perm_fail
      = s2_has_more_then_3_ways_BtoT && s2_grow_perm\n468:   XSError(s2_valid && s2_grow_perm
      && io.btot_ways_for_set.andR,\n469:     \"BtoT grow permission, but all ways
      are BtoT\\n\"\n470:   )\n471: \n472:   // For a store req, it either hits and
      goes to s3, or miss and enter miss queue immediately\n473:   val s2_replace_block
      = io.replace.block && io.replace.req.valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 469-480
    context: "469:     \"BtoT grow permission, but all ways are BtoT\\n\"\n470:  \
      \ )\n471: \n472:   // For a store req, it either hits and goes to s3, or miss
      and enter miss queue immediately\n473:   val s2_replace_block = io.replace.block
      && io.replace.req.valid\n474:   val s2_req_miss_without_data = Mux(s2_valid,
      s2_req.miss && !io.refill_info.valid, false.B)\n475:   val s2_can_go_to_mq_no_data
      = (s2_req_miss_without_data && RegEnable(s2_req_miss_without_data && !io.mainpipe_info.s2_replay_to_mq,
      false.B, s2_valid)) // miss_req in s2 but refill data is invalid, can block
      1 cycle\n476:   val s2_can_go_to_mq_evict_fail = s2_replace_block // dcache
      and miss queue both occupy the same set, (BtoT scheme)\n477:   val s2_can_go_to_mq_replay
      = s2_can_go_to_mq_no_data || s2_can_go_to_mq_evict_fail\n478:   val s2_can_go_to_mq
      = RegEnable(s1_pregen_can_go_to_mq, s1_fire)\n479:   val s2_can_go_to_s3 = (s2_sc
      || s2_req.replace || s2_req.probe ||\n480:     Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 480-504
    context: "480:     Mux(\n481:       s2_req.miss,\n482:       io.refill_info.valid
      && !s2_replace_block,\n483:       (s2_req.isStore || s2_req.isAMO) && s2_hit\n\
      484:     )\n485:   ) && s3_ready\n486:   assert(RegNext(!(s2_valid && s2_can_go_to_s3
      && s2_can_go_to_mq && s2_can_go_to_mq_replay)))\n487:   val s2_can_go = s2_can_go_to_s3
      || s2_can_go_to_mq || s2_can_go_to_mq_replay\n488:   val s2_fire = s2_valid
      && s2_can_go\n489:   val s2_fire_to_s3 = s2_valid && s2_can_go_to_s3\n490: \
      \  when (s1_fire) {\n491:     s2_valid := true.B\n492:   }.elsewhen (s2_fire)
      {\n493:     s2_valid := false.B\n494:   }\n495:   s2_ready := !s2_valid || s2_can_go\n\
      496:   val replay = !io.miss_req.ready || io.wbq_block_miss_req\n497: \n498:\
      \   io.data_readline_can_go := GatedValidRegNext(s1_fire)\n499:   io.data_readline_stall
      := s2_valid\n500:   io.data_readline_can_resp := s2_fire_to_s3\n501: \n502:\
      \   def mergePutData(old_data: UInt, new_data: UInt, wmask: UInt): UInt = {\n\
      503:     val full_wmask = FillInterleaved(8, wmask)\n504:     ((~full_wmask
      & old_data) | (full_wmask & new_data))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 512-526
    context: "512:     s2_merge_mask(i) := Mux(s2_amo_hit, 0.U(wordBytes.W), get_mask_of_bank(i,
      Mux(s2_req.miss, io.refill_info.bits.store_mask, s2_req.store_mask)))\n513:\
      \     s2_store_data_merged_without_cache(i) := mergePutData(0.U(DCacheSRAMRowBits.W),
      new_data, s2_merge_mask(i))\n514:   }\n515: \n516:   io.pseudo_data_error_inj_done
      := s2_fire_to_s3 && (s2_tag_error || s2_hit) && s2_may_report_data_error\n517:\
      \   io.pseudo_error.ready := false.B\n518:   XSError(s2_valid && s2_can_go_to_s3
      && s2_req.miss && !io.refill_info.valid, \"MainPipe req can go to s3 but no
      refill data\")\n519: \n520:   // s3: write data, meta and tag\n521:   val s3_valid
      = RegInit(false.B)\n522:   val s3_req = RegEnable(s2_req, s2_fire_to_s3)\n523:\
      \   val s3_miss_param = RegEnable(io.refill_info.bits.miss_param, s2_fire_to_s3)\n\
      524:   val s3_miss_dirty = RegEnable(io.refill_info.bits.miss_dirty, s2_fire_to_s3)\n\
      525:   val s3_tag = RegEnable(s2_tag, s2_fire_to_s3)\n526:   val s3_tag_match
      = RegEnable(s2_tag_match, s2_fire_to_s3)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 555-565
    context: "555: \n556:   val s3_sc_fail  = Wire(Bool()) // miss or lr mismatch\n\
      557:   val s3_need_replacement = RegEnable(s2_need_replacement && !s2_refill_tag_eq_way,
      s2_fire_to_s3)\n558: \n559:   val (_, probe_shrink_param, probe_new_coh) = s3_coh.onProbe(s3_req.probe_param)\n\
      560:   val (_, miss_shrink_param, _) = s3_coh.onCacheControl(M_FLUSH)\n561:\
      \ \n562:   val miss_update_meta = s3_req.miss\n563:   val probe_update_meta
      = s3_req.probe && s3_tag_match && s3_coh =/= probe_new_coh\n564:   val store_update_meta
      = s3_req.isStore && !s3_req.probe && s3_hit_coh =/= s3_new_hit_coh\n565:   val
      amo_update_meta = s3_req.isAMO && !s3_req.probe && s3_hit_coh =/= s3_new_hit_coh
      && !s3_sc_fail"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 604-614
    context: "604:   val debug_sc_fail_addr = RegInit(0.U)\n605:   val debug_sc_fail_cnt\
      \  = RegInit(0.U(8.W))\n606:   val debug_sc_addr_match_fail_cnt  = RegInit(0.U(8.W))\n\
      607: \n608:   val lrsc_count = RegInit(0.U(log2Ceil(LRSCCycles).W))\n609:  \
      \ val lrsc_valid = lrsc_count > LRSCBackOff.U\n610:   val lrsc_addr = Reg(UInt())\n\
      611: \n612:   val s3_s_amoalu = RegInit(false.B)\n613:   val s3_lr = !s3_req.probe
      && s3_req.isAMO && s3_req.cmd === M_XLR\n614:   val s3_sc = !s3_req.probe &&
      s3_req.isAMO && s3_req.cmd === M_XSC"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 611-622
    context: "611: \n612:   val s3_s_amoalu = RegInit(false.B)\n613:   val s3_lr =
      !s3_req.probe && s3_req.isAMO && s3_req.cmd === M_XLR\n614:   val s3_sc = !s3_req.probe
      && s3_req.isAMO && s3_req.cmd === M_XSC\n615:   val s3_cas = !s3_req.probe &&
      s3_req.isAMO && isAMOCAS(s3_req.cmd)\n616:   val s3_lrsc_addr_match = lrsc_valid
      && lrsc_addr === get_block_addr(s3_req.addr)\n617:   val debug_s3_sc_fail_addr_match
      = s3_sc && lrsc_addr === get_block_addr(s3_req.addr) && !lrsc_valid\n618: \n\
      619:   s3_sc_fail  := s3_sc && (!s3_lrsc_addr_match || !s3_hit)\n620:   val
      s3_cas_fail = s3_cas && (FillInterleaved(8, s3_req.amo_mask) & (s3_req.amo_cmp
      ^ s3_data_quad_word)) =/= 0.U\n621: \n622:   val s3_can_do_amo = (s3_req.miss
      && !s3_req.probe && s3_req.isAMO) || s3_amo_hit"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 620-630
    context: "620:   val s3_cas_fail = s3_cas && (FillInterleaved(8, s3_req.amo_mask)
      & (s3_req.amo_cmp ^ s3_data_quad_word)) =/= 0.U\n621: \n622:   val s3_can_do_amo
      = (s3_req.miss && !s3_req.probe && s3_req.isAMO) || s3_amo_hit\n623:   val s3_can_do_amo_write
      = s3_can_do_amo && isWrite(s3_req.cmd) && !s3_sc_fail && !s3_cas_fail\n624:\
      \ \n625:   when (s3_valid && (s3_lr || s3_sc)) {\n626:     when (s3_can_do_amo
      && s3_lr) {\n627:       lrsc_count := (LRSCCycles - 1).U\n628:       lrsc_addr
      := get_block_addr(s3_req.addr)\n629:     } .otherwise {\n630:       lrsc_count
      := 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 636-646
    context: "636:   }.elsewhen (lrsc_count > 0.U) {\n637:     lrsc_count := lrsc_count
      - 1.U\n638:   }\n639: \n640: \n641:   io.lrsc_locked_block.valid := lrsc_valid\n\
      642:   io.lrsc_locked_block.bits  := lrsc_addr\n643:   io.block_lr := GatedValidRegNext(lrsc_count
      > 0.U)\n644: \n645:   // When we update update_resv_set, block all probe req
      in the next cycle\n646:   // It should give Probe reservation set addr compare
      an independent cycle,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 643-655
    context: "643:   io.block_lr := GatedValidRegNext(lrsc_count > 0.U)\n644: \n645:\
      \   // When we update update_resv_set, block all probe req in the next cycle\n\
      646:   // It should give Probe reservation set addr compare an independent cycle,\n\
      647:   // which will lead to better timing\n648:   io.update_resv_set := s3_valid
      && s3_lr && s3_can_do_amo\n649: \n650:   when (s3_valid) {\n651:     when (s3_req.addr
      === debug_sc_fail_addr) {\n652:       when (s3_sc_fail) {\n653:         debug_sc_fail_cnt
      := debug_sc_fail_cnt + 1.U\n654:       } .elsewhen (s3_sc) {\n655:         debug_sc_fail_cnt
      := 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 661-671
    context: "661:       }\n662:     }\n663:   }\n664:   XSWarn(debug_sc_fail_cnt
      > 100.U, \"L1DCache failed too many SCs in a row\")\n665: \n666:   when (s3_valid)
      {\n667:     when (s3_req.addr === debug_sc_fail_addr) {\n668:       when (debug_s3_sc_fail_addr_match)
      {\n669:         debug_sc_addr_match_fail_cnt := debug_sc_addr_match_fail_cnt
      + 1.U\n670:       } .elsewhen (s3_sc) {\n671:         debug_sc_addr_match_fail_cnt
      := 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 682-692
    context: "682:   val banked_amo_wmask = UIntToOH(s3_req.word_idx)\n683:   val
      update_data = s3_req.miss || s3_store_hit || s3_can_do_amo_write\n684: \n685:\
      \   // generate write data\n686:   // AMO hits\n687:   val do_amoalu = amo_wait_amoalu
      && s3_valid && !s3_s_amoalu\n688:   val amoalu   = Module(new AMOALU(wordBits))\n\
      689:   amoalu.io.mask := s3_req.amo_mask\n690:   amoalu.io.cmd  := s3_req.cmd\n\
      691:   amoalu.io.lhs  := s3_data_word\n692:   amoalu.io.rhs  := s3_req.amo_data"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 723-733
    context: "723:         )\n724:       )\n725:     )\n726:   }\n727:   val s3_amo_data_merged_reg
      = RegEnable(s3_amo_data_merged, do_amoalu)\n728:   val miss_wb = s3_req.miss
      && s3_need_replacement && s3_coh.state =/= ClientStates.Nothing\n729:   val
      probe_wb = s3_req.probe\n730:   val replace_wb = s3_req.replace\n731:   val
      need_wb = miss_wb || probe_wb || replace_wb\n732: \n733:   val writeback_param
      = Mux(probe_wb, probe_shrink_param, miss_shrink_param)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 731-763
    context: "731:   val need_wb = miss_wb || probe_wb || replace_wb\n732: \n733:\
      \   val writeback_param = Mux(probe_wb, probe_shrink_param, miss_shrink_param)\n\
      734:   val writeback_data = if (dcacheParameters.alwaysReleaseData) {\n735:\
      \     s3_tag_match && s3_req.probe && s3_req.probe_need_data ||\n736:      \
      \ s3_coh === ClientStates.Dirty || (miss_wb || replace_wb) && s3_coh.state =/=
      ClientStates.Nothing\n737:   } else {\n738:     s3_tag_match && s3_req.probe
      && s3_req.probe_need_data || s3_coh === ClientStates.Dirty\n739:   }\n740: \n\
      741:   val s3_probe_can_go = s3_req.probe && io.wb.ready && (io.meta_write.ready
      || !probe_update_meta)\n742:   val s3_store_can_go = s3_req.source === STORE_SOURCE.U
      && !s3_req.probe && (io.meta_write.ready || !store_update_meta) && (io.data_write.ready
      || !update_data) && !s3_req.miss\n743:   val s3_amo_can_go = s3_amo_hit && (io.meta_write.ready
      || !amo_update_meta) && (io.data_write.ready || !update_data) && (s3_s_amoalu
      || !amo_wait_amoalu) || s3_sc_fail\n744:   val s3_miss_can_go = s3_req.miss
      &&\n745:     (io.meta_write.ready || !amo_update_meta) &&\n746:     (io.data_write.ready
      || !update_data) &&\n747:     (s3_s_amoalu || !amo_wait_amoalu) &&\n748:   \
      \  io.tag_write.ready &&\n749:     io.wb.ready\n750:   val s3_replace_nothing
      = s3_req.replace && s3_coh.state === ClientStates.Nothing\n751:   val s3_replace_can_go
      = s3_req.replace && (s3_replace_nothing || io.wb.ready)\n752:   val s3_can_go
      = s3_probe_can_go || s3_store_can_go || s3_amo_can_go || s3_miss_can_go || s3_replace_can_go\n\
      753:   val s3_update_data_cango = s3_store_can_go || s3_amo_can_go || s3_miss_can_go
      // used to speed up data_write gen\n754:   val s3_fire = s3_valid && s3_can_go\n\
      755:   when (s2_fire_to_s3) {\n756:     s3_valid := true.B\n757:   }.elsewhen
      (s3_fire) {\n758:     s3_valid := false.B\n759:   }\n760:   when (do_amoalu)
      { s3_s_amoalu := true.B }\n761:   when (s3_fire) { s3_s_amoalu := false.B }\n\
      762: \n763:   val s3_probe_new_coh = probe_new_coh"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 789-799
    context: "789:         ),\n790:         banked_none_wmask\n791:       )\n792:\
      \     )\n793:   )\n794:   assert(!(s3_valid && banked_wmask.orR && !update_data))\n\
      795: \n796:   for (i <- 0 until DCacheBanks) {\n797:     val old_data = s3_store_data_merged(i)\n\
      798:     s3_sc_data_merged(i) := mergePutData(old_data, s3_req.amo_data,\n799:\
      \       Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 802-819
    context: "802:         0.U(wordBytes.W)\n803:       )\n804:     )\n805:   }\n\
      806:   for (i <- 0 until DCacheBanks) {\n807:     io.data_write_dup(i).valid
      := s3_valid && s3_update_data_cango && update_data\n808:     io.data_write_dup(i).bits.way_en
      := s3_way_en\n809:     io.data_write_dup(i).bits.addr := s3_req.vaddr\n810:\
      \   }\n811: \n812:   s3_ready := !s3_valid || s3_can_go\n813:   s3_s0_set_conflict
      := s3_valid && s3_idx === s0_idx\n814:   s3_s0_set_conflict_store := s3_valid
      && s3_idx === store_idx\n815:   //assert(RegNext(!s3_valid || !(s3_req.source
      === STORE_SOURCE.U && !s3_req.probe) || s3_hit)) // miss store should never
      come to s3 ,fixed(reserve)\n816: \n817:   io.meta_read.valid := req.valid\n\
      818:   io.meta_read.bits.idx := get_idx(s0_req.vaddr)\n819:   io.meta_read.bits.way_en
      := Mux(s0_req.replace, s0_req.replace_way_en, ~0.U(nWays.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 816-858
    context: "816: \n817:   io.meta_read.valid := req.valid\n818:   io.meta_read.bits.idx
      := get_idx(s0_req.vaddr)\n819:   io.meta_read.bits.way_en := Mux(s0_req.replace,
      s0_req.replace_way_en, ~0.U(nWays.W))\n820: \n821:   io.tag_read.valid := req.valid
      && !s0_req.replace\n822:   io.tag_read.bits.idx := get_idx(s0_req.vaddr)\n823:\
      \   io.tag_read.bits.way_en := ~0.U(nWays.W)\n824: \n825:   io.data_read_intend
      := s1_valid && s1_need_data\n826:   io.data_readline.valid := s1_valid && s1_need_data\n\
      827:   io.data_readline.bits.rmask := s1_banked_rmask\n828:   io.data_readline.bits.way_en
      := s1_way_en\n829:   io.data_readline.bits.addr := s1_req.vaddr\n830: \n831:\
      \   io.miss_req.valid := s2_valid && s2_can_go_to_mq\n832:   val miss_req =
      io.miss_req.bits\n833:   miss_req := DontCare\n834:   miss_req.source := s2_req.source\n\
      835:   miss_req.pf_source := L1_HW_PREFETCH_NULL\n836:   miss_req.cmd := s2_req.cmd\n\
      837:   miss_req.addr := s2_req.addr\n838:   miss_req.vaddr := s2_req.vaddr\n\
      839:   miss_req.store_data := s2_req.store_data\n840:   miss_req.store_mask
      := s2_req.store_mask\n841:   miss_req.word_idx := s2_req.word_idx\n842:   miss_req.amo_data
      := s2_req.amo_data\n843:   miss_req.amo_mask := s2_req.amo_mask\n844:   miss_req.amo_cmp\
      \  := s2_req.amo_cmp\n845:   miss_req.req_coh := s2_hit_coh\n846:   miss_req.id
      := s2_req.id\n847:   miss_req.cancel := s2_grow_perm_fail\n848:   miss_req.pc
      := DontCare\n849:   miss_req.full_overwrite := s2_req.isStore && s2_req.store_mask.andR\n\
      850:   miss_req.isBtoT := s2_grow_perm\n851:   miss_req.occupy_way := s2_tag_ecc_match_way\n\
      852: \n853:   io.wbq_conflict_check.valid := s2_valid && s2_can_go_to_mq\n854:\
      \   io.wbq_conflict_check.bits := s2_req.addr\n855: \n856:   /**\n857:     *
      `s2_req.isStore` includes miss requests from Sbuffer sent from MissQueue,\n\
      858:     * while `s2_isStore`` only requests from sbuffer."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 857-876
    context: "857:     * `s2_req.isStore` includes miss requests from Sbuffer sent
      from MissQueue,\n858:     * while `s2_isStore`` only requests from sbuffer.\n\
      859:     * In the case of `BtoT` fail, only requests from sbuffer are allowed
      to return replay response.\n860:     */\n861:   val s2_isStore = RegEnable(s1_isStore,
      s1_fire)\n862:   io.store_replay_resp.valid := s2_valid && (s2_can_go_to_mq
      && replay && s2_req.isStore || s2_grow_perm_fail && s2_isStore)\n863:   io.store_replay_resp.bits.data
      := DontCare\n864:   io.store_replay_resp.bits.miss := true.B // s2_can_go_to_mq
      && replay\n865:   io.store_replay_resp.bits.replay := true.B // s2_grow_perm_fail\n\
      866:   io.store_replay_resp.bits.id := s2_req.id\n867: \n868:   io.store_hit_resp.valid
      := s3_valid && (s3_store_can_go || (s3_miss_can_go && s3_req.isStore))\n869:\
      \   io.store_hit_resp.bits.data := DontCare\n870:   io.store_hit_resp.bits.miss
      := false.B\n871:   io.store_hit_resp.bits.replay := false.B\n872:   io.store_hit_resp.bits.id
      := s3_req.id\n873: \n874:   val atomic_hit_resp = Wire(new MainPipeResp)\n875:\
      \   atomic_hit_resp.source := s3_req.source\n876:   atomic_hit_resp.data :=
      Mux(s3_sc, s3_sc_fail.asUInt, s3_data_quad_word)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 875-887
    context: "875:   atomic_hit_resp.source := s3_req.source\n876:   atomic_hit_resp.data
      := Mux(s3_sc, s3_sc_fail.asUInt, s3_data_quad_word)\n877:   atomic_hit_resp.miss
      := false.B\n878:   atomic_hit_resp.miss_id := s3_req.miss_id\n879:   atomic_hit_resp.error
      := s3_error_wb\n880:   atomic_hit_resp.replay := false.B\n881:   atomic_hit_resp.ack_miss_queue
      := s3_req.miss\n882:   atomic_hit_resp.id := lrsc_valid\n883:   val atomic_replay_resp
      = Wire(new MainPipeResp)\n884:   atomic_replay_resp.source := s2_req.source\n\
      885:   atomic_replay_resp.data := DontCare\n886:   atomic_replay_resp.miss :=
      true.B\n887:   atomic_replay_resp.miss_id := DontCare"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 884-899
    context: "884:   atomic_replay_resp.source := s2_req.source\n885:   atomic_replay_resp.data
      := DontCare\n886:   atomic_replay_resp.miss := true.B\n887:   atomic_replay_resp.miss_id
      := DontCare\n888:   atomic_replay_resp.error := false.B\n889:   atomic_replay_resp.replay
      := true.B\n890:   atomic_replay_resp.ack_miss_queue := false.B\n891:   atomic_replay_resp.id
      := DontCare\n892: \n893:   val atomic_replay_resp_valid = s2_valid && (s2_can_go_to_mq
      && replay || s2_grow_perm_fail) && s2_req.isAMO\n894:   val atomic_hit_resp_valid
      = s3_valid && (s3_amo_can_go || s3_miss_can_go && s3_req.isAMO)\n895: \n896:\
      \   io.atomic_resp.valid := atomic_replay_resp_valid || atomic_hit_resp_valid\n\
      897:   io.atomic_resp.bits := Mux(atomic_replay_resp_valid, atomic_replay_resp,
      atomic_hit_resp)\n898: \n899:   // io.replace_resp.valid := s3_fire && s3_req.replace"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 922-937
    context: "922: \n923:   io.bloom_filter_query.clr.valid := s3_fire && isFromL1Prefetch(s3_req.pf_source)\n\
      924:   io.bloom_filter_query.clr.bits.addr := io.bloom_filter_query.clr.bits.get_addr(s3_req.addr)\n\
      925: \n926:   XSPerfAccumulate(\"mainpipe_update_prefetchArray\", io.prefetch_flag_write.valid)\n\
      927:   XSPerfAccumulate(\"mainpipe_s2_miss_req\", s2_valid && s2_req.miss)\n\
      928:   XSPerfAccumulate(\"mainpipe_s2_block_penalty\", s2_valid && s2_req.miss
      && !io.refill_info.valid)\n929:   XSPerfAccumulate(\"mainpipe_s2_missqueue_replay\"\
      , s2_valid && s2_can_go_to_mq_replay)\n930:   XSPerfAccumulate(\"mainpipe_slot_conflict_1_2\"\
      , (s1_idx === s2_idx && s1_way_en === s2_way_en && s1_req.miss && s2_req.miss
      && s1_valid && s2_valid ))\n931:   XSPerfAccumulate(\"mainpipe_slot_conflict_1_3\"\
      , (s1_idx === s3_idx && s1_way_en === s3_way_en && s1_req.miss && s3_req.miss
      && s1_valid && s3_valid))\n932:   XSPerfAccumulate(\"mainpipe_slot_conflict_2_3\"\
      , (s2_idx === s3_idx && s2_way_en === s3_way_en && s2_req.miss && s3_req.miss
      && s2_valid && s3_valid))\n933:   // probe / replace will not update access
      bit\n934:   io.access_flag_write.valid := s3_fire && !s3_req.probe && !s3_req.replace\n\
      935:   io.access_flag_write.bits.idx := s3_idx\n936:   io.access_flag_write.bits.way_en
      := s3_way_en\n937:   // io.access_flag_write.bits.flag := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 942-956
    context: "942:   io.tag_write.bits.way_en := s3_way_en\n943:   io.tag_write.bits.tag
      := get_tag(s3_req.addr)\n944:   io.tag_write.bits.ecc := DontCare // generate
      ecc code in tagArray\n945:   io.tag_write.bits.vaddr := s3_req.vaddr\n946: \n\
      947:   io.tag_write_intend := s3_req.miss && s3_valid\n948:   XSPerfAccumulate(\"\
      fake_tag_write_intend\", io.tag_write_intend && !io.tag_write.valid)\n949: \
      \  XSPerfAccumulate(\"mainpipe_tag_write\", io.tag_write.valid)\n950: \n951:\
      \   io.replace.req.valid := s2_valid && s2_need_eviction && !s2_refill_tag_eq_way\n\
      952:   io.replace.req.bits.addr := get_block_addr(Cat(s2_tag, get_untag(s2_req.vaddr)))\n\
      953:   io.replace.req.bits.vaddr := s2_req.vaddr\n954: \n955:   io.evict_set
      := addr_to_dcache_set(s2_req.vaddr) // only use set index\n956: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 954-964
    context: "954: \n955:   io.evict_set := addr_to_dcache_set(s2_req.vaddr) // only
      use set index\n956: \n957:   assert(!RegNext(io.tag_write.valid && !io.tag_write_intend))\n\
      958: \n959:   io.data_write.valid := s3_valid && s3_update_data_cango && update_data\n\
      960:   io.data_write.bits.way_en := s3_way_en\n961:   io.data_write.bits.addr
      := s3_req.vaddr\n962:   io.data_write.bits.wmask := banked_wmask\n963:   io.data_write.bits.data
      := Mux(\n964:     amo_wait_amoalu,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 975-995
    context: "975:   )\n976:   //assert(RegNext(!io.meta_write.valid || !s3_req.replace))\n\
      977:   assert(RegNext(!io.tag_write.valid || !s3_req.replace))\n978:   assert(RegNext(!io.data_write.valid
      || !s3_req.replace))\n979: \n980:   io.wb.valid := s3_valid && (\n981:     //
      replace\n982:     s3_req.replace && !s3_replace_nothing ||\n983:     // probe
      can go to wbq\n984:     s3_req.probe && (io.meta_write.ready || !probe_update_meta)
      ||\n985:       // amo miss can go to wbq\n986:       s3_req.miss &&\n987:  \
      \       (io.meta_write.ready || !amo_update_meta) &&\n988:         (io.data_write.ready
      || !update_data) &&\n989:         (s3_s_amoalu || !amo_wait_amoalu) &&\n990:\
      \         io.tag_write.ready\n991:     ) && need_wb\n992: \n993:   io.wb.bits.addr
      := get_block_addr(Cat(s3_tag, get_untag(s3_req.vaddr)))\n994:   io.wb.bits.param
      := writeback_param\n995:   io.wb.bits.voluntary := s3_req.miss || s3_req.replace"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 1008-1018
    context: "1008:   io.replace_way.set.valid := GatedValidRegNext(s0_fire)\n1009:\
      \   io.replace_way.set.bits := s1_idx\n1010:   io.replace_way.dmWay := s1_dmWay\n\
      1011: \n1012:   // send evict hint to sms\n1013:   val sms_agt_evict_valid =
      s2_valid && s2_req.miss && s2_fire_to_s3\n1014:   io.sms_agt_evict_req.valid
      := GatedValidRegNext(sms_agt_evict_valid)\n1015:   io.sms_agt_evict_req.bits.vaddr
      := RegEnable(Cat(s2_repl_tag(tagBits - 1, 2), s2_req.vaddr(13,12), 0.U((VAddrBits
      - tagBits).W)), sms_agt_evict_valid)\n1016: \n1017:   // TODO: consider block
      policy of a finer granularity\n1018:   io.status.s0_set.valid := req.valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 1015-1042
    context: "1015:   io.sms_agt_evict_req.bits.vaddr := RegEnable(Cat(s2_repl_tag(tagBits
      - 1, 2), s2_req.vaddr(13,12), 0.U((VAddrBits - tagBits).W)), sms_agt_evict_valid)\n\
      1016: \n1017:   // TODO: consider block policy of a finer granularity\n1018:\
      \   io.status.s0_set.valid := req.valid\n1019:   io.status.s0_set.bits := get_idx(s0_req.vaddr)\n\
      1020:   io.status.s1.valid := s1_valid\n1021:   io.status.s1.bits.set := s1_idx\n\
      1022:   io.status.s1.bits.way_en := s1_way_en\n1023:   io.status.s2.valid :=
      s2_valid && !s2_req.replace\n1024:   io.status.s2.bits.set := s2_idx\n1025:\
      \   io.status.s2.bits.way_en := s2_way_en\n1026:   io.status.s3.valid := s3_valid
      && !s3_req.replace\n1027:   io.status.s3.bits.set := s3_idx\n1028:   io.status.s3.bits.way_en
      := s3_way_en\n1029: \n1030:   for ((s, i) <- io.status_dup.zipWithIndex) {\n\
      1031:     s.s1.valid := s1_valid\n1032:     s.s1.bits.set := RegEnable(get_idx(s0_req.vaddr),
      s0_fire)\n1033:     s.s1.bits.way_en := s1_way_en\n1034:     s.s2.valid := s2_valid
      && !RegEnable(s1_req.replace, s1_fire)\n1035:     s.s2.bits.set := RegEnable(get_idx(s1_req.vaddr),
      s1_fire)\n1036:     s.s2.bits.way_en := s2_way_en\n1037:     s.s3.valid := s3_valid
      && !RegEnable(s2_req.replace, s2_fire_to_s3)\n1038:     s.s3.bits.set := RegEnable(get_idx(s2_req.vaddr),
      s2_fire_to_s3)\n1039:     s.s3.bits.way_en := RegEnable(s2_way_en, s2_fire_to_s3)\n\
      1040:   }\n1041:   dontTouch(io.status_dup)\n1042: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 1038-1056
    context: "1038:     s.s3.bits.set := RegEnable(get_idx(s2_req.vaddr), s2_fire_to_s3)\n\
      1039:     s.s3.bits.way_en := RegEnable(s2_way_en, s2_fire_to_s3)\n1040:   }\n\
      1041:   dontTouch(io.status_dup)\n1042: \n1043:   io.mainpipe_info.s2_valid
      := s2_valid && s2_req.miss\n1044:   io.mainpipe_info.s2_miss_id := s2_req.miss_id\n\
      1045:   io.mainpipe_info.s2_replay_to_mq := s2_can_go_to_mq_no_data\n1046: \
      \  io.mainpipe_info.s2_evict_BtoT_way := s2_can_go_to_mq_evict_fail\n1047: \
      \  io.mainpipe_info.s2_next_evict_way := PriorityEncoderOH(~io.btot_ways_for_set)\n\
      1048:   io.mainpipe_info.s3_valid := s3_valid\n1049:   io.mainpipe_info.s3_miss_id
      := s3_req.miss_id\n1050:   io.mainpipe_info.s3_refill_resp := RegNext(s2_valid
      && s2_req.miss && s2_fire_to_s3)\n1051:   XSError(s2_valid && s2_way_en.andR,
      \"s2_way_en should not be all 1\")\n1052: \n1053:   // report error to beu and
      csr, 1 cycle after read data resp\n1054:   io.error := 0.U.asTypeOf(ValidIO(new
      L1CacheErrorInfo))\n1055:   // report error, update error csr\n1056:   io.error.valid
      := s3_error_beu && GatedValidRegNext(s2_fire && !s2_should_not_report_ecc_error)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 1066-1074
    context: "1066:   io.error.bits.opType.release := RegEnable(s2_req.replace, s2_fire)\n\
      1067:   io.error.bits.opType.atom := RegEnable(s2_req.isAMO && !s2_req.probe,
      s2_fire)\n1068: \n1069:   val perfEvents = Seq(\n1070:     (\"dcache_mp_req\
      \          \", s0_fire                                                     \
      \ ),\n1071:     (\"dcache_mp_total_penalty\", PopCount(VecInit(Seq(s0_fire,
      s1_valid, s2_valid, s3_valid))))\n1072:   )\n1073:   generatePerfEvent()\n1074:
      }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 144-154
    context: "144:   // Release merge ProbeAck: s_invalid -> s_sleep -> s_release_req\n\
      145:   //                        (change Release into ProbeAck when Release
      is not fired)\n146:   //                     or: s_invalid -> s_sleep -> s_release_req
      -> s_release_resp -> s_release_req\n147:   //                        (send a
      ProbeAck after Release transaction is over)\n148: \n149:   val state = RegInit(s_invalid)\n\
      150:   val state_dup_0 = RegInit(s_invalid)\n151:   val state_dup_1 = RegInit(s_invalid)\n\
      152:   val state_dup_for_mp = RegInit(VecInit(Seq.fill(nDupWbReady)(s_invalid)))
      //TODO: clock gate\n153: \n154:   val remain = RegInit(0.U(refillCycles.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 178-192
    context: "178:   //val busy = remain.orR && s_data_override && s_data_merge //
      have remain beats and data write finished\n179:   val busy = remain.orR && s_data_override\
      \  // have remain beats and data write finished\n180:   val req = Reg(new WritebackReqWodata)\n\
      181: \n182:   // assign default signals to output signals\n183:   io.req.ready
      := false.B\n184:   io.mem_release.valid := false.B\n185:   io.mem_release.bits\
      \  := DontCare\n186:   io.mem_grant.ready   := false.B\n187:   io.block_addr.valid\
      \  := state =/= s_invalid\n188:   io.block_addr.bits   := req.addr\n189: \n\
      190:   s_data_override := true.B // data_override takes only 1 cycle\n191: \
      \  //s_data_merge := true.B // data_merge takes only 1 cycle\n192: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 188-203
    context: "188:   io.block_addr.bits   := req.addr\n189: \n190:   s_data_override
      := true.B // data_override takes only 1 cycle\n191:   //s_data_merge := true.B
      // data_merge takes only 1 cycle\n192: \n193:   XSDebug(state =/= s_invalid,
      \"WritebackEntry: %d state: %d block_addr: %x\\n\", io.id, state, io.block_addr.bits)\n\
      194: \n195:   // --------------------------------------------------------------------------------\n\
      196:   // s_invalid: receive requests\n197:   // new req entering\n198:   io.req.ready
      := state === s_invalid\n199:   val alloc = io.req.valid && io.primary_valid
      && io.primary_ready\n200:   when (alloc) {\n201:     assert (remain === 0.U)\n\
      202:     req := io.req.bits\n203:     s_data_override := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 205-218
    context: "205:     paddr_dup_0 := io.req.bits.addr\n206:     paddr_dup_1 := io.req.bits.addr\n\
      207:     paddr_dup_2 := io.req.bits.addr\n208: \n209:     remain_set := Mux(io.req.bits.hasData,
      ~0.U(refillCycles.W), 1.U(refillCycles.W))\n210:     state      := s_release_req\n\
      211:     state_dup_0 := s_release_req\n212:     state_dup_1 := s_release_req\n\
      213:     state_dup_for_mp.foreach(_ := s_release_req)\n214:   }\n215: \n216:\
      \   // --------------------------------------------------------------------------------\n\
      217:   // while there beats remaining to be sent, we keep sending\n218:   //
      which beat to send in this cycle?"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 268-297
    context: "268:   io.mem_release.bits  := Mux(req.voluntary,\n269:     Mux(req.hasData,
      voluntaryReleaseData, voluntaryRelease),\n270:     Mux(req.hasData, probeResponseData,
      probeResponse))\n271: \n272: \n273:   when (io.mem_release.fire) {remain_clr
      := PriorityEncoderOH(remain_dup_1)}\n274: \n275:   when(state === s_release_req
      && release_done){\n276:     state := Mux(req.voluntary, s_release_resp, s_invalid)\n\
      277:     when(req.voluntary){\n278:       state_dup_for_mp.foreach(_ := s_release_resp)\n\
      279:     } .otherwise{\n280:       state_dup_for_mp.foreach(_ := s_invalid)\n\
      281:     }\n282:   }\n283: \n284:   io.primary_ready := state === s_invalid\n\
      285:   io.primary_ready_dup.zip(state_dup_for_mp).foreach { case (rdy, st) =>
      rdy := st === s_invalid }\n286:   // --------------------------------------------------------------------------------\n\
      287:   // receive ReleaseAck for Releases\n288:   when (state === s_release_resp)
      {\n289:     io.mem_grant.ready := true.B\n290:     when (io.mem_grant.fire)
      {\n291:       state := s_invalid\n292:       state_dup_for_mp.foreach(_ := s_invalid)\n\
      293:     }\n294:   }\n295: \n296:   // data update logic\n297:   when(!s_data_override
      && (req.hasData || RegNext(alloc))) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 299-313
    context: "299:   }\n300: \n301:   // assert(!RegNext(!s_data_merge && !s_data_override))\n\
      302: \n303:   // performance counters\n304:   XSPerfAccumulate(\"wb_req\", io.req.fire)\n\
      305:   XSPerfAccumulate(\"wb_release\", state === s_release_req && release_done
      && req.voluntary)\n306:   XSPerfAccumulate(\"wb_probe_resp\", state === s_release_req
      && release_done && !req.voluntary)\n307:   XSPerfAccumulate(\"penalty_blocked_by_channel_C\"\
      , io.mem_release.valid && !io.mem_release.ready)\n308:   XSPerfAccumulate(\"\
      penalty_waiting_for_channel_D\", io.mem_grant.ready && !io.mem_grant.valid &&
      state === s_release_resp)\n309: }\n310: \n311: class WritebackQueue(edge: TLEdgeOut)(implicit
      p: Parameters) extends DCacheModule with HasTLDump with HasPerfEvents\n312:
      {\n313:   val io = IO(new Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 330-345
    context: "330:   val alloc = Cat(primary_ready_vec).orR\n331: \n332:   val req
      = io.req\n333:   val block_conflict = Wire(Bool())\n334: \n335:   req.ready
      := alloc && !block_conflict\n336: \n337:   // assign default values to output
      signals\n338:   io.mem_release.valid := false.B\n339:   io.mem_release.bits\
      \  := DontCare\n340:   io.mem_grant.ready   := false.B\n341: \n342:   // delay
      data write in writeback req for 1 cycle\n343:   val req_data = RegEnable(io.req.bits.toWritebackReqData(),
      io.req.valid)\n344: \n345:   require(isPow2(cfg.nMissEntries))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 343-353
    context: "343:   val req_data = RegEnable(io.req.bits.toWritebackReqData(), io.req.valid)\n\
      344: \n345:   require(isPow2(cfg.nMissEntries))\n346:   val grant_source = io.mem_grant.bits.source\n\
      347:   val entries = Seq.fill(cfg.nReleaseEntries)(Module(new WritebackEntry(edge)))\n\
      348:   entries.zipWithIndex.foreach {\n349:     case (entry, i) =>\n350:   \
      \    val former_primary_ready = if(i == 0)\n351:         false.B\n352:     \
      \  else\n353:         Cat((0 until i).map(j => entries(j).io.primary_ready)).orR"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 370-390
    context: "370:       //when (i.U === io.mem_grant.bits.source) {\n371:       //\
      \  io.mem_grant.ready := entry.io.mem_grant.ready\n372:       //}\n373:   }\n\
      374: \n375:   io.req_ready_dup.zipWithIndex.foreach { case (rdy, i) =>\n376:\
      \     rdy := Cat(entries.map(_.io.primary_ready_dup(i))).orR && !block_conflict\n\
      377:   }\n378: \n379:   io.mem_grant.ready := true.B\n380:   block_conflict
      := VecInit(entries.map(e => e.io.block_addr.valid && e.io.block_addr.bits ===
      io.req.bits.addr)).asUInt.orR\n381:   val miss_req_conflict = io.miss_req_conflict_check.map{
      r =>\n382:     VecInit(entries.map(e => e.io.block_addr.valid && e.io.block_addr.bits
      === r.bits)).asUInt.orR\n383:   }\n384:   io.block_miss_req.zipWithIndex.foreach{
      case(blk, i) =>\n385:     blk := io.miss_req_conflict_check(i).valid && miss_req_conflict(i)\n\
      386:   }\n387: \n388:   TLArbiter.robin(edge, io.mem_release, entries.map(_.io.mem_release):_*)\n\
      389: \n390:   // sanity check"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 388-400
    context: "388:   TLArbiter.robin(edge, io.mem_release, entries.map(_.io.mem_release):_*)\n\
      389: \n390:   // sanity check\n391:   // print all input/output requests for
      debug purpose\n392:   // print req\n393:   io.req.bits.dump(io.req.fire)\n394:\
      \ \n395:   io.mem_grant.bits.dump(io.mem_release.fire)\n396: \n397:   // XSDebug(io.miss_req.valid,
      \"miss_req: addr: %x\\n\", io.miss_req.bits)\n398:   // XSDebug(io.block_miss_req,
      \"block_miss_req\\n\")\n399: \n400:   // performance counters"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 396-410
    context: "396: \n397:   // XSDebug(io.miss_req.valid, \"miss_req: addr: %x\\n\"\
      , io.miss_req.bits)\n398:   // XSDebug(io.block_miss_req, \"block_miss_req\\\
      n\")\n399: \n400:   // performance counters\n401:   XSPerfAccumulate(\"wb_req\"\
      , io.req.fire)\n402: \n403:   val perfValidCount = RegNext(PopCount(entries.map(e
      => e.io.block_addr.valid)))\n404:   val perfEvents = Seq(\n405:     (\"dcache_wbq_req\
      \      \", io.req.fire),\n406:     (\"dcache_wbq_1_4_valid\", (perfValidCount
      < (cfg.nReleaseEntries.U/4.U))),\n407:     (\"dcache_wbq_2_4_valid\", (perfValidCount
      > (cfg.nReleaseEntries.U/4.U)) & (perfValidCount <= (cfg.nReleaseEntries.U/2.U))),\n\
      408:     (\"dcache_wbq_3_4_valid\", (perfValidCount > (cfg.nReleaseEntries.U/2.U))
      & (perfValidCount <= (cfg.nReleaseEntries.U*3.U/4.U))),\n409:     (\"dcache_wbq_4_4_valid\"\
      , (perfValidCount > (cfg.nReleaseEntries.U*3.U/4.U))),\n410:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/Probe.scala
    lines: 58-98
    context: "58:     val block_addr  = Output(Valid(UInt()))\n59:   })\n60: \n61:\
      \   val s_invalid :: s_pipe_req :: s_wait_resp :: Nil = Enum(3)\n62: \n63: \
      \  val state = RegInit(s_invalid)\n64: \n65:   val req = Reg(new ProbeReq)\n\
      66: \n67:   // assign default values to signals\n68:   io.req.ready      :=
      false.B\n69:   io.pipe_req.valid := false.B\n70:   io.pipe_req.bits  := DontCare\n\
      71: \n72:   io.block_addr.valid := state =/= s_invalid\n73:   io.block_addr.bits\
      \  := req.addr\n74: \n75:   XSDebug(state =/= s_invalid, \"state: %d\\n\", state)\n\
      76: \n77:   XSDebug(state =/= s_invalid, \"ProbeEntry: state: %d block_addr:
      %x\\n\", state, io.block_addr.bits)\n78: \n79:   when (state === s_invalid)
      {\n80:     io.req.ready := true.B\n81:     when (io.req.fire) {\n82:       req
      := io.req.bits\n83:       state := s_pipe_req\n84:     }\n85:   }\n86: \n87:\
      \   val lrsc_blocked = Mux(\n88:     io.req.fire,\n89:     io.lrsc_locked_block.valid
      && get_block(io.lrsc_locked_block.bits) === get_block(io.req.bits.addr),\n90:\
      \     io.lrsc_locked_block.valid && get_block(io.lrsc_locked_block.bits) ===
      get_block(req.addr)\n91:   )\n92: \n93:   when (state === s_pipe_req) {\n94:\
      \     // Note that probe req will be blocked in the next cycle if a lr updates
      lrsc_locked_block addr\n95:     // in this way, we can RegNext(lrsc_blocked)
      for better timing\n96:     io.pipe_req.valid := !RegNext(lrsc_blocked)\n97:\
      \ \n98:     val pipe_req = io.pipe_req.bits"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/Probe.scala
    lines: 105-130
    context: "105:     pipe_req.probe_need_data := req.needData\n106:     pipe_req.error
      := false.B\n107:     pipe_req.id := io.id\n108:     pipe_req.miss_fail_cause_evict_btot
      := false.B\n109: \n110:     when (io.pipe_req.fire) {\n111:       state := s_wait_resp\n\
      112:     }\n113:   }\n114: \n115:   when (state === s_wait_resp) {\n116:   \
      \  when (io.pipe_resp.valid && io.id === io.pipe_resp.bits.id) {\n117:     \
      \  state := s_invalid\n118:     }\n119:   }\n120: \n121:   // perfoemance counters\n\
      122:   XSPerfAccumulate(\"probe_req\", state === s_invalid && io.req.fire)\n\
      123:   XSPerfAccumulate(\"probe_penalty\", state =/= s_invalid)\n124:   XSPerfAccumulate(\"\
      probe_penalty_blocked_by_lrsc\", state === s_pipe_req && io.lrsc_locked_block.valid
      && get_block(io.lrsc_locked_block.bits) === get_block(req.addr))\n125:   XSPerfAccumulate(\"\
      probe_penalty_blocked_by_pipeline\", state === s_pipe_req && io.pipe_req.valid
      && !io.pipe_req.ready)\n126: }\n127: \n128: class ProbeQueue(edge: TLEdgeOut)(implicit
      p: Parameters) extends DCacheModule with HasTLDump with HasPerfEvents\n129:
      {\n130:   val io = IO(new Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/Probe.scala
    lines: 159-169
    context: "159:   }\n160:   req.param := io.mem_probe.bits.param\n161:   req.needData
      := io.mem_probe.bits.data(0)\n162:   req.id := DontCare\n163: \n164:   io.mem_probe.ready
      := allocate\n165: \n166:   val entries = (0 until cfg.nProbeEntries) map { i
      =>\n167:     val entry = Module(new ProbeEntry)\n168:     entry.io.id := i.U\n\
      169: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/Probe.scala
    lines: 167-177
    context: "167:     val entry = Module(new ProbeEntry)\n168:     entry.io.id :=
      i.U\n169: \n170:     // entry req\n171:     entry.io.req.valid := (i.U === alloc_idx)
      && allocate && io.mem_probe.valid\n172:     primary_ready(i)   := entry.io.req.ready\n\
      173:     entry.io.req.bits  := req\n174: \n175:     // pipe_req\n176:     pipe_req_arb.io.in(i)
      <> entry.io.pipe_req\n177: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/Probe.scala
    lines: 174-184
    context: "174: \n175:     // pipe_req\n176:     pipe_req_arb.io.in(i) <> entry.io.pipe_req\n\
      177: \n178:     // pipe_resp\n179:     entry.io.pipe_resp.valid := io.pipe_req.fire\n\
      180:     entry.io.pipe_resp.bits.id := io.pipe_req.bits.id\n181: \n182:    \
      \ entry.io.lrsc_locked_block := io.lrsc_locked_block\n183: \n184:     entry"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/Probe.scala
    lines: 184-196
    context: "184:     entry\n185:   }\n186: \n187:   // delay probe req for 1 cycle\n\
      188:   val selected_req_valid = RegInit(false.B)\n189:   val selected_req_bits
      = RegEnable(pipe_req_arb.io.out.bits, pipe_req_arb.io.out.fire)\n190:   val
      selected_lrsc_blocked = Mux(\n191:     pipe_req_arb.io.out.fire,\n192:     io.lrsc_locked_block.valid
      && get_block(io.lrsc_locked_block.bits) === get_block(pipe_req_arb.io.out.bits.addr),\n\
      193:     io.lrsc_locked_block.valid && get_block(io.lrsc_locked_block.bits)
      === get_block(selected_req_bits.addr) && selected_req_valid\n194:   )\n195:\
      \   val resvsetProbeBlock = RegNext(io.update_resv_set || selected_lrsc_blocked)\n\
      196:   // When we update update_resv_set, block all probe req in the next cycle"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/Probe.scala
    lines: 194-210
    context: "194:   )\n195:   val resvsetProbeBlock = RegNext(io.update_resv_set
      || selected_lrsc_blocked)\n196:   // When we update update_resv_set, block all
      probe req in the next cycle\n197:   // It should give Probe reservation set
      addr compare an independent cycle,\n198:   // which will lead to better timing\n\
      199:   pipe_req_arb.io.out.ready := !selected_req_valid || io.pipe_req.fire\n\
      200:   io.pipe_req.valid := selected_req_valid && !resvsetProbeBlock\n201: \
      \  io.pipe_req.bits := selected_req_bits\n202:   when(io.pipe_req.fire){\n203:\
      \     selected_req_valid := false.B\n204:   }\n205:   when(pipe_req_arb.io.out.fire){\n\
      206:     selected_req_valid := true.B\n207:   }\n208: \n209:   // print all
      input/output requests for debug purpose\n210:   when (io.mem_probe.valid) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/Probe.scala
    lines: 214-234
    context: "214:     // for now, we can only deal with ProbeBlock\n215:     assert
      (io.mem_probe.bits.opcode === TLMessages.Probe)\n216:   }\n217: \n218:   //
      debug output\n219:   XSDebug(io.mem_probe.fire, \"mem_probe: \")\n220:   io.mem_probe.bits.dump(io.mem_probe.fire)\n\
      221: \n222: // io.pipe_req.bits.dump(io.pipe_req.fire)\n223: \n224:   XSDebug(io.lrsc_locked_block.valid,
      \"lrsc_locked_block: %x\\n\", io.lrsc_locked_block.bits)\n225:   XSPerfAccumulate(\"\
      ProbeL1DCache\", io.mem_probe.fire)\n226: \n227:   val perfValidCount = RegNext(PopCount(entries.map(e
      => e.io.block_addr.valid)))\n228:   val perfEvents = Seq(\n229:     (\"dcache_probq_req\
      \      \", io.pipe_req.fire),\n230:     (\"dcache_probq_1_4_valid\", (perfValidCount
      < (cfg.nProbeEntries.U/4.U))),\n231:     (\"dcache_probq_2_4_valid\", (perfValidCount
      > (cfg.nProbeEntries.U/4.U)) & (perfValidCount <= (cfg.nProbeEntries.U/2.U))),\n\
      232:     (\"dcache_probq_3_4_valid\", (perfValidCount > (cfg.nProbeEntries.U/2.U))
      & (perfValidCount <= (cfg.nProbeEntries.U*3.U/4.U))),\n233:     (\"dcache_probq_4_4_valid\"\
      , (perfValidCount > (cfg.nProbeEntries.U*3.U/4.U))),\n234:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 43-53
    context: "43:     // meta and data array read port\n44:     val meta_read = DecoupledIO(new
      MetaReadReq)\n45:     val meta_resp = Input(Vec(nWays, new Meta))\n46:     val
      extra_meta_resp = Input(Vec(nWays, new DCacheExtraMeta))\n47: \n48:     val
      tag_read = DecoupledIO(new TagReadReq)\n49:     val tag_resp = Input(Vec(nWays,
      UInt(encTagBits.W)))\n50:     val vtag_update = Flipped(DecoupledIO(new TagWriteReq))\n\
      51: \n52:     val banked_data_read = DecoupledIO(new L1BankedDataReadReqWithMask)\n\
      53:     val is128Req = Output(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 60-70
    context: "60: \n61:     // banked data read conflict\n62:     val bank_conflict_slow
      = Input(Bool())\n63: \n64:     // send miss request to miss queue\n65:     val
      miss_req    = DecoupledIO(new MissReq)\n66:     val miss_resp   = Input(new
      MissResp)\n67: \n68:     // send miss request to wbq\n69:     val wbq_conflict_check
      = Valid(UInt())\n70:     val wbq_block_miss_req = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 112-128
    context: "112: \n113:     val counter_filter_query = new CounterFilterQueryBundle\n\
      114:     val counter_filter_enq = new ValidIO(new CounterFilterDataBundle())\n\
      115:   })\n116: \n117:   assert(RegNext(io.meta_read.ready))\n118: \n119:  \
      \ val s1_ready = Wire(Bool())\n120:   val s2_ready = Wire(Bool())\n121:   //
      LSU requests\n122:   // it you got nacked, you can directly passdown\n123: \
      \  val not_nacked_ready = io.meta_read.ready && io.tag_read.ready && s1_ready\n\
      124:   val nacked_ready     = true.B\n125: \n126:   // Pipeline\n127:   // --------------------------------------------------------------------------------\n\
      128:   // stage 0"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 128-145
    context: "128:   // stage 0\n129:   // --------------------------------------------------------------------------------\n\
      130:   // read tag\n131: \n132:   // ready can wait for valid\n133:   io.lsu.req.ready
      := (!io.nack && not_nacked_ready) || (io.nack && nacked_ready)\n134:   io.meta_read.valid
      := io.lsu.req.fire && !io.nack\n135:   io.tag_read.valid := io.lsu.req.fire
      && !io.nack\n136: \n137:   val s0_valid = io.lsu.req.fire\n138:   val s0_req
      = WireInit(io.lsu.req.bits)\n139:   s0_req.vaddr := Mux(io.load128Req, Cat(io.lsu.req.bits.vaddr(io.lsu.req.bits.vaddr.getWidth
      - 1, 4), 0.U(4.W)), io.lsu.req.bits.vaddr)\n140:   val s0_fire = s0_valid &&
      s1_ready\n141:   val s0_vaddr = s0_req.vaddr\n142:   val s0_replayCarry = s0_req.replayCarry\n\
      143:   val s0_load128Req = io.load128Req\n144:   val s0_bank_oh_64 = UIntToOH(addr_to_dcache_bank(s0_vaddr))\n\
      145:   val s0_bank_oh_128 = (s0_bank_oh_64 << 1.U).asUInt | s0_bank_oh_64.asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 142-153
    context: "142:   val s0_replayCarry = s0_req.replayCarry\n143:   val s0_load128Req
      = io.load128Req\n144:   val s0_bank_oh_64 = UIntToOH(addr_to_dcache_bank(s0_vaddr))\n\
      145:   val s0_bank_oh_128 = (s0_bank_oh_64 << 1.U).asUInt | s0_bank_oh_64.asUInt\n\
      146:   val s0_bank_oh = Mux(s0_load128Req, s0_bank_oh_128, s0_bank_oh_64)\n\
      147:   assert(RegNext(!(s0_valid && (s0_req.cmd =/= MemoryOpConstants.M_XRD
      && s0_req.cmd =/= MemoryOpConstants.M_PFR && s0_req.cmd =/= MemoryOpConstants.M_PFW))),
      \"LoadPipe only accepts load req / softprefetch read or write!\")\n148:   dump_pipeline_reqs(\"\
      LoadPipe s0\", s0_valid, s0_req)\n149: \n150:   // wpu\n151:   // val dwpu =
      Module(new DCacheWpuWrapper)\n152:   // req in s0\n153:   if(dwpuParam.enWPU){"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 151-161
    context: "151:   // val dwpu = Module(new DCacheWpuWrapper)\n152:   // req in
      s0\n153:   if(dwpuParam.enWPU){\n154:     io.dwpu.req(0).bits.vaddr := s0_vaddr\n\
      155:     io.dwpu.req(0).bits.replayCarry := s0_replayCarry\n156:     io.dwpu.req(0).valid
      := s0_valid\n157:   }else{\n158:     io.dwpu.req(0).valid := false.B\n159: \
      \    io.dwpu.req(0).bits := DontCare\n160:   }\n161: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 159-169
    context: "159:     io.dwpu.req(0).bits := DontCare\n160:   }\n161: \n162: \n163:\
      \   val meta_read = io.meta_read.bits\n164:   val tag_read = io.tag_read.bits\n\
      165: \n166:   // Tag read for new requests\n167:   meta_read.idx := get_idx(io.lsu.req.bits.vaddr)\n\
      168:   meta_read.way_en := ~0.U(nWays.W)\n169:   // meta_read.tag := DontCare"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 166-177
    context: "166:   // Tag read for new requests\n167:   meta_read.idx := get_idx(io.lsu.req.bits.vaddr)\n\
      168:   meta_read.way_en := ~0.U(nWays.W)\n169:   // meta_read.tag := DontCare\n\
      170: \n171:   tag_read.idx := get_idx(io.lsu.req.bits.vaddr)\n172:   tag_read.way_en
      := ~0.U(nWays.W)\n173: \n174:   // --------------------------------------------------------------------------------\n\
      175:   // stage 1\n176:   // --------------------------------------------------------------------------------\n\
      177:   // tag match, read data"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 174-184
    context: "174:   // --------------------------------------------------------------------------------\n\
      175:   // stage 1\n176:   // --------------------------------------------------------------------------------\n\
      177:   // tag match, read data\n178: \n179:   val s1_valid = RegInit(false.B)\n\
      180:   val s1_req = RegEnable(s0_req, s0_fire)\n181:   // in stage 1, load unit
      gets the physical address\n182:   val s1_paddr_dup_lsu = io.lsu.s1_paddr_dup_lsu\n\
      183:   val s1_paddr_dup_dcache = io.lsu.s1_paddr_dup_dcache\n184:   val s1_load128Req
      = RegEnable(s0_load128Req, s0_fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 188-204
    context: "188:   val s1_vaddr_update_dup = Cat(s1_req.vaddr_dup(VAddrBits - 1,
      blockOffBits), io.lsu.s1_paddr_dup_dcache(blockOffBits - 1, 0))\n189:   val
      s1_vaddr = Mux(s1_load128Req, Cat(s1_vaddr_update(VAddrBits - 1, 4), 0.U(4.W)),
      s1_vaddr_update)\n190:   val s1_vaddr_dup = Mux(s1_load128Req, Cat(s1_vaddr_update_dup(VAddrBits
      - 1, 4), 0.U(4.W)), s1_vaddr_update_dup)\n191:   val s1_bank_oh = RegEnable(s0_bank_oh,
      s0_fire)\n192:   val s1_nack = RegNext(io.nack)\n193:   val s1_fire = s1_valid
      && s2_ready\n194:   s1_ready := !s1_valid || s1_fire\n195: \n196:   when (s0_fire)
      { s1_valid := true.B }\n197:   .elsewhen (s1_fire) { s1_valid := false.B }\n\
      198: \n199:   dump_pipeline_reqs(\"LoadPipe s1\", s1_valid, s1_req)\n200: \n\
      201:   // tag check\n202:   def wayMap[T <: Data](f: Int => T) = VecInit((0
      until nWays).map(f))\n203:   val meta_resp = io.meta_resp\n204:   // pseudo
      enc ecc tag"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 226-241
    context: "226:   val s1_tag_match_way_dup_lsu = wayMap((w: Int) => s1_tag_resp(w)
      === get_tag(s1_paddr_dup_lsu) && meta_resp(w).coh.isValid()).asUInt\n227:  \
      \ val s1_wpu_pred_valid = RegEnable(io.dwpu.resp(0).valid, s0_fire)\n228:  \
      \ val s1_wpu_pred_way_en = RegEnable(io.dwpu.resp(0).bits.s0_pred_way_en, s0_fire)\n\
      229: \n230:   // lookup update\n231:   io.dwpu.lookup_upd(0).valid := s1_valid\n\
      232:   io.dwpu.lookup_upd(0).bits.vaddr := s1_vaddr\n233:   io.dwpu.lookup_upd(0).bits.s1_real_way_en
      := s1_tag_match_way_dup_dc\n234:   io.dwpu.lookup_upd(0).bits.s1_pred_way_en
      := s1_wpu_pred_way_en\n235:   // replace / tag write\n236:   io.vtag_update.ready
      := true.B\n237:   // dwpu.io.tagwrite_upd.valid := io.vtag_update.valid\n238:\
      \   // dwpu.io.tagwrite_upd.bits.vaddr := io.vtag_update.bits.vaddr\n239:  \
      \ // dwpu.io.tagwrite_upd.bits.s1_real_way_en := io.vtag_update.bits.way_en\n\
      240: \n241:   val s1_direct_map_way_num = get_direct_map_way(s1_req.vaddr)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 245-260
    context: "245:     //    io.dwpu.cfpred(0).s0_vaddr := io.lsu.s0_pc\n246:    \
      \ //    io.dwpu.cfpred(0).s1_vaddr := io.lsu.s1_pc\n247:     // }\n248: \n249:\
      \     /* method2: record the vaddr */\n250:     io.dwpu.cfpred(0).s0_vaddr :=
      s0_vaddr\n251:     io.dwpu.cfpred(0).s1_vaddr := s1_vaddr\n252:     // whether
      direct_map_way miss with valid tag value\n253:     io.dwpu.cfpred(0).s1_dm_hit
      := wayMap((w: Int) => w.U === s1_direct_map_way_num && s1_tag_resp(w) === get_tag(s1_paddr_dup_lsu)
      && meta_resp(w).coh.isValid()).asUInt.orR\n254:   }else{\n255:     io.dwpu.cfpred(0)
      := DontCare\n256:   }\n257: \n258:   val s1_pred_tag_match_way_dup_dc = Wire(UInt(nWays.W))\n\
      259:   val s1_wpu_pred_fail = Wire(Bool())\n260:   val s1_wpu_pred_fail_and_real_hit
      = Wire(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 262-272
    context: "262:     when(s1_wpu_pred_valid) {\n263:       s1_pred_tag_match_way_dup_dc
      := s1_wpu_pred_way_en\n264:     }.otherwise {\n265:       s1_pred_tag_match_way_dup_dc
      := s1_tag_match_way_dup_dc\n266:     }\n267:     s1_wpu_pred_fail := s1_valid
      && s1_tag_match_way_dup_dc =/= s1_pred_tag_match_way_dup_dc\n268:     s1_wpu_pred_fail_and_real_hit
      := s1_wpu_pred_fail && s1_tag_match_way_dup_dc.orR\n269:   } else {\n270:  \
      \   s1_pred_tag_match_way_dup_dc := s1_tag_match_way_dup_dc\n271:     s1_wpu_pred_fail
      := false.B\n272:     s1_wpu_pred_fail_and_real_hit := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 272-282
    context: "272:     s1_wpu_pred_fail_and_real_hit := false.B\n273:   }\n274: \n\
      275:   val s1_tag_match_dup_dc = ParallelORR(s1_tag_match_way_dup_dc)\n276:\
      \   val s1_tag_match_dup_lsu = ParallelORR(s1_tag_match_way_dup_lsu)\n277: \
      \  assert(RegNext(!s1_valid || PopCount(s1_tag_match_way_dup_dc) <= 1.U), \"\
      tag should not match with more than 1 way\")\n278:   io.pseudo_tag_error_inj_done
      := s1_fire && wayMap((w: Int) => meta_resp(w).coh.isValid()).asUInt.orR\n279:\
      \ \n280:   // when there are no tag match, we give it a Fake Meta\n281:   //
      this simplifies our logic in s2 stage\n282:   val s1_hit_meta = ParallelMux(s1_tag_match_way_dup_dc.asBools,
      (0 until nWays).map(w => meta_resp(w)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 296-306
    context: "296:   val s1_need_replacement = !s1_tag_match_dup_dc\n297: \n298: \
      \  XSPerfAccumulate(\"load_using_replacement\", io.replace_way.set.valid &&
      s1_need_replacement)\n299: \n300:   // query bloom filter\n301:   io.bloom_filter_query.query.valid
      := s1_valid\n302:   io.bloom_filter_query.query.bits.addr := io.bloom_filter_query.query.bits.get_addr(s1_paddr_dup_dcache)\n\
      303: \n304:   // get s1_will_send_miss_req in lpad_s1\n305:   val (s1_has_permission,
      s1_shrink_perm, s1_new_hit_coh) = s1_hit_coh.onAccess(s1_req.cmd)\n306:   val
      s1_hit = s1_tag_match_dup_dc && s1_has_permission && s1_hit_coh === s1_new_hit_coh"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 302-312
    context: "302:   io.bloom_filter_query.query.bits.addr := io.bloom_filter_query.query.bits.get_addr(s1_paddr_dup_dcache)\n\
      303: \n304:   // get s1_will_send_miss_req in lpad_s1\n305:   val (s1_has_permission,
      s1_shrink_perm, s1_new_hit_coh) = s1_hit_coh.onAccess(s1_req.cmd)\n306:   val
      s1_hit = s1_tag_match_dup_dc && s1_has_permission && s1_hit_coh === s1_new_hit_coh\n\
      307:   val s1_will_send_miss_req = s1_valid && !s1_nack && !s1_hit\n308: \n\
      309:   // data read\n310:   io.banked_data_read.valid := s1_fire && !s1_nack
      && !s1_is_prefetch\n311:   io.banked_data_read.bits.addr := s1_vaddr\n312: \
      \  io.banked_data_read.bits.addr_dup := s1_vaddr_dup"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 323-333
    context: "323:   // stage 2\n324:   // --------------------------------------------------------------------------------\n\
      325:   // return data\n326: \n327:   // val s2_valid = RegEnable(next = s1_valid
      && !io.lsu.s1_kill, init = false.B, enable = s1_fire)\n328:   val s2_valid =
      RegInit(false.B)\n329:   val s2_valid_dup = RegInit(false.B)\n330:   val s2_req
      = RegEnable(s1_req, s1_fire)\n331:   val s2_load128Req = RegEnable(s1_load128Req,
      s1_fire)\n332:   val s2_paddr = RegEnable(s1_paddr_dup_dcache, s1_fire)\n333:\
      \   val s2_vaddr = RegEnable(s1_vaddr, s1_fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 340-363
    context: "340:   val s2_wpu_pred_fail_and_real_hit = RegEnable(s1_wpu_pred_fail_and_real_hit,
      s1_fire)\n341: \n342:   // occupy set check, it will fail if the number of BtoT
      at same set great equal nWays - 1\n343:   io.occupy_set := addr_to_dcache_set(s2_vaddr)\n\
      344: \n345:   s2_ready := true.B\n346: \n347:   val s2_fire = s2_valid\n348:\
      \ \n349:   when (s1_fire) {\n350:     s2_valid := !io.lsu.s1_kill\n351:    \
      \ s2_valid_dup := !io.lsu.s1_kill\n352:   }\n353:   .elsewhen(io.lsu.resp.fire)
      {\n354:     s2_valid := false.B\n355:     s2_valid_dup := false.B\n356:   }\n\
      357: \n358:   dump_pipeline_reqs(\"LoadPipe s2\", s2_valid, s2_req)\n359: \n\
      360: \n361:   // hit, miss, nack, permission checking\n362:   // dcache side
      tag match\n363:   val s2_tag_errors = RegEnable(s1_tag_errors, s1_fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 382-394
    context: "382: \n383:   //\n384:   val s2_can_send_miss_req = RegEnable(s1_will_send_miss_req,
      s1_fire)\n385:   val s2_can_send_miss_req_dup = RegEnable(s1_will_send_miss_req,
      s1_fire)\n386: \n387:   val s2_miss_req_valid     = s2_valid && s2_can_send_miss_req\n\
      388:   val s2_miss_req_valid_dup = s2_valid_dup && s2_can_send_miss_req_dup\n\
      389:   val s2_miss_req_fire      = s2_miss_req_valid_dup && io.miss_req.ready\n\
      390: \n391:   // when req got nacked, upper levels should replay this request\n\
      392:   // nacked or not\n393:   val s2_nack_hit = RegEnable(s1_nack, s1_fire)\n\
      394:   // can no allocate mshr for load miss"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 390-407
    context: "390: \n391:   // when req got nacked, upper levels should replay this
      request\n392:   // nacked or not\n393:   val s2_nack_hit = RegEnable(s1_nack,
      s1_fire)\n394:   // can no allocate mshr for load miss\n395:   val s2_nack_no_mshr
      = s2_miss_req_valid_dup && !io.miss_req.ready\n396:   // block with a wbq valid
      req\n397:   val s2_nack_wbq_conflict = s2_miss_req_valid_dup && io.wbq_block_miss_req\n\
      398:   // Bank conflict on data arrays\n399:   val s2_nack_data = RegEnable(!io.banked_data_read.ready,
      s1_fire)\n400:   val s2_nack = s2_nack_hit || s2_nack_no_mshr || s2_nack_data
      || s2_nack_wbq_conflict\n401:   // s2 miss merged\n402:   val s2_miss_merged
      = s2_miss_req_fire && !io.miss_req.bits.cancel && !io.wbq_block_miss_req &&
      io.miss_resp.merged\n403: \n404:   val s2_bank_addr = addr_to_dcache_bank(s2_paddr)\n\
      405:   dontTouch(s2_bank_addr)\n406: \n407:   val s2_instrtype = s2_req.instrtype"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 416-429
    context: "416: \n417:   val s2_data128bit = Cat(io.banked_data_resp(1).raw_data,
      io.banked_data_resp(0).raw_data)\n418:   val s2_resp_data  = s2_data128bit\n\
      419: \n420:   // only dump these signals when they are actually valid\n421:\
      \   dump_pipeline_valids(\"LoadPipe s2\", \"s2_hit\", s2_valid && s2_hit)\n\
      422:   dump_pipeline_valids(\"LoadPipe s2\", \"s2_nack\", s2_valid && s2_nack)\n\
      423:   dump_pipeline_valids(\"LoadPipe s2\", \"s2_nack_hit\", s2_valid && s2_nack_hit)\n\
      424:   dump_pipeline_valids(\"LoadPipe s2\", \"s2_nack_no_mshr\", s2_valid &&
      s2_nack_no_mshr)\n425: \n426:   if(EnableTagEcc) {\n427:     s2_tag_error :=
      s2_tag_errors.orR // error reported by tag ecc check\n428:   }\n429:   io.pseudo_data_error_inj_done
      := s2_fire && s2_hit && !io.bank_conflict_slow"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 425-450
    context: "425: \n426:   if(EnableTagEcc) {\n427:     s2_tag_error := s2_tag_errors.orR
      // error reported by tag ecc check\n428:   }\n429:   io.pseudo_data_error_inj_done
      := s2_fire && s2_hit && !io.bank_conflict_slow\n430:   io.pseudo_error.ready
      := false.B\n431: \n432:   // send load miss to miss queue\n433:   io.miss_req.valid
      := s2_miss_req_valid\n434:   io.miss_req.bits := DontCare\n435:   io.miss_req.bits.source
      := s2_instrtype\n436:   io.miss_req.bits.pf_source := RegNext(RegNext(io.lsu.pf_source))\
      \  // TODO: clock gate\n437:   io.miss_req.bits.cmd := s2_req.cmd\n438:   io.miss_req.bits.addr
      := get_block_addr(s2_paddr)\n439:   io.miss_req.bits.vaddr := s2_vaddr\n440:\
      \   io.miss_req.bits.req_coh := s2_hit_coh\n441:   io.miss_req.bits.cancel :=
      io.lsu.s2_kill || s2_tag_error || s2_btot_occupy_fail\n442:   io.miss_req.bits.pc
      := io.lsu.s2_pc\n443:   io.miss_req.bits.lqIdx := io.lsu.req.bits.lqIdx\n444:\
      \   io.miss_req.bits.isBtoT := s2_grow_perm_btot\n445:   io.miss_req.bits.occupy_way
      := s2_tag_match_way\n446: \n447:   //send load miss to wbq\n448:   io.wbq_conflict_check.valid
      := s2_miss_req_valid_dup\n449:   io.wbq_conflict_check.bits := get_block_addr(s2_paddr)\n\
      450: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 448-458
    context: "448:   io.wbq_conflict_check.valid := s2_miss_req_valid_dup\n449:  \
      \ io.wbq_conflict_check.bits := get_block_addr(s2_paddr)\n450: \n451:   // send
      back response\n452:   val resp = Wire(ValidIO(new DCacheWordResp))\n453:   resp.valid
      := s2_valid\n454:   resp.bits := DontCare\n455:   // resp.bits.data := s2_word_decoded\n\
      456:   // resp.bits.data := banked_data_resp_word.raw_data\n457:   // * on miss
      or nack, upper level should replay request\n458:   // but if we successfully
      sent the request to miss queue"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 465-476
    context: "465:   resp.bits.real_miss := real_miss\n466:   resp.bits.miss := real_miss\n\
      467:   resp.bits.data := s2_resp_data\n468:   io.lsu.s2_first_hit := s2_req.isFirstIssue
      && s2_hit\n469:   // load pipe need replay when there is a bank conflict or
      wpu predict fail\n470:   resp.bits.replay := (resp.bits.miss && (s2_nack ||
      io.miss_req.bits.cancel)) || io.bank_conflict_slow || s2_wpu_pred_fail || s2_btot_occupy_fail\n\
      471:   resp.bits.replayCarry.valid := (resp.bits.miss && (s2_nack || io.miss_req.bits.cancel))
      || io.bank_conflict_slow || s2_wpu_pred_fail || s2_btot_occupy_fail\n472:  \
      \ resp.bits.replayCarry.real_way_en := s2_real_way_en\n473:   resp.bits.meta_prefetch
      := s2_hit_prefetch\n474:   resp.bits.meta_access := s2_hit_access\n475:   resp.bits.tag_error
      := false.B\n476:   resp.bits.mshr_id := io.miss_resp.id"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 472-482
    context: "472:   resp.bits.replayCarry.real_way_en := s2_real_way_en\n473:   resp.bits.meta_prefetch
      := s2_hit_prefetch\n474:   resp.bits.meta_access := s2_hit_access\n475:   resp.bits.tag_error
      := false.B\n476:   resp.bits.mshr_id := io.miss_resp.id\n477:   resp.bits.handled
      := s2_miss_req_fire && !io.miss_req.bits.cancel && !io.wbq_block_miss_req &&
      io.miss_resp.handled\n478:   resp.bits.debug_robIdx := s2_req.debug_robIdx\n\
      479:   // debug info\n480:   io.lsu.s2_first_hit := s2_req.isFirstIssue && s2_hit\n\
      481:   io.lsu.debug_s2_real_way_num := OneHot.OHToUIntStartOne(s2_real_way_en)\n\
      482:   if(dwpuParam.enWPU) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 489-511
    context: "489:   }else{\n490:     io.lsu.debug_s2_dm_way_num := 0.U\n491:   }\n\
      492: \n493: \n494:   XSPerfAccumulate(\"dcache_read_bank_conflict\", io.bank_conflict_slow
      && s2_valid)\n495:   XSPerfAccumulate(\"dcache_read_from_prefetched_line\",
      s2_valid && isPrefetchRelated(s2_hit_prefetch) && !resp.bits.miss)\n496:   XSPerfAccumulate(\"\
      dcache_first_read_from_prefetched_line\", s2_valid && isPrefetchRelated(s2_hit_prefetch)
      && !resp.bits.miss && !s2_hit_access)\n497: \n498:   // if ldu0 and ldu1 hit
      the same, count for 1\n499:   val total_prefetch = s2_valid && (s2_req.instrtype
      === DCACHE_PREFETCH_SOURCE.U)\n500:   val late_hit_prefetch = s2_valid && s2_hit
      && (s2_req.instrtype === DCACHE_PREFETCH_SOURCE.U)\n501:   val late_load_hit
      = s2_valid && s2_hit && (s2_req.instrtype === DCACHE_PREFETCH_SOURCE.U) && !isFromL1Prefetch(s2_hit_prefetch)\n\
      502:   val late_prefetch_hit = s2_valid && s2_hit && (s2_req.instrtype === DCACHE_PREFETCH_SOURCE.U)
      && isFromL1Prefetch(s2_hit_prefetch)\n503:   val useless_prefetch = s2_miss_req_fire
      && (s2_req.instrtype === DCACHE_PREFETCH_SOURCE.U)\n504:   val useful_prefetch
      = s2_valid && (s2_req.instrtype === DCACHE_PREFETCH_SOURCE.U) && resp.bits.handled
      && !io.miss_resp.merged\n505: \n506:   val prefetch_hit = s2_valid && (s2_req.instrtype
      =/= DCACHE_PREFETCH_SOURCE.U) && s2_hit && isFromL1Prefetch(s2_hit_prefetch)
      && s2_req.isFirstIssue\n507: \n508:   io.prefetch_info.naive.total_prefetch
      := total_prefetch\n509:   io.prefetch_info.naive.late_hit_prefetch := late_hit_prefetch\n\
      510:   io.prefetch_info.naive.late_load_hit := late_load_hit\n511:   io.prefetch_info.naive.late_prefetch_hit
      := late_prefetch_hit"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 511-526
    context: "511:   io.prefetch_info.naive.late_prefetch_hit := late_prefetch_hit\n\
      512:   io.prefetch_info.naive.useless_prefetch := useless_prefetch\n513:   io.prefetch_info.naive.useful_prefetch
      := useful_prefetch\n514:   io.prefetch_info.naive.prefetch_hit := prefetch_hit\n\
      515: \n516:   io.prefetch_info.fdp.demand_miss := s2_valid && (s2_req.instrtype
      =/= DCACHE_PREFETCH_SOURCE.U) && !s2_hit && s2_req.isFirstIssue\n517:   io.prefetch_info.fdp.pollution
      := io.prefetch_info.fdp.demand_miss && io.bloom_filter_query.resp.valid && io.bloom_filter_query.resp.bits.res\n\
      518: \n519:   io.lsu.resp.valid := resp.valid\n520:   io.lsu.resp.bits := resp.bits\n\
      521:   assert(RegNext(!(resp.valid && !io.lsu.resp.ready)), \"lsu should be
      ready in s2\")\n522: \n523:   resp.bits.dump(resp.valid)\n524: \n525:   io.lsu.debug_s1_hit_way
      := s1_tag_match_way_dup_dc\n526:   io.lsu.s1_disable_fast_wakeup := io.disable_ld_fast_wakeup"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 524-535
    context: "524: \n525:   io.lsu.debug_s1_hit_way := s1_tag_match_way_dup_dc\n526:\
      \   io.lsu.s1_disable_fast_wakeup := io.disable_ld_fast_wakeup\n527:   io.lsu.s2_bank_conflict
      := io.bank_conflict_slow\n528:   io.lsu.s2_wpu_pred_fail := s2_wpu_pred_fail_and_real_hit\n\
      529:   io.lsu.s2_mq_nack       := (resp.bits.miss && (s2_nack_no_mshr || io.miss_req.bits.cancel
      || io.wbq_block_miss_req ) || s2_btot_occupy_fail)\n530:   assert(RegNext(s1_ready
      && s2_ready), \"load pipeline should never be blocked\")\n531: \n532:   // --------------------------------------------------------------------------------\n\
      533:   // stage 3\n534:   // --------------------------------------------------------------------------------\n\
      535:   // report ecc error and get selected dcache data"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 532-542
    context: "532:   // --------------------------------------------------------------------------------\n\
      533:   // stage 3\n534:   // --------------------------------------------------------------------------------\n\
      535:   // report ecc error and get selected dcache data\n536: \n537:   val s3_valid
      = RegNext(s2_valid)\n538:   val s3_load128Req = RegEnable(s2_load128Req, s2_fire)\n\
      539:   val s3_vaddr = RegEnable(s2_vaddr, s2_fire)\n540:   val s3_paddr = RegEnable(s2_paddr,
      s2_fire)\n541:   val s3_hit = RegEnable(s2_hit, s2_fire)\n542:   val s3_tag_match_way
      = RegEnable(s2_tag_match_way, s2_fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 549-559
    context: "549:   val s3_flag_error = RegEnable(s2_flag_error, s2_fire)\n550: \
      \  val s3_hit_prefetch = RegEnable(s2_hit_prefetch, s2_fire)\n551:   val s3_error
      = s3_tag_error || s3_flag_error || s3_data_error\n552: \n553:   // error_delayed
      signal will be used to update uop.exception 1 cycle after load writeback\n554:\
      \   resp.bits.error_delayed := s3_error && (s3_hit || s3_tag_error) && s3_valid\n\
      555:   resp.bits.data_delayed := s3_banked_data_resp_word\n556:   resp.bits.replacementUpdated
      := io.replace_access.valid\n557: \n558:   // report tag / data / l2 error (with
      paddr) to bus error unit\n559:   io.error := 0.U.asTypeOf(ValidIO(new L1CacheErrorInfo))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 555-565
    context: "555:   resp.bits.data_delayed := s3_banked_data_resp_word\n556:   resp.bits.replacementUpdated
      := io.replace_access.valid\n557: \n558:   // report tag / data / l2 error (with
      paddr) to bus error unit\n559:   io.error := 0.U.asTypeOf(ValidIO(new L1CacheErrorInfo))\n\
      560:   io.error.bits.report_to_beu := (s3_tag_error || s3_data_error) && s3_valid\n\
      561:   io.error.bits.paddr := s3_paddr\n562:   io.error.bits.source.tag := s3_tag_error\n\
      563:   io.error.bits.source.data := s3_data_error\n564:   io.error.bits.source.l2
      := s3_flag_error\n565:   io.error.bits.opType.load := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 562-579
    context: "562:   io.error.bits.source.tag := s3_tag_error\n563:   io.error.bits.source.data
      := s3_data_error\n564:   io.error.bits.source.l2 := s3_flag_error\n565:   io.error.bits.opType.load
      := true.B\n566:   // report tag error / l2 corrupted to CACHE_ERROR csr\n567:\
      \   io.error.valid := s3_error && s3_valid\n568: \n569:   io.replace_access.valid
      := s3_valid && s3_hit\n570:   io.replace_access.bits.set := RegNext(RegNext(get_idx(s1_req.vaddr)))\n\
      571:   io.replace_access.bits.way := RegNext(RegNext(OHToUInt(s1_tag_match_way_dup_dc)))\n\
      572: \n573:   // update access bit\n574:   io.access_flag_write.valid := s3_valid
      && s3_hit && !s3_is_prefetch\n575:   io.access_flag_write.bits.idx := get_idx(s3_vaddr)\n\
      576:   io.access_flag_write.bits.way_en := s3_tag_match_way\n577:   io.access_flag_write.bits.flag
      := true.B\n578: \n579:   // clear prefetch source when prefetch hit"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 575-585
    context: "575:   io.access_flag_write.bits.idx := get_idx(s3_vaddr)\n576:   io.access_flag_write.bits.way_en
      := s3_tag_match_way\n577:   io.access_flag_write.bits.flag := true.B\n578: \n\
      579:   // clear prefetch source when prefetch hit\n580:   val s3_clear_pf_flag_en
      = s3_valid && s3_hit && !s3_is_prefetch && isFromL1Prefetch(s3_hit_prefetch)\n\
      581:   io.prefetch_flag_write.valid := s3_clear_pf_flag_en && !io.counter_filter_query.resp\n\
      582:   io.prefetch_flag_write.bits.idx := get_idx(s3_vaddr)\n583:   io.prefetch_flag_write.bits.way_en
      := s3_tag_match_way\n584:   io.prefetch_flag_write.bits.source := L1_HW_PREFETCH_CLEAR\n\
      585: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/loadpipe/LoadPipe.scala
    lines: 608-661
    context: "608:     XSDebug(valid, s\"$pipeline_stage_name $signal_name\\n\")\n\
      609:   }\n610: \n611:   val load_trace = Wire(new LoadPfDbBundle)\n612:   val
      pf_trace = Wire(new LoadPfDbBundle)\n613:   val miss_trace = Wire(new LoadPfDbBundle)\n\
      614:   val mshr_trace = Wire(new LoadPfDbBundle)\n615: \n616:   load_trace.paddr
      := get_block_addr(s2_paddr)\n617:   pf_trace.paddr := get_block_addr(s2_paddr)\n\
      618:   miss_trace.paddr := get_block_addr(s2_paddr)\n619:   mshr_trace.paddr
      := get_block_addr(s2_paddr)\n620: \n621:   val table_load = ChiselDB.createTable(\"\
      LoadTrace\" + id.toString + \"_hart\"+ p(XSCoreParamsKey).HartId.toString, new
      LoadPfDbBundle, basicDB = false)\n622:   val site_load = \"LoadPipe_load\" +
      id.toString\n623:   table_load.log(load_trace, s2_valid && s2_req.isFirstIssue
      && (s2_req.instrtype =/= DCACHE_PREFETCH_SOURCE.U), site_load, clock, reset)\n\
      624: \n625:   val table_pf = ChiselDB.createTable(\"LoadPfTrace\" + id.toString
      + \"_hart\"+ p(XSCoreParamsKey).HartId.toString, new LoadPfDbBundle, basicDB
      = false)\n626:   val site_pf = \"LoadPipe_pf\" + id.toString\n627:   table_pf.log(pf_trace,
      s2_valid && (s2_req.instrtype === DCACHE_PREFETCH_SOURCE.U), site_pf, clock,
      reset)\n628: \n629:   val table_miss = ChiselDB.createTable(\"LoadTraceMiss\"\
      \ + id.toString + \"_hart\"+ p(XSCoreParamsKey).HartId.toString, new LoadPfDbBundle,
      basicDB = false)\n630:   val site_load_miss = \"LoadPipe_load_miss\" + id.toString\n\
      631:   table_miss.log(miss_trace, s2_valid && s2_req.isFirstIssue && (s2_req.instrtype
      =/= DCACHE_PREFETCH_SOURCE.U) && real_miss, site_load_miss, clock, reset)\n\
      632: \n633:   val table_mshr = ChiselDB.createTable(\"LoadPfMshr\" + id.toString
      + \"_hart\"+ p(XSCoreParamsKey).HartId.toString, new LoadPfDbBundle, basicDB
      = false)\n634:   val site_mshr = \"LoadPipe_mshr\" + id.toString\n635:   table_mshr.log(mshr_trace,
      s2_valid && (s2_req.instrtype === DCACHE_PREFETCH_SOURCE.U) && io.miss_req.fire,
      site_mshr, clock, reset)\n636: \n637:   // performance counters\n638:   XSPerfAccumulate(\"\
      load_req\", io.lsu.req.fire)\n639:   XSPerfAccumulate(\"load_s1_kill\", s1_fire
      && io.lsu.s1_kill)\n640:   XSPerfAccumulate(\"load_hit_way\", s1_fire && s1_tag_match_dup_dc)\n\
      641:   XSPerfAccumulate(\"load_replay\", io.lsu.resp.fire && resp.bits.replay)\n\
      642:   XSPerfAccumulate(\"load_replay_for_dcache_data_nack\", io.lsu.resp.fire
      && resp.bits.replay && s2_nack_data)\n643:   XSPerfAccumulate(\"load_replay_for_dcache_no_mshr\"\
      , io.lsu.resp.fire && resp.bits.replay && s2_nack_no_mshr)\n644:   XSPerfAccumulate(\"\
      load_replay_for_dcache_conflict\", io.lsu.resp.fire && resp.bits.replay && io.bank_conflict_slow)\n\
      645:   XSPerfAccumulate(\"load_replay_for_dcache_wpu_pred_fail\", io.lsu.resp.fire
      && resp.bits.replay && s2_wpu_pred_fail)\n646:   XSPerfAccumulate(\"load_hit\"\
      , io.lsu.resp.fire && !real_miss)\n647:   XSPerfAccumulate(\"load_miss\", io.lsu.resp.fire
      && real_miss)\n648:   XSPerfAccumulate(\"load_succeed\", io.lsu.resp.fire &&
      !resp.bits.miss && !resp.bits.replay)\n649:   XSPerfAccumulate(\"load_miss_or_conflict\"\
      , io.lsu.resp.fire && resp.bits.miss)\n650:   XSPerfAccumulate(\"actual_ld_fast_wakeup\"\
      , s1_fire && s1_tag_match_dup_dc && !io.disable_ld_fast_wakeup)\n651:   XSPerfAccumulate(\"\
      ideal_ld_fast_wakeup\", io.banked_data_read.fire && s1_tag_match_dup_dc)\n652:\
      \ \n653:   val perfEvents = Seq(\n654:     (\"load_req                 \", io.lsu.req.fire\
      \                                               ),\n655:     (\"load_replay\
      \              \", io.lsu.resp.fire && resp.bits.replay                    \
      \      ),\n656:     (\"load_replay_for_data_nack\", io.lsu.resp.fire && resp.bits.replay
      && s2_nack_data          ),\n657:     (\"load_replay_for_no_mshr  \", io.lsu.resp.fire
      && resp.bits.replay && s2_nack_no_mshr       ),\n658:     (\"load_replay_for_conflict
      \", io.lsu.resp.fire && resp.bits.replay && io.bank_conflict_slow ),\n659: \
      \  )\n660:   generatePerfEvent()\n661: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/LegacyMetaArray.scala
    lines: 55-65
    context: "55:   val rstVal = onReset()\n56:   val metaBits = rstVal.getWidth\n\
      57:   val encMetaBits = cacheParams.tagCode.width(metaBits)\n58: \n59:   val
      io = IO(new Bundle {\n60:     val read = Flipped(Decoupled(new L1MetaReadReq))\n\
      61:     val write = Flipped(Decoupled(new L1MetaWriteReq))\n62:     val resp
      = Output(Vec(nWays, UInt(encMetaBits.W)))\n63:     val error = Output(ValidIO(new
      L1CacheErrorInfo))\n64:   })\n65:   val rst_cnt = RegInit(0.U(log2Up(nSets +
      1).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/LegacyMetaArray.scala
    lines: 65-75
    context: "65:   val rst_cnt = RegInit(0.U(log2Up(nSets + 1).W))\n66:   val rst
      = rst_cnt < nSets.U\n67:   val waddr = Mux(rst, rst_cnt, io.write.bits.idx)\n\
      68:   val wdata = Mux(rst, rstVal, io.write.bits.data).asUInt\n69:   val wmask
      = Mux(rst || (nWays == 1).B, (-1).asSInt, io.write.bits.way_en.asSInt).asBools\n\
      70:   val rmask = Mux(rst || (nWays == 1).B, (-1).asSInt, io.read.bits.way_en.asSInt).asBools\n\
      71:   when(rst) {\n72:     rst_cnt := rst_cnt + 1.U\n73:   }\n74: \n75:   val
      tag_array = Module(new SRAMTemplate(UInt(encMetaBits.W), set = nSets, way =
      nWays,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/LegacyMetaArray.scala
    lines: 82-114
    context: "82:     setIdx = waddr,\n83:     data = cacheParams.tagCode.encode(wdata),\n\
      84:     waymask = VecInit(wmask).asUInt)\n85: \n86:   // tag read\n87:   val
      ren = io.read.fire\n88:   tag_array.io.r.req.valid := ren\n89:   tag_array.io.r.req.bits.apply(setIdx
      = io.read.bits.idx)\n90:   io.resp := tag_array.io.r.resp.data\n91:   val ecc_errors
      = tag_array.io.r.resp.data.zipWithIndex.map({ case (d, w) =>\n92:     cacheParams.tagCode.decode(d).error
      && RegNext(io.read.bits.way_en(w))\n93:   })\n94:   io.error.bits.report_to_beu
      := RegNext(io.read.fire) && Cat(ecc_errors).orR\n95:   io.error.bits.paddr :=
      Cat(io.read.bits.idx, 0.U(pgUntagBits.W))\n96: \n97:   io.write.ready := !rst\n\
      98:   io.read.ready := !wen\n99: \n100:   def dumpRead = {\n101:     XSDebug(io.read.fire,\n\
      102:       \"MetaArray Read: idx: %d way_en: %x tag: %x\\n\",\n103:       io.read.bits.idx,
      io.read.bits.way_en, io.read.bits.tag)\n104:   }\n105: \n106:   def dumpWrite
      = {\n107:     XSDebug(io.write.fire,\n108:       \"MetaArray Write: idx: %d
      way_en: %x tag: %x new_tag: %x new_coh: %x\\n\",\n109:       io.write.bits.idx,
      io.write.bits.way_en, io.write.bits.tag, io.write.bits.data.tag, io.write.bits.data.coh.state)\n\
      110:   }\n111: \n112:   // def dumpResp() = {\n113:   //   (0 until nWays) map
      { i =>\n114:   //     XSDebug(s\"MetaArray Resp: way: $i tag: %x coh: %x\\n\"\
      ,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/LegacyMetaArray.scala
    lines: 128-138
    context: "128: \n129:   val metaBits = onReset.getWidth\n130:   val encMetaBits
      = cacheParams.tagCode.width(metaBits)\n131: \n132:   val io = IO(new DCacheBundle
      {\n133:     val read = Vec(numReadPorts, Flipped(DecoupledIO(new L1MetaReadReq)))\n\
      134:     val write = Flipped(DecoupledIO(new L1MetaWriteReq))\n135:     val
      resp = Output(Vec(numReadPorts, Vec(nWays, UInt(encMetaBits.W))))\n136:    \
      \ val errors = Output(Vec(numReadPorts, ValidIO(new L1CacheErrorInfo)))\n137:\
      \   })\n138:   val meta = Seq.fill(numReadPorts) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/LegacyMetaArray.scala
    lines: 141-169
    context: "141: \n142:   for (w <- 0 until numReadPorts) {\n143:     // meta(w).io.write
      <> io.write\n144:     meta(w).io.write.valid := io.write.valid\n145:     meta(w).io.write.bits
      := io.write.bits\n146:     meta(w).io.read <> io.read(w)\n147:     io.resp(w)
      <> meta(w).io.resp\n148:     io.errors(w) <> meta(w).io.error\n149:   }\n150:\
      \   // io.write.ready := VecInit(meta.map(_.io.write.ready)).asUInt.andR\n151:\
      \   io.write.ready := true.B\n152: \n153:   def dumpRead = {\n154:     (0 until
      numReadPorts) map { w =>\n155:       XSDebug(io.read(w).fire,\n156:        \
      \ s\"MetaArray Read channel: $w idx: %d way_en: %x tag: %x\\n\",\n157:     \
      \    io.read(w).bits.idx, io.read(w).bits.way_en, io.read(w).bits.tag)\n158:\
      \     }\n159:   }\n160: \n161:   def dumpWrite = {\n162:     XSDebug(io.write.fire,\n\
      163:       \"MetaArray Write: idx: %d way_en: %x tag: %x new_tag: %x new_coh:
      %x\\n\",\n164:       io.write.bits.idx, io.write.bits.way_en, io.write.bits.tag,
      io.write.bits.data.tag, io.write.bits.data.coh.state)\n165:   }\n166: \n167:\
      \   // def dumpResp() = {\n168:   //   (0 until LoadPipelineWidth) map { w =>\n\
      169:   //     (0 until nWays) map { i =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/TagArray.scala
    lines: 52-62
    context: "52:   val TagEccParam = if(EnableTagEcc) Some(HasTagEccParam) else None\n\
      53: }\n54: \n55: class TagSRAMBank(index: Int)(implicit p: Parameters) extends
      AbstractTagArray {\n56:   val io = IO(new Bundle() {\n57:     val read = Flipped(DecoupledIO(new
      TagReadReq {\n58:       override val way_en = UInt(DCacheWayDiv.W)\n59:    \
      \ }))\n60:     val resp = Output(Vec(DCacheWayDiv, UInt(encTagBits.W)))\n61:\
      \     val write = Flipped(DecoupledIO(new TagWriteReq {\n62:       override
      val way_en = UInt(DCacheWayDiv.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/TagArray.scala
    lines: 67-77
    context: "67:   val rst = rst_cnt < nSets.U\n68:   val rstVal = 0.U\n69:   val
      waddr = Mux(rst, rst_cnt, io.write.bits.idx)\n70:   val wdata = Mux(rst, rstVal,
      io.write.bits.asECCTag())\n71:   val wmask = Mux(rst || (DCacheWayDiv == 1).B,
      (-1).asSInt, io.write.bits.way_en.asSInt).asBools\n72:   val rmask = Mux(rst
      || (DCacheWayDiv == 1).B, (-1).asSInt, io.read.bits.way_en.asSInt).asBools\n\
      73:   when (rst) {\n74:     rst_cnt := rst_cnt + 1.U\n75:   }\n76: \n77:   val
      tag_array = Module(new SRAMTemplate(UInt(encTagBits.W), set = nSets, way = DCacheWayDiv,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/TagArray.scala
    lines: 77-87
    context: "77:   val tag_array = Module(new SRAMTemplate(UInt(encTagBits.W), set
      = nSets, way = DCacheWayDiv,\n78:     shouldReset = false, holdRead = false,
      singlePort = true, withClockGate = true,\n79:     hasMbist = hasMbist,  hasSramCtl
      = hasSramCtl, suffix = Some(\"dcsh_tag\")))\n80: \n81:   val wen = rst || io.write.valid\n\
      82:   io.write.ready := !rst\n83:   tag_array.io.w.req.valid := wen\n84:   tag_array.io.w.req.bits.apply(\n\
      85:     setIdx = waddr,\n86:     data = wdata,\n87:     waymask = VecInit(wmask).asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/TagArray.scala
    lines: 86-99
    context: "86:     data = wdata,\n87:     waymask = VecInit(wmask).asUInt\n88:\
      \   )\n89: \n90:   // tag read\n91:   val ren = io.read.fire\n92:   io.read.ready
      := !wen\n93:   tag_array.io.r.req.valid := ren\n94:   tag_array.io.r.req.bits.apply(setIdx
      = io.read.bits.idx)\n95:   io.resp := tag_array.io.r.resp.data\n96: \n97:  \
      \ XSPerfAccumulate(\"part_tag_read_counter_\" + index, tag_array.io.r.req.valid)\n\
      98: }\n99: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/TagArray.scala
    lines: 97-107
    context: "97:   XSPerfAccumulate(\"part_tag_read_counter_\" + index, tag_array.io.r.req.valid)\n\
      98: }\n99: \n100: class TagArray(implicit p: Parameters) extends AbstractTagArray
      {\n101:   val io = IO(new Bundle() {\n102:     val read = Flipped(DecoupledIO(new
      TagReadReq))\n103:     val resp = Output(Vec(nWays, UInt(encTagBits.W)))\n104:\
      \     val write = Flipped(DecoupledIO(new TagWriteReq))\n105:   })\n106: \n\
      107:   val tag_arrays = List.tabulate(nWays / DCacheWayDiv)(i => Module(new
      TagSRAMBank(i)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/TagArray.scala
    lines: 103-119
    context: "103:     val resp = Output(Vec(nWays, UInt(encTagBits.W)))\n104:   \
      \  val write = Flipped(DecoupledIO(new TagWriteReq))\n105:   })\n106: \n107:\
      \   val tag_arrays = List.tabulate(nWays / DCacheWayDiv)(i => Module(new TagSRAMBank(i)))\n\
      108:   tag_arrays.zipWithIndex.foreach { case (tag_array, i) =>\n109:     tag_array.io.read
      <> io.read\n110:     tag_array.io.read.bits.way_en := io.read.bits.way_en((i
      + 1) * DCacheWayDiv - 1, i * DCacheWayDiv)\n111:     tag_array.io.write <> io.write\n\
      112:     tag_array.io.write.bits.way_en := io.write.bits.way_en((i + 1) * DCacheWayDiv
      - 1, i * DCacheWayDiv)\n113:   }\n114:   io.resp.zip(tag_arrays.map(_.io.resp).flatten).foreach
      {\n115:     case (resp, bank_resp) =>\n116:       resp := bank_resp\n117:  \
      \ }\n118: }\n119: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/TagArray.scala
    lines: 117-127
    context: "117:   }\n118: }\n119: \n120: class DuplicatedTagArray(readPorts: Int)(implicit
      p: Parameters) extends AbstractTagArray {\n121:   val io = IO(new Bundle() {\n\
      122:     val read = Vec(readPorts, Flipped(DecoupledIO(new TagReadReq)))\n123:\
      \     val resp = Output(Vec(readPorts, Vec(nWays, UInt(encTagBits.W))))\n124:\
      \     val write = Flipped(DecoupledIO(new TagWriteReq))\n125:   })\n126: \n\
      127:   val array = Seq.fill(readPorts) { Module(new TagArray) }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/TagArray.scala
    lines: 143-157
    context: "143:     array(i).io.write.bits.idx := io.write.bits.idx\n144:     array(i).io.write.bits.way_en
      := io.write.bits.way_en\n145:     array(i).io.write.bits.vaddr := io.write.bits.vaddr\n\
      146:     array(i).io.write.bits.tag := io.write.bits.tag\n147:     array(i).io.write.bits.ecc
      := getECCFromEncTag(cacheParams.tagCode.encode(io.write.bits.tag))\n148:   \
      \  io.write.ready := true.B\n149: \n150:     array(i).io.read <> io.read(i)\n\
      151:     io.read(i).ready := array(i).io.read.ready\n152:     io.resp(i) :=
      array(i).io.resp\n153:     tag_read_oh(i) := PopCount(array(i).io.read.fire)\n\
      154:   }\n155: \n156:   XSPerfAccumulate(\"tag_read_counter\", tag_read_oh.reduce(_
      + _))\n157: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/AsynchronousMetaArray.scala
    lines: 48-58
    context: "48:   val flag = Bool()\n49: }\n50: \n51: class L1CohMetaArray(readPorts:
      Int, writePorts: Int, bypassRead: Boolean = true)(implicit p: Parameters) extends
      DCacheModule {\n52:   val io = IO(new Bundle() {\n53:     val read = Vec(readPorts,
      Flipped(DecoupledIO(new MetaReadReq)))\n54:     val resp = Output(Vec(readPorts,
      Vec(nWays, new Meta)))\n55:     val write = Vec(writePorts, Flipped(DecoupledIO(new
      CohMetaWriteReq)))\n56:   })\n57: \n58:   val meta_array = RegInit("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/AsynchronousMetaArray.scala
    lines: 66-78
    context: "66:   val s0_way_wdata = Wire(Vec(nWays, Vec(writePorts, new Meta)))\n\
      67:   val s1_way_wen = Wire(Vec(nWays, Vec(writePorts, Bool())))\n68:   val
      s1_way_waddr = Wire(Vec(nWays, Vec(writePorts, UInt(idxBits.W))))\n69:   val
      s1_way_wdata = Wire(Vec(nWays, Vec(writePorts, new Meta)))\n70: \n71:   (io.read.zip(io.resp)).zipWithIndex.foreach
      {\n72:     case ((read, resp), i) =>\n73:       read.ready := true.B\n74:  \
      \     (0 until nWays).map(way => {\n75:         val read_way_bypass = WireInit(false.B)\n\
      76:         val bypass_data = Wire(new Meta)\n77:         bypass_data := DontCare\n\
      78:         (0 until writePorts).map { wport =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/AsynchronousMetaArray.scala
    lines: 74-88
    context: "74:       (0 until nWays).map(way => {\n75:         val read_way_bypass
      = WireInit(false.B)\n76:         val bypass_data = Wire(new Meta)\n77:     \
      \    bypass_data := DontCare\n78:         (0 until writePorts).map { wport =>\n\
      79:           when(s1_way_wen(way)(wport) && s1_way_waddr(way)(wport) === read.bits.idx)
      {\n80:             read_way_bypass := true.B\n81:             bypass_data :=
      s1_way_wdata(way)(wport)\n82:           }\n83:           when(s0_way_wen(way)(wport)
      && s0_way_waddr(way)(wport) === read.bits.idx) {\n84:             read_way_bypass
      := true.B\n85:             bypass_data := s0_way_wdata(way)(wport)\n86:    \
      \       }\n87:         }\n88:         if (bypassRead) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/AsynchronousMetaArray.scala
    lines: 85-108
    context: "85:             bypass_data := s0_way_wdata(way)(wport)\n86:       \
      \    }\n87:         }\n88:         if (bypassRead) {\n89:           resp(way)
      := Mux(\n90:             RegEnable(read_way_bypass, read.valid),\n91:      \
      \       RegEnable(bypass_data, read_way_bypass),\n92:             RegEnable(meta_array(read.bits.idx)(way),
      read.valid)\n93:           )\n94:         } else {\n95:           resp(way)
      := meta_array(RegEnable(read.bits.idx, read.valid))(way)\n96:         }\n97:\
      \       })\n98:   }\n99: \n100:   io.write.zipWithIndex.foreach {\n101:    \
      \ case (write, wport) =>\n102:       write.ready := true.B\n103:       write.bits.way_en.asBools.zipWithIndex.foreach
      {\n104:         case (wen, way) =>\n105:           s0_way_wen(way)(wport) :=
      write.valid && wen\n106:           s0_way_waddr(way)(wport) := write.bits.idx\n\
      107:           s0_way_wdata(way)(wport) := write.bits.meta\n108:           s1_way_wen(way)(wport)
      := RegNext(s0_way_wen(way)(wport))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/AsynchronousMetaArray.scala
    lines: 115-125
    context: "115:   }\n116: }\n117: \n118: class L1FlagMetaArray(readPorts: Int,
      writePorts: Int, enableBypass: Boolean = false)(implicit p: Parameters) extends
      DCacheModule {\n119:   val io = IO(new Bundle() {\n120:     val read = Vec(readPorts,
      Flipped(DecoupledIO(new MetaReadReq)))\n121:     val resp = Output(Vec(readPorts,
      Vec(nWays, Bool())))\n122:     val write = Vec(writePorts, Flipped(DecoupledIO(new
      FlagMetaWriteReq)))\n123:     // customized cache op port\n124:     // val cacheOp
      = Flipped(new L1CacheInnerOpIO)\n125:   })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/AsynchronousMetaArray.scala
    lines: 135-147
    context: "135:   val s0_way_wdata = Wire(Vec(nWays, Vec(writePorts, Bool())))\n\
      136:   val s1_way_wen = Wire(Vec(nWays, Vec(writePorts, Bool())))\n137:   val
      s1_way_waddr = Wire(Vec(nWays, Vec(writePorts, UInt(idxBits.W))))\n138:   val
      s1_way_wdata = Wire(Vec(nWays, Vec(writePorts, Bool())))\n139: \n140:   (io.read.zip(io.resp)).zipWithIndex.foreach
      {\n141:     case ((read, resp), i) =>\n142:       read.ready := true.B\n143:\
      \       (0 until nWays).map(way => {\n144:         val read_way_bypass = WireInit(false.B)\n\
      145:         val bypass_data = Wire(Bool())\n146:         bypass_data := DontCare\n\
      147:         (0 until writePorts).map { wport =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/AsynchronousMetaArray.scala
    lines: 143-157
    context: "143:       (0 until nWays).map(way => {\n144:         val read_way_bypass
      = WireInit(false.B)\n145:         val bypass_data = Wire(Bool())\n146:     \
      \    bypass_data := DontCare\n147:         (0 until writePorts).map { wport
      =>\n148:           when(s1_way_wen(way)(wport) && s1_way_waddr(way)(wport) ===
      read.bits.idx) {\n149:             read_way_bypass := true.B\n150:         \
      \    bypass_data := s1_way_wdata(way)(wport)\n151:           }\n152:       \
      \    when(s0_way_wen(way)(wport) && s0_way_waddr(way)(wport) === read.bits.idx)
      {\n153:             read_way_bypass := true.B\n154:             bypass_data
      := s0_way_wdata(way)(wport)\n155:           }\n156:         }\n157: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/AsynchronousMetaArray.scala
    lines: 155-178
    context: "155:           }\n156:         }\n157: \n158:         if (enableBypass)
      {\n159:           resp(way) := Mux(\n160:             RegEnable(read_way_bypass,
      read.valid),\n161:             RegEnable(bypass_data, read_way_bypass),\n162:\
      \             meta_array(RegEnable(read.bits.idx, read.valid))(way)\n163:  \
      \         )\n164:         } else {\n165:           resp(way) := meta_array(RegEnable(read.bits.idx,
      read.valid))(way)\n166:         }\n167:       })\n168:   }\n169: \n170:   io.write.zipWithIndex.foreach
      {\n171:     case (write, wport) =>\n172:       write.ready := true.B\n173: \
      \      write.bits.way_en.asBools.zipWithIndex.foreach {\n174:         case (wen,
      way) =>\n175:           s0_way_wen(way)(wport) := write.valid && wen\n176: \
      \          s0_way_waddr(way)(wport) := write.bits.idx\n177:           s0_way_wdata(way)(wport)
      := write.bits.flag\n178:           s1_way_wen(way)(wport) := RegNext(s0_way_wen(way)(wport))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/AsynchronousMetaArray.scala
    lines: 189-199
    context: "189:   val source = UInt(L1PfSourceBits.W)\n190: }\n191: \n192: class
      L1PrefetchSourceArray(readPorts: Int, writePorts: Int)(implicit p: Parameters)
      extends DCacheModule {\n193:   val io = IO(new Bundle() {\n194:     val read
      = Vec(readPorts, Flipped(DecoupledIO(new MetaReadReq)))\n195:     val resp =
      Output(Vec(readPorts, Vec(nWays, UInt(L1PfSourceBits.W))))\n196:     val write
      = Vec(writePorts, Flipped(DecoupledIO(new SourceMetaWriteReq)))\n197:   })\n\
      198: \n199:   val meta_array = RegInit("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/AsynchronousMetaArray.scala
    lines: 205-217
    context: "205:   val s0_way_wen = Wire(Vec(nWays, Vec(writePorts, Bool())))\n\
      206:   val s1_way_wen = Wire(Vec(nWays, Vec(writePorts, Bool())))\n207:   val
      s1_way_waddr = Wire(Vec(nWays, Vec(writePorts, UInt(idxBits.W))))\n208:   val
      s1_way_wdata = Wire(Vec(nWays, Vec(writePorts, UInt(L1PfSourceBits.W))))\n209:\
      \ \n210:   (io.read.zip(io.resp)).zipWithIndex.foreach {\n211:     case ((read,
      resp), i) =>\n212:       read.ready := true.B\n213:       (0 until nWays).map(way
      => {\n214:         val read_way_bypass = WireInit(false.B)\n215:         val
      bypass_data = Wire(UInt(L1PfSourceBits.W))\n216:         bypass_data := DontCare\n\
      217:         (0 until writePorts).map(wport =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/AsynchronousMetaArray.scala
    lines: 213-223
    context: "213:       (0 until nWays).map(way => {\n214:         val read_way_bypass
      = WireInit(false.B)\n215:         val bypass_data = Wire(UInt(L1PfSourceBits.W))\n\
      216:         bypass_data := DontCare\n217:         (0 until writePorts).map(wport
      =>\n218:           when(s1_way_wen(way)(wport) && s1_way_waddr(way)(wport) ===
      read.bits.idx){\n219:             read_way_bypass := true.B\n220:          \
      \   bypass_data := s1_way_wdata(way)(wport)\n221:           }\n222:        \
      \ )\n223:         resp(way) := Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/meta/AsynchronousMetaArray.scala
    lines: 219-239
    context: "219:             read_way_bypass := true.B\n220:             bypass_data
      := s1_way_wdata(way)(wport)\n221:           }\n222:         )\n223:        \
      \ resp(way) := Mux(\n224:           RegEnable(read_way_bypass, read.valid),\n\
      225:           RegEnable(bypass_data, read_way_bypass),\n226:           meta_array(RegEnable(read.bits.idx,
      read.valid))(way)\n227:         )\n228:       })\n229:   }\n230: \n231:   io.write.zipWithIndex.foreach
      {\n232:     case (write, wport) =>\n233:       write.ready := true.B\n234: \
      \      write.bits.way_en.asBools.zipWithIndex.foreach {\n235:         case (wen,
      way) =>\n236:           s0_way_wen(way)(wport) := write.valid && wen\n237: \
      \          s1_way_wen(way)(wport) := RegNext(s0_way_wen(way)(wport))\n238: \
      \          s1_way_waddr(way)(wport) := RegEnable(write.bits.idx, s0_way_wen(way)(wport))\n\
      239:           s1_way_wdata(way)(wport) := RegEnable(write.bits.source, s0_way_wen(way)(wport))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/FakeDCache.scala
    lines: 30-44
    context: "30:   for (i <- 0 until LoadPipelineWidth) {\n31:     val ram = DifftestMem(64L
      * 1024 * 1024 * 1024, 8)\n32:     val ren = RegNext(io.lsu.load(i).req.valid)\n\
      33:     val raddr = ((io.lsu.load(i).s1_paddr_dup_dcache - \"h80000000\".U)
      >> 3).asUInt\n34: \n35:     io.lsu.load(i).req.ready := true.B\n36:     io.lsu.load(i).resp.valid
      := RegNext(ren && !io.lsu.load(i).s1_kill)\n37:     io.lsu.load(i).resp.bits.data
      := ram.readAndHold(raddr, ren)\n38:     io.lsu.load(i).resp.bits.miss := false.B\n\
      39:     io.lsu.load(i).resp.bits.replay := false.B\n40:     io.lsu.load(i).resp.bits.id
      := DontCare\n41:     io.lsu.load(i).s2_hit := true.B\n42:     io.lsu.load(i).s1_disable_fast_wakeup
      := false.B\n43:   }\n44:   // to LSQ"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/FakeDCache.scala
    lines: 43-53
    context: "43:   }\n44:   // to LSQ\n45:   //io.lsu.lsq.valid := false.B\n46: \
      \  //io.lsu.lsq.bits := DontCare\n47:   // to Store Buffer\n48:   io.lsu.store.req.ready
      := true.B\n49:   io.lsu.store.main_pipe_hit_resp := DontCare\n50:   //io.lsu.store.refill_hit_resp
      := DontCare\n51:   io.lsu.store.replay_resp := DontCare\n52:   io.lsu.store.main_pipe_hit_resp.valid
      := RegNext(io.lsu.store.req.valid)\n53:   io.lsu.store.main_pipe_hit_resp.bits.id
      := RegEnable(io.lsu.store.req.bits.id, io.lsu.store.req.valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/FakeDCache.scala
    lines: 57-68
    context: "57:   amoHelper.enable := io.lsu.atomics.req.valid && !reset.asBool\n\
      58:   amoHelper.cmd := io.lsu.atomics.req.bits.cmd\n59:   amoHelper.addr :=
      io.lsu.atomics.req.bits.addr\n60:   amoHelper.wdata := io.lsu.atomics.req.bits.amo_data\n\
      61:   amoHelper.mask := io.lsu.atomics.req.bits.amo_mask\n62:   io.lsu.atomics.req.ready
      := true.B\n63:   io.lsu.atomics.resp.valid := RegNext(io.lsu.atomics.req.valid)\n\
      64:   // assert(!io.lsu.atomics.resp.valid || io.lsu.atomics.resp.ready)\n65:\
      \   io.lsu.atomics.resp.bits.data := amoHelper.rdata\n66:   io.lsu.atomics.resp.bits.replay
      := false.B\n67:   io.lsu.atomics.resp.bits.id := 1.U\n68: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/CtrlUnit.scala
    lines: 82-97
    context: "82:     val ctrlRegs  = RegInit(VecInit(Seq.fill(1)(0.U(params.regWidth.W))))\n\
      83:     val delayRegs = RegInit(VecInit(Seq.fill(1)(0.U(params.regWidth.W))))\n\
      84:     val maskRegs  = RegInit(VecInit(Seq.fill(DCacheBanks)(0.U(DCacheSRAMRowBits.W))))\n\
      85:     val counterRegs = RegInit(VecInit(Seq.fill(1)(0.U(params.regWidth.W))))\n\
      86: \n87:     io_pseudoError.zipWithIndex.foreach {\n88:       case (inj, i)
      =>\n89:         val ctrlReg = ctrlRegs.head\n90:         val ctrlRegBundle =
      ctrlRegs.head.asTypeOf(new CtrlUnitCtrlBundle)\n91:         val delayReg = delayRegs.head\n\
      92:         val counterReg = counterRegs.head\n93: \n94:         require(log2Up(io_pseudoError.length)
      == ctrlRegBundle.comp.getWidth, \"io_pseudoError must equal number of components!\"\
      )\n95:         inj.valid := ctrlRegBundle.ese && (ctrlRegBundle.comp === i.U)
      && (!ctrlRegBundle.ede || counterReg === 0.U)\n96:         inj.bits.zip(ctrlRegBundle.bank.asBools).zip(maskRegs).map
      {\n97:           case ((bankOut, bankEnable), mask) =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/CtrlUnit.scala
    lines: 97-107
    context: "97:           case ((bankOut, bankEnable), mask) =>\n98:           \
      \  bankOut.valid := bankEnable\n99:             bankOut.mask  := mask\n100:\
      \         }\n101: \n102:         when (inj.fire) {\n103:           val newCtrlReg
      = WireInit(0.U.asTypeOf(ctrlRegBundle))\n104:           newCtrlReg := ctrlRegBundle\n\
      105:           newCtrlReg.ese := Mux(ctrlRegBundle.persist, ctrlRegBundle.ese,
      false.B)\n106: \n107:           when (newCtrlReg.ese && newCtrlReg.ede) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/CtrlUnit.scala
    lines: 109-119
    context: "109:           }\n110:           ctrlReg := newCtrlReg.asUInt\n111:\
      \         }\n112:     }\n113: \n114:     ctrlRegs.map(_.asTypeOf(new CtrlUnitCtrlBundle)).zip(counterRegs).zipWithIndex.foreach
      {\n115:       case ((ctl, cnt), i) =>\n116:         when (ctl.ese && ctl.ede
      && cnt =/= 0.U) {\n117:           cnt := cnt - 1.U\n118:         }\n119:   \
      \  }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/storepipe/StorePipe.scala
    lines: 42-52
    context: "42:   val req = DecoupledIO(new DcacheStoreRequestIO)\n43:   val resp
      = Flipped(DecoupledIO(new DCacheBundle() {\n44:     // this store misses (for
      now, not used)\n45:     val miss = Bool()\n46:     // this store needs replay
      (for now, not used)\n47:     val replay = Bool()\n48:     // tag error TODO:
      add logic\n49:     val tag_error = Bool()\n50:   }))\n51: }\n52: /** Non-Blocking
      Store Dcache Pipeline"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/storepipe/StorePipe.scala
    lines: 65-79
    context: "65:     val meta_read = DecoupledIO(new MetaReadReq)\n66:     val meta_resp
      = Input(Vec(nWays, new Meta))\n67:     // TODO extra_meta_resp: error; prefetch;
      access (prefetch hit?)\n68:     // val extra_meta_resp = Input(Vec(nWays, new
      DCacheExtraMeta))\n69: \n70:     val tag_read = DecoupledIO(new TagReadReq)\n\
      71:     val tag_resp = Input(Vec(nWays, UInt(encTagBits.W)))\n72: \n73:    \
      \ // send miss request to dcache miss queue\n74:     val miss_req = DecoupledIO(new
      MissReq)\n75: \n76:     // update state vec in replacement algo, for now, set
      this as false\n77:     val replace_access = ValidIO(new ReplacementAccessBundle)\n\
      78:     // find the way to be replaced\n79:     val replace_way = new ReplacementWayReqIO"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/storepipe/StorePipe.scala
    lines: 86-111
    context: "86:   io.error := 0.U.asTypeOf(ValidIO(new L1CacheErrorInfo))\n87: \n\
      88: /** S0:\n89:   *   send tag and meta read req\n90:   */\n91:   val s0_valid
      = io.lsu.req.valid\n92:   val s0_req = io.lsu.req.bits\n93:   val s0_fire =
      io.lsu.req.fire\n94: \n95:   io.meta_read.valid        := s0_valid\n96:   io.meta_read.bits.idx\
      \     := get_idx(io.lsu.req.bits.vaddr)\n97:   io.meta_read.bits.way_en  :=
      ~0.U(nWays.W)\n98: \n99:   io.tag_read.valid         := s0_valid\n100:   io.tag_read.bits.idx\
      \      := get_idx(io.lsu.req.bits.vaddr)\n101:   io.tag_read.bits.way_en   :=
      ~0.U(nWays.W)\n102: \n103:   io.lsu.req.ready := io.meta_read.ready && io.tag_read.ready\n\
      104: \n105:   XSPerfAccumulate(\"s0_valid\", io.lsu.req.valid)\n106:   XSPerfAccumulate(\"\
      s0_valid_not_ready\", io.lsu.req.valid && !io.lsu.req.ready)\n107: \n108: \n\
      109: /** S1:\n110:   * get tag and meta read resp\n111:   * judge hit or miss"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/storepipe/StorePipe.scala
    lines: 110-120
    context: "110:   * get tag and meta read resp\n111:   * judge hit or miss\n112:\
      \   */\n113:   def wayMap[T <: Data](f: Int => T) = VecInit((0 until nWays).map(f))\n\
      114: \n115:   val s1_valid = RegNext(s0_fire)\n116:   val s1_req = RegEnable(s0_req,
      s0_fire)\n117: \n118:   val s1_meta_resp = io.meta_resp\n119:   val s1_tag_resp\
      \  = io.tag_resp.map(tag => tag(tagBits - 1, 0))\n120: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/storepipe/StorePipe.scala
    lines: 144-164
    context: "144: \n145: /** S2:\n146:   * miss: send a write hint to Dache\n147:\
      \   * hit : update replace algrithom to make the hited line stay longer\n148:\
      \   */\n149:   val s2_valid = RegNext(s1_valid) && RegNext(!io.lsu.s1_kill)\n\
      150:   val s2_req = RegEnable(s1_req, s1_valid)\n151: \n152:   val s2_hit =
      RegEnable(s1_hit, s1_valid)\n153:   val s2_paddr = RegEnable(s1_paddr, s1_valid)\n\
      154:   val s2_hit_coh = RegEnable(s1_hit_coh, s1_valid)\n155:   val s2_is_prefetch
      = RegEnable(s1_req.instrtype === DCACHE_PREFETCH_SOURCE.U, s1_valid)\n156: \n\
      157:   io.lsu.resp.valid := s2_valid\n158:   io.lsu.resp.bits.miss := !s2_hit\n\
      159:   io.lsu.resp.bits.replay := false.B\n160:   // TODO: consider tag error\n\
      161:   io.lsu.resp.bits.tag_error := false.B\n162: \n163: \n164:   /**"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/storepipe/StorePipe.scala
    lines: 164-189
    context: "164:   /**\n165:     * send req to Dcache MissQueue\n166:     */\n167:\
      \   if(EnableStorePrefetchAtIssue) {\n168:     // all miss stores, whether prefetched
      or normal, send requests directly to mshr\n169:     io.miss_req.valid := s2_valid
      && !s2_hit\n170:   }else {\n171:     // only prefetched miss stores will send
      requests directly to mshr\n172:     io.miss_req.valid := s2_valid && !s2_hit
      && s2_is_prefetch\n173:   }\n174:   io.miss_req.bits := DontCare\n175:   //
      only send out a prefetch write to Dcache\n176:   io.miss_req.bits.source :=
      DCACHE_PREFETCH_SOURCE.U\n177:   io.miss_req.bits.pf_source := L1_HW_PREFETCH_STORE\n\
      178:   io.miss_req.bits.cmd := MemoryOpConstants.M_PFW\n179:   io.miss_req.bits.addr
      := get_block_addr(s2_paddr)\n180:   io.miss_req.bits.vaddr := s2_req.vaddr\n\
      181:   io.miss_req.bits.req_coh := s2_hit_coh\n182:   // TODO: consider tag
      error\n183:   io.miss_req.bits.cancel := io.lsu.s2_kill\n184:   io.miss_req.bits.pc
      := io.lsu.s2_pc\n185: \n186:   /**\n187:     * update replacer, for now, disable
      this\n188:     */\n189:   io.replace_access.valid := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/storepipe/StorePipe.scala
    lines: 187-197
    context: "187:     * update replacer, for now, disable this\n188:     */\n189:\
      \   io.replace_access.valid := false.B\n190:   io.replace_access.bits  := DontCare\n\
      191: \n192:   XSPerfAccumulate(\"store_fire\", s2_valid && !io.lsu.s2_kill)\n\
      193:   XSPerfAccumulate(\"sta_hit\",  s2_valid &&  s2_hit && !io.lsu.s2_kill)\n\
      194:   XSPerfAccumulate(\"sta_miss\", s2_valid && !s2_hit && !io.lsu.s2_kill)\n\
      195:   XSPerfAccumulate(\"store_miss_prefetch_fire\", io.miss_req.fire && !io.miss_req.bits.cancel)\n\
      196:   XSPerfAccumulate(\"store_miss_prefetch_not_fire\", io.miss_req.valid
      && !io.miss_req.ready && !io.miss_req.bits.cancel)\n197: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 48-58
    context: "48:   updateReplaceOn2ndmiss: Boolean = true,\n49:   nMissEntries: Int
      = 1,\n50:   nProbeEntries: Int = 1,\n51:   nReleaseEntries: Int = 1,\n52:  \
      \ nMMIOEntries: Int = 1,\n53:   nMMIOs: Int = 1,\n54:   blockBytes: Int = 64,\n\
      55:   nMaxPrefetchEntry: Int = 1,\n56:   alwaysReleaseData: Boolean = false,\n\
      57:   isKeywordBitsOpt: Option[Boolean] = Some(true),\n58:   enableDataEcc:
      Boolean = false,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 450-460
    context: "450:   val data_delayed = UInt(VLEN.W)\n451:   val id     = UInt(reqIdWidth.W)\n\
      452:   // cache req missed, send it to miss queue\n453:   val miss   = Bool()\n\
      454:   // cache miss, and failed to enter the missqueue, replay from RS is needed\n\
      455:   val replay = Bool()\n456:   val replayCarry = new ReplayCarry(nWays)\n\
      457:   // data has been corrupted\n458:   val tag_error = Bool() // tag error\n\
      459:   val mshr_id = UInt(log2Up(cfg.nMissEntries).W)\n460: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 458-469
    context: "458:   val tag_error = Bool() // tag error\n459:   val mshr_id = UInt(log2Up(cfg.nMissEntries).W)\n\
      460: \n461:   val debug_robIdx = UInt(log2Ceil(RobSize).W)\n462:   def dump(cond:
      Bool) = {\n463:     XSDebug(cond, \"DCacheWordResp: data: %x id: %d miss: %b
      replay: %b\\n\",\n464:       data, id, miss, replay)\n465:   }\n466: }\n467:\
      \ \n468: class DCacheWordResp(implicit p: Parameters) extends BaseDCacheWordResp\n\
      469: {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 493-507
    context: "493: {\n494:   val data   = UInt((cfg.blockBytes * 8).W)\n495:   //
      cache req missed, send it to miss queue\n496:   val miss   = Bool()\n497:  \
      \ // cache req nacked, replay it later\n498:   val replay = Bool()\n499:   val
      id     = UInt(reqIdWidth.W)\n500:   def dump(cond: Bool) = {\n501:     XSDebug(cond,
      \"DCacheLineResp: data: %x id: %d miss: %b replay: %b\\n\",\n502:       data,
      id, miss, replay)\n503:   }\n504: }\n505: \n506: class Refill(implicit p: Parameters)
      extends DCacheBundle\n507: {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 567-577
    context: "567:   val data_delayed = UInt(XLEN.W)\n568:   val id        = UInt(UncacheBufferIndexWidth.W)
      // resp identified signals\n569:   val nc        = Bool() // resp identified
      signals\n570:   val is2lq     = Bool() // resp identified signals\n571:   val
      miss      = Bool()\n572:   val replay    = Bool()\n573:   val tag_error = Bool()\n\
      574:   val error     = Bool()\n575:   val nderr     = Bool()\n576:   val replayCarry
      = new ReplayCarry(nWays)\n577:   val mshr_id = UInt(log2Up(cfg.nMissEntries).W)\
      \  // FIXME: why uncacheWordResp is not merged to baseDcacheResp"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 576-587
    context: "576:   val replayCarry = new ReplayCarry(nWays)\n577:   val mshr_id
      = UInt(log2Up(cfg.nMissEntries).W)  // FIXME: why uncacheWordResp is not merged
      to baseDcacheResp\n578: \n579:   val debug_robIdx = UInt(log2Ceil(RobSize).W)\n\
      580:   def dump(cond: Bool) = {\n581:     XSDebug(cond, \"UncacheWordResp: data:
      %x id: %d miss: %b replay: %b, tag_error: %b, error: %b\\n\",\n582:       data,
      id, miss, replay, tag_error, error)\n583:   }\n584: }\n585: \n586: class UncacheWordIO(implicit
      p: Parameters) extends DCacheBundle\n587: {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 594-604
    context: "594:   //distinguish amo\n595:   val source  = UInt(sourceTypeWidth.W)\n\
      596:   val data    = UInt(QuadWordBits.W)\n597:   val miss    = Bool()\n598:\
      \   val miss_id = UInt(log2Up(cfg.nMissEntries).W)\n599:   val replay  = Bool()\n\
      600:   val error   = Bool()\n601: \n602:   val ack_miss_queue = Bool()\n603:\
      \ \n604:   val id     = UInt(reqIdWidth.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 613-623
    context: "613:   val resp = Flipped(ValidIO(new MainPipeResp))\n614:   val block_lr
      = Input(Bool())\n615: }\n616: \n617: class CMOReq(implicit p: Parameters) extends
      Bundle {\n618:   val opcode = UInt(3.W)   // 0-cbo.clean, 1-cbo.flush, 2-cbo.inval,
      3-cbo.zero\n619:   val address = UInt(64.W)\n620: }\n621: \n622: class CMOResp(implicit
      p: Parameters) extends Bundle {\n623:   val address = UInt(64.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 703-713
    context: "703:     mshrid := DontCare\n704:     last := DontCare\n705:     corrupt
      := false.B\n706:   }\n707: \n708:   def forward(req_valid : Bool, req_mshr_id
      : UInt, req_paddr : UInt) = {\n709:     val all_match = req_valid && valid &&\n\
      710:                 req_mshr_id === mshrid &&\n711:                 req_paddr(log2Up(refillBytes))
      === last\n712:     val forward_D = RegInit(false.B)\n713:     val forwardData
      = RegInit(VecInit(List.fill(VLEN/8)(0.U(8.W))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 733-744
    context: "733: \n734: class MissEntryForwardIO(implicit p: Parameters) extends
      DCacheBundle {\n735:   val inflight = Bool()\n736:   val paddr = UInt(PAddrBits.W)\n\
      737:   val raw_data = Vec(blockRows, UInt(rowBits.W))\n738:   val firstbeat_valid
      = Bool()\n739:   val lastbeat_valid = Bool()\n740:   val corrupt = Bool()\n\
      741: \n742:   // check if we can forward from mshr or D channel\n743:   def
      check(req_valid : Bool, req_paddr : UInt) = {\n744:     RegNext(req_valid &&
      inflight && req_paddr(PAddrBits - 1, blockOffBits) === paddr(PAddrBits - 1,
      blockOffBits)) // TODO: clock gate(1-bit)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 742-754
    context: "742:   // check if we can forward from mshr or D channel\n743:   def
      check(req_valid : Bool, req_paddr : UInt) = {\n744:     RegNext(req_valid &&
      inflight && req_paddr(PAddrBits - 1, blockOffBits) === paddr(PAddrBits - 1,
      blockOffBits)) // TODO: clock gate(1-bit)\n745:   }\n746: \n747:   def forward(req_valid
      : Bool, req_paddr : UInt) = {\n748:     val all_match = (req_paddr(log2Up(refillBytes))
      === 0.U && firstbeat_valid) ||\n749:                     (req_paddr(log2Up(refillBytes))
      === 1.U && lastbeat_valid)\n750: \n751:     val forward_mshr = RegInit(false.B)\n\
      752:     val forwardData = RegInit(VecInit(List.fill(VLEN/8)(0.U(8.W))))\n753:\
      \ \n754:     val block_idx = req_paddr(log2Up(refillBytes), 3)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 788-798
    context: "788:     forwardData := sink.forwardData\n789:     forward_result_valid
      := sink.forward_result_valid\n790:     corrupt := sink.corrupt\n791:   }\n792:\
      \ \n793:   def forward() = {\n794:     (forward_result_valid, forward_mshr,
      forwardData, corrupt)\n795:   }\n796: }\n797: \n798: class StorePrefetchReq(implicit
      p: Parameters) extends DCacheBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 840-850
    context: "840: \n841: private object ArbiterCtrl {\n842:   def apply(request:
      Seq[Bool]): Seq[Bool] = request.length match {\n843:     case 0 => Seq()\n844:\
      \     case 1 => Seq(true.B)\n845:     case _ => true.B +: request.tail.init.scanLeft(request.head)(_
      || _).map(!_)\n846:   }\n847: }\n848: \n849: class TreeArbiter[T <: MissReqWoStoreData](val
      gen: T, val n: Int) extends Module{\n850:   val io = IO(new ArbiterIO(gen, n))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 857-872
    context: "857:         Mux(in(0).valid, sIdx, sIdx + 1.U),\n858:         Mux(in(0).valid,
      in(0).bits, in(1).bits)\n859:       )\n860:     } else {\n861:       val half
      = in.length / 2\n862:       val leftValid = in.slice(0, half).map(_.valid).reduce(_
      || _)\n863:       val (leftIdx, leftSel) = selectTree(VecInit(in.slice(0, half)),
      sIdx)\n864:       val (rightIdx, rightSel) = selectTree(VecInit(in.slice(half,
      in.length)), sIdx + half.U)\n865:       (\n866:         Mux(leftValid, leftIdx,
      rightIdx),\n867:         Mux(leftValid, leftSel, rightSel)\n868:       )\n869:\
      \     }\n870:   }\n871:   val ins = Wire(Vec(n, Valid(gen)))\n872:   for (i
      <- 0 until n) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 878-888
    context: "878:   io.chosen := idx\n879:   io.out.bits := sel\n880: \n881:   val
      grant = ArbiterCtrl(io.in.map(_.valid))\n882:   for ((in, g) <- io.in.zip(grant))\n\
      883:     in.ready := g && io.out.ready\n884:   io.out.valid := !grant.last ||
      io.in.last.valid\n885: }\n886: \n887: class DCacheMEQueryIOBundle(implicit p:
      Parameters) extends DCacheBundle\n888: {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 892-914
    context: "892:   val secondary_reject = Input(Bool())\n893: }\n894: \n895: class
      DCacheMQQueryIOBundle(implicit p: Parameters) extends DCacheBundle\n896: {\n\
      897:   val req    = ValidIO(new MissReq)\n898:   val ready  = Input(Bool())\n\
      899: }\n900: \n901: class MissReadyGen(val n: Int)(implicit p: Parameters) extends
      XSModule {\n902:   val io = IO(new Bundle {\n903:     val in = Vec(n, Flipped(DecoupledIO(new
      MissReq)))\n904:     val queryMQ = Vec(n, new DCacheMQQueryIOBundle)\n905: \
      \  })\n906: \n907:   val mqReadyVec = io.queryMQ.map(_.ready)\n908: \n909: \
      \  io.queryMQ.zipWithIndex.foreach{\n910:     case (q, idx) => {\n911:     \
      \  q.req.valid := io.in(idx).valid\n912:       q.req.bits  := io.in(idx).bits\n\
      913:     }\n914:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 913-925
    context: "913:     }\n914:   }\n915:   io.in.zipWithIndex.map {\n916:     case
      (r, idx) => {\n917:       if (idx == 0) {\n918:         r.ready := mqReadyVec(idx)\n\
      919:       } else {\n920:         r.ready := mqReadyVec(idx) && !Cat(io.in.slice(0,
      idx).map(_.valid)).orR\n921:       }\n922:     }\n923:   }\n924: \n925: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 956-966
    context: "956: \n957: class DCacheImp(outer: DCache) extends LazyModuleImp(outer)
      with HasDCacheParameters with HasPerfEvents with HasL1PrefetchSourceParameter
      {\n958: \n959:   val io = IO(new DCacheIO)\n960: \n961:   val (bus, edge) =
      outer.clientNode.out.head\n962:   require(bus.d.bits.data.getWidth == l1BusDataWidth,
      \"DCache: tilelink width does not match\")\n963: \n964:   println(\"DCache:\"\
      )\n965:   println(\"  DCacheSets: \" + DCacheSets)\n966:   println(\"  DCacheSetDiv:
      \" + DCacheSetDiv)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1034-1045
    context: "1034:   missQueue.io.hartId := io.hartId\n1035:   missQueue.io.l2_pf_store_only
      := RegNext(io.l2_pf_store_only, false.B)\n1036:   missQueue.io.debugTopDown
      <> io.debugTopDown\n1037:   missQueue.io.l2_hint <> RegNext(io.l2_hint)\n1038:\
      \   missQueue.io.mainpipe_info := mainPipe.io.mainpipe_info\n1039:   missQueue.io.occupy_set.zip(ldu.map(_.io.occupy_set)).foreach
      { case (l, r) => l <> r }\n1040:   missQueue.io.occupy_fail.zip(ldu.map(_.io.occupy_fail)).foreach
      { case (l, r) => l <> r }\n1041:   mainPipe.io.refill_info := missQueue.io.refill_info\n\
      1042:   mainPipe.io.replace <> missQueue.io.replace\n1043:   mainPipe.io.sms_agt_evict_req
      <> io.sms_agt_evict_req\n1044:   io.memSetPattenDetected := missQueue.io.memSetPattenDetected\n\
      1045:   io.wfi <> missQueue.io.wfi"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1043-1059
    context: "1043:   mainPipe.io.sms_agt_evict_req <> io.sms_agt_evict_req\n1044:\
      \   io.memSetPattenDetected := missQueue.io.memSetPattenDetected\n1045:   io.wfi
      <> missQueue.io.wfi\n1046: \n1047:   // l1 dcache controller\n1048:   outer.cacheCtrlOpt.foreach
      {\n1049:     case mod =>\n1050:       mod.module.io_pseudoError.foreach {\n\
      1051:         case x => x.ready := false.B\n1052:       }\n1053:   }\n1054:\
      \   ldu.foreach {\n1055:     case mod =>\n1056:       mod.io.pseudo_error.valid
      := false.B\n1057:       mod.io.pseudo_error.bits := DontCare\n1058:   }\n1059:\
      \   mainPipe.io.pseudo_error.valid := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1061-1074
    context: "1061:   bankedDataArray.io.pseudo_error.valid := false.B\n1062:   bankedDataArray.io.pseudo_error.bits\
      \  := DontCare\n1063: \n1064:   // pseudo tag ecc error\n1065:   if (outer.cacheCtrlOpt.nonEmpty
      && EnableTagEcc) {\n1066:     val ctrlUnit = outer.cacheCtrlOpt.head.module\n\
      1067:     ldu.map(mod => mod.io.pseudo_error <> ctrlUnit.io_pseudoError(0))\n\
      1068:     mainPipe.io.pseudo_error <> ctrlUnit.io_pseudoError(0)\n1069:    \
      \ ctrlUnit.io_pseudoError(0).ready := mainPipe.io.pseudo_tag_error_inj_done
      ||\n1070:                                         ldu.map(_.io.pseudo_tag_error_inj_done).reduce(_|_)\n\
      1071:   }\n1072: \n1073:   // pseudo data ecc error\n1074:   if (outer.cacheCtrlOpt.nonEmpty
      && EnableDataEcc) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1070-1082
    context: "1070:                                         ldu.map(_.io.pseudo_tag_error_inj_done).reduce(_|_)\n\
      1071:   }\n1072: \n1073:   // pseudo data ecc error\n1074:   if (outer.cacheCtrlOpt.nonEmpty
      && EnableDataEcc) {\n1075:     val ctrlUnit = outer.cacheCtrlOpt.head.module\n\
      1076:     bankedDataArray.io.pseudo_error <> ctrlUnit.io_pseudoError(1)\n1077:\
      \     ctrlUnit.io_pseudoError(1).ready := bankedDataArray.io.pseudo_error.ready
      &&\n1078:                                         (mainPipe.io.pseudo_data_error_inj_done
      ||\n1079:                                          ldu.map(_.io.pseudo_data_error_inj_done).reduce(_|_))\n\
      1080:   }\n1081: \n1082:   val errors = Seq(mainPipe.io.error) ++ // store /
      misc error"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1101-1112
    context: "1101:     hybrid_meta_read_ports(i).valid := ldu(HybridLoadMetaReadPort).io.meta_read.valid
      ||\n1102:                                        (stu(HybridStoreMetaReadPort).io.meta_read.valid
      && StorePrefetchL1Enabled.B)\n1103:     hybrid_meta_read_ports(i).bits := Mux(ldu(HybridLoadMetaReadPort).io.meta_read.valid,
      ldu(HybridLoadMetaReadPort).io.meta_read.bits,\n1104:                      \
      \                     stu(HybridStoreMetaReadPort).io.meta_read.bits)\n1105:\
      \ \n1106:     ldu(HybridLoadMetaReadPort).io.meta_read.ready := hybrid_meta_read_ports(i).ready\n\
      1107:     stu(HybridStoreMetaReadPort).io.meta_read.ready := hybrid_meta_read_ports(i).ready
      && StorePrefetchL1Enabled.B\n1108: \n1109:     ldu(HybridLoadMetaReadPort).io.meta_resp
      := hybrid_meta_resp_ports(i)\n1110:     stu(HybridStoreMetaReadPort).io.meta_resp
      := hybrid_meta_resp_ports(i)\n1111:   }\n1112: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1122-1161
    context: "1122:   val meta_write_ports = Seq(\n1123:     mainPipe.io.meta_write\n\
      1124:     // refillPipe.io.meta_write\n1125:   )\n1126:   if(StorePrefetchL1Enabled)
      {\n1127:     meta_read_ports.zip(metaArray.io.read).foreach { case (p, r) =>
      r <> p }\n1128:     meta_resp_ports.zip(metaArray.io.resp).foreach { case (p,
      r) => p := r }\n1129:   } else {\n1130:     (meta_read_ports.take(HybridLoadReadBase
      + 1) ++\n1131:      meta_read_ports.takeRight(backendParams.HyuCnt)).zip(metaArray.io.read).foreach
      { case (p, r) => r <> p }\n1132:     (meta_resp_ports.take(HybridLoadReadBase
      + 1) ++\n1133:      meta_resp_ports.takeRight(backendParams.HyuCnt)).zip(metaArray.io.resp).foreach
      { case (p, r) => p := r }\n1134: \n1135:     meta_read_ports.drop(HybridLoadReadBase
      + 1).take(HybridStoreReadBase).foreach { case p => p.ready := false.B }\n1136:\
      \     meta_resp_ports.drop(HybridLoadReadBase + 1).take(HybridStoreReadBase).foreach
      { case p => p := 0.U.asTypeOf(p) }\n1137:   }\n1138:   meta_write_ports.zip(metaArray.io.write).foreach
      { case (p, w) => w <> p }\n1139: \n1140:   // read extra meta (exclude stu)\n\
      1141:   (meta_read_ports.take(HybridLoadReadBase + 1) ++\n1142:    meta_read_ports.takeRight(backendParams.HyuCnt)).zip(errorArray.io.read).foreach
      { case (p, r) => r <> p }\n1143:   (meta_read_ports.take(HybridLoadReadBase
      + 1) ++\n1144:    meta_read_ports.takeRight(backendParams.HyuCnt)).zip(prefetchArray.io.read).foreach
      { case (p, r) => r <> p }\n1145:   (meta_read_ports.take(HybridLoadReadBase
      + 1) ++\n1146:    meta_read_ports.takeRight(backendParams.HyuCnt)).zip(accessArray.io.read).foreach
      { case (p, r) => r <> p }\n1147:   val extra_meta_resp_ports = ldu.map(_.io.extra_meta_resp).take(HybridLoadReadBase)
      ++\n1148:     Seq(mainPipe.io.extra_meta_resp) ++\n1149:     ldu.map(_.io.extra_meta_resp).takeRight(backendParams.HyuCnt)\n\
      1150:   extra_meta_resp_ports.zip(errorArray.io.resp).foreach { case (p, r)
      => {\n1151:     (0 until nWays).map(i => { p(i).error := r(i) })\n1152:   }}\n\
      1153:   extra_meta_resp_ports.zip(prefetchArray.io.resp).foreach { case (p,
      r) => {\n1154:     (0 until nWays).map(i => { p(i).prefetch := r(i) })\n1155:\
      \   }}\n1156:   extra_meta_resp_ports.zip(accessArray.io.resp).foreach { case
      (p, r) => {\n1157:     (0 until nWays).map(i => { p(i).access := r(i) })\n1158:\
      \   }}\n1159: \n1160:   if(LoadPrefetchL1Enabled) {\n1161:     // use last port
      to read prefetch and access flag"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1164-1180
    context: "1164: //    prefetchArray.io.read.last.bits.way_en := refillPipe.io.prefetch_flag_write.bits.way_en\n\
      1165: //\n1166: //    accessArray.io.read.last.valid := refillPipe.io.prefetch_flag_write.valid\n\
      1167: //    accessArray.io.read.last.bits.idx := refillPipe.io.prefetch_flag_write.bits.idx\n\
      1168: //    accessArray.io.read.last.bits.way_en := refillPipe.io.prefetch_flag_write.bits.way_en\n\
      1169:     prefetchArray.io.read.last.valid := mainPipe.io.prefetch_flag_write.valid\n\
      1170:     prefetchArray.io.read.last.bits.idx := mainPipe.io.prefetch_flag_write.bits.idx\n\
      1171:     prefetchArray.io.read.last.bits.way_en := mainPipe.io.prefetch_flag_write.bits.way_en\n\
      1172: \n1173:     accessArray.io.read.last.valid := mainPipe.io.prefetch_flag_write.valid\n\
      1174:     accessArray.io.read.last.bits.idx := mainPipe.io.prefetch_flag_write.bits.idx\n\
      1175:     accessArray.io.read.last.bits.way_en := mainPipe.io.prefetch_flag_write.bits.way_en\n\
      1176: \n1177:     val extra_flag_valid = RegNext(mainPipe.io.prefetch_flag_write.valid)\n\
      1178:     val extra_flag_way_en = RegEnable(mainPipe.io.prefetch_flag_write.bits.way_en,
      mainPipe.io.prefetch_flag_write.valid)\n1179:     val extra_flag_prefetch =
      Mux1H(extra_flag_way_en, prefetchArray.io.resp.last)\n1180:     val extra_flag_access
      = Mux1H(extra_flag_way_en, accessArray.io.resp.last)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1186-1196
    context: "1186:   // write extra meta\n1187:   val error_flag_write_ports = Seq(\n\
      1188:     mainPipe.io.error_flag_write // error flag generated by corrupted
      store\n1189:     // refillPipe.io.error_flag_write // corrupted signal from
      l2\n1190:   )\n1191:   error_flag_write_ports.zip(errorArray.io.write).foreach
      { case (p, w) => w <> p }\n1192: \n1193:   val prefetch_flag_write_ports = ldu.map(_.io.prefetch_flag_write)
      ++ Seq(\n1194:     mainPipe.io.prefetch_flag_write // set prefetch_flag to false
      if coh is set to Nothing\n1195:     // refillPipe.io.prefetch_flag_write //
      refill required by prefetch will set prefetch_flag\n1196:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1192-1202
    context: "1192: \n1193:   val prefetch_flag_write_ports = ldu.map(_.io.prefetch_flag_write)
      ++ Seq(\n1194:     mainPipe.io.prefetch_flag_write // set prefetch_flag to false
      if coh is set to Nothing\n1195:     // refillPipe.io.prefetch_flag_write //
      refill required by prefetch will set prefetch_flag\n1196:   )\n1197:   prefetch_flag_write_ports.zip(prefetchArray.io.write).foreach
      { case (p, w) => w <> p }\n1198: \n1199:   // FIXME: add hybrid unit?\n1200:\
      \   val same_cycle_update_pf_flag = ldu(0).io.prefetch_flag_write.valid && ldu(1).io.prefetch_flag_write.valid
      && (ldu(0).io.prefetch_flag_write.bits.idx === ldu(1).io.prefetch_flag_write.bits.idx)
      && (ldu(0).io.prefetch_flag_write.bits.way_en === ldu(1).io.prefetch_flag_write.bits.way_en)\n\
      1201:   XSPerfAccumulate(\"same_cycle_update_pf_flag\", same_cycle_update_pf_flag)\n\
      1202: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1202-1240
    context: "1202: \n1203:   val access_flag_write_ports = ldu.map(_.io.access_flag_write)
      ++ Seq(\n1204:     mainPipe.io.access_flag_write\n1205:     // refillPipe.io.access_flag_write\n\
      1206:   )\n1207:   access_flag_write_ports.zip(accessArray.io.write).foreach
      { case (p, w) => w <> p }\n1208: \n1209:   //----------------------------------------\n\
      1210:   // tag array\n1211:   if(StorePrefetchL1Enabled) {\n1212:     require(tagArray.io.read.size
      == (LoadPipelineWidth + StorePipelineWidth - backendParams.HyuCnt + 1))\n1213:\
      \   }else {\n1214:     require(tagArray.io.read.size == (LoadPipelineWidth +
      1))\n1215:   }\n1216:   // val tag_write_intend = missQueue.io.refill_pipe_req.valid
      || mainPipe.io.tag_write_intend\n1217:   val tag_write_intend = mainPipe.io.tag_write_intend\n\
      1218:   assert(!RegNext(!tag_write_intend && tagArray.io.write.valid))\n1219:\
      \   ldu.take(HybridLoadReadBase).zipWithIndex.foreach {\n1220:     case (ld,
      i) =>\n1221:       tagArray.io.read(i) <> ld.io.tag_read\n1222:       ld.io.tag_resp
      := tagArray.io.resp(i)\n1223:       ld.io.tag_read.ready := !tag_write_intend\n\
      1224:   }\n1225:   if(StorePrefetchL1Enabled) {\n1226:     stu.take(HybridStoreReadBase).zipWithIndex.foreach
      {\n1227:       case (st, i) =>\n1228:         tagArray.io.read(HybridLoadReadBase
      + i) <> st.io.tag_read\n1229:         st.io.tag_resp := tagArray.io.resp(HybridLoadReadBase
      + i)\n1230:         st.io.tag_read.ready := !tag_write_intend\n1231:     }\n\
      1232:   }else {\n1233:     stu.foreach {\n1234:       case st =>\n1235:    \
      \     st.io.tag_read.ready := false.B\n1236:         st.io.tag_resp := 0.U.asTypeOf(st.io.tag_resp)\n\
      1237:     }\n1238:   }\n1239:   for (i <- 0 until backendParams.HyuCnt) {\n\
      1240:     val HybridLoadTagReadPort = HybridLoadReadBase + i"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1244-1267
    context: "1244:         HybridLoadReadBase + HybridStoreReadBase + i\n1245:  \
      \     else\n1246:         HybridLoadReadBase + i\n1247: \n1248:     // read
      tag\n1249:     ldu(HybridLoadTagReadPort).io.tag_read.ready := false.B\n1250:\
      \     stu(HybridStoreTagReadPort).io.tag_read.ready := false.B\n1251: \n1252:\
      \     if (StorePrefetchL1Enabled) {\n1253:       when (ldu(HybridLoadTagReadPort).io.tag_read.valid)
      {\n1254:         tagArray.io.read(TagReadPort) <> ldu(HybridLoadTagReadPort).io.tag_read\n\
      1255:         ldu(HybridLoadTagReadPort).io.tag_read.ready := !tag_write_intend\n\
      1256:       } .otherwise {\n1257:         tagArray.io.read(TagReadPort) <> stu(HybridStoreTagReadPort).io.tag_read\n\
      1258:         stu(HybridStoreTagReadPort).io.tag_read.ready := !tag_write_intend\n\
      1259:       }\n1260:     } else {\n1261:       tagArray.io.read(TagReadPort)
      <> ldu(HybridLoadTagReadPort).io.tag_read\n1262:       ldu(HybridLoadTagReadPort).io.tag_read.ready
      := !tag_write_intend\n1263:     }\n1264: \n1265:     // tag resp\n1266:    \
      \ ldu(HybridLoadTagReadPort).io.tag_resp := tagArray.io.resp(TagReadPort)\n\
      1267:     stu(HybridStoreTagReadPort).io.tag_resp := tagArray.io.resp(TagReadPort)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1264-1277
    context: "1264: \n1265:     // tag resp\n1266:     ldu(HybridLoadTagReadPort).io.tag_resp
      := tagArray.io.resp(TagReadPort)\n1267:     stu(HybridStoreTagReadPort).io.tag_resp
      := tagArray.io.resp(TagReadPort)\n1268:   }\n1269:   tagArray.io.read.last <>
      mainPipe.io.tag_read\n1270:   mainPipe.io.tag_resp := tagArray.io.resp.last\n\
      1271: \n1272:   val fake_tag_read_conflict_this_cycle = PopCount(ldu.map(ld=>
      ld.io.tag_read.valid))\n1273:   XSPerfAccumulate(\"fake_tag_read_conflict\"\
      , fake_tag_read_conflict_this_cycle)\n1274: \n1275:   val tag_write_arb = Module(new
      Arbiter(new TagWriteReq, 1))\n1276:   // tag_write_arb.io.in(0) <> refillPipe.io.tag_write\n\
      1277:   tag_write_arb.io.in(0) <> mainPipe.io.tag_write"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1310-1320
    context: "1310:   mainPipe.io.readline_error := bankedDataArray.io.readline_error\n\
      1311:   mainPipe.io.readline_error_delayed := bankedDataArray.io.readline_error_delayed\n\
      1312:   mainPipe.io.data_resp := bankedDataArray.io.readline_resp\n1313: \n\
      1314:   (0 until LoadPipelineWidth).map(i => {\n1315:     bankedDataArray.io.read(i)
      <> ldu(i).io.banked_data_read\n1316:     bankedDataArray.io.is128Req(i) <> ldu(i).io.is128Req\n\
      1317:     bankedDataArray.io.read_error_delayed(i) <> ldu(i).io.read_error_delayed\n\
      1318: \n1319:     ldu(i).io.banked_data_resp := bankedDataArray.io.read_resp(i)\n\
      1320: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1341-1351
    context: "1341:     val dwpu = Module(new DCacheWpuWrapper(LoadPipelineWidth))\n\
      1342:     for(i <- 0 until LoadPipelineWidth){\n1343:       dwpu.io.req(i) <>
      ldu(i).io.dwpu.req(0)\n1344:       dwpu.io.resp(i) <> ldu(i).io.dwpu.resp(0)\n\
      1345:       dwpu.io.lookup_upd(i) <> ldu(i).io.dwpu.lookup_upd(0)\n1346:   \
      \    dwpu.io.cfpred(i) <> ldu(i).io.dwpu.cfpred(0)\n1347:     }\n1348:     dwpu.io.tagwrite_upd.valid
      := tagArray.io.write.valid\n1349:     dwpu.io.tagwrite_upd.bits.vaddr := tagArray.io.write.bits.vaddr\n\
      1350:     dwpu.io.tagwrite_upd.bits.s1_real_way_en := tagArray.io.write.bits.way_en\n\
      1351:   } else {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1348-1358
    context: "1348:     dwpu.io.tagwrite_upd.valid := tagArray.io.write.valid\n1349:\
      \     dwpu.io.tagwrite_upd.bits.vaddr := tagArray.io.write.bits.vaddr\n1350:\
      \     dwpu.io.tagwrite_upd.bits.s1_real_way_en := tagArray.io.write.bits.way_en\n\
      1351:   } else {\n1352:     for(i <- 0 until LoadPipelineWidth){\n1353:    \
      \   ldu(i).io.dwpu.req(0).ready := true.B\n1354:       ldu(i).io.dwpu.resp(0).valid
      := false.B\n1355:       ldu(i).io.dwpu.resp(0).bits := DontCare\n1356:     }\n\
      1357:   }\n1358: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1392-1410
    context: "1392:   val siteName = s\"DcacheWrapper$hartId\"\n1393:   val loadMissTable
      = ChiselDB.createTable(tableName, new LoadMissEntry)\n1394:   for( i <- 0 until
      LoadPipelineWidth){\n1395:     val loadMissEntry = Wire(new LoadMissEntry)\n\
      1396:     val loadMissWriteEn =\n1397:       (!ldu(i).io.lsu.resp.bits.replay
      && ldu(i).io.miss_req.fire) ||\n1398:       (ldu(i).io.lsu.s2_first_hit && ldu(i).io.lsu.resp.valid
      && isFirstHitWrite.orR)\n1399:     loadMissEntry.timeCnt := GTimer()\n1400:\
      \     loadMissEntry.robIdx := ldu(i).io.lsu.resp.bits.debug_robIdx\n1401:  \
      \   loadMissEntry.paddr := ldu(i).io.miss_req.bits.addr\n1402:     loadMissEntry.vaddr
      := ldu(i).io.miss_req.bits.vaddr\n1403:     loadMissEntry.missState := OHToUInt(Cat(Seq(\n\
      1404:       ldu(i).io.miss_req.fire & ldu(i).io.miss_resp.merged,\n1405:   \
      \    ldu(i).io.miss_req.fire & !ldu(i).io.miss_resp.merged,\n1406:       ldu(i).io.lsu.s2_first_hit
      && ldu(i).io.lsu.resp.valid\n1407:     )))\n1408:     loadMissTable.log(\n1409:\
      \       data = loadMissEntry,\n1410:       en = isWriteLoadMissTable.orR &&
      loadMissWriteEn,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1418-1432
    context: "1418:   val loadAccessTable = ChiselDB.createTable(s\"LoadAccessDB$hartId\"\
      , new LoadAccessEntry)\n1419:   for (i <- 0 until LoadPipelineWidth) {\n1420:\
      \     val loadAccessEntry = Wire(new LoadAccessEntry)\n1421:     loadAccessEntry.timeCnt
      := GTimer()\n1422:     loadAccessEntry.robIdx := ldu(i).io.lsu.resp.bits.debug_robIdx\n\
      1423:     loadAccessEntry.paddr := ldu(i).io.miss_req.bits.addr\n1424:     loadAccessEntry.vaddr
      := ldu(i).io.miss_req.bits.vaddr\n1425:     loadAccessEntry.missState := OHToUInt(Cat(Seq(\n\
      1426:       ldu(i).io.miss_req.fire & ldu(i).io.miss_resp.merged,\n1427:   \
      \    ldu(i).io.miss_req.fire & !ldu(i).io.miss_resp.merged,\n1428:       ldu(i).io.lsu.s2_first_hit
      && ldu(i).io.lsu.resp.valid\n1429:     )))\n1430:     loadAccessEntry.pred_way_num
      := ldu(i).io.lsu.debug_s2_pred_way_num\n1431:     loadAccessEntry.real_way_num
      := ldu(i).io.lsu.debug_s2_real_way_num\n1432:     loadAccessEntry.dm_way_num
      := ldu(i).io.lsu.debug_s2_dm_way_num"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1452-1470
    context: "1452:   io.lsu.atomics.resp.valid := RegNext(atomic_resp_valid)\n1453:\
      \   io.lsu.atomics.resp.bits := RegEnable(mainPipe.io.atomic_resp.bits, atomic_resp_valid)\n\
      1454:   io.lsu.atomics.block_lr := mainPipe.io.block_lr\n1455: \n1456:   //
      Request\n1457:   val missReqArb = Module(new TreeArbiter(new MissReq, MissReqPortCount))\n\
      1458:   // seperately generating miss queue enq ready for better timeing\n1459:\
      \   val missReadyGen = Module(new MissReadyGen(MissReqPortCount))\n1460: \n\
      1461:   missReqArb.io.in(MainPipeMissReqPort) <> mainPipe.io.miss_req\n1462:\
      \   missReadyGen.io.in(MainPipeMissReqPort) <> mainPipe.io.miss_req\n1463: \
      \  for (w <- 0 until backendParams.LduCnt) {\n1464:     missReqArb.io.in(w +
      1) <> ldu(w).io.miss_req\n1465:     missReadyGen.io.in(w + 1) <> ldu(w).io.miss_req\n\
      1466:   }\n1467: \n1468:   for (w <- 0 until LoadPipelineWidth) { ldu(w).io.miss_resp
      := missQueue.io.resp }\n1469:   mainPipe.io.miss_resp := missQueue.io.resp\n\
      1470: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1468-1482
    context: "1468:   for (w <- 0 until LoadPipelineWidth) { ldu(w).io.miss_resp :=
      missQueue.io.resp }\n1469:   mainPipe.io.miss_resp := missQueue.io.resp\n1470:\
      \ \n1471:   if(StorePrefetchL1Enabled) {\n1472:     for (w <- 0 until backendParams.StaCnt)
      {\n1473:       missReqArb.io.in(1 + backendParams.LduCnt + w) <> stu(w).io.miss_req\n\
      1474:       missReadyGen.io.in(1 + backendParams.LduCnt + w) <> stu(w).io.miss_req\n\
      1475:     }\n1476:   }else {\n1477:     for (w <- 0 until backendParams.StaCnt)
      { stu(w).io.miss_req.ready := false.B }\n1478:   }\n1479: \n1480:   for (i <-
      0 until backendParams.HyuCnt) {\n1481:     val HybridLoadReqPort = HybridLoadReadBase
      + i\n1482:     val HybridStoreReqPort = HybridStoreReadBase + i"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1480-1503
    context: "1480:   for (i <- 0 until backendParams.HyuCnt) {\n1481:     val HybridLoadReqPort
      = HybridLoadReadBase + i\n1482:     val HybridStoreReqPort = HybridStoreReadBase
      + i\n1483:     val HybridMissReqPort = HybridMissReqBase + i\n1484: \n1485:\
      \     ldu(HybridLoadReqPort).io.miss_req.ready := false.B\n1486:     stu(HybridStoreReqPort).io.miss_req.ready
      := false.B\n1487: \n1488:     if (StorePrefetchL1Enabled) {\n1489:       when
      (ldu(HybridLoadReqPort).io.miss_req.valid) {\n1490:         missReqArb.io.in(HybridMissReqPort)
      <> ldu(HybridLoadReqPort).io.miss_req\n1491:         missReadyGen.io.in(HybridMissReqPort)
      <> ldu(HybridLoadReqPort).io.miss_req\n1492:       } .otherwise {\n1493:   \
      \      missReqArb.io.in(HybridMissReqPort) <> stu(HybridStoreReqPort).io.miss_req\n\
      1494:         missReadyGen.io.in(HybridMissReqPort) <> stu(HybridStoreReqPort).io.miss_req\n\
      1495:       }\n1496:     } else {\n1497:       missReqArb.io.in(HybridMissReqPort)
      <> ldu(HybridLoadReqPort).io.miss_req\n1498:       missReadyGen.io.in(HybridMissReqPort)
      <> ldu(HybridLoadReqPort).io.miss_req\n1499:     }\n1500:   }\n1501: \n1502:\
      \   for(w <- 0 until LoadPipelineWidth) {\n1503:     wb.io.miss_req_conflict_check(w)
      := ldu(w).io.wbq_conflict_check"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1514-1532
    context: "1514:   missReqArb.io.out <> missQueue.io.req\n1515:   missReadyGen.io.queryMQ
      <> missQueue.io.queryMQ\n1516:   io.cmoOpReq <> missQueue.io.cmo_req\n1517:\
      \   io.cmoOpResp <> missQueue.io.cmo_resp\n1518: \n1519:   XSPerfAccumulate(\"\
      miss_queue_fire\", PopCount(VecInit(missReqArb.io.in.map(_.fire))) >= 1.U)\n\
      1520:   XSPerfAccumulate(\"miss_queue_muti_fire\", PopCount(VecInit(missReqArb.io.in.map(_.fire)))
      > 1.U)\n1521: \n1522:   XSPerfAccumulate(\"miss_queue_has_enq_req\", PopCount(VecInit(missReqArb.io.in.map(_.valid)))
      >= 1.U)\n1523:   XSPerfAccumulate(\"miss_queue_has_muti_enq_req\", PopCount(VecInit(missReqArb.io.in.map(_.valid)))
      > 1.U)\n1524:   XSPerfAccumulate(\"miss_queue_has_muti_enq_but_not_fire\", PopCount(VecInit(missReqArb.io.in.map(_.valid)))
      > 1.U && PopCount(VecInit(missReqArb.io.in.map(_.fire))) === 0.U)\n1525: \n\
      1526:   // forward missqueue\n1527:   (0 until LoadPipelineWidth).map(i => io.lsu.forward_mshr(i).connect(missQueue.io.forward(i)))\n\
      1528: \n1529:   // refill to load queue\n1530:  // io.lsu.lsq <> missQueue.io.refill_to_ldq\n\
      1531: \n1532:   // tilelink stuff"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1572-1582
    context: "1572:   io.lsu.store.main_pipe_hit_resp := mainPipe.io.store_hit_resp\n\
      1573: \n1574:   mainPipe.io.atomic_req <> io.lsu.atomics.req\n1575: \n1576:\
      \   mainPipe.io.invalid_resv_set := RegNext(\n1577:     wb.io.req.fire &&\n\
      1578:     wb.io.req.bits.addr === mainPipe.io.lrsc_locked_block.bits &&\n1579:\
      \     mainPipe.io.lrsc_locked_block.valid\n1580:   )\n1581: \n1582:   //----------------------------------------"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1584-1594
    context: "1584:   val mpStatus = mainPipe.io.status\n1585:   mainPipe.io.refill_req
      <> missQueue.io.main_pipe_req\n1586: \n1587:   mainPipe.io.data_write_ready_dup
      := VecInit(Seq.fill(nDupDataWriteReady)(true.B))\n1588:   mainPipe.io.tag_write_ready_dup
      := VecInit(Seq.fill(nDupDataWriteReady)(true.B))\n1589:   mainPipe.io.wb_ready_dup
      := wb.io.req_ready_dup\n1590: \n1591:   //----------------------------------------\n\
      1592:   // wb\n1593:   // add a queue between MainPipe and WritebackUnit to
      reduce MainPipe stalls due to WritebackUnit busy\n1594:   wb.io.req <> mainPipe.io.wb"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1596-1607
    context: "1596:   // wb.io.release_wakeup := refillPipe.io.release_wakeup\n1597:\
      \   // wb.io.release_update := mainPipe.io.release_update\n1598:   //wb.io.probe_ttob_check_req
      <> mainPipe.io.probe_ttob_check_req\n1599:   //wb.io.probe_ttob_check_resp <>
      mainPipe.io.probe_ttob_check_resp\n1600: \n1601:   io.lsu.release.valid := RegNext(wb.io.req.fire)\n\
      1602:   io.lsu.release.bits.paddr := RegEnable(wb.io.req.bits.addr, wb.io.req.fire)\n\
      1603:   // Note: RegNext() is required by:\n1604:   // * load queue released
      flag update logic\n1605:   // * load / load violation check logic\n1606:   //
      * and timing requirements\n1607:   // CHANGE IT WITH CARE"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1612-1622
    context: "1612: \n1613:   wb.io.mem_grant.valid := false.B\n1614:   wb.io.mem_grant.bits\
      \  := DontCare\n1615: \n1616:   // in L1DCache, we ony expect Grant[Data] and
      ReleaseAck\n1617:   bus.d.ready := false.B\n1618:   when (bus.d.bits.opcode
      === TLMessages.Grant || bus.d.bits.opcode === TLMessages.GrantData || bus.d.bits.opcode
      === TLMessages.CBOAck) {\n1619:     missQueue.io.mem_grant <> bus.d\n1620: \
      \  } .elsewhen (bus.d.bits.opcode === TLMessages.ReleaseAck) {\n1621:     wb.io.mem_grant
      <> bus.d\n1622:   } .otherwise {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1618-1628
    context: "1618:   when (bus.d.bits.opcode === TLMessages.Grant || bus.d.bits.opcode
      === TLMessages.GrantData || bus.d.bits.opcode === TLMessages.CBOAck) {\n1619:\
      \     missQueue.io.mem_grant <> bus.d\n1620:   } .elsewhen (bus.d.bits.opcode
      === TLMessages.ReleaseAck) {\n1621:     wb.io.mem_grant <> bus.d\n1622:   }
      .otherwise {\n1623:     assert (!bus.d.fire)\n1624:   }\n1625: \n1626:   //----------------------------------------\n\
      1627:   // Feedback Direct Prefetch Monitor\n1628:   fdpMonitor.io.refill :=
      missQueue.io.prefetch_info.fdp.prefetch_monitor_cnt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1657-1667
    context: "1657:   val replacer = ReplacementPolicy.fromString(cacheParams.replacer,
      nWays, nSets)\n1658:   val replWayReqs = ldu.map(_.io.replace_way) ++ Seq(mainPipe.io.replace_way)
      ++ stu.map(_.io.replace_way)\n1659: \n1660:   if (dwpuParam.enCfPred) {\n1661:\
      \     val victimList = VictimList(nSets)\n1662:     replWayReqs.foreach {\n\
      1663:       case req =>\n1664:         req.way := DontCare\n1665:         when(req.set.valid)
      {\n1666:           when(victimList.whether_sa(req.set.bits)) {\n1667:      \
      \       req.way := replacer.way(req.set.bits)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1669-1679
    context: "1669:             req.way := req.dmWay\n1670:           }\n1671:   \
      \      }\n1672:     }\n1673:   } else {\n1674:     replWayReqs.foreach {\n1675:\
      \       case req =>\n1676:         req.way := DontCare\n1677:         when(req.set.valid)
      {\n1678:           req.way := replacer.way(req.set.bits)\n1679:         }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1682-1692
    context: "1682: \n1683:   val replAccessReqs = ldu.map(_.io.replace_access) ++
      Seq(\n1684:     mainPipe.io.replace_access\n1685:   ) ++ stu.map(_.io.replace_access)\n\
      1686:   val touchWays = Seq.fill(replAccessReqs.size)(Wire(ValidIO(UInt(log2Up(nWays).W))))\n\
      1687:   touchWays.zip(replAccessReqs).foreach {\n1688:     case (w, req) =>\n\
      1689:       w.valid := req.valid\n1690:       w.bits := req.bits.way\n1691:\
      \   }\n1692:   val touchSets = replAccessReqs.map(_.bits.set)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1694-1710
    context: "1694: \n1695:   //----------------------------------------\n1696:  \
      \ // assertions\n1697:   // dcache should only deal with DRAM addresses\n1698:\
      \   import freechips.rocketchip.util._\n1699:   when (bus.a.fire) {\n1700: \
      \    assert(PmemRanges.map(_.cover(bus.a.bits.address)).reduce(_ || _))\n1701:\
      \   }\n1702:   when (bus.b.fire) {\n1703:     assert(PmemRanges.map(_.cover(bus.b.bits.address)).reduce(_
      || _))\n1704:   }\n1705:   when (bus.c.fire) {\n1706:     assert(PmemRanges.map(_.cover(bus.c.bits.address)).reduce(_
      || _))\n1707:   }\n1708: \n1709:   //----------------------------------------\n\
      1710:   // utility functions"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1708-1718
    context: "1708: \n1709:   //----------------------------------------\n1710:  \
      \ // utility functions\n1711:   def block_decoupled[T <: Data](source: DecoupledIO[T],
      sink: DecoupledIO[T], block_signal: Bool) = {\n1712:     sink.valid   := source.valid
      && !block_signal\n1713:     source.ready := sink.ready   && !block_signal\n\
      1714:     sink.bits    := source.bits\n1715:   }\n1716: \n1717:   //----------------------------------------\n\
      1718:   // performance counters"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1714-1724
    context: "1714:     sink.bits    := source.bits\n1715:   }\n1716: \n1717:   //----------------------------------------\n\
      1718:   // performance counters\n1719:   val num_loads = PopCount(ldu.map(e
      => e.io.lsu.req.fire))\n1720:   XSPerfAccumulate(\"num_loads\", num_loads)\n\
      1721: \n1722:   io.mshrFull := missQueue.io.full\n1723:   io.l1Miss := missQueue.io.l1Miss\n\
      1724: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/AbstractDataArray.scala
    lines: 40-50
    context: "40:   val data = Vec(blockRows, Bits(rowBits.W))\n41: }\n42: \n43: abstract
      class AbstractDataArray(implicit p: Parameters) extends DCacheModule {\n44:\
      \   val io = IO(new DCacheBundle {\n45:     val read = Vec(3, Flipped(DecoupledIO(new
      L1DataReadReq)))\n46:     val write = Flipped(DecoupledIO(new L1DataWriteReq))\n\
      47:     val resp = Output(Vec(3, Vec(blockRows, Bits(encRowBits.W))))\n48: \
      \    val nacks = Output(Vec(3, Bool()))\n49:     val errors = Output(Vec(3,
      ValidIO(new L1CacheErrorInfo)))\n50:   })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/AbstractDataArray.scala
    lines: 51-63
    context: "51: \n52:   def pipeMap[T <: Data](f: Int => T) = VecInit((0 until 3).map(f))\n\
      53: \n54:   def dumpRead = {\n55:     (0 until 3) map { w =>\n56:       XSDebug(io.read(w).valid,\n\
      57:         s\"DataArray Read channel: $w valid way_en: %x addr: %x\\n\",\n\
      58:         io.read(w).bits.way_en, io.read(w).bits.addr)\n59:     }\n60:  \
      \ }\n61: \n62:   def dumpWrite = {\n63:     XSDebug(io.write.valid,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/DuplicatedDataArray.scala
    lines: 42-57
    context: "42:       getECCFromEncWord(cacheParams.dataCode.encode(word))\n43:\
      \     })\n44:   }\n45: \n46:   val waddr = (io.write.bits.addr >> blockOffBits).asUInt\n\
      47:   val raddrs = io.read.map(r => (r.bits.addr >> blockOffBits).asUInt)\n\
      48:   io.write.ready := (if (readHighPriority) {\n49:     if (singlePort) {\n\
      50:       !VecInit(io.read.map(_.valid)).asUInt.orR\n51:     } else {\n52: \
      \      !(Cat(io.read.zipWithIndex.map { case (r, i) => r.valid && raddrs(i)
      === waddr }).orR)\n53:     }\n54:   } else {\n55:     true.B\n56:   })\n57: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/DuplicatedDataArray.scala
    lines: 90-100
    context: "90:     }\n91: \n92:     val half = nWays / 2\n93:     val data_read
      = data_array.map(_.io.r.resp.data(0))\n94:     val data_left = Mux1H(r_way_en_reg.tail(half),
      data_read.take(half))\n95:     val data_right = Mux1H(r_way_en_reg.head(half),
      data_read.drop(half))\n96: \n97:     val sel_low = r_way_en_reg.tail(half).orR\n\
      98:     val row_data = Mux(sel_low, data_left, data_right)\n99: \n100:     io.rdata
      := row_data"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/DuplicatedDataArray.scala
    lines: 100-119
    context: "100:     io.rdata := row_data\n101:   }\n102: \n103:   for (j <- 0 until
      3) {\n104:     val raddr = raddrs(j)\n105:     val rmask = io.read(j).bits.rmask\n\
      106: \n107:     // for single port SRAM, do not allow read and write in the
      same cycle\n108:     // for dual port SRAM, raddr === waddr is undefined behavior\n\
      109:     val rwhazard = if (singlePort) io.write.valid else io.write.valid &&
      waddr === raddr\n110:     io.read(j).ready := (if (readHighPriority) true.B
      else !rwhazard)\n111: \n112:     // use way_en to select a way after data read
      out\n113:     assert(!(RegNext(io.read(j).fire && PopCount(io.read(j).bits.way_en)
      > 1.U)))\n114:     val way_en = RegEnable(io.read(j).bits.way_en, io.read(j).fire)\n\
      115: \n116:     val row_error = Wire(Vec(blockRows, Vec(rowWords, Bool())))\n\
      117:     for (r <- 0 until blockRows) {\n118:       val ecc_array = Module(new
      SRAMTemplate(\n119:         Vec(rowWords, Bits(eccBits.W)),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/DuplicatedDataArray.scala
    lines: 129-139
    context: "129:         data = getECCFromRow(io.write.bits.data(r)),\n130:    \
      \     waymask = io.write.bits.way_en\n131:       )\n132:       XSDebug(ecc_array.io.w.req.valid,\n\
      133:         p\"write in ecc sram ${j.U} row ${r.U}: setIdx=${Hexadecimal(ecc_array.io.w.req.bits.setIdx)}
      ecc(0)=${Hexadecimal(getECCFromRow(io.write.bits.data(r))(0))} ecc(1)=${Hexadecimal(getECCFromRow(io.write.bits.data(r))(1))}
      waymask=${Hexadecimal(io.write.bits.way_en)}\\n\")\n134:       ecc_array.io.r.req.valid
      := io.read(j).valid && rmask(r)\n135:       ecc_array.io.r.req.bits.apply(setIdx
      = raddr)\n136: \n137:       val dataGroup = Module(new DataSRAMGroup)\n138:\
      \       dataGroup.io.wen := io.write.valid && io.write.bits.wmask(r)\n139: \
      \      dataGroup.io.w_way_en := io.write.bits.way_en"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/DuplicatedDataArray.scala
    lines: 137-148
    context: "137:       val dataGroup = Module(new DataSRAMGroup)\n138:       dataGroup.io.wen
      := io.write.valid && io.write.bits.wmask(r)\n139:       dataGroup.io.w_way_en
      := io.write.bits.way_en\n140:       dataGroup.io.waddr := waddr\n141:      \
      \ dataGroup.io.wdata := io.write.bits.data(r)\n142:       dataGroup.io.ren :=
      io.read(j).valid && io.read(j).bits.rmask(r)\n143:       dataGroup.io.r_way_en
      := io.read(j).bits.way_en\n144:       dataGroup.io.raddr := raddr\n145: \n146:\
      \       val ecc_resp = Wire(Vec(rowWords, Vec(nWays, Bits(eccBits.W))))\n147:\
      \       for(w <- 0 until nWays){\n148:         for(k <- 0 until rowWords){"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/DuplicatedDataArray.scala
    lines: 160-171
    context: "160:           val data = Cat(ecc_resp_chosen(k), data_resp_chosen(k))\n\
      161:           row_error(r)(k) := dcacheParameters.dataCode.decode(data).error
      && RegNext(rmask(r))\n162:           data\n163:         }\n164:       }.toSeq)\n\
      165:       io.errors(j).bits.report_to_beu := RegNext(io.read(j).fire) && Cat(row_error.flatten).orR\n\
      166:       io.errors(j).bits.paddr := RegEnable(io.read(j).bits.addr, io.read(j).fire)\n\
      167:     }\n168: \n169:     io.nacks(j) := false.B\n170:   }\n171: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 134-144
    context: "134:   io.r.data := data_sram.io.r.resp.data(0)\n135:   XSPerfAccumulate(\"\
      part_data_read_counter\", data_sram.io.r.req.valid)\n136: \n137:   def dump_r()
      = {\n138:     XSDebug(RegNext(io.r.en),\n139:       \"bank read set %x bank
      %x way %x data %x\\n\",\n140:       RegEnable(io.r.addr, io.r.en),\n141:   \
      \    bankIdx.U,\n142:       wayIdx.U,\n143:       io.r.data\n144:     )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 209-219
    context: "209: \n210:   io.r.data := data_bank.map(_.io.r.resp.data(0))\n211:\
      \ \n212:   def dump_r() = {\n213:     XSDebug(RegNext(io.r.en),\n214:      \
      \ \"bank read addr %x data %x\\n\",\n215:       RegEnable(io.r.addr, io.r.en),\n\
      216:       io.r.data.asUInt\n217:     )\n218:   }\n219: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 246-256
    context: "246: {\n247:   val DataEccParam = if(EnableDataEcc) Some(HasDataEccParam)
      else None\n248:   val ReadlinePortErrorIndex = LoadPipelineWidth\n249:   val
      io = IO(new DCacheBundle {\n250:     // load pipeline read word req\n251:  \
      \   val read = Vec(LoadPipelineWidth, Flipped(DecoupledIO(new L1BankedDataReadReqWithMask)))\n\
      252:     val is128Req = Input(Vec(LoadPipelineWidth, Bool()))\n253:     // main
      pipeline read / write line req\n254:     val readline_intend = Input(Bool())\n\
      255:     val readline = Flipped(DecoupledIO(new L1BankedDataReadLineReq))\n\
      256:     val readline_can_go = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 298-313
    context: "298:     }\n299:   }\n300: \n301:   def dumpRead = {\n302:     (0 until
      LoadPipelineWidth) map { w =>\n303:       XSDebug(io.read(w).valid,\n304:  \
      \       s\"DataArray Read channel: $w valid way_en: %x addr: %x\\n\",\n305:\
      \         io.read(w).bits.way_en, io.read(w).bits.addr)\n306:     }\n307:  \
      \   XSDebug(io.readline.valid,\n308:       s\"DataArray Read Line, valid way_en:
      %x addr: %x rmask %x\\n\",\n309:       io.readline.bits.way_en, io.readline.bits.addr,
      io.readline.bits.rmask)\n310:   }\n311: \n312:   def dumpWrite = {\n313:   \
      \  XSDebug(io.write.valid,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 340-363
    context: "340:     require(valid.length == bits.length &&  bits.length == index.length,
      s\"length must eq, valid:${valid.length}, bits:${bits.length}, index:${index.length}\"\
      )\n341:     ParallelOperation(valid zip bits zip index,\n342:       (a: ((Bool,
      LqPtr), UInt), b: ((Bool, LqPtr), UInt)) => {\n343:         val au = a._1._2\n\
      344:         val bu = b._1._2\n345:         val aValid = a._1._1\n346:     \
      \    val bValid = b._1._1\n347:         val bSel = au > bu\n348:         val
      bits = Mux(\n349:           aValid && bValid,\n350:           Mux(bSel, b._1._2,
      a._1._2),\n351:           Mux(aValid && !bValid, a._1._2, b._1._2)\n352:   \
      \      )\n353:         val idx = Mux(\n354:           aValid && bValid,\n355:\
      \           Mux(bSel, b._2, a._2),\n356:           Mux(aValid && !bValid, a._2,
      b._2)\n357:         )\n358:         ((aValid || bValid, bits), idx)\n359:  \
      \     }\n360:     )\n361:   }\n362: \n363: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 365-385
    context: "365: // the smallest access unit is sram\n366: class SramedDataArray(implicit
      p: Parameters) extends AbstractBankedDataArray {\n367:   println(\"  DCacheType:
      SramedDataArray\")\n368:   val ReduceReadlineConflict = false\n369: \n370: \
      \  io.write.ready := true.B\n371:   io.write_dup.foreach(_.ready := true.B)\n\
      372: \n373:   val data_banks = List.tabulate(DCacheSetDiv)( k => {\n374:   \
      \  val banks = List.tabulate(DCacheBanks)(i => List.tabulate(DCacheWays)(j =>
      Module(new DataSRAM(i,j))))\n375:     val mbistPl = MbistPipeline.PlaceMbistPipeline(1,
      s\"MbistPipeDataSet$k\", hasMbist)\n376:     banks\n377:   })\n378:   data_banks.map(_.map(_.map(_.dump())))\n\
      379: \n380:   val way_en = Wire(Vec(LoadPipelineWidth, io.read(0).bits.way_en.cloneType))\n\
      381:   val set_addrs = Wire(Vec(LoadPipelineWidth, UInt()))\n382:   val div_addrs
      = Wire(Vec(LoadPipelineWidth, UInt()))\n383:   val bank_addrs = Wire(Vec(LoadPipelineWidth,
      Vec(VLEN/DCacheSRAMRowBits, UInt())))\n384: \n385:   val line_set_addr = addr_to_dcache_div_set(io.readline.bits.addr)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 398-415
    context: "398: \n399:   // read data_banks and ecc_banks\n400:   // for single
      port SRAM, do not allow read and write in the same cycle\n401:   val rrhazard
      = false.B // io.readline.valid\n402:   (0 until LoadPipelineWidth).map(rport_index
      => {\n403:     div_addrs(rport_index) := addr_to_dcache_div(io.read(rport_index).bits.addr)\n\
      404:     set_addrs(rport_index) := addr_to_dcache_div_set(io.read(rport_index).bits.addr)\n\
      405:     bank_addrs(rport_index)(0) := addr_to_dcache_bank(io.read(rport_index).bits.addr)\n\
      406:     bank_addrs(rport_index)(1) := bank_addrs(rport_index)(0) + 1.U\n407:\
      \ \n408:     // use way_en to select a way after data read out\n409:     assert(!(RegNext(io.read(rport_index).fire
      && PopCount(io.read(rport_index).bits.way_en) > 1.U)))\n410:     way_en(rport_index)
      := io.read(rport_index).bits.way_en\n411:   })\n412: \n413:   // read conflict\n\
      414:   val rr_bank_conflict = Seq.tabulate(LoadPipelineWidth)(x => Seq.tabulate(LoadPipelineWidth)(y
      => {\n415:     if (x == y) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 413-432
    context: "413:   // read conflict\n414:   val rr_bank_conflict = Seq.tabulate(LoadPipelineWidth)(x
      => Seq.tabulate(LoadPipelineWidth)(y => {\n415:     if (x == y) {\n416:    \
      \   false.B\n417:     } else {\n418:       io.read(x).valid && io.read(y).valid
      &&\n419:         div_addrs(x) === div_addrs(y) &&\n420:         (io.read(x).bits.bankMask
      & io.read(y).bits.bankMask) =/= 0.U &&\n421:         io.read(x).bits.way_en
      === io.read(y).bits.way_en &&\n422:         set_addrs(x) =/= set_addrs(y)\n\
      423:     }\n424:   }))\n425:   val load_req_with_bank_conflict = rr_bank_conflict.map(_.reduce(_
      || _))\n426:   val load_req_valid = io.read.map(_.valid)\n427:   val load_req_lqIdx
      = io.read.map(_.bits.lqIdx)\n428:   val load_req_index = (0 until LoadPipelineWidth).map(_.asUInt)\n\
      429: \n430: \n431:   val load_req_bank_conflict_selcet = selcetOldestPort(load_req_with_bank_conflict,
      load_req_lqIdx, load_req_index)\n432:   val load_req_bank_select_port  = UIntToOH(load_req_bank_conflict_selcet._2).asBools"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 435-464
    context: "435:     !load_req_bank_select_port(i) && load_req_with_bank_conflict(i)\n\
      436:   )\n437: \n438:   val rrl_bank_conflict = Wire(Vec(LoadPipelineWidth,
      Bool()))\n439:   val rrl_bank_conflict_intend = Wire(Vec(LoadPipelineWidth,
      Bool()))\n440:   (0 until LoadPipelineWidth).foreach { i =>\n441:     val judge
      = if (ReduceReadlineConflict) io.read(i).valid && (io.readline.bits.rmask &
      io.read(i).bits.bankMask) =/= 0.U && line_div_addr === div_addrs(i) && line_set_addr
      =/= set_addrs(i)\n442:                 else io.read(i).valid && line_div_addr
      === div_addrs(i) && line_set_addr =/= set_addrs(i)\n443:     rrl_bank_conflict(i)
      := judge && io.readline.valid\n444:     rrl_bank_conflict_intend(i) := judge
      && io.readline_intend\n445:   }\n446:   val wr_bank_conflict = Seq.tabulate(LoadPipelineWidth)(x
      =>\n447:     io.read(x).valid && write_valid_reg &&\n448:     div_addrs(x) ===
      write_div_addr_dup_reg.head &&\n449:     way_en(x) === write_wayen_dup_reg.head
      &&\n450:     (write_bank_mask_reg(bank_addrs(x)(0)) || write_bank_mask_reg(bank_addrs(x)(1))
      && io.is128Req(x))\n451:   )\n452:   val wrl_bank_conflict = io.readline.valid
      && write_valid_reg && line_div_addr === write_div_addr_dup_reg.head\n453:  \
      \ // ready\n454:   io.readline.ready := !(wrl_bank_conflict)\n455:   io.read.zipWithIndex.map
      { case (x, i) => x.ready := !(wr_bank_conflict(i) || rrhazard) }\n456: \n457:\
      \   val perf_multi_read = PopCount(io.read.map(_.valid)) >= 2.U\n458:   val
      bank_conflict_fast = Wire(Vec(LoadPipelineWidth, Bool()))\n459:   (0 until LoadPipelineWidth).foreach(i
      => {\n460:     bank_conflict_fast(i) := wr_bank_conflict(i) || rrl_bank_conflict(i)
      ||\n461:     rr_bank_conflict_oldest(i)\n462:     io.bank_conflict_slow(i) :=
      RegNext(bank_conflict_fast(i))\n463:     io.disable_ld_fast_wakeup(i) := wr_bank_conflict(i)
      || rrl_bank_conflict_intend(i) ||\n464:       (if (i == 0) 0.B else (0 until
      i).map(rr_bank_conflict(_)(i)).reduce(_ || _))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 462-480
    context: "462:     io.bank_conflict_slow(i) := RegNext(bank_conflict_fast(i))\n\
      463:     io.disable_ld_fast_wakeup(i) := wr_bank_conflict(i) || rrl_bank_conflict_intend(i)
      ||\n464:       (if (i == 0) 0.B else (0 until i).map(rr_bank_conflict(_)(i)).reduce(_
      || _))\n465:   })\n466:   XSPerfAccumulate(\"data_array_multi_read\", perf_multi_read)\n\
      467:   (1 until LoadPipelineWidth).foreach(y => (0 until y).foreach(x =>\n468:\
      \     XSPerfAccumulate(s\"data_array_rr_bank_conflict_${x}_${y}\", rr_bank_conflict(x)(y))\n\
      469:   ))\n470:   (0 until LoadPipelineWidth).foreach(i => {\n471:     XSPerfAccumulate(s\"\
      data_array_rrl_bank_conflict_${i}\", rrl_bank_conflict(i))\n472:     XSPerfAccumulate(s\"\
      data_array_rw_bank_conflict_${i}\", wr_bank_conflict(i))\n473:     XSPerfAccumulate(s\"\
      data_array_read_${i}\", io.read(i).valid)\n474:   })\n475:   XSPerfAccumulate(\"\
      data_array_access_total\", PopCount(io.read.map(_.valid)))\n476:   XSPerfAccumulate(\"\
      data_array_read_line\", io.readline.valid)\n477:   XSPerfAccumulate(\"data_array_write\"\
      , io.write.valid)\n478: \n479:   val read_result = Wire(Vec(DCacheSetDiv, Vec(DCacheBanks,
      Vec(DCacheWays,new L1BankedDataReadResult()))))\n480:   val read_result_delayed
      = Wire(Vec(DCacheSetDiv, Vec(DCacheBanks, Vec(DCacheWays,new L1BankedDataReadResult()))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 484-502
    context: "484: \n485:   val pseudo_data_toggle_mask = io.pseudo_error.bits.map
      {\n486:     case bank =>\n487:       Mux(io.pseudo_error.valid && bank.valid,
      bank.mask, 0.U)\n488:   }\n489:   val readline_hit = io.readline.fire &&\n490:\
      \                      (io.readline.bits.rmask & VecInit(io.pseudo_error.bits.map(_.valid)).asUInt).orR\n\
      491:   val readbank_hit = io.read.zip(bank_addrs.zip(io.is128Req)).zipWithIndex.map
      {\n492:                           case ((read, (bank_addr, is128Req)), i) =>\n\
      493:                             val error_bank0 = io.pseudo_error.bits(bank_addr(0))\n\
      494:                             val error_bank1 = io.pseudo_error.bits(bank_addr(1))\n\
      495:                             read.fire && (error_bank0.valid || error_bank1.valid
      && is128Req) && !io.bank_conflict_slow(i)\n496:                       }.reduce(_|_)\n\
      497:   io.pseudo_error.ready := RegNext(readline_hit || readbank_hit)\n498:\
      \ \n499:   for (div_index <- 0 until DCacheSetDiv){\n500:     for (bank_index
      <- 0 until DCacheBanks) {\n501:       for (way_index <- 0 until DCacheWays)
      {\n502:         //     Set Addr & Read Way Mask"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 511-521
    context: "511:         //              |\n512:         //     +--------+--------+\n\
      513:         //     |    Data Bank    |\n514:         //     +-----------------+\n\
      515:         val loadpipe_en = WireInit(VecInit(List.tabulate(LoadPipelineWidth)(i
      => {\n516:           io.read(i).valid && div_addrs(i) === div_index.U && (bank_addrs(i)(0)
      === bank_index.U || bank_addrs(i)(1) === bank_index.U && io.is128Req(i)) &&\n\
      517:           way_en(i)(way_index) &&\n518:           !rr_bank_conflict_oldest(i)\n\
      519:         })))\n520:         val readline_en = Wire(Bool())\n521:       \
      \  if (ReduceReadlineConflict) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 525-538
    context: "525:         }\n526:         val sram_set_addr = Mux(readline_en,\n\
      527:           addr_to_dcache_div_set(io.readline.bits.addr),\n528:        \
      \   PriorityMux(Seq.tabulate(LoadPipelineWidth)(i => loadpipe_en(i) -> set_addrs(i)))\n\
      529:         )\n530:         val read_en = loadpipe_en.asUInt.orR || readline_en\n\
      531:         // read raw data\n532:         val data_bank = data_banks(div_index)(bank_index)(way_index)\n\
      533:         data_bank.io.r.en := read_en\n534:         data_bank.io.r.addr
      := sram_set_addr\n535: \n536:         read_result(div_index)(bank_index)(way_index).ecc
      := getECCFromEncWord(data_bank.io.r.data)\n537:         read_result(div_index)(bank_index)(way_index).raw_data
      := getDataFromEncWord(data_bank.io.r.data) ^ pseudo_data_toggle_mask(bank_index)\n\
      538: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 536-546
    context: "536:         read_result(div_index)(bank_index)(way_index).ecc := getECCFromEncWord(data_bank.io.r.data)\n\
      537:         read_result(div_index)(bank_index)(way_index).raw_data := getDataFromEncWord(data_bank.io.r.data)
      ^ pseudo_data_toggle_mask(bank_index)\n538: \n539:         if (EnableDataEcc)
      {\n540:           val ecc_data = read_result(div_index)(bank_index)(way_index).asECCData()\n\
      541:           val ecc_data_delayed = RegEnable(ecc_data, RegNext(read_en))\n\
      542:           read_result(div_index)(bank_index)(way_index).error_delayed :=
      dcacheParameters.dataCode.decode(ecc_data_delayed).error\n543:           read_error_delayed_result(div_index)(bank_index)(way_index)
      := read_result(div_index)(bank_index)(way_index).error_delayed\n544:       \
      \  } else {\n545:           read_result(div_index)(bank_index)(way_index).error_delayed
      := false.B\n546:           read_error_delayed_result(div_index)(bank_index)(way_index)
      := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 544-554
    context: "544:         } else {\n545:           read_result(div_index)(bank_index)(way_index).error_delayed
      := false.B\n546:           read_error_delayed_result(div_index)(bank_index)(way_index)
      := false.B\n547:         }\n548: \n549:         read_result_delayed(div_index)(bank_index)(way_index)
      := RegEnable(read_result(div_index)(bank_index)(way_index), RegNext(read_en))\n\
      550:       }\n551:     }\n552:   }\n553: \n554:   val data_read_oh = WireInit(VecInit(Seq.fill(DCacheSetDiv
      * DCacheBanks * DCacheWays)(0.U(1.W))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 563-580
    context: "563: \n564:   // read result: expose banked read result\n565:   // TODO:
      clock gate\n566:   (0 until LoadPipelineWidth).map(i => {\n567:     // io.read_resp(i)
      := read_result(RegNext(bank_addrs(i)))(RegNext(OHToUInt(way_en(i))))\n568: \
      \    val r_read_fire = RegNext(io.read(i).fire)\n569:     val r_div_addr  =
      RegEnable(div_addrs(i), io.read(i).fire)\n570:     val r_bank_addr = RegEnable(bank_addrs(i),
      io.read(i).fire)\n571:     val r_way_addr  = RegNext(OHToUInt(way_en(i)))\n\
      572:     val rr_read_fire = RegNext(RegNext(io.read(i).fire))\n573:     val
      rr_div_addr = RegEnable(RegEnable(div_addrs(i), io.read(i).fire), r_read_fire)\n\
      574:     val rr_bank_addr = RegEnable(RegEnable(bank_addrs(i), io.read(i).fire),
      r_read_fire)\n575:     val rr_way_addr = RegEnable(RegEnable(OHToUInt(way_en(i)),
      io.read(i).fire), r_read_fire)\n576:     (0 until VLEN/DCacheSRAMRowBits).map(
      j =>{\n577:       io.read_resp(i)(j) := read_result(r_div_addr)(r_bank_addr(j))(r_way_addr)\n\
      578:       // error detection\n579:       // normal read ports\n580:       io.read_error_delayed(i)(j)
      := rr_read_fire && read_error_delayed_result(rr_div_addr)(rr_bank_addr(j))(rr_way_addr)
      && !RegNext(io.bank_conflict_slow(i))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 589-600
    context: "589:   val readline_rr_div_addr = RegEnable(readline_r_div_addr, RegNext(io.readline.valid))\n\
      590:   (0 until DCacheBanks).map(i => {\n591:     io.readline_resp(i) := read_result(readline_r_div_addr)(i)(readline_r_way_addr)\n\
      592:     readline_error_delayed(i) := read_result(readline_rr_div_addr)(i)(readline_rr_way_addr).error_delayed\n\
      593:   })\n594:   io.readline_error := RegNext(RegNext(io.readline.fire)) &&
      readline_error_delayed.asUInt.orR\n595:   io.readline_error_delayed := RegNext(RegNext(io.readline.fire))
      && readline_error_delayed.asUInt.orR\n596: \n597:   // write data_banks & ecc_banks\n\
      598:   for (div_index <- 0 until DCacheSetDiv) {\n599:     for (bank_index <-
      0 until DCacheBanks) {\n600:       for (way_index <- 0 until DCacheWays) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 616-626
    context: "616:   val siteName = \"BankedDataArray\" + p(XSCoreParamsKey).HartId.toString\n\
      617:   val bankConflictTable = ChiselDB.createTable(tableName, new BankConflictDB)\n\
      618:   val bankConflictData = Wire(new BankConflictDB)\n619:   for (i <- 0 until
      LoadPipelineWidth) {\n620:     bankConflictData.set_index(i) := set_addrs(i)\n\
      621:     bankConflictData.addr(i) := io.read(i).bits.addr\n622:   }\n623: \n\
      624:   // FIXME: rr_bank_conflict(0)(1) no generalization\n625:   when(rr_bank_conflict(0)(1))
      {\n626:     (0 until (VLEN/DCacheSRAMRowBits)).map(i => {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 643-653
    context: "643:     site = siteName,\n644:     clock = clock,\n645:     reset =
      reset\n646:   )\n647: \n648:   (1 until LoadPipelineWidth).foreach(y => (0 until
      y).foreach(x =>\n649:     XSPerfAccumulate(s\"data_array_fake_rr_bank_conflict_${x}_${y}\"\
      , rr_bank_conflict(x)(y) && set_addrs(x)===set_addrs(y) && div_addrs(x) ===
      div_addrs(y))\n650:   ))\n651: \n652:   if (backendParams.debugEn){\n653:  \
      \   load_req_with_bank_conflict.map(dontTouch(_))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 659-670
    context: "659: // the smallest access unit is bank\n660: class BankedDataArray(implicit
      p: Parameters) extends AbstractBankedDataArray {\n661:   println(\"  DCacheType:
      BankedDataArray\")\n662:   val ReduceReadlineConflict = false\n663: \n664: \
      \  io.write.ready := true.B\n665:   io.write_dup.foreach(_.ready := true.B)\n\
      666: \n667:   val data_banks = Seq.tabulate(DCacheSetDiv, DCacheBanks)({(k,
      i) => Module(new DataSRAMBank(i))})\n668:   val mbistPl = MbistPipeline.PlaceMbistPipeline(1,
      s\"MbistPipeDCacheData\", hasMbist)\n669:   val mbistSramPorts = mbistPl.map(pl
      => Seq.tabulate(DCacheSetDiv, DCacheBanks, DCacheWays) ({ (i, j, k) =>\n670:\
      \     pl.toSRAM(i * DCacheBanks * DCacheWays + j * DCacheWays + k)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 675-685
    context: "675:   private val mbist_r_div = OHToUInt(mbistSramPorts.map(_.map(d
      => Cat(d.flatMap(w => w.map(_.re))).orR)).getOrElse(Seq.fill(DCacheSetDiv)(false.B)))\n\
      676:   private val mbist_ack = mbistPl.map(_.mbist.ack).getOrElse(false.B)\n\
      677: \n678:   data_banks.map(_.map(_.dump()))\n679: \n680:   val way_en = Wire(Vec(LoadPipelineWidth,
      io.read(0).bits.way_en.cloneType))\n681:   val set_addrs = Wire(Vec(LoadPipelineWidth,
      UInt()))\n682:   val set_addrs_dup = Wire(Vec(LoadPipelineWidth, UInt()))\n\
      683:   val div_addrs = Wire(Vec(LoadPipelineWidth, UInt()))\n684:   val div_addrs_dup
      = Wire(Vec(LoadPipelineWidth, UInt()))\n685:   val bank_addrs = Wire(Vec(LoadPipelineWidth,
      Vec(VLEN/DCacheSRAMRowBits, UInt())))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 682-692
    context: "682:   val set_addrs_dup = Wire(Vec(LoadPipelineWidth, UInt()))\n683:\
      \   val div_addrs = Wire(Vec(LoadPipelineWidth, UInt()))\n684:   val div_addrs_dup
      = Wire(Vec(LoadPipelineWidth, UInt()))\n685:   val bank_addrs = Wire(Vec(LoadPipelineWidth,
      Vec(VLEN/DCacheSRAMRowBits, UInt())))\n686:   val bank_addrs_dup = Wire(Vec(LoadPipelineWidth,
      Vec(VLEN/DCacheSRAMRowBits, UInt())))\n687:   val way_en_reg = Wire(Vec(LoadPipelineWidth,
      io.read(0).bits.way_en.cloneType))\n688:   val set_addrs_reg = Wire(Vec(LoadPipelineWidth,
      UInt()))\n689:   val set_addrs_dup_reg = Wire(Vec(LoadPipelineWidth, UInt()))\n\
      690: \n691:   val line_set_addr = addr_to_dcache_div_set(io.readline.bits.addr)\n\
      692:   val line_div_addr = addr_to_dcache_div(io.readline.bits.addr)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 703-727
    context: "703:   // read data_banks and ecc_banks\n704:   // for single port SRAM,
      do not allow read and write in the same cycle\n705:   val rwhazard = RegNext(io.write.valid)\n\
      706:   val rrhazard = false.B // io.readline.valid\n707:   (0 until LoadPipelineWidth).map(rport_index
      => {\n708:     div_addrs(rport_index) := addr_to_dcache_div(io.read(rport_index).bits.addr)\n\
      709:     div_addrs_dup(rport_index) := addr_to_dcache_div(io.read(rport_index).bits.addr_dup)\n\
      710:     bank_addrs(rport_index)(0) := addr_to_dcache_bank(io.read(rport_index).bits.addr)\n\
      711:     bank_addrs(rport_index)(1) := Mux(io.is128Req(rport_index), bank_addrs(rport_index)(0)
      + 1.U, bank_addrs(rport_index)(0))\n712:     bank_addrs_dup(rport_index)(0)
      := addr_to_dcache_bank(io.read(rport_index).bits.addr_dup)\n713:     bank_addrs_dup(rport_index)(1)
      := Mux(io.is128Req(rport_index), bank_addrs_dup(rport_index)(0) + 1.U, bank_addrs_dup(rport_index)(0))\n\
      714:     set_addrs(rport_index) := addr_to_dcache_div_set(io.read(rport_index).bits.addr)\n\
      715:     set_addrs_dup(rport_index) := addr_to_dcache_div_set(io.read(rport_index).bits.addr_dup)\n\
      716:     set_addrs_reg(rport_index) := RegEnable(addr_to_dcache_div_set(io.read(rport_index).bits.addr),
      io.read(rport_index).valid)\n717:     set_addrs_dup_reg(rport_index) := RegEnable(addr_to_dcache_div_set(io.read(rport_index).bits.addr_dup),
      io.read(rport_index).valid)\n718: \n719:     // use way_en to select a way after
      data read out\n720:     assert(!(RegNext(io.read(rport_index).fire && PopCount(io.read(rport_index).bits.way_en)
      > 1.U)))\n721:     way_en(rport_index) := io.read(rport_index).bits.way_en\n\
      722:     way_en_reg(rport_index) := RegEnable(io.read(rport_index).bits.way_en,
      io.read(rport_index).valid)\n723:   })\n724: \n725:   // read each bank, get
      bank result\n726:   val rr_bank_conflict = Seq.tabulate(LoadPipelineWidth)(x
      => Seq.tabulate(LoadPipelineWidth)(y => {\n727:     if (x == y) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 725-737
    context: "725:   // read each bank, get bank result\n726:   val rr_bank_conflict
      = Seq.tabulate(LoadPipelineWidth)(x => Seq.tabulate(LoadPipelineWidth)(y =>
      {\n727:     if (x == y) {\n728:       false.B\n729:     } else {\n730:     \
      \  io.read(x).valid && io.read(y).valid &&\n731:       div_addrs(x) === div_addrs(y)
      &&\n732:       (io.read(x).bits.bankMask & io.read(y).bits.bankMask) =/= 0.U
      &&\n733:       set_addrs(x) =/= set_addrs(y)\n734:     }\n735:   }\n736:   ))\n\
      737: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 734-745
    context: "734:     }\n735:   }\n736:   ))\n737: \n738:   val load_req_with_bank_conflict
      = rr_bank_conflict.map(_.reduce(_ || _))\n739:   val load_req_valid = io.read.map(_.valid)\n\
      740:   val load_req_lqIdx = io.read.map(_.bits.lqIdx)\n741:   val load_req_index
      = (0 until LoadPipelineWidth).map(_.asUInt)\n742: \n743:   val load_req_bank_conflict_selcet
      = selcetOldestPort(load_req_with_bank_conflict, load_req_lqIdx, load_req_index)\n\
      744:   val load_req_bank_select_port  = UIntToOH(load_req_bank_conflict_selcet._2).asBools\n\
      745: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 747-775
    context: "747:     !load_req_bank_select_port(i) && load_req_with_bank_conflict(i)\n\
      748:   )\n749: \n750:   val rrl_bank_conflict = Wire(Vec(LoadPipelineWidth,
      Bool()))\n751:   val rrl_bank_conflict_intend = Wire(Vec(LoadPipelineWidth,
      Bool()))\n752:   (0 until LoadPipelineWidth).foreach { i =>\n753:     val judge
      = if (ReduceReadlineConflict) io.read(i).valid && (io.readline.bits.rmask &
      io.read(i).bits.bankMask) =/= 0.U && div_addrs(i) === line_div_addr\n754:  \
      \               else io.read(i).valid && div_addrs(i)===line_div_addr\n755:\
      \     rrl_bank_conflict(i) := judge && io.readline.valid\n756:     rrl_bank_conflict_intend(i)
      := judge && io.readline_intend\n757:   }\n758:   val wr_bank_conflict = Seq.tabulate(LoadPipelineWidth)(x
      =>\n759:     io.read(x).valid &&\n760:     write_valid_reg &&\n761:     div_addrs(x)
      === write_div_addr_dup_reg.head &&\n762:     (write_bank_mask_reg(bank_addrs(x)(0))
      || write_bank_mask_reg(bank_addrs(x)(1)) && io.is128Req(x))\n763:   )\n764:\
      \   val wrl_bank_conflict = io.readline.valid && write_valid_reg && line_div_addr
      === write_div_addr_dup_reg.head\n765:   // ready\n766:   io.readline.ready :=
      !(wrl_bank_conflict)\n767:   io.read.zipWithIndex.map{case(x, i) => x.ready
      := !(wr_bank_conflict(i) || rrhazard)}\n768: \n769:   val perf_multi_read =
      PopCount(io.read.map(_.valid)) >= 2.U\n770:   (0 until LoadPipelineWidth).foreach(i
      => {\n771:     // remove fake rr_bank_conflict situation in s2\n772:     val
      real_other_bank_conflict_reg = RegNext(wr_bank_conflict(i) || rrl_bank_conflict(i))\n\
      773:     val real_rr_bank_conflict_reg = RegNext(rr_bank_conflict_oldest(i))\n\
      774:     io.bank_conflict_slow(i) := real_other_bank_conflict_reg || real_rr_bank_conflict_reg\n\
      775: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 776-794
    context: "776:     // get result in s1\n777:     io.disable_ld_fast_wakeup(i)
      := wr_bank_conflict(i) || rrl_bank_conflict_intend(i) ||\n778:       (if (i
      == 0) 0.B else (0 until i).map(rr_bank_conflict(_)(i)).reduce(_ || _))\n779:\
      \   })\n780:   XSPerfAccumulate(\"data_array_multi_read\", perf_multi_read)\n\
      781:   (1 until LoadPipelineWidth).foreach(y => (0 until y).foreach(x =>\n782:\
      \     XSPerfAccumulate(s\"data_array_rr_bank_conflict_${x}_${y}\", rr_bank_conflict(x)(y))\n\
      783:   ))\n784:   (0 until LoadPipelineWidth).foreach(i => {\n785:     XSPerfAccumulate(s\"\
      data_array_rrl_bank_conflict_${i}\", rrl_bank_conflict(i))\n786:     XSPerfAccumulate(s\"\
      data_array_rw_bank_conflict_${i}\", wr_bank_conflict(i))\n787:     XSPerfAccumulate(s\"\
      data_array_read_${i}\", io.read(i).valid)\n788:   })\n789:   XSPerfAccumulate(\"\
      data_array_access_total\", PopCount(io.read.map(_.valid)))\n790:   XSPerfAccumulate(\"\
      data_array_read_line\", io.readline.valid)\n791:   XSPerfAccumulate(\"data_array_write\"\
      , io.write.valid)\n792: \n793:   val bank_result = Wire(Vec(DCacheSetDiv, Vec(DCacheBanks,
      Vec(DCacheWays, new L1BankedDataReadResult()))))\n794:   val bank_result_delayed
      = Wire(Vec(DCacheSetDiv, Vec(DCacheBanks, Vec(DCacheWays, new L1BankedDataReadResult()))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 796-814
    context: "796: \n797:   val pseudo_data_toggle_mask = io.pseudo_error.bits.map
      {\n798:     case bank =>\n799:       Mux(io.pseudo_error.valid && bank.valid,
      bank.mask, 0.U)\n800:   }\n801:   val readline_hit = io.readline.fire &&\n802:\
      \                      (io.readline.bits.rmask & VecInit(io.pseudo_error.bits.map(_.valid)).asUInt).orR\n\
      803:   val readbank_hit = io.read.zip(bank_addrs.zip(io.is128Req)).zipWithIndex.map
      {\n804:                           case ((read, (bank_addr, is128Req)), i) =>\n\
      805:                             val error_bank0 = io.pseudo_error.bits(bank_addr(0))\n\
      806:                             val error_bank1 = io.pseudo_error.bits(bank_addr(1))\n\
      807:                             read.fire && (error_bank0.valid || error_bank1.valid
      && is128Req) && !io.bank_conflict_slow(i)\n808:                       }.reduce(_|_)\n\
      809:   io.pseudo_error.ready := RegNext(readline_hit || readbank_hit)\n810:\
      \ \n811:   for (div_index <- 0 until DCacheSetDiv) {\n812:     for (bank_index
      <- 0 until DCacheBanks) {\n813:       //     Set Addr & Read Way Mask\n814:\
      \       //"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 822-836
    context: "822:       //              |\n823:       //     +--------+--------+\n\
      824:       //     |    Data Bank    |\n825:       //     +-----------------+\n\
      826:       val bank_addr_matchs = WireInit(VecInit(List.tabulate(LoadPipelineWidth)(i
      => {\n827:         io.read(i).valid && div_addrs(i) === div_index.U && (bank_addrs(i)(0)
      === bank_index.U || bank_addrs(i)(1) === bank_index.U && io.is128Req(i)) &&\n\
      828:           !rr_bank_conflict_oldest(i)\n829:       })))\n830:       val
      bank_addr_matchs_dup = WireInit(VecInit(List.tabulate(LoadPipelineWidth)(i =>
      {\n831:         io.read(i).valid && div_addrs_dup(i) === div_index.U && (bank_addrs_dup(i)(0)
      === bank_index.U || bank_addrs_dup(i)(1) === bank_index.U && io.is128Req(i))
      &&\n832:           !rr_bank_conflict_oldest(i)\n833:       })))\n834:      \
      \ val readline_match = Wire(Bool())\n835:       if (ReduceReadlineConflict)
      {\n836:         readline_match := io.readline.valid && io.readline.bits.rmask(bank_index)
      && line_div_addr === div_index.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 886-904
    context: "886:   }\n887:   XSPerfAccumulate(\"data_read_counter\", data_read_oh.foldLeft(0.U)(_
      + _))\n888: \n889:   (0 until LoadPipelineWidth).map(i => {\n890:     // 1 cycle
      after read fire(load s2)\n891:     val r_read_fire = RegNext(io.read(i).fire)\n\
      892:     val r_div_addr = RegEnable(div_addrs(i), io.read(i).fire)\n893:   \
      \  val r_bank_addr = RegEnable(bank_addrs(i), io.read(i).fire)\n894:     val
      r_way_addr = RegEnable(OHToUInt(way_en(i)), io.read(i).fire)\n895:     // 2
      cycles after read fire(load s3)\n896:     val rr_read_fire = RegNext(r_read_fire)\n\
      897:     val rr_div_addr = RegEnable(RegEnable(div_addrs(i), io.read(i).fire),
      r_read_fire)\n898:     val rr_bank_addr = RegEnable(RegEnable(bank_addrs(i),
      io.read(i).fire), r_read_fire)\n899:     val rr_way_addr = RegEnable(RegEnable(OHToUInt(way_en(i)),
      io.read(i).fire), r_read_fire)\n900:     (0 until VLEN/DCacheSRAMRowBits).map(
      j =>{\n901:       io.read_resp(i)(j)          := bank_result(r_div_addr)(r_bank_addr(j))(r_way_addr)\n\
      902:       // error detection\n903:       io.read_error_delayed(i)(j) := rr_read_fire
      && read_bank_error_delayed(rr_div_addr)(rr_bank_addr(j))(rr_way_addr) && !RegNext(io.bank_conflict_slow(i))\n\
      904:     })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 904-920
    context: "904:     })\n905:   })\n906: \n907:   val readline_error = Wire(Vec(DCacheBanks,
      Bool()))\n908:   val readline_error_delayed = Wire(Vec(DCacheBanks, Bool()))\n\
      909:   val readline_r_way_addr = RegEnable(Mux(mbist_ack, mbist_r_way, OHToUInt(io.readline.bits.way_en)),
      io.readline.fire | mbist_ack)\n910:   val readline_rr_way_addr = RegEnable(readline_r_way_addr,
      RegNext(io.readline.fire))\n911:   val readline_r_div_addr = RegEnable(Mux(mbist_ack,
      mbist_r_div, line_div_addr), io.readline.fire | mbist_ack)\n912:   val readline_rr_div_addr
      = RegEnable(readline_r_div_addr, RegNext(io.readline.fire))\n913:   val readline_resp
      = Wire(io.readline_resp.cloneType)\n914:   (0 until DCacheBanks).foreach(i =>
      {\n915:     mbistSramPorts.foreach(_.foreach(_(i).foreach(_.rdata := Cat(io.readline_resp(i).ecc,
      io.readline_resp(i).raw_data))))\n916:     readline_resp(i) := Mux(\n917:  \
      \     io.readline_can_go | mbist_ack,\n918:       bank_result(readline_r_div_addr)(i)(readline_r_way_addr),\n\
      919:       RegEnable(readline_resp(i), io.readline_stall | mbist_ack)\n920:\
      \     )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 953-963
    context: "953:   val siteName = \"BankedDataArray\" + p(XSCoreParamsKey).HartId.toString\n\
      954:   val bankConflictTable = ChiselDB.createTable(tableName, new BankConflictDB)\n\
      955:   val bankConflictData = Wire(new BankConflictDB)\n956:   for (i <- 0 until
      LoadPipelineWidth) {\n957:     bankConflictData.set_index(i) := set_addrs(i)\n\
      958:     bankConflictData.addr(i) := io.read(i).bits.addr\n959:   }\n960: \n\
      961:   // FIXME: rr_bank_conflict(0)(1) no generalization\n962:   when(rr_bank_conflict(0)(1))
      {\n963:     (0 until (VLEN/DCacheSRAMRowBits)).map(i => {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/data/BankedDataArray.scala
    lines: 980-990
    context: "980:     site = siteName,\n981:     clock = clock,\n982:     reset =
      reset\n983:   )\n984: \n985:   (1 until LoadPipelineWidth).foreach(y => (0 until
      y).foreach(x =>\n986:     XSPerfAccumulate(s\"data_array_fake_rr_bank_conflict_${x}_${y}\"\
      , rr_bank_conflict(x)(y) && set_addrs(x) === set_addrs(y) && div_addrs(x) ===
      div_addrs(y))\n987:   ))\n988: \n989:   if (backendParams.debugEn){\n990:  \
      \   load_req_with_bank_conflict.map(dontTouch(_))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 117-127
    context: "117:     r.id := eid\n118:     r.nderr := resp_nderr\n119:     r.nc
      := nc\n120:     r.is2lq := cmd === MemoryOpConstants.M_XRD\n121:     r.miss
      := false.B\n122:     r.replay := false.B\n123:     r.tag_error := false.B\n\
      124:     r.error := false.B\n125:     r\n126:   }\n127: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 148-158
    context: "148:   def can2Lsq(): Bool = valid && waitReturn\n149:   def canMerge():
      Bool = valid && !inflight\n150:   def isFwdOld(): Bool = valid && (inflight
      || waitReturn)\n151:   def isFwdNew(): Bool = valid && !inflight && !waitReturn\n\
      152: \n153:   def setValid(x: Bool): Unit = { valid := x}\n154:   def setInflight(x:
      Bool): Unit = { inflight := x}\n155:   def setWaitReturn(x: Bool): Unit = {
      waitReturn := x }\n156:   def setWaitSame(x: Bool): Unit = { waitSame := x}\n\
      157: \n158:   def updateUncacheResp(): Unit = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 169-181
    context: "169: }\n170: \n171: class UncacheIO(implicit p: Parameters) extends
      DCacheBundle {\n172:   val hartId = Input(UInt())\n173:   val enableOutstanding
      = Input(Bool())\n174:   val flush = Flipped(new UncacheFlushBundle)\n175:  \
      \ val lsq = Flipped(new UncacheWordIO)\n176:   val forward = Vec(LoadPipelineWidth,
      Flipped(new LoadForwardQueryIO))\n177:   val wfi = Flipped(new WfiReqBundle)\n\
      178:   val busError = Output(new L1BusErrorUnitInfo())\n179: }\n180: \n181:
      // convert DCacheIO to TileLink"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 205-215
    context: "205:   with HasPerfEvents\n206: {\n207:   println(s\"Uncahe Buffer Size:
      $UncacheBufferSize entries\")\n208:   val io = IO(new UncacheIO)\n209: \n210:\
      \   val (bus, edge) = outer.clientNode.out.head\n211: \n212:   val req  = io.lsq.req\n\
      213:   val resp = io.lsq.resp\n214:   val mem_acquire = bus.a\n215:   val mem_grant\
      \   = bus.d"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 211-230
    context: "211: \n212:   val req  = io.lsq.req\n213:   val resp = io.lsq.resp\n\
      214:   val mem_acquire = bus.a\n215:   val mem_grant   = bus.d\n216:   val req_ready
      = WireInit(false.B)\n217: \n218:   // assign default values to output signals\n\
      219:   bus.b.ready := false.B\n220:   bus.c.valid := false.B\n221:   bus.c.bits\
      \  := DontCare\n222:   bus.d.ready := false.B\n223:   bus.e.valid := false.B\n\
      224:   bus.e.bits  := DontCare\n225:   io.lsq.req.ready := req_ready\n226: \
      \  io.lsq.resp.valid := false.B\n227:   io.lsq.resp.bits := DontCare\n228: \n\
      229: \n230:   /******************************************************************"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 230-242
    context: "230:   /******************************************************************\n\
      231:    * Data Structure\n232:    ******************************************************************/\n\
      233: \n234:   val entries = Reg(Vec(UncacheBufferSize, new UncacheEntry))\n\
      235:   val states = RegInit(VecInit(Seq.fill(UncacheBufferSize)(0.U.asTypeOf(new
      UncacheEntryState))))\n236:   val s_idle :: s_inflight :: s_wait_return :: Nil
      = Enum(3)\n237:   val uState = RegInit(s_idle)\n238:   val noPending = RegInit(VecInit(Seq.fill(UncacheBufferSize)(true.B)))\n\
      239: \n240:   // drain buffer\n241:   val empty = Wire(Bool())\n242:   val f1_needDrain
      = Wire(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 239-249
    context: "239: \n240:   // drain buffer\n241:   val empty = Wire(Bool())\n242:\
      \   val f1_needDrain = Wire(Bool())\n243:   val do_uarch_drain = RegInit(false.B)\n\
      244:   when((f1_needDrain || io.flush.valid) && !empty){\n245:     do_uarch_drain
      := true.B\n246:   }.elsewhen(empty){\n247:     do_uarch_drain := false.B\n248:\
      \   }.otherwise{\n249:     do_uarch_drain := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 284-299
    context: "284:     getBlockAddr(x.vaddr) === getBlockAddr(e.vaddr) &&\n285:  \
      \     x.cmd === e.cmd && x.nc && e.nc &&\n286:       x.memBackTypeMM === e.memBackTypeMM
      &&\n287:       continueAndAlign(x.mask | e.mask) &&\n288:     // not receiving
      uncache response, not waitReturn -> no wake-up signal in these cases\n289: \
      \      !(mem_grant.fire && mem_grant.bits.source === eid || states(eid).isWaitReturn())\n\
      290:   }\n291: \n292:   def canMergeSecondary(eid: UInt): Bool = {\n293:   \
      \  // old entry is not inflight and senting\n294:     states(eid).canMerge()
      && !(q0_canSent && q0_canSentIdx === eid)\n295:   }\n296: \n297:   /******************************************************************\n\
      298:    * uState for non-outstanding\n299:    ******************************************************************/"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 296-319
    context: "296: \n297:   /******************************************************************\n\
      298:    * uState for non-outstanding\n299:    ******************************************************************/\n\
      300: \n301:   switch(uState){\n302:     is(s_idle){\n303:       when(mem_acquire.fire){\n\
      304:         uState := s_inflight\n305:       }\n306:     }\n307:     is(s_inflight){\n\
      308:       when(mem_grant.fire){\n309:         uState := s_wait_return\n310:\
      \       }\n311:     }\n312:     is(s_wait_return){\n313:       when(resp.fire){\n\
      314:         uState := s_idle\n315:       }\n316:     }\n317:   }\n318: \n319: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 327-337
    context: "327:    *    e0: solved in one cycle for achieving the original performance.\n\
      328:    *    e1: return idResp to set sid for handshake\n329:    ******************************************************************/\n\
      330: \n331:   /* e0: merge/alloc */\n332:   val e0_fire = req.fire\n333:   val
      e0_req_valid = req.valid\n334:   val e0_req = req.bits\n335: \n336:   val e0_rejectVec
      = Wire(Vec(UncacheBufferSize, Bool()))\n337:   val e0_mergeVec = Wire(Vec(UncacheBufferSize,
      Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 335-345
    context: "335: \n336:   val e0_rejectVec = Wire(Vec(UncacheBufferSize, Bool()))\n\
      337:   val e0_mergeVec = Wire(Vec(UncacheBufferSize, Bool()))\n338:   val e0_allocWaitSameVec
      = Wire(Vec(UncacheBufferSize, Bool()))\n339:   sizeForeach(i => {\n340:    \
      \ val valid = e0_req_valid && states(i).isValid()\n341:     val isAddrMatch
      = addrMatch(e0_req, entries(i))\n342:     val canMerge1 = canMergePrimary(e0_req,
      entries(i), i.U)\n343:     val canMerge2 = canMergeSecondary(i.U)\n344:    \
      \ e0_rejectVec(i) := valid && isAddrMatch && !canMerge1\n345:     e0_mergeVec(i)
      := valid && isAddrMatch && canMerge1 && canMerge2"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 345-355
    context: "345:     e0_mergeVec(i) := valid && isAddrMatch && canMerge1 && canMerge2\n\
      346:     e0_allocWaitSameVec(i) := valid && isAddrMatch && canMerge1 && !canMerge2\n\
      347:   })\n348:   assert(PopCount(e0_mergeVec) <= 1.U, \"Uncache buffer should
      not merge multiple entries\")\n349: \n350:   val e0_invalidVec = sizeMap(i =>
      !states(i).isValid())\n351:   val (e0_mergeIdx, e0_canMerge) = PriorityEncoderWithFlag(e0_mergeVec)\n\
      352:   val (e0_allocIdx, e0_canAlloc) = PriorityEncoderWithFlag(e0_invalidVec)\n\
      353:   val e0_allocWaitSame = e0_allocWaitSameVec.reduce(_ || _)\n354:   val
      e0_sid = Mux(e0_canMerge, e0_mergeIdx, e0_allocIdx)\n355:   val e0_reject =
      do_uarch_drain || (!e0_canMerge && !e0_invalidVec.asUInt.orR) || e0_rejectVec.reduce(_
      || _)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 357-373
    context: "357:   // e0_fire is used to guarantee that it will not be rejected\n\
      358:   when(e0_canMerge && e0_req_valid){\n359:     entries(e0_mergeIdx).update(e0_req)\n\
      360:   }.elsewhen(e0_canAlloc && e0_fire){\n361:     entries(e0_allocIdx).set(e0_req)\n\
      362:     states(e0_allocIdx).setValid(true.B)\n363:     when(e0_allocWaitSame){\n\
      364:       states(e0_allocIdx).setWaitSame(true.B)\n365:     }\n366:   }\n367:\
      \ \n368:   req_ready := !e0_reject\n369: \n370:   /* e1: return accept */\n\
      371:   io.lsq.idResp.valid := RegNext(e0_fire)\n372:   io.lsq.idResp.bits.mid
      := RegEnable(e0_req.id, e0_fire)\n373:   io.lsq.idResp.bits.sid := RegEnable(e0_sid,
      e0_fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 385-396
    context: "385:    *    NOTE: \"Enter Buffer\" & \"Uncache Req\" not a continuous
      pipeline,\n386:    *          because there is no guarantee that mem_aquire
      will be always ready.\n387:    ******************************************************************/\n\
      388: \n389:   val q0_canSentVec = sizeMap(i =>\n390:     (io.enableOutstanding
      || uState === s_idle) &&\n391:     states(i).can2Bus()\n392:   )\n393:   val
      q0_res = PriorityEncoderWithFlag(q0_canSentVec)\n394:   q0_canSentIdx := q0_res._1\n\
      395:   q0_canSent := q0_res._2\n396:   q0_entry := entries(q0_canSentIdx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 420-439
    context: "420: \n421:   val q0_isStore = q0_entry.cmd === MemoryOpConstants.M_XWR\n\
      422: \n423:   mem_acquire.valid := q0_canSent && !io.wfi.wfiReq\n424:   mem_acquire.bits
      := Mux(q0_isStore, q0_store, q0_load)\n425:   mem_acquire.bits.user.lift(MemBackTypeMM).foreach(_
      := q0_entry.memBackTypeMM)\n426:   mem_acquire.bits.user.lift(MemPageTypeNC).foreach(_
      := q0_entry.nc)\n427:   when(mem_acquire.fire){\n428:     states(q0_canSentIdx).setInflight(true.B)\n\
      429:     noPending(q0_canSentIdx) := false.B\n430: \n431:     // q0 should judge
      whether wait same block\n432:     (0 until UncacheBufferSize).map(j =>\n433:\
      \       when(q0_canSentIdx =/= j.U && states(j).isValid() && !states(j).isWaitReturn()
      && addrMatch(q0_entry, entries(j))){\n434:         states(j).setWaitSame(true.B)\n\
      435:       }\n436:     )\n437:   }\n438: \n439:   // uncache store but memBackTypeMM
      should update the golden memory"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 439-449
    context: "439:   // uncache store but memBackTypeMM should update the golden memory\n\
      440:   if (env.EnableDifftest) {\n441:     val difftest = DifftestModule(new
      DiffUncacheMMStoreEvent, delay = 1)\n442:     difftest.coreid := io.hartId\n\
      443:     difftest.index  := 0.U\n444:     difftest.valid  := mem_acquire.fire
      && isStore(entries(q0_canSentIdx)) && entries(q0_canSentIdx).memBackTypeMM\n\
      445:     difftest.addr   := entries(q0_canSentIdx).addr\n446:     difftest.data\
      \   := entries(q0_canSentIdx).data.asTypeOf(Vec(DataBytes, UInt(8.W)))\n447:\
      \     difftest.mask   := entries(q0_canSentIdx).mask\n448:   }\n449: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 451-465
    context: "451:    * Uncache Resp\n452:    ******************************************************************/\n\
      453: \n454:   val (_, _, refill_done, _) = edge.addr_inc(mem_grant)\n455: \n\
      456:   mem_grant.ready := true.B\n457:   when (mem_grant.fire) {\n458:     val
      id = mem_grant.bits.source\n459:     entries(id).update(mem_grant.bits)\n460:\
      \     states(id).updateUncacheResp()\n461:     noPending(id) := true.B\n462:\
      \     assert(refill_done, \"Uncache response should be one beat only!\")\n463:\
      \ \n464:     // remove state of wait same block\n465:     (0 until UncacheBufferSize).map(j
      =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 461-476
    context: "461:     noPending(id) := true.B\n462:     assert(refill_done, \"Uncache
      response should be one beat only!\")\n463: \n464:     // remove state of wait
      same block\n465:     (0 until UncacheBufferSize).map(j =>\n466:       when(id
      =/= j.U && states(j).isValid() && states(j).isWaitSame() && addrMatch(entries(id),
      entries(j))){\n467:         states(j).setWaitSame(false.B)\n468:       }\n469:\
      \     )\n470:   }\n471:   io.busError.ecc_error.valid := mem_grant.fire && isStore(entries(mem_grant.bits.source))
      &&\n472:     (mem_grant.bits.denied || mem_grant.bits.corrupt)\n473:   io.busError.ecc_error.bits
      := entries(mem_grant.bits.source).addr >> blockOffBits << blockOffBits\n474:\
      \ \n475:   io.wfi.wfiSafe := GatedValidRegNext(noPending.asUInt.andR && io.wfi.wfiReq)\n\
      476:   /******************************************************************"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 475-490
    context: "475:   io.wfi.wfiSafe := GatedValidRegNext(noPending.asUInt.andR &&
      io.wfi.wfiReq)\n476:   /******************************************************************\n\
      477:    * Return to LSQ\n478:    ******************************************************************/\n\
      479: \n480:   val r0_canSentVec = sizeMap(i => states(i).can2Lsq())\n481:  \
      \ val (r0_canSentIdx, r0_canSent) = PriorityEncoderWithFlag(r0_canSentVec)\n\
      482:   resp.valid := r0_canSent\n483:   resp.bits := entries(r0_canSentIdx).toUncacheWordResp(r0_canSentIdx)\n\
      484:   when(resp.fire){\n485:     states(r0_canSentIdx).updateReturn()\n486:\
      \   }\n487: \n488: \n489:   /******************************************************************\n\
      490:    * Buffer Flush"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 488-499
    context: "488: \n489:   /******************************************************************\n\
      490:    * Buffer Flush\n491:    * 1. when io.flush.valid is true: drain store
      queue and ubuffer\n492:    ******************************************************************/\n\
      493:   empty := !VecInit(states.map(_.isValid())).asUInt.orR\n494:   io.flush.empty
      := empty\n495: \n496: \n497:   /******************************************************************\n\
      498:    * Load Data Forward to loadunit\n499:    *  f0: vaddr match, fast resp"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 499-509
    context: "499:    *  f0: vaddr match, fast resp\n500:    *  f1: mask & data select,
      merge; paddr match; resp\n501:    *      NOTE: forward.paddr from dtlb, which
      is far from uncache f0\n502:    ******************************************************************/\n\
      503: \n504:   val f0_validMask = sizeMap(i => isStore(entries(i)) && states(i).isValid())\n\
      505:   val f0_fwdMaskCandidates = VecInit(entries.map(e => e.mask))\n506:  \
      \ val f0_fwdDataCandidates = VecInit(entries.map(e => e.data))\n507:   val f1_fwdMaskCandidates
      = sizeMap(i => RegEnable(entries(i).mask, f0_validMask(i)))\n508:   val f1_fwdDataCandidates
      = sizeMap(i => RegEnable(entries(i).data, f0_validMask(i)))\n509:   val f1_tagMismatchVec
      = Wire(Vec(LoadPipelineWidth, Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 507-539
    context: "507:   val f1_fwdMaskCandidates = sizeMap(i => RegEnable(entries(i).mask,
      f0_validMask(i)))\n508:   val f1_fwdDataCandidates = sizeMap(i => RegEnable(entries(i).data,
      f0_validMask(i)))\n509:   val f1_tagMismatchVec = Wire(Vec(LoadPipelineWidth,
      Bool()))\n510:   f1_needDrain := f1_tagMismatchVec.asUInt.orR && !empty\n511:\
      \ \n512:   for ((forward, i) <- io.forward.zipWithIndex) {\n513:     val f0_fwdValid
      = forward.valid\n514:     val f1_fwdValid = RegNext(f0_fwdValid)\n515: \n516:\
      \     /* f0 */\n517:     // vaddr match\n518:     val f0_vtagMatches = sizeMap(w
      => addrMatch(entries(w).vaddr, forward.vaddr))\n519:     val f0_flyTagMatches
      = sizeMap(w => f0_vtagMatches(w) && f0_validMask(w) && f0_fwdValid && states(w).isFwdOld())\n\
      520:     val f0_idleTagMatches = sizeMap(w => f0_vtagMatches(w) && f0_validMask(w)
      && f0_fwdValid && states(w).isFwdNew())\n521:     // ONLY for fast use to get
      better timing\n522:     val f0_flyMaskFast = shiftMaskToHigh(\n523:       forward.vaddr,\n\
      524:       Mux1H(f0_flyTagMatches, f0_fwdMaskCandidates)\n525:     ).asTypeOf(Vec(VDataBytes,
      Bool()))\n526:     val f0_idleMaskFast = shiftMaskToHigh(\n527:       forward.vaddr,\n\
      528:       Mux1H(f0_idleTagMatches, f0_fwdMaskCandidates)\n529:     ).asTypeOf(Vec(VDataBytes,
      Bool()))\n530: \n531:     /* f1 */\n532:     val f1_flyTagMatches = RegEnable(f0_flyTagMatches,
      f0_fwdValid)\n533:     val f1_idleTagMatches = RegEnable(f0_idleTagMatches,
      f0_fwdValid)\n534:     val f1_fwdPAddr = RegEnable(forward.paddr, f0_fwdValid)\n\
      535:     // select\n536:     val f1_flyMask = Mux1H(f1_flyTagMatches, f1_fwdMaskCandidates)\n\
      537:     val f1_flyData = Mux1H(f1_flyTagMatches, f1_fwdDataCandidates)\n538:\
      \     val f1_idleMask = Mux1H(f1_idleTagMatches, f1_fwdMaskCandidates)\n539:\
      \     val f1_idleData = Mux1H(f1_idleTagMatches, f1_fwdDataCandidates)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 540-572
    context: "540:     // merge old(inflight) and new(idle)\n541:     val (f1_fwdDataTmp,
      f1_fwdMaskTmp) = doMerge(f1_flyData, f1_flyMask, f1_idleData, f1_idleMask)\n\
      542:     val f1_fwdMask = shiftMaskToHigh(f1_fwdPAddr, f1_fwdMaskTmp).asTypeOf(Vec(VDataBytes,
      Bool()))\n543:     val f1_fwdData = shiftDataToHigh(f1_fwdPAddr, f1_fwdDataTmp).asTypeOf(Vec(VDataBytes,
      UInt(8.W)))\n544:     // paddr match and mismatch judge\n545:     val f1_ptagMatches
      = sizeMap(w => addrMatch(RegEnable(entries(w).addr, f0_fwdValid), f1_fwdPAddr))\n\
      546:     f1_tagMismatchVec(i) := sizeMap(w =>\n547:       RegEnable(f0_vtagMatches(w),
      f0_fwdValid) =/= f1_ptagMatches(w) && RegEnable(f0_validMask(w), f0_fwdValid)
      && f1_fwdValid\n548:     ).asUInt.orR\n549:     XSDebug(\n550:       f1_tagMismatchVec(i),\n\
      551:       \"forward tag mismatch: pmatch %x vmatch %x vaddr %x paddr %x\\n\"\
      ,\n552:       f1_ptagMatches.asUInt,\n553:       RegEnable(f0_vtagMatches.asUInt,
      f0_fwdValid),\n554:       RegEnable(forward.vaddr, f0_fwdValid),\n555:     \
      \  RegEnable(forward.paddr, f0_fwdValid)\n556:     )\n557:     // response\n\
      558:     forward.addrInvalid := false.B // addr in ubuffer is always ready\n\
      559:     forward.dataInvalid := false.B // data in ubuffer is always ready\n\
      560:     forward.matchInvalid := f1_tagMismatchVec(i) // paddr / vaddr cam result
      does not match\n561:     for (j <- 0 until VDataBytes) {\n562:       forward.forwardMaskFast(j)
      := f0_flyMaskFast(j) || f0_idleMaskFast(j)\n563: \n564:       forward.forwardData(j)
      := f1_fwdData(j)\n565:       forward.forwardMask(j) := false.B\n566:       when(f1_fwdMask(j)
      && f1_fwdValid) {\n567:         forward.forwardMask(j) := true.B\n568:     \
      \  }\n569:     }\n570: \n571:   }\n572: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 576-594
    context: "576:    ******************************************************************/\n\
      577: \n578:   /* Debug Counters */\n579:   // print all input/output requests
      for debug purpose\n580:   // print req/resp\n581:   XSDebug(req.fire, \"req
      cmd: %x addr: %x data: %x mask: %x\\n\",\n582:     req.bits.cmd, req.bits.addr,
      req.bits.data, req.bits.mask)\n583:   XSDebug(resp.fire, \"data: %x\\n\", req.bits.data)\n\
      584:   // print tilelink messages\n585:   XSDebug(mem_acquire.valid, \"mem_acquire
      valid, ready=%d \", mem_acquire.ready)\n586:   mem_acquire.bits.dump(mem_acquire.valid)\n\
      587: \n588:   XSDebug(mem_grant.fire, \"mem_grant fire \")\n589:   mem_grant.bits.dump(mem_grant.fire)\n\
      590: \n591:   /* Performance Counters */\n592:   XSPerfAccumulate(\"e0_reject\"\
      , e0_reject && e0_req_valid)\n593:   XSPerfAccumulate(\"e0_total_enter\", e0_fire)\n\
      594:   XSPerfAccumulate(\"e0_merge\", e0_fire && e0_canMerge)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/Uncache.scala
    lines: 595-620
    context: "595:   XSPerfAccumulate(\"e0_alloc_simple\", e0_fire && e0_canAlloc
      && !e0_allocWaitSame)\n596:   XSPerfAccumulate(\"e0_alloc_wait_same\", e0_fire
      && e0_canAlloc && e0_allocWaitSame)\n597:   XSPerfAccumulate(\"q0_acquire\"\
      , q0_canSent)\n598:   XSPerfAccumulate(\"q0_acquire_store\", q0_canSent && q0_isStore)\n\
      599:   XSPerfAccumulate(\"q0_acquire_load\", q0_canSent && !q0_isStore)\n600:\
      \   XSPerfAccumulate(\"uncache_memBackTypeMM\", io.lsq.req.fire && io.lsq.req.bits.memBackTypeMM)\n\
      601:   XSPerfAccumulate(\"uncache_mmio_store\", io.lsq.req.fire && isStore(io.lsq.req.bits.cmd)
      && !io.lsq.req.bits.nc)\n602:   XSPerfAccumulate(\"uncache_mmio_load\", io.lsq.req.fire
      && !isStore(io.lsq.req.bits.cmd) && !io.lsq.req.bits.nc)\n603:   XSPerfAccumulate(\"\
      uncache_nc_store\", io.lsq.req.fire && isStore(io.lsq.req.bits.cmd) && io.lsq.req.bits.nc)\n\
      604:   XSPerfAccumulate(\"uncache_nc_load\", io.lsq.req.fire && !isStore(io.lsq.req.bits.cmd)
      && io.lsq.req.bits.nc)\n605:   XSPerfAccumulate(\"uncache_outstanding\", uState
      =/= s_idle && mem_acquire.fire)\n606:   XSPerfAccumulate(\"forward_count\",
      PopCount(io.forward.map(_.forwardMask.asUInt.orR)))\n607:   XSPerfAccumulate(\"\
      forward_vaddr_match_failed\", PopCount(f1_tagMismatchVec))\n608: \n609:   val
      perfEvents = Seq(\n610:     (\"uncache_mmio_store\", io.lsq.req.fire && isStore(io.lsq.req.bits.cmd)
      && !io.lsq.req.bits.nc),\n611:     (\"uncache_mmio_load\", io.lsq.req.fire &&
      !isStore(io.lsq.req.bits.cmd) && !io.lsq.req.bits.nc),\n612:     (\"uncache_nc_store\"\
      , io.lsq.req.fire && isStore(io.lsq.req.bits.cmd) && io.lsq.req.bits.nc),\n\
      613:     (\"uncache_nc_load\", io.lsq.req.fire && !isStore(io.lsq.req.bits.cmd)
      && io.lsq.req.bits.nc),\n614:     (\"uncache_outstanding\", uState =/= s_idle
      && mem_acquire.fire),\n615:     (\"forward_count\", PopCount(io.forward.map(_.forwardMask.asUInt.orR))),\n\
      616:     (\"forward_vaddr_match_failed\", PopCount(f1_tagMismatchVec))\n617:\
      \   )\n618: \n619:   generatePerfEvent()\n620:   //  End"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Parameters.scala
    lines: 181-211
    context: "181:   VTypeBufferSize: Int = 64, // used to reorder vtype\n182:   IssueQueueSize:
      Int = 24,\n183:   IssueQueueCompEntrySize: Int = 16,\n184:   intPreg: PregParams
      = IntPregParams(\n185:     numEntries = 224,\n186:     numRead = None,\n187:\
      \     numWrite = None,\n188:   ),\n189:   fpPreg: PregParams = FpPregParams(\n\
      190:     numEntries = 192,\n191:     numRead = None,\n192:     numWrite = None,\n\
      193:   ),\n194:   vfPreg: VfPregParams = VfPregParams(\n195:     numEntries
      = 128,\n196:     numRead = None,\n197:     numWrite = None,\n198:   ),\n199:\
      \   v0Preg: V0PregParams = V0PregParams(\n200:     numEntries = 22,\n201:  \
      \   numRead = None,\n202:     numWrite = None,\n203:   ),\n204:   vlPreg: VlPregParams
      = VlPregParams(\n205:     numEntries = 32,\n206:     numRead = None,\n207: \
      \    numWrite = None,\n208:   ),\n209:   IntRegCacheSize: Int = 16,\n210:  \
      \ MemRegCacheSize: Int = 12,\n211:   intSchdVlWbPort: Int = 0,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Parameters.scala
    lines: 209-219
    context: "209:   IntRegCacheSize: Int = 16,\n210:   MemRegCacheSize: Int = 12,\n\
      211:   intSchdVlWbPort: Int = 0,\n212:   vfSchdVlWbPort: Int = 1,\n213:   prefetcher:
      Option[PrefetcherParams] = Some(SMSParams()),\n214:   IfuRedirectNum: Int =
      1,\n215:   LoadPipelineWidth: Int = 3,\n216:   StorePipelineWidth: Int = 2,\n\
      217:   VecLoadPipelineWidth: Int = 2,\n218:   VecStorePipelineWidth: Int = 2,\n\
      219:   VecMemSrcInWidth: Int = 2,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Parameters.scala
    lines: 250-260
    context: "250:   EnableStorePrefetchSMS: Boolean = false,\n251:   EnableStorePrefetchSPB:
      Boolean = false,\n252:   HasCMO: Boolean = true,\n253:   MMUAsidLen: Int = 16,
      // max is 16, 0 is not supported now\n254:   MMUVmidLen: Int = 14,\n255:   ReSelectLen:
      Int = 7, // load replay queue replay select counter len\n256:   iwpuParameters:
      WPUParameters = WPUParameters(\n257:     enWPU = false,\n258:     algoName =
      \"mmru\",\n259:     isICache = true,\n260:   ),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Parameters.scala
    lines: 262-278
    context: "262:     enWPU = false,\n263:     algoName = \"mmru\",\n264:     enCfPred
      = false,\n265:     isICache = false,\n266:   ),\n267:   itlbParameters: TLBParameters
      = TLBParameters(\n268:     name = \"itlb\",\n269:     fetchi = true,\n270: \
      \    useDmode = false,\n271:     NWays = 48,\n272:   ),\n273:   itlbPortNum:
      Int = ICacheParameters().PortNumber + 1,\n274:   ipmpPortNum: Int = 2 * ICacheParameters().PortNumber
      + 1,\n275:   ldtlbParameters: TLBParameters = TLBParameters(\n276:     name
      = \"ldtlb\",\n277:     NWays = 48,\n278:     outReplace = false,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Parameters.scala
    lines: 359-369
    context: "359:   def ISAExtensions = Seq(\n360:     // single letter extensions,
      in canonical order\n361:     \"i\", \"m\", \"a\", \"f\", \"d\", \"c\", /* \"\
      b\", */ \"v\", \"h\",\n362:     // multi-letter extensions, sorted alphanumerically\n\
      363:     \"sdtrig\", \"sha\", \"shcounterenw\", \"shgatpa\", \"shlcofideleg\"\
      , \"shtvala\", \"shvsatpa\", \"shvstvala\",\n364:     \"shvstvecd\", \"smaia\"\
      , \"smcsrind\", \"smdbltrp\", \"smmpm\", \"smnpm\", \"smrnmi\", \"smstateen\"\
      ,\n365:     \"ss1p13\", \"ssaia\", \"ssccptr\", \"sscofpmf\", \"sscounterenw\"\
      , \"sscsrind\", \"ssdbltrp\", \"ssnpm\",\n366:     \"sspm\", \"ssstateen\",
      \"ssstrict\", \"sstc\", \"sstvala\", \"sstvecd\", \"ssu64xl\", \"supm\", \"\
      sv39\",\n367:     \"sv48\", \"svade\", \"svbare\", \"svinval\", \"svnapot\"\
      , \"svpbmt\", \"za64rs\", \"zacas\", \"zawrs\", \"zba\",\n368:     \"zbb\",
      \"zbc\", \"zbkb\", \"zbkc\", \"zbkx\", \"zbs\", \"zcb\", \"zcmop\", \"zfa\"\
      , \"zfh\", \"zfhmin\", \"zic64b\",\n369:     \"zicbom\", \"zicbop\", \"zicboz\"\
      , \"ziccamoa\", \"ziccif\", \"zicclsm\", \"ziccrse\", \"zicntr\", \"zicond\"\
      ,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Parameters.scala
    lines: 418-436
    context: "418: \n419:   val fpSchdParams = {\n420:     implicit val schdType:
      SchedulerType = FpScheduler()\n421:     SchdBlockParams(Seq(\n422:       IssueBlockParams(Seq(\n\
      423:         ExeUnitParams(\"FEX0\", Seq(FaluCfg, FcvtCfg, F2vCfg, FmacCfg),
      Seq(FpWB(port = 0, 0), IntWB(port = 0, 2), VfWB(port = 3, 0), V0WB(port = 3,
      0)), Seq(Seq(FpRD(0, 0)), Seq(FpRD(1, 0)), Seq(FpRD(2, 0)))),\n424:        \
      \ ExeUnitParams(\"FEX1\", Seq(FdivCfg), Seq(FpWB(port = 3, 1)), Seq(Seq(FpRD(2,
      1)), Seq(FpRD(5, 1)))),\n425:       ), numEntries = 18, numEnq = 2, numComp
      = 14),\n426:       IssueBlockParams(Seq(\n427:         ExeUnitParams(\"FEX2\"\
      , Seq(FaluCfg, FmacCfg), Seq(FpWB(port = 1, 0), IntWB(port = 1, 2)), Seq(Seq(FpRD(3,
      0)), Seq(FpRD(4, 0)), Seq(FpRD(5, 0)))),\n428:         ExeUnitParams(\"FEX3\"\
      , Seq(FdivCfg), Seq(FpWB(port = 4, 1)), Seq(Seq(FpRD(8, 1)), Seq(FpRD(9, 1)))),\n\
      429:       ), numEntries = 18, numEnq = 2, numComp = 14),\n430:       IssueBlockParams(Seq(\n\
      431:         ExeUnitParams(\"FEX4\", Seq(FaluCfg, FmacCfg), Seq(FpWB(port =
      2, 0), IntWB(port = 2, 1)), Seq(Seq(FpRD(6, 0)), Seq(FpRD(7, 0)), Seq(FpRD(8,
      0)))),\n432:       ), numEntries = 18, numEnq = 2, numComp = 14),\n433:    \
      \ ),\n434:       numPregs = fpPreg.numEntries,\n435:       numDeqOutside = 0,\n\
      436:       schdType = schdType,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Parameters.scala
    lines: 440-458
    context: "440: \n441:   val vfSchdParams = {\n442:     implicit val schdType:
      SchedulerType = VfScheduler()\n443:     SchdBlockParams(Seq(\n444:       IssueBlockParams(Seq(\n\
      445:         ExeUnitParams(\"VFEX0\", Seq(VfmaCfg, VialuCfg, VimacCfg, VppuCfg),
      Seq(VfWB(port = 0, 0), V0WB(port = 0, 0)), Seq(Seq(VfRD(0, 0)), Seq(VfRD(1,
      0)), Seq(VfRD(2, 0)), Seq(V0RD(0, 0)), Seq(VlRD(0, 0)))),\n446:         ExeUnitParams(\"\
      VFEX1\", Seq(VfaluCfg, VfcvtCfg, VipuCfg, VSetRvfWvfCfg), Seq(VfWB(port = 0,
      1), V0WB(port = 0, 1), VlWB(port = vfSchdVlWbPort, 0), IntWB(port = 1, 1), FpWB(port
      = 0, 1)), Seq(Seq(VfRD(0, 1)), Seq(VfRD(1, 1)), Seq(VfRD(2, 1)), Seq(V0RD(0,
      1)), Seq(VlRD(0, 1)))),\n447:       ), numEntries = 16, numEnq = 2, numComp
      = 12),\n448:       IssueBlockParams(Seq(\n449:         ExeUnitParams(\"VFEX2\"\
      , Seq(VfmaCfg, VialuCfg), Seq(VfWB(port = 1, 0), V0WB(port = 1, 0)), Seq(Seq(VfRD(3,
      0)), Seq(VfRD(4, 0)), Seq(VfRD(5, 0)), Seq(V0RD(1, 0)), Seq(VlRD(1, 0)))),\n\
      450:         ExeUnitParams(\"VFEX3\", Seq(VfaluCfg), Seq(VfWB(port = 2, 1),
      V0WB(port = 2, 1), FpWB(port = 1, 1)), Seq(Seq(VfRD(3, 1)), Seq(VfRD(4, 1)),
      Seq(VfRD(5, 1)), Seq(V0RD(1, 1)), Seq(VlRD(1, 1)))),\n451:       ), numEntries
      = 16, numEnq = 2, numComp = 12),\n452:       IssueBlockParams(Seq(\n453:   \
      \      ExeUnitParams(\"VFEX4\", Seq(VfdivCfg, VidivCfg), Seq(VfWB(port = 3,
      1), V0WB(port = 3, 1)), Seq(Seq(VfRD(3, 2)), Seq(VfRD(4, 2)), Seq(VfRD(5, 2)),
      Seq(V0RD(1, 2)), Seq(VlRD(1, 2)))),\n454:       ), numEntries = 10, numEnq =
      2, numComp = 6),\n455:     ),\n456:       numPregs = vfPreg.numEntries,\n457:\
      \       numDeqOutside = 0,\n458:       schdType = schdType,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Parameters.scala
    lines: 479-498
    context: "479:       ), numEntries = 16, numEnq = 2, numComp = 12),\n480:    \
      \   IssueBlockParams(Seq(\n481:         ExeUnitParams(\"LDU2\", Seq(LduCfg),
      Seq(IntWB(7, 0), FpWB(5, 0)), Seq(Seq(IntRD(10, 0))), true, 2),\n482:      \
      \ ), numEntries = 16, numEnq = 2, numComp = 12),\n483:       IssueBlockParams(Seq(\n\
      484:         ExeUnitParams(\"VLSU0\", Seq(VlduCfg, VstuCfg, VseglduSeg, VsegstuCfg),
      Seq(VfWB(4, 0), V0WB(4, 0), VlWB(port = 2, 0)), Seq(Seq(VfRD(6, 0)), Seq(VfRD(7,
      0)), Seq(VfRD(8, 0)), Seq(V0RD(2, 0)), Seq(VlRD(2, 0)))),\n485:       ), numEntries
      = 16, numEnq = 2, numComp = 12),\n486:       IssueBlockParams(Seq(\n487:   \
      \      ExeUnitParams(\"VLSU1\", Seq(VlduCfg, VstuCfg), Seq(VfWB(5, 0), V0WB(5,
      0), VlWB(port = 3, 0)), Seq(Seq(VfRD(9, 0)), Seq(VfRD(10, 0)), Seq(VfRD(11,
      0)), Seq(V0RD(3, 0)), Seq(VlRD(3, 0)))),\n488:       ), numEntries = 16, numEnq
      = 2, numComp = 12),\n489:       IssueBlockParams(Seq(\n490:         ExeUnitParams(\"\
      STD0\", Seq(StdCfg, MoudCfg), Seq(), Seq(Seq(IntRD(5, 2), FpRD(9, 0)))),\n491:\
      \       ), numEntries = 16, numEnq = 2, numComp = 12),\n492:       IssueBlockParams(Seq(\n\
      493:         ExeUnitParams(\"STD1\", Seq(StdCfg, MoudCfg), Seq(), Seq(Seq(IntRD(3,
      2), FpRD(10, 0)))),\n494:       ), numEntries = 16, numEnq = 2, numComp = 12),\n\
      495:     ),\n496:       numPregs = intPreg.numEntries max vfPreg.numEntries,\n\
      497:       numDeqOutside = 0,\n498:       schdType = schdType,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Parameters.scala
    lines: 514-524
    context: "514:         Seq(\"FEX0\", \"FEX1\", \"FEX2\", \"FEX3\", \"FEX4\")\n\
      515:       ),\n516:     ).flatten\n517:   }\n518: \n519:   def fakeIntPreg =
      FakeIntPregParams(intPreg.numEntries, intPreg.numRead, intPreg.numWrite)\n520:\
      \ \n521:   val backendParams: BackendParams = backend.BackendParams(\n522: \
      \    Map(\n523:       IntScheduler() -> intSchdParams,\n524:       FpScheduler()
      -> fpSchdParams,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Parameters.scala
    lines: 791-804
    context: "791:   def VlsQueueSize = coreParams.VlsQueueSize\n792: \n793:   def
      MemIQSizeMax = backendParams.memSchdParams.get.issueBlockParams.map(_.numEntries).max\n\
      794:   def IQSizeMax = backendParams.allSchdParams.map(_.issueBlockParams.map(_.numEntries).max).max\n\
      795: \n796:   def NumRedirect = backendParams.numRedirect\n797:   def BackendRedirectNum
      = NumRedirect + 2 //2: ldReplay + Exception\n798:   def FtqRedirectAheadNum
      = NumRedirect\n799:   def IfuRedirectNum = coreParams.IfuRedirectNum\n800: \
      \  def LoadPipelineWidth = coreParams.LoadPipelineWidth\n801:   def StorePipelineWidth
      = coreParams.StorePipelineWidth\n802:   def VecLoadPipelineWidth = coreParams.VecLoadPipelineWidth\n\
      803:   def VecStorePipelineWidth = coreParams.VecStorePipelineWidth\n804:  \
      \ def VecMemSrcInWidth = coreParams.VecMemSrcInWidth"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Parameters.scala
    lines: 841-855
    context: "841:   def vmidLen = coreParams.MMUVmidLen\n842:   def BTLBWidth = coreParams.LoadPipelineWidth
      + coreParams.StorePipelineWidth\n843:   def refillBothTlb = coreParams.refillBothTlb\n\
      844:   def iwpuParam = coreParams.iwpuParameters\n845:   def dwpuParam = coreParams.dwpuParameters\n\
      846:   def itlbParams = coreParams.itlbParameters\n847:   def ldtlbParams =
      coreParams.ldtlbParameters\n848:   def sttlbParams = coreParams.sttlbParameters\n\
      849:   def hytlbParams = coreParams.hytlbParameters\n850:   def pftlbParams
      = coreParams.pftlbParameters\n851:   def l2ToL1Params = coreParams.l2ToL1tlbParameters\n\
      852:   def btlbParams = coreParams.btlbParameters\n853:   def l2tlbParams =
      coreParams.l2tlbParameters\n854:   def NumPerfCounters = coreParams.NumPerfCounters\n\
      855: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/transforms/PrintModuleName.scala
    lines: 31-44
    context: "31:       case _: firrtl.stage.FirrtlCircuitAnnotation => true\n32:\
      \       case _ => false\n33:     }\n34:     val c = circuitAnno.circuit\n35:\
      \ \n36:     def onStmt(s: firrtl.ir.Statement): firrtl.ir.Statement = s match
      {\n37:       case firrtl.ir.Print(info, firrtl.ir.StringLit(string), args, clk,
      en) =>\n38:         firrtl.ir.Print(info, firrtl.ir.StringLit(XSLog.replaceFIRStr(string)),
      args, clk, en)\n39:       case other: firrtl.ir.Statement =>\n40:         other.mapStmt(onStmt)\n\
      41:     }\n42: \n43:     firrtl.stage.FirrtlCircuitAnnotation(c.mapModule(m
      => m.mapStmt(onStmt))) +: otherAnnos\n44:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/transforms/Helpers.scala
    lines: 22-32
    context: "22:   implicit class CircuitHelper(circuit: firrtl.ir.Circuit) {\n23:\
      \     def mapModule(f: firrtl.ir.DefModule => firrtl.ir.DefModule): firrtl.ir.Circuit
      = circuit.copy(modules = circuit.modules.map(f))\n24:   }\n25: \n26:   implicit
      class DefModuleHelper(defModule: firrtl.ir.DefModule) {\n27:     def mapStmt(f:
      firrtl.ir.Statement => firrtl.ir.Statement): firrtl.ir.DefModule = defModule
      match {\n28:       case firrtl.ir.Module(info, name, ports, body) => firrtl.ir.Module(info,
      name, ports, f(body))\n29:       case firrtl.ir.DefClass(info, name, ports,
      body) => firrtl.ir.DefClass(info, name, ports, f(body))\n30:       case other:
      firrtl.ir.DefModule => other\n31:     }\n32: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/transforms/Helpers.scala
    lines: 28-38
    context: "28:       case firrtl.ir.Module(info, name, ports, body) => firrtl.ir.Module(info,
      name, ports, f(body))\n29:       case firrtl.ir.DefClass(info, name, ports,
      body) => firrtl.ir.DefClass(info, name, ports, f(body))\n30:       case other:
      firrtl.ir.DefModule => other\n31:     }\n32: \n33:     def foreachStmt(f: firrtl.ir.Statement
      => Unit): Unit = defModule match {\n34:       case firrtl.ir.Module(_, _, _,
      body) => f(body)\n35:       case firrtl.ir.DefClass(_, _, _, body) => f(body)\n\
      36:       case _: firrtl.ir.DefModule =>\n37:     }\n38:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/transforms/Helpers.scala
    lines: 35-52
    context: "35:       case firrtl.ir.DefClass(_, _, _, body) => f(body)\n36:   \
      \    case _: firrtl.ir.DefModule =>\n37:     }\n38:   }\n39: \n40:   implicit
      class StatementHelper(statement: firrtl.ir.Statement) {\n41:     def mapStmt(f:
      firrtl.ir.Statement => firrtl.ir.Statement): firrtl.ir.Statement = statement
      match {\n42:       case firrtl.ir.Conditionally(info, pred, conseq, alt) =>
      firrtl.ir.Conditionally(info, pred, f(conseq), f(alt))\n43:       case firrtl.ir.Block(stmts)
      => \n44:         val res = new scala.collection.mutable.ArrayBuffer[firrtl.ir.Statement]()\n\
      45:         var its = stmts.iterator :: Nil\n46:         while (its.nonEmpty)
      {\n47:           val it = its.head\n48:           if (it.hasNext) {\n49:   \
      \          it.next() match {\n50:               case firrtl.ir.EmptyStmt =>
      // flatten out\n51:               case b: firrtl.ir.Block =>\n52:          \
      \       its = b.stmts.iterator :: its"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/transforms/Helpers.scala
    lines: 56-64
    context: "56:           } else {\n57:             its = its.tail\n58:        \
      \   }\n59:         }\n60:         firrtl.ir.Block(res.toSeq)\n61:       case
      other: firrtl.ir.Statement => other\n62:     }\n63:   }\n64: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/transforms/PrintControl.scala
    lines: 111-122
    context: "111:     queue += top\n112:     ancestors(top) = mutable.LinkedHashSet.empty\n\
      113: \n114:     while (queue.nonEmpty) {\n115:       val curr = queue.dequeue()\n\
      116:       c.modules.find(m => m.name==curr).foreach(m => {\n117:         def
      viewStmt(s: firrtl.ir.Statement): firrtl.ir.Statement = s match {\n118:    \
      \       case firrtl.ir.DefInstance(_, _, module, _) =>\n119:             ancestors(module)
      = ancestors(curr).union(Set(m.name))\n120:             queue += module\n121:\
      \             s\n122:           case other =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/transforms/PrintControl.scala
    lines: 134-144
    context: "134:             ancestors(m.name).contains(elm)\n135:           }).reduce(_||_))\n\
      136:         }\n137:         val enable = enableList.isEmpty || inRange(enableList)\n\
      138:         val disable = disableAll || inRange(disableList) || !enable\n139:\
      \         def onStmt(s: firrtl.ir.Statement): firrtl.ir.Statement = s match
      {\n140:           case _: firrtl.ir.Print if disable => firrtl.ir.EmptyStmt\n\
      141:           case _: firrtl.ir.Stop if removeAssert => firrtl.ir.EmptyStmt\n\
      142:           case _: firrtl.ir.Verification if removeAssert => firrtl.ir.EmptyStmt\n\
      143:           case other => other.mapStmt(onStmt)\n144:         }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSTile.scala
    lines: 43-53
    context: "43:   val enableL2 = coreParams.L2CacheParamsOpt.isDefined\n44:   //
      =========== Public Ports ============\n45:   val memBlock = core.memBlock.inner\n\
      46:   val core_l3_pf_port = memBlock.l3_pf_sender_opt\n47:   val memory_port
      = if (enableCHI && enableL2) None else Some(l2top.inner.memory_port.get)\n48:\
      \   val tl_uncache = l2top.inner.mmio_port\n49:   val sep_tl_opt = l2top.inner.sep_tl_port_opt\n\
      50:   val beu_int_source = l2top.inner.beu.intNode\n51:   val core_reset_sink
      = BundleBridgeSink(Some(() => Reset()))\n52:   val clint_int_node = l2top.inner.clint_int_node\n\
      53:   val plic_int_node = l2top.inner.plic_int_node"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSTile.scala
    lines: 72-82
    context: "72:   }\n73: \n74:   // L2 Prefetch\n75:   l2top.inner.l2cache match
      {\n76:     case Some(l2) =>\n77:       l2.pf_recv_node.foreach(recv => {\n78:\
      \         println(\"Connecting L1 prefetcher to L2!\")\n79:         recv :=
      memBlock.l2_pf_sender_opt.get\n80:       })\n81:     case None =>\n82:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSTile.scala
    lines: 116-127
    context: "116:       val chi = if (enableCHI) Some(new PortIO) else None\n117:\
      \       val nodeID = if (enableCHI) Some(Input(UInt(NodeIDWidth.W))) else None\n\
      118:       val clintTime = Input(ValidIO(UInt(64.W)))\n119:       val dft =
      Option.when(hasDFT)(Input(new SramBroadcastBundle))\n120:       val dft_reset
      = Option.when(hasMbist)(Input(new DFTResetSignals()))\n121:       val l2_flush_en
      = Option.when(EnablePowerDown) (Output(Bool()))\n122:       val l2_flush_done
      = Option.when(EnablePowerDown) (Output(Bool()))\n123:     })\n124: \n125:  \
      \   dontTouch(io.hartId)\n126:     dontTouch(io.msiInfo)\n127:     if (!io.chi.isEmpty)
      { dontTouch(io.chi.get) }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSTile.scala
    lines: 124-134
    context: "124: \n125:     dontTouch(io.hartId)\n126:     dontTouch(io.msiInfo)\n\
      127:     if (!io.chi.isEmpty) { dontTouch(io.chi.get) }\n128: \n129:     val
      core_soft_rst = core_reset_sink.in.head._1 // unused\n130: \n131:     l2top.module.io.hartId.fromTile
      := io.hartId\n132:     core.module.io.hartId := l2top.module.io.hartId.toCore\n\
      133:     core.module.io.reset_vector := l2top.module.io.reset_vector.toCore\n\
      134:     core.module.io.msiInfo := l2top.module.io.msiInfo.toCore"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSTile.scala
    lines: 150-168
    context: "150: \n151:     l2top.module.io.beu_errors.icache <> core.module.io.beu_errors.icache\n\
      152:     l2top.module.io.beu_errors.dcache <> core.module.io.beu_errors.dcache\n\
      153:     l2top.module.io.beu_errors.uncache <> core.module.io.beu_errors.uncache\n\
      154: \n155:     l2top.module.io.l2_flush_en.foreach { _ := core.module.io.l2_flush_en
      }\n156:     io.l2_flush_en.foreach { _ := core.module.io.l2_flush_en }\n157:\
      \     core.module.io.l2_flush_done := l2top.module.io.l2_flush_done.getOrElse(false.B)\n\
      158:     io.l2_flush_done.foreach { _ := l2top.module.io.l2_flush_done.getOrElse(false.B)
      }\n159: \n160:     l2top.module.io.dft.zip(io.dft).foreach({ case (a, b) =>
      a := b })\n161:     l2top.module.io.dft_reset.zip(io.dft_reset).foreach({ case
      (a, b) => a := b })\n162:     core.module.io.dft.zip(io.dft).foreach({ case
      (a, b) => a := b })\n163:     core.module.io.dft_reset.zip(io.dft_reset).foreach({
      case (a, b) => a := b })\n164: \n165:     if (enableL2) {\n166:       // TODO:
      add ECC interface of L2\n167:       l2top.module.io.pfCtrlFromCore := core.module.io.l2PfCtrl\n\
      168: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSTile.scala
    lines: 172-182
    context: "172:       core.module.io.l2_hint.valid := l2top.module.io.l2_hint.valid\n\
      173: \n174:       core.module.io.l2PfqBusy := false.B\n175:       core.module.io.debugTopDown.l2MissMatch
      := l2top.module.io.debugTopDown.l2MissMatch\n176:       l2top.module.io.debugTopDown.robHeadPaddr
      := core.module.io.debugTopDown.robHeadPaddr\n177:       l2top.module.io.debugTopDown.robTrueCommit
      := core.module.io.debugTopDown.robTrueCommit\n178:       l2top.module.io.l2_pmp_resp
      := core.module.io.l2_pmp_resp\n179:       core.module.io.l2_tlb_req <> l2top.module.io.l2_tlb_req\n\
      180:       core.module.io.topDownInfo.l2Miss := l2top.module.io.l2Miss\n181:\
      \ \n182:       core.module.io.perfEvents <> l2top.module.io.perfEvents"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSTile.scala
    lines: 192-202
    context: "192:       core.module.io.topDownInfo.l2Miss := false.B\n193: \n194:\
      \       core.module.io.l2_tlb_req.req.valid := false.B\n195:       core.module.io.l2_tlb_req.req.bits
      := DontCare\n196:       core.module.io.l2_tlb_req.req_kill := DontCare\n197:\
      \       core.module.io.l2_tlb_req.resp.ready := true.B\n198: \n199:       core.module.io.perfEvents
      <> DontCare\n200:     }\n201: \n202:     io.debugTopDown.robHeadPaddr := core.module.io.debugTopDown.robHeadPaddr"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSTile.scala
    lines: 202-213
    context: "202:     io.debugTopDown.robHeadPaddr := core.module.io.debugTopDown.robHeadPaddr\n\
      203:     core.module.io.debugTopDown.l3MissMatch := io.debugTopDown.l3MissMatch\n\
      204:     l2top.module.io.l3Miss.fromTile := io.l3Miss\n205:     core.module.io.topDownInfo.l3Miss
      := l2top.module.io.l3Miss.toCore\n206: \n207:     io.chi.foreach(_ <> l2top.module.io.chi.get)\n\
      208:     l2top.module.io.nodeID.foreach(_ := io.nodeID.get)\n209: \n210:   \
      \  if (debugOpts.ResetGen && enableL2) {\n211:       core.module.reset := l2top.module.reset_core\n\
      212:     }\n213:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/DbEntry.scala
    lines: 14-24
    context: "14:   val timeCnt = UInt(XLEN.W)\n15:   val robIdx = UInt(log2Ceil(RobSize).W)\n\
      16:   val paddr = UInt(PAddrBits.W)\n17:   val vaddr = UInt(VAddrBits.W)\n18:\
      \   // 1:first hit, 2:first miss, 3:second miss\n19:   val missState = UInt(3.W)\n\
      20: }\n21: \n22: class LoadAccessEntry(implicit p: Parameters) extends LoadMissEntry{\n\
      23:   val pred_way_num = UInt(XLEN.W)\n24:   val dm_way_num = UInt(XLEN.W)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSTileWrap.scala
    lines: 56-69
    context: "56:   // seperate TL bus\n57:   println(s\"SeperateTLBus = $SeperateTLBus\"\
      )\n58:   println(s\"EnableSeperateTLAsync = $EnableSeperateTLAsync\")\n59: \
      \  // asynchronous bridge source node\n60:   val tlAsyncSourceOpt = Option.when(SeperateTLBus
      && EnableSeperateTLAsync)(LazyModule(new TLAsyncCrossingSource()))\n61:   tlAsyncSourceOpt.foreach(_.node
      := tile.sep_tl_opt.get)\n62:   // synchronous source node\n63:   val tlSyncSourceOpt
      = Option.when(SeperateTLBus && !EnableSeperateTLAsync)(TLTempNode())\n64:  \
      \ tlSyncSourceOpt.foreach(_ := tile.sep_tl_opt.get)\n65: \n66:   class XSTileWrapImp(wrapper:
      LazyModule) extends LazyRawModuleImp(wrapper) {\n67:     val clock = IO(Input(Clock()))\n\
      68:     val reset = IO(Input(AsyncReset()))\n69:     val noc_reset = EnableCHIAsyncBridge.map(_
      => IO(Input(AsyncReset())))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSTileWrap.scala
    lines: 92-103
    context: "92:         case Some(param) => Flipped(new AsyncBundle(UInt(64.W),
      param))\n93:         case None => Input(ValidIO(UInt(64.W)))\n94:       }\n\
      95:       val dft = Option.when(hasDFT)(Input(new SramBroadcastBundle))\n96:\
      \       val dft_reset = Option.when(hasMbist)(Input(new DFTResetSignals()))\n\
      97:       val l2_flush_en = Option.when(EnablePowerDown) (Output(Bool()))\n\
      98:       val l2_flush_done = Option.when(EnablePowerDown) (Output(Bool()))\n\
      99:       val pwrdown_req_n = Option.when(EnablePowerDown) (Input (Bool()))\n\
      100:       val pwrdown_ack_n = Option.when(EnablePowerDown) (Output (Bool()))\n\
      101:       val iso_en = Option.when(EnablePowerDown) (Input (Bool()))\n102:\
      \     })\n103: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSTileWrap.scala
    lines: 110-121
    context: "110:     childReset := reset_sync\n111: \n112:     tile.module.io.hartId
      := io.hartId\n113:     tile.module.io.msiInfo := io.msiInfo\n114:     tile.module.io.reset_vector
      := io.reset_vector\n115:     tile.module.io.dft.zip(io.dft).foreach({ case (a,
      b) => a := b })\n116:     tile.module.io.dft_reset.zip(io.dft_reset).foreach({
      case (a, b) => a := b })\n117:     io.cpu_halt := tile.module.io.cpu_halt\n\
      118:     io.cpu_crtical_error := tile.module.io.cpu_crtical_error\n119:    \
      \ io.msiAck := tile.module.io.msiAck\n120:     io.hartIsInReset := tile.module.io.hartIsInReset\n\
      121:     io.traceCoreInterface <> tile.module.io.traceCoreInterface"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSTileWrap.scala
    lines: 119-133
    context: "119:     io.msiAck := tile.module.io.msiAck\n120:     io.hartIsInReset
      := tile.module.io.hartIsInReset\n121:     io.traceCoreInterface <> tile.module.io.traceCoreInterface\n\
      122:     io.debugTopDown <> tile.module.io.debugTopDown\n123:     tile.module.io.l3Miss
      := io.l3Miss\n124:     tile.module.io.nodeID.foreach(_ := io.nodeID.get)\n125:\
      \     io.l2_flush_en.foreach { _ := tile.module.io.l2_flush_en.getOrElse(false.B)
      }\n126:     io.l2_flush_done.foreach { _ := tile.module.io.l2_flush_done.getOrElse(false.B)
      }\n127:     io.pwrdown_ack_n.foreach { _ := DontCare }\n128:     io.pwrdown_ack_n
      zip io.pwrdown_req_n foreach { case (ack, req) =>\n129:       val powerSwitchBuffer
      = Module(new PowerSwitchBuffer)\n130:       ack := powerSwitchBuffer.ack\n131:\
      \       powerSwitchBuffer.sleep := req\n132:     }\n133: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSTileWrap.scala
    lines: 134-144
    context: "134:     // CLINT Async Queue Sink\n135:     EnableClintAsyncBridge
      match {\n136:       case Some(param) =>\n137:         val sink = withClockAndReset(clock,
      soc_reset_sync)(Module(new AsyncQueueSink(UInt(64.W), param)))\n138:       \
      \  sink.io.async <> io.clintTime\n139:         sink.io.deq.ready := true.B\n\
      140:         tile.module.io.clintTime.valid := sink.io.deq.valid\n141:     \
      \    tile.module.io.clintTime.bits := sink.io.deq.bits\n142:       case None
      =>\n143:         tile.module.io.clintTime := io.clintTime\n144:     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSTileWrap.scala
    lines: 166-176
    context: "166:       val resetChain = Seq(Seq(tile.module))\n167:       ResetGen(resetChain,
      reset_sync, !debugOpts.FPGAPlatform, io.dft_reset)\n168:     }\n169:     dontTouch(io.hartId)\n\
      170:     dontTouch(io.msiInfo)\n171:     io.pwrdown_req_n.foreach(dontTouch(_))\n\
      172:     io.pwrdown_ack_n.foreach(dontTouch(_))\n173:     io.iso_en.foreach(dontTouch(_))\n\
      174:   }\n175:   lazy val module = new XSTileWrapImp(this)\n176: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 42-52
    context: "42: \n43:   def basicDebugEn(implicit p: Parameters): Boolean = p(DebugOptionsKey).AlwaysBasicDiff
      || debugEn\n44: \n45:   val copyPdestInfo = mutable.HashMap[Int, (Int, Int)]()\n\
      46: \n47:   def updateCopyPdestInfo: Unit = allExuParams.filter(_.copyWakeupOut).map(x
      => getExuIdx(x.name) -> (x.copyDistance, -1)).foreach { x =>\n48:     copyPdestInfo.addOne(x)\n\
      49:   }\n50:   def isCopyPdest(exuIdx: Int): Boolean = {\n51:     copyPdestInfo.contains(exuIdx)\n\
      52:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 122-132
    context: "122:   def numNoDataWB = allSchdParams.map(_.numNoDataWB).sum\n123:\
      \   def numExu = allSchdParams.map(_.numExu).sum\n124: \n125:   def numException
      = allRealExuParams.count(_.exceptionOut.nonEmpty)\n126: \n127:   def numRedirect
      = 1 // only for ahead info to frontend\n128: \n129:   def numLoadDp = memSchdParams.get.issueBlockParams.filter(x
      => x.isLdAddrIQ || x.isHyAddrIQ).map(_.numEnq).sum\n130: \n131:   def numStoreDp
      = memSchdParams.get.issueBlockParams.filter(x => x.isStAddrIQ || x.isHyAddrIQ).map(_.numEnq).sum\n\
      132: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 160-171
    context: "160: \n161:   def genWriteBackBundles(implicit p: Parameters): Seq[RfWritePortWithConfig]
      = {\n162:     genIntWriteBackBundle ++ genVfWriteBackBundle\n163:   }\n164:\
      \ \n165:   def genWrite2CtrlBundles(implicit p: Parameters): MixedVec[ValidIO[ExuOutput]]
      = {\n166:     MixedVec(allSchdParams.map(_.genExuOutputValidBundle.flatten).flatten)\n\
      167:   }\n168: \n169:   def getIntWbArbiterParams: WbArbiterParams = {\n170:\
      \     val intWbCfgs: Seq[IntWB] = allSchdParams.flatMap(_.getWbCfgs.flatten.flatten.filter(_.writeInt)).map(_.asInstanceOf[IntWB])\n\
      171:     datapath.WbArbiterParams(intWbCfgs, intPregParams, this)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 261-271
    context: "261:     * Get size of read ports of int regfile\n262:     *\n263: \
      \    * @return if [[IntPregParams.numRead]] is [[None]], get size of ports in
      [[IntRD]]\n264:     */\n265:   def getIntRfReadSize = {\n266:     this.intPregParams.numRead.getOrElse(this.getRdPortIndices(IntData()).size)\n\
      267:   }\n268: \n269:   /**\n270:     * Get size of write ports of int regfile\n\
      271:     *"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 288-298
    context: "288:     * Get size of read ports of vec regfile\n289:     *\n290: \
      \    * @return if [[VfPregParams.numRead]] is [[None]], get size of ports in
      [[VfRD]]\n291:     */\n292:   def getVfRfReadSize = {\n293:     this.vfPregParams.numRead.getOrElse(this.getRdPortIndices(VecData()).size)\n\
      294:   }\n295: \n296:   /**\n297:     * Get size of write ports of vec regfile\n\
      298:     *"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 310-325
    context: "310:     this.vlPregParams.numWrite.getOrElse(this.getWbPortIndices(VlData()).size)\n\
      311:   }\n312: \n313:   def getRfReadSize(dataCfg: DataConfig) = {\n314:   \
      \  dataCfg match{\n315:       case IntData() => this.getPregParams(dataCfg).numRead.getOrElse(this.getRdPortIndices(dataCfg).size)\n\
      316:       case FpData()  => this.getPregParams(dataCfg).numRead.getOrElse(this.getRdPortIndices(dataCfg).size)\n\
      317:       case VecData() => this.getPregParams(dataCfg).numRead.getOrElse(this.getRdPortIndices(dataCfg).size)\n\
      318:       case V0Data() => this.getPregParams(dataCfg).numRead.getOrElse(this.getRdPortIndices(dataCfg).size)\n\
      319:       case VlData() => this.getPregParams(dataCfg).numRead.getOrElse(this.getRdPortIndices(dataCfg).size)\n\
      320:       case _ => throw new IllegalArgumentException(s\"DataConfig ${dataCfg}
      can not get RfReadSize\")\n321:     }\n322:   }\n323: \n324:   def getRfWriteSize(dataCfg:
      DataConfig) = {\n325:     this.getPregParams(dataCfg).numWrite.getOrElse(this.getWbPortIndices(dataCfg).size)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 389-404
    context: "389:     checkWritePortContinuous\n390:     configCheck\n391:   }\n\
      392: \n393:   def checkReadPortContinuous = {\n394:     pregParams.filterNot(_.isFake).foreach
      { x =>\n395:       if (x.numRead.isEmpty) {\n396:         val portIndices: Seq[Int]
      = getRdPortIndices(x.dataCfg)\n397:         require(isContinuous(portIndices),\n\
      398:           s\"The read ports of ${x.getClass.getSimpleName} should be continuous,
      \" +\n399:             s\"when numRead of ${x.getClass.getSimpleName} is None.
      The read port indices are $portIndices\")\n400:       }\n401:     }\n402:  \
      \ }\n403: \n404:   def checkWritePortContinuous = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 400-410
    context: "400:       }\n401:     }\n402:   }\n403: \n404:   def checkWritePortContinuous
      = {\n405:     pregParams.filterNot(_.isFake).foreach { x =>\n406:       if (x.numWrite.isEmpty)
      {\n407:         val portIndices: Seq[Int] = getWbPortIndices(x.dataCfg)\n408:\
      \         require(\n409:           isContinuous(portIndices),\n410:        \
      \   s\"The write ports of ${x.getClass.getSimpleName} should be continuous,
      \" +"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 418-433
    context: "418:     // check 0\n419:     val maxPortSource = 4\n420: \n421:   \
      \  allRealExuParams.map {\n422:       case exuParam => exuParam.wbPortConfigs.collectFirst
      { case x: IntWB => x }\n423:     }.filter(_.isDefined).groupBy(_.get.port).foreach
      {\n424:       case (wbPort, priorities) => assert(priorities.size <= maxPortSource,
      \"There has \" + priorities.size + \" exu's \" + \"Int WBport is \" + wbPort
      + \", but the maximum is \" + maxPortSource + \".\")\n425:     }\n426:     allRealExuParams.map
      {\n427:       case exuParam => exuParam.wbPortConfigs.collectFirst { case x:
      VfWB => x }\n428:     }.filter(_.isDefined).groupBy(_.get.port).foreach {\n\
      429:       case (wbPort, priorities) => assert(priorities.size <= maxPortSource,
      \"There has \" + priorities.size + \" exu's \" + \"Vf  WBport is \" + wbPort
      + \", but the maximum is \" + maxPortSource + \".\")\n430:     }\n431: \n432:\
      \     // check 1\n433:     // if some exus share the same wb port and rd ports,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 431-441
    context: "431: \n432:     // check 1\n433:     // if some exus share the same
      wb port and rd ports,\n434:     // the exu with high priority at wb must also
      have high priority at rd.\n435:     val wbTypes = Seq(IntWB(), FpWB(), VfWB())\n\
      436:     val rdTypes = Seq(IntRD(), FpRD(), VfRD())\n437:     for(wbType <-
      wbTypes){\n438:       for(rdType <- rdTypes){\n439:         println(s\"[BackendParams]
      wbType: ${wbType}, rdType: ${rdType}\")\n440:         allRealExuParams.map {\n\
      441:           case exuParam =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 447-458
    context: "447:               case _        => None\n448:             }\n449: \
      \            val rfReadPortConfigs = exuParam.rfrPortConfigs\n450:         \
      \    val rdConfigs = rdType match{\n451:               case _: IntRD => rfReadPortConfigs.flatten.filter(_.isInstanceOf[IntRD])\n\
      452:               case _: FpRD  => rfReadPortConfigs.flatten.filter(_.isInstanceOf[FpRD])\n\
      453:               case _: VfRD  => rfReadPortConfigs.flatten.filter(_.isInstanceOf[VfRD])\n\
      454:               case _        => Seq()\n455:             }\n456:        \
      \     (wbConfigs, rdConfigs)\n457:         }.filter(_._1.isDefined)\n458:  \
      \         .sortBy(_._1.get.priority)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 457-469
    context: "457:         }.filter(_._1.isDefined)\n458:           .sortBy(_._1.get.priority)\n\
      459:           .groupBy(_._1.get.port).map { case (wbPort, intWbRdPairs) =>\n\
      460:             val rdCfgs = intWbRdPairs.map(_._2).flatten\n461:         \
      \    println(s\"[BackendParams] wb port ${wbPort} rdcfgs: ${rdCfgs}\")\n462:\
      \             rdCfgs.groupBy(_.port).foreach { case (p, rdCfg) =>\n463:    \
      \           //println(s\"[BackendParams] rdport: ${p}, cfgs: ${rdCfg}\")\n464:\
      \               rdCfg.zip(rdCfg.drop(1)).foreach { case (cfg0, cfg1) => assert(cfg0.priority
      <= cfg1.priority, s\"an exu has high priority at ${wbType} wb port ${wbPort},
      but has low priority at ${rdType} rd port ${p}\") }\n465:             }\n466:\
      \         }\n467:       }\n468:     }\n469:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 30-40
    context: "30:   val robIdx = OptionWrapper(!env.FPGAPlatform, new RobPtr)\n31:
      }\n32: \n33: class RenameBuffer(size: Int)(implicit p: Parameters) extends XSModule
      with HasCircularQueuePtrHelper {\n34:   val io = IO(new Bundle {\n35:     val
      redirect = Input(ValidIO(new Bundle {\n36:     }))\n37: \n38:     val req =
      Vec(RenameWidth, Flipped(ValidIO(new DynInst)))\n39:     val fromRob = new Bundle
      {\n40:       val walkSize = Input(UInt(log2Up(size).W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 65-75
    context: "65:   // alias\n66:   private val snptSelect = io.snpt.snptSelect\n\
      67: \n68:   // pointer\n69:   private val enqPtrVec = RegInit(VecInit.tabulate(RenameWidth)(idx
      => RenameBufferPtr(flag = false, idx)))\n70:   private val enqPtr = enqPtrVec.head\n\
      71:   private val enqPtrOH = RegInit(1.U(size.W))\n72:   private val enqPtrOHShift
      = CircularShift(enqPtrOH)\n73:   // may shift [0, RenameWidth] steps\n74:  \
      \ private val enqPtrOHVec = VecInit.tabulate(RenameWidth + 1)(enqPtrOHShift.left)\n\
      75:   private val enqPtrVecNext = Wire(enqPtrVec.cloneType)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 73-83
    context: "73:   // may shift [0, RenameWidth] steps\n74:   private val enqPtrOHVec
      = VecInit.tabulate(RenameWidth + 1)(enqPtrOHShift.left)\n75:   private val enqPtrVecNext
      = Wire(enqPtrVec.cloneType)\n76: \n77:   private val deqPtrVec = RegInit(VecInit.tabulate(RabCommitWidth)(idx
      => RenameBufferPtr(flag = false, idx)))\n78:   private val deqPtr = deqPtrVec.head\n\
      79:   private val deqPtrOH = RegInit(1.U(size.W))\n80:   private val deqPtrOHShift
      = CircularShift(deqPtrOH)\n81:   private val deqPtrOHVec = VecInit.tabulate(RabCommitWidth
      + 1)(deqPtrOHShift.left)\n82:   private val deqPtrVecNext = Wire(deqPtrVec.cloneType)\n\
      83:   XSError(deqPtr.toOH =/= deqPtrOH, p\"wrong one-hot reg between $deqPtr
      and $deqPtrOH\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 85-95
    context: "85:   private val walkPtr = Reg(new RenameBufferPtr)\n86:   private
      val walkPtrOH = walkPtr.toOH\n87:   private val walkPtrOHVec = VecInit.tabulate(RabCommitWidth
      + 1)(CircularShift(walkPtrOH).left)\n88:   private val walkPtrNext = Wire(new
      RenameBufferPtr)\n89: \n90:   private val walkPtrSnapshots = SnapshotGenerator(enqPtr,
      io.snpt.snptEnq, io.snpt.snptDeq, io.redirect.valid, io.snpt.flushVec)\n91:\
      \ \n92:   val vcfgPtrOH = RegInit(1.U(size.W))\n93:   val vcfgPtrOHShift = CircularShift(vcfgPtrOH)\n\
      94:   // may shift [0, 2) steps\n95:   val vcfgPtrOHVec = VecInit.tabulate(2)(vcfgPtrOHShift.left)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 105-121
    context: "105:   private val maxLMUL = 8\n106:   private val vdIdxWidth = log2Up(maxLMUL
      + 1)\n107:   val currentVdIdx = Reg(UInt(vdIdxWidth.W)) // store 0~8\n108: \n\
      109:   val s_idle :: s_special_walk :: s_walk :: Nil = Enum(3)\n110:   val state
      = RegInit(s_idle)\n111:   val stateNext = WireInit(state) // otherwise keep
      state value\n112: \n113:   private val robWalkEndReg = RegInit(false.B)\n114:\
      \   private val robWalkEnd = io.fromRob.walkEnd || robWalkEndReg\n115: \n116:\
      \   when(io.redirect.valid) {\n117:     robWalkEndReg := false.B\n118:   }.elsewhen(io.fromRob.walkEnd)
      {\n119:     robWalkEndReg := true.B\n120:   }\n121: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 124-139
    context: "124:   val commitNum = Wire(UInt(log2Up(RabCommitWidth).W))\n125:  \
      \ val walkNum = Wire(UInt(log2Up(RabCommitWidth).W))\n126:   commitNum := Mux(io.commits.commitValid(0),
      PriorityMux((0 until RabCommitWidth).map(\n127:     i => io.commits.commitValid(RabCommitWidth
      - 1 - i) -> (RabCommitWidth - i).U\n128:   )), 0.U)\n129:   walkNum := Mux(io.commits.walkValid(0),
      PriorityMux((0 until RabCommitWidth).map(\n130:     i => io.commits.walkValid(RabCommitWidth
      - 1 - i) -> (RabCommitWidth-i).U\n131:   )), 0.U)\n132:   val commitCount =
      Mux(io.commits.isCommit && !io.commits.isWalk, commitNum, 0.U)\n133:   val walkCount\
      \   = Mux(io.commits.isWalk && !io.commits.isCommit, walkNum, 0.U)\n134:   val
      specialWalkCount = Mux(io.commits.isCommit && io.commits.isWalk, walkNum, 0.U)\n\
      135: \n136:   // number of pair(ldest, pdest) ready to commit to arch_rat\n\
      137:   val commitSize = RegInit(0.U(log2Up(size).W))\n138:   val walkSize =
      RegInit(0.U(log2Up(size).W))\n139:   val specialWalkSize = RegInit(0.U(log2Up(size).W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 142-163
    context: "142:   val newWalkSize = io.fromRob.walkSize\n143: \n144:   val commitSizeNxt
      = commitSize + newCommitSize - commitCount\n145:   val walkSizeNxt = walkSize
      + newWalkSize - walkCount\n146: \n147:   val newSpecialWalkSize = Mux(io.redirect.valid
      && !io.snpt.useSnpt, commitSizeNxt, 0.U)\n148:   val specialWalkSizeNext = specialWalkSize
      + newSpecialWalkSize - specialWalkCount\n149: \n150:   commitSize := Mux(io.redirect.valid
      && !io.snpt.useSnpt, 0.U, commitSizeNxt)\n151:   specialWalkSize := specialWalkSizeNext\n\
      152:   walkSize := Mux(io.redirect.valid, 0.U, walkSizeNxt)\n153: \n154:   walkPtrNext
      := MuxCase(walkPtr, Seq(\n155:     (state === s_idle && stateNext === s_walk)
      -> walkPtrSnapshots(snptSelect),\n156:     (state === s_special_walk && stateNext
      === s_walk) -> deqPtrVecNext.head,\n157:     (state === s_walk && io.snpt.useSnpt
      && io.redirect.valid) -> walkPtrSnapshots(snptSelect),\n158:     (state ===
      s_walk) -> (walkPtr + walkCount),\n159:   ))\n160: \n161:   walkPtr := walkPtrNext\n\
      162: \n163:   val walkCandidates   = VecInit(walkPtrOHVec.map(sel => Mux1H(sel,
      renameBufferEntries)))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 172-187
    context: "172:   // TODO: do not use diffPtrNext here\n173:   vcfgPtrOH := diffPtrNext.toOH\n\
      174: \n175:   // update enq pointer\n176:   val enqPtrNext = Mux(\n177:    \
      \ state === s_walk && stateNext === s_idle,\n178:     walkPtrNext,\n179:   \
      \  enqPtr + enqCount\n180:   )\n181:   val enqPtrOHNext = Mux(\n182:     state
      === s_walk && stateNext === s_idle,\n183:     walkPtrNext.toOH,\n184:     enqPtrOHVec(enqCount)\n\
      185:   )\n186:   enqPtr := enqPtrNext\n187:   enqPtrOH := enqPtrOHNext"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 187-198
    context: "187:   enqPtrOH := enqPtrOHNext\n188:   enqPtrVecNext.zipWithIndex.map{
      case(ptr, i) => ptr := enqPtrNext + i.U }\n189:   enqPtrVec := enqPtrVecNext\n\
      190: \n191:   val deqPtrSteps = Mux1H(Seq(\n192:     (state === s_idle) -> commitCount,\n\
      193:     (state === s_special_walk) -> specialWalkCount,\n194:   ))\n195: \n\
      196:   // update deq pointer\n197:   val deqPtrNext = deqPtr + deqPtrSteps\n\
      198:   val deqPtrOHNext = deqPtrOHVec(deqPtrSteps)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 203-225
    context: "203: \n204:   val allocatePtrVec = VecInit((0 until RenameWidth).map(i
      => enqPtrVec(PopCount(realNeedAlloc.take(i))).value))\n205:   allocatePtrVec.zip(io.req).zip(realNeedAlloc).map{
      case((allocatePtr, req), realNeedAlloc) =>\n206:     when(realNeedAlloc){\n\
      207:       renameBuffer(allocatePtr).info := req.bits\n208:       renameBuffer(allocatePtr).robIdx.foreach(_
      := req.bits.robIdx)\n209:     }\n210:   }\n211: \n212:   io.commits.isCommit
      := state === s_idle || state === s_special_walk\n213:   io.commits.isWalk :=
      state === s_walk || state === s_special_walk\n214: \n215:   for(i <- 0 until
      RabCommitWidth) {\n216:     io.commits.commitValid(i) := state === s_idle &&
      i.U < commitSize || state === s_special_walk && i.U < specialWalkSize\n217:\
      \     io.commits.walkValid(i) := state === s_walk && i.U < walkSize || state
      === s_special_walk && i.U < specialWalkSize\n218:     // special walk use commitPtr\n\
      219:     io.commits.info(i) := Mux(state === s_idle || state === s_special_walk,
      commitCandidates(i).info, walkCandidates(i).info)\n220:     io.commits.robIdx.foreach(_(i)
      := Mux(state === s_idle || state === s_special_walk, commitCandidates(i).robIdx.get,
      walkCandidates(i).robIdx.get))\n221:   }\n222: \n223:   private val walkEndNext
      = walkSizeNxt === 0.U\n224:   private val commitEndNext = commitSizeNxt ===
      0.U\n225:   private val specialWalkEndNext = specialWalkSize <= RabCommitWidth.U"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 224-239
    context: "224:   private val commitEndNext = commitSizeNxt === 0.U\n225:   private
      val specialWalkEndNext = specialWalkSize <= RabCommitWidth.U\n226:   // when
      robWalkEndReg is 1, walkSize donot increase and decrease RabCommitWidth per
      Cycle\n227:   private val walkEndNextCycle = (robWalkEndReg || io.fromRob.walkEnd
      && io.fromRob.walkSize === 0.U) && (walkSize <= RabCommitWidth.U)\n228:   //
      change state\n229:   state := stateNext\n230:   when(io.redirect.valid) {\n\
      231:     when(io.snpt.useSnpt) {\n232:       stateNext := s_walk\n233:     }.otherwise
      {\n234:       stateNext := s_special_walk\n235:       vecLoadExcp := io.fromRob.vecLoadExcp\n\
      236:       when(io.fromRob.vecLoadExcp.valid) {\n237:         currentVdIdx :=
      0.U\n238:       }\n239:     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 237-255
    context: "237:         currentVdIdx := 0.U\n238:       }\n239:     }\n240:   }.otherwise
      {\n241:     // change stateNext\n242:     switch(state) {\n243:       // this
      transaction is not used actually, just list all states\n244:       is(s_idle)
      {\n245:         stateNext := s_idle\n246:       }\n247:       is(s_special_walk)
      {\n248:         currentVdIdx := currentVdIdx + specialWalkCount\n249:      \
      \   when(specialWalkEndNext) {\n250:           stateNext := s_walk\n251:   \
      \        vecLoadExcp.valid := false.B\n252:         }\n253:       }\n254:  \
      \     is(s_walk) {\n255:         when(walkEndNextCycle) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 251-261
    context: "251:           vecLoadExcp.valid := false.B\n252:         }\n253:  \
      \     }\n254:       is(s_walk) {\n255:         when(walkEndNextCycle) {\n256:\
      \           stateNext := s_idle\n257:         }\n258:       }\n259:     }\n\
      260:   }\n261: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 261-272
    context: "261: \n262:   val numValidEntries = distanceBetween(enqPtr, deqPtr)\n\
      263:   val allowEnqueue = GatedValidRegNext(numValidEntries + enqCount <= (size
      - RenameWidth).U, true.B)\n264:   val allowEnqueueForDispatch = GatedValidRegNext(numValidEntries
      + enqCount <= (size - 2*RenameWidth).U, true.B)\n265: \n266:   io.canEnq :=
      allowEnqueue && state === s_idle\n267:   io.canEnqForDispatch := allowEnqueueForDispatch
      && state === s_idle\n268:   io.enqPtrVec := enqPtrVec\n269: \n270:   io.status.walkEnd
      := walkEndNext\n271:   io.status.commitEnd := commitEndNext\n272: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 269-279
    context: "269: \n270:   io.status.walkEnd := walkEndNext\n271:   io.status.commitEnd
      := commitEndNext\n272: \n273:   for (i <- 0 until RabCommitWidth) {\n274:  \
      \   val valid = (state === s_special_walk) && vecLoadExcp.valid && io.commits.commitValid(i)\n\
      275:     io.toVecExcpMod.logicPhyRegMap(i).valid := RegNext(valid)\n276:   \
      \  io.toVecExcpMod.logicPhyRegMap(i).bits match {\n277:       case x =>\n278:\
      \         x.lreg := RegEnable(io.commits.info(i).ldest, valid)\n279:       \
      \  x.preg := RegEnable(io.commits.info(i).pdest, valid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 279-293
    context: "279:         x.preg := RegEnable(io.commits.info(i).pdest, valid)\n\
      280:     }\n281:   }\n282: \n283:   // for difftest\n284:   io.diffCommits.foreach(_
      := 0.U.asTypeOf(new DiffCommitIO))\n285:   io.diffCommits.foreach(_.isCommit
      := true.B)\n286:   for(i <- 0 until RabCommitWidth * MaxUopSize) {\n287:   \
      \  io.diffCommits.foreach(_.commitValid(i) := i.U < newCommitSize)\n288:   \
      \  io.diffCommits.foreach(_.info(i) := renameBufferEntries((diffPtr + i.U).value).info)\n\
      289:   }\n290: \n291:   XSError(isBefore(enqPtr, deqPtr) && !isFull(enqPtr,
      deqPtr), \"\\ndeqPtr is older than enqPtr!\\n\")\n292: \n293:   QueuePerf(RabSize,
      numValidEntries, numValidEntries === size.U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 298-316
    context: "298:     dontTouch(walkSizeNxt)\n299:     dontTouch(walkEndNext)\n300:\
      \     dontTouch(walkEndNextCycle)\n301:   }\n302: \n303:   XSPerfAccumulate(\"\
      s_idle_to_idle\", state === s_idle         && stateNext === s_idle)\n304:  \
      \ XSPerfAccumulate(\"s_idle_to_swlk\", state === s_idle         && stateNext
      === s_special_walk)\n305:   XSPerfAccumulate(\"s_idle_to_walk\", state === s_idle\
      \         && stateNext === s_walk)\n306:   XSPerfAccumulate(\"s_swlk_to_idle\"\
      , state === s_special_walk && stateNext === s_idle)\n307:   XSPerfAccumulate(\"\
      s_swlk_to_swlk\", state === s_special_walk && stateNext === s_special_walk)\n\
      308:   XSPerfAccumulate(\"s_swlk_to_walk\", state === s_special_walk && stateNext
      === s_walk)\n309:   XSPerfAccumulate(\"s_walk_to_idle\", state === s_walk  \
      \       && stateNext === s_idle)\n310:   XSPerfAccumulate(\"s_walk_to_swlk\"\
      , state === s_walk         && stateNext === s_special_walk)\n311:   XSPerfAccumulate(\"\
      s_walk_to_walk\", state === s_walk         && stateNext === s_walk)\n312: \n\
      313:   XSPerfAccumulate(\"disallow_enq_cycle\", !allowEnqueue)\n314:   XSPerfAccumulate(\"\
      disallow_enq_full_cycle\", numValidEntries + enqCount > (size - RenameWidth).U)\n\
      315:   XSPerfAccumulate(\"disallow_enq_not_idle_cycle\", state =/= s_idle)\n\
      316: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobDeqPtrWrapper.scala
    lines: 35-50
    context: "35: import xiangshan.backend.rename.SnapshotGenerator\n36: \n37: class
      NewRobDeqPtrWrapper(implicit p: Parameters) extends XSModule with HasCircularQueuePtrHelper
      {\n38:   val io = IO(new Bundle {\n39:     // for commits/flush\n40:     val
      state = Input(UInt(2.W))\n41:     val deq_v = Vec(CommitWidth, Input(Bool()))\n\
      42:     val deq_w = Vec(CommitWidth, Input(Bool()))\n43:     val hasCommitted
      = Vec(CommitWidth, Input(Bool()))\n44:     val allCommitted = Input(Bool())\n\
      45:     val exception_state = Flipped(ValidIO(new RobExceptionInfo))\n46:  \
      \   // for flush: when exception occurs, reset deqPtrs to range(0, CommitWidth)\n\
      47:     val intrBitSetReg = Input(Bool())\n48:     val allowOnlyOneCommit =
      Input(Bool())\n49:     val hasNoSpecExec = Input(Bool())\n50:     val interrupt_safe
      = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobDeqPtrWrapper.scala
    lines: 62-78
    context: "62:   val deqPosition = deqPtrVec(0).value(bankAddrWidth - 1, 0)\n63:\
      \ \n64:   // for exceptions (flushPipe included) and interrupts:\n65:   // only
      consider the first instruction\n66:   val intrEnable = io.intrBitSetReg && !io.hasNoSpecExec
      && io.interrupt_safe\n67:   val exceptionEnable = io.deq_w(deqPosition) && io.exception_state.valid
      && io.exception_state.bits.not_commit && io.exception_state.bits.robIdx ===
      deqPtrVec(0)\n68:   val redirectOutValid = io.state === 0.U && io.deq_v(deqPosition)
      && (intrEnable || exceptionEnable)\n69: \n70:   // for normal commits: only
      to consider when there're no exceptions\n71:   // we don't need to consider
      whether the first instruction has exceptions since it wil trigger exceptions.\n\
      72:   val realCommitLast = deqPtrVec(0).lineHeadPtr + Fill(bankAddrWidth, 1.U)\n\
      73:   val commit_exception = io.exception_state.valid && !isAfter(io.exception_state.bits.robIdx,
      realCommitLast)\n74:   val canCommit = VecInit((0 until CommitWidth).map(i =>
      io.deq_v(i) && io.deq_w(i) || io.hasCommitted(i)))\n75:   val normalCommitCnt
      = PriorityEncoder(canCommit.map(c => !c) :+ true.B) - PopCount(io.hasCommitted)\n\
      76:   // when io.intrBitSetReg or there're possible exceptions in these instructions,\n\
      77:   // only one instruction is allowed to commit\n78:   val allowOnlyOne =
      io.allowOnlyOneCommit"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobDeqPtrWrapper.scala
    lines: 88-98
    context: "88:   val commitDeqPtrAll = VecInit((0 until 2*CommitWidth).map{case
      i => deqPtrVec(0).lineHeadPtr + i.U})\n89:   val commitDeqPtrVec = Wire(chiselTypeOf(deqPtrVec))\n\
      90:   for (i <- 0 until CommitWidth){\n91:     commitDeqPtrVec(i) := PriorityMuxDefault(io.canCommitPriorityCond.zip(commitDeqPtrAll.drop(i).take(CommitWidth+1)),
      deqPtrVec(i))\n92:   }\n93:   val deqPtrVec_next = Mux(io.state === 0.U && !redirectOutValid
      && !io.blockCommit, commitDeqPtrVec, deqPtrVec)\n94: \n95:   deqPtrVec := deqPtrVec_next\n\
      96: \n97:   io.next_out := deqPtrVec_next\n98:   io.out      := deqPtrVec"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobDeqPtrWrapper.scala
    lines: 95-107
    context: "95:   deqPtrVec := deqPtrVec_next\n96: \n97:   io.next_out := deqPtrVec_next\n\
      98:   io.out      := deqPtrVec\n99:   io.commitCnt := commitCnt\n100:   io.commitEn
      := io.state === 0.U && !redirectOutValid && !io.blockCommit\n101: \n102:   XSInfo(io.state
      === 0.U && commitCnt > 0.U, \"retired %d insts\\n\", commitCnt)\n103: \n104:\
      \   if(backendParams.debugEn){\n105:     dontTouch(commitDeqPtrVec)\n106:  \
      \   dontTouch(commitDeqPtrAll)\n107:     dontTouch(allowOnlyOneCond)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobDeqPtrWrapper.scala
    lines: 104-112
    context: "104:   if(backendParams.debugEn){\n105:     dontTouch(commitDeqPtrVec)\n\
      106:     dontTouch(commitDeqPtrAll)\n107:     dontTouch(allowOnlyOneCond)\n\
      108:     dontTouch(io.canCommitPriorityCond)\n109:     dontTouch(redirectOutValid)\n\
      110:   }\n111: \n112: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 62-78
    context: "62:   private val StaCnt = params.StaCnt\n63:   private val HyuCnt =
      params.HyuCnt\n64: \n65:   val io = IO(new Bundle() {\n66:     val hartId =
      Input(UInt(hartIdLen.W))\n67:     val redirect = Input(Valid(new Redirect))\n\
      68:     val enq = new RobEnqIO\n69:     val flushOut = ValidIO(new Redirect)\n\
      70:     val exception = ValidIO(new ExceptionInfo)\n71:     // exu + brq\n72:\
      \     val writeback: MixedVec[ValidIO[ExuOutput]] = Flipped(params.genWrite2CtrlBundles)\n\
      73:     val exuWriteback: MixedVec[ValidIO[ExuOutput]] = Flipped(params.genWrite2CtrlBundles)\n\
      74:     val writebackNums = Flipped(Vec(writeback.size - params.StdCnt, ValidIO(UInt(writeback.size.U.getWidth.W))))\n\
      75:     val writebackNeedFlush = Input(Vec(params.allExuParams.filter(_.needExceptionGen).length,
      Bool()))\n76:     val commits = Output(new RobCommitIO)\n77:     val trace =
      new Bundle {\n78:       val blockCommit = Input(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 96-106
    context: "96:     val wfi_enable = Input(Bool())\n97:     val toDecode = new Bundle
      {\n98:       val isResumeVType = Output(Bool())\n99:       val walkToArchVType
      = Output(Bool())\n100:       val walkVType = ValidIO(VType())\n101:       val
      commitVType = new Bundle {\n102:         val vtype = ValidIO(VType())\n103:\
      \         val hasVsetvl = Output(Bool())\n104:       }\n105:     }\n106:   \
      \  val fromVecExcpMod = Input(new Bundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 138-150
    context: "138:   })\n139: \n140:   val exuWBs: Seq[ValidIO[ExuOutput]] = io.exuWriteback.filter(!_.bits.params.hasStdFu).toSeq\n\
      141:   val stdWBs: Seq[ValidIO[ExuOutput]] = io.exuWriteback.filter(_.bits.params.hasStdFu).toSeq\n\
      142:   val vldWBs: Seq[ValidIO[ExuOutput]] = io.exuWriteback.filter(_.bits.params.hasVLoadFu).toSeq\n\
      143:   val fflagsWBs = io.exuWriteback.filter(x => x.bits.fflags.nonEmpty).toSeq\n\
      144:   val exceptionWBs = io.writeback.filter(x => x.bits.exceptionVec.nonEmpty).toSeq\n\
      145:   val redirectWBs = io.writeback.filter(x => x.bits.redirect.nonEmpty).toSeq\n\
      146:   val vxsatWBs = io.exuWriteback.filter(x => x.bits.vxsat.nonEmpty).toSeq\n\
      147:   val branchWBs = io.exuWriteback.filter(_.bits.params.hasBrhFu).toSeq\n\
      148:   val jmpWBs = io.exuWriteback.filter(_.bits.params.hasJmpFu).toSeq\n149:\
      \   val csrWBs = io.exuWriteback.filter(x => x.bits.params.hasCSR).toSeq\n150: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 148-158
    context: "148:   val jmpWBs = io.exuWriteback.filter(_.bits.params.hasJmpFu).toSeq\n\
      149:   val csrWBs = io.exuWriteback.filter(x => x.bits.params.hasCSR).toSeq\n\
      150: \n151:   PerfCCT.tick(clock, reset)\n152: \n153:   io.exuWriteback.zipWithIndex.foreach{
      case (wb, i) =>\n154:     PerfCCT.updateInstPos(wb.bits.debug_seqNum, PerfCCT.InstPos.AtWriteVal.id.U,
      wb.valid, clock, reset)\n155:   }\n156: \n157:   val numExuWbPorts = exuWBs.length\n\
      158:   val numStdWbPorts = stdWBs.length"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 196-206
    context: "196:   val timer = GTimer()\n197:   // robEntries enqueue\n198:   for
      (i <- 0 until RobSize) {\n199:     val enqOH = VecInit(canEnqueue.zip(allocatePtrVec.map(_.value
      === i.U)).map(x => x._1 && x._2))\n200:     assert(PopCount(enqOH) < 2.U, s\"\
      robEntries$i enqOH is not one hot\")\n201:     when(enqOH.asUInt.orR && !io.redirect.valid){\n\
      202:       connectEnq(robEntries(i), Mux1H(enqOH, io.enq.req.map(_.bits)))\n\
      203:     }\n204:   }\n205:   // robBanks0 include robidx : 0 8 16 24 32 ...\n\
      206:   val robBanks = VecInit((0 until bankNum).map(i => VecInit(robEntries.zipWithIndex.filter(_._2
      % bankNum == i).map(_._1))))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 232-253
    context: "232:   val donotNeedWalk = RegInit(VecInit(Seq.fill(CommitWidth)(false.B)))\n\
      233:   val allCommitted = Wire(Bool())\n234: \n235:   when(allCommitted) {\n\
      236:     hasCommitted := 0.U.asTypeOf(hasCommitted)\n237:   }.elsewhen(io.commits.isCommit){\n\
      238:     for (i <- 0 until CommitWidth){\n239:       hasCommitted(i) := commitValidThisLine(i)
      || hasCommitted(i)\n240:     }\n241:   }\n242:   allCommitted := io.commits.isCommit
      && commitValidThisLine.last\n243:   val walkPtrHead = Wire(new RobPtr)\n244:\
      \   val changeBankAddrToDeqPtr = (walkPtrVec.head + CommitWidth.U) > lastWalkPtr\n\
      245:   when(io.redirect.valid){\n246:     robBanksRaddrNextLine := UIntToOH(walkPtrHead.value(walkPtrHead.value.getWidth-1,
      bankAddrWidth))\n247:   }.elsewhen(allCommitted || io.commits.isWalk && !changeBankAddrToDeqPtr){\n\
      248:     robBanksRaddrNextLine := Mux(robBanksRaddrThisLine.head(1) === 1.U,
      1.U, robBanksRaddrThisLine << 1)\n249:   }.elsewhen(io.commits.isWalk && changeBankAddrToDeqPtr){\n\
      250:     robBanksRaddrNextLine := UIntToOH(deqPtr.value(deqPtr.value.getWidth-1,
      bankAddrWidth))\n251:   }.otherwise(\n252:     robBanksRaddrNextLine := robBanksRaddrThisLine\n\
      253:   )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 265-276
    context: "265:   // In each robentry, the ftqIdx and ftqOffset belong to the first
      instruction that was compressed,\n266:   // That is Necessary when exceptions
      happen.\n267:   // Update the ftqOffset to correctly notify the frontend which
      instructions have been committed.\n268:   // Instructions in multiple Ftq entries
      compressed to one RobEntry do not occur.\n269:   for (i <- 0 until CommitWidth)
      {\n270:     val lastOffset = (rawInfo(i).traceBlockInPipe.iretire - (1.U <<
      rawInfo(i).traceBlockInPipe.ilastsize.asUInt).asUInt) + rawInfo(i).ftqOffset\n\
      271:     commitInfo(i).ftqOffset := Mux(CommitType.isFused(rawInfo(i).commitType),
      rawInfo(i).ftqOffset, lastOffset)\n272:   }\n273: \n274:   // data for debug\n\
      275:   // Warn: debug_* prefix should not exist in generated verilog.\n276:\
      \   val debug_microOp = DebugMem(RobSize, new DynInst)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 286-296
    context: "286:   val snapshotPtrVec = Wire(Vec(CommitWidth, new RobPtr))\n287:\
      \   snapshotPtrVec(0) := io.enq.req(0).bits.robIdx\n288:   for (i <- 1 until
      CommitWidth) {\n289:     snapshotPtrVec(i) := snapshotPtrVec(0) + i.U\n290:\
      \   }\n291:   val snapshots = SnapshotGenerator(snapshotPtrVec, snptEnq, io.snpt.snptDeq,
      io.redirect.valid, io.snpt.flushVec)\n292:   val debug_lsIssue = WireDefault(debug_lsIssued)\n\
      293:   debug_lsIssue(deqPtr.value) := io.debugHeadLsIssue\n294: \n295:   /**\n\
      296:    * states of Rob"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 294-337
    context: "294: \n295:   /**\n296:    * states of Rob\n297:    */\n298:   val s_idle
      :: s_walk :: Nil = Enum(2)\n299:   val state = RegInit(s_idle)\n300:   val state_next
      = Wire(chiselTypeOf(state))\n301: \n302:   val tip_computing :: tip_stalled
      :: tip_walk :: tip_drained :: Nil = Enum(4)\n303:   val tip_state = WireInit(0.U(4.W))\n\
      304:   when(!isEmpty) {  // One or more inst in ROB\n305:     when(state ===
      s_walk || io.redirect.valid) {\n306:       tip_state := tip_walk\n307:     }.elsewhen(io.commits.isCommit
      && PopCount(io.commits.commitValid) =/= 0.U) {\n308:       tip_state := tip_computing\n\
      309:     }.otherwise {\n310:       tip_state := tip_stalled\n311:     }\n312:\
      \   }.otherwise {\n313:     tip_state := tip_drained\n314:   }\n315:   class
      TipEntry()(implicit p: Parameters) extends XSBundle {\n316:     val state =
      UInt(4.W)\n317:     val commits = new RobCommitIO()      // info of commit\n\
      318:     val redirect = Valid(new Redirect)   // info of redirect\n319:    \
      \ val redirect_pc = UInt(VAddrBits.W)  // PC of the redirect uop\n320:     val
      debugLsInfo = new DebugLsInfo()\n321:   }\n322:   val tip_table = ChiselDB.createTable(\"\
      Tip_\" + p(XSCoreParamsKey).HartId.toString, new TipEntry)\n323:   val tip_data
      = Wire(new TipEntry())\n324:   tip_data.state := tip_state\n325:   tip_data.commits
      := io.commits\n326:   tip_data.redirect := io.redirect\n327:   tip_data.redirect_pc
      := debug_microOp(io.redirect.bits.robIdx.value).pc\n328:   tip_data.debugLsInfo
      := debug_lsInfo(io.commits.robIdx(0).value)\n329:   tip_table.log(tip_data,
      true.B, \"\", clock, reset)\n330: \n331:   val exceptionGen = Module(new ExceptionGen(params))\n\
      332:   val exceptionDataRead = exceptionGen.io.state\n333:   val fflagsDataRead
      = Wire(Vec(CommitWidth, UInt(5.W)))\n334:   val vxsatDataRead = Wire(Vec(CommitWidth,
      Bool()))\n335:   io.robDeqPtr := deqPtr\n336:   io.debugRobHead := debug_microOp(deqPtr.value)\n\
      337: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 336-346
    context: "336:   io.debugRobHead := debug_microOp(deqPtr.value)\n337: \n338: \
      \  /**\n339:    * connection of [[rab]]\n340:    */\n341:   rab.io.redirect.valid
      := io.redirect.valid\n342: \n343:   rab.io.req.zip(io.enq.req).map { case (dest,
      src) =>\n344:     dest.bits := src.bits\n345:     dest.valid := src.valid &&
      io.enq.canAccept\n346:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 348-359
    context: "348:   val walkDestSizeDeqGroup = RegInit(VecInit(Seq.fill(CommitWidth)(0.U(log2Up(MaxUopSize
      + 1).W))))\n349:   val realDestSizeSeq = VecInit(robDeqGroup.zip(hasCommitted).map{case
      (r, h) => Mux(h, 0.U, r.realDestSize)})\n350:   val walkDestSizeSeq = VecInit(robDeqGroup.zip(donotNeedWalk).map{case
      (r, d) => Mux(d, 0.U, r.realDestSize)})\n351:   val commitSizeSumSeq = VecInit((0
      until CommitWidth).map(i => realDestSizeSeq.take(i + 1).reduce(_ +& _)))\n352:\
      \   val walkSizeSumSeq   = VecInit((0 until CommitWidth).map(i => walkDestSizeSeq.take(i
      + 1).reduce(_ +& _)))\n353:   val commitSizeSumCond = VecInit(commitValidThisLine.zip(hasCommitted).map{case
      (c,h) => (c || h) && io.commits.isCommit})\n354:   val walkSizeSumCond   = VecInit(io.commits.walkValid.zip(donotNeedWalk).map{case
      (w,d) => (w || d) && io.commits.isWalk})\n355:   val commitSizeSum = PriorityMuxDefault(commitSizeSumCond.reverse.zip(commitSizeSumSeq.reverse),
      0.U)\n356:   val walkSizeSum   = PriorityMuxDefault(walkSizeSumCond.reverse.zip(walkSizeSumSeq.reverse),
      0.U)\n357: \n358:   val deqVlsExceptionNeedCommit = RegInit(false.B)\n359: \
      \  val deqVlsExceptionCommitSize = RegInit(0.U(log2Up(MaxUopSize + 1).W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 366-376
    context: "366:   rab.io.snpt := io.snpt\n367:   rab.io.snpt.snptEnq := snptEnq\n\
      368: \n369:   // pipe rab commits for better timing and area\n370:   io.rabCommits
      := RegNext(rab.io.commits)\n371:   io.diffCommits.foreach(_ := rab.io.diffCommits.get)\n\
      372: \n373:   /**\n374:    * connection of [[vtypeBuffer]]\n375:    */\n376: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 372-382
    context: "372: \n373:   /**\n374:    * connection of [[vtypeBuffer]]\n375:   \
      \ */\n376: \n377:   vtypeBuffer.io.redirect.valid := io.redirect.valid\n378:\
      \ \n379:   vtypeBuffer.io.req.zip(io.enq.req).map { case (sink, source) =>\n\
      380:     sink.valid := source.valid && io.enq.canAccept\n381:     sink.bits
      := source.bits\n382:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 379-390
    context: "379:   vtypeBuffer.io.req.zip(io.enq.req).map { case (sink, source)
      =>\n380:     sink.valid := source.valid && io.enq.canAccept\n381:     sink.bits
      := source.bits\n382:   }\n383: \n384:   private val commitIsVTypeVec = VecInit(io.commits.commitValid.zip(io.commits.info).map
      { case (valid, info) => io.commits.isCommit && valid && info.isVset })\n385:\
      \   private val walkIsVTypeVec = VecInit(io.commits.walkValid.zip(walkInfo).map
      { case (valid, info) => io.commits.isWalk && valid && info.isVset })\n386: \
      \  vtypeBuffer.io.fromRob.commitSize := PopCount(commitIsVTypeVec)\n387:   vtypeBuffer.io.fromRob.walkSize
      := PopCount(walkIsVTypeVec)\n388:   vtypeBuffer.io.snpt := io.snpt\n389:   vtypeBuffer.io.snpt.snptEnq
      := snptEnq\n390:   io.toDecode.walkToArchVType := vtypeBuffer.io.toDecode.walkToArchVType"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 386-396
    context: "386:   vtypeBuffer.io.fromRob.commitSize := PopCount(commitIsVTypeVec)\n\
      387:   vtypeBuffer.io.fromRob.walkSize := PopCount(walkIsVTypeVec)\n388:   vtypeBuffer.io.snpt
      := io.snpt\n389:   vtypeBuffer.io.snpt.snptEnq := snptEnq\n390:   io.toDecode.walkToArchVType
      := vtypeBuffer.io.toDecode.walkToArchVType\n391:   io.toDecode.commitVType :=
      vtypeBuffer.io.toDecode.commitVType\n392:   io.toDecode.walkVType := vtypeBuffer.io.toDecode.walkVType\n\
      393: \n394:   // When blockBackward instruction leaves Rob (commit or walk),
      hasBlockBackward should be set to false.B\n395:   // To reduce registers usage,
      for hasBlockBackward cases, we allow enqueue after ROB is empty.\n396:   when(isEmpty)
      {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 416-426
    context: "416:     }.elsewhen(!hasWFI && RegNext(hasWFI)) {\n417:       wfi_cycles
      := 0.U\n418:     }\n419:   }\n420:   val wfi_timeout = wfi_cycles.andR\n421:\
      \   when(RegNext(RegNext(io.csr.wfiEvent)) || io.flushOut.valid || wfi_timeout)
      {\n422:     hasWFI := false.B\n423:   }\n424: \n425:   for (i <- 0 until RenameWidth)
      {\n426:     // we don't check whether io.redirect is valid here since redirect
      has higher priority"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 447-457
    context: "447:       val enqHasException = ExceptionNO.selectFrontend(enqUop.exceptionVec).asUInt.orR\n\
      448:       when(enqUop.isWFI && !enqHasException && !enqTriggerActionIsDebugMode)
      {\n449:         hasWFI := true.B\n450:       }\n451: \n452:       robEntries(enqIndex).mmio
      := false.B\n453:       robEntries(enqIndex).vls := enqUop.vlsInstr\n454:   \
      \  }\n455:   }\n456: \n457:   for (i <- 0 until RenameWidth) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 466-476
    context: "466: \n467:   when(!io.wfi_enable) {\n468:     hasWFI := false.B\n469:\
      \   }\n470:   // sel vsetvl's flush position\n471:   val vs_idle :: vs_waitVinstr
      :: vs_waitFlush :: Nil = Enum(3)\n472:   val vsetvlState = RegInit(vs_idle)\n\
      473: \n474:   val firstVInstrFtqPtr = RegInit(0.U.asTypeOf(new FtqPtr))\n475:\
      \   val firstVInstrFtqOffset = RegInit(0.U.asTypeOf(UInt(log2Up(PredictWidth).W)))\n\
      476:   val firstVInstrRobIdx = RegInit(0.U.asTypeOf(new RobPtr))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 475-486
    context: "475:   val firstVInstrFtqOffset = RegInit(0.U.asTypeOf(UInt(log2Up(PredictWidth).W)))\n\
      476:   val firstVInstrRobIdx = RegInit(0.U.asTypeOf(new RobPtr))\n477: \n478:\
      \   val enq0 = io.enq.req(0)\n479:   val enq0IsVset = enq0.bits.isVset && enq0.bits.lastUop
      && canEnqueue(0)\n480:   val enq0IsVsetFlush = enq0IsVset && enq0.bits.flushPipe\n\
      481:   val enqIsVInstrVec = io.enq.req.zip(canEnqueue).map { case (req, fire)
      => FuType.isVArith(req.bits.fuType) && fire }\n482:   // for vs_idle\n483: \
      \  val firstVInstrIdle = PriorityMux(enqIsVInstrVec.zip(io.enq.req).drop(1)
      :+ (true.B, 0.U.asTypeOf(io.enq.req(0).cloneType)))\n484:   // for vs_waitVinstr\n\
      485:   val enqIsVInstrOrVset = (enqIsVInstrVec(0) || enq0IsVset) +: enqIsVInstrVec.drop(1)\n\
      486:   val firstVInstrWait = PriorityMux(enqIsVInstrOrVset, io.enq.req)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 495-516
    context: "495:       firstVInstrRobIdx := firstVInstrWait.bits.robIdx\n496:  \
      \   }\n497:   }\n498: \n499:   val hasVInstrAfterI = Cat(enqIsVInstrVec(0)).orR\n\
      500:   when(vsetvlState === vs_idle && !io.redirect.valid) {\n501:     when(enq0IsVsetFlush)
      {\n502:       vsetvlState := Mux(hasVInstrAfterI, vs_waitFlush, vs_waitVinstr)\n\
      503:     }\n504:   }.elsewhen(vsetvlState === vs_waitVinstr) {\n505:     when(io.redirect.valid)
      {\n506:       vsetvlState := vs_idle\n507:     }.elsewhen(Cat(enqIsVInstrOrVset).orR)
      {\n508:       vsetvlState := vs_waitFlush\n509:     }\n510:   }.elsewhen(vsetvlState
      === vs_waitFlush) {\n511:     when(io.redirect.valid) {\n512:       vsetvlState
      := vs_idle\n513:     }\n514:   }\n515: \n516:   // lqEnq"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 512-522
    context: "512:       vsetvlState := vs_idle\n513:     }\n514:   }\n515: \n516:\
      \   // lqEnq\n517:   io.debugEnqLsq.needAlloc.map(_(0)).zip(io.debugEnqLsq.req).foreach
      { case (alloc, req) =>\n518:     when(io.debugEnqLsq.canAccept && alloc && req.valid)
      {\n519:       debug_microOp(req.bits.robIdx.value).lqIdx := req.bits.lqIdx\n\
      520:       debug_lqIdxValid(req.bits.robIdx.value) := true.B\n521:     }\n522:\
      \   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 553-564
    context: "553: \n554:   val writebackNum = PopCount(exuWBs.map(_.valid))\n555:\
      \   XSInfo(writebackNum =/= 0.U, \"writebacked %d insts\\n\", writebackNum)\n\
      556: \n557:   for (i <- 0 until LoadPipelineWidth) {\n558:     when(RegNext(io.lsq.mmio(i)))
      {\n559:       robEntries(RegEnable(io.lsq.uop(i).robIdx, io.lsq.mmio(i)).value).mmio
      := true.B\n560:     }\n561:   }\n562: \n563: \n564:   /**"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 569-584
    context: "569:   val deqPtrEntry = rawInfo(0)\n570:   val deqPtrEntryValid = deqPtrEntry.commit_v\n\
      571:   val deqHasFlushed = RegInit(false.B)\n572:   val intrBitSetReg = RegNext(io.csr.intrBitSet)\n\
      573:   val intrEnable = intrBitSetReg && !hasWaitForward && deqPtrEntry.interrupt_safe
      && !deqHasFlushed\n574:   val deqNeedFlush = deqPtrEntry.needFlush && deqPtrEntry.commit_v
      && deqPtrEntry.commit_w\n575:   val deqHitExceptionGenState = exceptionDataRead.valid
      && exceptionDataRead.bits.robIdx === deqPtr\n576:   val deqNeedFlushAndHitExceptionGenState
      = deqNeedFlush && deqHitExceptionGenState\n577:   val exceptionGenStateIsException
      = exceptionDataRead.bits.exceptionVec.asUInt.orR || exceptionDataRead.bits.singleStep
      || TriggerAction.isDmode(exceptionDataRead.bits.trigger)\n578:   val deqHasException
      = deqNeedFlushAndHitExceptionGenState && exceptionGenStateIsException && (!deqPtrEntry.isVls
      || RegNext(RegNext(deqPtrEntry.commit_w)))\n579:   val deqHasFlushPipe = deqNeedFlushAndHitExceptionGenState
      && exceptionDataRead.bits.flushPipe && !deqHasException && (!deqPtrEntry.isVls
      || RegNext(RegNext(deqPtrEntry.commit_w)))\n580:   val deqHasReplayInst = deqNeedFlushAndHitExceptionGenState
      && exceptionDataRead.bits.replayInst\n581:   val deqIsVlsException = deqHasException
      && deqPtrEntry.isVls && !exceptionDataRead.bits.isEnqExcp\n582:   // delay 2
      cycle wait exceptionGen out\n583:   // vls exception can be committed only when
      RAB commit all its reg pairs\n584:   deqVlsCanCommit := RegNext(RegNext(deqIsVlsException
      && deqPtrEntry.commit_w)) && rab.io.status.commitEnd"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 583-596
    context: "583:   // vls exception can be committed only when RAB commit all its
      reg pairs\n584:   deqVlsCanCommit := RegNext(RegNext(deqIsVlsException && deqPtrEntry.commit_w))
      && rab.io.status.commitEnd\n585: \n586:   // lock at assertion of deqVlsExceptionNeedCommit
      until condition not assert\n587:   val deqVlsExcpLock = RegInit(false.B)\n588:\
      \   val handleVlsExcp = deqIsVlsException && deqVlsCanCommit && !deqVlsExcpLock
      && state === s_idle\n589:   when(handleVlsExcp) {\n590:     deqVlsExcpLock :=
      true.B\n591:   }.elsewhen(deqPtrVec.head =/= deqPtrVec_next.head) {\n592:  \
      \   deqVlsExcpLock := false.B\n593:   }\n594: \n595:   // Only assert once when
      deqVlsExcp occurs until condition not assert to avoid multi message passed to
      RAB\n596:   when (deqVlsExceptionNeedCommit) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 612-638
    context: "612:   val needModifyFtqIdxOffset = false.B\n613:   io.isVsetFlushPipe
      := isVsetFlushPipe\n614:   io.toDecode.isResumeVType := vtypeBuffer.io.toDecode.isResumeVType
      || isVsetFlushPipeReg\n615:   // io.flushOut will trigger redirect at the next
      cycle.\n616:   // Block any redirect or commit at the next cycle.\n617:   val
      lastCycleFlush = RegNext(io.flushOut.valid)\n618: \n619:   io.flushOut.valid
      := (state === s_idle) && deqPtrEntryValid && (intrEnable || deqHasException
      && (!deqIsVlsException || deqVlsCanCommit) || isFlushPipe) && !lastCycleFlush\n\
      620:   io.flushOut.bits := DontCare\n621:   io.flushOut.bits.isRVC := deqPtrEntry.isRVC\n\
      622:   io.flushOut.bits.robIdx := Mux(needModifyFtqIdxOffset, firstVInstrRobIdx,
      deqPtr)\n623:   io.flushOut.bits.ftqIdx := Mux(needModifyFtqIdxOffset, firstVInstrFtqPtr,
      deqPtrEntry.ftqIdx)\n624:   io.flushOut.bits.ftqOffset := Mux(needModifyFtqIdxOffset,
      firstVInstrFtqOffset, deqPtrEntry.ftqOffset)\n625:   io.flushOut.bits.level
      := Mux(deqHasReplayInst || intrEnable || deqHasException || needModifyFtqIdxOffset,
      RedirectLevel.flush, RedirectLevel.flushAfter) // TODO use this to implement
      \"exception next\"\n626:   io.flushOut.bits.interrupt := true.B\n627:   XSPerfAccumulate(\"\
      flush_num\", io.flushOut.valid)\n628:   XSPerfAccumulate(\"interrupt_num\",
      io.flushOut.valid && intrEnable)\n629:   XSPerfAccumulate(\"exception_num\"\
      , io.flushOut.valid && deqHasException)\n630:   XSPerfAccumulate(\"flush_pipe_num\"\
      , io.flushOut.valid && isFlushPipe)\n631:   XSPerfAccumulate(\"replay_inst_num\"\
      , io.flushOut.valid && isFlushPipe && deqHasReplayInst)\n632: \n633:   val exceptionHappen
      = (state === s_idle) && deqPtrEntryValid && (intrEnable || deqHasException &&
      (!deqIsVlsException || deqVlsCanCommit)) && !lastCycleFlush\n634:   io.exception.valid
      := RegNext(exceptionHappen)\n635:   io.exception.bits.pc := RegEnable(debug_deqUop.pc,
      exceptionHappen)\n636:   io.exception.bits.gpaddr := io.readGPAMemData.gpaddr\n\
      637:   io.exception.bits.isForVSnonLeafPTE := io.readGPAMemData.isForVSnonLeafPTE\n\
      638:   io.exception.bits.instr := RegEnable(debug_deqUop.instr, exceptionHappen)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 634-644
    context: "634:   io.exception.valid := RegNext(exceptionHappen)\n635:   io.exception.bits.pc
      := RegEnable(debug_deqUop.pc, exceptionHappen)\n636:   io.exception.bits.gpaddr
      := io.readGPAMemData.gpaddr\n637:   io.exception.bits.isForVSnonLeafPTE := io.readGPAMemData.isForVSnonLeafPTE\n\
      638:   io.exception.bits.instr := RegEnable(debug_deqUop.instr, exceptionHappen)\n\
      639:   io.exception.bits.commitType := RegEnable(deqPtrEntry.commitType, exceptionHappen)\n\
      640:   io.exception.bits.exceptionVec := RegEnable(exceptionDataRead.bits.exceptionVec,
      exceptionHappen)\n641:   // fetch trigger fire or execute ebreak\n642:   io.exception.bits.isPcBkpt
      := RegEnable(\n643:     exceptionDataRead.bits.exceptionVec(ExceptionNO.EX_BP)
      && (\n644:       exceptionDataRead.bits.isEnqExcp ||"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 657-669
    context: "657:   // data will be one cycle after valid\n658:   io.readGPAMemAddr.valid
      := exceptionHappen\n659:   io.readGPAMemAddr.bits.ftqPtr := exceptionDataRead.bits.ftqPtr\n\
      660:   io.readGPAMemAddr.bits.ftqOffset := exceptionDataRead.bits.ftqOffset\n\
      661: \n662:   XSDebug(io.flushOut.valid,\n663:     p\"generate redirect: pc
      0x${Hexadecimal(io.exception.bits.pc)} intr $intrEnable \" +\n664:       p\"\
      excp $deqHasException flushPipe $isFlushPipe \" +\n665:       p\"Trap_target
      0x${Hexadecimal(io.csr.trapTarget.pc)} exceptionVec ${Binary(exceptionDataRead.bits.exceptionVec.asUInt)}\\\
      n\")\n666: \n667: \n668:   /**\n669:    * Commits (and walk)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 670-684
    context: "670:    * They share the same width.\n671:    */\n672:   // T redirect.valid,
      T+1 use walkPtrVec read robEntries, T+2 start walk, shouldWalkVec used in T+2\n\
      673:   val shouldWalkVec = Wire(Vec(CommitWidth,Bool()))\n674:   val walkingPtrVec
      = RegNext(walkPtrVec)\n675:   when(io.redirect.valid){\n676:     shouldWalkVec
      := 0.U.asTypeOf(shouldWalkVec)\n677:   }.elsewhen(RegNext(io.redirect.valid)){\n\
      678:     shouldWalkVec := 0.U.asTypeOf(shouldWalkVec)\n679:   }.elsewhen(state
      === s_walk){\n680:     shouldWalkVec := VecInit(walkingPtrVec.map(_ <= lastWalkPtr).zip(donotNeedWalk).map(x
      => x._1 && !x._2))\n681:   }.otherwise(\n682:     shouldWalkVec := 0.U.asTypeOf(shouldWalkVec)\n\
      683:   )\n684:   val walkFinished = walkPtrTrue > lastWalkPtr"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 680-691
    context: "680:     shouldWalkVec := VecInit(walkingPtrVec.map(_ <= lastWalkPtr).zip(donotNeedWalk).map(x
      => x._1 && !x._2))\n681:   }.otherwise(\n682:     shouldWalkVec := 0.U.asTypeOf(shouldWalkVec)\n\
      683:   )\n684:   val walkFinished = walkPtrTrue > lastWalkPtr\n685:   rab.io.fromRob.walkEnd
      := state === s_walk && walkFinished\n686:   vtypeBuffer.io.fromRob.walkEnd :=
      state === s_walk && walkFinished\n687: \n688:   require(RenameWidth <= CommitWidth)\n\
      689: \n690:   // wiring to csr\n691:   val (wflags, dirtyFs) = (0 until CommitWidth).map(i
      => {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 691-703
    context: "691:   val (wflags, dirtyFs) = (0 until CommitWidth).map(i => {\n692:\
      \     val v = io.commits.commitValid(i)\n693:     val info = io.commits.info(i)\n\
      694:     (v & info.wflags, v & info.dirtyFs)\n695:   }).unzip\n696:   val fflags
      = Wire(Valid(UInt(5.W)))\n697:   fflags.valid := io.commits.isCommit && VecInit(wflags).asUInt.orR\n\
      698:   fflags.bits := wflags.zip(fflagsDataRead).map({\n699:     case (w, f)
      => Mux(w, f, 0.U)\n700:   }).reduce(_ | _)\n701:   val dirtyVs = (0 until CommitWidth).map(i
      => {\n702:     val v = io.commits.commitValid(i)\n703:     val info = io.commits.info(i)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 701-712
    context: "701:   val dirtyVs = (0 until CommitWidth).map(i => {\n702:     val
      v = io.commits.commitValid(i)\n703:     val info = io.commits.info(i)\n704:\
      \     v & info.dirtyVs\n705:   })\n706:   val dirty_fs = io.commits.isCommit
      && VecInit(dirtyFs).asUInt.orR\n707:   val dirty_vs = io.commits.isCommit &&
      VecInit(dirtyVs).asUInt.orR\n708: \n709:   val resetVstart = dirty_vs && !io.vstartIsZero\n\
      710: \n711:   vecExcpInfo.valid := exceptionHappen && !intrEnable && exceptionDataRead.bits.vstartEn
      && exceptionDataRead.bits.isVecLoad && !exceptionDataRead.bits.isEnqExcp\n712:\
      \   when (exceptionHappen) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 723-733
    context: "723: \n724:   io.csr.vstart.valid := RegNext(Mux(exceptionHappen &&
      deqHasException, exceptionDataRead.bits.vstartEn, resetVstart))\n725:   io.csr.vstart.bits
      := RegNext(Mux(exceptionHappen && deqHasException, exceptionDataRead.bits.vstart,
      0.U))\n726: \n727:   val vxsat = Wire(Valid(Bool()))\n728:   vxsat.valid :=
      io.commits.isCommit && vxsat.bits\n729:   vxsat.bits := io.commits.commitValid.zip(vxsatDataRead).map
      {\n730:     case (valid, vxsat) => valid & vxsat\n731:   }.reduce(_ | _)\n732:\
      \ \n733:   // when mispredict branches writeback, stop commit in the next 2
      cycles"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 730-741
    context: "730:     case (valid, vxsat) => valid & vxsat\n731:   }.reduce(_ | _)\n\
      732: \n733:   // when mispredict branches writeback, stop commit in the next
      2 cycles\n734:   // TODO: don't check all exu write back\n735:   val misPredWb
      = Cat(VecInit(redirectWBs.map(wb =>\n736:     wb.bits.redirect.get.bits.cfiUpdate.isMisPred
      && wb.bits.redirect.get.valid && wb.valid\n737:   ).toSeq)).orR\n738:   val
      misPredBlockCounter = Reg(UInt(3.W))\n739:   misPredBlockCounter := Mux(misPredWb,\n\
      740:     \"b111\".U,\n741:     misPredBlockCounter >> 1.U"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 741-756
    context: "741:     misPredBlockCounter >> 1.U\n742:   )\n743:   val misPredBlock
      = misPredBlockCounter(0)\n744:   val deqFlushBlockCounter = Reg(UInt(3.W))\n\
      745:   val deqFlushBlock = deqFlushBlockCounter(0)\n746:   val deqHasCommitted
      = io.commits.isCommit && io.commits.commitValid(0)\n747:   // TODO *** WARNING
      ***\n748:   // Blocking commit. Don't change this before we fully understand
      the logic.\n749:   val deqHitRedirectReg = RegNext(io.redirect.valid && io.redirect.bits.robIdx
      === deqPtr) || RegNext(RegNext(io.redirect.valid && io.redirect.bits.robIdx
      === deqPtr))\n750:   val criticalErrorState = io.csr.criticalErrorState\n751:\
      \   when(deqNeedFlush && deqHitRedirectReg){\n752:     deqFlushBlockCounter
      := \"b111\".U\n753:   }.otherwise{\n754:     deqFlushBlockCounter := deqFlushBlockCounter
      >> 1.U\n755:   }\n756:   when(deqHasCommitted){"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 753-771
    context: "753:   }.otherwise{\n754:     deqFlushBlockCounter := deqFlushBlockCounter
      >> 1.U\n755:   }\n756:   when(deqHasCommitted){\n757:     deqHasFlushed := false.B\n\
      758:   }.elsewhen(deqNeedFlush && io.flushOut.valid && !io.flushOut.bits.flushItself()){\n\
      759:     deqHasFlushed := true.B\n760:   }\n761:   val traceBlock = io.trace.blockCommit\n\
      762:   val blockCommit = misPredBlock || lastCycleFlush || hasWFI || io.redirect.valid
      ||\n763:     (deqNeedFlush && !deqHasFlushed) || deqFlushBlock || criticalErrorState
      || traceBlock\n764: \n765:   io.commits.isWalk := state === s_walk\n766:   io.commits.isCommit
      := state === s_idle && !blockCommit\n767: \n768:   val walk_v = VecInit(walkingPtrVec.map(ptr
      => robEntries(ptr.value).valid))\n769:   val commit_vDeqGroup = VecInit(robDeqGroup.map(_.commit_v))\n\
      770:   val commit_wDeqGroup = VecInit(robDeqGroup.map(_.commit_w))\n771:   val
      realCommitLast = deqPtrVec(0).lineHeadPtr + Fill(bankAddrWidth, 1.U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 768-778
    context: "768:   val walk_v = VecInit(walkingPtrVec.map(ptr => robEntries(ptr.value).valid))\n\
      769:   val commit_vDeqGroup = VecInit(robDeqGroup.map(_.commit_v))\n770:   val
      commit_wDeqGroup = VecInit(robDeqGroup.map(_.commit_w))\n771:   val realCommitLast
      = deqPtrVec(0).lineHeadPtr + Fill(bankAddrWidth, 1.U)\n772:   val commit_block
      = VecInit((0 until CommitWidth).map(i => !commit_wDeqGroup(i) && !hasCommitted(i)))\n\
      773:   val allowOnlyOneCommit = VecInit(robDeqGroup.map(x => x.commit_v && x.needFlush)).asUInt.orR
      || intrBitSetReg\n774:   // for instructions that may block others, we don't
      allow them to commit\n775:   io.commits.commitValid := PriorityMux(commitValidThisLine,
      (0 until CommitWidth).map(i => (commitValidThisLine.asUInt >> i).asUInt.asTypeOf(io.commits.commitValid)))\n\
      776: \n777:   for (i <- 0 until CommitWidth) {\n778:     // defaults: state
      === s_idle and instructions commit"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 781-801
    context: "781:     val isBlockedByOlder = if (i != 0) commit_block.asUInt(i, 0).orR
      || allowOnlyOneCommit && !hasCommitted.asUInt(i - 1, 0).andR else false.B\n\
      782:     commitValidThisLine(i) := commit_vDeqGroup(i) && commit_wDeqGroup(i)
      && !isBlocked && !isBlockedByOlder && !hasCommitted(i)\n783:     io.commits.info(i)
      := commitInfo(i)\n784:     io.commits.robIdx(i) := deqPtrVec(i)\n785:     val
      deqDebugInst = debug_microOp(deqPtrVec(i).value)\n786:     PerfCCT.commitInstMeta(i.U,
      deqDebugInst.debug_seqNum, deqDebugInst.instrSize, io.commits.isCommit && io.commits.commitValid(i),
      clock, reset)\n787: \n788:     io.commits.walkValid(i) := shouldWalkVec(i)\n\
      789:     XSError(\n790:       state === s_walk &&\n791:       io.commits.isWalk
      && state === s_walk && shouldWalkVec(i) &&\n792:       !walk_v(i),\n793:   \
      \    s\"The walking entry($i) should be valid\\n\")\n794: \n795:     XSInfo(io.commits.isCommit
      && io.commits.commitValid(i),\n796:       \"retired pc %x wen %d ldest %d pdest
      %x data %x fflags: %b vxsat: %b\\n\",\n797:       debug_microOp(deqPtrVec(i).value).pc,\n\
      798:       io.commits.info(i).rfWen,\n799:       io.commits.info(i).debug_ldest.getOrElse(0.U),\n\
      800:       io.commits.info(i).debug_pdest.getOrElse(0.U),\n801:       debug_exuData(deqPtrVec(i).value),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 800-810
    context: "800:       io.commits.info(i).debug_pdest.getOrElse(0.U),\n801:    \
      \   debug_exuData(deqPtrVec(i).value),\n802:       fflagsDataRead(i),\n803:\
      \       vxsatDataRead(i)\n804:     )\n805:     XSInfo(state === s_walk && io.commits.walkValid(i),
      \"walked pc %x wen %d ldst %d data %x\\n\",\n806:       debug_microOp(walkPtrVec(i).value).pc,\n\
      807:       io.commits.info(i).rfWen,\n808:       io.commits.info(i).debug_ldest.getOrElse(0.U),\n\
      809:       debug_exuData(walkPtrVec(i).value)\n810:     )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 809-819
    context: "809:       debug_exuData(walkPtrVec(i).value)\n810:     )\n811:   }\n\
      812: \n813:   // sync fflags/dirty_fs/vxsat to csr\n814:   io.csr.fflags   :=
      RegNextWithEnable(fflags)\n815:   io.csr.dirty_fs := GatedValidRegNext(dirty_fs)\n\
      816:   io.csr.dirty_vs := GatedValidRegNext(dirty_vs)\n817:   io.csr.vxsat \
      \   := RegNextWithEnable(vxsat)\n818: \n819:   // commit load/store to lsq"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 815-839
    context: "815:   io.csr.dirty_fs := GatedValidRegNext(dirty_fs)\n816:   io.csr.dirty_vs
      := GatedValidRegNext(dirty_vs)\n817:   io.csr.vxsat    := RegNextWithEnable(vxsat)\n\
      818: \n819:   // commit load/store to lsq\n820:   val ldCommitVec = VecInit((0
      until CommitWidth).map(i => io.commits.commitValid(i) && io.commits.info(i).commitType
      === CommitType.LOAD))\n821:   // TODO: Check if meet the require that only set
      scommit when commit scala store uop\n822:   val stCommitVec = VecInit((0 until
      CommitWidth).map(i => io.commits.commitValid(i) && io.commits.info(i).commitType
      === CommitType.STORE && !robEntries(deqPtrVec(i).value).vls ))\n823:   io.lsq.lcommit
      := RegNext(Mux(io.commits.isCommit, PopCount(ldCommitVec), 0.U))\n824:   io.lsq.scommit
      := RegNext(Mux(io.commits.isCommit, PopCount(stCommitVec), 0.U))\n825:   //
      indicate a pending load or store\n826:   io.lsq.pendingMMIOld := RegNext(io.commits.isCommit
      && io.commits.info(0).commitType === CommitType.LOAD && deqPtrEntryValid &&
      deqPtrEntry.mmio)\n827:   io.lsq.pendingld := RegNext(io.commits.isCommit &&
      io.commits.info(0).commitType === CommitType.LOAD && deqPtrEntryValid)\n828:\
      \   // TODO: Check if need deassert pendingst when it is vst\n829:   io.lsq.pendingst
      := RegNext(io.commits.isCommit && io.commits.info(0).commitType === CommitType.STORE
      && deqPtrEntryValid)\n830:   // TODO: Check if set correctly when vector store
      is at the head of ROB\n831:   io.lsq.pendingVst := RegNext(io.commits.isCommit
      && io.commits.info(0).commitType === CommitType.STORE && deqPtrEntryValid &&
      deqPtrEntry.vls)\n832:   io.lsq.commit := RegNext(io.commits.isCommit && io.commits.commitValid(0))\n\
      833:   io.lsq.pendingPtr := RegNext(deqPtr)\n834:   io.lsq.pendingPtrNext :=
      RegNext(deqPtrVec_next.head)\n835: \n836:   /**\n837:    * state changes\n838:\
      \    * (1) redirect: switch to s_walk\n839:    * (2) walk: when walking comes
      to the end, switch to s_idle"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 836-857
    context: "836:   /**\n837:    * state changes\n838:    * (1) redirect: switch
      to s_walk\n839:    * (2) walk: when walking comes to the end, switch to s_idle\n\
      840:    */\n841:   state_next := Mux(\n842:     io.redirect.valid || RegNext(io.redirect.valid),
      s_walk,\n843:     Mux(\n844:       state === s_walk && walkFinished && rab.io.status.walkEnd
      && vtypeBuffer.io.status.walkEnd, s_idle,\n845:       state\n846:     )\n847:\
      \   )\n848:   XSPerfAccumulate(\"s_idle_to_idle\", state === s_idle && state_next
      === s_idle)\n849:   XSPerfAccumulate(\"s_idle_to_walk\", state === s_idle &&
      state_next === s_walk)\n850:   XSPerfAccumulate(\"s_walk_to_idle\", state ===
      s_walk && state_next === s_idle)\n851:   XSPerfAccumulate(\"s_walk_to_walk\"\
      , state === s_walk && state_next === s_walk)\n852:   state := state_next\n853:\
      \ \n854:   /**\n855:    * pointers and counters\n856:    */\n857:   val deqPtrGenModule
      = Module(new NewRobDeqPtrWrapper)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 853-866
    context: "853: \n854:   /**\n855:    * pointers and counters\n856:    */\n857:\
      \   val deqPtrGenModule = Module(new NewRobDeqPtrWrapper)\n858:   deqPtrGenModule.io.state
      := state\n859:   deqPtrGenModule.io.deq_v := commit_vDeqGroup\n860:   deqPtrGenModule.io.deq_w
      := commit_wDeqGroup\n861:   deqPtrGenModule.io.exception_state := exceptionDataRead\n\
      862:   deqPtrGenModule.io.intrBitSetReg := intrBitSetReg\n863:   deqPtrGenModule.io.hasNoSpecExec
      := hasWaitForward\n864:   deqPtrGenModule.io.allowOnlyOneCommit := allowOnlyOneCommit\n\
      865:   deqPtrGenModule.io.interrupt_safe := robDeqGroup(deqPtr.value(bankAddrWidth-1,0)).interrupt_safe\n\
      866:   deqPtrGenModule.io.blockCommit := blockCommit"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 868-878
    context: "868:   deqPtrGenModule.io.allCommitted := allCommitted\n869:   deqPtrVec
      := deqPtrGenModule.io.out\n870:   deqPtrVec_next := deqPtrGenModule.io.next_out\n\
      871: \n872:   val enqPtrGenModule = Module(new RobEnqPtrWrapper)\n873:   enqPtrGenModule.io.redirect
      := io.redirect\n874:   enqPtrGenModule.io.allowEnqueue := allowEnqueue && rab.io.canEnq
      && !io.fromVecExcpMod.busy\n875:   enqPtrGenModule.io.hasBlockBackward := hasBlockBackward\n\
      876:   enqPtrGenModule.io.enq := VecInit(io.enq.req.map(req => req.valid &&
      req.bits.firstUop))\n877:   enqPtrVec := enqPtrGenModule.io.out\n878: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 881-909
    context: "881:   // (2) walk: move forwards\n882:   val deqPtrReadBank = deqPtrVec_next(0).lineHeadPtr\n\
      883:   val deqPtrVecForWalk = VecInit((0 until CommitWidth).map(i => deqPtrReadBank
      + i.U))\n884:   val snapPtrReadBank = snapshots(io.snpt.snptSelect)(0).lineHeadPtr\n\
      885:   val snapPtrVecForWalk = VecInit((0 until CommitWidth).map(i => snapPtrReadBank
      + i.U))\n886:   val walkPtrVec_next: Vec[RobPtr] = Mux(io.redirect.valid,\n\
      887:     Mux(io.snpt.useSnpt, snapPtrVecForWalk, deqPtrVecForWalk),\n888:  \
      \   Mux((state === s_walk) && !walkFinished, VecInit(walkPtrVec.map(_ + CommitWidth.U)),
      walkPtrVec)\n889:   )\n890:   val walkPtrTrue_next: RobPtr = Mux(io.redirect.valid,\n\
      891:     Mux(io.snpt.useSnpt, snapshots(io.snpt.snptSelect)(0), deqPtrVec_next(0)),\n\
      892:     Mux((state === s_walk) && !walkFinished, walkPtrVec_next.head, walkPtrTrue)\n\
      893:   )\n894:   walkPtrHead := walkPtrVec_next.head\n895:   walkPtrVec := walkPtrVec_next\n\
      896:   walkPtrTrue := walkPtrTrue_next\n897:   // T io.redirect.valid, T+1 walkPtrLowBits
      update, T+2 donotNeedWalk update\n898:   val walkPtrLowBits = Reg(UInt(bankAddrWidth.W))\n\
      899:   when(io.redirect.valid){\n900:     walkPtrLowBits := Mux(io.snpt.useSnpt,
      snapshots(io.snpt.snptSelect)(0).value(bankAddrWidth-1, 0), deqPtrVec_next(0).value(bankAddrWidth-1,
      0))\n901:   }\n902:   when(io.redirect.valid) {\n903:     donotNeedWalk := Fill(donotNeedWalk.length,
      true.B).asTypeOf(donotNeedWalk)\n904:   }.elsewhen(RegNext(io.redirect.valid)){\n\
      905:     donotNeedWalk := (0 until CommitWidth).map(i => (i.U < walkPtrLowBits))\n\
      906:   }.otherwise{\n907:     donotNeedWalk := 0.U.asTypeOf(donotNeedWalk)\n\
      908:   }\n909:   walkDestSizeDeqGroup.zip(walkPtrVec_next).map {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 913-925
    context: "913:   val commitCnt = PopCount(io.commits.commitValid)\n914: \n915:\
      \   allowEnqueue := numValidEntries + dispatchNum <= (RobSize - RenameWidth).U\n\
      916:   allowEnqueueForDispatch := numValidEntries + dispatchNum <= (RobSize
      - 2 * RenameWidth).U\n917: \n918:   val redirectWalkDistance = distanceBetween(io.redirect.bits.robIdx,
      deqPtrVec_next(0))\n919:   when(io.redirect.valid) {\n920:     lastWalkPtr :=
      Mux(io.redirect.bits.flushItself(), io.redirect.bits.robIdx - 1.U, io.redirect.bits.robIdx)\n\
      921:   }\n922: \n923: \n924:   /**\n925:    * States"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 929-948
    context: "929:    * All states: (1) valid; (2) writebacked; (3) flagBkup\n930:\
      \    */\n931: \n932:   val deqPtrGroup = Wire(Vec(2 * CommitWidth, new RobPtr))\n\
      933:   deqPtrGroup.zipWithIndex.map { case (deq, i) => deq := deqPtrVec(0) +
      i.U }\n934:   val commitReadAddr = Mux(state === s_idle, VecInit(deqPtrVec.map(_.value)),
      VecInit(walkPtrVec.map(_.value)))\n935: \n936:   val redirectValidReg = RegNext(io.redirect.valid)\n\
      937:   val redirectBegin = Reg(UInt(log2Up(RobSize).W))\n938:   val redirectEnd
      = Reg(UInt(log2Up(RobSize).W))\n939:   val redirectAll = RegInit(false.B)\n\
      940:   when(io.redirect.valid){\n941:     redirectBegin := Mux(io.redirect.bits.flushItself(),
      io.redirect.bits.robIdx.value - 1.U, io.redirect.bits.robIdx.value)\n942:  \
      \   redirectEnd := enqPtr.value\n943:     redirectAll := io.redirect.bits.flushItself()
      && (io.redirect.bits.robIdx.value === enqPtr.value) && (io.redirect.bits.robIdx.flag
      ^ enqPtr.flag)\n944:   }\n945: \n946:   // update robEntries valid\n947:   for
      (i <- 0 until RobSize) {\n948:     val enqOH = VecInit(canEnqueue.zip(allocatePtrVec.map(_.value
      === i.U)).map(x => x._1 && x._2))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 944-965
    context: "944:   }\n945: \n946:   // update robEntries valid\n947:   for (i <-
      0 until RobSize) {\n948:     val enqOH = VecInit(canEnqueue.zip(allocatePtrVec.map(_.value
      === i.U)).map(x => x._1 && x._2))\n949:     val commitCond = io.commits.isCommit
      && io.commits.commitValid.zip(deqPtrVec.map(_.value === i.U)).map(x => x._1
      && x._2).reduce(_ || _)\n950:     assert(PopCount(enqOH) < 2.U, s\"robEntries$i
      enqOH is not one hot\")\n951:     val needFlush = redirectValidReg && (Mux(\n\
      952:       redirectEnd > redirectBegin,\n953:       (i.U > redirectBegin) &&
      (i.U < redirectEnd),\n954:       (i.U > redirectBegin) || (i.U < redirectEnd)\n\
      955:     ) || redirectAll)\n956:     when(commitCond) {\n957:       robEntries(i).valid
      := false.B\n958:     }.elsewhen(enqOH.asUInt.orR && !io.redirect.valid) {\n\
      959:       robEntries(i).valid := true.B\n960:     }.elsewhen(needFlush){\n\
      961:       robEntries(i).valid := false.B\n962:     }\n963:   }\n964: \n965:\
      \   // debug_inst update"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1014-1031
    context: "1014:     val canWbSeq = exuWBs.map(writeback => writeback.valid &&
      writeback.bits.robIdx.value === i.U)\n1015:     val canStdWbSeq = VecInit(stdWBs.map(writeback
      => writeback.valid && writeback.bits.robIdx.value === i.U))\n1016:     val wbCnt
      = Mux1H(canWbSeq, io.writebackNums.map(_.bits))\n1017: \n1018:     val canWbExceptionSeq
      = exceptionWBs.map(writeback => writeback.valid && writeback.bits.robIdx.value
      === i.U)\n1019:     val needFlush = robEntries(i).needFlush\n1020:     val needFlushWriteBack
      = Wire(Bool())\n1021:     needFlushWriteBack := Mux1H(canWbExceptionSeq, io.writebackNeedFlush)\n\
      1022:     when(robEntries(i).valid){\n1023:       needFlush := needFlush ||
      needFlushWriteBack\n1024:     }\n1025: \n1026:     when(robEntries(i).valid
      && (needFlush || needFlushWriteBack)) {\n1027:       // exception flush\n1028:\
      \       robEntries(i).uopNum := robEntries(i).uopNum - wbCnt\n1029:       robEntries(i).stdWritebacked
      := true.B\n1030:     }.elsewhen(!robEntries(i).valid && instCanEnqFlag) {\n\
      1031:       // enq set num of uops"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1039-1053
    context: "1039:         robEntries(i).stdWritebacked := true.B\n1040:       }\n\
      1041:     }\n1042: \n1043:     val fflagsCanWbSeq = fflags_wb.map(writeback
      => writeback.valid && writeback.bits.robIdx.value === i.U && writeback.bits.wflags.getOrElse(false.B))\n\
      1044:     val fflagsRes = fflagsCanWbSeq.zip(fflags_wb).map { case (canWb, wb)
      => Mux(canWb, wb.bits.fflags.get, 0.U) }.fold(false.B)(_ | _)\n1045:     when(isFirstEnq)
      {\n1046:       robEntries(i).fflags := 0.U\n1047:     }.elsewhen(fflagsRes.orR)
      {\n1048:       robEntries(i).fflags := robEntries(i).fflags | fflagsRes\n1049:\
      \     }\n1050: \n1051:     val vxsatCanWbSeq = vxsat_wb.map(writeback => writeback.valid
      && writeback.bits.robIdx.value === i.U)\n1052:     val vxsatRes = vxsatCanWbSeq.zip(vxsat_wb).map
      { case (canWb, wb) => Mux(canWb, wb.bits.vxsat.get, 0.U) }.fold(false.B)(_ |
      _)\n1053:     when(isFirstEnq) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1055-1065
    context: "1055:     }.elsewhen(vxsatRes.orR) {\n1056:       robEntries(i).vxsat
      := robEntries(i).vxsat | vxsatRes\n1057:     }\n1058: \n1059:     // trace\n\
      1060:     val taken = branchWBs.map(writeback => writeback.valid && writeback.bits.robIdx.value
      === i.U && writeback.bits.redirect.get.bits.cfiUpdate.taken).reduce(_ || _)\n\
      1061:     when(robEntries(i).valid && Itype.isBranchType(robEntries(i).traceBlockInPipe.itype)
      && taken){\n1062:       // BranchType code(notaken itype = 4) must be correctly
      replaced!\n1063:       robEntries(i).traceBlockInPipe.itype := Itype.Taken\n\
      1064:     }\n1065:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1087-1104
    context: "1087:     val canWbSeq = exuWBs.map(writeback => writeback.valid &&
      writeback.bits.robIdx.value === needUpdateRobIdx(i))\n1088:     val canStdWbSeq
      = VecInit(stdWBs.map(writeback => writeback.valid && writeback.bits.robIdx.value
      === needUpdateRobIdx(i)))\n1089:     val wbCnt = Mux1H(canWbSeq, io.writebackNums.map(_.bits))\n\
      1090: \n1091:     val canWbExceptionSeq = exceptionWBs.map(writeback => writeback.valid
      && (writeback.bits.robIdx.value === needUpdateRobIdx(i)))\n1092:     val needFlush
      = robBanksRdata(i).needFlush\n1093:     val needFlushWriteBack = Wire(Bool())\n\
      1094:     needFlushWriteBack := Mux1H(canWbExceptionSeq, io.writebackNeedFlush)\n\
      1095:     when(needUpdate(i).valid) {\n1096:       needUpdate(i).needFlush :=
      needFlush || needFlushWriteBack\n1097:     }\n1098: \n1099:     when(needUpdate(i).valid
      && (needFlush || needFlushWriteBack)) {\n1100:       // exception flush\n1101:\
      \       needUpdate(i).uopNum := robBanksRdata(i).uopNum - wbCnt\n1102:     \
      \  needUpdate(i).stdWritebacked := true.B\n1103:     }.elsewhen(!needUpdate(i).valid
      && instCanEnqFlag) {\n1104:       // enq set num of uops"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1111-1122
    context: "1111:         needUpdate(i).stdWritebacked := true.B\n1112:       }\n\
      1113:     }\n1114: \n1115:     val fflagsCanWbSeq = fflags_wb.map(writeback
      => writeback.valid && writeback.bits.robIdx.value === needUpdateRobIdx(i) &&
      writeback.bits.wflags.getOrElse(false.B))\n1116:     val fflagsRes = fflagsCanWbSeq.zip(fflags_wb).map
      { case (canWb, wb) => Mux(canWb, wb.bits.fflags.get, 0.U) }.fold(false.B)(_
      | _)\n1117:     needUpdate(i).fflags := Mux(!robBanksRdata(i).valid && instCanEnqFlag,
      0.U, robBanksRdata(i).fflags | fflagsRes)\n1118: \n1119:     val vxsatCanWbSeq
      = vxsat_wb.map(writeback => writeback.valid && writeback.bits.robIdx.value ===
      needUpdateRobIdx(i))\n1120:     val vxsatRes = vxsatCanWbSeq.zip(vxsat_wb).map
      { case (canWb, wb) => Mux(canWb, wb.bits.vxsat.get, 0.U) }.fold(false.B)(_ |
      _)\n1121:     needUpdate(i).vxsat := Mux(!robBanksRdata(i).valid && instCanEnqFlag,
      0.U, robBanksRdata(i).vxsat | vxsatRes)\n1122: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1119-1129
    context: "1119:     val vxsatCanWbSeq = vxsat_wb.map(writeback => writeback.valid
      && writeback.bits.robIdx.value === needUpdateRobIdx(i))\n1120:     val vxsatRes
      = vxsatCanWbSeq.zip(vxsat_wb).map { case (canWb, wb) => Mux(canWb, wb.bits.vxsat.get,
      0.U) }.fold(false.B)(_ | _)\n1121:     needUpdate(i).vxsat := Mux(!robBanksRdata(i).valid
      && instCanEnqFlag, 0.U, robBanksRdata(i).vxsat | vxsatRes)\n1122: \n1123:  \
      \   // trace\n1124:     val taken = branchWBs.map(writeback => writeback.valid
      && writeback.bits.robIdx.value === needUpdateRobIdx(i) && writeback.bits.redirect.get.bits.cfiUpdate.taken).reduce(_
      || _)\n1125:     when(robBanksRdata(i).valid && Itype.isBranchType(robBanksRdata(i).traceBlockInPipe.itype)
      && taken){\n1126:       // BranchType code(notaken itype = 4) must be correctly
      replaced!\n1127:       needUpdate(i).traceBlockInPipe.itype := Itype.Taken\n\
      1128:     }\n1129:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1138-1148
    context: "1138:       // For MMIO instructions, they should not trigger interrupts
      since they may\n1139:       // be sent to lower level before it writes back.\n\
      1140:       // However, we cannot determine whether a load/store instruction
      is MMIO.\n1141:       // Thus, we don't allow load/store instructions to trigger
      an interrupt.\n1142:       // TODO: support non-MMIO load-store instructions
      to trigger interrupts\n1143:       val allow_interrupts = !CommitType.isLoadStore(io.enq.req(i).bits.commitType)
      && !FuType.isFence(io.enq.req(i).bits.fuType) && !FuType.isCsr(io.enq.req(i).bits.fuType)
      && !FuType.isVset(io.enq.req(i).bits.fuType)\n1144:       robEntries(allocatePtrVec(i).value).interrupt_safe
      := allow_interrupts\n1145:     }\n1146:   }\n1147: \n1148:   /**"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1146-1162
    context: "1146:   }\n1147: \n1148:   /**\n1149:    * read and write of data modules\n\
      1150:    */\n1151:   val commitReadAddr_next = Mux(state_next === s_idle,\n\
      1152:     VecInit(deqPtrVec_next.map(_.value)),\n1153:     VecInit(walkPtrVec_next.map(_.value))\n\
      1154:   )\n1155: \n1156:   exceptionGen.io.redirect <> io.redirect\n1157:  \
      \ exceptionGen.io.flush := io.flushOut.valid\n1158: \n1159:   val canEnqueueEG
      = VecInit(io.enq.req.map(req => req.valid && io.enq.canAccept))\n1160:   for
      (i <- 0 until RenameWidth) {\n1161:     exceptionGen.io.enq(i).valid := canEnqueueEG(i)\n\
      1162:     exceptionGen.io.enq(i).bits.robIdx := io.enq.req(i).bits.robIdx"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1164-1174
    context: "1164:     exceptionGen.io.enq(i).bits.ftqOffset := io.enq.req(i).bits.ftqOffset\n\
      1165:     exceptionGen.io.enq(i).bits.exceptionVec := ExceptionNO.selectFrontend(io.enq.req(i).bits.exceptionVec)\n\
      1166:     exceptionGen.io.enq(i).bits.hasException := io.enq.req(i).bits.hasException\n\
      1167:     exceptionGen.io.enq(i).bits.isEnqExcp := io.enq.req(i).bits.hasException\n\
      1168:     exceptionGen.io.enq(i).bits.isFetchMalAddr := io.enq.req(i).bits.isFetchMalAddr\n\
      1169:     exceptionGen.io.enq(i).bits.flushPipe := io.enq.req(i).bits.flushPipe\n\
      1170:     exceptionGen.io.enq(i).bits.isVset := io.enq.req(i).bits.isVset\n\
      1171:     exceptionGen.io.enq(i).bits.replayInst := false.B\n1172:     XSError(canEnqueue(i)
      && io.enq.req(i).bits.replayInst, \"enq should not set replayInst\")\n1173:\
      \     exceptionGen.io.enq(i).bits.singleStep := io.enq.req(i).bits.singleStep\n\
      1174:     exceptionGen.io.enq(i).bits.crossPageIPFFix := io.enq.req(i).bits.crossPageIPFFix"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1200-1212
    context: "1200:     exc_wb.bits.ftqOffset       := 0.U.asTypeOf(exc_wb.bits.ftqOffset)\n\
      1201:     exc_wb.bits.exceptionVec    := wb.bits.exceptionVec.get\n1202:   \
      \  exc_wb.bits.hasException    := wb.bits.exceptionVec.get.asUInt.orR // Todo:
      use io.writebackNeedFlush(i) instead\n1203:     exc_wb.bits.isEnqExcp      \
      \ := false.B\n1204:     exc_wb.bits.isFetchMalAddr  := false.B\n1205:     exc_wb.bits.flushPipe\
      \       := wb.bits.flushPipe.getOrElse(false.B)\n1206:     exc_wb.bits.isVset\
      \          := false.B\n1207:     exc_wb.bits.replayInst      := wb.bits.replay.getOrElse(false.B)\n\
      1208:     exc_wb.bits.singleStep      := false.B\n1209:     exc_wb.bits.crossPageIPFFix
      := false.B\n1210:     val trigger = wb.bits.trigger.getOrElse(TriggerAction.None).asTypeOf(exc_wb.bits.trigger)\n\
      1211:     exc_wb.bits.trigger := trigger\n1212:     exc_wb.bits.vstartEn :=
      (if (wb.bits.vls.nonEmpty) wb.bits.exceptionVec.get.asUInt.orR || TriggerAction.isDmode(trigger)
      else 0.U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1221-1238
    context: "1221:     exc_wb.bits.vsew := wb.bits.vls.map(_.vpu.vsew).getOrElse(0.U)\n\
      1222:     exc_wb.bits.veew := wb.bits.vls.map(_.vpu.veew).getOrElse(0.U)\n1223:\
      \     exc_wb.bits.vlmul := wb.bits.vls.map(_.vpu.vlmul).getOrElse(0.U)\n1224:\
      \   }\n1225: \n1226:   fflagsDataRead := (0 until CommitWidth).map(i => robEntries(deqPtrVec(i).value).fflags)\n\
      1227:   vxsatDataRead := (0 until CommitWidth).map(i => robEntries(deqPtrVec(i).value).vxsat)\n\
      1228: \n1229:   val isCommit = io.commits.isCommit\n1230:   val isCommitReg
      = GatedValidRegNext(io.commits.isCommit)\n1231:   val instrCntReg = RegInit(0.U(64.W))\n\
      1232:   val fuseCommitCnt = PopCount(io.commits.commitValid.zip(io.commits.info).map
      { case (v, i) => RegEnable(v && CommitType.isFused(i.commitType), isCommit)
      })\n1233:   val trueCommitCnt = RegEnable(io.commits.commitValid.zip(io.commits.info).map
      { case (v, i) => Mux(v, i.instrSize, 0.U) }.reduce(_ +& _), isCommit) +& fuseCommitCnt\n\
      1234:   val retireCounter = Mux(isCommitReg, trueCommitCnt, 0.U)\n1235:   val
      instrCnt = instrCntReg + retireCounter\n1236:   when(isCommitReg){\n1237:  \
      \   instrCntReg := instrCnt\n1238:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1251-1266
    context: "1251:   val traceValids = io.trace.traceCommitInfo.blocks.map(_.valid)\n\
      1252:   val traceBlocks = io.trace.traceCommitInfo.blocks\n1253:   val traceBlockInPipe
      = io.trace.traceCommitInfo.blocks.map(_.bits.tracePipe)\n1254: \n1255:   for
      (i <- 0 until CommitWidth) {\n1256:     traceBlocks(i).bits.ftqIdx.foreach(_
      := rawInfo(i).ftqIdx)\n1257:     traceBlocks(i).bits.ftqOffset.foreach(_ :=
      rawInfo(i).ftqOffset)\n1258:     traceBlockInPipe(i).itype := rawInfo(i).traceBlockInPipe.itype\n\
      1259:     traceBlockInPipe(i).iretire := rawInfo(i).traceBlockInPipe.iretire\n\
      1260:     traceBlockInPipe(i).ilastsize := rawInfo(i).traceBlockInPipe.ilastsize\n\
      1261:     traceValids(i) := io.commits.isCommit && io.commits.commitValid(i)\n\
      1262:     // exception only occur in block(0).\n1263:     if(i == 0) {\n1264:\
      \       when(io.exception.valid){ // trace exception\n1265:         traceBlocks(i).bits.tracePipe.itype
      := Mux(io.exception.bits.isInterrupt,\n1266:           Itype.Interrupt,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1265-1275
    context: "1265:         traceBlocks(i).bits.tracePipe.itype := Mux(io.exception.bits.isInterrupt,\n\
      1266:           Itype.Interrupt,\n1267:           Itype.Exception\n1268:   \
      \      )\n1269:         traceValids(i) := true.B\n1270:         traceBlockInPipe(i).iretire
      := 0.U\n1271:       }\n1272:     }\n1273:   }\n1274: \n1275:   /**"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1292-1302
    context: "1292:     XSDebug(false, robEntries(i).valid && robEntries(i).isWritebacked,
      \"w \")\n1293:     XSDebug(false, robEntries(i).valid && !robEntries(i).isWritebacked,
      \"v \")\n1294:     if (i % 4 == 3) XSDebug(false, true.B, \"\\n\")\n1295:  \
      \ }\n1296: \n1297:   def ifCommit(counter: UInt): UInt = Mux(isCommit, counter,
      0.U)\n1298: \n1299:   def ifCommitReg(counter: UInt): UInt = Mux(isCommitReg,
      counter, 0.U)\n1300: \n1301:   val commitDebugUop = deqPtrVec.map(_.value).map(debug_microOp(_))\n\
      1302:   XSPerfAccumulate(\"clock_cycle\", 1.U, XSPerfLevel.CRITICAL)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1299-1335
    context: "1299:   def ifCommitReg(counter: UInt): UInt = Mux(isCommitReg, counter,
      0.U)\n1300: \n1301:   val commitDebugUop = deqPtrVec.map(_.value).map(debug_microOp(_))\n\
      1302:   XSPerfAccumulate(\"clock_cycle\", 1.U, XSPerfLevel.CRITICAL)\n1303:\
      \   QueuePerf(RobSize, numValidEntries, numValidEntries === RobSize.U)\n1304:\
      \   XSPerfAccumulate(\"commitUop\", ifCommit(commitCnt))\n1305:   XSPerfAccumulate(\"\
      commitInstr\", ifCommitReg(trueCommitCnt), XSPerfLevel.CRITICAL)\n1306:   XSPerfRolling(\"\
      ipc\", ifCommitReg(trueCommitCnt), 1000, clock, reset)\n1307:   XSPerfRolling(\"\
      cpi\", perfCnt = 1.U /*Cycle*/ , eventTrigger = ifCommitReg(trueCommitCnt),
      granularity = 1000, clock, reset)\n1308:   XSPerfAccumulate(\"commitInstrFused\"\
      , ifCommitReg(fuseCommitCnt))\n1309:   val commitIsLoad = io.commits.info.map(_.commitType).map(_
      === CommitType.LOAD)\n1310:   val commitLoadValid = io.commits.commitValid.zip(commitIsLoad).map
      { case (v, t) => v && t }\n1311:   XSPerfAccumulate(\"commitInstrLoad\", ifCommit(PopCount(commitLoadValid)))\n\
      1312:   val commitIsBranch = io.commits.info.map(_.commitType).map(_ === CommitType.BRANCH)\n\
      1313:   val commitBranchValid = io.commits.commitValid.zip(commitIsBranch).map
      { case (v, t) => v && t }\n1314:   XSPerfAccumulate(\"commitInstrBranch\", ifCommit(PopCount(commitBranchValid)))\n\
      1315:   val commitIsStore = io.commits.info.map(_.commitType).map(_ === CommitType.STORE)\n\
      1316:   XSPerfAccumulate(\"commitInstrStore\", ifCommit(PopCount(io.commits.commitValid.zip(commitIsStore).map
      { case (v, t) => v && t })))\n1317:   XSPerfAccumulate(\"writeback\", PopCount((0
      until RobSize).map(i => robEntries(i).valid && robEntries(i).isWritebacked)))\n\
      1318:   // XSPerfAccumulate(\"enqInstr\", PopCount(io.dp1Req.map(_.fire)))\n\
      1319:   // XSPerfAccumulate(\"d2rVnR\", PopCount(io.dp1Req.map(p => p.valid
      && !p.ready)))\n1320:   XSPerfAccumulate(\"walkInstr\", Mux(io.commits.isWalk,
      PopCount(io.commits.walkValid), 0.U))\n1321:   XSPerfAccumulate(\"walkCycleTotal\"\
      , state === s_walk)\n1322:   XSPerfAccumulate(\"waitRabWalkEnd\", state ===
      s_walk && walkFinished && !rab.io.status.walkEnd)\n1323:   private val walkCycle
      = RegInit(0.U(8.W))\n1324:   private val waitRabWalkCycle = RegInit(0.U(8.W))\n\
      1325:   walkCycle := Mux(io.redirect.valid, 0.U, Mux(state === s_walk, walkCycle
      + 1.U, 0.U))\n1326:   waitRabWalkCycle := Mux(state === s_walk && walkFinished,
      0.U, Mux(state === s_walk, walkCycle + 1.U, 0.U))\n1327: \n1328:   XSPerfHistogram(\"\
      walkRobCycleHist\", walkCycle, state === s_walk && walkFinished, 0, 32)\n1329:\
      \   XSPerfHistogram(\"walkRabExtraCycleHist\", waitRabWalkCycle, state === s_walk
      && walkFinished && rab.io.status.walkEnd, 0, 32)\n1330:   XSPerfHistogram(\"\
      walkTotalCycleHist\", walkCycle, state === s_walk && state_next === s_idle,
      0, 32)\n1331: \n1332:   private val deqNotWritebacked = robEntries(deqPtr.value).valid
      && !robEntries(deqPtr.value).isWritebacked\n1333:   private val deqStdNotWritebacked
      = robEntries(deqPtr.value).valid && !robEntries(deqPtr.value).stdWritebacked\n\
      1334:   private val deqUopNotWritebacked = robEntries(deqPtr.value).valid &&
      !robEntries(deqPtr.value).isUopWritebacked\n1335:   private val deqHeadInfo
      = debug_microOp(deqPtr.value)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1331-1341
    context: "1331: \n1332:   private val deqNotWritebacked = robEntries(deqPtr.value).valid
      && !robEntries(deqPtr.value).isWritebacked\n1333:   private val deqStdNotWritebacked
      = robEntries(deqPtr.value).valid && !robEntries(deqPtr.value).stdWritebacked\n\
      1334:   private val deqUopNotWritebacked = robEntries(deqPtr.value).valid &&
      !robEntries(deqPtr.value).isUopWritebacked\n1335:   private val deqHeadInfo
      = debug_microOp(deqPtr.value)\n1336:   val deqUopCommitType = debug_microOp(deqPtr.value).commitType\n\
      1337: \n1338:   XSPerfAccumulate(\"waitAluCycle\", deqNotWritebacked && deqHeadInfo.fuType
      === FuType.alu.U)\n1339:   XSPerfAccumulate(\"waitMulCycle\", deqNotWritebacked
      && deqHeadInfo.fuType === FuType.mul.U)\n1340:   XSPerfAccumulate(\"waitDivCycle\"\
      , deqNotWritebacked && deqHeadInfo.fuType === FuType.div.U)\n1341:   XSPerfAccumulate(\"\
      waitBrhCycle\", deqNotWritebacked && deqHeadInfo.fuType === FuType.brh.U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1361-1380
    context: "1361:     case(fuoptype,i) =>  XSPerfAccumulate(s\"waitVfalu_${i}Cycle\"\
      , deqStdNotWritebacked && deqHeadInfo.fuOpType === fuoptype && deqHeadInfo.fuType
      === FuType.vfalu.U)\n1362:   }\n1363: \n1364: \n1365: \n1366:   XSPerfAccumulate(\"\
      waitNormalCycle\", deqNotWritebacked && deqUopCommitType === CommitType.NORMAL)\n\
      1367:   XSPerfAccumulate(\"waitBranchCycle\", deqNotWritebacked && deqUopCommitType
      === CommitType.BRANCH)\n1368:   XSPerfAccumulate(\"waitLoadCycle\", deqNotWritebacked
      && deqUopCommitType === CommitType.LOAD)\n1369:   XSPerfAccumulate(\"waitStoreCycle\"\
      , deqNotWritebacked && deqUopCommitType === CommitType.STORE)\n1370:   XSPerfAccumulate(\"\
      robHeadPC\", io.commits.info(0).debug_pc.getOrElse(0.U))\n1371:   XSPerfAccumulate(\"\
      commitCompressCntAll\", PopCount(io.commits.commitValid.zip(io.commits.info).map
      { case (valid, info) => io.commits.isCommit && valid && info.instrSize > 1.U
      }))\n1372:   (2 to RenameWidth).foreach(i =>\n1373:     XSPerfAccumulate(s\"\
      commitCompressCnt${i}\", PopCount(io.commits.commitValid.zip(io.commits.info).map
      { case (valid, info) => io.commits.isCommit && valid && info.instrSize === i.U
      }))\n1374:   )\n1375:   XSPerfAccumulate(\"compressSize\", io.commits.commitValid.zip(io.commits.info).map
      { case (valid, info) => Mux(io.commits.isCommit && valid && info.instrSize >
      1.U, info.instrSize, 0.U) }.reduce(_ +& _))\n1376:   val dispatchLatency = commitDebugUop.map(uop
      => uop.debugInfo.dispatchTime - uop.debugInfo.renameTime)\n1377:   val enqRsLatency
      = commitDebugUop.map(uop => uop.debugInfo.enqRsTime - uop.debugInfo.dispatchTime)\n\
      1378:   val selectLatency = commitDebugUop.map(uop => uop.debugInfo.selectTime
      - uop.debugInfo.enqRsTime)\n1379:   val issueLatency = commitDebugUop.map(uop
      => uop.debugInfo.issueTime - uop.debugInfo.selectTime)\n1380:   val executeLatency
      = commitDebugUop.map(uop => uop.debugInfo.writebackTime - uop.debugInfo.issueTime)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1377-1387
    context: "1377:   val enqRsLatency = commitDebugUop.map(uop => uop.debugInfo.enqRsTime
      - uop.debugInfo.dispatchTime)\n1378:   val selectLatency = commitDebugUop.map(uop
      => uop.debugInfo.selectTime - uop.debugInfo.enqRsTime)\n1379:   val issueLatency
      = commitDebugUop.map(uop => uop.debugInfo.issueTime - uop.debugInfo.selectTime)\n\
      1380:   val executeLatency = commitDebugUop.map(uop => uop.debugInfo.writebackTime
      - uop.debugInfo.issueTime)\n1381:   val rsFuLatency = commitDebugUop.map(uop
      => uop.debugInfo.writebackTime - uop.debugInfo.enqRsTime)\n1382:   val commitLatency
      = commitDebugUop.map(uop => timer - uop.debugInfo.writebackTime)\n1383: \n1384:\
      \   def latencySum(cond: Seq[Bool], latency: Seq[UInt]): UInt = {\n1385:   \
      \  cond.zip(latency).map(x => Mux(x._1, x._2, 0.U)).reduce(_ +& _)\n1386:  \
      \ }\n1387: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1386-1406
    context: "1386:   }\n1387: \n1388:   for (fuType <- FuType.functionNameMap.keys)
      {\n1389:     val fuName = FuType.functionNameMap(fuType)\n1390:     val commitIsFuType
      = io.commits.commitValid.zip(commitDebugUop).map(x => x._1 && x._2.fuType ===
      fuType.U)\n1391:     XSPerfRolling(s\"ipc_futype_${fuName}\", ifCommit(PopCount(commitIsFuType)),
      1000, clock, reset)\n1392:     XSPerfAccumulate(s\"${fuName}_instr_cnt\", ifCommit(PopCount(commitIsFuType)))\n\
      1393:     XSPerfAccumulate(s\"${fuName}_latency_dispatch\", ifCommit(latencySum(commitIsFuType,
      dispatchLatency)))\n1394:     XSPerfAccumulate(s\"${fuName}_latency_enq_rs\"\
      , ifCommit(latencySum(commitIsFuType, enqRsLatency)))\n1395:     XSPerfAccumulate(s\"\
      ${fuName}_latency_select\", ifCommit(latencySum(commitIsFuType, selectLatency)))\n\
      1396:     XSPerfAccumulate(s\"${fuName}_latency_issue\", ifCommit(latencySum(commitIsFuType,
      issueLatency)))\n1397:     XSPerfAccumulate(s\"${fuName}_latency_execute\",
      ifCommit(latencySum(commitIsFuType, executeLatency)))\n1398:     XSPerfAccumulate(s\"\
      ${fuName}_latency_enq_rs_execute\", ifCommit(latencySum(commitIsFuType, rsFuLatency)))\n\
      1399:     XSPerfAccumulate(s\"${fuName}_latency_commit\", ifCommit(latencySum(commitIsFuType,
      commitLatency)))\n1400:   }\n1401:   XSPerfAccumulate(s\"redirect_use_snapshot\"\
      , io.redirect.valid && io.snpt.useSnpt)\n1402: \n1403:   // top-down info\n\
      1404:   io.debugTopDown.toCore.robHeadVaddr.valid := debug_lsTopdownInfo(deqPtr.value).s1.vaddr_valid\n\
      1405:   io.debugTopDown.toCore.robHeadVaddr.bits := debug_lsTopdownInfo(deqPtr.value).s1.vaddr_bits\n\
      1406:   io.debugTopDown.toCore.robHeadPaddr.valid := debug_lsTopdownInfo(deqPtr.value).s2.paddr_valid"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1403-1413
    context: "1403:   // top-down info\n1404:   io.debugTopDown.toCore.robHeadVaddr.valid
      := debug_lsTopdownInfo(deqPtr.value).s1.vaddr_valid\n1405:   io.debugTopDown.toCore.robHeadVaddr.bits
      := debug_lsTopdownInfo(deqPtr.value).s1.vaddr_bits\n1406:   io.debugTopDown.toCore.robHeadPaddr.valid
      := debug_lsTopdownInfo(deqPtr.value).s2.paddr_valid\n1407:   io.debugTopDown.toCore.robHeadPaddr.bits
      := debug_lsTopdownInfo(deqPtr.value).s2.paddr_bits\n1408:   io.debugTopDown.toDispatch.robTrueCommit
      := ifCommitReg(trueCommitCnt)\n1409:   io.debugTopDown.toDispatch.robHeadLsIssue
      := debug_lsIssue(deqPtr.value)\n1410:   io.debugTopDown.robHeadLqIdx.valid :=
      debug_lqIdxValid(deqPtr.value)\n1411:   io.debugTopDown.robHeadLqIdx.bits :=
      debug_microOp(deqPtr.value).lqIdx\n1412: \n1413:   // rolling"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1409-1424
    context: "1409:   io.debugTopDown.toDispatch.robHeadLsIssue := debug_lsIssue(deqPtr.value)\n\
      1410:   io.debugTopDown.robHeadLqIdx.valid := debug_lqIdxValid(deqPtr.value)\n\
      1411:   io.debugTopDown.robHeadLqIdx.bits := debug_microOp(deqPtr.value).lqIdx\n\
      1412: \n1413:   // rolling\n1414:   io.debugRolling.robTrueCommit := ifCommitReg(trueCommitCnt)\n\
      1415: \n1416:   // debug trigger for simulation\n1417:   if (backendParams.debugEn)
      {\n1418:     val debug_sim_trig = dontTouch(Wire(Bool()))\n1419:     debug_sim_trig
      := io.commits.isCommit && (io.commits.commitValid zip commitDebugUop map {\n\
      1420:       case (valid, uop) => valid && uop.debug_sim_trig.get\n1421:    \
      \ }).reduce(_ || _)\n1422:   }\n1423: \n1424:   /**"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1467-1477
    context: "1467: \n1468:   vldWBs.map{ vldWb =>\n1469:     val vldWbPdest  = vldWb.bits.pdest\n\
      1470:     val vldWbRobIdx = vldWb.bits.robIdx.value\n1471:     val vldWbvdIdx\
      \  = vldWb.bits.vls.get.vdIdx\n1472:     when (vldWb.fire && robEntries(vldWbRobIdx).valid
      && (vldWb.bits.vecWen.get || vldWb.bits.v0Wen.get)) {\n1473:       debug_VecOtherPdest(vldWbRobIdx)(vldWbvdIdx)
      := vldWbPdest\n1474:     }\n1475:   }\n1476: \n1477:   //difftest signals"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1473-1483
    context: "1473:       debug_VecOtherPdest(vldWbRobIdx)(vldWbvdIdx) := vldWbPdest\n\
      1474:     }\n1475:   }\n1476: \n1477:   //difftest signals\n1478:   val firstValidCommit
      = (deqPtr + PriorityMux(io.commits.commitValid, VecInit(List.tabulate(CommitWidth)(_.U(log2Up(CommitWidth).W))))).value\n\
      1479: \n1480:   val wdata = Wire(Vec(CommitWidth, UInt(XLEN.W)))\n1481:   val
      wpc = Wire(Vec(CommitWidth, UInt(XLEN.W)))\n1482: \n1483:   for (i <- 0 until
      CommitWidth) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1494-1504
    context: "1494:     val dt_exuDebug = Reg(Vec(RobSize, new DebugBundle))\n1495:\
      \     for (i <- 0 until RenameWidth) {\n1496:       when(canEnqueue(i)) {\n\
      1497:         dt_eliminatedMove(allocatePtrVec(i).value) := io.enq.req(i).bits.eliminatedMove\n\
      1498:         dt_isRVC(allocatePtrVec(i).value) := io.enq.req(i).bits.preDecodeInfo.isRVC\n\
      1499:         dt_pcTransType.foreach(_(allocatePtrVec(i).value) := io.debugInstrAddrTransType)\n\
      1500:       }\n1501:     }\n1502:     for (wb <- exuWBs) {\n1503:       when(wb.valid)
      {\n1504:         val wbIdx = wb.bits.robIdx.value"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1514-1528
    context: "1514:       val eliminatedMove = dt_eliminatedMove(ptr)\n1515:     \
      \  val isRVC = dt_isRVC(ptr)\n1516:       val instr = uop.instr.asTypeOf(new
      XSInstBitFields)\n1517:       val isVLoad = instr.isVecLoad\n1518: \n1519: \
      \      val difftest = DifftestModule(new DiffInstrCommit(MaxPhyRegs), delay
      = 3, dontCare = true)\n1520:       val dt_skip = Mux(eliminatedMove, false.B,
      exuOut.isSkipDiff)\n1521:       difftest.coreid := io.hartId\n1522:       difftest.index
      := i.U\n1523:       difftest.valid := io.commits.commitValid(i) && io.commits.isCommit\n\
      1524:       difftest.skip := dt_skip\n1525:       difftest.isRVC := isRVC\n\
      1526:       difftest.rfwen := io.commits.commitValid(i) && commitInfo.rfWen
      && commitInfo.debug_ldest.get =/= 0.U\n1527:       difftest.fpwen := io.commits.commitValid(i)
      && uop.fpWen\n1528:       difftest.vecwen := io.commits.commitValid(i) && uop.vecWen"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1528-1540
    context: "1528:       difftest.vecwen := io.commits.commitValid(i) && uop.vecWen\n\
      1529:       difftest.v0wen := io.commits.commitValid(i) && (uop.v0Wen || isVLoad
      && instr.VD === 0.U)\n1530:       difftest.wpdest := commitInfo.debug_pdest.get\n\
      1531:       difftest.wdest := Mux(isVLoad, instr.VD, commitInfo.debug_ldest.get)\n\
      1532:       difftest.otherwpdest := debug_VecOtherPdest(ptr)\n1533:       difftest.nFused
      := CommitType.isFused(commitInfo.commitType).asUInt + commitInfo.instrSize -
      1.U\n1534:       when(difftest.valid) {\n1535:         assert(CommitType.isFused(commitInfo.commitType).asUInt
      + commitInfo.instrSize >= 1.U)\n1536:       }\n1537:       if (env.EnableDifftest)
      {\n1538:         val pcTransType = dt_pcTransType.get(deqPtrVec(i).value)\n\
      1539:         difftest.pc := Mux(pcTransType.shouldBeSext, SignExt(uop.pc, XLEN),
      uop.pc)\n1540:         difftest.instr := uop.instr"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1539-1550
    context: "1539:         difftest.pc := Mux(pcTransType.shouldBeSext, SignExt(uop.pc,
      XLEN), uop.pc)\n1540:         difftest.instr := uop.instr\n1541:         difftest.robIdx
      := ZeroExt(ptr, 10)\n1542:         difftest.lqIdx := ZeroExt(uop.lqIdx.value,
      7)\n1543:         difftest.sqIdx := ZeroExt(uop.sqIdx.value, 7)\n1544:     \
      \    difftest.isLoad := io.commits.info(i).commitType === CommitType.LOAD\n\
      1545:         difftest.isStore := io.commits.info(i).commitType === CommitType.STORE\n\
      1546:         // Check LoadEvent only when isAmo or isLoad and skip MMIO\n1547:\
      \         val difftestLoadEvent = DifftestModule(new DiffLoadEvent, delay =
      3)\n1548:         difftestLoadEvent.coreid := io.hartId\n1549:         difftestLoadEvent.index
      := i.U\n1550:         val loadCheck = (FuType.isAMO(uop.fuType) || FuType.isLoad(uop.fuType)
      || isVLoad) && !dt_skip"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1546-1556
    context: "1546:         // Check LoadEvent only when isAmo or isLoad and skip
      MMIO\n1547:         val difftestLoadEvent = DifftestModule(new DiffLoadEvent,
      delay = 3)\n1548:         difftestLoadEvent.coreid := io.hartId\n1549:     \
      \    difftestLoadEvent.index := i.U\n1550:         val loadCheck = (FuType.isAMO(uop.fuType)
      || FuType.isLoad(uop.fuType) || isVLoad) && !dt_skip\n1551:         difftestLoadEvent.valid\
      \    := io.commits.commitValid(i) && io.commits.isCommit && loadCheck\n1552:\
      \         difftestLoadEvent.paddr    := exuOut.paddr\n1553:         difftestLoadEvent.opType\
      \   := uop.fuOpType\n1554:         difftestLoadEvent.isAtomic := FuType.isAMO(uop.fuType)\n\
      1555:         difftestLoadEvent.isLoad   := FuType.isLoad(uop.fuType)\n1556:\
      \         difftestLoadEvent.isVLoad  := isVLoad"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1564-1574
    context: "1564:       when(canEnqueue(i)) {\n1565:         dt_isXSTrap(allocatePtrVec(i).value)
      := io.enq.req(i).bits.isXSTrap\n1566:       }\n1567:     }\n1568:     val trapVec
      = io.commits.commitValid.zip(deqPtrVec).map { case (v, d) =>\n1569:       io.commits.isCommit
      && v && dt_isXSTrap(d.value)\n1570:     }\n1571:     val hitTrap = trapVec.reduce(_
      || _)\n1572:     val difftest = DifftestModule(new DiffTrapEvent, dontCare =
      true)\n1573:     difftest.coreid := io.hartId\n1574:     difftest.hasTrap :=
      hitTrap"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1590-1601
    context: "1590:     io.storeDebugInfo.map{port =>\n1591:       port.pc := debug_microOp(port.robidx.value).pc\n\
      1592:     }\n1593:   }\n1594: \n1595:   val brhMispred = PopCount(branchWBs.map(wb
      => wb.valid & wb.bits.redirect.get.valid))\n1596:   val jmpMispred = PopCount(jmpWBs.map(wb
      => wb.valid && wb.bits.redirect.get.valid))\n1597:   val misPred = brhMispred
      +& jmpMispred\n1598: \n1599:   XSPerfAccumulate(\"br_mis_pred\", misPred)\n\
      1600: \n1601:   val commitLoadVec = VecInit(commitLoadValid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1598-1621
    context: "1598: \n1599:   XSPerfAccumulate(\"br_mis_pred\", misPred)\n1600: \n\
      1601:   val commitLoadVec = VecInit(commitLoadValid)\n1602:   val commitBranchVec
      = VecInit(commitBranchValid)\n1603:   val commitStoreVec = VecInit(io.commits.commitValid.zip(commitIsStore).map
      { case (v, t) => v && t })\n1604:   val perfEvents = Seq(\n1605:     (\"rob_interrupt_num\
      \      \", io.flushOut.valid && intrEnable),\n1606:     (\"rob_exception_num\
      \      \", io.flushOut.valid && deqHasException),\n1607:     (\"rob_flush_pipe_num\
      \     \", io.flushOut.valid && isFlushPipe),\n1608:     (\"rob_replay_inst_num\
      \    \", io.flushOut.valid && isFlushPipe && deqHasReplayInst),\n1609:     (\"\
      rob_commitUop          \", ifCommit(commitCnt)),\n1610:     (\"rob_commitInstr\
      \        \", ifCommitReg(trueCommitCnt)),\n1611:     (\"rob_commitInstrFused\
      \   \", ifCommitReg(fuseCommitCnt)),\n1612:     (\"rob_commitInstrLoad    \"\
      , ifCommitReg(PopCount(RegEnable(commitLoadVec, isCommit)))),\n1613:     (\"\
      rob_commitInstrBranch  \", ifCommitReg(PopCount(RegEnable(commitBranchVec, isCommit)))),\n\
      1614:     (\"rob_commitInstrStore   \", ifCommitReg(PopCount(RegEnable(commitStoreVec,
      isCommit)))),\n1615:     (\"rob_walkInstr          \", Mux(io.commits.isWalk,
      PopCount(io.commits.walkValid), 0.U)),\n1616:     (\"rob_walkCycle         \
      \ \", (state === s_walk)),\n1617:     (\"rob_1_4_valid          \", numValidEntries
      <= (RobSize / 4).U),\n1618:     (\"rob_2_4_valid          \", numValidEntries
      > (RobSize / 4).U && numValidEntries <= (RobSize / 2).U),\n1619:     (\"rob_3_4_valid\
      \          \", numValidEntries > (RobSize / 2).U && numValidEntries <= (RobSize
      * 3 / 4).U),\n1620:     (\"rob_4_4_valid          \", numValidEntries > (RobSize
      * 3 / 4).U),\n1621:     (\"BR_MIS_PRED            \", misPred),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1617-1633
    context: "1617:     (\"rob_1_4_valid          \", numValidEntries <= (RobSize
      / 4).U),\n1618:     (\"rob_2_4_valid          \", numValidEntries > (RobSize
      / 4).U && numValidEntries <= (RobSize / 2).U),\n1619:     (\"rob_3_4_valid \
      \         \", numValidEntries > (RobSize / 2).U && numValidEntries <= (RobSize
      * 3 / 4).U),\n1620:     (\"rob_4_4_valid          \", numValidEntries > (RobSize
      * 3 / 4).U),\n1621:     (\"BR_MIS_PRED            \", misPred),\n1622:     (\"\
      TOTAL_FLUSH            \", io.flushOut.valid)\n1623:   )\n1624:   generatePerfEvent()\n\
      1625: \n1626:   // max commit-stuck cycle\n1627:   val deqismmio = Mux(robEntries(deqPtr.value).valid,
      robEntries(deqPtr.value).mmio, false.B)\n1628:   val commitStuck = (!io.commits.commitValid.reduce(_
      || _) || !io.commits.isCommit) && !deqismmio\n1629:   val commitStuckCycle =
      RegInit(0.U(log2Up(maxCommitStuck).W))\n1630:   when(commitStuck) {\n1631: \
      \    commitStuckCycle := commitStuckCycle + 1.U\n1632:   }.elsewhen(!commitStuck
      && RegNext(commitStuck)) {\n1633:     commitStuckCycle := 0.U"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1668-1678
    context: "1668:     dontTouch(walkDestSizeSeq)\n1669:     dontTouch(io.commits)\n\
      1670:     dontTouch(commitIsVTypeVec)\n1671:     dontTouch(walkIsVTypeVec)\n\
      1672:     dontTouch(commitValidThisLine)\n1673:     dontTouch(commitReadAddr_next)\n\
      1674:     dontTouch(donotNeedWalk)\n1675:     dontTouch(walkPtrVec_next)\n1676:\
      \     dontTouch(walkPtrVec)\n1677:     dontTouch(deqPtrVec_next)\n1678:    \
      \ dontTouch(deqPtrVecForWalk)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 28-38
    context: "28:   val vtype = new VType()\n29:   val isVsetvl = Bool()\n30: }\n\
      31: \n32: class VTypeBufferIO(size: Int)(implicit p: Parameters) extends XSBundle
      {\n33:   val redirect = Input(ValidIO(new Bundle{}))\n34: \n35:   val req =
      Vec(RenameWidth, Flipped(ValidIO(new DynInst)))\n36: \n37:   val fromRob = new
      Bundle {\n38:     val walkSize = Input(UInt(log2Up(size).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 47-57
    context: "47: \n48:   val toDecode = Output(new Bundle {\n49:     val isResumeVType
      = Bool()\n50:     val walkToArchVType = Bool()\n51:     val walkVType = ValidIO(VType())\n\
      52:     val commitVType = new Bundle {\n53:       val vtype = ValidIO(VType())\n\
      54:       val hasVsetvl = Bool()\n55:     }\n56:   })\n57: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 66-82
    context: "66:   // alias\n67:   private val useSnpt = io.snpt.useSnpt\n68:   private
      val snptSelect = io.snpt.snptSelect\n69: \n70:   private val s_idle :: s_spcl_walk
      :: s_walk :: Nil = Enum(3)\n71:   private val state = RegInit(s_idle)\n72: \
      \  private val stateNext = WireInit(state) // otherwise keep state value\n73:\
      \   private val stateLast = RegEnable(state, state =/= stateNext)\n74:   private
      val stateLastCycle = RegNext(state)\n75: \n76:   // +1 read port to get walk
      initial state\n77:   private val vtypeBuffer = Module(new SyncDataModuleTemplate(new
      VTypeBufferEntry(), size, numWrite = RenameWidth, numRead = CommitWidth))\n\
      78:   private val vtypeBufferReadAddrVec = vtypeBuffer.io.raddr\n79:   private
      val vtypeBufferReadDataVec = vtypeBuffer.io.rdata\n80:   private val vtypeBufferWriteEnVec
      = vtypeBuffer.io.wen\n81:   private val vtypeBufferWriteAddrVec = vtypeBuffer.io.waddr\n\
      82:   private val vtypeBufferWriteDataVec = vtypeBuffer.io.wdata"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 81-91
    context: "81:   private val vtypeBufferWriteAddrVec = vtypeBuffer.io.waddr\n82:\
      \   private val vtypeBufferWriteDataVec = vtypeBuffer.io.wdata\n83: \n84:  \
      \ // pointer\n85:   private val enqPtrVec = RegInit(VecInit.tabulate(RenameWidth)(idx
      => VTypeBufferPtr(flag = false, idx)))\n86:   private val enqPtr = enqPtrVec.head\n\
      87:   private val enqPtrOH = RegInit(1.U(size.W))\n88:   private val enqPtrOHShift
      = CircularShift(enqPtrOH)\n89:   // may shift [0, RenameWidth] steps\n90:  \
      \ private val enqPtrOHVec = VecInit.tabulate(RenameWidth + 1)(enqPtrOHShift.left)\n\
      91:   private val enqPtrVecNext = WireInit(enqPtrVec)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 89-99
    context: "89:   // may shift [0, RenameWidth] steps\n90:   private val enqPtrOHVec
      = VecInit.tabulate(RenameWidth + 1)(enqPtrOHShift.left)\n91:   private val enqPtrVecNext
      = WireInit(enqPtrVec)\n92: \n93:   private val deqPtrVec = RegInit(VecInit.tabulate(CommitWidth)(idx
      => VTypeBufferPtr(flag = false, idx)))\n94:   private val deqPtr = deqPtrVec.head\n\
      95:   private val deqPtrOH = RegInit(1.U(size.W))\n96:   private val deqPtrOHShift
      = CircularShift(deqPtrOH)\n97:   private val deqPtrOHVec = VecInit.tabulate(CommitWidth
      + 1)(deqPtrOHShift.left)\n98:   private val deqPtrVecNext = WireInit(deqPtrVec)\n\
      99:   XSError(deqPtr.toOH =/= deqPtrOH, p\"wrong one-hot reg between $deqPtr
      and $deqPtrOH\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 108-124
    context: "108:   // get enque vtypes in io.req\n109:   private val enqVTypes =
      VecInit(io.req.map(req => req.bits.vpu.specVType))\n110:   private val enqValids
      = VecInit(io.req.map(_.valid))\n111:   private val enqVType = PriorityMux(enqValids.zip(enqVTypes).map
      { case (valid, vtype) => valid -> vtype })\n112: \n113:   private val walkPtrSnapshots
      = SnapshotGenerator(enqPtr, io.snpt.snptEnq, io.snpt.snptDeq, io.redirect.valid,
      io.snpt.flushVec)\n114:   private val walkVTypeSnapshots = SnapshotGenerator(enqVType,
      io.snpt.snptEnq, io.snpt.snptDeq, io.redirect.valid, io.snpt.flushVec)\n115:\
      \ \n116:   private val robWalkEndReg = RegInit(false.B)\n117:   private val
      robWalkEnd = io.fromRob.walkEnd || robWalkEndReg\n118: \n119:   when(io.redirect.valid)
      {\n120:     robWalkEndReg := false.B\n121:   }.elsewhen(io.fromRob.walkEnd)
      {\n122:     robWalkEndReg := true.B\n123:   }\n124: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 139-149
    context: "139:   private val walkSizeNext     = Wire(UInt(CommitWidth.U.getWidth.W))\n\
      140:   private val spclWalkSizeNext = Wire(UInt(CommitWidth.U.getWidth.W))\n\
      141: \n142:   private val newCommitSize   = io.fromRob.commitSize\n143:   private
      val newWalkSize     = io.fromRob.walkSize\n144:   private val newSpclWalkSize
      = Mux(io.redirect.valid && !io.snpt.useSnpt, commitSizeNext, 0.U)\n145: \n146:\
      \   commitSizeNext   := commitSize + newCommitSize - commitCount\n147:   walkSizeNext\
      \     := walkSize + newWalkSize - walkCount\n148:   spclWalkSizeNext := spclWalkSize
      + newSpclWalkSize - spclWalkCount\n149: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 145-163
    context: "145: \n146:   commitSizeNext   := commitSize + newCommitSize - commitCount\n\
      147:   walkSizeNext     := walkSize + newWalkSize - walkCount\n148:   spclWalkSizeNext
      := spclWalkSize + newSpclWalkSize - spclWalkCount\n149: \n150:   commitSize
      := Mux(io.redirect.valid && !io.snpt.useSnpt, 0.U, commitSizeNext)\n151:   spclWalkSize
      := spclWalkSizeNext\n152:   walkSize := Mux(io.redirect.valid, 0.U, walkSizeNext)\n\
      153: \n154:   walkPtrNext := MuxCase(walkPtr, Seq(\n155:     (state === s_idle
      && stateNext === s_walk) -> walkPtrSnapshots(snptSelect),\n156:     (state ===
      s_spcl_walk && stateNext === s_walk) -> deqPtrVecNext.head,\n157:     (state
      === s_walk && io.snpt.useSnpt && io.redirect.valid) -> walkPtrSnapshots(snptSelect),\n\
      158:     (state === s_walk) -> (walkPtr + walkCount),\n159:   ))\n160: \n161:\
      \   walkPtr := walkPtrNext\n162: \n163:   private val useSnapshotNext = WireInit(false.B)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 160-170
    context: "160: \n161:   walkPtr := walkPtrNext\n162: \n163:   private val useSnapshotNext
      = WireInit(false.B)\n164: \n165:   useSnapshotNext := (state === s_idle && stateNext
      === s_walk) || (state === s_walk && io.snpt.useSnpt && io.redirect.valid)\n\
      166:   private val useSnapshot = RegNext(useSnapshotNext)\n167:   private val
      snapshotVType = RegEnable(walkVTypeSnapshots(snptSelect), useSnapshotNext)\n\
      168: \n169:   // update enq ptr\n170:   private val enqPtrNext = Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 166-176
    context: "166:   private val useSnapshot = RegNext(useSnapshotNext)\n167:   private
      val snapshotVType = RegEnable(walkVTypeSnapshots(snptSelect), useSnapshotNext)\n\
      168: \n169:   // update enq ptr\n170:   private val enqPtrNext = Mux(\n171:\
      \     state === s_walk && stateNext === s_idle,\n172:     walkPtrNext,\n173:\
      \     enqPtr + enqCount\n174:   )\n175: \n176:   private val enqPtrOHNext =
      Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 172-182
    context: "172:     walkPtrNext,\n173:     enqPtr + enqCount\n174:   )\n175: \n\
      176:   private val enqPtrOHNext = Mux(\n177:     state === s_walk && stateNext
      === s_idle,\n178:     walkPtrNext.toOH,\n179:     enqPtrOHVec(enqCount)\n180:\
      \   )\n181: \n182:   enqPtrOH := enqPtrOHNext"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 183-194
    context: "183:   enqPtrVecNext.zipWithIndex.map{ case(ptr, i) => ptr := enqPtrNext
      + i.U }\n184:   enqPtrVec := enqPtrVecNext\n185: \n186:   // update deq ptr\n\
      187:   private val deqPtrSteps = Mux1H(Seq(\n188:     (state === s_idle) ->
      commitCount,\n189:     (state === s_spcl_walk) -> spclWalkCount,\n190:   ))\n\
      191: \n192:   private val deqPtrNext = deqPtr + deqPtrSteps\n193:   private
      val deqPtrOHNext = deqPtrOHVec(deqPtrSteps)\n194:   deqPtrOH := deqPtrOHNext"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 195-207
    context: "195:   deqPtrVecNext.zipWithIndex.map{ case(ptr, i) => ptr := deqPtrNext
      + i.U }\n196:   deqPtrVec := deqPtrVecNext\n197: \n198:   private val allocPtrVec:
      Vec[VTypeBufferPtr] = VecInit((0 until RenameWidth).map(i => enqPtrVec(PopCount(needAllocVec.take(i)))))\n\
      199:   private val vtypeBufferReadPtrVecNext: Vec[VTypeBufferPtr] = Mux1H(Seq(\n\
      200:     (stateNext === s_idle) -> deqPtrVecNext,\n201:     (stateNext === s_walk)
      -> walkPtrVecNext,\n202:     (stateNext === s_spcl_walk) -> deqPtrVecNext,\n\
      203:   ))\n204: \n205:   /**\n206:    * connection of [[vtypeBuffer]]\n207:\
      \    */"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 205-215
    context: "205:   /**\n206:    * connection of [[vtypeBuffer]]\n207:    */\n208:\
      \   vtypeBufferWriteAddrVec := allocPtrVec.map(_.value)\n209:   vtypeBufferWriteEnVec
      := needAllocVec\n210:   vtypeBufferWriteDataVec.zip(io.req.map(_.bits)).foreach
      { case (entry: VTypeBufferEntry, inst) =>\n211:     entry.vtype := inst.vpu.vtype\n\
      212:     entry.isVsetvl := VSETOpType.isVsetvl(inst.fuOpType)\n213:   }\n214:\
      \   vtypeBufferReadAddrVec := vtypeBufferReadPtrVecNext.map(_.value)\n215: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 217-228
    context: "217:   private val walkValidVec = Wire(Vec(CommitWidth, Bool()))\n218:\
      \   private val infoVec = Wire(Vec(CommitWidth, VType()))\n219:   private val
      hasVsetvlVec = Wire(Vec(CommitWidth, Bool()))\n220: \n221:   for (i <- 0 until
      CommitWidth) {\n222:     commitValidVec(i) := state === s_idle && i.U < commitSize
      || state === s_spcl_walk && i.U < spclWalkSize\n223:     walkValidVec(i) :=
      state === s_walk && i.U < walkSize || state === s_spcl_walk && i.U < spclWalkSize\n\
      224: \n225:     infoVec(i) := vtypeBufferReadDataVec(i).vtype\n226:     hasVsetvlVec(i)
      := vtypeBufferReadDataVec(i).isVsetvl\n227:   }\n228: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 224-261
    context: "224: \n225:     infoVec(i) := vtypeBufferReadDataVec(i).vtype\n226:\
      \     hasVsetvlVec(i) := vtypeBufferReadDataVec(i).isVsetvl\n227:   }\n228:\
      \ \n229:   commitCount   := Mux(state === s_idle,      PopCount(commitValidVec),
      0.U)\n230:   walkCount     := Mux(state === s_walk,      PopCount(walkValidVec),
      0.U)\n231:   spclWalkCount := Mux(state === s_spcl_walk, PopCount(walkValidVec),
      0.U)\n232: \n233:   private val walkEndNext = walkSizeNext === 0.U\n234:   private
      val spclWalkEndNext = spclWalkSizeNext === 0.U\n235: \n236:   state := stateNext\n\
      237: \n238:   when (io.redirect.valid) {\n239:     when (io.snpt.useSnpt) {\n\
      240:       stateNext := s_walk\n241:     }.otherwise {\n242:       stateNext
      := s_spcl_walk\n243:     }\n244:   }.otherwise {\n245:     switch (state) {\n\
      246:       is(s_idle) {\n247:         stateNext := s_idle\n248:       }\n249:\
      \       is(s_spcl_walk) {\n250:         when (spclWalkEndNext) {\n251:     \
      \      stateNext := s_walk\n252:         }\n253:       }\n254:       is(s_walk)
      {\n255:         when (robWalkEnd && walkEndNext) {\n256:           stateNext
      := s_idle\n257:         }\n258:       }\n259:     }\n260:   }\n261: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 268-278
    context: "268:     numValidEntries + enqCount <= (size - 2*RenameWidth).U,\n269:\
      \     true.B\n270:   )\n271: \n272:   private val decodeResumeVType = RegInit(0.U.asTypeOf(new
      ValidIO(VType())))\n273:   private val newestVType = PriorityMux(walkValidVec.zip(infoVec).map
      { case(walkValid, info) => walkValid -> info }.reverse)\n274:   private val
      newestArchVType = PriorityMux(commitValidVec.zip(infoVec).map { case(commitValid,
      info) => commitValid -> info }.reverse)\n275:   private val commitVTypeValid
      = commitValidVec.asUInt.orR\n276:   private val walkToArchVType = RegInit(false.B)\n\
      277: \n278:   walkToArchVType := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 275-285
    context: "275:   private val commitVTypeValid = commitValidVec.asUInt.orR\n276:\
      \   private val walkToArchVType = RegInit(false.B)\n277: \n278:   walkToArchVType
      := false.B\n279: \n280:   when (state === s_spcl_walk) {\n281:     // special
      walk use commit vtype\n282:     decodeResumeVType.valid := commitVTypeValid\n\
      283:     decodeResumeVType.bits := newestArchVType\n284:   }.elsewhen (useSnapshot)
      {\n285:     // use snapshot vtype"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 283-296
    context: "283:     decodeResumeVType.bits := newestArchVType\n284:   }.elsewhen
      (useSnapshot) {\n285:     // use snapshot vtype\n286:     decodeResumeVType.valid
      := true.B\n287:     decodeResumeVType.bits := snapshotVType\n288:   }.elsewhen
      (state === s_walk && walkCount =/= 0.U) {\n289:     decodeResumeVType.valid
      := true.B\n290:     decodeResumeVType.bits := newestVType\n291:   }.elsewhen
      (state === s_walk && stateLastCycle =/= s_walk) {\n292:     // walk start with
      arch vtype\n293:     decodeResumeVType.valid := false.B\n294:     walkToArchVType
      := true.B\n295:   }.otherwise {\n296:     decodeResumeVType.valid := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 294-314
    context: "294:     walkToArchVType := true.B\n295:   }.otherwise {\n296:     decodeResumeVType.valid
      := false.B\n297:   }\n298: \n299:   io.canEnq := allowEnqueue && state === s_idle\n\
      300:   io.canEnqForDispatch := allowEnqueueForDispatch && state === s_idle\n\
      301:   io.status.walkEnd := walkEndNext\n302:   // update vtype in decode when
      VTypeBuffer resumes from walk state\n303:   // note that VTypeBuffer can still
      send resuming request in the first cycle of s_idle\n304:   io.toDecode.isResumeVType
      := state =/= s_idle || decodeResumeVType.valid\n305:   io.toDecode.walkVType.valid
      := decodeResumeVType.valid\n306:   io.toDecode.walkVType.bits := Mux(io.toDecode.walkVType.valid,
      decodeResumeVType.bits, 0.U.asTypeOf(VType()))\n307: \n308:   io.toDecode.commitVType.vtype.valid
      := commitVTypeValid\n309:   io.toDecode.commitVType.vtype.bits := newestArchVType\n\
      310: \n311:   io.toDecode.walkToArchVType := walkToArchVType\n312: \n313:  \
      \ // because vsetvl flush pipe, there is only one vset instruction when vsetvl
      is committed\n314:   private val hasVsetvl = commitValidVec.zip(hasVsetvlVec).map
      { case(commitValid, hasVsetvl) => commitValid && hasVsetvl }.reduce(_ || _)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 310-320
    context: "310: \n311:   io.toDecode.walkToArchVType := walkToArchVType\n312: \n\
      313:   // because vsetvl flush pipe, there is only one vset instruction when
      vsetvl is committed\n314:   private val hasVsetvl = commitValidVec.zip(hasVsetvlVec).map
      { case(commitValid, hasVsetvl) => commitValid && hasVsetvl }.reduce(_ || _)\n\
      315:   io.toDecode.commitVType.hasVsetvl := hasVsetvl\n316: \n317:   XSError(isBefore(enqPtr,
      deqPtr) && !isFull(enqPtr, deqPtr), \"\\ndeqPtr is older than enqPtr!\\n\")\n\
      318: \n319:   QueuePerf(size, numValidEntries, numValidEntries === size.U)\n\
      320: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 316-334
    context: "316: \n317:   XSError(isBefore(enqPtr, deqPtr) && !isFull(enqPtr, deqPtr),
      \"\\ndeqPtr is older than enqPtr!\\n\")\n318: \n319:   QueuePerf(size, numValidEntries,
      numValidEntries === size.U)\n320: \n321:   XSPerfAccumulate(\"s_idle_to_idle\"\
      , state === s_idle      && stateNext === s_idle)\n322:   XSPerfAccumulate(\"\
      s_idle_to_swlk\", state === s_idle      && stateNext === s_spcl_walk)\n323:\
      \   XSPerfAccumulate(\"s_idle_to_walk\", state === s_idle      && stateNext
      === s_walk)\n324:   XSPerfAccumulate(\"s_swlk_to_idle\", state === s_spcl_walk
      && stateNext === s_idle)\n325:   XSPerfAccumulate(\"s_swlk_to_swlk\", state
      === s_spcl_walk && stateNext === s_spcl_walk)\n326:   XSPerfAccumulate(\"s_swlk_to_walk\"\
      , state === s_spcl_walk && stateNext === s_walk)\n327:   XSPerfAccumulate(\"\
      s_walk_to_idle\", state === s_walk      && stateNext === s_idle)\n328:   XSPerfAccumulate(\"\
      s_walk_to_swlk\", state === s_walk      && stateNext === s_spcl_walk)\n329:\
      \   XSPerfAccumulate(\"s_walk_to_walk\", state === s_walk      && stateNext
      === s_walk)\n330: \n331:   dontTouch(enqPtrVec)\n332:   dontTouch(deqPtrVec)\n\
      333:   dontTouch(deqPtr)\n334:   dontTouch(numValidEntries)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobEnqPtrWrapper.scala
    lines: 35-45
    context: "35: import xiangshan.backend.rename.SnapshotGenerator\n36: \n37: class
      RobEnqPtrWrapper(implicit p: Parameters) extends XSModule with HasCircularQueuePtrHelper
      {\n38:   val io = IO(new Bundle {\n39:     // for input redirect\n40:     val
      redirect = Input(Valid(new Redirect))\n41:     // for enqueue\n42:     val allowEnqueue
      = Input(Bool())\n43:     val hasBlockBackward = Input(Bool())\n44:     val enq
      = Vec(RenameWidth, Input(Bool()))\n45:     val out = Output(Vec(RenameWidth,
      new RobPtr))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobEnqPtrWrapper.scala
    lines: 50-61
    context: "50:   // enqueue\n51:   val canAccept = io.allowEnqueue && !io.hasBlockBackward\n\
      52:   val dispatchNum = Mux(canAccept, PopCount(io.enq), 0.U)\n53: \n54:   for
      ((ptr, i) <- enqPtrVec.zipWithIndex) {\n55:     when(io.redirect.valid) {\n\
      56:       ptr := Mux(io.redirect.bits.flushItself(), io.redirect.bits.robIdx
      + i.U, io.redirect.bits.robIdx + (i + 1).U)\n57:     }.otherwise {\n58:    \
      \   ptr := ptr + dispatchNum\n59:     }\n60:   }\n61: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 52-62
    context: "52:     val interrupt_safe = Bool()\n53:     val fpWen = Bool()\n54:\
      \     val rfWen = Bool()\n55:     val wflags = Bool()\n56:     val dirtyVs =
      Bool()\n57:     val commitType = CommitType()\n58:     val ftqIdx = new FtqPtr\n\
      59:     val ftqOffset = UInt(log2Up(PredictWidth).W)\n60:     val isRVC = Bool()\n\
      61:     val isVset = Bool()\n62:     val isHls = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 65-76
    context: "65:     \n66:     // trace\n67:     val traceBlockInPipe = new TracePipe(IretireWidthInPipe)\n\
      68:     // status begin\n69:     val valid = Bool()\n70:     val fflags = UInt(5.W)\n\
      71:     val mmio = Bool()\n72:     // store will be commited if both sta & std
      have been writebacked\n73:     val stdWritebacked = Bool()\n74:     val vxsat
      = Bool()\n75:     val realDestSize = UInt(log2Up(MaxUopSize + 1).W)\n76:   \
      \  val uopNum = UInt(log2Up(MaxUopSize + 1).W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 72-82
    context: "72:     // store will be commited if both sta & std have been writebacked\n\
      73:     val stdWritebacked = Bool()\n74:     val vxsat = Bool()\n75:     val
      realDestSize = UInt(log2Up(MaxUopSize + 1).W)\n76:     val uopNum = UInt(log2Up(MaxUopSize
      + 1).W)\n77:     val needFlush = Bool()\n78:     // status end\n79: \n80:  \
      \   // debug_begin\n81:     val debug_pc = OptionWrapper(backendParams.debugEn,
      UInt(VAddrBits.W))\n82:     val debug_instr = OptionWrapper(backendParams.debugEn,
      UInt(32.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 95-105
    context: "95:     val commit_v = Bool()\n96:     val commit_w = Bool()\n97:  \
      \   val realDestSize = UInt(log2Up(MaxUopSize + 1).W)\n98:     val interrupt_safe
      = Bool()\n99:     val wflags = Bool()\n100:     val fflags = UInt(5.W)\n101:\
      \     val vxsat = Bool()\n102:     val isRVC = Bool()\n103:     val isVset =
      Bool()\n104:     val isHls = Bool()\n105:     val isVls = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 102-113
    context: "102:     val isRVC = Bool()\n103:     val isVset = Bool()\n104:    \
      \ val isHls = Bool()\n105:     val isVls = Bool()\n106:     val vls = Bool()\n\
      107:     val mmio = Bool()\n108:     val commitType = CommitType()\n109:   \
      \  val ftqIdx = new FtqPtr\n110:     val ftqOffset = UInt(log2Up(PredictWidth).W)\n\
      111:     val instrSize = UInt(log2Ceil(RenameWidth + 1).W)\n112:     val fpWen
      = Bool()\n113:     val rfWen = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 109-119
    context: "109:     val ftqIdx = new FtqPtr\n110:     val ftqOffset = UInt(log2Up(PredictWidth).W)\n\
      111:     val instrSize = UInt(log2Ceil(RenameWidth + 1).W)\n112:     val fpWen
      = Bool()\n113:     val rfWen = Bool()\n114:     val needFlush = Bool()\n115:\
      \     // trace\n116:     val traceBlockInPipe = new TracePipe(IretireWidthInPipe)\n\
      117:     // debug_begin\n118:     val debug_pc = OptionWrapper(backendParams.debugEn,
      UInt(VAddrBits.W))\n119:     val debug_instr = OptionWrapper(backendParams.debugEn,
      UInt(32.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 125-136
    context: "125:     val dirtyFs = Bool()\n126:     val dirtyVs = Bool()\n127: \
      \  }\n128: \n129:   def connectEnq(robEntry: RobEntryBundle, robEnq: DynInst):
      Unit = {\n130:     robEntry.wflags := robEnq.wfflags\n131:     robEntry.commitType
      := robEnq.commitType\n132:     robEntry.ftqIdx := robEnq.ftqPtr\n133:     robEntry.ftqOffset
      := robEnq.ftqOffset\n134:     robEntry.isRVC := robEnq.preDecodeInfo.isRVC\n\
      135:     robEntry.isVset := robEnq.isVset\n136:     robEntry.isHls := robEnq.isHls"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 137-154
    context: "137:     robEntry.instrSize := robEnq.instrSize\n138:     robEntry.rfWen
      := robEnq.rfWen\n139:     robEntry.fpWen := robEnq.dirtyFs\n140:     robEntry.dirtyVs
      := robEnq.dirtyVs\n141:     // flushPipe needFlush but not exception\n142: \
      \    robEntry.needFlush := robEnq.hasException || robEnq.flushPipe\n143:   \
      \  // trace\n144:     robEntry.traceBlockInPipe := robEnq.traceBlockInPipe\n\
      145:     robEntry.debug_pc.foreach(_ := robEnq.pc)\n146:     robEntry.debug_instr.foreach(_
      := robEnq.instr)\n147:     robEntry.debug_ldest.foreach(_ := robEnq.ldest)\n\
      148:     robEntry.debug_pdest.foreach(_ := robEnq.pdest)\n149:     robEntry.debug_fuType.foreach(_
      := robEnq.fuType)\n150:   }\n151: \n152:   def connectCommitEntry(robCommitEntry:
      RobCommitEntryBundle, robEntry: RobEntryBundle): Unit = {\n153:     robCommitEntry.walk_v
      := robEntry.valid\n154:     robCommitEntry.commit_v := robEntry.valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 155-165
    context: "155:     robCommitEntry.commit_w := (robEntry.uopNum === 0.U) && (robEntry.stdWritebacked
      === true.B)\n156:     robCommitEntry.realDestSize := robEntry.realDestSize\n\
      157:     robCommitEntry.interrupt_safe := robEntry.interrupt_safe\n158:    \
      \ robCommitEntry.rfWen := robEntry.rfWen\n159:     robCommitEntry.fpWen := robEntry.fpWen\n\
      160:     robCommitEntry.fflags := robEntry.fflags\n161:     robCommitEntry.wflags
      := robEntry.wflags\n162:     robCommitEntry.vxsat := robEntry.vxsat\n163:  \
      \   robCommitEntry.isRVC := robEntry.isRVC\n164:     robCommitEntry.isVset :=
      robEntry.isVset\n165:     robCommitEntry.isHls := robEntry.isHls"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 163-186
    context: "163:     robCommitEntry.isRVC := robEntry.isRVC\n164:     robCommitEntry.isVset
      := robEntry.isVset\n165:     robCommitEntry.isHls := robEntry.isHls\n166:  \
      \   robCommitEntry.isVls := robEntry.vls\n167:     robCommitEntry.vls := robEntry.vls\n\
      168:     robCommitEntry.mmio := robEntry.mmio\n169:     robCommitEntry.ftqIdx
      := robEntry.ftqIdx\n170:     robCommitEntry.ftqOffset := robEntry.ftqOffset\n\
      171:     robCommitEntry.commitType := robEntry.commitType\n172:     robCommitEntry.instrSize
      := robEntry.instrSize\n173:     robCommitEntry.dirtyFs := robEntry.fpWen ||
      robEntry.wflags\n174:     robCommitEntry.dirtyVs := robEntry.dirtyVs\n175: \
      \    robCommitEntry.needFlush := robEntry.needFlush\n176:     robCommitEntry.traceBlockInPipe
      := robEntry.traceBlockInPipe\n177:     robCommitEntry.debug_pc.foreach(_ :=
      robEntry.debug_pc.get)\n178:     robCommitEntry.debug_instr.foreach(_ := robEntry.debug_instr.get)\n\
      179:     robCommitEntry.debug_ldest.foreach(_ := robEntry.debug_ldest.get)\n\
      180:     robCommitEntry.debug_pdest.foreach(_ := robEntry.debug_pdest.get)\n\
      181:     robCommitEntry.debug_fuType.foreach(_ := robEntry.debug_fuType.get)\n\
      182:   }\n183: }\n184: \n185: import RobBundles._\n186: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 188-203
    context: "188:   entries\n189: ) with HasCircularQueuePtrHelper {\n190: \n191:\
      \   def this()(implicit p: Parameters) = this(p(XSCoreParamsKey).RobSize)\n\
      192: \n193:   def needFlush(redirect: Valid[Redirect]): Bool = {\n194:     val
      flushItself = redirect.bits.flushItself() && this === redirect.bits.robIdx\n\
      195:     redirect.valid && (flushItself || isAfter(this, redirect.bits.robIdx))\n\
      196:   }\n197: \n198:   def needFlush(redirect: Seq[Valid[Redirect]]): Bool
      = VecInit(redirect.map(needFlush)).asUInt.orR\n199: \n200:   def lineHeadPtr(implicit
      p: Parameters): RobPtr = {\n201:     val CommitWidth = p(XSCoreParamsKey).CommitWidth\n\
      202:     val out = Wire(new RobPtr)\n203:     out.flag := this.flag"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 221-231
    context: "221:   val trapTarget = Input(new TargetPCBundle)\n222:   val isXRet\
      \     = Input(Bool())\n223:   val wfiEvent   = Input(Bool())\n224:   val criticalErrorState
      = Input(Bool())\n225: \n226:   val fflags     = Output(Valid(UInt(5.W)))\n227:\
      \   val vxsat      = Output(Valid(Bool()))\n228:   val vstart     = Output(Valid(UInt(XLEN.W)))\n\
      229:   val dirty_fs   = Output(Bool())\n230:   val dirty_vs   = Output(Bool())\n\
      231:   val perfinfo   = new Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 239-253
    context: "239:   val pendingMMIOld = Output(Bool())\n240:   val pendingld = Output(Bool())\n\
      241:   val pendingst = Output(Bool())\n242:   // set when vector store at the
      head of ROB\n243:   val pendingVst = Output(Bool())\n244:   val commit = Output(Bool())\n\
      245:   val pendingPtr = Output(new RobPtr)\n246:   val pendingPtrNext = Output(new
      RobPtr)\n247: \n248:   val mmio = Input(Vec(LoadPipelineWidth, Bool()))\n249:\
      \   // Todo: what's this?\n250:   val uop = Input(Vec(LoadPipelineWidth, new
      DynInst))\n251: }\n252: \n253: class RobEnqIO(implicit p: Parameters) extends
      XSBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 264-279
    context: "264:   val robHeadVaddr = Valid(UInt(VAddrBits.W))\n265:   val robHeadPaddr
      = Valid(UInt(PAddrBits.W))\n266: }\n267: \n268: class RobDispatchTopDownIO extends
      Bundle {\n269:   val robTrueCommit = Output(UInt(64.W))\n270:   val robHeadLsIssue
      = Output(Bool())\n271: }\n272: \n273: class RobDebugRollingIO extends Bundle
      {\n274:   val robTrueCommit = Output(UInt(64.W))\n275: }\n276: \n277: class
      RobExceptionInfo(implicit p: Parameters) extends XSBundle {\n278:   // val valid
      = Bool()\n279:   val robIdx = new RobPtr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 284-296
    context: "284:   // This signal is valid iff currentValid is true\n285:   // 0:
      is execute exception, 1: is fetch exception\n286:   val isEnqExcp = Bool()\n\
      287:   val exceptionVec = ExceptionVec()\n288:   val isFetchMalAddr = Bool()\n\
      289:   val flushPipe = Bool()\n290:   val isVset = Bool()\n291:   val replayInst
      = Bool() // redirect to that inst itself\n292:   val singleStep = Bool() //
      TODO add frontend hit beneath\n293:   val crossPageIPFFix = Bool()\n294:   val
      trigger = TriggerAction()\n295:   // if vstart is udpated by vector unit\n296:\
      \   val vstartEn = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 304-315
    context: "304:   val nf = Nf()\n305:   val vsew = VSew()\n306:   val veew = VSew()\n\
      307:   val vlmul = VLmul()\n308: \n309:   def has_exception = hasException ||
      flushPipe || singleStep || replayInst || TriggerAction.isDmode(trigger)\n310:\
      \   def not_commit = hasException || singleStep || replayInst || TriggerAction.isDmode(trigger)\n\
      311:   // only exceptions are allowed to writeback when enqueue\n312:   def
      can_writeback = hasException || singleStep || TriggerAction.isDmode(trigger)\n\
      313: }\n314: \n315: class RobFlushInfo(implicit p: Parameters) extends XSBundle
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/ExceptionGen.scala
    lines: 34-50
    context: "34: import xiangshan.backend.fu.vector.Bundles.VType\n35: import xiangshan.backend.rename.SnapshotGenerator\n\
      36: \n37: class ExceptionGen(params: BackendParams)(implicit p: Parameters)
      extends XSModule with HasCircularQueuePtrHelper {\n38:   val io = IO(new Bundle
      {\n39:     val redirect = Input(Valid(new Redirect))\n40:     val flush = Input(Bool())\n\
      41:     val enq = Vec(RenameWidth, Flipped(ValidIO(new RobExceptionInfo)))\n\
      42:     // csr + load + store + varith + vload + vstore\n43:     val wb = Vec(params.numException,
      Flipped(ValidIO(new RobExceptionInfo)))\n44:     val out = ValidIO(new RobExceptionInfo)\n\
      45:     val state = ValidIO(new RobExceptionInfo)\n46:   })\n47: \n48:   val
      wbExuParams = params.allExuParams.filter(_.exceptionOut.nonEmpty)\n49: \n50:\
      \   def getOldest(valid: Seq[Bool], bits: Seq[RobExceptionInfo]): RobExceptionInfo
      = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/ExceptionGen.scala
    lines: 57-67
    context: "57:         for (i <- res.indices) {\n58:           res(i).valid :=
      valid(i)\n59:           res(i).bits := bits(i)\n60:         }\n61:         val
      oldest = Mux(\n62:           !valid(1) || (valid(0) && (isAfter(bits(1).robIdx,
      bits(0).robIdx) || ((bits(1).robIdx === bits(0).robIdx) && bits(1).vuopIdx >
      bits(0).vuopIdx))),\n63:           res(0),\n64:           res(1)\n65:      \
      \   )\n66:         (Seq(oldest.valid), Seq(oldest.bits))\n67:       } else {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/ExceptionGen.scala
    lines: 68-78
    context: "68:         val left = getOldest_recursion(valid.take(valid.length /
      2), bits.take(valid.length / 2))\n69:         val right = getOldest_recursion(valid.drop(valid.length
      / 2), bits.drop(valid.length / 2))\n70:         getOldest_recursion(left._1
      ++ right._1, left._2 ++ right._2)\n71:       }\n72:     }\n73:     getOldest_recursion(valid,
      bits)._2.head\n74:   }\n75: \n76: \n77:   val currentValid = RegInit(false.B)\n\
      78:   val current = Reg(new RobExceptionInfo)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/ExceptionGen.scala
    lines: 76-90
    context: "76: \n77:   val currentValid = RegInit(false.B)\n78:   val current =
      Reg(new RobExceptionInfo)\n79: \n80:   // orR the exceptionVec\n81:   val lastCycleFlush
      = RegNext(io.flush)\n82:   val enq_s0_valid = VecInit(io.enq.map(e => e.valid
      && e.bits.has_exception && !lastCycleFlush))\n83:   val enq_s0_bits = WireInit(VecInit(io.enq.map(_.bits)))\n\
      84:   enq_s0_bits zip io.enq foreach { case (sink, source) =>\n85:     sink.flushPipe
      := source.bits.flushPipe && !source.bits.hasException\n86:   }\n87: \n88:  \
      \ // s0: compare wb in 6 groups\n89:   val csr_wb = io.wb.zip(wbExuParams).filter(_._2.fuConfigs.filter(t
      => t.isCsr).nonEmpty).map(_._1)\n90:   val load_wb = io.wb.zip(wbExuParams).filter(_._2.fuConfigs.filter(_.fuType
      == FuType.ldu).nonEmpty).map(_._1)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/ExceptionGen.scala
    lines: 93-116
    context: "93:   val vls_wb = io.wb.zip(wbExuParams).filter(_._2.fuConfigs.exists(x
      => FuType.FuTypeOrR(x.fuType, FuType.vecMem))).map(_._1)\n94: \n95:   val writebacks
      = Seq(csr_wb, load_wb, store_wb, varith_wb, vls_wb)\n96:   val in_wb_valids
      = writebacks.map(_.map(w => w.valid && w.bits.has_exception && !lastCycleFlush))\n\
      97:   val wb_valid = in_wb_valids.zip(writebacks).map { case (valid, wb) =>\n\
      98:     valid.zip(wb.map(_.bits)).map { case (v, bits) => v && !(bits.robIdx.needFlush(io.redirect)
      || io.flush) }.reduce(_ || _)\n99:   }\n100:   val wb_bits = in_wb_valids.zip(writebacks).map
      { case (valid, wb) => getOldest(valid, wb.map(_.bits))}\n101: \n102:   val s0_out_valid
      = wb_valid.map(x => RegNext(x))\n103:   val s0_out_bits = wb_bits.zip(wb_valid).map{
      case(b, v) => RegEnable(b, v)}\n104: \n105:   // s1: compare last six and current
      flush\n106:   val s1_valid = VecInit(s0_out_valid.zip(s0_out_bits).map{ case
      (v, b) => v && !(b.robIdx.needFlush(io.redirect) || io.flush) })\n107:   val
      s1_out_bits = RegEnable(getOldest(s0_out_valid, s0_out_bits), s1_valid.asUInt.orR)\n\
      108:   val s1_out_valid = RegNext(s1_valid.asUInt.orR)\n109: \n110:   val enq_s1_valid
      = RegNext(enq_s0_valid.asUInt.orR && !io.redirect.valid && !io.flush)\n111:\
      \   val enq_s1_bits: RobExceptionInfo = RegEnable(ParallelPriorityMux(enq_s0_valid,
      enq_s0_bits), enq_s0_valid.asUInt.orR && !io.redirect.valid && !io.flush)\n\
      112: \n113:   // s2: compare the input exception with the current one\n114:\
      \   // priorities:\n115:   // (1) system reset\n116:   // (2) current is valid:
      flush, remain, merge, update"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/ExceptionGen.scala
    lines: 113-132
    context: "113:   // s2: compare the input exception with the current one\n114:\
      \   // priorities:\n115:   // (1) system reset\n116:   // (2) current is valid:
      flush, remain, merge, update\n117:   // (3) current is not valid: s1 or enq\n\
      118:   val current_flush = current.robIdx.needFlush(io.redirect) || io.flush\n\
      119:   val s1_flush = s1_out_bits.robIdx.needFlush(io.redirect) || io.flush\n\
      120: \n121:   val isVecUpdate = s1_out_bits.vstart < current.vstart || !current.vstartEn\n\
      122:   when (currentValid) {\n123:     when (current_flush) {\n124:       currentValid
      := Mux(s1_flush, false.B, s1_out_valid)\n125:     }\n126:     when (s1_out_valid
      && !s1_flush) {\n127:       when (isAfter(current.robIdx, s1_out_bits.robIdx))
      {\n128:         current := s1_out_bits\n129:         // s1 is older than current
      and caused by wb, set current.isEnqExcp to false\n130:         current.isEnqExcp
      := false.B\n131:       }.elsewhen (current.robIdx === s1_out_bits.robIdx) {\n\
      132:         current.exceptionVec := Mux(isVecUpdate, s1_out_bits.exceptionVec,
      current.exceptionVec)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/ExceptionGen.scala
    lines: 129-139
    context: "129:         // s1 is older than current and caused by wb, set current.isEnqExcp
      to false\n130:         current.isEnqExcp := false.B\n131:       }.elsewhen (current.robIdx
      === s1_out_bits.robIdx) {\n132:         current.exceptionVec := Mux(isVecUpdate,
      s1_out_bits.exceptionVec, current.exceptionVec)\n133:         current.hasException
      := Mux(isVecUpdate, s1_out_bits.hasException, current.hasException)\n134:  \
      \       current.flushPipe := (s1_out_bits.flushPipe || current.flushPipe) &&
      !s1_out_bits.exceptionVec.asUInt.orR\n135:         current.replayInst := s1_out_bits.replayInst
      || current.replayInst\n136:         current.singleStep := s1_out_bits.singleStep
      || current.singleStep\n137:         current.trigger   := Mux(isVecUpdate, s1_out_bits.trigger,\
      \    current.trigger)\n138:         current.vstart    := Mux(isVecUpdate, s1_out_bits.vstart,\
      \     current.vstart)\n139:         current.vstartEn  := Mux(isVecUpdate, s1_out_bits.vstartEn,\
      \   current.vstartEn)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/ExceptionGen.scala
    lines: 148-162
    context: "148:         current.vlmul     := Mux(isVecUpdate, s1_out_bits.vlmul,\
      \      current.vlmul)\n149:         // current has a new exception caused by
      wb, set current.isEnqExcp to false\n150:         current.isEnqExcp := false.B\n\
      151:       }\n152:     }\n153:   }.elsewhen (s1_out_valid && !s1_flush) {\n\
      154:     currentValid := true.B\n155:     current := s1_out_bits\n156:     current.isEnqExcp
      := false.B\n157:   }.elsewhen (enq_s1_valid && !(io.redirect.valid || io.flush))
      {\n158:     currentValid := true.B\n159:     current := enq_s1_bits\n160:  \
      \   current.isEnqExcp := true.B\n161:   }\n162: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/ExceptionGen.scala
    lines: 158-168
    context: "158:     currentValid := true.B\n159:     current := enq_s1_bits\n160:\
      \     current.isEnqExcp := true.B\n161:   }\n162: \n163:   io.out.valid   :=
      s1_out_valid || enq_s1_valid && enq_s1_bits.can_writeback\n164:   io.out.bits\
      \    := Mux(s1_out_valid, s1_out_bits, enq_s1_bits)\n165:   io.state.valid :=
      currentValid\n166:   io.state.bits  := current\n167: \n168: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 33-43
    context: "33:    * There is no limit to the number of ports on both sides.\n34:\
      \    *\n35:    * Don't forget to connect the remaining ports!\n36:    */\n37:\
      \   def connectSamePort (bundleSource: Bundle, bundleSink: Bundle):Unit = {\n\
      38:     bundleSource.elements.foreach { case (name, data) =>\n39:       if (bundleSink.elements.contains(name))\n\
      40:         data := bundleSink.elements(name)\n41:     }\n42:   }\n43:   //
      frontend -> backend"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 100-110
    context: "100:     val v0Wen           = Bool()\n101:     val vlWen          \
      \ = Bool()\n102:     val isXSTrap        = Bool()\n103:     val waitForward\
      \     = Bool() // no speculate execution\n104:     val blockBackward   = Bool()\n\
      105:     val flushPipe       = Bool() // This inst will flush all the pipe when
      commit, like exception but can commit\n106:     val canRobCompress  = Bool()\n\
      107:     val selImm          = SelImm()\n108:     val imm             = UInt(ImmUnion.maxLen.W)\n\
      109:     val fpu             = new FPUCtrlSignals\n110:     val vpu        \
      \     = new VPUCtrlSignals"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 107-117
    context: "107:     val selImm          = SelImm()\n108:     val imm          \
      \   = UInt(ImmUnion.maxLen.W)\n109:     val fpu             = new FPUCtrlSignals\n\
      110:     val vpu             = new VPUCtrlSignals\n111:     val vlsInstr   \
      \     = Bool()\n112:     val wfflags         = Bool()\n113:     val isMove \
      \         = Bool()\n114:     val uopIdx          = UopIdx()\n115:     val uopSplitType\
      \    = UopSplitType()\n116:     val isVset          = Bool()\n117:     val firstUop\
      \        = Bool()"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 116-126
    context: "116:     val isVset          = Bool()\n117:     val firstUop       \
      \ = Bool()\n118:     val lastUop         = Bool()\n119:     val numUops    \
      \     = UInt(log2Up(MaxUopSize).W) // rob need this\n120:     val numWB    \
      \       = UInt(log2Up(MaxUopSize).W) // rob need this\n121:     val commitType\
      \      = CommitType() // Todo: remove it\n122:     val needFrm         = new
      NeedFrmBundle\n123: \n124:     val debug_fuType    = OptionWrapper(backendParams.debugEn,
      FuType())\n125:     val debug_seqNum    = InstSeqNum()\n126: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 123-133
    context: "123: \n124:     val debug_fuType    = OptionWrapper(backendParams.debugEn,
      FuType())\n125:     val debug_seqNum    = InstSeqNum()\n126: \n127:     private
      def allSignals = srcType.take(3) ++ Seq(fuType, fuOpType, rfWen, fpWen, vecWen,\n\
      128:       isXSTrap, waitForward, blockBackward, flushPipe, canRobCompress,
      uopSplitType, selImm)\n129: \n130:     def decode(inst: UInt, table: Iterable[(BitPat,
      List[BitPat])]): DecodedInst = {\n131:       val decoder: Seq[UInt] = ListLookup(\n\
      132:         inst, XDecode.decodeDefault.map(bitPatToUInt),\n133:         table.map{
      case (pat, pats) => (pat, pats.map(bitPatToUInt)) }.toArray"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 130-141
    context: "130:     def decode(inst: UInt, table: Iterable[(BitPat, List[BitPat])]):
      DecodedInst = {\n131:       val decoder: Seq[UInt] = ListLookup(\n132:     \
      \    inst, XDecode.decodeDefault.map(bitPatToUInt),\n133:         table.map{
      case (pat, pats) => (pat, pats.map(bitPatToUInt)) }.toArray\n134:       )\n\
      135:       allSignals zip decoder foreach { case (s, d) => s := d }\n136:  \
      \     debug_fuType.foreach(_ := fuType)\n137:       this\n138:     }\n139: \n\
      140:     def isSoftPrefetch: Bool = {\n141:       fuType === FuType.alu.U &&
      fuOpType === ALUOpType.or && selImm === SelImm.IMM_I && ldest === 0.U"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 153-165
    context: "153:   class TrapInstInfo(implicit p: Parameters) extends XSBundle {\n\
      154:     val instr = UInt(32.W)\n155:     val ftqPtr = new FtqPtr\n156:    \
      \ val ftqOffset = UInt(log2Up(PredictWidth).W)\n157: \n158:     def needFlush(ftqPtr:
      FtqPtr, ftqOffset: UInt): Bool = {\n159:       val sameFlush = this.ftqPtr ===
      ftqPtr && this.ftqOffset > ftqOffset\n160:       sameFlush || isAfter(this.ftqPtr,
      ftqPtr)\n161:     }\n162: \n163:     def sameInst(ftqPtr: FtqPtr, ftqOffset:
      UInt): Bool = {\n164:       this.ftqPtr === ftqPtr && this.ftqOffset === ftqOffset\n\
      165:     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 199-209
    context: "199:     val v0Wen           = Bool()\n200:     val vlWen          \
      \ = Bool()\n201:     val isXSTrap        = Bool()\n202:     val waitForward\
      \     = Bool() // no speculate execution\n203:     val blockBackward   = Bool()\n\
      204:     val flushPipe       = Bool() // This inst will flush all the pipe when
      commit, like exception but can commit\n205:     val canRobCompress  = Bool()\n\
      206:     val selImm          = SelImm()\n207:     val imm             = UInt(32.W)\n\
      208:     val fpu             = new FPUCtrlSignals\n209:     val vpu        \
      \     = new VPUCtrlSignals"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 206-216
    context: "206:     val selImm          = SelImm()\n207:     val imm          \
      \   = UInt(32.W)\n208:     val fpu             = new FPUCtrlSignals\n209:  \
      \   val vpu             = new VPUCtrlSignals\n210:     val vlsInstr        =
      Bool()\n211:     val wfflags         = Bool()\n212:     val isMove         \
      \ = Bool()\n213:     val isDropAmocasSta = Bool()\n214:     val uopIdx     \
      \     = UopIdx()\n215:     val isVset          = Bool()\n216:     val firstUop\
      \        = Bool()"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 215-225
    context: "215:     val isVset          = Bool()\n216:     val firstUop       \
      \ = Bool()\n217:     val lastUop         = Bool()\n218:     val numUops    \
      \     = UInt(log2Up(MaxUopSize).W) // rob need this\n219:     val numWB    \
      \       = UInt(log2Up(MaxUopSize).W) // rob need this\n220:     val commitType\
      \      = CommitType()\n221:     // rename\n222:     val srcState        = Vec(numSrc,
      SrcState())\n223:     val srcLoadDependency  = Vec(numSrc, Vec(LoadPipelineWidth,
      UInt(LoadDependencyWidth.W)))\n224:     val psrc            = Vec(numSrc, UInt(PhyRegIdxWidth.W))\n\
      225:     val pdest           = UInt(PhyRegIdxWidth.W)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 263-276
    context: "263: \n264:     def isLUI: Bool = this.fuType === FuType.alu.U && (this.selImm
      === SelImm.IMM_U || this.selImm === SelImm.IMM_LUI32)\n265:     def isLUI32:
      Bool = this.selImm === SelImm.IMM_LUI32\n266:     def isWFI: Bool = this.fuType
      === FuType.csr.U && fuOpType === CSROpType.wfi\n267: \n268:     def isSvinvalBegin(flush:
      Bool) = FuType.isFence(fuType) && fuOpType === FenceOpType.nofence && !flush\n\
      269:     def isSvinval(flush: Bool) = FuType.isFence(fuType) &&\n270:      \
      \ Cat(Seq(FenceOpType.sfence, FenceOpType.hfence_v, FenceOpType.hfence_g).map(_
      === fuOpType)).orR && !flush\n271:     def isSvinvalEnd(flush: Bool) = FuType.isFence(fuType)
      && fuOpType === FenceOpType.nofence && flush\n272:     def isNotSvinval = !FuType.isFence(fuType)\n\
      273: \n274:     def isHls: Bool = {\n275:       fuType === FuType.ldu.U && LSUOpType.isHlv(fuOpType)
      || fuType === FuType.stu.U && LSUOpType.isHsv(fuOpType)\n276:     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 275-287
    context: "275:       fuType === FuType.ldu.U && LSUOpType.isHlv(fuOpType) || fuType
      === FuType.stu.U && LSUOpType.isHsv(fuOpType)\n276:     }\n277: \n278:     def
      isAMOCAS: Bool = FuType.isAMO(fuType) && LSUOpType.isAMOCAS(fuOpType)\n279:\
      \ \n280:     def srcIsReady: Vec[Bool] = {\n281:       VecInit(this.srcType.zip(this.srcState).map
      {\n282:         case (t, s) => SrcType.isNotReg(t) || SrcState.isReady(s)\n\
      283:       })\n284:     }\n285: \n286:     def clearExceptions(\n287:      \
      \ exceptionBits: Seq[Int] = Seq(),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 283-297
    context: "283:       })\n284:     }\n285: \n286:     def clearExceptions(\n287:\
      \       exceptionBits: Seq[Int] = Seq(),\n288:       flushPipe    : Boolean
      = false,\n289:       replayInst   : Boolean = false\n290:     ): DynInst = {\n\
      291:       this.exceptionVec.zipWithIndex.filterNot(x => exceptionBits.contains(x._2)).foreach(_._1
      := false.B)\n292:       if (!flushPipe) { this.flushPipe := false.B }\n293:\
      \       if (!replayInst) { this.replayInst := false.B }\n294:       this\n295:\
      \     }\n296: \n297:     def needWriteRf: Bool = rfWen || fpWen || vecWen ||
      v0Wen || vlWen"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 376-386
    context: "376: \n377:     def isIQWakeUp = this.isInstanceOf[IssueQueueIQWakeUpBundle]\n\
      378: \n379:     def exuIdx: Int = {\n380:       require(hasOnlyOneSource)\n\
      381:       this.exuIndices.head\n382:     }\n383:   }\n384: \n385:   class IssueQueueWBWakeUpBundle(exuIndices:
      Seq[Int], backendParams: BackendParams)(implicit p: Parameters) extends IssueQueueWakeUpBaseBundle(backendParams.pregIdxWidth,
      exuIndices) {\n386: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 392-402
    context: "392:     copyWakeupOut: Boolean = false,\n393:     copyNum: Int = 0\n\
      394:   )(implicit p: Parameters) extends IssueQueueWakeUpBaseBundle(backendParams.pregIdxWidth,
      Seq(exuIdx)) {\n395:     val loadDependency = Vec(LoadPipelineWidth, UInt(LoadDependencyWidth.W))\n\
      396:     val is0Lat = Bool()\n397:     val params = backendParams.allExuParams.filter(_.exuIdx
      == exuIdx).head\n398:     val rcDest = OptionWrapper(params.needWriteRegCache,
      UInt(RegCacheIdxWidth.W))\n399:     val pdestCopy  = OptionWrapper(copyWakeupOut,
      Vec(copyNum, UInt(params.wbPregIdxWidth.W)))\n400:     val rfWenCopy  = OptionWrapper(copyWakeupOut
      && params.needIntWen, Vec(copyNum, Bool()))\n401:     val fpWenCopy  = OptionWrapper(copyWakeupOut
      && params.needFpWen, Vec(copyNum, Bool()))\n402:     val vecWenCopy = OptionWrapper(copyWakeupOut
      && params.needVecWen, Vec(copyNum, Bool()))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 509-521
    context: "509:   )(implicit\n510:     p: Parameters\n511:   ) extends XSBundle
      {\n512:     private val rfReadDataCfgSet: Seq[Set[DataConfig]] = exuParams.getRfReadDataCfgSet\n\
      513: \n514:     val rf: MixedVec[MixedVec[RfReadPortWithConfig]] = Flipped(MixedVec(\n\
      515:       rfReadDataCfgSet.map((set: Set[DataConfig]) =>\n516:         MixedVec(set.map((x:
      DataConfig) => new RfReadPortWithConfig(x, exuParams.rdPregIdxWidth)).toSeq)\n\
      517:       )\n518:     ))\n519: \n520:     val srcType = Vec(exuParams.numRegSrc,
      SrcType()) // used to select imm or reg data\n521:     val rcIdx = OptionWrapper(exuParams.needReadRegCache,
      Vec(exuParams.numRegSrc, UInt(RegCacheIdxWidth.W))) // used to select regcache
      data"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 526-537
    context: "526:     def exuIdx = exuParams.exuIdx\n527:     def getSource: SchedulerType
      = exuParams.getWBSource\n528: \n529:     def getRfReadValidBundle(issueValid:
      Bool): Seq[ValidIO[RfReadPortWithConfig]] = {\n530:       rf.zip(srcType).map
      {\n531:         case (rfRd: MixedVec[RfReadPortWithConfig], t: UInt) =>\n532:\
      \           makeValid(issueValid, rfRd.head)\n533:       }.toSeq\n534:     }\n\
      535:   }\n536: \n537:   class OGRespBundle(implicit p:Parameters, params: IssueBlockParams)
      extends XSBundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 626-636
    context: "626:     val vecWen        = if (params.needVecWen)    Some(Bool())\
      \                        else None\n627:     val v0Wen         = if (params.needV0Wen)\
      \     Some(Bool())                        else None\n628:     val vlWen    \
      \     = if (params.needVlWen)     Some(Bool())                        else None\n\
      629:     val fpu           = if (params.writeFflags)   Some(new FPUCtrlSignals)\
      \            else None\n630:     val vpu           = if (params.needVPUCtrl)\
      \   Some(new VPUCtrlSignals)            else None\n631:     val flushPipe  \
      \   = if (params.flushPipe)     Some(Bool())                        else None\n\
      632:     val pc            = if (params.needPc)        Some(UInt(VAddrData().dataWidth.W))
      else None\n633:     val preDecode     = if (params.hasPredecode)  Some(new PreDecodeInfo)\
      \             else None\n634:     val ftqIdx        = if (params.needPc || params.replayInst
      || params.hasStoreAddrFu || params.hasCSR)\n635:                           \
      \                        Some(new FtqPtr)                    else None\n636:\
      \     val ftqOffset     = if (params.needPc || params.replayInst || params.hasStoreAddrFu
      || params.hasCSR)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 668-702
    context: "668:       this.pdest         := source.common.pdest\n669:       this.isFirstIssue\
      \  := source.common.isFirstIssue // Only used by mem debug log\n670:       this.iqIdx\
      \         := source.common.iqIdx        // Only used by mem feedback\n671: \
      \      this.dataSources   := source.common.dataSources\n672:       this.debug_seqNum\
      \  := source.common.debug_seqNum\n673:       this.exuSources    .foreach(_ :=
      source.common.exuSources.get)\n674:       this.rfWen         .foreach(_ := source.common.rfWen.get)\n\
      675:       this.fpWen         .foreach(_ := source.common.fpWen.get)\n676: \
      \      this.vecWen        .foreach(_ := source.common.vecWen.get)\n677:    \
      \   this.v0Wen         .foreach(_ := source.common.v0Wen.get)\n678:       this.vlWen\
      \         .foreach(_ := source.common.vlWen.get)\n679:       this.fpu      \
      \     .foreach(_ := source.common.fpu.get)\n680:       this.vpu           .foreach(_
      := source.common.vpu.get)\n681:       this.flushPipe     .foreach(_ := source.common.flushPipe.get)\n\
      682:       this.pc            .foreach(_ := source.common.pc.get)\n683:    \
      \   this.preDecode     .foreach(_ := source.common.preDecode.get)\n684:    \
      \   this.nextPcOffset  .foreach(_ := source.common.nextPcOffset.get)\n685: \
      \      this.ftqIdx        .foreach(_ := source.common.ftqIdx.get)\n686:    \
      \   this.ftqOffset     .foreach(_ := source.common.ftqOffset.get)\n687:    \
      \   this.predictInfo   .foreach(_ := source.common.predictInfo.get)\n688:  \
      \     this.loadWaitBit   .foreach(_ := source.common.loadWaitBit.get)\n689:\
      \       this.waitForRobIdx .foreach(_ := source.common.waitForRobIdx.get)\n\
      690:       this.storeSetHit   .foreach(_ := source.common.storeSetHit.get)\n\
      691:       this.loadWaitStrict.foreach(_ := source.common.loadWaitStrict.get)\n\
      692:       this.ssid          .foreach(_ := source.common.ssid.get)\n693:  \
      \     this.lqIdx         .foreach(_ := source.common.lqIdx.get)\n694:      \
      \ this.sqIdx         .foreach(_ := source.common.sqIdx.get)\n695:       this.numLsElem\
      \     .foreach(_ := source.common.numLsElem.get)\n696:       this.srcTimer \
      \     .foreach(_ := source.common.srcTimer.get)\n697:       this.loadDependency.foreach(_
      := source.common.loadDependency.get.map(_ << 1))\n698:     }\n699:   }\n700:\
      \ \n701:   // ExuInput --[FuncUnit]--> ExuOutput\n702:   class ExuOutput("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 710-726
    context: "710:     val intWen       = if (params.needIntWen)   Some(Bool())  \
      \                else None\n711:     val fpWen        = if (params.needFpWen)\
      \    Some(Bool())                  else None\n712:     val vecWen       = if
      (params.needVecWen)   Some(Bool())                  else None\n713:     val
      v0Wen        = if (params.needV0Wen)    Some(Bool())                  else None\n\
      714:     val vlWen        = if (params.needVlWen)    Some(Bool())          \
      \        else None\n715:     val redirect     = if (params.hasRedirect)  Some(ValidIO(new
      Redirect))   else None\n716:     val fflags       = if (params.writeFflags)\
      \  Some(UInt(5.W))               else None\n717:     val wflags       = if (params.writeFflags)\
      \  Some(Bool())                  else None\n718:     val vxsat        = if (params.writeVxsat)\
      \   Some(Bool())                  else None\n719:     val exceptionVec = if
      (params.exceptionOut.nonEmpty) Some(ExceptionVec()) else None\n720:     val
      flushPipe    = if (params.flushPipe)    Some(Bool())                  else None\n\
      721:     val replay       = if (params.replayInst)   Some(Bool())          \
      \        else None\n722:     val lqIdx        = if (params.hasLoadFu)    Some(new
      LqPtr())             else None\n723:     val sqIdx        = if (params.hasStoreAddrFu
      || params.hasStdFu)\n724:                                                 Some(new
      SqPtr())             else None\n725:     val trigger      = if (params.trigger)\
      \      Some(TriggerAction())           else None\n726:     // uop info"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 751-764
    context: "751:     val v0Wen = Bool()\n752:     val vlWen = Bool()\n753:     val
      pdest = UInt(params.pregIdxWidth(backendParams).W)\n754:     val data = UInt(params.dataWidth.W)\n\
      755:     val robIdx = new RobPtr()(p)\n756:     val flushPipe = Bool()\n757:\
      \     val replayInst = Bool()\n758:     val redirect = ValidIO(new Redirect)\n\
      759:     val fflags = UInt(5.W)\n760:     val vxsat = Bool()\n761:     val exceptionVec
      = ExceptionVec()\n762:     val debug = new DebugBundle\n763:     val debugInfo
      = new PerfDebugInfo\n764:     val debug_seqNum = InstSeqNum()"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 773-786
    context: "773:       this.v0Wen  := source.v0Wen.getOrElse(false.B)\n774:    \
      \   this.vlWen  := source.vlWen.getOrElse(false.B)\n775:       this.pdest  :=
      source.pdest\n776:       this.data   := source.data(source.params.wbIndex(typeMap(wbType)))\n\
      777:       this.robIdx := source.robIdx\n778:       this.flushPipe := source.flushPipe.getOrElse(false.B)\n\
      779:       this.replayInst := source.replay.getOrElse(false.B)\n780:       this.redirect
      := source.redirect.getOrElse(0.U.asTypeOf(this.redirect))\n781:       this.fflags
      := source.fflags.getOrElse(0.U.asTypeOf(this.fflags))\n782:       this.vxsat
      := source.vxsat.getOrElse(0.U.asTypeOf(this.vxsat))\n783:       this.exceptionVec
      := source.exceptionVec.getOrElse(0.U.asTypeOf(this.exceptionVec))\n784:    \
      \   this.debug := source.debug\n785:       this.debugInfo := source.debugInfo\n\
      786:       this.debug_seqNum := source.debug_seqNum"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 784-796
    context: "784:       this.debug := source.debug\n785:       this.debugInfo :=
      source.debugInfo\n786:       this.debug_seqNum := source.debug_seqNum\n787:\
      \     }\n788: \n789:     def asIntRfWriteBundle(fire: Bool): RfWritePortWithConfig
      = {\n790:       val rfWrite = Wire(Output(new RfWritePortWithConfig(this.params.dataCfg,
      backendParams.getPregParams(IntData()).addrWidth)))\n791:       rfWrite.wen
      := this.rfWen && fire\n792:       rfWrite.addr := this.pdest\n793:       rfWrite.data
      := this.data\n794:       rfWrite.intWen := this.rfWen\n795:       rfWrite.fpWen
      := false.B\n796:       rfWrite.vecWen := false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 797-809
    context: "797:       rfWrite.v0Wen := false.B\n798:       rfWrite.vlWen := false.B\n\
      799:       rfWrite\n800:     }\n801: \n802:     def asFpRfWriteBundle(fire:
      Bool): RfWritePortWithConfig = {\n803:       val rfWrite = Wire(Output(new RfWritePortWithConfig(this.params.dataCfg,
      backendParams.getPregParams(FpData()).addrWidth)))\n804:       rfWrite.wen :=
      this.fpWen && fire\n805:       rfWrite.addr := this.pdest\n806:       rfWrite.data
      := this.data\n807:       rfWrite.intWen := false.B\n808:       rfWrite.fpWen
      := this.fpWen\n809:       rfWrite.vecWen := false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 810-822
    context: "810:       rfWrite.v0Wen := false.B\n811:       rfWrite.vlWen := false.B\n\
      812:       rfWrite\n813:     }\n814: \n815:     def asVfRfWriteBundle(fire:
      Bool): RfWritePortWithConfig = {\n816:       val rfWrite = Wire(Output(new RfWritePortWithConfig(this.params.dataCfg,
      backendParams.getPregParams(VecData()).addrWidth)))\n817:       rfWrite.wen
      := this.vecWen && fire\n818:       rfWrite.addr := this.pdest\n819:       rfWrite.data
      := this.data\n820:       rfWrite.intWen := false.B\n821:       rfWrite.fpWen
      := false.B\n822:       rfWrite.vecWen := this.vecWen"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 823-835
    context: "823:       rfWrite.v0Wen := false.B\n824:       rfWrite.vlWen := false.B\n\
      825:       rfWrite\n826:     }\n827: \n828:     def asV0RfWriteBundle(fire:
      Bool): RfWritePortWithConfig = {\n829:       val rfWrite = Wire(Output(new RfWritePortWithConfig(this.params.dataCfg,
      backendParams.getPregParams(V0Data()).addrWidth)))\n830:       rfWrite.wen :=
      this.v0Wen && fire\n831:       rfWrite.addr := this.pdest\n832:       rfWrite.data
      := this.data\n833:       rfWrite.intWen := false.B\n834:       rfWrite.fpWen
      := false.B\n835:       rfWrite.vecWen := false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 836-848
    context: "836:       rfWrite.v0Wen := this.v0Wen\n837:       rfWrite.vlWen :=
      false.B\n838:       rfWrite\n839:     }\n840: \n841:     def asVlRfWriteBundle(fire:
      Bool): RfWritePortWithConfig = {\n842:       val rfWrite = Wire(Output(new RfWritePortWithConfig(this.params.dataCfg,
      backendParams.getPregParams(VlData()).addrWidth)))\n843:       rfWrite.wen :=
      this.vlWen && fire\n844:       rfWrite.addr := this.pdest\n845:       rfWrite.data
      := this.data\n846:       rfWrite.intWen := false.B\n847:       rfWrite.fpWen
      := false.B\n848:       rfWrite.vecWen := false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 864-874
    context: "864:   }\n865: \n866:   class ExceptionInfo(implicit p: Parameters)
      extends XSBundle {\n867:     val pc = UInt(VAddrData().dataWidth.W)\n868:  \
      \   val instr = UInt(32.W)\n869:     val commitType = CommitType()\n870:   \
      \  val exceptionVec = ExceptionVec()\n871:     val isPcBkpt = Bool()\n872: \
      \    val isFetchMalAddr = Bool()\n873:     val gpaddr = UInt(XLEN.W)\n874: \
      \    val singleStep = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/TraceBuffer.scala
    lines: 37-47
    context: "37:   }\n38: \n39:   val blocksUpdate = WireInit(io.in.fromRob.blocks)\n\
      40:   for(i <- 1 until CommitWidth){\n41:     when(!needPcVec(i-1)){\n42:  \
      \     blocksUpdate(i).bits.tracePipe.iretire := blocksUpdate(i - 1).bits.tracePipe.iretire
      + io.in.fromRob.blocks(i).bits.tracePipe.iretire\n43:       blocksUpdate(i).bits.ftqOffset.get
      := blocksUpdate(i - 1).bits.ftqOffset.get\n44:       blocksUpdate(i).bits.ftqIdx.get
      := blocksUpdate(i - 1).bits.ftqIdx.get\n45:      }\n46:   }\n47: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/Interface.scala
    lines: 14-24
    context: "14:   val currentPriv = Priv()\n15: }\n16: \n17: class TracePipe(iretireWidth:
      Int)(implicit val p: Parameters) extends Bundle with HasXSParameter {\n18: \
      \  val itype     = Itype()\n19:   val iretire   = UInt(iretireWidth.W)\n20:\
      \   val ilastsize = Ilastsize()\n21: }\n22: \n23: class TraceBlock(hasIaddr:
      Boolean, iretireWidth: Int)(implicit val p: Parameters) extends Bundle with
      HasXSParameter {\n24:   val iaddr     = if (hasIaddr)   Some(UInt(IaddrWidth.W))\
      \                else None"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/Interface.scala
    lines: 49-59
    context: "49:     }\n50:     val groups = Vec(TraceGroupNum, ValidIO(new Bundle{\n\
      51:       val iaddr     = UInt(IaddrWidth.W)\n52:       val ftqOffset = if (hasOffset)\
      \  Some(UInt(log2Up(PredictWidth).W)) else None\n53:       val itype     = UInt(ItypeWidth.W)\n\
      54:       val iretire   = UInt(IretireWidthCompressed.W)\n55:       val ilastsize
      = UInt(IlastsizeWidth.W)\n56:     }))\n57:   })\n58: }\n59: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/Interface.scala
    lines: 60-71
    context: "60: object Itype extends NamedUInt(4) {\n61:   def None            \
      \     = 0.U\n62:   def Exception            = 1.U    //rob\n63:   def Interrupt\
      \            = 2.U    //rob\n64:   def ExpIntReturn         = 3.U    //rename\n\
      65:   def NonTaken             = 4.U    //commit\n66:   def Taken          \
      \      = 5.U    //commit\n67:   def UninferableJump      = 6.U    //It's reserved
      when width of itype is 4.\n68:   def reserved             = 7.U    //reserved\n\
      69:   def UninferableCall      = 8.U    //rename\n70:   def InferableCall  \
      \      = 9.U    //rename\n71:   def UninferableTailCall  = 10.U   //rename"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/Interface.scala
    lines: 84-98
    context: "84:     val isJal       = brType === BrType.jal\n85:     val isJalr\
      \      = brType === BrType.jalr\n86:     val isBranch    = brType === BrType.branch\n\
      87: \n88:     // push to RAS when rd is link, pop from RAS when rs is link\n\
      89:     def isUninferableCall      = isJalr && rd.isLink && (!rs.isLink || rs.isLink
      && isEqualRdRs)  //8   push\n90:     def isInferableCall        = isJal && rd.isLink\
      \                                               //9   push\n91:     def isUninferableTailCall\
      \  = isJalr && rd.isX0 && !rs.isLink                                  //10 \
      \ no op\n92:     def isInferableTailCall    = isJal && rd.isX0             \
      \                                    //11  no op\n93:     def isCoRoutineSwap\
      \        = isJalr && rd.isLink && rs.isLink && !isEqualRdRs                \
      \ //12  pop then push\n94:     def isFunctionReturn       = isJalr && !rd.isLink
      && rs.isLink                                //13  pop\n95:     def isOtherUninferableJump
      = isJalr && !rd.isLink && !rd.isX0 && !rs.isLink                   //14  no
      op\n96:     def isOtherInferableJump   = isJal && !rd.isLink && !rd.isX0   \
      \                               //15  no op\n97: \n98:     val jumpType = Mux1H("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 91-101
    context: "91: class DecodeUnitCompOutput(implicit p: Parameters) extends XSBundle
      {\n92:   val complexDecodedInsts = Vec(RenameWidth, DecoupledIO(new DecodedInst))\n\
      93: }\n94: \n95: class DecodeUnitCompIO(implicit p: Parameters) extends XSBundle
      {\n96:   val redirect = Input(Bool())\n97:   val csrCtrl = Input(new CustomCSRCtrlIO)\n\
      98:   val vtypeBypass = Input(new VType)\n99:   // When the first inst in decode
      vector is complex inst, pass it in\n100:   val in = Flipped(DecoupledIO(new
      DecodeUnitCompInput))\n101:   val out = new DecodeUnitCompOutput"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 107-117
    context: "107:  */\n108: class DecodeUnitComp()(implicit p : Parameters) extends
      XSModule with DecodeUnitConstants with VectorConstants {\n109:   val io = IO(new
      DecodeUnitCompIO)\n110: \n111:   // alias\n112:   private val inReady = io.in.ready\n\
      113:   private val inValid = io.in.valid\n114:   private val inDecodedInst =
      WireInit(io.in.bits.simpleDecodedInst)\n115:   private val inInstFields = io.in.bits.simpleDecodedInst.instr.asTypeOf(new
      XSInstBitFields)\n116:   private val inUopInfo = io.in.bits.uopInfo\n117:  \
      \ private val outValids = io.out.complexDecodedInsts.map(_.valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 113-128
    context: "113:   private val inValid = io.in.valid\n114:   private val inDecodedInst
      = WireInit(io.in.bits.simpleDecodedInst)\n115:   private val inInstFields =
      io.in.bits.simpleDecodedInst.instr.asTypeOf(new XSInstBitFields)\n116:   private
      val inUopInfo = io.in.bits.uopInfo\n117:   private val outValids = io.out.complexDecodedInsts.map(_.valid)\n\
      118:   private val outReadys = io.out.complexDecodedInsts.map(_.ready)\n119:\
      \   private val outDecodedInsts = io.out.complexDecodedInsts.map(_.bits)\n120:\
      \   private val outComplexNum = io.complexNum\n121: \n122:   val maxUopSize
      = MaxUopSize\n123:   when (io.in.fire && io.in.bits.simpleDecodedInst.isVset)
      {\n124:     when(inInstFields.RD === 0.U && inInstFields.RS1 === 0.U) {\n125:\
      \       inDecodedInst.fuOpType := VSETOpType.keepVl(io.in.bits.simpleDecodedInst.fuOpType)\n\
      126:     }.elsewhen(inInstFields.RS1 === 0.U) {\n127:       inDecodedInst.fuOpType
      := VSETOpType.setVlmax(io.in.bits.simpleDecodedInst.fuOpType)\n128:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 126-137
    context: "126:     }.elsewhen(inInstFields.RS1 === 0.U) {\n127:       inDecodedInst.fuOpType
      := VSETOpType.setVlmax(io.in.bits.simpleDecodedInst.fuOpType)\n128:     }\n\
      129:   }\n130: \n131:   val latchedInst = RegEnable(inDecodedInst, inValid &&
      inReady)\n132:   val latchedUopInfo = RegEnable(inUopInfo, inValid && inReady)\n\
      133:   //input bits\n134:   private val instFields: XSInstBitFields = latchedInst.instr.asTypeOf(new
      XSInstBitFields)\n135: \n136:   val src1 = Cat(0.U(1.W), instFields.RS1)\n137:\
      \   val src2 = Cat(0.U(1.W), instFields.RS2)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 175-186
    context: "175:   numOfUop := latchedUopInfo.numOfUop\n176:   numOfWB := latchedUopInfo.numOfWB\n\
      177: \n178:   //uops dispatch\n179:   val s_idle :: s_active :: Nil = Enum(2)\n\
      180:   val state = RegInit(s_idle)\n181:   val stateNext = WireDefault(state)\n\
      182:   val numDecodedUop = RegInit(0.U(log2Up(maxUopSize).W))\n183:   val uopRes
      = RegInit(0.U(log2Up(maxUopSize).W))\n184:   val uopResNext = WireInit(uopRes)\n\
      185:   val e64 = 3.U(2.W)\n186:   val isUsSegment = instFields.MOP === 0.U &&
      ((nf =/= 0.U && instFields.LUMOP === 0.U) || instFields.LUMOP === \"b10000\"\
      .U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 189-199
    context: "189: \n190:   //uop div up to maxUopSize\n191:   val csBundle = Wire(Vec(maxUopSize,
      new DecodedInst))\n192:   val fixedDecodedInst = Wire(Vec(maxUopSize, new DecodedInst))\n\
      193: \n194:   csBundle.foreach { case dst =>\n195:     dst := latchedInst\n\
      196:     dst.numUops := latchedUopInfo.numOfUop\n197:     dst.numWB := latchedUopInfo.numOfWB\n\
      198:     dst.exceptionVec(ExceptionNO.EX_II) := latchedInst.exceptionVec(ExceptionNO.EX_II)
      || illegalInst\n199:     dst.firstUop := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 205-215
    context: "205:   csBundle(numOfUop - 1.U).lastUop := true.B\n206: \n207:   //
      when vstart is not zero, the last uop will modify vstart to zero\n208:   //
      therefore, blockback and flush pipe\n209:   csBundle(numOfUop - 1.U).blockBackward
      := vstartReg =/= 0.U\n210:   csBundle(0.U).flushPipe := vstartReg =/= 0.U\n\
      211: \n212:   switch(typeOfSplit) {\n213:     is(UopSplitType.AMO_CAS_W) {\n\
      214:       csBundle(0).uopIdx := 0.U\n215:       csBundle(0).fuOpType := Cat(1.U(3.W),
      LSUOpType.amocas_w)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 278-288
    context: "278:       // In simple decoder, rfWen and vecWen are not set\n279:\
      \       when(isVsetSimple) {\n280:         // Default\n281:         // uop0
      set rd, never flushPipe\n282:         csBundle(0).fuType := FuType.vsetiwi.U\n\
      283:         csBundle(0).flushPipe := Mux(VSETOpType.isVsetvl(latchedInst.fuOpType),
      true.B, vstartReg =/= 0.U)\n284:         csBundle(0).blockBackward := false.B\n\
      285:         csBundle(0).rfWen := true.B\n286:         // uop1 set vl, vsetvl
      will flushPipe\n287:         csBundle(1).ldest := Vl_IDX.U\n288:         csBundle(1).vecWen
      := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 285-295
    context: "285:         csBundle(0).rfWen := true.B\n286:         // uop1 set vl,
      vsetvl will flushPipe\n287:         csBundle(1).ldest := Vl_IDX.U\n288:    \
      \     csBundle(1).vecWen := false.B\n289:         csBundle(1).vlWen := true.B\n\
      290:         csBundle(1).flushPipe := false.B\n291:         csBundle(1).blockBackward
      := Mux(VSETOpType.isVsetvl(latchedInst.fuOpType), true.B, vstartReg =/= 0.U)\n\
      292:         when(VSETOpType.isVsetvli(latchedInst.fuOpType) && dest === 0.U
      && src1 === 0.U) {\n293:           // write nothing, uop0 is a nop instruction\n\
      294:           csBundle(0).rfWen := false.B\n295:           csBundle(0).fpWen
      := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 1755-1765
    context: "1755:         csBundle(i + 1).lsrc(2) := dest + i.U // old vd\n1756:\
      \         csBundle(i + 1).ldest := dest + i.U\n1757:         csBundle(i + 1).uopIdx
      := i.U\n1758:         csBundle(i + 1).vlsInstr := true.B\n1759:       }\n1760:\
      \       csBundle.head.waitForward := isUsSegment\n1761:       csBundle(numOfUop
      - 1.U).blockBackward := isUsSegment\n1762:     }\n1763:     is(UopSplitType.VEC_US_FF_LD)
      {\n1764:       csBundle(0).srcType(0) := SrcType.reg\n1765:       csBundle(0).srcType(1)
      := SrcType.imm"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 1778-1788
    context: "1778:         csBundle(i + 1).lsrc(2) := dest + i.U // old vd\n1779:\
      \         csBundle(i + 1).ldest := dest + i.U\n1780:         csBundle(i + 1).uopIdx
      := i.U\n1781:         csBundle(i + 1).vlsInstr := true.B\n1782:       }\n1783:\
      \       csBundle.head.waitForward := isUsSegment\n1784:       csBundle(numOfUop
      - 1.U).blockBackward := isUsSegment\n1785:       // last uop read vl and write
      vl\n1786:       csBundle(numOfUop - 1.U).srcType(0) := SrcType.no\n1787:   \
      \    csBundle(numOfUop - 1.U).srcType(1) := SrcType.no\n1788:       csBundle(numOfUop
      - 1.U).srcType(2) := SrcType.no"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 1830-1840
    context: "1830:         csBundle(i + 2).lsrc(2) := dest + i.U // old vd\n1831:\
      \         csBundle(i + 2).ldest := dest + i.U\n1832:         csBundle(i + 2).uopIdx
      := i.U\n1833:         csBundle(i + 2).vlsInstr := true.B\n1834:       }\n1835:\
      \       csBundle.head.waitForward := isSdSegment\n1836:       csBundle(numOfUop
      - 1.U).blockBackward := isSdSegment\n1837:     }\n1838:     is(UopSplitType.VEC_I_LDST)
      {\n1839:       def genCsBundle_SEGMENT_INDEXED_LOADSTORE(lmul:Int, nf:Int):
      Unit ={\n1840:         for (i <- 0 until MAX_VLMUL) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 1975-1985
    context: "1975:           for (i <- 0 until MAX_VLMUL) {\n1976:             csBundle(i
      + 1).vecWen := false.B\n1977:           }\n1978:         }\n1979:       }\n\
      1980:       csBundle.head.waitForward := isIxSegment\n1981:       csBundle(numOfUop
      - 1.U).blockBackward := isIxSegment\n1982:     }\n1983:   }\n1984: \n1985: \
      \  //readyFromRename Counter"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 1981-1991
    context: "1981:       csBundle(numOfUop - 1.U).blockBackward := isIxSegment\n\
      1982:     }\n1983:   }\n1984: \n1985:   //readyFromRename Counter\n1986:   val
      readyCounter = Mux(outReadys.head, RenameWidth.U, 0.U)\n1987: \n1988:   // The
      left uops of the complex inst in ComplexDecoder can be send out this cycle\n\
      1989:   val thisAllOut = uopRes <= readyCounter\n1990: \n1991:   val count =
      RegInit(0.U(log2Up(maxUopSize/RenameWidth + 1).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 1989-2002
    context: "1989:   val thisAllOut = uopRes <= readyCounter\n1990: \n1991:   val
      count = RegInit(0.U(log2Up(maxUopSize/RenameWidth + 1).W))\n1992:   val countNext
      = WireInit(count)\n1993: \n1994:   switch(state) {\n1995:     is(s_idle) {\n\
      1996:       when (inValid) {\n1997:         stateNext := s_active\n1998:   \
      \      uopResNext := inUopInfo.numOfUop\n1999:         countNext := 0.U\n2000:\
      \       }\n2001:     }\n2002:     is(s_active) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 2000-2027
    context: "2000:       }\n2001:     }\n2002:     is(s_active) {\n2003:       when
      (thisAllOut) {\n2004:         when (inValid) {\n2005:           stateNext :=
      s_active\n2006:           uopResNext := inUopInfo.numOfUop\n2007:         }.otherwise
      {\n2008:           stateNext := s_idle\n2009:           uopResNext := 0.U\n\
      2010:         }\n2011:         countNext := 0.U\n2012:       }.otherwise {\n\
      2013:         stateNext := s_active\n2014:         uopResNext := uopRes - readyCounter\n\
      2015:         countNext := count + outReadys.head.asUInt\n2016:       }\n2017:\
      \     }\n2018:   }\n2019: \n2020:   state := Mux(io.redirect, s_idle, stateNext)\n\
      2021:   uopRes := Mux(io.redirect, 0.U, uopResNext)\n2022:   count := Mux(io.redirect,
      0.U, countNext)\n2023: \n2024:   val complexNum = Mux(uopRes > readyCounter,
      readyCounter, uopRes)\n2025: \n2026:   fixedDecodedInst := csBundle\n2027: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 2025-2035
    context: "2025: \n2026:   fixedDecodedInst := csBundle\n2027: \n2028:   // when
      vstart is not zero, the last uop will modify vstart to zero\n2029:   // therefore,
      blockback and flush pipe\n2030:   fixedDecodedInst(numOfUop - 1.U).flushPipe
      := (vstartReg =/= 0.U) || latchedInst.flushPipe\n2031:   val uopsSeq = (0 until
      RenameWidth).map(i => VecInit(fixedDecodedInst.zipWithIndex.filter(_._2 % RenameWidth
      == i).map(_._1)))\n2032: \n2033:   /** Generate output insts and valid signals
      */\n2034:   for(i <- 0 until RenameWidth) {\n2035:     outValids(i) := complexNum
      > i.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 2035-2046
    context: "2035:     outValids(i) := complexNum > i.U\n2036:     outDecodedInsts(i)
      := uopsSeq(i)(count)\n2037:   }\n2038: \n2039:   /** Generate number of valid
      output insts */\n2040:   outComplexNum := Mux(state === s_active, complexNum,
      0.U)\n2041:   inReady := state === s_idle || state === s_active && thisAllOut\n\
      2042: \n2043: \n2044:   XSError(inValid && inUopInfo.numOfUop === 0.U,\n2045:\
      \     p\"uop number ${inUopInfo.numOfUop} is illegal, cannot be zero\")\n2046:
      //  val validSimple = Wire(Vec(DecodeWidth, Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 34-44
    context: "34:   })\n35: \n36:   val inst = io.instr.asTypeOf(new XSInstBitFields)\n\
      37:   val fpToVecInsts = Seq(\n38:     FADD_S, FSUB_S, FADD_D, FSUB_D, FADD_H,
      FSUB_H,\n39:     FEQ_S, FLT_S, FLE_S, FEQ_D, FLT_D, FLE_D, FEQ_H, FLT_H, FLE_H,\n\
      40:     FMIN_S, FMAX_S, FMIN_D, FMAX_D, FMIN_H, FMAX_H,\n41:     FMUL_S, FMUL_D,
      FMUL_H,\n42:     FDIV_S, FDIV_D, FSQRT_S, FSQRT_D, FDIV_H, FSQRT_H,\n43:   \
      \  FMADD_S, FMSUB_S, FNMADD_S, FNMSUB_S, FMADD_D, FMSUB_D, FNMADD_D, FNMSUB_D,
      FMADD_H, FMSUB_H, FNMADD_H, FNMSUB_H,\n44:     FCLASS_S, FCLASS_D, FSGNJ_S,
      FSGNJ_D, FSGNJX_S, FSGNJX_D, FSGNJN_S, FSGNJN_D,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 40-56
    context: "40:     FMIN_S, FMAX_S, FMIN_D, FMAX_D, FMIN_H, FMAX_H,\n41:     FMUL_S,
      FMUL_D, FMUL_H,\n42:     FDIV_S, FDIV_D, FSQRT_S, FSQRT_D, FDIV_H, FSQRT_H,\n\
      43:     FMADD_S, FMSUB_S, FNMADD_S, FNMSUB_S, FMADD_D, FMSUB_D, FNMADD_D, FNMSUB_D,
      FMADD_H, FMSUB_H, FNMADD_H, FNMSUB_H,\n44:     FCLASS_S, FCLASS_D, FSGNJ_S,
      FSGNJ_D, FSGNJX_S, FSGNJX_D, FSGNJN_S, FSGNJN_D,\n45:     FCLASS_H, FSGNJ_H,
      FSGNJX_H, FSGNJN_H,\n46:     // scalar cvt inst\n47:     FCVT_W_S, FCVT_WU_S,
      FCVT_L_S, FCVT_LU_S,\n48:     FCVT_W_D, FCVT_WU_D, FCVT_L_D, FCVT_LU_D, FCVT_S_D,
      FCVT_D_S,\n49:     FCVT_S_H, FCVT_H_S, FCVT_H_D, FCVT_D_H,\n50:     FMV_X_W,
      FMV_X_D, FMV_X_H,\n51:     FCVT_W_H, FCVT_WU_H, FCVT_L_H, FCVT_LU_H,\n52:  \
      \   // zfa inst\n53:     FLEQ_H, FLEQ_S, FLEQ_D, FLTQ_H, FLTQ_S, FLTQ_D, FMINM_H,
      FMINM_S, FMINM_D, FMAXM_H, FMAXM_S, FMAXM_D,\n54:     FROUND_H, FROUND_S, FROUND_D,
      FROUNDNX_H, FROUNDNX_S, FROUNDNX_D, FCVTMOD_W_D,\n55:   )\n56:   val isFpToVecInst
      = fpToVecInsts.map(io.instr === _).reduce(_ || _)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 54-67
    context: "54:     FROUND_H, FROUND_S, FROUND_D, FROUNDNX_H, FROUNDNX_S, FROUNDNX_D,
      FCVTMOD_W_D,\n55:   )\n56:   val isFpToVecInst = fpToVecInsts.map(io.instr ===
      _).reduce(_ || _)\n57:   val isFP16Instrs = Seq(\n58:     // zfh inst\n59: \
      \    FADD_H, FSUB_H, FEQ_H, FLT_H, FLE_H, FMIN_H, FMAX_H,\n60:     FMUL_H, FDIV_H,
      FSQRT_H,\n61:     FMADD_H, FMSUB_H, FNMADD_H, FNMSUB_H,\n62:     FCLASS_H, FSGNJ_H,
      FSGNJX_H, FSGNJN_H,\n63:     // zfa inst\n64:     FLEQ_H, FLTQ_H, FMINM_H, FMAXM_H,\n\
      65:     FROUND_H, FROUNDNX_H,\n66:   )\n67:   val isFP16Instr = isFP16Instrs.map(io.instr
      === _).reduce(_ || _)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 64-74
    context: "64:     FLEQ_H, FLTQ_H, FMINM_H, FMAXM_H,\n65:     FROUND_H, FROUNDNX_H,\n\
      66:   )\n67:   val isFP16Instr = isFP16Instrs.map(io.instr === _).reduce(_ ||
      _)\n68:   val isFP32Instrs = Seq(\n69:     FADD_S, FSUB_S, FEQ_S, FLT_S, FLE_S,
      FMIN_S, FMAX_S,\n70:     FMUL_S, FDIV_S, FSQRT_S,\n71:     FMADD_S, FMSUB_S,
      FNMADD_S, FNMSUB_S,\n72:     FCLASS_S, FSGNJ_S, FSGNJX_S, FSGNJN_S,\n73:   \
      \  // zfa inst\n74:     FLEQ_S, FLTQ_S, FMINM_S, FMAXM_S,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 74-84
    context: "74:     FLEQ_S, FLTQ_S, FMINM_S, FMAXM_S,\n75:     FROUND_S, FROUNDNX_S,\n\
      76:   )\n77:   val isFP32Instr = isFP32Instrs.map(io.instr === _).reduce(_ ||
      _)\n78:   val isFP64Instrs = Seq(\n79:     FADD_D, FSUB_D, FEQ_D, FLT_D, FLE_D,
      FMIN_D, FMAX_D,\n80:     FMUL_D, FDIV_D, FSQRT_D,\n81:     FMADD_D, FMSUB_D,
      FNMADD_D, FNMSUB_D,\n82:     FCLASS_D, FSGNJ_D, FSGNJX_D, FSGNJN_D,\n83:   )\n\
      84:   val isFP64Instr = isFP64Instrs.map(io.instr === _).reduce(_ || _)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 82-92
    context: "82:     FCLASS_D, FSGNJ_D, FSGNJX_D, FSGNJN_D,\n83:   )\n84:   val isFP64Instr
      = isFP64Instrs.map(io.instr === _).reduce(_ || _)\n85:   // scalar cvt inst\n\
      86:   val isSew2Cvts = Seq(\n87:     FCVT_W_S, FCVT_WU_S, FCVT_L_S, FCVT_LU_S,\n\
      88:     FCVT_W_D, FCVT_WU_D, FCVT_S_D, FCVT_D_S,\n89:     FMV_X_W,\n90:    \
      \ // zfa inst\n91:     FCVTMOD_W_D,\n92:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 99-109
    context: "99:   val isSew2Cvth = Seq(\n100:     FCVT_S_H, FCVT_H_S, FCVT_D_H,\n\
      101:     FMV_X_H,\n102:     FCVT_W_H, FCVT_L_H, FCVT_H_W,\n103:     FCVT_H_L,
      FCVT_H_WU, FCVT_H_LU,\n104:     FCVT_WU_H, FCVT_LU_H,\n105:   )\n106:   val
      isSew2Cvt32 = isSew2Cvts.map(io.instr === _).reduce(_ || _)\n107:   val isSew2Cvt16
      = isSew2Cvth.map(io.instr === _).reduce(_ || _)\n108:   val isLmulMf4Cvts =
      Seq(\n109:     FCVT_W_S, FCVT_WU_S,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 110-120
    context: "110:     FMV_X_W,\n111:   )\n112:   val isLmulMf4Cvt = isLmulMf4Cvts.map(io.instr
      === _).reduce(_ || _)\n113:   val needReverseInsts = Seq(\n114:     FADD_S,
      FSUB_S, FADD_D, FSUB_D, FADD_H, FSUB_H,\n115:     FEQ_S, FLT_S, FLE_S, FEQ_D,
      FLT_D, FLE_D, FEQ_H, FLT_H, FLE_H,\n116:     FMIN_S, FMAX_S, FMIN_D, FMAX_D,
      FMIN_H, FMAX_H,\n117:     FMUL_S, FMUL_D, FMUL_H,\n118:     FDIV_S, FDIV_D,
      FSQRT_S, FSQRT_D, FDIV_H, FSQRT_H,\n119:     FMADD_S, FMSUB_S, FNMADD_S, FNMSUB_S,
      FMADD_D, FMSUB_D, FNMADD_D, FNMSUB_D,\n120:     FMADD_H, FMSUB_H, FNMADD_H,
      FNMSUB_H,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 117-127
    context: "117:     FMUL_S, FMUL_D, FMUL_H,\n118:     FDIV_S, FDIV_D, FSQRT_S,
      FSQRT_D, FDIV_H, FSQRT_H,\n119:     FMADD_S, FMSUB_S, FNMADD_S, FNMSUB_S, FMADD_D,
      FMSUB_D, FNMADD_D, FNMSUB_D,\n120:     FMADD_H, FMSUB_H, FNMADD_H, FNMSUB_H,\n\
      121:     FCLASS_S, FCLASS_D, FSGNJ_S, FSGNJ_D, FSGNJX_S, FSGNJX_D, FSGNJN_S,
      FSGNJN_D,\n122:     FCLASS_H, FSGNJ_H, FSGNJX_H, FSGNJN_H,\n123:     // zfa
      inst\n124:     FLEQ_H, FLEQ_S, FLEQ_D, FLTQ_H, FLTQ_S, FLTQ_D, FMINM_H, FMINM_S,
      FMINM_D, FMAXM_H, FMAXM_S, FMAXM_D,\n125:   )\n126:   val needReverseInst =
      needReverseInsts.map(_ === inst.ALL).reduce(_ || _)\n127:   io.vpuCtrl := 0.U.asTypeOf(io.vpuCtrl)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 177-190
    context: "177:     FMV_X_W  -> List(N,d,i,N,N,N,N,N,N), // dont box result of
      fmv.fp.int\n178:     FCLASS_S -> List(N,s,i,N,N,N,N,N,N),\n179:     FCVT_W_S
      -> List(N,s,i,N,Y,N,N,N,Y),\n180:     FCVT_WU_S-> List(N,s,i,N,Y,N,N,N,Y),\n\
      181:     FCVT_L_S -> List(N,s,i,N,Y,N,N,N,Y),\n182:     FCVT_LU_S-> List(N,s,i,N,Y,N,N,N,Y),\n\
      183:     FEQ_S    -> List(N,s,i,N,Y,N,N,N,N),\n184:     FLT_S    -> List(N,s,i,N,Y,N,N,N,N),\n\
      185:     FLE_S    -> List(N,s,i,N,Y,N,N,N,N),\n186:     // FPToFP\n187:    \
      \ FSGNJ_S  -> List(N,s,s,N,N,Y,N,N,N),\n188:     FSGNJN_S -> List(N,s,s,N,N,Y,N,N,N),\n\
      189:     FSGNJX_S -> List(N,s,s,N,N,Y,N,N,N),\n190:     FMIN_S   -> List(N,s,s,N,Y,Y,N,N,N),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 214-226
    context: "214:     FCVT_WU_D-> List(N,d,i,N,Y,N,N,N,Y),\n215:     FCVT_L_D ->
      List(N,d,i,N,Y,N,N,N,Y),\n216:     FCVT_LU_D-> List(N,d,i,N,Y,N,N,N,Y),\n217:\
      \     FCVT_S_D -> List(N,d,s,N,Y,Y,N,N,Y),\n218:     FCVT_D_S -> List(N,s,d,N,Y,Y,N,N,Y),\n\
      219:     FEQ_D    -> List(N,d,i,N,Y,N,N,N,N),\n220:     FLT_D    -> List(N,d,i,N,Y,N,N,N,N),\n\
      221:     FLE_D    -> List(N,d,i,N,Y,N,N,N,N),\n222:     FSGNJ_D  -> List(N,d,d,N,N,Y,N,N,N),\n\
      223:     FSGNJN_D -> List(N,d,d,N,N,Y,N,N,N),\n224:     FSGNJX_D -> List(N,d,d,N,N,Y,N,N,N),\n\
      225:     FMIN_D   -> List(N,d,d,N,Y,Y,N,N,N),\n226:     FMAX_D   -> List(N,d,d,N,Y,Y,N,N,N),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 242-259
    context: "242:     FCVT_H_WU-> List(N,i,h,Y,Y,Y,N,N,Y),\n243:     FCVT_H_L ->
      List(N,i,h,Y,Y,Y,N,N,Y),\n244:     FCVT_H_LU-> List(N,i,h,Y,Y,Y,N,N,Y),\n245:\
      \     // FPToInt\n246:     FMV_X_H  -> List(N,h,i,N,N,N,N,N,N), // d or h ??\n\
      247:     FCLASS_H -> List(N,h,i,N,N,N,N,N,N),\n248:     FCVT_W_H -> List(N,h,i,N,Y,N,N,N,Y),\n\
      249:     FCVT_WU_H-> List(N,h,i,N,Y,N,N,N,Y),\n250:     FCVT_L_H -> List(N,h,i,N,Y,N,N,N,Y),\n\
      251:     FCVT_LU_H-> List(N,h,i,N,Y,N,N,N,Y),\n252:     FEQ_H    -> List(N,h,i,N,Y,N,N,N,N),\n\
      253:     FLT_H    -> List(N,h,i,N,Y,N,N,N,N),\n254:     FLE_H    -> List(N,h,i,N,Y,N,N,N,N),\n\
      255:     // FPToFP\n256:     FSGNJ_H  -> List(N,h,h,N,N,Y,N,N,N),\n257:    \
      \ FSGNJN_H -> List(N,h,h,N,N,Y,N,N,N),\n258:     FSGNJX_H -> List(N,h,h,N,N,Y,N,N,N),\n\
      259:     FMIN_H   -> List(N,h,h,N,Y,Y,N,N,N),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 279-292
    context: "279:   sigs(0) := decoder(2)\n280:   sigs(1) := decoder(4)\n281:   ctrl.typ
      := inst.TYP\n282:   val isFP16Instrs = Seq(\n283:     // zfh inst\n284:    \
      \ FADD_H, FSUB_H, FEQ_H, FLT_H, FLE_H, FMIN_H, FMAX_H,\n285:     FMUL_H, FDIV_H,
      FSQRT_H,\n286:     FMADD_H, FMSUB_H, FNMADD_H, FNMSUB_H,\n287:     FCLASS_H,
      FSGNJ_H, FSGNJX_H, FSGNJN_H,\n288:     // zfa inst\n289:     FLEQ_H, FLTQ_H,
      FMINM_H, FMAXM_H,\n290:     FROUND_H, FROUNDNX_H,\n291:   )\n292:   val isFP16Instr
      = isFP16Instrs.map(io.instr === _).reduce(_ || _)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 289-299
    context: "289:     FLEQ_H, FLTQ_H, FMINM_H, FMAXM_H,\n290:     FROUND_H, FROUNDNX_H,\n\
      291:   )\n292:   val isFP16Instr = isFP16Instrs.map(io.instr === _).reduce(_
      || _)\n293:   val isFP32Instrs = Seq(\n294:     FADD_S, FSUB_S, FEQ_S, FLT_S,
      FLE_S, FMIN_S, FMAX_S,\n295:     FMUL_S, FDIV_S, FSQRT_S,\n296:     FMADD_S,
      FMSUB_S, FNMADD_S, FNMSUB_S,\n297:     FCLASS_S, FSGNJ_S, FSGNJX_S, FSGNJN_S,\n\
      298:     // zfa inst\n299:     FLEQ_S, FLTQ_S, FMINM_S, FMAXM_S,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 299-309
    context: "299:     FLEQ_S, FLTQ_S, FMINM_S, FMAXM_S,\n300:     FROUND_S, FROUNDNX_S,\n\
      301:   )\n302:   val isFP32Instr = isFP32Instrs.map(io.instr === _).reduce(_
      || _)\n303:   val isFP64Instrs = Seq(\n304:     FADD_D, FSUB_D, FEQ_D, FLT_D,
      FLE_D, FMIN_D, FMAX_D,\n305:     FMUL_D, FDIV_D, FSQRT_D,\n306:     FMADD_D,
      FMSUB_D, FNMADD_D, FNMSUB_D,\n307:     FCLASS_D, FSGNJ_D, FSGNJX_D, FSGNJN_D,\n\
      308:   )\n309:   val isFP64Instr = isFP64Instrs.map(io.instr === _).reduce(_
      || _)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 307-317
    context: "307:     FCLASS_D, FSGNJ_D, FSGNJX_D, FSGNJN_D,\n308:   )\n309:   val
      isFP64Instr = isFP64Instrs.map(io.instr === _).reduce(_ || _)\n310:   // scalar
      cvt inst\n311:   val isSew2Cvts = Seq(\n312:     FCVT_W_S, FCVT_WU_S, FCVT_L_S,
      FCVT_LU_S,\n313:     FCVT_W_D, FCVT_WU_D, FCVT_S_D, FCVT_D_S,\n314:     FMV_X_W,\n\
      315:     // zfa inst\n316:     FCVTMOD_W_D,\n317:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FPDecoder.scala
    lines: 324-334
    context: "324:   val isSew2Cvth = Seq(\n325:     FCVT_S_H, FCVT_H_S, FCVT_D_H,\n\
      326:     FMV_X_H,\n327:     FCVT_W_H, FCVT_L_H, FCVT_H_W,\n328:     FCVT_H_L,
      FCVT_H_WU, FCVT_H_LU,\n329:     FCVT_WU_H, FCVT_LU_H,\n330:   )\n331:   val
      simpleFmt = Mux1H(\n332:     // scala format to vsew format, when inst.FMT ===
      \"b11\".U, ctrl.fmt := \"b00\".U\n333:     Seq(\n334:       (inst.FMT === \"\
      b00\".U) -> \"b10\".U, // S"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VTypeGen.scala
    lines: 16-26
    context: "16:   val walkToArchVType = Input(Bool())\n17:   val walkVType   = Flipped(Valid(new
      VType))\n18:   val canUpdateVType = Input(Bool())\n19:   val vtype = Output(new
      VType)\n20:   val vsetvlVType = Input(new VType)\n21:   val commitVType = new
      Bundle {\n22:     val vtype = Flipped(Valid(new VType))\n23:     val hasVsetvl
      = Input(Bool())\n24:   }\n25: }\n26: /**"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VTypeGen.scala
    lines: 79-92
    context: "79: \n80:   /** New vtype generated by vsetModule */\n81:   private
      val vtypeNew = vsetModule.io.out.vconfig.vtype\n82: \n83:   /** Set the source
      of vtypeArch from commit instructions */\n84:   when(io.commitVType.hasVsetvl)
      {\n85:     vtypeArchNext := io.vsetvlVType\n86:   }.elsewhen(io.commitVType.vtype.valid)
      {\n87:     vtypeArchNext := io.commitVType.vtype.bits\n88:   }\n89: \n90:  \
      \ /** whether there is a vset instruction among input instructions */\n91: \
      \  private val inHasVset = isVsetVec.asUInt.orR\n92: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VTypeGen.scala
    lines: 95-105
    context: "95:    * 1. committed vsetvl instruction, which flushes the pipeline.\n\
      96:    * 2. walk-vtype, which is used to update vtype when walking.\n97:   \
      \ * 3. walking to architectural vtype\n98:    * 4. new vset instruction\n99:\
      \    */\n100:   when(io.commitVType.hasVsetvl) {\n101:     // when vsetvl instruction
      commit, also update vtypeSpec, because vsetvl flush pipe\n102:     vtypeSpecNext
      := io.vsetvlVType\n103:   }.elsewhen(io.walkVType.valid) {\n104:     vtypeSpecNext
      := io.walkVType.bits\n105:   }.elsewhen(io.walkToArchVType) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FusionDecoder.scala
    lines: 48-58
    context: "48:   protected def instr2Rs1ToRs2: Bool = instr2Rs1 === instr2Rs2\n\
      49: \n50:   protected def getInstrTable(pat: BitPat): List[BitPat] = {\n51:\
      \     // Only these instructions can be fused now\n52:     val allDecodeTable
      = XDecode.table ++ BitmanipDecode.table ++ ScalarCryptoDecode.table\n53:   \
      \  allDecodeTable.filter(_._1 == pat).map(_._2).head\n54:   }\n55:   // Must
      sync these indices with MicroOp.decode\n56:   protected def getInstrFuType(pat:
      BitPat): BitPat = getInstrTable(pat)(3)\n57:   protected def getInstrFuOpType(pat:
      BitPat): BitPat = getInstrTable(pat)(4)\n58:   protected def getInstrSrc1Type(pat:
      BitPat): BitPat = getInstrTable(pat)(0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FusionDecoder.scala
    lines: 538-548
    context: "538: class FusionDecoder(implicit p: Parameters) extends XSModule {\n\
      539:   val io = IO(new Bundle {\n540:     val disableFusion = Input(Bool())\n\
      541:     // T0: detect instruction fusions in these instructions\n542:     val
      in = Vec(DecodeWidth, Flipped(ValidIO(UInt(32.W))))\n543:     val inReady =
      Vec(DecodeWidth - 1, Input(Bool())) // dropRight(1)\n544:     // T1: decode
      result\n545:     val dec = Vec(DecodeWidth - 1, Input(new DecodedInst)) // dropRight(1)\n\
      546:     // T1: whether an instruction fusion is found\n547:     val out = Vec(DecodeWidth
      - 1, ValidIO(new FusionDecodeReplace)) // dropRight(1)\n548:     val info =
      Vec(DecodeWidth - 1, new FusionDecodeInfo) // dropRight(1)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FusionDecoder.scala
    lines: 548-561
    context: "548:     val info = Vec(DecodeWidth - 1, new FusionDecodeInfo) // dropRight(1)\n\
      549:     // T1: fused instruction needs to be cleared\n550:     val clear =
      Vec(DecodeWidth, Output(Bool()))\n551:   })\n552: \n553:   io.clear.head :=
      false.B\n554: \n555:   val instrPairs = io.in.dropRight(1).zip(io.in.drop(1)).map(x
      => Seq(x._1, x._2))\n556:   instrPairs.zip(io.dec).zip(io.out).zipWithIndex.foreach{
      case (((pair, dec), out), i) =>\n557:     val fusionList = Seq(\n558:      \
      \ new FusedAdduw(pair),\n559:       new FusedZexth(pair),\n560:       new FusedZexth1(pair),\n\
      561:       new FusedSexth(pair),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FusionDecoder.scala
    lines: 582-599
    context: "582:       new FusedLogiclsb(pair),\n583:       new FusedLogicZexth(pair),\n\
      584:       new FusedLui32(pair),\n585:       new FusedLui32w(pair)\n586:   \
      \  )\n587:     val fire = io.in(i).valid && io.inReady(i)\n588:     val instrPairValid
      = RegEnable(VecInit(pair.map(_.valid)).asUInt.andR, false.B, io.inReady(i))\n\
      589:     val fusionVec = RegEnable(VecInit(fusionList.map(_.isValid)), fire)\n\
      590:     // HINT instructions are not considered for fusion.\n591:     // NOTE:
      The RD of some FENCE instructions are not 0, but they are also HINT instructions.\n\
      592:     //       However, as FENCE instructions can never be fused, we do not
      need to consider them.\n593:     val notHint = RegEnable(VecInit(pair.map(_.bits(11,
      7) =/= 0.U)).asUInt.andR, fire)\n594:     val enabled = RegEnable(!io.disableFusion,
      fire)\n595:     val thisCleared = io.clear(i)\n596:     out.valid := instrPairValid
      && !thisCleared && fusionVec.asUInt.orR && notHint && enabled\n597:     XSError(instrPairValid
      && PopCount(fusionVec) > 1.U, \"more then one fusion matched\\n\")\n598:   \
      \  def connectByInt(field: FusionDecodeReplace => Valid[UInt], replace: Seq[Option[Int]]):
      Unit = {\n599:       field(out.bits).valid := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FusionDecoder.scala
    lines: 609-619
    context: "609:       }\n610:     }\n611:     def connectByUInt(field: FusionDecodeReplace
      => Valid[UInt], replace: Seq[Option[UInt]], needReg: Boolean): Unit = {\n612:\
      \       field(out.bits).valid := false.B\n613:       field(out.bits).bits :=
      DontCare\n614:       val replaceVec = if (needReg) fusionVec.zip(replace).filter(_._2.isDefined).map(x
      => (x._1, RegEnable(x._2.get, fire))) else fusionVec.zip(replace).filter(_._2.isDefined).map(x
      => (x._1, x._2.get))\n615:       if (replaceVec.nonEmpty) {\n616:         val
      replEnable = VecInit(replaceVec.map(_._1)).asUInt.orR\n617:         val replTypes
      = replaceVec.map(_._2).distinct\n618:         val replSel = replTypes.map(t
      => VecInit(replaceVec.filter(_._2 == t).map(_._1)).asUInt.orR)\n619:       \
      \  field(out.bits).valid := replEnable"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FusionDecoder.scala
    lines: 647-661
    context: "647:     connectByUInt((x: FusionDecodeReplace) => x.selImm, fusionList.map(_.selImm),
      false)\n648: \n649:     val src2WithZero = VecInit(fusionVec.zip(fusionList.map(_.lsrc2NeedZero)).filter(_._2).map(_._1)).asUInt.orR\n\
      650:     val src2WithMux = VecInit(fusionVec.zip(fusionList.map(_.lsrc2NeedMux)).filter(_._2).map(_._1)).asUInt.orR\n\
      651:     io.info(i).rs2FromZero := enabled && src2WithZero\n652:     io.info(i).rs2FromRs1
      := enabled && src2WithMux && !RegEnable(fusionList.head.destToRs1, fire)\n653:\
      \     io.info(i).rs2FromRs2 := enabled && src2WithMux && RegEnable(fusionList.head.destToRs1,
      fire)\n654:     out.bits.lsrc2.valid := enabled && (src2WithMux || src2WithZero)\n\
      655:     when (src2WithMux) {\n656:       out.bits.lsrc2.bits := RegEnable(fusionList.head.lsrc2MuxResult,
      fire)\n657:     }.otherwise {//elsewhen (src2WithZero) {\n658:       out.bits.lsrc2.bits
      := 0.U\n659:     }\n660:     // TODO: assume every instruction fusion clears
      the second instruction now\n661:     io.clear(i + 1) := out.valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FusionDecoder.scala
    lines: 657-668
    context: "657:     }.otherwise {//elsewhen (src2WithZero) {\n658:       out.bits.lsrc2.bits
      := 0.U\n659:     }\n660:     // TODO: assume every instruction fusion clears
      the second instruction now\n661:     io.clear(i + 1) := out.valid\n662:    \
      \ val lastFire = RegNext(fire)\n663:     fusionList.zip(fusionVec).foreach {
      case (f, v) =>\n664:       XSPerfAccumulate(s\"case_${f.fusionName}_$i\", instrPairValid
      && !thisCleared && v && lastFire)\n665:     }\n666:     XSPerfAccumulate(s\"\
      conflict_fusion_$i\", instrPairValid && thisCleared && fusionVec.asUInt.orR
      && lastFire)\n667:   }\n668: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/FusionDecoder.scala
    lines: 664-670
    context: "664:       XSPerfAccumulate(s\"case_${f.fusionName}_$i\", instrPairValid
      && !thisCleared && v && lastFire)\n665:     }\n666:     XSPerfAccumulate(s\"\
      conflict_fusion_$i\", instrPairValid && thisCleared && fusionVec.asUInt.orR
      && lastFire)\n667:   }\n668: \n669:   XSPerfAccumulate(\"fused_instr\", PopCount(io.out.zipWithIndex.map{
      case (x, i) => x.valid && RegNext(io.in(i).valid && io.inReady(i)) }))\n670:
      }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VecDecoder.scala
    lines: 14-29
    context: "14: import xiangshan.backend.decode.Zvbb._\n15: \n16: abstract class
      VecDecode extends XSDecodeBase {\n17:   def generate() : List[BitPat]\n18: \
      \  def asOldDecodeOutput(): List[BitPat] = {\n19:     val src1::src2::src3::fu::fuOp::xWen::fWen::vWen::mWen::vxsatWen::xsTrap::noSpec::blockBack::flushPipe::selImm::Nil
      = generate()\n20:     List (src1, src2, src3, fu, fuOp, xWen, fWen, xsTrap,
      noSpec, blockBack, flushPipe, selImm)\n21:   }\n22:   def asFirstStageDecodeOutput():
      List[BitPat] = {\n23:     val src1::src2::src3::fu::fuOp::xWen::fWen::vWen::mWen::vxsatWen::xsTrap::noSpec::blockBack::flushPipe::selImm::Nil
      = generate()\n24:     List (src1, src2, src3, fu, fuOp, xWen, fWen, bitPatToUInt(vWen)
      | bitPatToUInt(mWen), xsTrap, noSpec, blockBack, flushPipe, selImm)\n25:   }\n\
      26: }\n27: \n28: case class OPIVV(\n29:   fu: FuType.OHType,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VecDecoder.scala
    lines: 36-46
    context: "36:   src2: BitPat = SrcType.vp,\n37:   src3: BitPat = SrcType.vp\n\
      38: ) extends XSDecodeBase {\n39:   def generate() : List[BitPat] = {\n40: \
      \    XSDecode(src1, src2, src3, fu, fuOp, SelImm.X, uopSplitType,\n41:     \
      \  xWen = F, fWen = F, vWen = vWen, mWen = mWen, xsTrap = F, noSpec = F, blockBack
      = F, flushPipe = F).generate()\n42:   }\n43: }\n44: \n45: case class OPIVX(\n\
      46:   fu: FuType.OHType,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VecDecoder.scala
    lines: 53-63
    context: "53:   src2: BitPat = SrcType.vp,\n54:   src3: BitPat = SrcType.vp\n\
      55: ) extends XSDecodeBase {\n56:   def generate() : List[BitPat] = {\n57: \
      \    XSDecode(src1, src2, src3, fu, fuOp, SelImm.X, uopSplitType,\n58:     \
      \  xWen = F, fWen = F, vWen = vWen, mWen = mWen, xsTrap = F, noSpec = F, blockBack
      = F, flushPipe = F).generate()\n59:   }\n60: }\n61: \n62: case class OPIVI(\n\
      63:   fu: FuType.OHType,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VecDecoder.scala
    lines: 71-81
    context: "71:   src2: BitPat = SrcType.vp,\n72:   src3: BitPat = SrcType.vp\n\
      73: ) extends XSDecodeBase {\n74:   def generate() : List[BitPat] = {\n75: \
      \    XSDecode(src1, src2, src3, fu, fuOp, selImm, uopSplitType,\n76:       xWen
      = F, fWen = F, vWen = vWen, mWen = mWen, xsTrap = F, noSpec = F, blockBack =
      F, flushPipe = F).generate()\n77:   }\n78: }\n79: \n80: case class OPMVV(\n\
      81:   vdRen: Boolean,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VecDecoder.scala
    lines: 106-116
    context: "106:   src2: BitPat = SrcType.vp\n107: ) extends XSDecodeBase {\n108:\
      \   private def src3: BitPat = if (vdRen) SrcType.vp else SrcType.X\n109:  \
      \ def generate() : List[BitPat] = {\n110:     XSDecode(src1, src2, src3, fu,
      fuOp, SelImm.X, uopSplitType,\n111:       xWen = xWen, fWen = F, vWen = vWen,
      mWen = mWen, xsTrap = F, noSpec = F, blockBack = F, flushPipe = F).generate()\n\
      112:   }\n113: }\n114: \n115: case class OPFVV(\n116:   src1: BitPat,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VecDecoder.scala
    lines: 123-133
    context: "123:   uopSplitType: BitPat = UopSplitType.dummy,\n124:   src2: BitPat
      = SrcType.vp\n125: ) extends XSDecodeBase {\n126:   def generate() : List[BitPat]
      = {\n127:     XSDecode(src1, src2, src3, fu, fuOp, SelImm.X, uopSplitType,\n\
      128:       xWen = F, fWen = fWen, vWen = vWen, mWen = mWen, xsTrap = F, noSpec
      = F, blockBack = F, flushPipe = F).generate()\n129:   }\n130: }\n131: \n132:
      case class OPFFF(src1: BitPat, src2: BitPat, src3: BitPat, fu: FuType.OHType,
      fuOp: BitPat, xWen: Boolean, fWen: Boolean, vWen: Boolean, uopSplitType: BitPat
      = UopSplitType.dummy) extends XSDecodeBase {\n133:   def generate() : List[BitPat]
      = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VecDecoder.scala
    lines: 130-140
    context: "130: }\n131: \n132: case class OPFFF(src1: BitPat, src2: BitPat, src3:
      BitPat, fu: FuType.OHType, fuOp: BitPat, xWen: Boolean, fWen: Boolean, vWen:
      Boolean, uopSplitType: BitPat = UopSplitType.dummy) extends XSDecodeBase {\n\
      133:   def generate() : List[BitPat] = {\n134:     XSDecode(src1, src2, src3,
      fu, fuOp, SelImm.X, uopSplitType,\n135:       xWen = xWen, fWen = fWen, vWen
      = vWen, mWen = F, xsTrap = F, noSpec = F, blockBack = F, flushPipe = F, canRobCompress
      = T).generate()\n136:   }\n137: }\n138: \n139: case class OPFVF(\n140:   src1:
      BitPat,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VecDecoder.scala
    lines: 147-166
    context: "147:   uopSplitType: BitPat = UopSplitType.dummy,\n148:   src2: BitPat
      = SrcType.vp\n149: ) extends XSDecodeBase {\n150:   def generate() : List[BitPat]
      = {\n151:     XSDecode(src1, src2, src3, fu, fuOp, SelImm.X, uopSplitType,\n\
      152:       xWen = F, fWen = fWen, vWen = vWen, mWen = mWen, xsTrap = F, noSpec
      = F, blockBack = F, flushPipe = F).generate()\n153:   }\n154: }\n155: \n156:
      case class VSET(vli: Boolean, vtypei: Boolean, fuOp: BitPat, flushPipe: Boolean,
      blockBack: Boolean, selImm: BitPat, uopSplitType: BitPat = UopSplitType.VSET)
      extends XSDecodeBase {\n157:   def generate() : List[BitPat] = {\n158:     val
      src1 = if (vli) SrcType.imm else SrcType.xp\n159:     val src2 = if (vtypei)
      SrcType.imm else SrcType.xp\n160:     XSDecode(src1, src2, SrcType.X, FuType.vsetiwf,
      fuOp, selImm, uopSplitType,\n161:       xWen = F, fWen = F, vWen = F, mWen =
      F, xsTrap = F, noSpec = F, blockBack = blockBack, flushPipe = flushPipe).generate()\n\
      162:   }\n163: }\n164: \n165: case class VLD(src2: BitPat, fuOp: BitPat, strided:
      Boolean = false, indexed: Boolean = false, ff: Boolean = false,\n166:   mask:
      Boolean = false, whole: Boolean = false, ordered: Boolean = false, uopSplitType:
      BitPat = UopSplitType.VEC_US_LDST) extends XSDecodeBase {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VecDecoder.scala
    lines: 167-177
    context: "167:   def generate() : List[BitPat] = {\n168:     val fu = FuType.vldu\n\
      169:     val src1 = SrcType.xp\n170:     val src3 = SrcType.vp\n171:     XSDecode(src1,
      src2, src3, fu, fuOp, SelImm.X, uopSplitType,\n172:       xWen = F, fWen = F,
      vWen = T, mWen = F, xsTrap = F, noSpec = F, blockBack = F, flushPipe = F).generate()\n\
      173:   }\n174: }\n175: \n176: case class VST(src2: BitPat, fuOp: BitPat, strided:
      Boolean = false, indexed: Boolean = false,\n177:   mask: Boolean = false, whole:
      Boolean = false, ordered: Boolean = false, uopSplitType: BitPat = UopSplitType.VEC_US_LDST)
      extends XSDecodeBase {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VecDecoder.scala
    lines: 178-188
    context: "178:   def generate() : List[BitPat] = {\n179:     val fu = FuType.vstu\n\
      180:     val src1 = SrcType.xp\n181:     val src3 = SrcType.vp\n182:     XSDecode(src1,
      src2, src3, fu, fuOp, SelImm.X, uopSplitType,\n183:       xWen = F, fWen = F,
      vWen = F, mWen = F, xsTrap = F, noSpec = F, blockBack = F, flushPipe = F).generate()\n\
      184:   }\n185: }\n186: \n187: object VecDecoder extends DecodeConstants {\n\
      188:   val opivv: Array[(BitPat, XSDecodeBase)] = Array("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VecDecoder.scala
    lines: 484-519
    context: "484:     VWSUBU_WX      -> OPMVX(T, FuType.vialuF, VialuFixType.vwsubu_wv,
      F, T, F, UopSplitType.VEC_WXW),\n485:   )\n486: \n487:   val opfff: Array[(BitPat,
      XSDecodeBase)] = Array(\n488:     // Scalar Float Point\n489:     FADD_S ->
      OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vfadd, F, T,
      F, UopSplitType.SCA_SIM),\n490:     FADD_D -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.X, FuType.falu, VfaluType.vfadd, F, T, F, UopSplitType.SCA_SIM),\n491:\
      \     FADD_H -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vfadd,
      F, T, F, UopSplitType.SCA_SIM),\n492:     FSUB_S -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.X, FuType.falu, VfaluType.vfsub, F, T, F, UopSplitType.SCA_SIM),\n493:\
      \     FSUB_D -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vfsub,
      F, T, F, UopSplitType.SCA_SIM),\n494:     FSUB_H -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.X, FuType.falu, VfaluType.vfsub, F, T, F, UopSplitType.SCA_SIM),\n495:\
      \     FEQ_S  -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vfeq
      , T, F, F, UopSplitType.SCA_SIM),\n496:     FLT_S  -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.X, FuType.falu, VfaluType.vflt , T, F, F, UopSplitType.SCA_SIM),\n497:\
      \     FLE_S  -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vfle
      , T, F, F, UopSplitType.SCA_SIM),\n498:     FEQ_D  -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.X, FuType.falu, VfaluType.vfeq , T, F, F, UopSplitType.SCA_SIM),\n499:\
      \     FLT_D  -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vflt
      , T, F, F, UopSplitType.SCA_SIM),\n500:     FLE_D  -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.X, FuType.falu, VfaluType.vfle , T, F, F, UopSplitType.SCA_SIM),\n501:\
      \     FEQ_H  -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vfeq
      , T, F, F, UopSplitType.SCA_SIM),\n502:     FLT_H  -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.X, FuType.falu, VfaluType.vflt , T, F, F, UopSplitType.SCA_SIM),\n503:\
      \     FLE_H  -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vfle
      , T, F, F, UopSplitType.SCA_SIM),\n504:     FMIN_S -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.X, FuType.falu, VfaluType.vfmin, F, T, F, UopSplitType.SCA_SIM),\n505:\
      \     FMIN_D -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vfmin,
      F, T, F, UopSplitType.SCA_SIM),\n506:     FMAX_S -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.X, FuType.falu, VfaluType.vfmax, F, T, F, UopSplitType.SCA_SIM),\n507:\
      \     FMAX_D -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vfmax,
      F, T, F, UopSplitType.SCA_SIM),\n508:     FMIN_H -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.X, FuType.falu, VfaluType.vfmin, F, T, F, UopSplitType.SCA_SIM),\n509:\
      \     FMAX_H -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vfmax,
      F, T, F, UopSplitType.SCA_SIM),\n510:     // Scalar Float Point Convert Inst.\n\
      511:     FCVT_W_S  -> OPFFF(SrcType.fp, SrcType.X, SrcType.X, FuType.fcvt, VfcvtType.vfcvt_xfv,\
      \   T, F, F, UopSplitType.SCA_SIM),\n512:     FCVT_WU_S -> OPFFF(SrcType.fp,
      SrcType.X, SrcType.X, FuType.fcvt, VfcvtType.vfcvt_xufv,  T, F, F, UopSplitType.SCA_SIM),\n\
      513:     FCVT_L_S  -> OPFFF(SrcType.fp, SrcType.X, SrcType.X, FuType.fcvt, VfcvtType.vfwcvt_xfv,\
      \  T, F, F, UopSplitType.SCA_SIM),\n514:     FCVT_LU_S -> OPFFF(SrcType.fp,
      SrcType.X, SrcType.X, FuType.fcvt, VfcvtType.vfwcvt_xufv, T, F, F, UopSplitType.SCA_SIM),\n\
      515:     FCVT_W_D  -> OPFFF(SrcType.fp, SrcType.X, SrcType.X, FuType.fcvt, VfcvtType.vfncvt_xfw,\
      \  T, F, F, UopSplitType.SCA_SIM),\n516:     FCVT_WU_D -> OPFFF(SrcType.fp,
      SrcType.X, SrcType.X, FuType.fcvt, VfcvtType.vfncvt_xufw, T, F, F, UopSplitType.SCA_SIM),\n\
      517:     FCVT_L_D  -> OPFFF(SrcType.fp, SrcType.X, SrcType.X, FuType.fcvt, VfcvtType.vfcvt_xfv,\
      \   T, F, F, UopSplitType.SCA_SIM),\n518:     FCVT_LU_D -> OPFFF(SrcType.fp,
      SrcType.X, SrcType.X, FuType.fcvt, VfcvtType.vfcvt_xufv,  T, F, F, UopSplitType.SCA_SIM),\n\
      519:     FCVT_S_D  -> OPFFF(SrcType.fp, SrcType.X, SrcType.X, FuType.fcvt, VfcvtType.vfncvt_ffw,\
      \  F, T, F, UopSplitType.SCA_SIM),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VecDecoder.scala
    lines: 524-534
    context: "524:     FCVT_H_D  -> OPFFF(SrcType.fp, SrcType.X, SrcType.X, FuType.fcvt,
      VfcvtType.fcvt_h_d,  F, T, F, UopSplitType.SCA_SIM),\n525:     FCVT_D_H  ->
      OPFFF(SrcType.fp, SrcType.X, SrcType.X, FuType.fcvt, VfcvtType.fcvt_d_h,  F,
      T, F, UopSplitType.SCA_SIM),\n526:     FCVT_W_H  -> OPFFF(SrcType.fp, SrcType.X,
      SrcType.X, FuType.fcvt, VfcvtType.fcvt_w_h,  T, F, F, UopSplitType.SCA_SIM),\n\
      527:     FCVT_WU_H -> OPFFF(SrcType.fp, SrcType.X, SrcType.X, FuType.fcvt, VfcvtType.fcvt_wu_h,
      T, F, F, UopSplitType.SCA_SIM),\n528:     FCVT_L_H  -> OPFFF(SrcType.fp, SrcType.X,
      SrcType.X, FuType.fcvt, VfcvtType.fcvt_l_h,  T, F, F, UopSplitType.SCA_SIM),\n\
      529:     FCVT_LU_H -> OPFFF(SrcType.fp, SrcType.X, SrcType.X, FuType.fcvt, VfcvtType.fcvt_lu_h,
      T, F, F, UopSplitType.SCA_SIM),\n530:     // Scalar Float Point f2i MV Inst.\n\
      531:     FMV_X_D -> OPFFF(SrcType.fp, SrcType.X, SrcType.X, FuType.fcvt, FuOpType.FMVXF,
      T, F, F, UopSplitType.SCA_SIM),\n532:     FMV_X_W -> OPFFF(SrcType.fp, SrcType.X,
      SrcType.X, FuType.fcvt, FuOpType.FMVXF, T, F, F, UopSplitType.SCA_SIM),\n533:\
      \     FMV_X_H -> OPFFF(SrcType.fp, SrcType.X, SrcType.X, FuType.fcvt, FuOpType.FMVXF,
      T, F, F, UopSplitType.SCA_SIM),\n534:     // donot wflags"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VecDecoder.scala
    lines: 530-551
    context: "530:     // Scalar Float Point f2i MV Inst.\n531:     FMV_X_D -> OPFFF(SrcType.fp,
      SrcType.X, SrcType.X, FuType.fcvt, FuOpType.FMVXF, T, F, F, UopSplitType.SCA_SIM),\n\
      532:     FMV_X_W -> OPFFF(SrcType.fp, SrcType.X, SrcType.X, FuType.fcvt, FuOpType.FMVXF,
      T, F, F, UopSplitType.SCA_SIM),\n533:     FMV_X_H -> OPFFF(SrcType.fp, SrcType.X,
      SrcType.X, FuType.fcvt, FuOpType.FMVXF, T, F, F, UopSplitType.SCA_SIM),\n534:\
      \     // donot wflags\n535:     FCLASS_S -> OPFFF(SrcType.fp, SrcType.X, SrcType.X,
      FuType.falu, VfaluType.vfclass, T, F, F, UopSplitType.SCA_SIM),\n536:     FCLASS_D
      -> OPFFF(SrcType.fp, SrcType.X, SrcType.X, FuType.falu, VfaluType.vfclass, T,
      F, F, UopSplitType.SCA_SIM),\n537:     FCLASS_H -> OPFFF(SrcType.fp, SrcType.X,
      SrcType.X, FuType.falu, VfaluType.vfclass, T, F, F, UopSplitType.SCA_SIM),\n\
      538:     FSGNJ_S  -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vfsgnj
      , F, T, F, UopSplitType.SCA_SIM),\n539:     FSGNJ_D  -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.X, FuType.falu, VfaluType.vfsgnj , F, T, F, UopSplitType.SCA_SIM),\n\
      540:     FSGNJ_H  -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vfsgnj
      , F, T, F, UopSplitType.SCA_SIM),\n541:     FSGNJX_S -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.X, FuType.falu, VfaluType.vfsgnjx, F, T, F, UopSplitType.SCA_SIM),\n\
      542:     FSGNJX_D -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vfsgnjx,
      F, T, F, UopSplitType.SCA_SIM),\n543:     FSGNJX_H -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.X, FuType.falu, VfaluType.vfsgnjx, F, T, F, UopSplitType.SCA_SIM),\n\
      544:     FSGNJN_S -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vfsgnjn,
      F, T, F, UopSplitType.SCA_SIM),\n545:     FSGNJN_D -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.X, FuType.falu, VfaluType.vfsgnjn, F, T, F, UopSplitType.SCA_SIM),\n\
      546:     FSGNJN_H -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu, VfaluType.vfsgnjn,
      F, T, F, UopSplitType.SCA_SIM),\n547: \n548:     FMUL_S -> OPFFF(SrcType.fp,
      SrcType.fp, SrcType.X, FuType.fmac , VfmaType.vfmul, F, T, F, UopSplitType.SCA_SIM),\n\
      549:     FMUL_D -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.fmac , VfmaType.vfmul,
      F, T, F, UopSplitType.SCA_SIM),\n550:     FMUL_H -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.X, FuType.fmac , VfmaType.vfmul, F, T, F, UopSplitType.SCA_SIM),\n551: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VecDecoder.scala
    lines: 739-751
    context: "739:     // vslide1down.vx vd, vs2, rs1, vm # vd[i] = vs2[i+1], vd[vl-1]=x[rs1]\n\
      740:     VFSLIDE1DOWN_VF    -> OPFVF(SrcType.fp, SrcType.vp , FuType.vppu, VpermType.vfslide1down,
      F, T, F, UopSplitType.VEC_FSLIDE1DOWN),// vd[i] = vs2[i+1], vd[vl-1]=f[rs1]\n\
      741:   )\n742: \n743:   val vset: Array[(BitPat, XSDecodeBase)] = Array(\n744:\
      \     VSETVLI   -> VSET(vli = F, vtypei = T, VSETOpType.uvsetvcfg_xi, flushPipe
      = F, blockBack = F, SelImm.IMM_VSETVLI),\n745:     VSETIVLI  -> VSET(vli = T,
      vtypei = T, VSETOpType.uvsetvcfg_ii, flushPipe = F, blockBack = F, SelImm.IMM_VSETIVLI),\n\
      746:     VSETVL    -> VSET(vli = F, vtypei = F, VSETOpType.uvsetvcfg_xx, flushPipe
      = T, blockBack = T, SelImm.X), // flush pipe\n747:   )\n748: \n749:   val vls:
      Array[(BitPat, XSDecodeBase)] = Array(\n750:     // 7.4. Vector Unit-Stride
      Instructions\n751:     VLE8_V        -> VLD(SrcType.X,   VlduType.vle),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 38-48
    context: "38:   private val numFpRegSrc = backendParams.numFpRegSrc\n39:   private
      val numFpRatPorts = numFpRegSrc\n40:   private val numVecRegSrc = backendParams.numVecRegSrc\n\
      41:   private val numVecRatPorts = numVecRegSrc\n42: \n43:   val redirect =
      Input(Bool())\n44:   val canAccept = Output(Bool())\n45:   // from Ibuffer\n\
      46:   val in = Vec(DecodeWidth, Flipped(DecoupledIO(new StaticInst)))\n47: \
      \  // to Rename\n48:   val out = Vec(DecodeWidth, DecoupledIO(new DecodedInst))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 59-69
    context: "59: \n60:   // vtype update\n61:   val fromRob = new Bundle {\n62: \
      \    val isResumeVType = Input(Bool())\n63:     val walkToArchVType = Input(Bool())\n\
      64:     val commitVType = new Bundle {\n65:       val vtype = Flipped(Valid(new
      VType))\n66:       val hasVsetvl = Input(Bool())\n67:     }\n68:     val walkVType
      = Flipped(Valid(new VType))\n69:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 83-98
    context: "83:   with HasPerfEvents\n84:   with VectorConstants {\n85: \n86:  \
      \ val io = IO(new DecodeStageIO)\n87: \n88:   io.in.zipWithIndex.foreach{ case
      (d, i) => \n89:     PerfCCT.updateInstPos(d.bits.debug_seqNum, PerfCCT.InstPos.AtDecode.id.U,
      d.valid, clock, reset)\n90:   }\n91: \n92:   // io alias\n93:   private val
      outReadys = io.out.map(_.ready)\n94:   private val inValids = io.in.map(_.valid)\n\
      95:   private val inValid = VecInit(inValids).asUInt.orR\n96:   private val
      outValids = io.out.map(_.valid)\n97:   private val outValid = VecInit(outValids).asUInt.orR\n\
      98:   //readyFromRename Counter"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 95-105
    context: "95:   private val inValid = VecInit(inValids).asUInt.orR\n96:   private
      val outValids = io.out.map(_.valid)\n97:   private val outValid = VecInit(outValids).asUInt.orR\n\
      98:   //readyFromRename Counter\n99:   /** Assume number of ready channels be
      \"RenameWidth\" if the first output channel is ready. If not, assume that be
      0 */\n100:   val readyCounter = Mux(outReadys.head, RenameWidth.U, 0.U)\n101:\
      \ \n102:   /** complex decoder */\n103:   val decoderComp = Module(new DecodeUnitComp)\n\
      104:   /** simple decoders in Seq of DecodeWidth */\n105:   val decoders = Seq.fill(DecodeWidth)(Module(new
      DecodeUnit))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 110-120
    context: "110: \n111:   /** whether DecodeStage can accept new requests from frontend
      (CtrlBlock) */\n112:   val canAccept = Wire(Bool())\n113: \n114:   //Simple
      6\n115:   decoders.zip(io.in).foreach { case (dst, src) =>\n116:     dst.io.enq.ctrlFlow
      := src.bits\n117:     dst.io.csrCtrl := io.csrCtrl\n118:     dst.io.fromCSR
      := io.fromCSR\n119:     dst.io.enq.vtype := vtypeGen.io.vtype\n120:     dst.io.enq.vstart
      := io.vstart"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 126-138
    context: "126:   val isSimpleVec = VecInit(inValids.zip(decoders.map(_.io.deq.isComplex)).map
      { case (valid, isComplex) => valid && !isComplex })\n127:   /** instructions
      decoded by simple decoders */\n128:   val simpleDecodedInst = VecInit(decoders.map(_.io.deq.decodedInst))\n\
      129: \n130:   /** whether instructions decoded by simple decoders are illegal
      */\n131:   val isIllegalInstVec = VecInit((outValids lazyZip outReadys lazyZip
      io.out.map(_.bits)).map {\n132:     case (valid, ready, decodedInst) =>\n133:\
      \       valid && ready && (decodedInst.exceptionVec(ExceptionNO.EX_II) || decodedInst.exceptionVec(ExceptionNO.EX_VI))\n\
      134:   })\n135:   /** at least 1 instruction decoded by simple decoders is illegal
      */\n136:   val hasIllegalInst = Cat(isIllegalInstVec).orR\n137:   /** at least
      1 instruction decoded by simple decoders is illegal */\n138:   val illegalInst
      = PriorityMuxDefault(isIllegalInstVec.zip(io.out.map(_.bits)), 0.U.asTypeOf(new
      DecodedInst))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 150-172
    context: "150:   /** selected complex instruction for complex decoder */\n151:\
      \   val complexInst = PriorityMuxDefault(isComplexVec.zip(decoders.map(_.io.deq.decodedInst)),
      0.U.asTypeOf(new DecodedInst))\n152:   /** selected complex micro operation
      information for complex decoder */\n153:   val complexUopInfo = PriorityMuxDefault(isComplexVec.zip(decoders.map(_.io.deq.uopInfo)),
      0.U.asTypeOf(new UopInfo))\n154: \n155:   vtypeGen.io.insts.zip(io.in).foreach
      { case (inst, in) =>\n156:     inst.valid := in.valid\n157:     inst.bits :=
      in.bits.instr\n158:   }\n159:   // when io.redirect is True, never update vtype\n\
      160:   vtypeGen.io.canUpdateVType := decoderComp.io.in.fire && decoderComp.io.in.bits.simpleDecodedInst.isVset
      && !io.redirect\n161:   vtypeGen.io.walkToArchVType := io.fromRob.walkToArchVType\n\
      162:   vtypeGen.io.commitVType := io.fromRob.commitVType\n163:   vtypeGen.io.walkVType
      := io.fromRob.walkVType\n164:   vtypeGen.io.vsetvlVType := io.vsetvlVType\n\
      165: \n166:   //Comp 1\n167:   decoderComp.io.redirect := io.redirect\n168:\
      \   decoderComp.io.csrCtrl := io.csrCtrl\n169:   decoderComp.io.vtypeBypass
      := vtypeGen.io.vtype\n170:   // The input inst of decoderComp is latched last
      cycle.\n171:   // Set input empty, if there is no complex inst latched last
      cycle.\n172:   decoderComp.io.in.valid := complexValid && !io.fromRob.isResumeVType"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 170-180
    context: "170:   // The input inst of decoderComp is latched last cycle.\n171:\
      \   // Set input empty, if there is no complex inst latched last cycle.\n172:\
      \   decoderComp.io.in.valid := complexValid && !io.fromRob.isResumeVType\n173:\
      \   decoderComp.io.in.bits.simpleDecodedInst := complexInst\n174:   decoderComp.io.in.bits.uopInfo
      := complexUopInfo\n175:   decoderComp.io.out.complexDecodedInsts.zipWithIndex.foreach
      { case (out, i) => out.ready := io.out(i).ready }\n176: \n177:   /** instructions
      decoded by complex decoders */\n178:   val complexDecodedInst = VecInit(decoderComp.io.out.complexDecodedInsts.map(_.bits))\n\
      179:   /** whether instructions decoded by complex decoders are valid */\n180:\
      \   val complexDecodedInstValid = VecInit(decoderComp.io.out.complexDecodedInsts.map(_.valid))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 190-200
    context: "190: \n191:   // block vector inst when vtype is resuming\n192:   val
      hasVectorInst = VecInit(decoders.map(x => FuType.FuTypeOrR(x.io.deq.decodedInst.fuType,
      FuType.vecArithOrMem ++ FuType.vecVSET))).asUInt.orR\n193: \n194:   /** condition
      of acceptation: no redirection, ready from rename/complex decoder, no resumeVType
      */\n195:   canAccept := !io.redirect && (io.out.head.ready || decoderComp.io.in.ready)
      && !io.fromRob.isResumeVType\n196: \n197:   io.canAccept := canAccept\n198:\
      \ \n199:   /**\n200:    * Assign ready signal for DecodeStage's input. Ready
      signal in i-th channel:"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 203-216
    context: "203:    * One situation for set up ready signal is that first \"i\"\
      \ instructions are all simple instructions, and these \"i\"\n204:    * instructions
      can be passed down to rename together with complex decoder's result.\n205: \
      \   * Another situation is that first \"i-1\" instructions are all simple instructions,
      and the \"i-th\" instructions needs\n206:    * to be sent to complex decoder,
      with complex decoder ready for new input.\n207:    */\n208:   io.in.zipWithIndex.foreach
      { case (in, i) =>\n209:     in.ready := !io.redirect && (\n210:       simplePrefixVec(i)
      && (i.U +& complexNum) < readyCounter ||\n211:       firstComplexOH(i) && (i.U
      +& complexNum) <= readyCounter && decoderComp.io.in.ready\n212:     ) && !io.fromRob.isResumeVType\n\
      213:   }\n214: \n215:   /** final instruction decoding result */\n216:   val
      finalDecodedInst = Wire(Vec(DecodeWidth, new DecodedInst))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 228-238
    context: "228: \n229:   /**\n230:    * Generate output of DecodeStage. Pass finalDecodedInst
      to output as decoded instructions.\n231:    * Note that finalDecodedInst is
      generated in order.\n232:    */\n233:   io.out.zipWithIndex.foreach { case (inst,
      i) =>\n234:     inst.valid := finalDecodedInstValid(i) && !io.fromRob.isResumeVType\n\
      235:     inst.bits := finalDecodedInst(i)\n236:     inst.bits.lsrc(0) := Mux(finalDecodedInst(i).vpu.isReverse,
      finalDecodedInst(i).lsrc(1), finalDecodedInst(i).lsrc(0))\n237:     inst.bits.lsrc(1)
      := Mux(finalDecodedInst(i).vpu.isReverse, finalDecodedInst(i).lsrc(0), finalDecodedInst(i).lsrc(1))\n\
      238:     inst.bits.srcType(0) := Mux(finalDecodedInst(i).vpu.isReverse, finalDecodedInst(i).srcType(1),
      finalDecodedInst(i).srcType(0))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 262-272
    context: "262:   for (i <- 0 until DecodeWidth) {\n263: \n264:     // We use the
      lsrc/ldest before fusion decoder to read RAT for better timing.\n265:     io.intRat(i)(0).addr
      := io.out(i).bits.lsrc(0)\n266:     io.intRat(i)(1).addr := io.out(i).bits.lsrc(1)\n\
      267:     io.intRat(i).foreach(_.hold := !io.out(i).ready)\n268: \n269:     //
      Floating-point instructions can not be fused now.\n270:     io.fpRat(i)(0).addr
      := io.out(i).bits.lsrc(0)\n271:     io.fpRat(i)(1).addr := io.out(i).bits.lsrc(1)\n\
      272:     io.fpRat(i)(2).addr := io.out(i).bits.lsrc(2)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 268-278
    context: "268: \n269:     // Floating-point instructions can not be fused now.\n\
      270:     io.fpRat(i)(0).addr := io.out(i).bits.lsrc(0)\n271:     io.fpRat(i)(1).addr
      := io.out(i).bits.lsrc(1)\n272:     io.fpRat(i)(2).addr := io.out(i).bits.lsrc(2)\n\
      273:     io.fpRat(i).foreach(_.hold := !io.out(i).ready)\n274: \n275:     //
      Vec instructions\n276:     // TODO: vec uop dividers need change this\n277:\
      \     io.vecRat(i)(0).addr := io.out(i).bits.lsrc(0) // vs1\n278:     io.vecRat(i)(1).addr
      := io.out(i).bits.lsrc(1) // vs2"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 275-300
    context: "275:     // Vec instructions\n276:     // TODO: vec uop dividers need
      change this\n277:     io.vecRat(i)(0).addr := io.out(i).bits.lsrc(0) // vs1\n\
      278:     io.vecRat(i)(1).addr := io.out(i).bits.lsrc(1) // vs2\n279:     io.vecRat(i)(2).addr
      := io.out(i).bits.lsrc(2) // old_vd\n280:     io.vecRat(i).foreach(_.hold :=
      !io.out(i).ready)\n281: \n282:     io.v0Rat(i).addr := V0_IDX.U // v0\n283:\
      \     io.v0Rat(i).hold := !io.out(i).ready\n284: \n285:     io.vlRat(i).addr
      := Vl_IDX.U // vl\n286:     io.vlRat(i).hold := !io.out(i).ready\n287:   }\n\
      288: \n289:   /** whether valid input requests from frontend exists */\n290:\
      \   val hasValid = VecInit(io.in.map(_.valid)).asUInt.orR\n291: \n292:   debug_globalCounter
      := debug_globalCounter + PopCount(io.out.map(_.fire))\n293: \n294:   io.stallReason.in.backReason
      := io.stallReason.out.backReason\n295:   io.stallReason.out.reason.zip(io.stallReason.in.reason).zip(io.in.map(_.valid)).foreach
      { case ((out, in), valid) =>\n296:     out := Mux(io.stallReason.out.backReason.valid,\n\
      297:                io.stallReason.out.backReason.bits,\n298:              \
      \  in)\n299:   }\n300: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 296-336
    context: "296:     out := Mux(io.stallReason.out.backReason.valid,\n297:     \
      \           io.stallReason.out.backReason.bits,\n298:                in)\n299:\
      \   }\n300: \n301:   io.toCSR.trapInstInfo.valid := hasIllegalInst && !io.redirect\n\
      302:   io.toCSR.trapInstInfo.bits.fromDecodedInst(illegalInst)\n303: \n304:\
      \   val recoveryFlag = RegInit(false.B)\n305:   when(io.redirect) {\n306:  \
      \   recoveryFlag := true.B\n307:   }.elsewhen(io.in.map(_.fire).reduce(_ ||
      _)) {\n308:     recoveryFlag := false.B\n309:   }\n310: \n311:   XSPerfAccumulate(\"\
      in_valid_count\", PopCount(io.in.map(_.valid)))\n312:   XSPerfAccumulate(\"\
      in_fire_count\", PopCount(io.in.map(_.fire)))\n313:   XSPerfAccumulate(\"in_valid_not_ready_count\"\
      , PopCount(io.in.map(x => x.valid && !x.ready)))\n314:   XSPerfAccumulate(\"\
      stall_cycle\", io.in.head match { case x => x.valid && !x.ready})\n315:   XSPerfAccumulate(\"\
      wait_cycle\", !io.in.head.valid && io.out.head.ready)\n316:   XSPerfAccumulate(\"\
      inst_spec\", PopCount(io.in.map(_.fire)))\n317:   XSPerfAccumulate(\"recovery_bubble\"\
      , recoveryFlag)\n318: \n319:   XSPerfHistogram(\"in_valid_range\", PopCount(io.in.map(_.valid)),
      true.B, 0, DecodeWidth + 1, 1)\n320:   XSPerfHistogram(\"in_fire_range\", PopCount(io.in.map(_.fire)),
      true.B, 0, DecodeWidth + 1, 1)\n321:   XSPerfHistogram(\"out_valid_range\",
      PopCount(io.out.map(_.valid)), true.B, 0, DecodeWidth + 1, 1)\n322:   XSPerfHistogram(\"\
      out_fire_range\", PopCount(io.out.map(_.fire)), true.B, 0, DecodeWidth + 1,
      1)\n323: \n324:   val fusionValid = VecInit(io.fusion.map(x => GatedValidRegNext(x)))\n\
      325:   val inValidNotReady = io.in.map(in => GatedValidRegNext(in.valid && !in.ready))\n\
      326:   val perfEvents = Seq(\n327:     (\"decoder_fused_instr\", PopCount(fusionValid)\
      \       ),\n328:     (\"decoder_waitInstr\",   PopCount(inValidNotReady)   ),\n\
      329:     (\"decoder_stall_cycle\", hasValid && !io.out(0).ready),\n330:    \
      \ (\"decoder_utilization\", PopCount(io.in.map(_.valid))),\n331:     (\"INST_SPEC\"\
      ,           PopCount(io.in.map(_.fire))),\n332:     (\"RECOVERY_BUBBLE\",  \
      \   recoveryFlag)\n333:   )\n334:   generatePerfEvent()\n335: \n336:   // for
      more readable verilog"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 100-114
    context: "100:   vWen: Boolean = false,\n101:   mWen: Boolean = false,\n102: \
      \  xsTrap: Boolean = false,\n103:   noSpec: Boolean = false,\n104:   blockBack:
      Boolean = false,\n105:   flushPipe: Boolean = false,\n106:   canRobCompress:
      Boolean = false,\n107: ) extends XSDecodeBase {\n108:   def generate() : List[BitPat]
      = {\n109:     List (src1, src2, src3, BitPat(fu.U(FuType.num.W)), fuOp, xWen.B,
      fWen.B, (vWen || mWen).B, xsTrap.B, noSpec.B, blockBack.B, flushPipe.B, canRobCompress.B,
      uopSplitType, selImm)\n110:   }\n111: }\n112: \n113: case class FDecode(\n114:\
      \   src1: BitPat, src2: BitPat, src3: BitPat,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 119-133
    context: "119:   vWen: Boolean = false,\n120:   mWen: Boolean = false,\n121: \
      \  xsTrap: Boolean = false,\n122:   noSpec: Boolean = false,\n123:   blockBack:
      Boolean = false,\n124:   flushPipe: Boolean = false,\n125:   canRobCompress:
      Boolean = false,\n126: ) extends XSDecodeBase {\n127:   def generate() : List[BitPat]
      = {\n128:     XSDecode(src1, src2, src3, fu, fuOp, selImm, uopSplitType, xWen,
      fWen, vWen, mWen, xsTrap, noSpec, blockBack, flushPipe, canRobCompress).generate()\n\
      129:   }\n130: }\n131: \n132: /**\n133:  * Overall Decode constants"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 223-236
    context: "223:     MRET    -> XSDecode(SrcType.reg, SrcType.imm, SrcType.X, FuType.csr,
      CSROpType.jmp, SelImm.IMM_I, xWen = T, noSpec = T, blockBack = T),\n224:   \
      \  MNRET   -> XSDecode(SrcType.reg, SrcType.imm, SrcType.X, FuType.csr, CSROpType.jmp,
      SelImm.IMM_I, xWen = T, noSpec = T, blockBack = T),\n225:     DRET    -> XSDecode(SrcType.reg,
      SrcType.imm, SrcType.X, FuType.csr, CSROpType.jmp, SelImm.IMM_I, xWen = T, noSpec
      = T, blockBack = T),\n226:     WFI     -> XSDecode(SrcType.pc , SrcType.imm,
      SrcType.X, FuType.csr, CSROpType.wfi, SelImm.X    , xWen = T, noSpec = T, blockBack
      = T),\n227: \n228:     SFENCE_VMA -> XSDecode(SrcType.reg, SrcType.reg, SrcType.X,
      FuType.fence, FenceOpType.sfence, SelImm.X, noSpec = T, blockBack = T, flushPipe
      = T),\n229:     FENCE_I    -> XSDecode(SrcType.pc , SrcType.imm, SrcType.X,
      FuType.fence, FenceOpType.fencei, SelImm.X, noSpec = T, blockBack = T, flushPipe
      = T),\n230:     FENCE      -> XSDecode(SrcType.pc , SrcType.imm, SrcType.X,
      FuType.fence, FenceOpType.fence , SelImm.X, noSpec = T, blockBack = T, flushPipe
      = T),\n231:     PAUSE      -> XSDecode(SrcType.pc , SrcType.imm, SrcType.X,
      FuType.fence, FenceOpType.fence , SelImm.X, noSpec = T, blockBack = T, flushPipe
      = T),\n232: \n233:     // Zawrs\n234:     WRS_NTO -> XSDecode(SrcType.pc , SrcType.imm,
      SrcType.X, FuType.csr, CSROpType.wrs_nto, SelImm.X , noSpec = T, blockBack =
      T),\n235:     WRS_STO -> XSDecode(SrcType.pc , SrcType.imm, SrcType.X, FuType.csr,
      CSROpType.wrs_sto, SelImm.X , noSpec = T, blockBack = T),\n236: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 392-405
    context: "392: /**\n393:  * FP Decode constants\n394:  */\n395: object FpDecode
      extends DecodeConstants{\n396:   val decodeArray: Array[(BitPat, XSDecodeBase)]
      = Array(\n397:     FLH     -> FDecode(SrcType.reg, SrcType.imm, SrcType.X, FuType.ldu,
      LSUOpType.lh, selImm = SelImm.IMM_I, fWen = T),\n398:     FLW     -> FDecode(SrcType.reg,
      SrcType.imm, SrcType.X, FuType.ldu, LSUOpType.lw, selImm = SelImm.IMM_I, fWen
      = T),\n399:     FLD     -> FDecode(SrcType.reg, SrcType.imm, SrcType.X, FuType.ldu,
      LSUOpType.ld, selImm = SelImm.IMM_I, fWen = T),\n400:     FSH     -> FDecode(SrcType.reg,
      SrcType.fp,  SrcType.X, FuType.stu, LSUOpType.sh, selImm = SelImm.IMM_S    \
      \      ),\n401:     FSW     -> FDecode(SrcType.reg, SrcType.fp,  SrcType.X,
      FuType.stu, LSUOpType.sw, selImm = SelImm.IMM_S          ),\n402:     FSD  \
      \   -> FDecode(SrcType.reg, SrcType.fp,  SrcType.X, FuType.stu, LSUOpType.sd,
      selImm = SelImm.IMM_S          ),\n403: \n404:     FMV_D_X -> FDecode(SrcType.reg,
      SrcType.imm, SrcType.X, FuType.i2v, IF2VectorType.FMX_D_X, fWen = T, canRobCompress
      = T),\n405:     FMV_W_X -> FDecode(SrcType.reg, SrcType.imm, SrcType.X, FuType.i2v,
      IF2VectorType.FMX_W_X, fWen = T, canRobCompress = T),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 455-465
    context: "455:     /* sfecne.inval.ir is the end instrucion of a TLB flush which
      set *noSpecExec* *blockBackward* and *flushPipe* signals\n456:      * so when
      it comes to dispatch , it will wait until all sinval_vma ahead of it in rob
      commit\n457:      * then dispatch and issue this instrucion\n458:      * when
      it commit at the head of rob , flush the pipeline since some instrucions have
      been fetched to ibuffer using old TLB map\n459:      */\n460:     SFENCE_INVAL_IR\
      \   -> XSDecode(SrcType.DC, SrcType.DC, SrcType.X, FuType.fence, FenceOpType.nofence,
      SelImm.X, noSpec = T, blockBack = T, flushPipe = T)\n461:     /* what is Svinval
      extension ?\n462:      *                       ----->             sfecne.w.inval\n\
      463:      * sfence.vma   vpn1     ----->             sinval_vma   vpn1\n464:\
      \      * sfence.vma   vpn2     ----->             sinval_vma   vpn2\n465:  \
      \    *                       ----->             sfecne.inval.ir"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 475-485
    context: "475:  */\n476: object CBODecode extends DecodeConstants {\n477:   val
      decodeArray: Array[(BitPat, XSDecodeBase)] = Array(\n478:     CBO_ZERO  -> XSDecode(SrcType.reg,
      SrcType.DC, SrcType.X, FuType.stu, LSUOpType.cbo_zero , SelImm.IMM_S),\n479:\
      \     CBO_CLEAN -> XSDecode(SrcType.reg, SrcType.DC, SrcType.X, FuType.stu,
      LSUOpType.cbo_clean, SelImm.IMM_S),\n480:     CBO_FLUSH -> XSDecode(SrcType.reg,
      SrcType.DC, SrcType.X, FuType.stu, LSUOpType.cbo_flush, SelImm.IMM_S),\n481:\
      \     CBO_INVAL -> XSDecode(SrcType.reg, SrcType.DC, SrcType.X, FuType.stu,
      LSUOpType.cbo_inval, SelImm.IMM_S)\n482:   )\n483: }\n484: \n485: /*"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 485-496
    context: "485: /*\n486:  * Hypervisor decode\n487:  */\n488: object HypervisorDecode
      extends DecodeConstants {\n489:   override val decodeArray: Array[(BitPat, XSDecodeBase)]
      = Array(\n490:     HFENCE_GVMA -> XSDecode(SrcType.reg, SrcType.reg, SrcType.X,
      FuType.fence, FenceOpType.hfence_g, SelImm.X, noSpec = T, blockBack = T, flushPipe
      = T),\n491:     HFENCE_VVMA -> XSDecode(SrcType.reg, SrcType.reg, SrcType.X,
      FuType.fence, FenceOpType.hfence_v, SelImm.X, noSpec = T, blockBack = T, flushPipe
      = T),\n492: \n493:     /**\n494:      * Since software cannot promiss all sinval.vma
      between sfence.w.inval and sfence.inval.ir, we make sinval.vma wait\n495:  \
      \    * forward.\n496:      */"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 530-548
    context: "530:   )\n531: }\n532: \n533: object ZfaDecode extends DecodeConstants
      {\n534:   override val decodeArray: Array[(BitPat, XSDecodeBase)] = Array(\n\
      535:     FLI_H       -> FDecode(SrcType.no, SrcType.X, SrcType.X, FuType.f2v,
      FuOpType.X, fWen = T, canRobCompress = T),\n536:     FLI_S       -> FDecode(SrcType.no,
      SrcType.X, SrcType.X, FuType.f2v, FuOpType.X, fWen = T, canRobCompress = T),\n\
      537:     FLI_D       -> FDecode(SrcType.no, SrcType.X, SrcType.X, FuType.f2v,
      FuOpType.X, fWen = T, canRobCompress = T),\n538:     FMINM_H     -> FDecode(SrcType.fp,
      SrcType.fp, SrcType.X, FuType.falu, VfaluType.fminm, fWen = T, canRobCompress
      = T),\n539:     FMINM_S     -> FDecode(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu,
      VfaluType.fminm, fWen = T, canRobCompress = T),\n540:     FMINM_D     -> FDecode(SrcType.fp,
      SrcType.fp, SrcType.X, FuType.falu, VfaluType.fminm, fWen = T, canRobCompress
      = T),\n541:     FMAXM_H     -> FDecode(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu,
      VfaluType.fmaxm, fWen = T, canRobCompress = T),\n542:     FMAXM_S     -> FDecode(SrcType.fp,
      SrcType.fp, SrcType.X, FuType.falu, VfaluType.fmaxm, fWen = T, canRobCompress
      = T),\n543:     FMAXM_D     -> FDecode(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu,
      VfaluType.fmaxm, fWen = T, canRobCompress = T),\n544:     FROUND_H    -> FDecode(SrcType.fp,
      SrcType.X,  SrcType.X, FuType.fcvt, VfcvtType.fround,   fWen = T, canRobCompress
      = T),\n545:     FROUND_S    -> FDecode(SrcType.fp, SrcType.X,  SrcType.X, FuType.fcvt,
      VfcvtType.fround,   fWen = T, canRobCompress = T),\n546:     FROUND_D    ->
      FDecode(SrcType.fp, SrcType.X,  SrcType.X, FuType.fcvt, VfcvtType.fround,  \
      \ fWen = T, canRobCompress = T),\n547:     FROUNDNX_H  -> FDecode(SrcType.fp,
      SrcType.X,  SrcType.X, FuType.fcvt, VfcvtType.froundnx, fWen = T, canRobCompress
      = T),\n548:     FROUNDNX_S  -> FDecode(SrcType.fp, SrcType.X,  SrcType.X, FuType.fcvt,
      VfcvtType.froundnx, fWen = T, canRobCompress = T),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 546-561
    context: "546:     FROUND_D    -> FDecode(SrcType.fp, SrcType.X,  SrcType.X, FuType.fcvt,
      VfcvtType.fround,   fWen = T, canRobCompress = T),\n547:     FROUNDNX_H  ->
      FDecode(SrcType.fp, SrcType.X,  SrcType.X, FuType.fcvt, VfcvtType.froundnx,
      fWen = T, canRobCompress = T),\n548:     FROUNDNX_S  -> FDecode(SrcType.fp,
      SrcType.X,  SrcType.X, FuType.fcvt, VfcvtType.froundnx, fWen = T, canRobCompress
      = T),\n549:     FROUNDNX_D  -> FDecode(SrcType.fp, SrcType.X,  SrcType.X, FuType.fcvt,
      VfcvtType.froundnx, fWen = T, canRobCompress = T),\n550:     FCVTMOD_W_D ->
      FDecode(SrcType.fp, SrcType.X,  SrcType.X, FuType.fcvt, VfcvtType.fcvtmod_w_d,
      xWen = T, canRobCompress = T),\n551:     FLEQ_H      -> FDecode(SrcType.fp,
      SrcType.fp, SrcType.X, FuType.falu, VfaluType.fleq, xWen = T, canRobCompress
      = T),\n552:     FLEQ_S      -> FDecode(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu,
      VfaluType.fleq, xWen = T, canRobCompress = T),\n553:     FLEQ_D      -> FDecode(SrcType.fp,
      SrcType.fp, SrcType.X, FuType.falu, VfaluType.fleq, xWen = T, canRobCompress
      = T),\n554:     FLTQ_H      -> FDecode(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu,
      VfaluType.fltq, xWen = T, canRobCompress = T),\n555:     FLTQ_S      -> FDecode(SrcType.fp,
      SrcType.fp, SrcType.X, FuType.falu, VfaluType.fltq, xWen = T, canRobCompress
      = T),\n556:     FLTQ_D      -> FDecode(SrcType.fp, SrcType.fp, SrcType.X, FuType.falu,
      VfaluType.fltq, xWen = T, canRobCompress = T),\n557:   )\n558: }\n559: \n560:
      /**\n561:  * XiangShan Debug Decode constants"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 817-829
    context: "817:     ZimopDecode.table ++\n818:     ZfaDecode.table\n819: \n820:\
      \   require(decode_table.map(_._2.length == 15).reduce(_ && _), \"Decode tables
      have different column size\")\n821:   // assertion for LUI: only LUI should
      be assigned `selImm === SelImm.IMM_U && fuType === FuType.alu`\n822:   val luiMatch
      = (t: Seq[BitPat]) => t(3).value == FuType.alu.ohid && t.reverse.head.value
      == SelImm.IMM_U.litValue\n823:   val luiTable = decode_table.filter(t => luiMatch(t._2)).map(_._1).distinct\n\
      824:   assert(luiTable.length == 1 && luiTable.head == LUI, \"Conflicts: LUI
      is determined by FuType and SelImm in Dispatch\")\n825: \n826:   // output\n\
      827:   val decodedInst: DecodedInst = Wire(new DecodedInst()).decode(ctrl_flow.instr,
      decode_table)\n828: \n829:   val fpDecoder = Module(new FPDecoder)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 827-837
    context: "827:   val decodedInst: DecodedInst = Wire(new DecodedInst()).decode(ctrl_flow.instr,
      decode_table)\n828: \n829:   val fpDecoder = Module(new FPDecoder)\n830:   fpDecoder.io.instr
      := ctrl_flow.instr\n831:   decodedInst.fpu := fpDecoder.io.fpCtrl\n832:   decodedInst.fpu.wflags
      := fpDecoder.io.fpCtrl.wflags || decodedInst.wfflags\n833: \n834:   decodedInst.connectStaticInst(io.enq.ctrlFlow)\n\
      835: \n836:   decodedInst.uopIdx := 0.U\n837:   decodedInst.firstUop := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 868-878
    context: "868:   // init v0Wen vlWen\n869:   decodedInst.v0Wen := false.B\n870:\
      \   decodedInst.vlWen := false.B\n871: \n872:   private val isCboClean = CBO_CLEAN
      === io.enq.ctrlFlow.instr\n873:   private val isCboFlush = CBO_FLUSH === io.enq.ctrlFlow.instr\n\
      874:   private val isCboInval = CBO_INVAL === io.enq.ctrlFlow.instr\n875:  \
      \ private val isCboZero  = CBO_ZERO  === io.enq.ctrlFlow.instr\n876: \n877:\
      \   // Note that rnum of aes64ks1i must be in the range 0x0..0xA. The values
      0xB..0xF are reserved.\n878:   private val isAes64ks1iIllegal ="
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 899-909
    context: "899:     io.fromCSR.illegalInst.wfi        && FuType.FuTypeOrR(decodedInst.fuType,
      FuType.csr)   && CSROpType.isWfi(decodedInst.fuOpType) ||\n900:     io.fromCSR.illegalInst.wrs_nto\
      \    && FuType.FuTypeOrR(decodedInst.fuType, FuType.csr)   && CSROpType.isWrsNto(decodedInst.fuOpType)
      ||\n901:     (decodedInst.needFrm.scalaNeedFrm || FuType.isScalaNeedFrm(decodedInst.fuType))
      && (((decodedInst.fpu.rm === 5.U) || (decodedInst.fpu.rm === 6.U)) || ((decodedInst.fpu.rm
      === 7.U) && io.fromCSR.illegalInst.frm)) ||\n902:     (decodedInst.needFrm.vectorNeedFrm
      || FuType.isVectorNeedFrm(decodedInst.fuType)) && io.fromCSR.illegalInst.frm
      ||\n903:     (io.fromCSR.illegalInst.cboZ  || !HasCMO.B) && isCboZero ||\n904:\
      \     (io.fromCSR.illegalInst.cboCF || !HasCMO.B) && (isCboClean || isCboFlush)
      ||\n905:     (io.fromCSR.illegalInst.cboI  || !HasCMO.B) && isCboInval ||\n\
      906:     isAes64ks1iIllegal ||\n907:     isAmocasQIllegal\n908: \n909:   private
      val exceptionVI ="
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 913-923
    context: "913:     io.fromCSR.virtualInst.hlsv       && FuType.FuTypeOrR(decodedInst.fuType,
      FuType.ldu)   && (LSUOpType.isHlv(decodedInst.fuOpType) || LSUOpType.isHlvx(decodedInst.fuOpType))
      ||\n914:     io.fromCSR.virtualInst.hlsv       && FuType.FuTypeOrR(decodedInst.fuType,
      FuType.stu)   && LSUOpType.isHsv(decodedInst.fuOpType) ||\n915:     io.fromCSR.virtualInst.wfi\
      \        && FuType.FuTypeOrR(decodedInst.fuType, FuType.csr)   && CSROpType.isWfi(decodedInst.fuOpType)
      ||\n916:     io.fromCSR.virtualInst.wrs_nto    && FuType.FuTypeOrR(decodedInst.fuType,
      FuType.csr)   && CSROpType.isWrsNto(decodedInst.fuOpType) ||\n917:     io.fromCSR.virtualInst.cboZ\
      \       && isCboZero ||\n918:     io.fromCSR.virtualInst.cboCF      && (isCboClean
      || isCboFlush) ||\n919:     io.fromCSR.virtualInst.cboI       && isCboInval\n\
      920: \n921: \n922:   decodedInst.exceptionVec(illegalInstr) := exceptionII ||
      io.enq.ctrlFlow.exceptionVec(EX_II)\n923:   decodedInst.exceptionVec(virtualInstr)
      := exceptionVI"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 938-948
    context: "938:   private val isStore = FuType.isStore(decodedInst.fuType)\n939:\
      \   private val isAMO = FuType.isAMO(decodedInst.fuType)\n940:   private val
      isVStore = FuType.isVStore(decodedInst.fuType)\n941:   private val isBranch
      = !decodedInst.preDecodeInfo.notCFI || FuType.isJump(decodedInst.fuType)\n942:\
      \ \n943:   decodedInst.commitType := Cat(isLs | isVls, (isStore && !isAMO) |
      isVStore | isBranch)\n944: \n945:   decodedInst.isVset := FuType.isVset(decodedInst.fuType)\n\
      946: \n947:   private val needReverseInsts = Seq(VRSUB_VI, VRSUB_VX, VFRDIV_VF,
      VFRSUB_VF, VFMV_F_S)\n948:   private val vextInsts = Seq(VZEXT_VF2, VZEXT_VF4,
      VZEXT_VF8, VSEXT_VF2, VSEXT_VF4, VSEXT_VF8)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 968-978
    context: "968:     VWMACCU_VV, VWMACCU_VX, VWMACC_VV, VWMACC_VX, VWMACCSU_VV,
      VWMACCSU_VX, VWMACCUS_VX,\n969:   )\n970:   private val wfflagsInsts = Seq(\n\
      971:     // opfff\n972:     FADD_S, FSUB_S, FADD_D, FSUB_D, FADD_H, FSUB_H,\n\
      973:     FEQ_S, FLT_S, FLE_S, FEQ_D, FLT_D, FLE_D, FEQ_H, FLT_H, FLE_H,\n974:\
      \     FMIN_S, FMAX_S, FMIN_D, FMAX_D, FMIN_H, FMAX_H,\n975:     FMUL_S, FMUL_D,
      FMUL_H,\n976:     FDIV_S, FDIV_D, FSQRT_S, FSQRT_D, FDIV_H, FSQRT_H,\n977: \
      \    FMADD_S, FMSUB_S, FNMADD_S, FNMSUB_S, FMADD_D, FMSUB_D, FNMADD_D, FNMSUB_D,
      FMADD_H, FMSUB_H, FNMADD_H, FNMSUB_H,\n978:     FSGNJ_S, FSGNJN_S, FSGNJX_S,
      FSGNJ_H, FSGNJN_H, FSGNJX_H,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 995-1010
    context: "995:     VFSGNJ_VF, VFSGNJN_VF, VFSGNJX_VF,\n996:     // vfred\n997:\
      \     VFREDOSUM_VS, VFREDUSUM_VS, VFREDMAX_VS, VFREDMIN_VS, VFWREDOSUM_VS, VFWREDUSUM_VS,\n\
      998:     // fcvt & vfcvt\n999:     FCVT_S_W, FCVT_S_WU, FCVT_S_L, FCVT_S_LU,\n\
      1000:     FCVT_W_S, FCVT_WU_S, FCVT_L_S, FCVT_LU_S,\n1001:     FCVT_D_W, FCVT_D_WU,
      FCVT_D_L, FCVT_D_LU,\n1002:     FCVT_W_D, FCVT_WU_D, FCVT_L_D, FCVT_LU_D, FCVT_S_D,
      FCVT_D_S,\n1003:     FCVT_S_H, FCVT_H_S, FCVT_H_D, FCVT_D_H,\n1004:     FCVT_H_W,
      FCVT_H_WU, FCVT_H_L, FCVT_H_LU,\n1005:     FCVT_W_H, FCVT_WU_H, FCVT_L_H, FCVT_LU_H,\n\
      1006:     VFCVT_XU_F_V, VFCVT_X_F_V, VFCVT_RTZ_XU_F_V, VFCVT_RTZ_X_F_V, VFCVT_F_XU_V,
      VFCVT_F_X_V,\n1007:     VFWCVT_XU_F_V, VFWCVT_X_F_V, VFWCVT_RTZ_XU_F_V, VFWCVT_RTZ_X_F_V,
      VFWCVT_F_XU_V, VFWCVT_F_X_V, VFWCVT_F_F_V,\n1008:     VFNCVT_XU_F_W, VFNCVT_X_F_W,
      VFNCVT_RTZ_XU_F_W, VFNCVT_RTZ_X_F_W, VFNCVT_F_XU_W, VFNCVT_F_X_W, VFNCVT_F_F_W,\n\
      1009:     VFNCVT_ROD_F_F_W, VFRSQRT7_V, VFREC7_V,\n1010:     // zfa"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 1014-1026
    context: "1014:     FCVTMOD_W_D,\n1015:   )\n1016: \n1017:   private val scalaNeedFrmInsts
      = Seq(\n1018:     FADD_S, FSUB_S, FADD_D, FSUB_D, FADD_H, FSUB_H,\n1019:   \
      \  FCVT_W_S, FCVT_WU_S, FCVT_L_S, FCVT_LU_S,\n1020:     FCVT_W_D, FCVT_WU_D,
      FCVT_L_D, FCVT_LU_D, FCVT_S_D, FCVT_D_S,\n1021:     FCVT_W_H, FCVT_WU_H, FCVT_L_H,
      FCVT_LU_H,\n1022:     FCVT_S_H, FCVT_H_S, FCVT_H_D, FCVT_D_H,\n1023:     FROUND_H,
      FROUND_S, FROUND_D, FROUNDNX_H, FROUNDNX_S, FROUNDNX_D,\n1024:   )\n1025: \n\
      1026:   private val vectorNeedFrmInsts = Seq ("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 1025-1035
    context: "1025: \n1026:   private val vectorNeedFrmInsts = Seq (\n1027:     VFSLIDE1UP_VF,
      VFSLIDE1DOWN_VF,\n1028:   )\n1029: \n1030:   decodedInst.wfflags := wfflagsInsts.map(_
      === inst.ALL).reduce(_ || _)\n1031:   decodedInst.needFrm.scalaNeedFrm := scalaNeedFrmInsts.map(_
      === inst.ALL).reduce(_ || _)\n1032:   decodedInst.needFrm.vectorNeedFrm := vectorNeedFrmInsts.map(_
      === inst.ALL).reduce(_ || _)\n1033:   decodedInst.vpu := 0.U.asTypeOf(decodedInst.vpu)
      // Todo: Connect vpu decoder\n1034:   decodedInst.vpu.vill := io.enq.vtype.illegal\n\
      1035:   decodedInst.vpu.vma := io.enq.vtype.vma"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 1172-1182
    context: "1172:     (isPreW || isPreR || isPreI) -> Mux1H(Seq(\n1173:       isPreW
      -> LSUOpType.prefetch_w,\n1174:       isPreR -> LSUOpType.prefetch_r,\n1175:\
      \       isPreI -> LSUOpType.prefetch_i,\n1176:     )),\n1177:     (isCboInval
      && io.fromCSR.special.cboI2F) -> LSUOpType.cbo_flush,\n1178:   ))\n1179: \n\
      1180:   // Don't compress in the same Rob entry when crossing Ftq entry boundary\n\
      1181:   io.deq.decodedInst.canRobCompress := decodedInst.canRobCompress && !io.enq.ctrlFlow.isLastInFtqEntry\n\
      1182: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Snapshot.scala
    lines: 10-26
    context: "10: class SnapshotPtr(implicit p: Parameters) extends CircularQueuePtr[SnapshotPtr](\n\
      11:   p => p(XSCoreParamsKey).RenameSnapshotNum\n12: )\n13: \n14: object SnapshotGenerator
      extends HasCircularQueuePtrHelper {\n15:   def apply[T <: Data](enqData: T,
      enq: Bool, deq: Bool, redirect: Bool, flushVec: Vec[Bool])(implicit p: Parameters):
      Vec[T] = {\n16:     val snapshotGen = Module(new SnapshotGenerator(enqData))\n\
      17:     snapshotGen.io.enq := enq\n18:     snapshotGen.io.enqData := enqData\n\
      19:     snapshotGen.io.deq := deq\n20:     snapshotGen.io.redirect := redirect\n\
      21:     snapshotGen.io.flushVec := flushVec\n22:     snapshotGen.io.snapshots\n\
      23:   }\n24: }\n25: \n26: class SnapshotGenerator[T <: Data](dataType: T)(implicit
      p: Parameters) extends XSModule"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Snapshot.scala
    lines: 28-39
    context: "28: \n29:   class SnapshotGeneratorIO extends Bundle {\n30:     val
      enq = Input(Bool())\n31:     val enqData = Input(chiselTypeOf(dataType))\n32:\
      \     val deq = Input(Bool())\n33:     val redirect = Input(Bool())\n34:   \
      \  val flushVec = Input(Vec(RenameSnapshotNum, Bool()))\n35:     val snapshots
      = Output(Vec(RenameSnapshotNum, chiselTypeOf(dataType)))\n36:     val enqPtr
      = Output(new SnapshotPtr)\n37:     val deqPtr = Output(new SnapshotPtr)\n38:\
      \     val valids = Output(Vec(RenameSnapshotNum, Bool()))\n39:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Snapshot.scala
    lines: 48-76
    context: "48:   io.snapshots := snapshots\n49:   io.enqPtr := snptEnqPtr\n50:\
      \   io.deqPtr := snptDeqPtr\n51:   io.valids := snptValids\n52: \n53:   when(!io.redirect
      && !isFull(snptEnqPtr, snptDeqPtr) && io.enq) {\n54:     snapshots(snptEnqPtr.value)
      := io.enqData\n55:     snptValids(snptEnqPtr.value) := true.B\n56:     snptEnqPtr
      := snptEnqPtr + 1.U\n57:   }\n58:   when(!io.redirect && io.deq) {\n59:    \
      \ snptValids(snptDeqPtr.value) := false.B\n60:     snptDeqPtr := snptDeqPtr
      + 1.U\n61:   }\n62:   XSError(!io.redirect && io.deq && isEmpty(snptEnqPtr,
      snptDeqPtr), \"snapshots should not be empty when dequeue!\\n\")\n63: \n64:\
      \   snptValids.zip(io.flushVec).foreach { case (valid, flush) =>\n65:     when(flush)
      { valid := false.B }\n66:   }\n67:   when((Cat(io.flushVec) & Cat(snptValids)).orR)
      {\n68:     val newEnqPtrCandidate = (0 until RenameSnapshotNum).map(snptDeqPtr
      + _.U)\n69:     val newEnqPtrQualified = Wire(Vec(RenameSnapshotNum, Bool()))\n\
      70:     newEnqPtrQualified.head := !snptValids(newEnqPtrCandidate.head.value)
      || io.flushVec(newEnqPtrCandidate.head.value)\n71:     newEnqPtrQualified.tail
      zip newEnqPtrCandidate.tail.zip(newEnqPtrCandidate.drop(1)).map {\n72:     \
      \  case (thiz, last) => snptValids(last.value) && (!snptValids(thiz.value) ||
      io.flushVec(thiz.value))\n73:     } foreach (x => x._1 := x._2)\n74:     snptEnqPtr
      := MuxCase(newEnqPtrCandidate.last, newEnqPtrQualified.zip(newEnqPtrCandidate).dropRight(1))\n\
      75:   }\n76: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 71-81
    context: "71:     case Reg_V0 => log2Ceil(V0LogicRegs)\n72:     case Reg_Vl =>
      log2Ceil(VlLogicRegs)\n73:   }\n74: \n75:   val io = IO(new Bundle {\n76:  \
      \   val redirect = Input(Bool())\n77:     val readPorts = Vec(readPortsNum *
      RenameWidth, new RatReadPort(renameTableWidth))\n78:     val specWritePorts
      = Vec(RabCommitWidth, Input(new RatWritePort(renameTableWidth)))\n79:     val
      archWritePorts = Vec(RabCommitWidth, Input(new RatWritePort(renameTableWidth)))\n\
      80:     val old_pdest = Vec(RabCommitWidth, Output(UInt(PhyRegIdxWidth.W)))\n\
      81:     val need_free = Vec(RabCommitWidth, Output(Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 121-139
    context: "121:   // For better timing, we optimize reading and writing to RenameTable
      as follows:\n122:   // (1) Writing at T0 will be actually processed at T1.\n\
      123:   // (2) Reading is synchronous now.\n124:   // (3) RAddr at T0 will be
      used to access the table and get data at T0.\n125:   // (4) WData at T0 is bypassed
      to RData at T1.\n126:   val t1_redirect = GatedValidRegNext(io.redirect, false.B)\n\
      127:   val t1_raddr = io.readPorts.map(p => RegEnable(p.addr, !p.hold))\n128:\
      \   val t1_rdata_use_t1_raddr = VecInit(t1_raddr.map(spec_table(_)))\n129: \
      \  val t1_wSpec = RegNext(Mux(io.redirect, 0.U.asTypeOf(io.specWritePorts),
      io.specWritePorts))\n130: \n131:   val t1_snpt = RegNext(io.snpt, 0.U.asTypeOf(io.snpt))\n\
      132:   val t2_snpt = RegNext(t1_snpt, 0.U.asTypeOf(io.snpt))\n133: \n134:  \
      \ val snapshots = SnapshotGenerator(spec_table, t1_snpt.snptEnq, t1_snpt.snptDeq,
      t1_redirect, t1_snpt.flushVec)\n135: \n136:   // WRITE: when instruction commits
      or walking\n137:   val t1_wSpec_addr = t1_wSpec.map(w => Mux(w.wen, UIntToOH(w.addr),
      0.U))\n138:   for ((next, i) <- spec_table_next.zipWithIndex) {\n139:     val
      matchVec = t1_wSpec_addr.map(w => w(i))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 138-148
    context: "138:   for ((next, i) <- spec_table_next.zipWithIndex) {\n139:     val
      matchVec = t1_wSpec_addr.map(w => w(i))\n140:     val wMatch = ParallelPriorityMux(matchVec.reverse,
      t1_wSpec.map(_.data).reverse)\n141:     // When there's a flush, we use arch_table
      to update spec_table.\n142:     next := Mux(\n143:       RegNext(t1_redirect),\n\
      144:       Mux(t2_snpt.useSnpt, snapshots(t2_snpt.snptSelect)(i), arch_table(i)),\n\
      145:       Mux(VecInit(matchVec).asUInt.orR, wMatch, spec_table(i))\n146:  \
      \   )\n147:   }\n148:   spec_table := spec_table_next"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 148-158
    context: "148:   spec_table := spec_table_next\n149: \n150:   // READ: decode-rename
      stage\n151:   for ((r, i) <- io.readPorts.zipWithIndex) {\n152:     val t0_bypass
      = io.specWritePorts.map(w => w.wen && Mux(r.hold, w.addr === t1_raddr(i), w.addr
      === r.addr))\n153:     val t1_bypass = RegNext(Mux(io.redirect, 0.U.asTypeOf(VecInit(t0_bypass)),
      VecInit(t0_bypass)))\n154:     val bypass_data = ParallelPriorityMux(t1_bypass.reverse,
      t1_wSpec.map(_.data).reverse)\n155:     r.data := Mux(t1_bypass.asUInt.orR,
      bypass_data, t1_rdata_use_t1_raddr(i))\n156:   }\n157: \n158:   for ((w, i)
      <- io.archWritePorts.zipWithIndex) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 164-188
    context: "164:       MuxCase(arch_table(w.addr) & arch_mask,\n165:           \
      \    io.archWritePorts.take(i).reverse.map(x => (x.wen && x.addr === w.addr,
      x.data & arch_mask)))\n166:   }\n167:   arch_table := arch_table_next\n168:\
      \ \n169:   for (((old, free), i) <- (old_pdest zip need_free).zipWithIndex)
      {\n170:     val hasDuplicate = old_pdest.take(i).map(_ === old)\n171:     val
      blockedByDup = if (i == 0) false.B else VecInit(hasDuplicate).asUInt.orR\n172:\
      \     free := VecInit(arch_table.map(_ =/= old)).asUInt.andR && !blockedByDup\n\
      173:   }\n174: \n175:   io.old_pdest := old_pdest\n176:   io.need_free := need_free\n\
      177:   io.debug_rdata.foreach{ x => reg_t match {\n178:       case Reg_V =>
      x := arch_table.drop(1).take(rdataNums)\n179:       case _ => x := arch_table.take(rdataNums)\n\
      180:     }\n181:   }\n182:   io.debug_v0.foreach(_ := arch_table(0))\n183: \
      \  io.debug_vl.foreach(_ := arch_table(0))\n184:   if (env.EnableDifftest ||
      env.AlwaysBasicDiff) {\n185:     val difftest_table = RegInit(rename_table_init)\n\
      186:     val difftest_table_next = WireDefault(difftest_table)\n187: \n188:\
      \     for (w <- io.diffWritePorts.get) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 190-211
    context: "190:         difftest_table_next(w.addr) := w.data\n191:       }\n192:\
      \     }\n193:     difftest_table := difftest_table_next\n194: \n195:     io.diff_rdata.foreach{
      x => reg_t match {\n196:         case Reg_V => x := difftest_table.drop(1).take(rdataNums)\n\
      197:         case _ => x := difftest_table.take(rdataNums)\n198:       }\n199:\
      \     }\n200:     io.diff_v0.foreach(_ := difftest_table(0))\n201:     io.diff_vl.foreach(_
      := difftest_table(0))\n202:   }\n203:   else {\n204:     io.diff_rdata.foreach(_
      := 0.U.asTypeOf(io.debug_rdata.get))\n205:     io.diff_v0.foreach(_ := 0.U)\n\
      206:     io.diff_vl.foreach(_ := 0.U)\n207:   }\n208: }\n209: \n210: class RenameTableWrapper(implicit
      p: Parameters) extends XSModule {\n211: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 212-222
    context: "212:   // params alias\n213:   private val numVecRegSrc = backendParams.numVecRegSrc\n\
      214:   private val numVecRatPorts = numVecRegSrc\n215: \n216:   val io = IO(new
      Bundle() {\n217:     val redirect = Input(Bool())\n218:     val rabCommits =
      Input(new RabCommitIO)\n219:     val diffCommits = if (backendParams.basicDebugEn)
      Some(Input(new DiffCommitIO)) else None\n220:     val intReadPorts = Vec(RenameWidth,
      Vec(2, new RatReadPort(IntLogicRegs)))\n221:     val intRenamePorts = Vec(RenameWidth,
      Input(new RatWritePort(IntLogicRegs)))\n222:     val fpReadPorts = Vec(RenameWidth,
      Vec(3, new RatReadPort(FpLogicRegs)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 255-268
    context: "255:   val fpRat  = Module(new RenameTable(Reg_F))\n256:   val vecRat
      = Module(new RenameTable(Reg_V))\n257:   val v0Rat  = Module(new RenameTable(Reg_V0))\n\
      258:   val vlRat  = Module(new RenameTable(Reg_Vl))\n259: \n260:   io.debug_int_rat
      .foreach(_ := intRat.io.debug_rdata.get)\n261:   io.diff_int_rat  .foreach(_
      := intRat.io.diff_rdata.get)\n262:   intRat.io.readPorts <> io.intReadPorts.flatten\n\
      263:   intRat.io.redirect := io.redirect\n264:   intRat.io.snpt := io.snpt\n\
      265:   io.int_old_pdest := intRat.io.old_pdest\n266:   io.int_need_free := intRat.io.need_free\n\
      267:   val intDestValid = io.rabCommits.info.map(_.rfWen)\n268:   for ((arch,
      i) <- intRat.io.archWritePorts.zipWithIndex) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 264-274
    context: "264:   intRat.io.snpt := io.snpt\n265:   io.int_old_pdest := intRat.io.old_pdest\n\
      266:   io.int_need_free := intRat.io.need_free\n267:   val intDestValid = io.rabCommits.info.map(_.rfWen)\n\
      268:   for ((arch, i) <- intRat.io.archWritePorts.zipWithIndex) {\n269:    \
      \ arch.wen  := io.rabCommits.isCommit && io.rabCommits.commitValid(i) && intDestValid(i)\n\
      270:     arch.addr := io.rabCommits.info(i).ldest\n271:     arch.data := io.rabCommits.info(i).pdest\n\
      272:     XSError(arch.wen && arch.addr === 0.U && arch.data =/= 0.U, \"pdest
      for $0 should be 0\\n\")\n273:   }\n274:   for ((spec, i) <- intRat.io.specWritePorts.zipWithIndex)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 270-280
    context: "270:     arch.addr := io.rabCommits.info(i).ldest\n271:     arch.data
      := io.rabCommits.info(i).pdest\n272:     XSError(arch.wen && arch.addr === 0.U
      && arch.data =/= 0.U, \"pdest for $0 should be 0\\n\")\n273:   }\n274:   for
      ((spec, i) <- intRat.io.specWritePorts.zipWithIndex) {\n275:     spec.wen  :=
      io.rabCommits.isWalk && io.rabCommits.walkValid(i) && intDestValid(i)\n276:\
      \     spec.addr := io.rabCommits.info(i).ldest\n277:     spec.data := io.rabCommits.info(i).pdest\n\
      278:     XSError(spec.wen && spec.addr === 0.U && spec.data =/= 0.U, \"pdest
      for $0 should be 0\\n\")\n279:   }\n280:   for ((spec, rename) <- intRat.io.specWritePorts.zip(io.intRenamePorts))
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 284-294
    context: "284:       spec.data := rename.data\n285:     }\n286:   }\n287:   if
      (backendParams.basicDebugEn) {\n288:     for ((diff, i) <- intRat.io.diffWritePorts.get.zipWithIndex)
      {\n289:       diff.wen := io.diffCommits.get.isCommit && io.diffCommits.get.commitValid(i)
      && io.diffCommits.get.info(i).rfWen\n290:       diff.addr := io.diffCommits.get.info(i).ldest\n\
      291:       diff.data := io.diffCommits.get.info(i).pdest\n292:     }\n293: \
      \  }\n294: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 291-314
    context: "291:       diff.data := io.diffCommits.get.info(i).pdest\n292:     }\n\
      293:   }\n294: \n295:   // debug read ports for difftest\n296:   io.debug_fp_rat.foreach(_
      := fpRat.io.debug_rdata.get)\n297:   io.diff_fp_rat .foreach(_ := fpRat.io.diff_rdata.get)\n\
      298:   fpRat.io.readPorts <> io.fpReadPorts.flatten\n299:   fpRat.io.redirect
      := io.redirect\n300:   fpRat.io.snpt := io.snpt\n301:   io.fp_old_pdest := fpRat.io.old_pdest\n\
      302: \n303:   for ((arch, i) <- fpRat.io.archWritePorts.zipWithIndex) {\n304:\
      \     arch.wen  := io.rabCommits.isCommit && io.rabCommits.commitValid(i) &&
      io.rabCommits.info(i).fpWen\n305:     arch.addr := io.rabCommits.info(i).ldest\n\
      306:     arch.data := io.rabCommits.info(i).pdest\n307:   }\n308:   for ((spec,
      i) <- fpRat.io.specWritePorts.zipWithIndex) {\n309:     spec.wen  := io.rabCommits.isWalk
      && io.rabCommits.walkValid(i) && io.rabCommits.info(i).fpWen\n310:     spec.addr
      := io.rabCommits.info(i).ldest\n311:     spec.data := io.rabCommits.info(i).pdest\n\
      312:   }\n313:   for ((spec, rename) <- fpRat.io.specWritePorts.zip(io.fpRenamePorts))
      {\n314:     when (rename.wen) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 317-327
    context: "317:       spec.data := rename.data\n318:     }\n319:   }\n320:   if
      (backendParams.basicDebugEn) {\n321:     for ((diff, i) <- fpRat.io.diffWritePorts.get.zipWithIndex)
      {\n322:       diff.wen := io.diffCommits.get.isCommit && io.diffCommits.get.commitValid(i)
      && io.diffCommits.get.info(i).fpWen\n323:       diff.addr := io.diffCommits.get.info(i).ldest\n\
      324:       diff.data := io.diffCommits.get.info(i).pdest\n325:     }\n326: \
      \  }\n327: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 324-337
    context: "324:       diff.data := io.diffCommits.get.info(i).pdest\n325:     }\n\
      326:   }\n327: \n328:   // debug read ports for difftest\n329:   io.debug_vec_rat\
      \    .foreach(_ := vecRat.io.debug_rdata.get)\n330:   io.diff_vec_rat     .foreach(_
      := vecRat.io.diff_rdata.get)\n331:   vecRat.io.readPorts <> io.vecReadPorts.flatten\n\
      332:   vecRat.io.redirect := io.redirect\n333:   vecRat.io.snpt := io.snpt\n\
      334:   io.vec_old_pdest := vecRat.io.old_pdest\n335: \n336:   //TODO: RM the
      donTouch\n337:   if(backendParams.debugEn) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 336-351
    context: "336:   //TODO: RM the donTouch\n337:   if(backendParams.debugEn) {\n\
      338:     dontTouch(vecRat.io)\n339:   }\n340:   for ((arch, i) <- vecRat.io.archWritePorts.zipWithIndex)
      {\n341:     arch.wen  := io.rabCommits.isCommit && io.rabCommits.commitValid(i)
      && io.rabCommits.info(i).vecWen\n342:     arch.addr := io.rabCommits.info(i).ldest\n\
      343:     arch.data := io.rabCommits.info(i).pdest\n344:   }\n345:   for ((spec,
      i) <- vecRat.io.specWritePorts.zipWithIndex) {\n346:     spec.wen  := io.rabCommits.isWalk
      && io.rabCommits.walkValid(i) && io.rabCommits.info(i).vecWen\n347:     spec.addr
      := io.rabCommits.info(i).ldest\n348:     spec.data := io.rabCommits.info(i).pdest\n\
      349:   }\n350:   for ((spec, rename) <- vecRat.io.specWritePorts.zip(io.vecRenamePorts))
      {\n351:     when (rename.wen) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 354-364
    context: "354:       spec.data := rename.data\n355:     }\n356:   }\n357:   if
      (backendParams.basicDebugEn) {\n358:     for ((diff, i) <- vecRat.io.diffWritePorts.get.zipWithIndex)
      {\n359:       diff.wen := io.diffCommits.get.isCommit && io.diffCommits.get.commitValid(i)
      && io.diffCommits.get.info(i).vecWen\n360:       diff.addr := io.diffCommits.get.info(i).ldest\n\
      361:       diff.data := io.diffCommits.get.info(i).pdest\n362:     }\n363: \
      \  }\n364: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 361-374
    context: "361:       diff.data := io.diffCommits.get.info(i).pdest\n362:     }\n\
      363:   }\n364: \n365:   // debug read ports for difftest\n366:   io.debug_v0_rat.foreach(_
      := v0Rat.io.debug_rdata.get)\n367:   io.diff_v0_rat.foreach(_ := v0Rat.io.diff_rdata.get)\n\
      368:   v0Rat.io.readPorts <> io.v0ReadPorts\n369:   v0Rat.io.redirect := io.redirect\n\
      370:   v0Rat.io.snpt := io.snpt\n371:   io.v0_old_pdest := v0Rat.io.old_pdest\n\
      372: \n373:   if (backendParams.debugEn) {\n374:     dontTouch(v0Rat.io)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 372-387
    context: "372: \n373:   if (backendParams.debugEn) {\n374:     dontTouch(v0Rat.io)\n\
      375:   }\n376:   for ((arch, i) <- v0Rat.io.archWritePorts.zipWithIndex) {\n\
      377:     arch.wen := io.rabCommits.isCommit && io.rabCommits.commitValid(i)
      && io.rabCommits.info(i).v0Wen\n378:     arch.addr := io.rabCommits.info(i).ldest\n\
      379:     arch.data := io.rabCommits.info(i).pdest\n380:   }\n381:   for ((spec,
      i) <- v0Rat.io.specWritePorts.zipWithIndex) {\n382:     spec.wen := io.rabCommits.isWalk
      && io.rabCommits.walkValid(i) && io.rabCommits.info(i).v0Wen\n383:     spec.addr
      := io.rabCommits.info(i).ldest\n384:     spec.data := io.rabCommits.info(i).pdest\n\
      385:   }\n386:   for ((spec, rename) <- v0Rat.io.specWritePorts.zip(io.v0RenamePorts))
      {\n387:     when(rename.wen) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 390-400
    context: "390:       spec.data := rename.data\n391:     }\n392:   }\n393:   if
      (backendParams.basicDebugEn) {\n394:     for ((diff, i) <- v0Rat.io.diffWritePorts.get.zipWithIndex)
      {\n395:       diff.wen := io.diffCommits.get.isCommit && io.diffCommits.get.commitValid(i)
      && io.diffCommits.get.info(i).v0Wen\n396:       diff.addr := io.diffCommits.get.info(i).ldest\n\
      397:       diff.data := io.diffCommits.get.info(i).pdest\n398:     }\n399: \
      \  }\n400: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 397-410
    context: "397:       diff.data := io.diffCommits.get.info(i).pdest\n398:     }\n\
      399:   }\n400: \n401:   // debug read ports for difftest\n402:   io.debug_vl_rat.foreach(_
      := vlRat.io.debug_rdata.get)\n403:   io.diff_vl_rat.foreach(_ := vlRat.io.diff_rdata.get)\n\
      404:   vlRat.io.readPorts <> io.vlReadPorts\n405:   vlRat.io.redirect := io.redirect\n\
      406:   vlRat.io.snpt := io.snpt\n407:   io.vl_old_pdest := vlRat.io.old_pdest\n\
      408: \n409:   if (backendParams.debugEn) {\n410:     dontTouch(vlRat.io)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 408-423
    context: "408: \n409:   if (backendParams.debugEn) {\n410:     dontTouch(vlRat.io)\n\
      411:   }\n412:   for ((arch, i) <- vlRat.io.archWritePorts.zipWithIndex) {\n\
      413:     arch.wen := io.rabCommits.isCommit && io.rabCommits.commitValid(i)
      && io.rabCommits.info(i).vlWen\n414:     arch.addr := io.rabCommits.info(i).ldest\n\
      415:     arch.data := io.rabCommits.info(i).pdest\n416:   }\n417:   for ((spec,
      i) <- vlRat.io.specWritePorts.zipWithIndex) {\n418:     spec.wen := io.rabCommits.isWalk
      && io.rabCommits.walkValid(i) && io.rabCommits.info(i).vlWen\n419:     spec.addr
      := io.rabCommits.info(i).ldest\n420:     spec.data := io.rabCommits.info(i).pdest\n\
      421:   }\n422:   for ((spec, rename) <- vlRat.io.specWritePorts.zip(io.vlRenamePorts))
      {\n423:     when(rename.wen) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 426-436
    context: "426:       spec.data := rename.data\n427:     }\n428:   }\n429:   if
      (backendParams.basicDebugEn) {\n430:     for ((diff, i) <- vlRat.io.diffWritePorts.get.zipWithIndex)
      {\n431:       diff.wen := io.diffCommits.get.isCommit && io.diffCommits.get.commitValid(i)
      && io.diffCommits.get.info(i).vlWen\n432:       diff.addr := io.diffCommits.get.info(i).ldest\n\
      433:       diff.data := io.diffCommits.get.info(i).pdest\n434:     }\n435: \
      \  }\n436: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/CompressUnit.scala
    lines: 47-57
    context: "47:   })\n48: \n49:   val noExc = io.in.map(in => !in.bits.exceptionVec.asUInt.orR
      && !TriggerAction.isDmode(in.bits.trigger))\n50:   val uopCanCompress = io.in.map(_.bits.canRobCompress)\n\
      51:   val canCompress = io.in.zip(noExc).zip(uopCanCompress).map { case ((in,
      noExc), canComp) =>\n52:     in.valid && !CommitType.isFused(in.bits.commitType)
      && in.bits.lastUop && noExc && canComp\n53:   }\n54: \n55:   val compressTable
      = (0 until 1 << RenameWidth).map { case keyCandidate =>\n56:     // padding
      0s at each side for convenience\n57:     val key = 0 +: (0 until RenameWidth).map(idx
      => (keyCandidate >> idx) & 1) :+ 0"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/CompressUnit.scala
    lines: 85-94
    context: "85:     (keyBitPat -> (needRobBitPats ++ uopSizeBitPats ++ maskBitPats))\n\
      86:   }\n87: \n88:   val default = Seq.fill(3 * RenameWidth)(BitPat.N())\n89:\
      \   val decoder = DecodeLogic(VecInit(canCompress).asUInt, default, compressTable)\n\
      90:   (io.out.needRobFlags ++ io.out.instrSizes ++ io.out.masks).zip(decoder).foreach
      {\n91:     case (sink, source) => sink := source\n92:   }\n93:   io.out.canCompressVec
      := VecInit(canCompress)\n94: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/BaseFreeList.scala
    lines: 25-35
    context: "25: import utility._\n26: \n27: \n28: abstract class BaseFreeList(size:
      Int, numLogicRegs:Int = 32)(implicit p: Parameters) extends XSModule with HasCircularQueuePtrHelper
      {\n29:   val io = IO(new Bundle {\n30:     val redirect = Input(Bool())\n31:\
      \     val walk = Input(Bool())\n32: \n33:     val allocateReq = Input(Vec(RenameWidth,
      Bool()))\n34:     val walkReq = Input(Vec(RabCommitWidth, Bool()))\n35:    \
      \ val allocatePhyReg = Output(Vec(RenameWidth, UInt(PhyRegIdxWidth.W)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/BaseFreeList.scala
    lines: 37-47
    context: "37:     val doAllocate = Input(Bool())\n38: \n39:     val freeReq =
      Input(Vec(RabCommitWidth, Bool()))\n40:     val freePhyReg = Input(Vec(RabCommitWidth,
      UInt(PhyRegIdxWidth.W)))\n41: \n42:     val commit = Input(new RabCommitIO)\n\
      43: \n44:     val snpt = Input(new SnapshotPort)\n45: \n46:     val debug_rat
      = if(backendParams.debugEn) Some(Vec(numLogicRegs, Input(UInt(PhyRegIdxWidth.W))))
      else None\n47:   })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/BaseFreeList.scala
    lines: 55-65
    context: "55:       ptr.value := v.U\n56:       ptr\n57:     }\n58:   }\n59: \n\
      60:   val lastCycleRedirect = RegNext(RegNext(io.redirect))\n61:   val lastCycleSnpt
      = RegNext(RegNext(io.snpt, 0.U.asTypeOf(io.snpt)))\n62: \n63:   val headPtr
      = RegInit(FreeListPtr(false, 0))\n64:   val headPtrOH = RegInit(1.U(size.W))\n\
      65:   val archHeadPtr = RegInit(FreeListPtr(false, 0))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/BaseFreeList.scala
    lines: 66-83
    context: "66:   XSError(headPtr.toOH =/= headPtrOH, p\"wrong one-hot reg between
      $headPtr and $headPtrOH\")\n67:   val headPtrOHShift = CircularShift(headPtrOH)\n\
      68:   // may shift [0, RenameWidth] steps\n69:   val headPtrOHVec = VecInit.tabulate(RenameWidth
      + 1)(headPtrOHShift.left)\n70: \n71:   val snapshots = SnapshotGenerator(headPtr,
      io.snpt.snptEnq, io.snpt.snptDeq, io.redirect, io.snpt.flushVec)\n72: \n73:\
      \   val redirectedHeadPtr = Mux(\n74:     lastCycleSnpt.useSnpt,\n75:     snapshots(lastCycleSnpt.snptSelect)
      + PopCount(io.walkReq),\n76:     archHeadPtr + PopCount(io.walkReq)\n77:   )\n\
      78:   val redirectedHeadPtrOH = Mux(\n79:     lastCycleSnpt.useSnpt,\n80:  \
      \   (snapshots(lastCycleSnpt.snptSelect) + PopCount(io.walkReq)).toOH,\n81:\
      \     (archHeadPtr + PopCount(io.walkReq)).toOH\n82:   )\n83: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/MEFreeList.scala
    lines: 29-42
    context: "29:     // originally {1, 2, ..., size - 1} are free. Register 0-31
      are mapped to x0.\n30:     Seq.tabulate(size - 1)(i => (i + 1).U(PhyRegIdxWidth.W))
      :+ 0.U(PhyRegIdxWidth.W)))\n31: \n32:   val tailPtr = RegInit(FreeListPtr(false,
      size - 1))\n33: \n34:   val doWalkRename = io.walk && io.doAllocate && !io.redirect\n\
      35:   val doNormalRename = io.canAllocate && io.doAllocate && !io.redirect\n\
      36:   val doRename = doWalkRename || doNormalRename\n37:   val doCommit = io.commit.isCommit\n\
      38: \n39:   /**\n40:     * Allocation: from freelist (same as StdFreelist)\n\
      41:     */\n42:   val phyRegCandidates = VecInit(headPtrOHVec.map(sel => Mux1H(sel,
      freeList)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/MEFreeList.scala
    lines: 43-64
    context: "43:   for (i <- 0 until RenameWidth) {\n44:     // enqueue instr, is
      move elimination\n45:     io.allocatePhyReg(i) := phyRegCandidates(PopCount(io.allocateReq.take(i)))\n\
      46:   }\n47:   // update arch head pointer\n48:   val archAlloc = io.commit.commitValid
      zip io.commit.info map {\n49:     case (valid, info) => valid && info.rfWen
      && !info.isMove\n50:   }\n51:   val numArchAllocate = PopCount(archAlloc)\n\
      52:   val archHeadPtrNew  = archHeadPtr + numArchAllocate\n53:   val archHeadPtrNext
      = Mux(doCommit, archHeadPtrNew, archHeadPtr)\n54:   archHeadPtr := archHeadPtrNext\n\
      55: \n56:   // update head pointer\n57:   val numAllocate = Mux(io.walk, PopCount(io.walkReq),
      PopCount(io.allocateReq))\n58:   val headPtrNew   = Mux(lastCycleRedirect, redirectedHeadPtr,
      headPtr + numAllocate)\n59:   val headPtrOHNew = Mux(lastCycleRedirect, redirectedHeadPtrOH,
      headPtrOHVec(numAllocate))\n60:   val headPtrNext   = Mux(doRename, headPtrNew,
      headPtr)\n61:   val headPtrOHNext = Mux(doRename, headPtrOHNew, headPtrOH)\n\
      62:   headPtr   := headPtrNext\n63:   headPtrOH := headPtrOHNext\n64: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/MEFreeList.scala
    lines: 77-88
    context: "77:   tailPtr := tailPtrNext\n78: \n79:   val freeRegCnt = Mux(doWalkRename
      && !lastCycleRedirect, distanceBetween(tailPtrNext, headPtr) - PopCount(io.walkReq),\n\
      80:                    Mux(doNormalRename,                     distanceBetween(tailPtrNext,
      headPtr) - PopCount(io.allocateReq),\n81:                                  \
      \                          distanceBetween(tailPtrNext, headPtr)))\n82:   val
      freeRegCntReg = RegNext(freeRegCnt)\n83:   io.canAllocate := freeRegCntReg >=
      RenameWidth.U\n84: \n85:   if(backendParams.debugEn){\n86:     val debugArchHeadPtr
      = RegNext(RegNext(archHeadPtr, FreeListPtr(false, 0)), FreeListPtr(false, 0))
      // two-cycle delay from refCounter\n87:     val debugArchRAT = RegNext(RegNext(io.debug_rat.get,
      VecInit(Seq.fill(32)(0.U(PhyRegIdxWidth.W)))), VecInit(Seq.fill(32)(0.U(PhyRegIdxWidth.W))))\n\
      88:     val debugUniqPR = Seq.tabulate(32)(i => i match {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/MEFreeList.scala
    lines: 87-100
    context: "87:     val debugArchRAT = RegNext(RegNext(io.debug_rat.get, VecInit(Seq.fill(32)(0.U(PhyRegIdxWidth.W)))),
      VecInit(Seq.fill(32)(0.U(PhyRegIdxWidth.W))))\n88:     val debugUniqPR = Seq.tabulate(32)(i
      => i match {\n89:       case 0 => true.B\n90:       case _ => !debugArchRAT.take(i).map(_
      === debugArchRAT(i)).reduce(_ || _)\n91:     })\n92:     XSError(distanceBetween(tailPtr,
      debugArchHeadPtr) +& PopCount(debugUniqPR) =/= size.U, \"Integer physical register
      should be in either arch RAT or arch free list\\n\")\n93:   }\n94: \n95:   QueuePerf(size
      = size, utilization = freeRegCntReg, full = freeRegCntReg === 0.U)\n96: \n97:\
      \   XSPerfAccumulate(\"allocation_blocked_cycle\", !io.canAllocate)\n98:   XSPerfAccumulate(\"\
      can_alloc_wrong\", !io.canAllocate && freeRegCnt >= RenameWidth.U)\n99: \n100:\
      \   val perfEvents = Seq("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/MEFreeList.scala
    lines: 96-107
    context: "96: \n97:   XSPerfAccumulate(\"allocation_blocked_cycle\", !io.canAllocate)\n\
      98:   XSPerfAccumulate(\"can_alloc_wrong\", !io.canAllocate && freeRegCnt >=
      RenameWidth.U)\n99: \n100:   val perfEvents = Seq(\n101:     (\"me_freelist_1_4_valid\"\
      , freeRegCntReg <  (size / 4).U                                     ),\n102:\
      \     (\"me_freelist_2_4_valid\", freeRegCntReg >= (size / 4).U && freeRegCntReg
      <= (size / 2).U    ),\n103:     (\"me_freelist_3_4_valid\", freeRegCntReg >=
      (size / 2).U && freeRegCntReg <= (size * 3 / 4).U),\n104:     (\"me_freelist_4_4_valid\"\
      , freeRegCntReg >= (size * 3 / 4).U                                 ),\n105:\
      \   )\n106:   generatePerfEvent()\n107: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/StdFreeList.scala
    lines: 27-37
    context: "27: \n28: class StdFreeList(freeListSize: Int, numLogicRegs: Int, regType:
      RegType, realNumLogicRegs: Int = 32)(implicit p: Parameters) extends BaseFreeList(freeListSize,
      realNumLogicRegs) with HasPerfEvents {\n29: \n30:   val freeList = RegInit(VecInit(Seq.tabulate(freeListSize)(
      i => (i + numLogicRegs).U(PhyRegIdxWidth.W) )))\n31:   val lastTailPtr = RegInit(FreeListPtr(true,
      0)) // tailPtr in the last cycle (need to add freeReqReg)\n32:   val tailPtr
      = Wire(new FreeListPtr) // this is the real tailPtr\n33:   val tailPtrOHReg
      = RegInit(0.U(freeListSize.W))\n34: \n35:   //\n36:   // free committed instructions'
      `old_pdest` reg\n37:   //"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/StdFreeList.scala
    lines: 44-54
    context: "44:     // Why we can RegNext: these free registers won't be used in
      the next cycle,\n45:     // since we set canAllocate only when the current free
      regs > RenameWidth.\n46:     when (freeReqReg(i)) {\n47:       freeList(enqPtr.value)
      := io.freePhyReg(i)\n48:     }\n49:     XSDebug(io.freeReq(i), p\"req#$i free
      physical reg: ${io.freePhyReg(i)}\\n\")\n50:   }\n51: \n52:   tailPtr := lastTailPtr
      + PopCount(freeReqReg)\n53:   lastTailPtr := tailPtr\n54: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/StdFreeList.scala
    lines: 53-63
    context: "53:   lastTailPtr := tailPtr\n54: \n55:   //\n56:   // allocate new
      physical registers for instructions at rename stage\n57:   //\n58:   val freeRegCnt
      = Wire(UInt()) // number of free registers in free list\n59:   io.canAllocate
      := GatedValidRegNext(freeRegCnt >= RenameWidth.U) // use RegNext for better
      timing\n60:   XSDebug(p\"freeRegCnt: $freeRegCnt\\n\")\n61: \n62:   val phyRegCandidates
      = VecInit(headPtrOHVec.map(sel => Mux1H(sel, freeList)))\n63: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/StdFreeList.scala
    lines: 63-74
    context: "63: \n64:   for(i <- 0 until RenameWidth) {\n65:     io.allocatePhyReg(i)
      := phyRegCandidates(PopCount(io.allocateReq.take(i)))\n66:     XSDebug(p\"req:${io.allocateReq(i)}
      canAllocate:${io.canAllocate} pdest:${io.allocatePhyReg(i)}\\n\")\n67:   }\n\
      68:   val doCommit = io.commit.isCommit\n69:   val archAlloc = io.commit.commitValid
      zip io.commit.info map { case (valid, info) =>\n70:     valid && (regType match
      {\n71:       case Reg_F => info.fpWen\n72:       case Reg_V => info.vecWen\n\
      73:       case Reg_V0 => info.v0Wen\n74:       case Reg_Vl => info.vlWen"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/StdFreeList.scala
    lines: 74-84
    context: "74:       case Reg_Vl => info.vlWen\n75:     })\n76:   }\n77:   val
      numArchAllocate = PopCount(archAlloc)\n78:   val archHeadPtrNew  = archHeadPtr
      + numArchAllocate\n79:   val archHeadPtrNext = Mux(doCommit, archHeadPtrNew,
      archHeadPtr)\n80:   archHeadPtr := archHeadPtrNext\n81: \n82:   val isWalkAlloc
      = io.walk && io.doAllocate\n83:   val isNormalAlloc = io.canAllocate && io.doAllocate\n\
      84:   val isAllocate = isWalkAlloc || isNormalAlloc"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/StdFreeList.scala
    lines: 81-92
    context: "81: \n82:   val isWalkAlloc = io.walk && io.doAllocate\n83:   val isNormalAlloc
      = io.canAllocate && io.doAllocate\n84:   val isAllocate = isWalkAlloc || isNormalAlloc\n\
      85:   val numAllocate = Mux(io.walk, PopCount(io.walkReq), PopCount(io.allocateReq))\n\
      86:   val headPtrAllocate = Mux(lastCycleRedirect, redirectedHeadPtr, headPtr
      + numAllocate)\n87:   val headPtrOHAllocate = Mux(lastCycleRedirect, redirectedHeadPtrOH,
      headPtrOHVec(numAllocate))\n88:   val headPtrNext = Mux(isAllocate, headPtrAllocate,
      headPtr)\n89:   freeRegCnt := Mux(isWalkAlloc && !lastCycleRedirect, distanceBetween(tailPtr,
      headPtr) - PopCount(io.walkReq),\n90:                 Mux(isNormalAlloc,   \
      \                  distanceBetween(tailPtr, headPtr) - PopCount(io.allocateReq),\n\
      91:                                                        distanceBetween(tailPtr,
      headPtr)))\n92: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/StdFreeList.scala
    lines: 89-103
    context: "89:   freeRegCnt := Mux(isWalkAlloc && !lastCycleRedirect, distanceBetween(tailPtr,
      headPtr) - PopCount(io.walkReq),\n90:                 Mux(isNormalAlloc,   \
      \                  distanceBetween(tailPtr, headPtr) - PopCount(io.allocateReq),\n\
      91:                                                        distanceBetween(tailPtr,
      headPtr)))\n92: \n93:   // priority: (1) exception and flushPipe; (2) walking;
      (3) mis-prediction; (4) normal dequeue\n94:   val realDoAllocate = !io.redirect
      && isAllocate\n95:   headPtr := Mux(realDoAllocate, headPtrAllocate, headPtr)\n\
      96:   headPtrOH := Mux(realDoAllocate, headPtrOHAllocate, headPtrOH)\n97: \n\
      98:   XSDebug(p\"head:$headPtr tail:$tailPtr\\n\")\n99: \n100:   XSError(!isFull(tailPtr,
      archHeadPtr), s\"${regType}ArchFreeList should always be full\\n\")\n101: \n\
      102:   val enableFreeListCheck = false\n103:   if (enableFreeListCheck) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/StdFreeList.scala
    lines: 101-111
    context: "101: \n102:   val enableFreeListCheck = false\n103:   if (enableFreeListCheck)
      {\n104:     for (i <- 0 until freeListSize) {\n105:       for (j <- i+1 until
      freeListSize) {\n106:         XSError(freeList(i) === freeList(j), s\"Found
      same entry in free list! (i=$i j=$j)\\n\")\n107:       }\n108:     }\n109: \
      \  }\n110: \n111:   XSPerfAccumulate(\"utilization\", PopCount(io.allocateReq))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/StdFreeList.scala
    lines: 110-126
    context: "110: \n111:   XSPerfAccumulate(\"utilization\", PopCount(io.allocateReq))\n\
      112:   XSPerfAccumulate(\"allocation_blocked_cycle\", !io.canAllocate)\n113:\
      \   XSPerfAccumulate(\"can_alloc_wrong\", !io.canAllocate && freeRegCnt >= RenameWidth.U)\n\
      114: \n115:   val freeRegCntReg = RegNext(freeRegCnt)\n116:   val perfEvents
      = Seq(\n117:     (\"std_freelist_1_4_valid\", freeRegCntReg <  (freeListSize
      / 4).U                                            ),\n118:     (\"std_freelist_2_4_valid\"\
      , freeRegCntReg >= (freeListSize / 4).U && freeRegCntReg < (freeListSize / 2).U\
      \    ),\n119:     (\"std_freelist_3_4_valid\", freeRegCntReg >= (freeListSize
      / 2).U && freeRegCntReg < (freeListSize * 3 / 4).U),\n120:     (\"std_freelist_4_4_valid\"\
      , freeRegCntReg >= (freeListSize * 3 / 4).U                                \
      \        )\n121:   )\n122: \n123:   QueuePerf(size = freeListSize, utilization
      = freeRegCntReg, full = freeRegCntReg === 0.U)\n124: \n125:   generatePerfEvent()\n\
      126: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 45-55
    context: "45:   private val numVecRatPorts = numVecRegSrc\n46: \n47:   println(s\"\
      [Rename] numRegSrc: $numRegSrc\")\n48: \n49:   val io = IO(new Bundle() {\n\
      50:     val redirect = Flipped(ValidIO(new Redirect))\n51:     val rabCommits
      = Input(new RabCommitIO)\n52:     // from csr\n53:     val singleStep = Input(Bool())\n\
      54:     // from decode\n55:     val in = Vec(RenameWidth, Flipped(DecoupledIO(new
      DecodedInst)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 98-108
    context: "98:   io.in.zipWithIndex.map { case (o, i) =>\n99:     PerfCCT.updateInstPos(o.bits.debug_seqNum,
      PerfCCT.InstPos.AtRename.id.U, o.valid, clock, reset)\n100:   }\n101: \n102:\
      \   // io alias\n103:   private val dispatchCanAcc = io.out.head.ready\n104:\
      \ \n105:   val compressUnit = Module(new CompressUnit())\n106:   // create free
      list and rat\n107:   val intFreeList = Module(new MEFreeList(IntPhyRegs))\n\
      108:   val fpFreeList = Module(new StdFreeList(FpPhyRegs - FpLogicRegs, FpLogicRegs,
      Reg_F))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 109-128
    context: "109:   val vecFreeList = Module(new StdFreeList(VfPhyRegs - VecLogicRegs,
      VecLogicRegs, Reg_V, 31))\n110:   val v0FreeList = Module(new StdFreeList(V0PhyRegs
      - V0LogicRegs, V0LogicRegs, Reg_V0, 1))\n111:   val vlFreeList = Module(new
      StdFreeList(VlPhyRegs - VlLogicRegs, VlLogicRegs, Reg_Vl, 1))\n112: \n113: \n\
      114:   intFreeList.io.commit    <> io.rabCommits\n115:   intFreeList.io.debug_rat.foreach(_
      <> io.debug_int_rat.get)\n116:   fpFreeList.io.commit     <> io.rabCommits\n\
      117:   fpFreeList.io.debug_rat.foreach(_ <> io.debug_fp_rat.get)\n118:   vecFreeList.io.commit\
      \    <> io.rabCommits\n119:   vecFreeList.io.debug_rat.foreach(_ <> io.debug_vec_rat.get)\n\
      120:   v0FreeList.io.commit <> io.rabCommits\n121:   v0FreeList.io.debug_rat.foreach(_
      <> io.debug_v0_rat.get)\n122:   vlFreeList.io.commit <> io.rabCommits\n123:\
      \   vlFreeList.io.debug_rat.foreach(_ <> io.debug_vl_rat.get)\n124: \n125: \
      \  // decide if given instruction needs allocating a new physical register (CfCtrl:
      from decode; RobCommitInfo: from rob)\n126:   def needDestReg[T <: DecodedInst](reg_t:
      RegType, x: T): Bool = reg_t match {\n127:     case Reg_I => x.rfWen\n128: \
      \    case Reg_F => x.fpWen"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 148-159
    context: "148:       case Reg_Vl => x.vlWen\n149:     }\n150:   }\n151: \n152:\
      \   // connect [redirect + walk] ports for fp & vec & int free list\n153:  \
      \ Seq(fpFreeList, vecFreeList, intFreeList, v0FreeList, vlFreeList).foreach
      { case fl =>\n154:     fl.io.redirect := io.redirect.valid\n155:     fl.io.walk
      := io.rabCommits.isWalk\n156:   }\n157:   // only when all free list and dispatch1
      has enough space can we do allocation\n158:   // when isWalk, freelist can definitely
      allocate\n159:   intFreeList.io.doAllocate := fpFreeList.io.canAllocate && vecFreeList.io.canAllocate
      && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate && dispatchCanAcc
      || io.rabCommits.isWalk"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 163-173
    context: "163:   vlFreeList.io.doAllocate := intFreeList.io.canAllocate && fpFreeList.io.canAllocate
      && vecFreeList.io.canAllocate && v0FreeList.io.canAllocate && dispatchCanAcc
      || io.rabCommits.isWalk\n164: \n165:   //           dispatch1 ready ++ float
      point free list ready ++ int free list ready ++ vec free list ready     ++ not
      walk\n166:   val canOut = dispatchCanAcc && fpFreeList.io.canAllocate && intFreeList.io.canAllocate
      && vecFreeList.io.canAllocate && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate
      && !io.rabCommits.isWalk\n167: \n168:   compressUnit.io.in.zip(io.in).foreach{
      case(sink, source) =>\n169:     sink.valid := source.valid && !io.singleStep\n\
      170:     sink.bits := source.bits\n171:   }\n172:   val needRobFlags = compressUnit.io.out.needRobFlags\n\
      173:   val instrSizesVec = compressUnit.io.out.instrSizes"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 174-186
    context: "174:   val compressMasksVec = compressUnit.io.out.masks\n175: \n176:\
      \   // speculatively assign the instruction with an robIdx\n177:   val validCount
      = PopCount(io.in.zip(needRobFlags).map{ case(in, needRobFlag) => in.valid &&
      in.bits.lastUop && needRobFlag}) // number of instructions waiting to enter
      rob (from decode)\n178:   val robIdxHead = RegInit(0.U.asTypeOf(new RobPtr))\n\
      179:   val lastCycleMisprediction = GatedValidRegNext(io.redirect.valid && !io.redirect.bits.flushItself())\n\
      180:   val robIdxHeadNext = Mux(io.redirect.valid, io.redirect.bits.robIdx,
      // redirect: move ptr to given rob index\n181:          Mux(lastCycleMisprediction,
      robIdxHead + 1.U, // mis-predict: not flush robIdx itself\n182:            Mux(canOut,
      robIdxHead + validCount, // instructions successfully entered next stage: increase
      robIdx\n183:                       /* default */  robIdxHead))) // no instructions
      passed by this cycle: stick to old value\n184:   robIdxHead := robIdxHeadNext\n\
      185: \n186:   /**"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 185-195
    context: "185: \n186:   /**\n187:     * Rename: allocate free physical register
      and update rename table\n188:     */\n189:   val uops = Wire(Vec(RenameWidth,
      new DynInst))\n190:   uops.foreach( uop => {\n191:     uop.srcState      :=
      DontCare\n192:     uop.debugInfo     := DontCare\n193:     uop.lqIdx       \
      \  := DontCare\n194:     uop.sqIdx         := DontCare\n195:     uop.waitForRobIdx
      := DontCare"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 253-266
    context: "253:   val needVecDest    = Wire(Vec(RenameWidth, Bool()))\n254:   val
      needFpDest     = Wire(Vec(RenameWidth, Bool()))\n255:   val needIntDest    =
      Wire(Vec(RenameWidth, Bool()))\n256:   val needV0Dest     = Wire(Vec(RenameWidth,
      Bool()))\n257:   val needVlDest     = Wire(Vec(RenameWidth, Bool()))\n258: \
      \  private val inHeadValid = io.in.head.valid\n259: \n260:   val isMove = Wire(Vec(RenameWidth,
      Bool()))\n261:   isMove zip io.in.map(_.bits) foreach {\n262:     case (move,
      in) => move := Mux(in.exceptionVec.asUInt.orR, false.B, in.isMove)\n263:   }\n\
      264: \n265:   val walkNeedIntDest = WireDefault(VecInit(Seq.fill(RenameWidth)(false.B)))\n\
      266:   val walkNeedFpDest = WireDefault(VecInit(Seq.fill(RenameWidth)(false.B)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 277-287
    context: "277: \n278:   val walkIntSpecWen = WireDefault(VecInit(Seq.fill(RenameWidth)(false.B)))\n\
      279: \n280:   val walkPdest = Wire(Vec(RenameWidth, UInt(PhyRegIdxWidth.W)))\n\
      281: \n282:   io.out.zipWithIndex.foreach{ case (o, i) =>\n283:     o.bits.debug_seqNum
      := io.in(i).bits.debug_seqNum\n284:   }\n285: \n286:   // uop calculation\n\
      287:   for (i <- 0 until RenameWidth) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 320-334
    context: "320:     needVlDest(i) := io.in(i).valid && needDestReg(Reg_Vl, io.in(i).bits)\n\
      321:     needVecDest(i) := io.in(i).valid && needDestReg(Reg_V, io.in(i).bits)\n\
      322:     needFpDest(i) := io.in(i).valid && needDestReg(Reg_F, io.in(i).bits)\n\
      323:     needIntDest(i) := io.in(i).valid && needDestReg(Reg_I, io.in(i).bits)\n\
      324:     if (i < RabCommitWidth) {\n325:       walkNeedIntDest(i) := io.rabCommits.walkValid(i)
      && needDestRegWalk(Reg_I, io.rabCommits.info(i))\n326:       walkNeedFpDest(i)
      := io.rabCommits.walkValid(i) && needDestRegWalk(Reg_F, io.rabCommits.info(i))\n\
      327:       walkNeedVecDest(i) := io.rabCommits.walkValid(i) && needDestRegWalk(Reg_V,
      io.rabCommits.info(i))\n328:       walkNeedV0Dest(i) := io.rabCommits.walkValid(i)
      && needDestRegWalk(Reg_V0, io.rabCommits.info(i))\n329:       walkNeedVlDest(i)
      := io.rabCommits.walkValid(i) && needDestRegWalk(Reg_Vl, io.rabCommits.info(i))\n\
      330:       walkIsMove(i) := io.rabCommits.info(i).isMove\n331:     }\n332: \
      \    fpFreeList.io.allocateReq(i) := needFpDest(i)\n333:     fpFreeList.io.walkReq(i)
      := walkNeedFpDest(i)\n334:     vecFreeList.io.allocateReq(i) := needVecDest(i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 339-349
    context: "339:     vlFreeList.io.walkReq(i) := walkNeedVlDest(i)\n340:     intFreeList.io.allocateReq(i)
      := needIntDest(i) && !isMove(i)\n341:     intFreeList.io.walkReq(i) := walkNeedIntDest(i)
      && !walkIsMove(i)\n342: \n343:     // no valid instruction from decode stage
      || all resources (dispatch1 + both free lists) ready\n344:     io.in(i).ready
      := !io.in(0).valid || canOut\n345: \n346:     uops(i).robIdx := robIdxHead +
      PopCount(io.in.zip(needRobFlags).take(i).map{ case(in, needRobFlag) => in.valid
      && in.bits.lastUop && needRobFlag})\n347:     uops(i).instrSize := instrSizesVec(i)\n\
      348:     val hasExceptionExceptFlushPipe = Cat(selectFrontend(uops(i).exceptionVec)
      :+ uops(i).exceptionVec(illegalInstr) :+ uops(i).exceptionVec(virtualInstr)).orR
      || TriggerAction.isDmode(uops(i).trigger)\n349:     when(isMove(i) || hasExceptionExceptFlushPipe)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 362-372
    context: "362:     when(!needRobFlags(i)) {\n363:       uops(i).lastUop := false.B\n\
      364:       uops(i).numUops := instrSizesVec(i) - PopCount(compressMasksVec(i)
      & Cat(isMove.reverse))\n365:       uops(i).numWB := instrSizesVec(i) - PopCount(compressMasksVec(i)
      & Cat(isMove.reverse))\n366:     }\n367:     uops(i).wfflags := (compressMasksVec(i)
      & Cat(io.in.map(_.bits.wfflags).reverse)).orR\n368:     uops(i).dirtyFs := (compressMasksVec(i)
      & Cat(io.in.map(_.bits.fpWen).reverse)).orR\n369:     uops(i).dirtyVs := (\n\
      370:       compressMasksVec(i) & Cat(io.in.map(in =>\n371:         // vector
      instructions' uopSplitType cannot be UopSplitType.SCA_SIM\n372:         in.bits.uopSplitType
      =/= UopSplitType.SCA_SIM &&"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 378-388
    context: "378:           (FuType.vipu, VipuType.vfirst_m),   // vfirst.m\n379:\
      \           (FuType.vipu, VipuType.vmv_x_s)     // vmv.x.s\n380:         ).map(x
      => FuTypeOrR(in.bits.fuType, x._1) && in.bits.fuOpType === x._2).reduce(_ ||
      _)\n381:       ).reverse)\n382:     ).orR\n383:     uops(i).debug_sim_trig.foreach(_
      := (compressMasksVec(i) & Cat(io.in.map(_.bits.instr === XSDebugDecode.SIM_TRIG).reverse)).orR)\n\
      384:     // psrc0,psrc1,psrc2 don't require v0ReadPorts because their srcType
      can distinguish whether they are V0 or not\n385:     uops(i).psrc(0) := Mux1H(uops(i).srcType(0)(2,
      0), Seq(io.intReadPorts(i)(0), io.fpReadPorts(i)(0), io.vecReadPorts(i)(0)))\n\
      386:     uops(i).psrc(1) := Mux1H(uops(i).srcType(1)(2, 0), Seq(io.intReadPorts(i)(1),
      io.fpReadPorts(i)(1), io.vecReadPorts(i)(1)))\n387:     uops(i).psrc(2) := Mux1H(uops(i).srcType(2)(2,
      1), Seq(io.fpReadPorts(i)(2), io.vecReadPorts(i)(2)))\n388:     uops(i).psrc(3)
      := io.v0ReadPorts(i)(0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 442-460
    context: "442:       }\n443:     }\n444: \n445:     // write speculative rename
      table\n446:     // we update rat later inside commit code\n447:     intSpecWen(i)
      := needIntDest(i) && intFreeList.io.canAllocate && intFreeList.io.doAllocate
      && !io.rabCommits.isWalk && !io.redirect.valid\n448:     fpSpecWen(i)  := needFpDest(i)\
      \  && fpFreeList.io.canAllocate  && fpFreeList.io.doAllocate  && !io.rabCommits.isWalk
      && !io.redirect.valid\n449:     vecSpecWen(i) := needVecDest(i) && vecFreeList.io.canAllocate
      && vecFreeList.io.doAllocate && !io.rabCommits.isWalk && !io.redirect.valid\n\
      450:     v0SpecWen(i) := needV0Dest(i) && v0FreeList.io.canAllocate && v0FreeList.io.doAllocate
      && !io.rabCommits.isWalk && !io.redirect.valid\n451:     vlSpecWen(i) := needVlDest(i)
      && vlFreeList.io.canAllocate && vlFreeList.io.doAllocate && !io.rabCommits.isWalk
      && !io.redirect.valid\n452: \n453: \n454:     if (i < RabCommitWidth) {\n455:\
      \       walkIntSpecWen(i) := walkNeedIntDest(i) && !io.redirect.valid\n456:\
      \       walkPdest(i) := io.rabCommits.info(i).pdest\n457:     } else {\n458:\
      \       walkPdest(i) := io.out(i).bits.pdest\n459:     }\n460:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 463-473
    context: "463:    * trace begin\n464:    */\n465:   // note: fusionInst can't
      robcompress\n466:   val inVec = io.in.map(_.bits)\n467:   val isRVCVec = inVec.map(_.preDecodeInfo.isRVC)\n\
      468:   val isFusionVec = inVec.map(_.commitType).map(ctype => CommitType.isFused(ctype))\n\
      469: \n470:   val canRobCompressVec = compressUnit.io.out.canCompressVec\n471:\
      \   val iLastSizeVec = isRVCVec.map(isRVC => Mux(isRVC, Ilastsize.HalfWord,
      Ilastsize.Word))\n472:   val halfWordNumVec = isRVCVec.map(isRVC => Mux(isRVC,
      1.U, 2.U))\n473:   val halfWordNumMatrix = (0 until RenameWidth).map("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 476-486
    context: "476:     }\n477:   )\n478: \n479:   for (i <- 0 until RenameWidth) {\n\
      480:     // iretire\n481:     uops(i).traceBlockInPipe.iretire := Mux(canRobCompressVec(i),\n\
      482:       halfWordNumMatrix(i).reduce(_ +& _),\n483:       (if(i < RenameWidth
      -1) Mux(isFusionVec(i), halfWordNumVec(i+1), 0.U) else 0.U) +& halfWordNumVec(i)\n\
      484:     )\n485: \n486:     // ilastsize"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 528-543
    context: "528:     *                           Mux(bypass(N, 0),     pdest(0),\n\
      529:     *                                                 rat_out(N))...)),\n\
      530:     *                           freelist_out(N))\n531:     */\n532:   //
      a simple functional model for now\n533:   io.out(0).bits.pdest := Mux(isMove(0),
      uops(0).psrc.head, uops(0).pdest)\n534: \n535:   // psrc(n) + pdest(1)\n536:\
      \   val bypassCond: Vec[MixedVec[UInt]] = Wire(Vec(numRegSrc, MixedVec(List.tabulate(RenameWidth-1)(i
      => UInt((i+1).W)))))\n537:   require(io.in(0).bits.srcType.size == io.in(0).bits.numSrc)\n\
      538:   private val pdestLoc = io.in.head.bits.srcType.size // 2 vector src:
      v0, vl&vtype\n539:   println(s\"[Rename] idx of pdest in bypassCond $pdestLoc\"\
      )\n540:   for (i <- 1 until RenameWidth) {\n541:     val v0Cond = io.in(i).bits.srcType.zipWithIndex.map{
      case (s, i) =>\n542:       if (i == 3) (s === SrcType.vp) || (s === SrcType.v0)\n\
      543:       else false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 592-602
    context: "592:       io.out(i).bits.imm := Cat(lui_imm, ld_imm)\n593:     }\n\
      594: \n595:   }\n596: \n597:   val genSnapshot = Cat(io.out.map(out => out.fire
      && out.bits.snapshot)).orR\n598:   val lastCycleCreateSnpt = RegInit(false.B)\n\
      599:   lastCycleCreateSnpt := genSnapshot && !io.snptIsFull\n600:   val sameSnptDistance
      = (RobCommitWidth * 4).U\n601:   // notInSameSnpt: 1.robidxHead - snapLastEnq
      >= sameSnptDistance 2.no snap\n602:   val notInSameSnpt = GatedValidRegNext(distanceBetween(robIdxHeadNext,
      io.snptLastEnq.bits) >= sameSnptDistance || !io.snptLastEnq.valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 598-609
    context: "598:   val lastCycleCreateSnpt = RegInit(false.B)\n599:   lastCycleCreateSnpt
      := genSnapshot && !io.snptIsFull\n600:   val sameSnptDistance = (RobCommitWidth
      * 4).U\n601:   // notInSameSnpt: 1.robidxHead - snapLastEnq >= sameSnptDistance
      2.no snap\n602:   val notInSameSnpt = GatedValidRegNext(distanceBetween(robIdxHeadNext,
      io.snptLastEnq.bits) >= sameSnptDistance || !io.snptLastEnq.valid)\n603:   val
      allowSnpt = if (EnableRenameSnapshot) notInSameSnpt && !lastCycleCreateSnpt
      && io.in.head.bits.firstUop else false.B\n604:   io.out.zip(io.in).foreach{
      case (out, in) => out.bits.snapshot := allowSnpt && (!in.bits.preDecodeInfo.notCFI
      || FuType.isJump(in.bits.fuType)) && in.fire }\n605:   io.out.map{ x =>\n606:\
      \     x.bits.hasException := Cat(selectFrontend(x.bits.exceptionVec) :+ x.bits.exceptionVec(illegalInstr)
      :+ x.bits.exceptionVec(virtualInstr)).orR || TriggerAction.isDmode(x.bits.trigger)\n\
      607:   }\n608:   if(backendParams.debugEn){\n609:     dontTouch(robIdxHeadNext)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 623-634
    context: "623: \n624:   /**\n625:     * Instructions commit: update freelist and
      rename table\n626:     */\n627:   for (i <- 0 until RabCommitWidth) {\n628:\
      \     val commitValid = io.rabCommits.isCommit && io.rabCommits.commitValid(i)\n\
      629:     val walkValid = io.rabCommits.isWalk && io.rabCommits.walkValid(i)\n\
      630: \n631:     // I. RAT Update\n632:     // When redirect happens (mis-prediction),
      don't update the rename table\n633:     io.intRenamePorts(i).wen  := intSpecWen(i)\n\
      634:     io.intRenamePorts(i).addr := uops(i).ldest(log2Ceil(IntLogicRegs) -
      1, 0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 665-675
    context: "665: \n666:   /*\n667:   Debug and performance counters\n668:    */\n\
      669:   def printRenameInfo(in: DecoupledIO[DecodedInst], out: DecoupledIO[DynInst])
      = {\n670:     XSInfo(out.fire, p\"pc:${Hexadecimal(in.bits.pc)} in(${in.valid},${in.ready})
      \" +\n671:       p\"lsrc(0):${in.bits.lsrc(0)} -> psrc(0):${out.bits.psrc(0)}
      \" +\n672:       p\"lsrc(1):${in.bits.lsrc(1)} -> psrc(1):${out.bits.psrc(1)}
      \" +\n673:       p\"lsrc(2):${in.bits.lsrc(2)} -> psrc(2):${out.bits.psrc(2)}
      \" +\n674:       p\"ldest:${in.bits.ldest} -> pdest:${out.bits.pdest}\\n\"\n\
      675:     )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 682-696
    context: "682:   io.out.map { case x =>\n683:     when(x.valid && x.bits.rfWen){\n\
      684:       assert(x.bits.ldest =/= 0.U, \"rfWen cannot be 1 when Int regfile
      ldest is 0\")\n685:     }\n686:   }\n687:   val debugRedirect = RegEnable(io.redirect.bits,
      io.redirect.valid)\n688:   // bad speculation\n689:   val recStall = io.redirect.valid
      || io.rabCommits.isWalk\n690:   val ctrlRecStall = Mux(io.redirect.valid, io.redirect.bits.debugIsCtrl,
      io.rabCommits.isWalk && debugRedirect.debugIsCtrl)\n691:   val mvioRecStall
      = Mux(io.redirect.valid, io.redirect.bits.debugIsMemVio, io.rabCommits.isWalk
      && debugRedirect.debugIsMemVio)\n692:   val otherRecStall = recStall && !(ctrlRecStall
      || mvioRecStall)\n693:   XSPerfAccumulate(\"recovery_stall\", recStall)\n694:\
      \   XSPerfAccumulate(\"control_recovery_stall\", ctrlRecStall)\n695:   XSPerfAccumulate(\"\
      mem_violation_recovery_stall\", mvioRecStall)\n696:   XSPerfAccumulate(\"other_recovery_stall\"\
      , otherRecStall)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 693-708
    context: "693:   XSPerfAccumulate(\"recovery_stall\", recStall)\n694:   XSPerfAccumulate(\"\
      control_recovery_stall\", ctrlRecStall)\n695:   XSPerfAccumulate(\"mem_violation_recovery_stall\"\
      , mvioRecStall)\n696:   XSPerfAccumulate(\"other_recovery_stall\", otherRecStall)\n\
      697:   // freelist stall\n698:   val notRecStall = !io.out.head.valid && !recStall\n\
      699:   val intFlStall = notRecStall && inHeadValid && fpFreeList.io.canAllocate
      && vecFreeList.io.canAllocate && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate
      && !intFreeList.io.canAllocate\n700:   val fpFlStall = notRecStall && inHeadValid
      && intFreeList.io.canAllocate && vecFreeList.io.canAllocate && v0FreeList.io.canAllocate
      && vlFreeList.io.canAllocate && !fpFreeList.io.canAllocate\n701:   val vecFlStall
      = notRecStall && inHeadValid && intFreeList.io.canAllocate && fpFreeList.io.canAllocate
      && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate && !vecFreeList.io.canAllocate\n\
      702:   val v0FlStall = notRecStall && inHeadValid && intFreeList.io.canAllocate
      && fpFreeList.io.canAllocate && vecFreeList.io.canAllocate && vlFreeList.io.canAllocate
      && !v0FreeList.io.canAllocate\n703:   val vlFlStall = notRecStall && inHeadValid
      && intFreeList.io.canAllocate && fpFreeList.io.canAllocate && vecFreeList.io.canAllocate
      && v0FreeList.io.canAllocate && !vlFreeList.io.canAllocate\n704:   val multiFlStall
      = notRecStall && inHeadValid && (PopCount(Cat(\n705:     !intFreeList.io.canAllocate,\n\
      706:     !fpFreeList.io.canAllocate,\n707:     !vecFreeList.io.canAllocate,\n\
      708:     !v0FreeList.io.canAllocate,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 707-719
    context: "707:     !vecFreeList.io.canAllocate,\n708:     !v0FreeList.io.canAllocate,\n\
      709:     !vlFreeList.io.canAllocate,\n710:   )) > 1.U)\n711:   // other stall\n\
      712:   val otherStall = notRecStall && !intFlStall && !fpFlStall && !vecFlStall
      && !v0FlStall && !vlFlStall && !multiFlStall\n713: \n714:   io.stallReason.in.backReason.valid
      := io.stallReason.out.backReason.valid || !io.in.head.ready\n715:   io.stallReason.in.backReason.bits
      := Mux(io.stallReason.out.backReason.valid, io.stallReason.out.backReason.bits,\n\
      716:     MuxCase(TopDownCounters.OtherCoreStall.id.U, Seq(\n717:       ctrlRecStall\
      \  -> TopDownCounters.ControlRecoveryStall.id.U,\n718:       mvioRecStall  ->
      TopDownCounters.MemVioRecoveryStall.id.U,\n719:       otherRecStall -> TopDownCounters.OtherRecoveryStall.id.U,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 716-741
    context: "716:     MuxCase(TopDownCounters.OtherCoreStall.id.U, Seq(\n717:   \
      \    ctrlRecStall  -> TopDownCounters.ControlRecoveryStall.id.U,\n718:     \
      \  mvioRecStall  -> TopDownCounters.MemVioRecoveryStall.id.U,\n719:       otherRecStall
      -> TopDownCounters.OtherRecoveryStall.id.U,\n720:       intFlStall    -> TopDownCounters.IntFlStall.id.U,\n\
      721:       fpFlStall     -> TopDownCounters.FpFlStall.id.U,\n722:       vecFlStall\
      \    -> TopDownCounters.VecFlStall.id.U,\n723:       v0FlStall     -> TopDownCounters.V0FlStall.id.U,\n\
      724:       vlFlStall     -> TopDownCounters.VlFlStall.id.U,\n725:       multiFlStall\
      \  -> TopDownCounters.MultiFlStall.id.U,\n726:     )\n727:   ))\n728:   io.stallReason.out.reason.zip(io.stallReason.in.reason).zip(io.in.map(_.valid)).foreach
      { case ((out, in), valid) =>\n729:     out := Mux(io.stallReason.in.backReason.valid,
      io.stallReason.in.backReason.bits, in)\n730:   }\n731: \n732:   XSDebug(io.rabCommits.isWalk,
      p\"Walk Recovery Enabled\\n\")\n733:   XSDebug(io.rabCommits.isWalk, p\"validVec:${Binary(io.rabCommits.walkValid.asUInt)}\\\
      n\")\n734:   for (i <- 0 until RabCommitWidth) {\n735:     val info = io.rabCommits.info(i)\n\
      736:     XSDebug(io.rabCommits.isWalk && io.rabCommits.walkValid(i), p\"[#$i
      walk info] \" +\n737:       p\"ldest:${info.ldest} rfWen:${info.rfWen} fpWen:${info.fpWen}
      vecWen:${info.vecWen} v0Wen:${info.v0Wen} vlWen:${info.vlWen}\")\n738:   }\n\
      739: \n740:   XSDebug(p\"inValidVec: ${Binary(Cat(io.in.map(_.valid)))}\\n\"\
      )\n741: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 738-754
    context: "738:   }\n739: \n740:   XSDebug(p\"inValidVec: ${Binary(Cat(io.in.map(_.valid)))}\\\
      n\")\n741: \n742:   XSPerfAccumulate(\"in_valid_count\", PopCount(io.in.map(_.valid)))\n\
      743:   XSPerfAccumulate(\"in_fire_count\", PopCount(io.in.map(_.fire)))\n744:\
      \   XSPerfAccumulate(\"in_valid_not_ready_count\", PopCount(io.in.map(x => x.valid
      && !x.ready)))\n745:   XSPerfAccumulate(\"wait_cycle\", !io.in.head.valid &&
      dispatchCanAcc)\n746: \n747:   // These stall reasons could overlap each other,
      but we configure the priority as fellows.\n748:   // walk stall > dispatch stall
      > int freelist stall > fp freelist stall\n749:   private val inHeadStall = io.in.head
      match { case x => x.valid && !x.ready }\n750:   private val stallForWalk   \
      \   = inHeadValid &&  io.rabCommits.isWalk\n751:   private val stallForDispatch\
      \  = inHeadValid && !io.rabCommits.isWalk && !dispatchCanAcc\n752:   private
      val stallForIntFL     = inHeadValid && !io.rabCommits.isWalk && dispatchCanAcc
      && fpFreeList.io.canAllocate && vecFreeList.io.canAllocate && v0FreeList.io.canAllocate
      && vlFreeList.io.canAllocate && !intFreeList.io.canAllocate\n753:   private
      val stallForFpFL      = inHeadValid && !io.rabCommits.isWalk && dispatchCanAcc
      && intFreeList.io.canAllocate && vecFreeList.io.canAllocate && v0FreeList.io.canAllocate
      && vlFreeList.io.canAllocate && !fpFreeList.io.canAllocate\n754:   private val
      stallForVecFL     = inHeadValid && !io.rabCommits.isWalk && dispatchCanAcc &&
      intFreeList.io.canAllocate && fpFreeList.io.canAllocate && v0FreeList.io.canAllocate
      && vlFreeList.io.canAllocate && !vecFreeList.io.canAllocate"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 762-782
    context: "762:   XSPerfAccumulate(\"stall_cycle_vec\",      stallForVecFL)\n763:\
      \   XSPerfAccumulate(\"stall_cycle_vec\",      stallForV0FL)\n764:   XSPerfAccumulate(\"\
      stall_cycle_vec\",      stallForVlFL)\n765: \n766:   XSPerfHistogram(\"in_valid_range\"\
      ,  PopCount(io.in.map(_.valid)),  true.B, 0, DecodeWidth + 1, 1)\n767:   XSPerfHistogram(\"\
      in_fire_range\",   PopCount(io.in.map(_.fire)),   true.B, 0, DecodeWidth + 1,
      1)\n768:   XSPerfHistogram(\"out_valid_range\", PopCount(io.out.map(_.valid)),
      true.B, 0, DecodeWidth + 1, 1)\n769:   XSPerfHistogram(\"out_fire_range\", \
      \ PopCount(io.out.map(_.fire)),  true.B, 0, DecodeWidth + 1, 1)\n770: \n771:\
      \   XSPerfAccumulate(\"move_instr_count\", PopCount(io.out.map(out => out.fire
      && out.bits.isMove)))\n772:   val is_fused_lui_load = io.out.map(o => o.fire
      && o.bits.fuType === FuType.ldu.U && o.bits.srcType(0) === SrcType.imm)\n773:\
      \   XSPerfAccumulate(\"fused_lui_load_instr_count\", PopCount(is_fused_lui_load))\n\
      774: \n775:   val renamePerf = Seq(\n776:     (\"rename_in                 \
      \ \", PopCount(io.in.map(_.valid & io.in(0).ready ))),\n777:     (\"rename_waitinstr\
      \           \", PopCount((0 until RenameWidth).map(i => io.in(i).valid && !io.in(i).ready))),\n\
      778:     (\"rename_stall               \", inHeadStall),\n779:     (\"rename_stall_cycle_walk\
      \    \", inHeadValid &&  io.rabCommits.isWalk),\n780:     (\"rename_stall_cycle_dispatch\"\
      , inHeadValid && !io.rabCommits.isWalk && !dispatchCanAcc),\n781:     (\"rename_stall_cycle_int\
      \     \", inHeadValid && !io.rabCommits.isWalk && dispatchCanAcc && fpFreeList.io.canAllocate
      && vecFreeList.io.canAllocate && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate
      && !intFreeList.io.canAllocate),\n782:     (\"rename_stall_cycle_fp      \"\
      , inHeadValid && !io.rabCommits.isWalk && dispatchCanAcc && intFreeList.io.canAllocate
      && vecFreeList.io.canAllocate && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate
      && !fpFreeList.io.canAllocate),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/BusyTable.scala
    lines: 53-63
    context: "53:     // cancelFromDatapath\n54:     val og0Cancel = Input(ExuVec())\n\
      55:     // cancelFromMem\n56:     val ldCancel = Vec(backendParams.LdExuCnt,
      Flipped(new LoadCancelIO))\n57:     // read preg state\n58:     val read = Vec(numReadPorts,
      new BusyTableReadIO)\n59:   })\n60: \n61:   val allExuParams = backendParams.allExuParams\n\
      62:   val intBusyTableNeedLoadCancel = allExuParams.map(x =>\n63:     x.needLoadDependency
      && x.writeIntRf && x.iqWakeUpSourcePairs.map(y => y.sink.getExuParam(allExuParams).readIntRf).foldLeft(false)(_
      || _)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/BusyTable.scala
    lines: 112-122
    context: "112:         sink := source << 1\n113:       }\n114:     }\n115:   }\n\
      116: \n117:   wakeupOHVec.zipWithIndex.foreach{ case (wakeupOH, idx) =>\n118:\
      \     val tmp = pregWB match {\n119:       case IntWB(_, _) => wakeUpIn.map(x
      => x.valid && x.bits.rfWen  && UIntToOH(x.bits.pdest)(idx) && !LoadShouldCancel(Some(x.bits.loadDependency),
      loadCancel) && !(x.bits.is0Lat && io.og0Cancel(x.bits.params.exuIdx)))\n120:\
      \       case FpWB(_, _)  => wakeUpIn.map(x => x.valid && x.bits.fpWen  && UIntToOH(x.bits.pdest)(idx)
      && !LoadShouldCancel(Some(x.bits.loadDependency), loadCancel) && !(x.bits.is0Lat
      && io.og0Cancel(x.bits.params.exuIdx)))\n121:       case VfWB(_, _)  => wakeUpIn.map(x
      => x.valid && x.bits.vecWen && UIntToOH(x.bits.pdest)(idx) && !LoadShouldCancel(Some(x.bits.loadDependency),
      loadCancel) && !(x.bits.is0Lat && io.og0Cancel(x.bits.params.exuIdx)))\n122:\
      \       case V0WB(_, _)  => wakeUpIn.map(x => x.valid && x.bits.v0Wen  && UIntToOH(x.bits.pdest)(idx)
      && !LoadShouldCancel(Some(x.bits.loadDependency), loadCancel) && !(x.bits.is0Lat
      && io.og0Cancel(x.bits.params.exuIdx)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/BusyTable.scala
    lines: 128-138
    context: "128:   val wbMask = reqVecToMask(io.wbPregs)\n129:   val allocMask =
      reqVecToMask(io.allocPregs)\n130:   val wakeUpMask = VecInit(wakeupOHVec.map(_.orR).toSeq).asUInt\n\
      131:   val ldCancelMask = loadDependency.map(x => LoadShouldCancel(Some(x),
      loadCancel))\n132: \n133:   loadDependency.zipWithIndex.foreach{ case (ldDp,
      idx) =>\n134:     when(wakeUpMask(idx)) {\n135:       ldDp := (if (wakeUpIn.nonEmpty)
      Mux1H(wakeupOHVec(idx), shiftLoadDependency) else 0.U.asTypeOf(ldDp))\n136:\
      \     }\n137:       .elsewhen(ldDp.map(x => x.orR).reduce(_ | _)) {\n138:  \
      \       ldDp := VecInit(ldDp.map(x => x << 1))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/BusyTable.scala
    lines: 150-162
    context: "150:    */\n151:   val table = VecInit((0 until numPhyPregs).zip(tableUpdate).map{
      case (idx, update) =>\n152:     RegEnable(update, 0.U(1.W), allocMask(idx) ||
      ldCancelMask(idx) || wakeUpMask(idx) || wbMask(idx))\n153:   }).asUInt\n154:\
      \ \n155:   tableUpdate.zipWithIndex.foreach{ case (update, idx) =>\n156:   \
      \  when(wakeUpMask(idx) || wbMask(idx)) {\n157:       update := false.B    \
      \                               //ready\n158:     }\n159:       .elsewhen(allocMask(idx)
      || ldCancelMask(idx)) {\n160:         update := true.B                     \
      \               //busy\n161:         if (idx == 0 && pregWB.isInstanceOf[IntWB])
      {\n162:           // Int RegFile 0 is always ready"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/BusyTable.scala
    lines: 166-178
    context: "166:       .otherwise {\n167:         update := table(idx)\n168:   \
      \    }\n169:   }\n170: \n171:   io.read.foreach{ case res =>\n172:     val readBypass
      = VecInit(io.allocPregs.map(x => x.valid && x.bits === res.req))\n173:     res.resp
      := !(table(res.req) || readBypass.asUInt.orR)\n174:     res.loadDependency :=
      (if (needLoadCancel) loadDependency(res.req) else 0.U.asTypeOf(res.loadDependency))\n\
      175:   }\n176: \n177:   val oddTable = table.asBools.zipWithIndex.filter(_._2
      % 2 == 1).map(_._1)\n178:   val evenTable = table.asBools.zipWithIndex.filter(_._2
      % 2 == 0).map(_._1)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/BusyTable.scala
    lines: 221-231
    context: "221:   val vlmaxTable = VecInit((0 until numPhyPregs).zip(vlmaxTableUpdate).map{
      case (idx, update) =>\n222:     RegEnable(update, 0.U(1.W), allocMask(idx) ||
      ldCancelMask(idx) || intVlWb(idx) || vfVlWb(idx) || otherPortsWb(idx))\n223:\
      \   }).asUInt\n224: \n225: \n226:   nonzeroTableUpdate.zipWithIndex.foreach{
      case (update, idx) =>\n227:     when(intVlWb(idx)) {\n228:       // int schd
      vl write back, check whether the vl is zero\n229:       update := io_vl_Wb.vlWriteBackInfo.vlFromIntIsZero\n\
      230:     }.elsewhen(vfVlWb(idx)) {\n231:       // vf schd vl write back, check
      whether the vl is zero"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/BusyTable.scala
    lines: 235-245
    context: "235:     }.otherwise {\n236:       update := nonzeroTable(idx)\n237:\
      \     }\n238:   }\n239: \n240:   vlmaxTableUpdate.zipWithIndex.foreach{ case
      (update, idx) =>\n241:     when(intVlWb(idx)) {\n242:       // int schd vl write
      back, check whether the vl is vlmax\n243:       update := !io_vl_Wb.vlWriteBackInfo.vlFromIntIsVlmax\n\
      244:     }.elsewhen(vfVlWb(idx)) {\n245:       // vf schd vl write back, check
      whether the vl is vlmax"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/BusyTable.scala
    lines: 249-259
    context: "249:     }.otherwise {\n250:       update := vlmaxTable(idx)\n251: \
      \    }\n252:   }\n253: \n254:   io_vl_read.vlReadInfo.zip(io.read).foreach{
      case (vlRes, res) =>\n255:     vlRes.is_nonzero := !nonzeroTable(res.req)\n\
      256:     vlRes.is_vlmax := !vlmaxTable(res.req)\n257:   }\n258: }\n259: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/GPAMem.scala
    lines: 15-40
    context: "15: }\n16: \n17: class GPAMemImp(override val wrapper: GPAMem)(implicit
      p: Parameters) extends LazyModuleImp(wrapper) with HasXSParameter {\n18:   val
      io = IO(new GPAMemIO)\n19: \n20:   private val mem = Module (new SyncDataModuleTemplate(new
      GPAMemEntry, FtqSize, numRead = 1, numWrite = 1, hasRen = true))\n21: \n22:\
      \   mem.io.wen.head := io.fromIFU.gpaddrMem_wen\n23:   mem.io.waddr.head :=
      io.fromIFU.gpaddrMem_waddr\n24:   mem.io.wdata.head := io.fromIFU.gpaddrMem_wdata\n\
      25: \n26:   mem.io.ren.get.head := io.exceptionReadAddr.valid\n27:   mem.io.raddr.head
      := io.exceptionReadAddr.bits.ftqPtr.value\n28: \n29:   private val ftqOffset
      = RegEnable(io.exceptionReadAddr.bits.ftqOffset, io.exceptionReadAddr.valid)\n\
      30: \n31:   private val gpabase = mem.io.rdata.head.gpaddr\n32:   private val
      gpa = gpabase + Cat(ftqOffset, 0.U(instOffsetBits.W))\n33: \n34:   io.exceptionReadData.gpaddr
      := gpa\n35:   io.exceptionReadData.isForVSnonLeafPTE := mem.io.rdata.head.isForVSnonLeafPTE\n\
      36: \n37:   def getGPAPage(vaddr: UInt): UInt = {\n38:     require(vaddr.getWidth
      == GPAddrBits, s\"The width of gpa should be $GPAddrBits\")\n39:     vaddr(GPAddrBits
      - 1, PageOffsetWidth)\n40:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/PipeGroupConnect.scala
    lines: 5-15
    context: "5: \n6: class PipeGroupConnect[T <: Data](n: Int, gen: => T) extends
      Module {\n7:   val io = IO(new Bundle {\n8:     val in = Vec(n, Flipped(DecoupledIO(gen)))\n\
      9:     val out = Vec(n, DecoupledIO(gen))\n10:     val flush = Input(Bool())\n\
      11:     val outAllFire = Input(Bool())\n12:   })\n13: \n14:   // Input Alias\n\
      15:   // Use private[this] to limit the wrong usage for not IO hardware in object
      with the same name."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/PipeGroupConnect.scala
    lines: 11-24
    context: "11:     val outAllFire = Input(Bool())\n12:   })\n13: \n14:   // Input
      Alias\n15:   // Use private[this] to limit the wrong usage for not IO hardware
      in object with the same name.\n16:   private[this] val flush = io.flush\n17:\
      \   private[this] val inValidSeq  = io.in.map(_.valid)\n18:   private[this]
      val inDataSeq   = io.in.map(_.bits)\n19:   private[this] val outReadySeq = io.out.map(_.ready)\n\
      20: \n21:   // Regs\n22:   private[this] val validVec = RegInit(VecInit.fill(n)(false.B))\n\
      23:   private[this] val dataVec  = Reg(Vec(n, gen))\n24: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/PipeGroupConnect.scala
    lines: 23-33
    context: "23:   private[this] val dataVec  = Reg(Vec(n, gen))\n24: \n25:   //
      Logic\n26:   private[this] val valids    = Cat(validVec.reverse)\n27:   private[this]
      val inValids  = Cat(inValidSeq.reverse)\n28:   private[this] val outReadys =
      Cat(outReadySeq.reverse)\n29: \n30:   // Todo: canAccVec for each elem\n31:\
      \   // Todo: no outReadys version for better timing and lower performance\n\
      32:   private[this] val canAcc = io.outAllFire || !valids.orR\n33: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/PipeGroupConnect.scala
    lines: 29-50
    context: "29: \n30:   // Todo: canAccVec for each elem\n31:   // Todo: no outReadys
      version for better timing and lower performance\n32:   private[this] val canAcc
      = io.outAllFire || !valids.orR\n33: \n34:   (validVec zip inValids.asBools zip
      outReadys.asBools).foreach { case ((valid, inValid), outReady) =>\n35:     valid
      := MuxCase(\n36:       default = valid /*keep*/,\n37:       Seq(\n38:      \
      \   flush               -> false.B,\n39:         (inValid && canAcc) -> true.B,\n\
      40:         outReady            -> false.B\n41:       )\n42:     )\n43:   }\n\
      44: \n45:   (dataVec zip inValids.asBools zip inDataSeq).foreach { case ((data,
      inValid), inData) =>\n46:     when (inValid && canAcc) {\n47:       data :=
      inData\n48:     }\n49:   }\n50: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/PipeGroupConnect.scala
    lines: 48-58
    context: "48:     }\n49:   }\n50: \n51:   // Output connections\n52:   for (i
      <- 0 until n) {\n53:     io.in(i).ready  := canAcc\n54:     io.out(i).valid
      := validVec(i)\n55:     io.out(i).bits  := dataVec(i)\n56:   }\n57: }\n58: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/PipeGroupConnect.scala
    lines: 59-69
    context: "59: object PipeGroupConnect {\n60:   def apply[T <: Data](\n61:    \
      \ // Left can be not Vec, but right must be Vec\n62:     left: Seq[DecoupledIO[T]],\n\
      63:     right: Vec[DecoupledIO[T]],\n64:     flush: Bool,\n65:     rightAllFire:
      Bool,\n66:     suggestName: String = null,\n67:   ): Unit =  {\n68:     require(left.size
      == right.size, \"The sizes of left and right Vec Bundle should be equal in PipeGroupConnect\"\
      )\n69:     require(left.size > 0, \"The size of Vec Bundle in PipeGroupConnect
      should be more than 0\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/PipeGroupConnect.scala
    lines: 65-80
    context: "65:     rightAllFire: Bool,\n66:     suggestName: String = null,\n67:\
      \   ): Unit =  {\n68:     require(left.size == right.size, \"The sizes of left
      and right Vec Bundle should be equal in PipeGroupConnect\")\n69:     require(left.size
      > 0, \"The size of Vec Bundle in PipeGroupConnect should be more than 0\")\n\
      70:     val mod = Module(new PipeGroupConnect(left.size, chiselTypeOf(left.head.bits)))\n\
      71:     mod.io.flush := flush\n72:     mod.io.in.zipWithIndex.foreach { case
      (in, i) =>\n73:       in.valid := left(i).valid\n74:       in.bits := left(i).bits\n\
      75:       left(i).ready := in.ready\n76:     }\n77:     mod.io.outAllFire :=
      rightAllFire\n78:     right <> mod.io.out\n79: \n80:     if (suggestName !=
      null)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 26-36
    context: "26:       val busy = Bool()\n27:     }\n28:   }))\n29: \n30:   private
      val oldPregVecFromRat: Vec[ValidIO[UInt]] = Wire(Vec(RabCommitWidth, ValidIO(UInt(VfPhyRegIdxWidth.W))))\n\
      31:   oldPregVecFromRat.zipWithIndex.foreach { case (oldPreg: ValidIO[UInt],
      idx) =>\n32:     val vecOldVd = i.fromRat.vecOldVdPdest(idx)\n33:     val v0OldVd\
      \  = i.fromRat.v0OldVdPdest(idx)\n34:     oldPreg.valid := (vecOldVd.valid ||
      v0OldVd.valid)\n35:     oldPreg.bits := Mux1H(Seq(\n36:       vecOldVd.valid
      -> vecOldVd.bits,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 202-212
    context: "202:   ))\n203: \n204:   dontTouch(oldVdLocVec)\n205:   dontTouch(newVdLocVec)\n\
      206: \n207:   private object State extends ChiselEnum {\n208:     val noExcp\
      \  = Value\n209:     val waitRab = Value\n210:     val mergeVd = Value\n211:\
      \     val mvOldVd = Value\n212:     val finish  = Value"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 210-222
    context: "210:     val mergeVd = Value\n211:     val mvOldVd = Value\n212:   \
      \  val finish  = Value\n213:   }\n214: \n215:   private val state: State.Type
      = RegInit(State.noExcp)\n216:   private val stateNext = WireInit(state)\n217:\
      \   state := stateNext\n218: \n219:   private val collectedAllRegMap = Wire(Bool())\n\
      220:   private val mergeFinished = currentIdx >= sWaitRab_needMergeUntil\n221:\
      \   private val mvFinished = currentIdx >= sWaitRab_handleUntil\n222: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 229-285
    context: "229:   private val filteredRatCommitedVec: Vec[Vec[Bool]] = WireInit(VecInit.tabulate(4,
      MaxLMUL) { case (i_d_n, vdIdx) =>\n230:     val vdLoc = vdIdx << i_d_n\n231:\
      \     ratCommitted(if (vdLoc >= MaxLMUL) 0 else vdLoc)\n232:   })\n233: \n234:\
      \   private val filteredRabCommited = Wire(Vec(MaxLMUL, Bool()))\n235:   private
      val filteredRatCommited = Wire(Vec(MaxLMUL, Bool()))\n236:   when (sWaitRab_nonSegIndexed)
      {\n237:     filteredRabCommited := Mux1H(sWaitRab_vemul_i_d, filteredRabCommitedVec)\n\
      238:     filteredRatCommited := Mux1H(sWaitRab_vemul_i_d, filteredRatCommitedVec)\n\
      239:   }.otherwise {\n240:     // No need to shuffle, since the vdIdx always
      compressed towards zero and left tail unused.\n241:     filteredRabCommited
      := rabCommitted\n242:     filteredRatCommited := ratCommitted\n243:   }\n244:\
      \ \n245:   // 1. no need commit\n246:   // 2. need commit and both rab and rat
      committed\n247:   collectedAllRegMap := ((~commitNeeded.asUInt).asUInt | (commitNeeded.asUInt
      & filteredRabCommited.asUInt & filteredRatCommited.asUInt)).andR\n248: \n249:\
      \   switch(state) {\n250:     is(State.noExcp) {\n251:       when (i.fromExceptionGen.valid)
      {\n252:         stateNext := State.waitRab\n253:       }\n254:     }\n255: \
      \    is(State.waitRab) {\n256:       when (collectedAllRegMap) {\n257:     \
      \    stateNext := State.mergeVd\n258:         currentIdx := sWaitRab_useNewVdUntil\n\
      259:       }\n260:     }\n261:     is(State.mergeVd) {\n262:       when (mvFinished)
      {\n263:         stateNext := State.finish\n264:       }.elsewhen (mergeFinished)
      {\n265:         stateNext := State.mvOldVd\n266:       }\n267:       when(o.toVPRF.w.head.valid)
      {\n268:         currentIdx := currentIdx + PopCount(o.toVPRF.w.map(_.valid))\n\
      269:       }\n270:     }\n271:     is(State.mvOldVd) {\n272:       when (mvFinished)
      {\n273:         stateNext := State.finish\n274:       }\n275:       when(o.toVPRF.w.head.valid)
      {\n276:         currentIdx := currentIdx + PopCount(o.toVPRF.w.map(_.valid))\n\
      277:       }\n278:     }\n279:     is(State.finish) {\n280:       stateNext
      := State.noExcp\n281:       currentIdx := 0.U\n282:     }\n283:   }\n284: \n\
      285:   private val regWriteFromRabVec: Vec[ValidIO[RegWriteFromRab]] = i.fromRab.logicPhyRegMap"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 284-297
    context: "284: \n285:   private val regWriteFromRabVec: Vec[ValidIO[RegWriteFromRab]]
      = i.fromRab.logicPhyRegMap\n286:   private val regWriteFromRatVec: Vec[ValidIO[UInt]]
      = oldPregVecFromRat\n287: \n288:   val mergedVdWData: Vec[VecE8Vec] = Wire(Vec(maxMergeNumPerCycle,
      new VecE8Vec(VLEN)))\n289:   mergedVdWData.zipWithIndex.foreach { case (vd,
      vIdx) =>\n290:     vd.data.zipWithIndex.foreach { case (vde, eIdx) =>\n291:\
      \       vde := Mux(\n292:         state === State.mergeVd,\n293:         Mux(\n\
      294:           eIdx.U >= sWaitRab_e8offset,\n295:           preMergedOldVd(vIdx).e8Vec(eIdx),\n\
      296:           preMergedNewVd(vIdx).e8Vec(eIdx),\n297:         ),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 298-309
    context: "298:         preMoveOldVd(vIdx).e8Vec(eIdx),\n299:       )\n300:   \
      \  }\n301:   }\n302: \n303:   private val hasRabWrite = regWriteFromRabVec.head.valid\n\
      304:   private val hasRatWrite = regWriteFromRatVec.head.valid\n305:   require(\n\
      306:     2 * RabCommitWidth >= (MaxLMUL + 2),\n307:     \"Cannot receive all
      10 reg maps from RAB and RAT in two cycles. \" +\n308:       \"This module should
      be rewrited to support more than 2 cycles receiving\"\n309:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 306-326
    context: "306:     2 * RabCommitWidth >= (MaxLMUL + 2),\n307:     \"Cannot receive
      all 10 reg maps from RAB and RAT in two cycles. \" +\n308:       \"This module
      should be rewrited to support more than 2 cycles receiving\"\n309:   )\n310:\
      \ \n311:   switch (state) {\n312:     is (State.noExcp) {\n313:       when (stateNext
      === State.waitRab) {\n314:         sWaitRab_rabWriteOffset := 0.U\n315:    \
      \     sWaitRab_ratWriteOffset := 0.U\n316:         commitNeeded.zipWithIndex.foreach
      { case (needed, idx) =>\n317:           needed := sNoExcp_maxVdIdx > idx.U\n\
      318:         }\n319:       }\n320:     }\n321:     is (State.waitRab) {\n322:\
      \       when (hasRabWrite) {\n323:         sWaitRab_rabWriteOffset := sWaitRab_rabWriteOffset
      +\n324:           PriorityMux((0 until RabCommitWidth).map(\n325:          \
      \   idx => i.fromRab.logicPhyRegMap.reverse(idx).valid -> (6 - idx).U\n326:\
      \           ))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 414-428
    context: "414:             }\n415:           }\n416:         }\n417:       }\n\
      418:     }\n419:     is (State.finish) {\n420:       commitNeeded.foreach(_
      := false.B)\n421:       rabCommitted.foreach(_ := false.B)\n422:       ratCommitted.foreach(_
      := false.B)\n423:       hasReadRf   .foreach(_ := false.B)\n424:       sWaitRab_rabWriteOffset
      := 0.U\n425:       sWaitRab_ratWriteOffset := 0.U\n426:       sWaitRab_vecExcpInfo.valid
      := false.B\n427:     }\n428:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 425-436
    context: "425:       sWaitRab_ratWriteOffset := 0.U\n426:       sWaitRab_vecExcpInfo.valid
      := false.B\n427:     }\n428:   }\n429: \n430:   switch (state) {\n431:     is
      (State.mergeVd, State.mvOldVd) {\n432:       (0 until maxMergeNumPerCycle).map(vIdx
      =>\n433:         when(i.fromVprf.rdata(vIdx).valid) {\n434:           mergedVd(vIdx)
      := mergedVdWData(vIdx).asTypeOf(new VecElemData(VLEN))\n435:         }\n436:\
      \       )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 435-446
    context: "435:         }\n436:       )\n437:     }\n438:   }\n439: \n440:   when
      (state === State.mergeVd) {\n441:     (0 until maxMergeNumPerCycle).foreach
      { case (idx) =>\n442:       val vdIdx = currentIdxVec(idx)\n443:       // when
      nonSegIndexed load, iemul/demul = 1 << 2, vdLoc will be mapped as (0, 1, 2,
      3, ...) -> (0, 4, ...)\n444:       val oldVdLoc = oldVdLocVec(idx)\n445:   \
      \    // when nonSegIndexed load, iemul/demul = 1 << 2, vdLoc will be mapped
      as (0, 1, 2, 3, ...) -> (3, 7, ...)\n446:       val newVdLoc = newVdLocVec(idx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 450-461
    context: "450:       o.toVPRF.r(idx + maxMergeNumPerCycle).valid := commitNeeded(vdIdx)
      && !hasReadRf(vdIdx) && vdIdx < sWaitRab_needMergeUntil\n451:       o.toVPRF.r(idx
      + maxMergeNumPerCycle).bits.addr := regMaps(newVdLoc).newPreg\n452:       o.toVPRF.r(idx
      + maxMergeNumPerCycle).bits.isV0 := (regMaps(newVdLoc).lreg === 0.U) && (idx
      == 0).B\n453:       hasReadRf(vdIdx) := true.B && vdIdx < sWaitRab_needMergeUntil\n\
      454:     }\n455:   }.elsewhen (state === State.mvOldVd) {\n456:     (0 until
      maxMergeNumPerCycle).foreach { case (idx) =>\n457:       val vdIdx = currentIdxVec(idx)\n\
      458:       // when nonSegIndexed load, iemul/demul = 1 << 2, vdLoc will be mapped
      as (0, 1, 2, 3, ...) -> (0, 4, ...)\n459:       val oldVdLoc = oldVdLocVec(idx)\n\
      460:       // when nonSegIndexed load, iemul/demul = 1 << 2, vdLoc will be mapped
      as (0, 1, 2, 3, ...) -> (3, 7, ...)\n461:       val newVdLoc = newVdLocVec(idx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 469-479
    context: "469:     }\n470:   }.otherwise {\n471:     o.toVPRF.r := 0.U.asTypeOf(chiselTypeOf(o.toVPRF.r))\n\
      472:   }\n473: \n474:   o.toVPRF.w.zipWithIndex.foreach { case (w, idx) =>\n\
      475:     val vdIdx = currentIdxVec(idx)\n476:     // when nonSegIndexed load,
      iemul/demul = 1 << 2, vdLoc will be mapped as (0, 1, 2, 3, ...) -> (0, 4, ...)\n\
      477:     val oldVdLoc = oldVdLocVec(idx)\n478:     // when nonSegIndexed load,
      iemul/demul = 1 << 2, vdLoc will be mapped as (0, 1, 2, 3, ...) -> (3, 7, ...)\n\
      479:     val newVdLoc = newVdLocVec(idx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 481-491
    context: "481:     w.bits.isV0      := (regMaps(newVdLoc).lreg === 0.U) && (idx
      == 0).B\n482:     w.bits.newVdAddr := regMaps(newVdLoc).newPreg\n483:     w.bits.newVdData
      := mergedVd(idx.U).asUInt\n484:   }\n485: \n486:   o.status.busy := DelayN(state.isOneOf(State.waitRab,
      State.mergeVd, State.mvOldVd), 1)\n487: }\n488: \n489: class LogicPhyRegMap(implicit
      p: Parameters) extends XSBundle {\n490:   val lreg = UInt(LogicRegsWidth.W)\n\
      491:   val newPreg = UInt(VfPhyRegIdxWidth.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/ctrlblock/MemCtrl.scala
    lines: 2-12
    context: "2: \n3: import org.chipsalliance.cde.config.Parameters\n4: import chisel3.util.ValidIO\n\
      5: import chisel3._\n6: import xiangshan.backend.BackendParams\n7: import xiangshan.{CustomCSRCtrlIO,
      MemPredUpdateReq, Redirect, XSBundle, XSModule}\n8: import xiangshan.mem.mdp.{DispatchLFSTIO,
      LFST, SSIT, SSITEntry, WaitTable}\n9: import xiangshan.backend.Bundles.DynInst\n\
      10: \n11: class MemCtrl(params: BackendParams)(implicit p: Parameters) extends
      XSModule {\n12:   val io = IO(new MemCtrlIO(params))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/ctrlblock/MemCtrl.scala
    lines: 22-32
    context: "22:   for (i <- 0 until RenameWidth) {\n23:     ssit.io.ren(i) := io.mdpFoldPcVecVld(i)\n\
      24:     ssit.io.raddr(i) := io.mdpFlodPcVec(i)\n25:     waittable.io.raddr(i)
      := io.mdpFlodPcVec(i)\n26:   }\n27:   lfst.io.redirect <> RegNext(io.redirect)\n\
      28:   lfst.io.storeIssue <> RegNext(io.stIn)\n29:   lfst.io.csrCtrl <> RegNext(io.csrCtrl)\n\
      30:   lfst.io.dispatch <> io.dispatchLFSTio\n31: \n32:   io.waitTable2Rename
      := waittable.io.rdata"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/ctrlblock/MemCtrl.scala
    lines: 32-42
    context: "32:   io.waitTable2Rename := waittable.io.rdata\n33:   io.ssit2Rename
      := ssit.io.rdata\n34: }\n35: \n36: class MemCtrlIO(params: BackendParams)(implicit
      p: Parameters) extends XSBundle {\n37:   val redirect = Flipped(ValidIO(new
      Redirect))\n38:   val csrCtrl = Input(new CustomCSRCtrlIO)\n39:   val stIn =
      Vec(params.StaExuCnt, Flipped(ValidIO(new DynInst))) // use storeSetHit, ssid,
      robIdx\n40:   val memPredUpdate = Input(new MemPredUpdateReq)\n41:   val mdpFoldPcVecVld
      = Input(Vec(DecodeWidth, Bool()))\n42:   val mdpFlodPcVec = Input(Vec(DecodeWidth,
      UInt(MemPredPCWidth.W)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/ctrlblock/MemCtrl.scala
    lines: 40-46
    context: "40:   val memPredUpdate = Input(new MemPredUpdateReq)\n41:   val mdpFoldPcVecVld
      = Input(Vec(DecodeWidth, Bool()))\n42:   val mdpFlodPcVec = Input(Vec(DecodeWidth,
      UInt(MemPredPCWidth.W)))\n43:   val dispatchLFSTio = Flipped(new DispatchLFSTIO)\n\
      44:   val waitTable2Rename = Vec(DecodeWidth, Output(Bool()))   // loadWaitBit\n\
      45:   val ssit2Rename = Vec(RenameWidth, Output(new SSITEntry)) // ssit read
      result\n46: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/ctrlblock/RedirectGenerator.scala
    lines: 2-31
    context: "2: \n3: import org.chipsalliance.cde.config.Parameters\n4: import chisel3.util._\n\
      5: import chisel3._\n6: import utility.{HasCircularQueuePtrHelper, XORFold,
      GatedValidRegNext}\n7: import xiangshan.frontend.{FtqRead, PreDecodeInfo}\n\
      8: import xiangshan.{MemPredUpdateReq, Redirect, XSBundle, XSModule, AddrTransType}\n\
      9: \n10: class RedirectGenerator(implicit p: Parameters) extends XSModule\n\
      11:   with HasCircularQueuePtrHelper {\n12: \n13:   class RedirectGeneratorIO(implicit
      p: Parameters) extends XSBundle {\n14:     def numRedirect = backendParams.numRedirect\n\
      15: \n16:     val hartId = Input(UInt(8.W))\n17:     val oldestExuRedirect =
      Flipped(ValidIO(new Redirect))\n18:     val oldestExuRedirectIsCSR = Input(Bool())\n\
      19:     val instrAddrTransType = Input(new AddrTransType)\n20:     val oldestExuOutPredecode
      = Input(new PreDecodeInfo) // guarded by exuRedirect.valid\n21:     val loadReplay
      = Flipped(ValidIO(new Redirect))\n22:     val robFlush = Flipped(ValidIO(new
      Redirect))\n23:     val stage2Redirect = ValidIO(new Redirect)\n24: \n25:  \
      \   val memPredUpdate = Output(new MemPredUpdateReq)\n26:     val memPredPcRead
      = new FtqRead(UInt(VAddrBits.W)) // read req send form stage 2\n27:     val
      stage2oldestOH = Output(UInt((1 + 1).W))\n28:   }\n29: \n30:   val io = IO(new
      RedirectGeneratorIO)\n31: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/ctrlblock/RedirectGenerator.scala
    lines: 27-68
    context: "27:     val stage2oldestOH = Output(UInt((1 + 1).W))\n28:   }\n29: \n\
      30:   val io = IO(new RedirectGeneratorIO)\n31: \n32:   val loadRedirect = io.loadReplay\n\
      33:   val robFlush = io.robFlush\n34:   val oldestExuRedirect = Wire(chiselTypeOf(io.oldestExuRedirect))\n\
      35:   oldestExuRedirect := io.oldestExuRedirect\n36:   oldestExuRedirect.bits.fullTarget
      := Cat(io.oldestExuRedirect.bits.fullTarget.head(XLEN - VAddrBits), io.oldestExuRedirect.bits.cfiUpdate.target)\n\
      37:   when(!io.oldestExuRedirectIsCSR){\n38:     oldestExuRedirect.bits.cfiUpdate.backendIAF
      := io.instrAddrTransType.checkAccessFault(oldestExuRedirect.bits.fullTarget)\n\
      39:     oldestExuRedirect.bits.cfiUpdate.backendIPF := io.instrAddrTransType.checkPageFault(oldestExuRedirect.bits.fullTarget)\n\
      40:     oldestExuRedirect.bits.cfiUpdate.backendIGPF := io.instrAddrTransType.checkGuestPageFault(oldestExuRedirect.bits.fullTarget)\n\
      41:   }\n42:   val allRedirect: Vec[ValidIO[Redirect]] = VecInit(oldestExuRedirect,
      loadRedirect)\n43:   val oldestOneHot = Redirect.selectOldestRedirect(allRedirect)\n\
      44:   val flushAfter = RegInit(0.U.asTypeOf(ValidIO(new Redirect)))\n45:   val
      needFlushVec = VecInit(allRedirect.map(_.bits.robIdx.needFlush(flushAfter) ||
      robFlush.valid))\n46:   val oldestValid = VecInit(oldestOneHot.zip(needFlushVec).map
      { case (v, f) => v && !f }).asUInt.orR\n47:   val oldestExuPredecode = io.oldestExuOutPredecode\n\
      48:   val oldestRedirect = Mux1H(oldestOneHot, allRedirect)\n49:   val s1_redirect_bits_reg
      = RegEnable(oldestRedirect.bits, oldestValid)\n50:   val s1_redirect_valid_reg
      = GatedValidRegNext(oldestValid)\n51:   val s1_redirect_onehot = VecInit(oldestOneHot.map(x
      => GatedValidRegNext(x)))\n52: \n53:   if (backendParams.debugEn){\n54:    \
      \ dontTouch(oldestValid)\n55:     dontTouch(needFlushVec)\n56:   }\n57:   val
      flushAfterCounter = Reg(UInt(3.W))\n58:   val robFlushOrExuFlushValid = oldestValid
      || robFlush.valid\n59:   when(robFlushOrExuFlushValid) {\n60:     flushAfter.valid
      := true.B\n61:     flushAfter.bits := Mux(robFlush.valid, robFlush.bits, oldestRedirect.bits)\n\
      62:   }.elsewhen(!flushAfterCounter(0)) {\n63:     flushAfter.valid := false.B\n\
      64:   }\n65:   when(robFlushOrExuFlushValid) {\n66:     flushAfterCounter :=
      \"b111\".U\n67:   }.elsewhen(flushAfterCounter(0)){\n68:     flushAfterCounter
      := flushAfterCounter >> 1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/ctrlblock/RedirectGenerator.scala
    lines: 66-94
    context: "66:     flushAfterCounter := \"b111\".U\n67:   }.elsewhen(flushAfterCounter(0)){\n\
      68:     flushAfterCounter := flushAfterCounter >> 1\n69:   }\n70:   // stage1
      -> stage2\n71:   io.stage2Redirect.valid := s1_redirect_valid_reg && !robFlush.valid\n\
      72:   io.stage2Redirect.bits := s1_redirect_bits_reg\n73:   io.stage2Redirect.bits.cfiUpdate.pd
      := RegEnable(oldestExuPredecode, oldestValid)\n74:   io.stage2oldestOH := s1_redirect_onehot.asUInt\n\
      75: \n76:   val s1_isReplay = s1_redirect_onehot.last\n77: \n78:   // get pc
      from ftq\n79:   // valid only if redirect is caused by load violation\n80: \
      \  // store_pc is used to update store set\n81:   val store_pc = io.memPredPcRead(s1_redirect_valid_reg,
      s1_redirect_bits_reg.stFtqIdx, s1_redirect_bits_reg.stFtqOffset)\n82:   val
      real_pc = s1_redirect_bits_reg.cfiUpdate.pc\n83:   // update load violation
      predictor if load violation redirect triggered\n84:   val s2_redirect_bits_reg
      = RegEnable(s1_redirect_bits_reg, s1_redirect_valid_reg)\n85:   io.memPredUpdate.valid
      := GatedValidRegNext(s1_isReplay && s1_redirect_valid_reg && s1_redirect_bits_reg.flushItself(),
      init = false.B)\n86:   // update wait table\n87:   io.memPredUpdate.waddr :=
      RegEnable(XORFold(real_pc(VAddrBits - 1, 1), MemPredPCWidth), s1_isReplay &&
      s1_redirect_valid_reg)\n88:   io.memPredUpdate.wdata := true.B\n89:   // update
      store set\n90:   io.memPredUpdate.ldpc := RegEnable(XORFold(real_pc(VAddrBits
      - 1, 1), MemPredPCWidth), s1_isReplay && s1_redirect_valid_reg)\n91:   // store
      pc is ready 1 cycle after s1_isReplay is judged\n92:   io.memPredUpdate.stpc
      := RegEnable(XORFold(store_pc(VAddrBits - 1, 1), MemPredPCWidth), s1_isReplay
      && s1_redirect_valid_reg)\n93: \n94: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/ctrlblock/LsInfo.scala
    lines: 13-23
    context: "13: \n14: class DebugLsInfo(implicit p: Parameters) extends XSBundle{\n\
      15:   val s1_isTlbFirstMiss = Bool() // in s1\n16:   val s1_isLoadToLoadForward
      = Bool()\n17:   val s2_isBankConflict = Bool()\n18:   val s2_isDcacheFirstMiss
      = Bool() // in s2 (predicted result is in s1 when using WPU, real result is
      in s2)\n19:   val s2_isForwardFail = Bool() // in s2\n20:   val s3_isReplayFast
      = Bool()\n21:   val s3_isReplaySlow = Bool()\n22:   val s3_isReplayRS = Bool()\n\
      23:   val s3_isReplay = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FunctionUnit.scala
    lines: 62-72
    context: "62: class FunctionUnitIO(val len: Int)(implicit p: Parameters) extends
      XSBundle {\n63:   val in = Flipped(DecoupledIO(new FunctionUnitInput(len)))\n\
      64: \n65:   val out = DecoupledIO(new FuOutput(len))\n66: \n67:   val redirectIn
      = Flipped(ValidIO(new Redirect))\n68: }\n69: \n70: abstract class FunctionUnit(len:
      Int = 64)(implicit p: Parameters) extends XSModule {\n71: \n72:   val io = IO(new
      FunctionUnitIO(len))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FunctionUnit.scala
    lines: 70-79
    context: "70: abstract class FunctionUnit(len: Int = 64)(implicit p: Parameters)
      extends XSModule {\n71: \n72:   val io = IO(new FunctionUnitIO(len))\n73: \n\
      74:   XSPerfAccumulate(\"in_valid\", io.in.valid)\n75:   XSPerfAccumulate(\"\
      in_fire\", io.in.fire)\n76:   XSPerfAccumulate(\"out_valid\", io.out.valid)\n\
      77:   XSPerfAccumulate(\"out_fire\", io.out.fire)\n78: \n79: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 33-46
    context: "33:   */\n34: class SRT4DividerDataModule(len: Int) extends Module {\n\
      35:   val io = IO(new Bundle() {\n36:     val src = Vec(2, Input(UInt(len.W)))\n\
      37:     val valid, sign, kill_w, kill_r, isHi, isW = Input(Bool())\n38:    \
      \ val in_ready = Output(Bool())\n39:     val out_valid = Output(Bool())\n40:\
      \     val out_data = Output(UInt(len.W))\n41:     val out_ready = Input(Bool())\n\
      42:   })\n43: \n44:   // consts\n45:   val lzc_width = log2Up(len)\n46:   val
      itn_len = 1 + len + 2 + 1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 46-66
    context: "46:   val itn_len = 1 + len + 2 + 1\n47:   require(lzc_width == 6)\n\
      48: \n49:   val (a, d, sign, valid, kill_w, kill_r, isHi, isW) =\n50:     (io.src(0),
      io.src(1), io.sign, io.valid, io.kill_w, io.kill_r, io.isHi, io.isW)\n51:  \
      \ val in_fire = valid && io.in_ready\n52:   val out_fire = io.out_ready && io.out_valid\n\
      53:   val newReq = in_fire\n54:   val startHandShake = io.in_ready && valid\n\
      55:   val s_idle :: s_pre_0 :: s_pre_1 :: s_iter :: s_post_0 :: s_post_1 ::
      s_finish :: Nil = Enum(7)\n56: \n57:   val state = RegInit(UIntToOH(s_idle,
      7))\n58: \n59:   val quot_neg_2 :: quot_neg_1 :: quot_0 :: quot_pos_1 :: quot_pos_2
      :: Nil = Enum(5)\n60: \n61:   val finished = state(s_finish)\n62: \n63:   //
      reused wire declarations\n64:   val aIsZero = Wire(Bool())\n65:   val dIsZero
      = Wire(Bool())\n66:   val aTooSmall = Wire(Bool()) // this is output of reg!"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 78-114
    context: "78:   val quotIter = Wire(UInt(len.W))\n79:   val quotM1Iter = Wire(UInt(len.W))\n\
      80:   val qIterEnd = Wire(UInt(5.W))\n81: \n82:   val rNext = Wire(UInt(itn_len.W))\n\
      83:   val rNextPd = Wire(UInt(itn_len.W)) // non-redundant remainder plus d,
      68, 67\n84:   //reused ctrl regs\n85: \n86:   //reused other regs\n87:   val
      aNormAbsReg = RegEnable(aNormAbs, startHandShake | state(s_pre_0) | state(s_post_0))
      // reg for normalized a & d and rem & rem+d\n88:   val dNormAbsReg = RegEnable(dNormAbs,
      startHandShake | state(s_pre_0) | state(s_post_0))\n89:   val quotIterReg =
      RegEnable(quotIter, state(s_pre_1) | state(s_iter) | state(s_post_0))\n90: \
      \  val quotM1IterReg = RegEnable(quotM1Iter, state(s_pre_1) | state(s_iter)
      | state(s_post_0))\n91: \n92:   when(kill_r) {\n93:     state := UIntToOH(s_idle,
      7)\n94:   } .elsewhen(state(s_idle) && in_fire && !kill_w) {\n95:     state
      := UIntToOH(s_pre_0, 7)\n96:   } .elsewhen(state(s_pre_0)) { // leading zero
      detection\n97:     state := UIntToOH(s_pre_1, 7)\n98:   } .elsewhen(state(s_pre_1))
      { // shift a/b\n99:     state := Mux(dIsZero | aTooSmall | noIter, UIntToOH(s_post_0,
      7), UIntToOH(s_iter, 7))\n100:   } .elsewhen(state(s_iter)) { // (ws[j+1], wc[j+1])
      = 4(ws[j],wc[j]) - q(j+1)*d\n101:     state := Mux(finalIter, UIntToOH(s_post_0,
      7), UIntToOH(s_iter, 7))\n102:   } .elsewhen(state(s_post_0)) { // if rem <
      0, rem = rem + d\n103:     state := UIntToOH(s_post_1, 7)\n104:   } .elsewhen(state(s_post_1))
      {\n105:     state := UIntToOH(s_finish, 7)\n106:   } .elsewhen(state(s_finish)
      && out_fire) {\n107:     state := UIntToOH(s_idle, 7)\n108:   } .otherwise {\n\
      109:     state := state\n110:   }\n111: \n112:   // First cycle:\n113:   //
      State is idle, we gain absolute value of a and b, using global inverter\n114: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 110-123
    context: "110:   }\n111: \n112:   // First cycle:\n113:   // State is idle, we
      gain absolute value of a and b, using global inverter\n114: \n115:   io.in_ready
      := state(s_idle)\n116: \n117:   aInverter := -Mux(state(s_idle), a, quotIterReg)
      // 64, 0\n118:   dInverter := -Mux(state(s_idle), d, quotM1IterReg) // 64, 0\n\
      119: \n120:   val aSign = io.sign && a(len - 1) // 1\n121:   val dSign = io.sign
      && d(len - 1)\n122: \n123:   val aAbs = Mux(aSign, aInverter, a) // 64, 0"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 124-141
    context: "124:   val dAbs = Mux(dSign, dInverter, d)\n125:   val aNorm = (aNormAbsReg(len
      - 1, 0) << aLZC(lzc_width - 1, 0))(len - 1, 0) // 64, 65\n126:   val dNorm =
      (dNormAbsReg(len - 1, 0) << dLZC(lzc_width - 1, 0))(len - 1, 0)\n127: \n128:\
      \   aNormAbs := Mux1H(Seq(\n129:     state(s_idle) -> Cat(0.U(1.W), aAbs), //
      65, 0\n130:     state(s_pre_0) -> Cat(0.U(1.W), aNorm), // 65, 0\n131:     state(s_post_0)
      -> rNext(len + 3, 3) // remainder 65, 64. highest is sign bit\n132:   ))\n133:\
      \   dNormAbs := Mux1H(Seq(\n134:     state(s_idle) -> Cat(0.U(1.W), dAbs),\n\
      135:     state(s_pre_0) -> Cat(0.U(1.W), dNorm),\n136:     state(s_post_0) ->
      rNextPd(len + 3, 3)\n137:     ))\n138: \n139:   // Second cycle, state is pre_0\n\
      140:   // calculate lzc and move div* and lzc diff check if no_iter_needed\n\
      141: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 139-150
    context: "139:   // Second cycle, state is pre_0\n140:   // calculate lzc and
      move div* and lzc diff check if no_iter_needed\n141: \n142:   aLZC := PriorityEncoder(aNormAbsReg(len
      - 1, 0).asBools.reverse)\n143:   dLZC := PriorityEncoder(dNormAbsReg(len - 1,
      0).asBools.reverse)\n144:   val aLZCReg = RegEnable(aLZC, state(s_pre_0)) //
      7, 0\n145:   val dLZCReg = RegEnable(dLZC, state(s_pre_0))\n146: \n147: \n148:\
      \ \n149:   val lzcWireDiff = Cat(0.U(1.W), dLZC(lzc_width - 1, 0)) - Cat(0.U(1.W),
      aLZC(lzc_width - 1, 0)) // 7, 0\n150:   val lzcRegDiff = Cat(0.U(1.W), dLZCReg(lzc_width
      - 1, 0)) - Cat(0.U(1.W), aLZCReg(lzc_width - 1, 0))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 146-172
    context: "146: \n147: \n148: \n149:   val lzcWireDiff = Cat(0.U(1.W), dLZC(lzc_width
      - 1, 0)) - Cat(0.U(1.W), aLZC(lzc_width - 1, 0)) // 7, 0\n150:   val lzcRegDiff
      = Cat(0.U(1.W), dLZCReg(lzc_width - 1, 0)) - Cat(0.U(1.W), aLZCReg(lzc_width
      - 1, 0))\n151:   val lzcDiff = Mux(state(s_pre_0), lzcWireDiff, lzcRegDiff)\n\
      152:   aIsZero := aLZC(lzc_width) // this is state pre_0\n153:   dIsZero :=
      dLZCReg(lzc_width) // this is pre_1 and all stages after\n154:   val dIsOne
      = dLZC(lzc_width - 1, 0).andR // this is pre_0\n155:   val noIterReg = RegEnable(dIsOne
      & aNormAbsReg(len - 1), state(s_pre_0)) // This means dividend has lzc 0 so
      iter is 17\n156:   noIter := noIterReg\n157:   val aTooSmallReg = RegEnable(aIsZero
      | lzcDiff(lzc_width), state(s_pre_0)) // a is zero or a smaller than d\n158:\
      \   aTooSmall := aTooSmallReg\n159: \n160:   val quotSign = Mux(state(s_idle),
      aSign ^ dSign, true.B) // if not s_idle then must be s_pre_1 & dIsZero, and
      that we have\n161:   val rSign = aSign\n162:   val quotSignReg = RegEnable(quotSign,
      startHandShake | (state(s_pre_1) & dIsZero))\n163:   val rSignReg = RegEnable(rSign,
      startHandShake)\n164: \n165:   val rShift = lzcDiff(0) // odd lzc diff, for
      SRT4\n166:   val rightShifted = Wire(UInt(len.W))\n167:   val rSumInit = Mux(aTooSmallReg
      | aIsZero, Cat(0.U(1.W), rightShifted, 0.U(3.W)), // right shift the dividend
      (which is already l-shifted)\n168:                     Mux(noIterReg, 0.U(itn_len.W),
      //\n169:                       Cat(0.U(3.W),\n170:                         \
      \  Mux(rShift, Cat(0.U(1.W), aNormAbsReg(len - 1, 0)), Cat(aNormAbsReg(len -
      1, 0), 0.U(1.W)))\n171:                         ) // Normal init value. 68,
      67; For even lzcDiff, 0.001xxx0; for odd lzcDiff 0.0001xxx\n172:           \
      \            )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 168-185
    context: "168:                     Mux(noIterReg, 0.U(itn_len.W), //\n169:   \
      \                    Cat(0.U(3.W),\n170:                           Mux(rShift,
      Cat(0.U(1.W), aNormAbsReg(len - 1, 0)), Cat(aNormAbsReg(len - 1, 0), 0.U(1.W)))\n\
      171:                         ) // Normal init value. 68, 67; For even lzcDiff,
      0.001xxx0; for odd lzcDiff 0.0001xxx\n172:                       )\n173:   \
      \                  ) // state is s_pre_1\n174:   val rCarryInit = 0.U(itn_len.W)\n\
      175: \n176:   val rightShifter = Module(new RightShifter(len, lzc_width))\n\
      177:   rightShifter.io.in := Mux(state(s_pre_1), aNormAbsReg(len - 1, 0), rPreShifted(len
      - 1, 0))\n178:   rightShifter.io.shiftNum := Mux(state(s_pre_1), aLZCReg,\n\
      179:                                   Mux(aTooSmallReg | dIsZero, 0.U(lzc_width.W),
      dLZCReg))\n180:   rightShifter.io.msb := state(s_post_1) & rSignReg & rPreShifted(len)\n\
      181:   rightShifted := rightShifter.io.out\n182: \n183:   // obtaining 1st quotient\n\
      184:   val rSumInitTrunc = Cat(0.U(1.W), rSumInit(itn_len - 4, itn_len - 4 -
      4 + 1)) // 0.00___\n185:   val mInitPos1 = MuxLookup(dNormAbsReg(len - 2, len
      - 2 - 3 + 1), \"b00100\".U(5.W))("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 207-219
    context: "207:     )\n208:   )\n209:   val initCmpPos1 = rSumInitTrunc >= mInitPos1\n\
      210:   val initCmpPos2 = rSumInitTrunc >= mInitPos2\n211:   val qInit = Mux(initCmpPos2,
      UIntToOH(quot_pos_2, 5), Mux(initCmpPos1, UIntToOH(quot_pos_1, 5), UIntToOH(quot_0,
      5)))\n212:   val qPrev = Mux(state(s_pre_1), qInit, qIterEnd)\n213:   val qPrevReg
      = RegEnable(qPrev, state(s_pre_1) | state(s_iter))\n214:   val specialDivisorReg
      = RegEnable(dNormAbsReg(len - 2, len - 2 - 3 + 1) === 0.U, state(s_pre_1)) //
      d=0.1000xxx\n215:   // rCarry and rSum in Iteration\n216:   val qXd = Mux1H(Seq(\n\
      217:     qPrevReg(quot_neg_2) -> Cat(dNormAbsReg(len - 1, 0), 0.U(4.W)), //
      68, 67 1.xxxxx0000\n218:     qPrevReg(quot_neg_1) -> Cat(0.U(1.W), dNormAbsReg(len
      - 1, 0), 0.U(3.W)), // 0.1xxxxx000\n219:     qPrevReg(quot_0)     -> 0.U(itn_len.W),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 215-226
    context: "215:   // rCarry and rSum in Iteration\n216:   val qXd = Mux1H(Seq(\n\
      217:     qPrevReg(quot_neg_2) -> Cat(dNormAbsReg(len - 1, 0), 0.U(4.W)), //
      68, 67 1.xxxxx0000\n218:     qPrevReg(quot_neg_1) -> Cat(0.U(1.W), dNormAbsReg(len
      - 1, 0), 0.U(3.W)), // 0.1xxxxx000\n219:     qPrevReg(quot_0)     -> 0.U(itn_len.W),\n\
      220:     qPrevReg(quot_pos_1) -> ~Cat(0.U(1.W), dNormAbsReg(len - 1, 0), 0.U(3.W)),
      // don't forget to plus 1 later\n221:     qPrevReg(quot_pos_2) -> ~Cat(dNormAbsReg(len
      - 1, 0), 0.U(4.W))  // don't forget to plus 1 later\n222:   ))\n223:   val csa
      = Module(new CSA3_2(itn_len))\n224: \n225:   val rSumIter = csa.io.out(0)\n\
      226:   val rCarryIter = Cat(csa.io.out(1)(itn_len - 2, 0), qPrevReg(quot_pos_1)
      | qPrevReg(quot_pos_2))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 222-233
    context: "222:   ))\n223:   val csa = Module(new CSA3_2(itn_len))\n224: \n225:\
      \   val rSumIter = csa.io.out(0)\n226:   val rCarryIter = Cat(csa.io.out(1)(itn_len
      - 2, 0), qPrevReg(quot_pos_1) | qPrevReg(quot_pos_2))\n227:   val rSumReg =
      RegEnable(Mux(state(s_pre_1), rSumInit, rSumIter), state(s_pre_1) | state(s_iter))
      // 68, 67\n228:   val rCarryReg = RegEnable(Mux(state(s_pre_1), rCarryInit,
      rCarryIter), state(s_pre_1) | state(s_iter))\n229:   csa.io.in(0) := rSumReg
      << 2\n230:   csa.io.in(1) := rCarryReg << 2\n231:   csa.io.in(2) := qXd\n232:\
      \ \n233:   val qds = Module(new SRT4QDS(len, itn_len))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 255-271
    context: "255:     qPrevReg(quot_neg_1) -> (quotM1IterReg << 2 | \"b10\".U),\n\
      256:     qPrevReg(quot_neg_2) -> (quotM1IterReg << 2 | \"b01\".U)\n257:   ))\n\
      258: \n259: \n260:   quotIter := Mux(state(s_pre_1),\n261:                 \
      \      Mux(dIsZero, VecInit(Seq.fill(len)(true.B)).asUInt,\n262:           \
      \              Mux(noIterReg, aNormAbsReg(len - 1, 0), 0.U(len.W))),\n263: \
      \                      Mux(state(s_iter), quotIterNext,\n264:              \
      \           Mux(quotSignReg, aInverter, quotIterReg)))\n265:   quotM1Iter :=
      Mux(state(s_pre_1),\n266:                         0.U(len.W), Mux(state(s_iter),
      quotIterM1Next,\n267:                           Mux(quotSignReg, dInverter,
      quotM1IterReg)))\n268: \n269: \n270:   // iter num\n271:   val iterNum = Wire(UInt((lzc_width
      - 1).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 267-279
    context: "267:                           Mux(quotSignReg, dInverter, quotM1IterReg)))\n\
      268: \n269: \n270:   // iter num\n271:   val iterNum = Wire(UInt((lzc_width
      - 1).W))\n272:   val iterNumReg = RegEnable(iterNum, state(s_pre_1) | state(s_iter))\n\
      273: \n274:   iterNum := Mux(state(s_pre_1), lzcDiff(lzc_width - 1, 1) +% lzcDiff(0),
      iterNumReg -% 1.U)\n275:   finalIter := iterNumReg === 0.U\n276: \n277:   //
      Post Process\n278: \n279:   when(rSignReg) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 287-297
    context: "287:   val r = aNormAbsReg\n288:   val rPd = dNormAbsReg\n289:   val
      rIsZero = ~(r.orR)\n290:   val needCorr = (~dIsZero & ~noIterReg) & Mux(rSignReg,
      ~r(len) & ~rIsZero, r(len)) // when we get pos rem for d<0 or neg rem for d>0\n\
      291:   rPreShifted := Mux(needCorr, rPd, r)\n292:   val rFinal = RegEnable(rightShifted,
      state(s_post_1))// right shifted remainder. shift by the number of bits divisor
      is shifted\n293:   val qFinal = Mux(needCorr, quotM1IterReg, quotIterReg)\n\
      294:   val res = Mux(isHi, rFinal, qFinal)\n295:   io.out_data := Mux(isW,\n\
      296:     SignExt(res(31, 0), len),\n297:     res"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 294-305
    context: "294:   val res = Mux(isHi, rFinal, qFinal)\n295:   io.out_data := Mux(isW,\n\
      296:     SignExt(res(31, 0), len),\n297:     res\n298:   )\n299:   io.in_ready
      := state(s_idle)\n300:   io.out_valid := state(s_finish) // state === s_finish\n\
      301: }\n302: \n303: class RightShifter(len: Int, lzc_width: Int) extends Module
      {\n304:   val io = IO(new Bundle() {\n305:     val shiftNum = Input(UInt(lzc_width.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 428-438
    context: "428: }\n429: \n430: \n431: class SRT4Divider(len: Int)(implicit p: Parameters)
      extends AbstractDivider(len) {\n432: \n433:   val newReq = io.in.fire\n434:\
      \ \n435:   val uop = io.in.bits.uop\n436:   val uopReg = RegEnable(uop, newReq)\n\
      437:   val ctrlReg = RegEnable(ctrl, newReq)\n438: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 436-447
    context: "436:   val uopReg = RegEnable(uop, newReq)\n437:   val ctrlReg = RegEnable(ctrl,
      newReq)\n438: \n439:   val divDataModule = Module(new SRT4DividerDataModule(len))\n\
      440: \n441:   val kill_w = uop.robIdx.needFlush(io.redirectIn)\n442:   val kill_r
      = !divDataModule.io.in_ready && uopReg.robIdx.needFlush(io.redirectIn)\n443:\
      \ \n444:   divDataModule.io.src(0) := io.in.bits.src(0)\n445:   divDataModule.io.src(1)
      := io.in.bits.src(1)\n446:   divDataModule.io.valid := io.in.valid\n447:   divDataModule.io.sign
      := sign"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT4Divider.scala
    lines: 447-458
    context: "447:   divDataModule.io.sign := sign\n448:   divDataModule.io.kill_w
      := kill_w\n449:   divDataModule.io.kill_r := kill_r\n450:   divDataModule.io.isHi
      := ctrlReg.isHi\n451:   divDataModule.io.isW := ctrlReg.isW\n452:   divDataModule.io.out_ready
      := io.out.ready\n453: \n454:   io.in.ready := divDataModule.io.in_ready\n455:\
      \   io.out.valid := divDataModule.io.out_valid\n456:   io.out.bits.data := divDataModule.io.out_data\n\
      457:   io.out.bits.uop := uopReg\n458: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/FMA.scala
    lines: 20-37
    context: "20:   private val src2 = inData.src(2)\n21: \n22:   // modules\n23:\
      \   private val fma = Module(new FloatFMA)\n24: \n25:   val fp_aIsFpCanonicalNAN\
      \  = fp_fmt === VSew.e32 && !src0.head(32).andR ||\n26:                    \
      \           fp_fmt === VSew.e16 && !src0.head(48).andR\n27:   val fp_bIsFpCanonicalNAN\
      \  = fp_fmt === VSew.e32 && !src1.head(32).andR ||\n28:                    \
      \           fp_fmt === VSew.e16 && !src1.head(48).andR\n29:   val fp_cIsFpCanonicalNAN\
      \  = !(opcode === VfmaType.vfmul) && (fp_fmt === VSew.e32 && !src2.head(32).andR
      ||\n30:                               fp_fmt === VSew.e16 && !src2.head(48).andR)\n\
      31: \n32:   fma.io.fire         := io.in.valid\n33:   fma.io.fp_a         :=
      src0\n34:   fma.io.fp_b         := src1\n35:   fma.io.fp_c         := src2\n\
      36:   fma.io.round_mode   := rm\n37:   fma.io.fp_format    := fp_fmt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/FMA.scala
    lines: 39-48
    context: "39:   fma.io.fp_aIsFpCanonicalNAN := fp_aIsFpCanonicalNAN\n40:   fma.io.fp_bIsFpCanonicalNAN
      := fp_bIsFpCanonicalNAN\n41:   fma.io.fp_cIsFpCanonicalNAN := fp_cIsFpCanonicalNAN\n\
      42: \n43:   private val resultData = fma.io.fp_result\n44:   private val fflagsData
      = fma.io.fflags\n45: \n46:   io.out.bits.res.fflags.get := fflagsData\n47: \
      \  io.out.bits.res.data       := resultData\n48: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VCVT.scala
    lines: 38-49
    context: "38: \n39:   val widen = opcode(4, 3) // 0->single 1->widen 2->norrow
      => width of result\n40:   val isSingleCvt = !widen(1) & !widen(0)\n41:   val
      isWidenCvt = !widen(1) & widen(0)\n42:   val isNarrowCvt = widen(1) & !widen(0)\n\
      43:   val fire = io.in.valid\n44:   val fireReg = GatedValidRegNext(fire)\n\
      45: \n46:   // output width 8 16 32 64\n47:   val output1H = Wire(UInt(4.W))\n\
      48:   output1H := chisel3.util.experimental.decode.decoder(\n49:     widen ##
      sew,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VCVT.scala
    lines: 73-83
    context: "73:   \n74:   // May be useful in the future.\n75:   // val outIsMvInst
      = outCtrl.fuOpType === FuOpType.FMVXF\n76:   val outIsMvInst = false.B\n77:\
      \ \n78:   val outEew = RegEnable(RegEnable(Mux1H(output1H, Seq(0,1,2,3).map(i
      => i.U)), fire), fireReg)\n79:   private val needNoMask = outVecCtrl.fpu.isFpToVecInst\n\
      80:   val maskToMgu = Mux(needNoMask, allMaskTrue, outSrcMask)\n81: \n82:  \
      \ // modules\n83:   private val vfcvt = Module(new VectorCvtTop(dataWidth, dataWidthOfDataModule))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VCVT.scala
    lines: 95-108
    context: "95:   vfcvt.sew := sew\n96:   vfcvt.rm := vfcvtRm\n97:   vfcvt.outputWidth1H
      := outputWidth1H\n98:   vfcvt.isWiden := isWidenCvt\n99:   vfcvt.isNarrow :=
      isNarrowCvt\n100:   vfcvt.fire := fire\n101:   vfcvt.isFpToVecInst := vecCtrl.fpu.isFpToVecInst\n\
      102:   val vfcvtResult = vfcvt.io.result\n103:   val vfcvtFflags = vfcvt.io.fflags\n\
      104: \n105:   /** fflags:\n106:    */\n107:   val eNum1H = chisel3.util.experimental.decode.decoder(sew
      ## (isWidenCvt || isNarrowCvt),\n108:     TruthTable("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VCVT.scala
    lines: 116-126
    context: "116:       ),\n117:       BitPat.N(4)\n118:     )\n119:   )\n120:  \
      \ val eNum1HEffect = Mux(isWidenCvt || isNarrowCvt, eNum1H << 1, eNum1H)\n121:\
      \   val eNumMax1H = Mux(lmul.head(1).asBool, eNum1HEffect >> ((~lmul.tail(1)).asUInt
      +1.U), eNum1HEffect << lmul.tail(1)).asUInt(6, 0)\n122:   val eNumMax = Mux1H(eNumMax1H,
      Seq(1,2,4,8,16,32,64).map(i => i.U)) //only for cvt intr, don't exist 128 in
      cvt\n123:   val vlForFflags = Mux(vecCtrl.fpu.isFpToVecInst, 1.U, vl)\n124:\
      \   val eNumEffectIdx = Mux(vlForFflags > eNumMax, eNumMax, vlForFflags)\n125:\
      \ \n126:   val eNum = Mux1H(eNum1H, Seq(1, 2, 4, 8).map(num =>num.U))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VCVT.scala
    lines: 130-144
    context: "130:   val mask =  Mux1H(eNum1H, Seq(1, 2, 4, 8).map(num => maskPart(num-1,
      0)))\n131:   val fflagsEn = Wire(Vec(4 * numVecModule, Bool()))\n132: \n133:\
      \   fflagsEn := mask.asBools.zipWithIndex.map{case(mask, i) => mask & (eNumEffectIdx
      > eStart + i.U) }\n134: \n135:   val fflagsEnCycle2 = RegEnable(RegEnable(fflagsEn,
      fire), fireReg)\n136:   val fflagsAll = Wire(Vec(8, UInt(5.W)))\n137:   fflagsAll
      := vfcvtFflags.asTypeOf(fflagsAll)\n138:   val fflags = fflagsEnCycle2.zip(fflagsAll).map{case(en,
      fflag) => Mux(en, fflag, 0.U(5.W))}.reduce(_ | _)\n139:   io.out.bits.res.fflags.get
      := Mux(outIsMvInst, 0.U, fflags)\n140: \n141: \n142:   /**\n143:    * [[mgu]]'s
      in connection\n144:    */"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VCVT.scala
    lines: 143-153
    context: "143:    * [[mgu]]'s in connection\n144:    */\n145:   val resultDataUInt
      = Wire(UInt(dataWidth.W))\n146:   resultDataUInt := vfcvtResult\n147: \n148:\
      \   private val narrow = RegEnable(RegEnable(isNarrowCvt, fire), fireReg)\n\
      149:   private val narrowNeedCat = outVecCtrl.vuopIdx(0).asBool && narrow\n\
      150:   private val outNarrowVd = Mux(narrowNeedCat, Cat(resultDataUInt(dataWidth
      / 2 - 1, 0), outOldVd(dataWidth / 2 - 1, 0)), \n151:                       \
      \                         Cat(outOldVd(dataWidth - 1, dataWidth / 2), resultDataUInt(dataWidth
      / 2 - 1, 0)))\n152: \n153:   // mgu.io.in.vd := resultDataUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VCVT.scala
    lines: 178-188
    context: "178:   )\n179:   io.out.bits.ctrl.exceptionVec.get(ExceptionNO.illegalInstr)
      := mgu.io.out.illegal\n180: }\n181: \n182: class VectorCvtTopIO(vlen: Int, xlen:
      Int) extends Bundle{\n183:   val fire = Input(Bool())\n184:   val uopIdx = Input(Bool())\n\
      185:   val src = Input(Vec(vlen / xlen, UInt(xlen.W)))\n186:   val opType =
      Input(UInt(8.W))\n187:   val sew = Input(UInt(2.W))\n188:   val rm = Input(UInt(3.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VCVT.scala
    lines: 190-200
    context: "190:   val isWiden = Input(Bool())\n191:   val isNarrow = Input(Bool())\n\
      192:   val isFpToVecInst = Input(Bool())\n193: \n194:   val result = Output(UInt(vlen.W))\n\
      195:   val fflags = Output(UInt((vlen/16*5).W))\n196: }\n197: \n198: \n199:\
      \ \n200: //according to uopindex, 1: high64 0:low64"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VCVT.scala
    lines: 199-212
    context: "199: \n200: //according to uopindex, 1: high64 0:low64\n201: class VectorCvtTop(vlen:
      Int, xlen: Int) extends Module{\n202:   val io = IO(new VectorCvtTopIO(vlen,
      xlen))\n203: \n204:   val (fire, uopIdx, src, opType, sew, rm, outputWidth1H,
      isWiden, isNarrow, isFpToVecInst) = (\n205:     io.fire, io.uopIdx, io.src,
      io.opType, io.sew, io.rm, io.outputWidth1H, io.isWiden, io.isNarrow, io.isFpToVecInst\n\
      206:   )\n207:   val fireReg = GatedValidRegNext(fire)\n208: \n209:   val in0
      = Mux(isWiden && !isFpToVecInst,\n210:     Mux(uopIdx, src(1).tail(32), src(0).tail(32)),\n\
      211:     src(0)\n212:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VCVT.scala
    lines: 210-225
    context: "210:     Mux(uopIdx, src(1).tail(32), src(0).tail(32)),\n211:     src(0)\n\
      212:   )\n213: \n214:   val in1 = Mux(isWiden,\n215:     Mux(uopIdx, src(1).head(32),
      src(0).head(32)),\n216:     src(1)\n217:   )\n218: \n219:   val vectorCvt0 =
      Module(new VectorCvt(xlen))\n220:   vectorCvt0.fire := fire\n221:   vectorCvt0.src
      := in0\n222:   vectorCvt0.opType := opType\n223:   vectorCvt0.sew := sew\n224:\
      \   vectorCvt0.rm := rm\n225:   vectorCvt0.isFpToVecInst := isFpToVecInst"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VCVT.scala
    lines: 225-235
    context: "225:   vectorCvt0.isFpToVecInst := isFpToVecInst\n226:   vectorCvt0.isFround
      := 0.U\n227:   vectorCvt0.isFcvtmod := false.B\n228: \n229:   val vectorCvt1
      = Module(new VectorCvt(xlen))\n230:   vectorCvt1.fire := fire\n231:   vectorCvt1.src
      := in1\n232:   vectorCvt1.opType := opType\n233:   vectorCvt1.sew := sew\n234:\
      \   vectorCvt1.rm := rm\n235:   vectorCvt1.isFpToVecInst := isFpToVecInst"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VCVT.scala
    lines: 234-245
    context: "234:   vectorCvt1.rm := rm\n235:   vectorCvt1.isFpToVecInst := isFpToVecInst\n\
      236:   vectorCvt1.isFround := 0.U\n237:   vectorCvt1.isFcvtmod := false.B\n\
      238: \n239:   val isNarrowCycle2 = RegEnable(RegEnable(isNarrow, fire), fireReg)\n\
      240:   val outputWidth1HCycle2 = RegEnable(RegEnable(outputWidth1H, fire), fireReg)\n\
      241: \n242:   //cycle2\n243:   io.result := Mux(isNarrowCycle2,\n244:     vectorCvt1.io.result.tail(32)
      ## vectorCvt0.io.result.tail(32),\n245:     vectorCvt1.io.result ## vectorCvt0.io.result)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VCVT.scala
    lines: 242-255
    context: "242:   //cycle2\n243:   io.result := Mux(isNarrowCycle2,\n244:     vectorCvt1.io.result.tail(32)
      ## vectorCvt0.io.result.tail(32),\n245:     vectorCvt1.io.result ## vectorCvt0.io.result)\n\
      246: \n247:   io.fflags := Mux1H(outputWidth1HCycle2, Seq(\n248:     vectorCvt1.io.fflags
      ## vectorCvt0.io.fflags,\n249:     Mux(isNarrowCycle2, vectorCvt1.io.fflags.tail(10)
      ## vectorCvt0.io.fflags.tail(10), vectorCvt1.io.fflags ## vectorCvt0.io.fflags),\n\
      250:     Mux(isNarrowCycle2, vectorCvt1.io.fflags(4,0) ## vectorCvt0.io.fflags(4,0),
      vectorCvt1.io.fflags.tail(10) ## vectorCvt0.io.fflags.tail(10)),\n251:     vectorCvt1.io.fflags(4,0)
      ## vectorCvt0.io.fflags(4,0)\n252:   ))\n253: }\n254: \n255: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VIMacU.scala
    lines: 94-106
    context: "94: \n95:   private val vs2VecUsed: Vec[UInt] = Mux(widen, vs2GroupedVec,
      vs2Split.io.outVec64b)\n96:   private val vs1VecUsed: Vec[UInt] = Mux(widen,
      vs1GroupedVec, vs1Split.io.outVec64b)\n97:   private val oldVdVecUsed: Vec[UInt]
      = WireInit(oldVdSplit.io.outVec64b)\n98: \n99:   vimacs.zipWithIndex.foreach
      {\n100:     case (mod, i) =>\n101:       mod.io.fire        := io.in.valid\n\
      102:       mod.io.info.vm     := vm\n103:       mod.io.info.ma     := vma\n\
      104:       mod.io.info.ta     := vta\n105:       mod.io.info.vlmul  := vlmul\n\
      106:       mod.io.info.vl     := srcVConfig.vl"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VIPU.scala
    lines: 61-71
    context: "61:     BitPat(VipuType.vredsum_vs)   -> List(BitPat(VAluOpcode.vredsum),
      uSew, uSew, uSew),\n62:     BitPat(VipuType.vredmaxu_vs)  -> List(BitPat(VAluOpcode.vredmax),
      uSew, uSew, uSew),\n63:     BitPat(VipuType.vredmax_vs)   -> List(BitPat(VAluOpcode.vredmax),
      sSew, sSew, sSew),\n64:     BitPat(VipuType.vredminu_vs)  -> List(BitPat(VAluOpcode.vredmin),
      uSew, uSew, uSew),\n65:     BitPat(VipuType.vredmin_vs)   -> List(BitPat(VAluOpcode.vredmin),
      sSew, sSew, sSew),\n66:     BitPat(VipuType.vredand_vs)   -> List(BitPat(VAluOpcode.vredand),
      uSew, uSew, uSew),\n67:     BitPat(VipuType.vredor_vs)    -> List(BitPat(VAluOpcode.vredor),
      uSew, uSew, uSew),\n68:     BitPat(VipuType.vredxor_vs)   -> List(BitPat(VAluOpcode.vredxor),
      uSew, uSew, uSew),\n69: \n70:     BitPat(VipuType.vwredsumu_vs) -> List(BitPat(VAluOpcode.vredsum),
      uSew, uSew, uSew2),\n71:     BitPat(VipuType.vwredsum_vs)  -> List(BitPat(VAluOpcode.vredsum),
      sSew, sSew, sSew2),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VIPU.scala
    lines: 80-90
    context: "80:     BitPat(VipuType.vid_v)        -> List(BitPat(VAluOpcode.vid),
      uSew, uSew, uSew),\n81:     BitPat(VipuType.vmv_x_s)      -> List(BitPat(VAluOpcode.vmvxs),
      uSew, uSew, uSew)\n82:   )\n83:   val decoder = DecodeLogic(io.in.fuOpType,
      default, decodeTable)\n84:   val outsig = Seq(io.out.opcode, io.out.srcType2,
      io.out.srcType1, io.out.vdType)\n85:   outsig.zip(decoder).foreach({case (s,
      d) => s := d})\n86: }\n87: \n88: class VIPU(cfg: FuConfig)(implicit p: Parameters)
      extends VecPipedFuncUnit(cfg) {\n89:   XSError(io.in.valid && io.in.bits.ctrl.fuOpType
      === VipuType.dummy, \"VIPU OpType not supported\")\n90: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/Alu.scala
    lines: 6-23
    context: "6: import xiangshan.backend.fu.FuConfig\n7: \n8: class Alu(cfg: FuConfig)(implicit
      p: Parameters) extends PipedFuncUnit(cfg) {\n9:   private val aluModule = Module(new
      AluDataModule)\n10: \n11:   private val flushed = io.in.bits.ctrl.robIdx.needFlush(io.flush)\n\
      12: \n13:   io.out.valid := io.in.valid\n14:   io.in.ready := io.out.ready\n\
      15: \n16:   private val in = io.in.bits\n17:   private val out = io.out.bits\n\
      18:   aluModule.io.src.zip(in.data.src).foreach { case (sink, source) =>\n19:\
      \     sink := source\n20:   }\n21:   aluModule.io.func := in.ctrl.fuOpType\n\
      22:   out.res.data := aluModule.io.result\n23: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFMA.scala
    lines: 52-64
    context: "52:   private val resultData = Wire(Vec(numVecModule, UInt(dataWidthOfDataModule.W)))\n\
      53:   private val fflagsData = Wire(Vec(numVecModule, UInt(20.W)))\n54:   val
      fp_aIsFpCanonicalNAN = Wire(Vec(numVecModule, Bool()))\n55:   val fp_bIsFpCanonicalNAN
      = Wire(Vec(numVecModule, Bool()))\n56:   val fp_cIsFpCanonicalNAN = Wire(Vec(numVecModule,
      Bool()))\n57:   vfmas.zipWithIndex.foreach {\n58:     case (mod, i) =>\n59:\
      \       mod.io.fire         := io.in.valid\n60:       mod.io.fp_a         :=
      vs2Split.io.outVec64b(i)\n61:       mod.io.fp_b         := vs1Split.io.outVec64b(i)\n\
      62:       mod.io.fp_c         := oldVdSplit.io.outVec64b(i)\n63:       mod.io.widen_a\
      \      := Cat(vs2Split.io.outVec32b(i+numVecModule), vs2Split.io.outVec32b(i))\n\
      64:       mod.io.widen_b      := Cat(vs1Split.io.outVec32b(i+numVecModule),
      vs1Split.io.outVec32b(i))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFMA.scala
    lines: 60-71
    context: "60:       mod.io.fp_a         := vs2Split.io.outVec64b(i)\n61:     \
      \  mod.io.fp_b         := vs1Split.io.outVec64b(i)\n62:       mod.io.fp_c  \
      \       := oldVdSplit.io.outVec64b(i)\n63:       mod.io.widen_a      := Cat(vs2Split.io.outVec32b(i+numVecModule),
      vs2Split.io.outVec32b(i))\n64:       mod.io.widen_b      := Cat(vs1Split.io.outVec32b(i+numVecModule),
      vs1Split.io.outVec32b(i))\n65:       mod.io.frs1         := 0.U     // already
      vf -> vv\n66:       mod.io.is_frs1      := false.B // already vf -> vv\n67:\
      \       mod.io.uop_idx      := vuopIdx(0)\n68:       mod.io.is_vec       :=
      true.B // Todo\n69:       mod.io.round_mode   := rm\n70:       mod.io.fp_format\
      \    := Mux(resWiden, vsew + 1.U, vsew)\n71:       mod.io.res_widening := resWiden"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFMA.scala
    lines: 69-90
    context: "69:       mod.io.round_mode   := rm\n70:       mod.io.fp_format    :=
      Mux(resWiden, vsew + 1.U, vsew)\n71:       mod.io.res_widening := resWiden\n\
      72:       mod.io.op_code      := opcode\n73:       resultData(i) := mod.io.fp_result\n\
      74:       fflagsData(i) := mod.io.fflags\n75:       fp_aIsFpCanonicalNAN(i)
      := vecCtrl.fpu.isFpToVecInst & (\n76:         ((vsew === VSew.e32) & (!vs2Split.io.outVec64b(i).head(32).andR))
      |\n77:           ((vsew === VSew.e16) & (!vs2Split.io.outVec64b(i).head(48).andR))\n\
      78:         )\n79:       fp_bIsFpCanonicalNAN(i) := vecCtrl.fpu.isFpToVecInst
      & (\n80:         ((vsew === VSew.e32) & (!vs1Split.io.outVec64b(i).head(32).andR))
      |\n81:           ((vsew === VSew.e16) & (!vs1Split.io.outVec64b(i).head(48).andR))\n\
      82:         )\n83:       fp_cIsFpCanonicalNAN(i) := !(opcode === VfmaType.vfmul)
      & vecCtrl.fpu.isFpToVecInst & (\n84:         ((vsew === VSew.e32) & (!oldVdSplit.io.outVec64b(i).head(32).andR))
      |\n85:           ((vsew === VSew.e16) & (!oldVdSplit.io.outVec64b(i).head(48).andR))\n\
      86:         )\n87:       mod.io.fp_aIsFpCanonicalNAN := fp_aIsFpCanonicalNAN(i)\n\
      88:       mod.io.fp_bIsFpCanonicalNAN := fp_bIsFpCanonicalNAN(i)\n89:      \
      \ mod.io.fp_cIsFpCanonicalNAN := fp_cIsFpCanonicalNAN(i)\n90:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFMA.scala
    lines: 139-151
    context: "139:   )\n140:   allFFlagsEn := (fflagsEn & vlMaskEn).asTypeOf(allFFlagsEn)\n\
      141: \n142:   val allFFlags = fflagsData.asTypeOf(Vec(4 * numVecModule, UInt(5.W)))\n\
      143:   val outFFlags = allFFlagsEn.zip(allFFlags).map {\n144:     case (en,
      fflags) => Mux(en, fflags, 0.U(5.W))\n145:   }.reduce(_ | _)\n146:   io.out.bits.res.fflags.get
      := outFFlags\n147: \n148:   val resultDataUInt = resultData.asUInt\n149:   mgu.io.in.vd
      := resultDataUInt\n150:   mgu.io.in.oldVd := outOldVd\n151:   mgu.io.in.mask
      := maskToMgu"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VIAluFix.scala
    lines: 173-183
    context: "173:   oldVdSplit.io.inVecData := oldVd\n174: \n175:   /**\n176:   \
      \ * [[vIntFixpAlus]]'s in connection\n177:    */\n178:   private val opcode
      = VialuFixType.getOpcode(inCtrl.fuOpType).asTypeOf(vIntFixpAlus.head.io.opcode)\n\
      179:   private val vs1Type = typeMod.io.out.vs1Type\n180:   private val vs2Type
      = typeMod.io.out.vs2Type\n181:   private val vdType = typeMod.io.out.vdType\n\
      182:   private val isVextF2 = typeMod.io.out.isVextF2\n183:   private val isVextF4
      = typeMod.io.out.isVextF4"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VIAluFix.scala
    lines: 230-242
    context: "230:   private val eewVd_is_1b = vdType === VdType.mask\n231:   private
      val maskUsed = splitMask(maskDataVec(maskIdx), Mux(eewVd_is_1b, eewVs1, eewVd))\n\
      232: \n233:   private val oldVdUsed = splitMask(VecDataToMaskDataVec(oldVd,
      vs1Type(1, 0))(vuopIdx), eewVs1)\n234: \n235:   vIntFixpAlus.zipWithIndex.foreach
      {\n236:     case (mod, i) =>\n237:       mod.io.fire := io.in.valid\n238:  \
      \     mod.io.opcode := opcode\n239: \n240:       mod.io.info.vm := vm\n241:\
      \       mod.io.info.ma := vma\n242:       mod.io.info.ta := vta"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VIAluFix.scala
    lines: 279-289
    context: "279:     outIsVwsllEewVdIs16 -> Cat(outVdTmp(127, 112), outVdTmp(63,
      48), outVdTmp(111, 96), outVdTmp(47, 32), outVdTmp(95, 80), outVdTmp(31, 16),
      outVdTmp(79, 64), outVdTmp(15,0)),\n280:   ))\n281:   private val outCmp = Mux1H(outEewVs1.oneHot,
      Seq(8, 4, 2, 1).map(\n282:     k => Cat(vIntFixpAlus.reverse.map(_.io.cmpOut(k
      - 1, 0)))))\n283:   private val outNarrow = Cat(vIntFixpAlus.reverse.map(_.io.narrowVd))\n\
      284:   private val outOpcode = VialuFixType.getOpcode(outCtrl.fuOpType).asTypeOf(vIntFixpAlus.head.io.opcode)\n\
      285: \n286:   private val numBytes = dataWidth / 8\n287:   private val maxMaskIdx
      = numBytes\n288:   private val maxVdIdx = 8\n289:   private val elementsInOneUop
      = Mux1H(outEewVs1.oneHot, Seq(1, 2, 4, 8).map(k => (numBytes / k).U(5.W)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/JumpUnit.scala
    lines: 1-11
    context: "1: package xiangshan.backend.fu.wrapper\n2: \n3: import org.chipsalliance.cde.config.Parameters\n\
      4: import chisel3._\n5: import utility.{SignExt, ZeroExt}\n6: import xiangshan.RedirectLevel\n\
      7: import xiangshan.backend.fu.{FuConfig, FuncUnit, JumpDataModule, PipedFuncUnit}\n\
      8: import xiangshan.backend.datapath.DataConfig.VAddrData\n9: \n10: \n11: class
      JumpUnit(cfg: FuConfig)(implicit p: Parameters) extends PipedFuncUnit(cfg) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/JumpUnit.scala
    lines: 9-19
    context: "9: \n10: \n11: class JumpUnit(cfg: FuConfig)(implicit p: Parameters)
      extends PipedFuncUnit(cfg) {\n12:   private val jumpDataModule = Module(new
      JumpDataModule)\n13: \n14:   private val flushed = io.in.bits.ctrl.robIdx.needFlush(io.flush)\n\
      15: \n16:   // associated with AddrData's position of JmpCfg.srcData\n17:  \
      \ private val src = io.in.bits.data.src(0)\n18:   private val pc = Mux(io.instrAddrTransType.get.shouldBeSext,\n\
      19:     SignExt(io.in.bits.data.pc.get, cfg.destDataBits),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/JumpUnit.scala
    lines: 31-59
    context: "31:   jumpDataModule.io.isRVC := isRVC\n32: \n33:   val jmpTarget =
      io.in.bits.ctrl.predictInfo.get.target\n34:   val predTaken = io.in.bits.ctrl.predictInfo.get.taken\n\
      35: \n36:   val redirect = io.out.bits.res.redirect.get.bits\n37:   val redirectValid
      = io.out.bits.res.redirect.get.valid\n38:   redirectValid := io.in.valid &&
      !jumpDataModule.io.isAuipc\n39:   redirect := 0.U.asTypeOf(redirect)\n40:  \
      \ redirect.level := RedirectLevel.flushAfter\n41:   redirect.robIdx := io.in.bits.ctrl.robIdx\n\
      42:   redirect.ftqIdx := io.in.bits.ctrl.ftqIdx.get\n43:   redirect.ftqOffset
      := io.in.bits.ctrl.ftqOffset.get\n44:   redirect.fullTarget := jumpDataModule.io.target\n\
      45:   redirect.cfiUpdate.predTaken := true.B\n46:   redirect.cfiUpdate.taken
      := true.B\n47:   redirect.cfiUpdate.target := jumpDataModule.io.target\n48:\
      \   redirect.cfiUpdate.pc := io.in.bits.data.pc.get\n49:   redirect.cfiUpdate.isMisPred
      := jumpDataModule.io.target(VAddrData().dataWidth - 1, 0) =/= jmpTarget || !predTaken\n\
      50:   redirect.cfiUpdate.backendIAF := io.instrAddrTransType.get.checkAccessFault(jumpDataModule.io.target)\n\
      51:   redirect.cfiUpdate.backendIPF := io.instrAddrTransType.get.checkPageFault(jumpDataModule.io.target)\n\
      52:   redirect.cfiUpdate.backendIGPF := io.instrAddrTransType.get.checkGuestPageFault(jumpDataModule.io.target)\n\
      53: //  redirect.debug_runahead_checkpoint_id := uop.debugInfo.runahead_checkpoint_id
      // Todo: assign it\n54: \n55:   io.in.ready := io.out.ready\n56:   io.out.valid
      := io.in.valid\n57:   io.out.bits.res.data := jumpDataModule.io.result\n58:\
      \   connect0LatencyCtrlSingal\n59: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFALU.scala
    lines: 25-35
    context: "25:   private val opcode  = fuOpType(4,0)\n26:   private val resWiden\
      \  = fuOpType(5)\n27:   private val opbWiden  = fuOpType(6)\n28: \n29:   //
      modules\n30:   private val vfalus = Seq.fill(numVecModule)(Module(new VectorFloatAdder))\n\
      31:   private val vs2Split = Module(new VecDataSplitModule(dataWidth, dataWidthOfDataModule))\n\
      32:   private val vs1Split = Module(new VecDataSplitModule(dataWidth, dataWidthOfDataModule))\n\
      33:   private val oldVdSplit  = Module(new VecDataSplitModule(dataWidth, dataWidthOfDataModule))\n\
      34:   private val mgu = Module(new Mgu(dataWidth))\n35:   private val mgtu =
      Module(new Mgtu(dataWidth))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFALU.scala
    lines: 68-78
    context: "68:     ))\n69:   )\n70:   val vlMaskForReduction = (~(Fill(VLEN, 1.U)
      << vl)).asUInt\n71:   srcMaskRShiftForReduction := ((srcMask & vlMaskForReduction)
      >> maskRshiftWidthForReduction)(8 * numVecModule - 1, 0)\n72:   val existMask
      = (srcMask & vlMaskForReduction).orR\n73:   val existMaskReg = RegEnable(existMask,
      io.in.fire)\n74: \n75: \n76:   def genMaskForReduction(inmask: UInt, sew: UInt,
      i: Int): UInt = {\n77:     val f64MaskNum = dataWidth / 64 * 2\n78:     val
      f32MaskNum = dataWidth / 32 * 2"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFALU.scala
    lines: 222-240
    context: "222:   srcMaskRShift := (srcMask >> maskRshiftWidth)(4 * numVecModule
      - 1, 0)\n223:   val fp_aIsFpCanonicalNAN = Wire(Vec(numVecModule,Bool()))\n\
      224:   val fp_bIsFpCanonicalNAN = Wire(Vec(numVecModule,Bool()))\n225:   val
      inIsFold = Wire(UInt(3.W))\n226:   inIsFold := Cat(vecCtrl.fpu.isFoldTo1_8,
      vecCtrl.fpu.isFoldTo1_4, vecCtrl.fpu.isFoldTo1_2)\n227:   vfalus.zipWithIndex.foreach
      {\n228:     case (mod, i) =>\n229:       mod.io.fire             := io.in.valid\n\
      230:       mod.io.fp_a             := vs2Split.io.outVec64b(i)\n231:       mod.io.fp_b\
      \             := vs1Split.io.outVec64b(i)\n232:       mod.io.widen_a       \
      \   := Cat(vs2Split.io.outVec32b(i+numVecModule), vs2Split.io.outVec32b(i))\n\
      233:       mod.io.widen_b          := Cat(vs1Split.io.outVec32b(i+numVecModule),
      vs1Split.io.outVec32b(i))\n234:       mod.io.frs1             := 0.U     //
      already vf -> vv\n235:       mod.io.is_frs1          := false.B // already vf
      -> vv\n236:       mod.io.mask             := Mux(isScalarMove, !vuopIdx.orR,
      genMaskForMerge(inmask = srcMaskRShift, sew = vsew, i = i))\n237:       mod.io.maskForReduction
      := genMaskForReduction(inmask = srcMaskRShiftForReduction, sew = vsew, i = i)\n\
      238:       mod.io.uop_idx          := vuopIdx(0)\n239:       mod.io.is_vec \
      \          := true.B // Todo\n240:       mod.io.round_mode       := rm"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFALU.scala
    lines: 244-261
    context: "244:       mod.io.op_code          := opcode\n245:       mod.io.is_vfwredosum\
      \    := fuOpType === VfaluType.vfwredosum\n246:       mod.io.is_fold       \
      \   := inIsFold\n247:       mod.io.vs2_fold         := vs2      // for better
      timing\n248:       resultData(i)           := mod.io.fp_result\n249:       fflagsData(i)\
      \           := mod.io.fflags\n250:       fp_aIsFpCanonicalNAN(i) := vecCtrl.fpu.isFpToVecInst
      & (\n251:           ((vsew === VSew.e32) & (!vs2Split.io.outVec64b(i).head(32).andR))
      |\n252:           ((vsew === VSew.e16) & (!vs2Split.io.outVec64b(i).head(48).andR))\n\
      253:         )\n254:       fp_bIsFpCanonicalNAN(i) := vecCtrl.fpu.isFpToVecInst
      & (\n255:           ((vsew === VSew.e32) & (!vs1Split.io.outVec64b(i).head(32).andR))
      |\n256:           ((vsew === VSew.e16) & (!vs1Split.io.outVec64b(i).head(48).andR))\n\
      257:         )\n258:       mod.io.fp_aIsFpCanonicalNAN := fp_aIsFpCanonicalNAN(i)\n\
      259:       mod.io.fp_bIsFpCanonicalNAN := fp_bIsFpCanonicalNAN(i)\n260:   }\n\
      261:   val outVuopidx = outVecCtrl.vuopIdx(2, 0) // for vfadd max vuopidx=7"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFALU.scala
    lines: 258-269
    context: "258:       mod.io.fp_aIsFpCanonicalNAN := fp_aIsFpCanonicalNAN(i)\n\
      259:       mod.io.fp_bIsFpCanonicalNAN := fp_bIsFpCanonicalNAN(i)\n260:   }\n\
      261:   val outVuopidx = outVecCtrl.vuopIdx(2, 0) // for vfadd max vuopidx=7\n\
      262:   val numOfUopVFRED = Wire(UInt(4.W))\n263:   val numofUopVFREDReg = RegEnable(numOfUopVFRED,
      io.in.fire)\n264:   val vs1Reg = RegEnable(vs1, io.in.fire)\n265:   val outIsVfRedUnordered
      = outCtrl.fuOpType === VfaluType.vfredusum ||\n266:     outCtrl.fuOpType ===
      VfaluType.vfredmax ||\n267:     outCtrl.fuOpType === VfaluType.vfredmin\n268:\
      \   val outIsVfRedUnComp = outCtrl.fuOpType === VfaluType.vfredmax ||\n269:\
      \     outCtrl.fuOpType === VfaluType.vfredmin"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFALU.scala
    lines: 299-312
    context: "299:     }\n300:     else if(i <  dataWidth / 16) {\n301:       cmpResult(i)
      := Mux(outVecCtrl.vsew === 1.U, resultDataUInt(i*16), false.B)\n302:     }\n\
      303:   }\n304:   val outCtrl_s0 = ctrlVec.head\n305:   val outVecCtrl_s0 = ctrlVec.head.vpu.get\n\
      306:   val outEew_s0 = Mux(resWiden, outVecCtrl_s0.vsew + 1.U, outVecCtrl_s0.vsew)\n\
      307:   val outWiden = RegEnable(resWiden, io.in.fire)\n308:   val outEew = Mux(outWiden,
      outVecCtrl.vsew + 1.U, outVecCtrl.vsew)\n309:   val vlMax_s0 = ((VLEN/8).U >>
      outEew_s0).asUInt\n310:   val vlMax = ((VLEN/8).U >> outEew).asUInt\n311:  \
      \ val outVlmulFix = Mux(outWiden, outVecCtrl.vlmul + 1.U, outVecCtrl.vlmul)\n\
      312:   val lmulAbs = Mux(outVlmulFix(2), (~outVlmulFix(1,0)).asUInt + 1.U, outVlmulFix(1,0))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFALU.scala
    lines: 337-347
    context: "337:   val outIsResuction_s0 = outCtrl_s0.fuOpType === VfaluType.vfredusum
      ||\n338:     outCtrl_s0.fuOpType === VfaluType.vfredmax ||\n339:     outCtrl_s0.fuOpType
      === VfaluType.vfredmin ||\n340:     outCtrl_s0.fuOpType === VfaluType.vfredosum
      ||\n341:     outCtrl_s0.fuOpType === VfaluType.vfwredosum\n342:   val outVConfig_s0\
      \  = if(!cfg.vconfigWakeUp) outVecCtrl_s0.vconfig else dataVec.head.getSrcVConfig.asTypeOf(new
      VConfig)\n343:   val outVl_s0       = outVConfig_s0.vl\n344:   val outVlFix_s0
      = Mux(\n345:     outVecCtrl_s0.fpu.isFpToVecInst || (outCtrl_s0.fuOpType ===
      VfaluType.vfmv_f_s),\n346:     1.U,\n347:     Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFALU.scala
    lines: 348-358
    context: "348:       outCtrl_s0.fuOpType === VfaluType.vfmv_s_f,\n349:       outVl_s0.orR,\n\
      350:       Mux(outIsResuction_s0, reductionVl, outVl_s0)\n351:     )\n352: \
      \  )\n353:   val outVlFix = RegEnable(outVlFix_s0,io.in.fire)\n354: \n355: \
      \  val vlMaxAllUop = Wire(outVl.cloneType)\n356:   vlMaxAllUop := Mux(outVecCtrl.vlmul(2),
      vlMax >> lmulAbs, vlMax << lmulAbs).asUInt\n357:   val vlMaxThisUop = Mux(outVecCtrl.vlmul(2),
      vlMax >> lmulAbs, vlMax).asUInt\n358:   val vlSetThisUop = Mux(outVlFix > outVuopidx*vlMaxThisUop,
      outVlFix - outVuopidx*vlMaxThisUop, 0.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFALU.scala
    lines: 406-416
    context: "406:   if (backendParams.debugEn){\n407:     dontTouch(allFFlagsEn)\n\
      408:     dontTouch(fflagsRedMask)\n409:   }\n410:   // use srcMask(XLEN-1, 0)
      because float format hasn't fp8\n411:   val allVmZero = RegEnable(LZD(Reverse(srcMask(XLEN-1,
      0))) >= outVl_s0, io.in.fire)\n412:   allFFlagsEn := Mux(outIsResuction,\n413:\
      \     Cat(\n414:       Fill(4*numVecModule - 1, firstNeedFFlags || outIsVfRedUnSum
      && !outVecCtrl.lastUop) & fflagsRedMask(4*numVecModule - 1, 1),\n415:      \
      \ !allVmZero && (lastNeedFFlags || firstNeedFFlags || outIsVfRedOrdered || outIsVfRedUnSum)\n\
      416:     ),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFALU.scala
    lines: 417-427
    context: "417:     fflagsEn & vlMaskEn\n418:   ).asTypeOf(allFFlagsEn)\n419: \n\
      420:   val allFFlags = fflagsData.asTypeOf(Vec( 4*numVecModule,UInt(5.W)))\n\
      421:   val outFFlags = allFFlagsEn.zip(allFFlags).map{\n422:     case(en,fflags)
      => Mux(en, fflags, 0.U(5.W))\n423:   }.reduce(_ | _)\n424: \n425: \n426:   val
      cmpResultOldVd = Wire(UInt(cmpResultWidth.W))\n427:   val cmpResultOldVdRshiftWidth
      = Wire(UInt(6.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFALU.scala
    lines: 488-500
    context: "488:   mgu.io.in.info.vl := outVlFix\n489:   mgu.io.in.info.vstart :=
      outVecCtrl.vstart\n490:   mgu.io.in.info.vlmul := outVecCtrl.vlmul\n491:   mgu.io.in.info.valid
      := Mux(notModifyVd, false.B, io.in.valid)\n492:   mgu.io.in.info.vstart := Mux(outVecCtrl.fpu.isFpToVecInst,
      0.U, outVecCtrl.vstart)\n493:   mgu.io.in.info.eew :=  RegEnable(outEew_s0,io.in.fire)\n\
      494:   mgu.io.in.info.vsew := outVecCtrl.vsew\n495:   mgu.io.in.info.vdIdx :=
      RegEnable(Mux(outIsResuction_s0, 0.U, outVecCtrl_s0.vuopIdx), io.in.fire)\n\
      496:   mgu.io.in.info.narrow := outVecCtrl.isNarrow\n497:   mgu.io.in.info.dstMask
      := outVecCtrl.isDstMask\n498:   mgu.io.in.isIndexedVls := false.B\n499:   mgtu.io.in.vd
      := Mux(outVecCtrl.isDstMask, mgu.io.out.vd, resultDataUInt)\n500:   mgtu.io.in.vl
      := outVl"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFALU.scala
    lines: 503-513
    context: "503:   val fpCmpFuOpType = Seq(VfaluType.vfeq, VfaluType.vflt, VfaluType.vfle)\n\
      504:   val isCmp = outVecCtrl.fpu.isFpToVecInst && (fpCmpFuOpType.map(_ ===
      outCtrl.fuOpType).reduce(_|_))\n505:   resultFpMask := Mux(isFclass || isCmp,
      Fill(16, 1.U(1.W)), Fill(VLEN, 1.U(1.W)))\n506:   // when dest is mask, the
      result need to be masked by mgtu\n507:   io.out.bits.res.data := Mux(notModifyVd,
      outOldVd, Mux(outVecCtrl.isDstMask, mgtu.io.out.vd, mgu.io.out.vd) & resultFpMask)\n\
      508:   io.out.bits.res.fflags.get := Mux(notModifyVd, 0.U(5.W), outFFlags)\n\
      509:   io.out.bits.ctrl.exceptionVec.get(ExceptionNO.illegalInstr) := mgu.io.out.illegal\n\
      510: \n511: }\n512: \n513: class VFMgu(vlen:Int)(implicit p: Parameters) extends
      Module{"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/FALU.scala
    lines: 8-19
    context: "8: import xiangshan.backend.fu.vector.Bundles.VSew\n9: import xiangshan.backend.fu.fpu.FpPipedFuncUnit\n\
      10: import yunsuan.{VfaluType, VfpuType}\n11: import yunsuan.fpu.FloatAdder\n\
      12: \n13: class FAlu(cfg: FuConfig)(implicit p: Parameters) extends FpPipedFuncUnit(cfg)
      {\n14:   XSError(io.in.valid && io.in.bits.ctrl.fuOpType === VfpuType.dummy,
      \"falu OpType not supported\")\n15: \n16:   // io alias\n17:   private val opcode
      = fuOpType(4, 0)\n18:   private val src0 = inData.src(0)\n19:   private val
      src1 = inData.src(1)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/FALU.scala
    lines: 17-43
    context: "17:   private val opcode = fuOpType(4, 0)\n18:   private val src0 =
      inData.src(0)\n19:   private val src1 = inData.src(1)\n20: \n21:   // modules\n\
      22:   private val falu = Module(new FloatAdder)\n23: \n24:   val fp_aIsFpCanonicalNAN\
      \  = fp_fmt === VSew.e32 && !src0.head(32).andR ||\n25:                    \
      \           fp_fmt === VSew.e16 && !src0.head(48).andR\n26:   val fp_bIsFpCanonicalNAN\
      \  = fp_fmt === VSew.e32 && !src1.head(32).andR ||\n27:                    \
      \           fp_fmt === VSew.e16 && !src1.head(48).andR\n28: \n29:   falu.io.fire\
      \             := io.in.valid\n30:   falu.io.fp_a             := src0\n31:  \
      \ falu.io.fp_b             := src1\n32:   falu.io.round_mode       := rm\n33:\
      \   falu.io.fp_format        := fp_fmt\n34:   falu.io.op_code          := opcode\n\
      35:   falu.io.fp_aIsFpCanonicalNAN := fp_aIsFpCanonicalNAN\n36:   falu.io.fp_bIsFpCanonicalNAN
      := fp_bIsFpCanonicalNAN\n37: \n38:   private val resultData = falu.io.fp_result\n\
      39:   private val fflagsData = falu.io.fflags\n40: \n41:   io.out.bits.res.fflags.get
      := fflagsData\n42:   io.out.bits.res.data       := resultData\n43: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VIDiv.scala
    lines: 21-31
    context: "21:   // modules\n22:   private val vidiv = Module(new VectorIdiv)\n\
      23:   private val mgu = Module(new Mgu(dataWidth))\n24: \n25:   private val
      thisRobIdx = Wire(new RobPtr)\n26:   when(io.in.ready){\n27:     thisRobIdx
      := io.in.bits.ctrl.robIdx\n28:   }.otherwise{\n29:     thisRobIdx := outCtrl.robIdx\n\
      30:   }\n31: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VIDiv.scala
    lines: 33-51
    context: "33:     * [[vidiv]]'s in connection\n34:     */\n35:   vidiv.io match
      {\n36:     case subIO =>\n37:       subIO.div_in_valid  := io.in.valid\n38:\
      \       subIO.div_out_ready := io.out.ready & io.out.valid\n39:       subIO.sew\
      \           := vsew\n40:       subIO.sign          := VidivType.isSigned(fuOpType)\n\
      41:       subIO.dividend_v    := vs2\n42:       subIO.divisor_v     := vs1\n\
      43:       subIO.flush         := thisRobIdx.needFlush(io.flush)\n44:   }\n45:\
      \ \n46:   io.in.ready  := vidiv.io.div_in_ready\n47:   io.out.valid := vidiv.io.div_out_valid\n\
      48: \n49:   private val outFuOpType = outCtrl.fuOpType\n50:   private val outIsDiv
      = VidivType.isDiv(outFuOpType)\n51:   private val resultData = Mux(outIsDiv,
      vidiv.io.div_out_q_v, vidiv.io.div_out_rem_v)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 11-21
    context: "11: import device._\n12: import system.HasSoCParameter\n13: import xiangshan.ExceptionNO._\n\
      14: import xiangshan.backend.Bundles.TrapInstInfo\n15: import xiangshan.backend.decode.Imm_Z\n\
      16: import xiangshan.backend.fu.NewCSR.CSRBundles.PrivState\n17: import xiangshan.backend.fu.NewCSR.CSRDefines.PrivMode\n\
      18: import xiangshan.backend.rob.RobPtr\n19: import xiangshan.frontend.FtqPtr\n\
      20: import CSRConst._\n21: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 25-35
    context: "25:   val csrIn = io.csrio.get\n26:   val csrOut = io.csrio.get\n27:\
      \   val csrToDecode = io.csrToDecode.get\n28: \n29:   val setFsDirty = csrIn.fpu.dirty_fs\n\
      30:   val setFflags = csrIn.fpu.fflags\n31: \n32:   val setVsDirty = csrIn.vpu.dirty_vs\n\
      33:   val setVstart = csrIn.vpu.set_vstart\n34:   val setVtype = csrIn.vpu.set_vtype\n\
      35:   val setVxsat = csrIn.vpu.set_vxsat"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 33-44
    context: "33:   val setVstart = csrIn.vpu.set_vstart\n34:   val setVtype = csrIn.vpu.set_vtype\n\
      35:   val setVxsat = csrIn.vpu.set_vxsat\n36:   val vlFromPreg = csrIn.vpu.vl\n\
      37: \n38:   val flushPipe = Wire(Bool())\n39:   val flush = io.flush.valid\n\
      40: \n41:   /** Alias of input signals */\n42:   val (valid, src1, imm, func)
      = (\n43:     io.in.valid,\n44:     io.in.bits.data.src(0),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 64-74
    context: "64: \n65:   val csrMod = Module(new NewCSR)\n66:   val trapInstMod =
      Module(new TrapInstMod)\n67:   val trapTvalMod = Module(new TrapTvalMod)\n68:\
      \ \n69:   private val privState = csrMod.io.status.privState\n70:   // The real
      reg value in CSR, with no read mask\n71:   private val regOut = csrMod.io.out.bits.regOut\n\
      72:   private val src = Mux(CSROpType.needImm(func), csri, src1)\n73:   private
      val wdata = LookupTree(func, Seq(\n74:     CSROpType.wrt  -> src1,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 87-100
    context: "87:   private val csrRen = valid && (\n88:     CSROpType.isCSRRW(func)
      && rd =/= 0.U ||\n89:     CSROpType.isCSRRSorRC(func)\n90:   )\n91: \n92:  \
      \ private val waddrReg = RegEnable(addr, 0.U(12.W), io.in.fire)\n93:   private
      val wdataReg = RegEnable(wdata, 0.U(64.W), io.in.fire)\n94: \n95:   private
      val robIdxReg = RegEnable(io.in.bits.ctrl.robIdx, io.in.fire)\n96:   private
      val thisRobIdx = Wire(new RobPtr)\n97:   when (io.in.valid) {\n98:     thisRobIdx
      := io.in.bits.ctrl.robIdx\n99:   }.otherwise {\n100:     thisRobIdx := robIdxReg"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 97-107
    context: "97:   when (io.in.valid) {\n98:     thisRobIdx := io.in.bits.ctrl.robIdx\n\
      99:   }.otherwise {\n100:     thisRobIdx := robIdxReg\n101:   }\n102:   private
      val redirectFlush = thisRobIdx.needFlush(io.flush)\n103: \n104:   csrMod.io.in
      match {\n105:     case in =>\n106:       in.valid := valid\n107:       in.bits.wen
      := csrWen"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 112-125
    context: "112:       in.bits.wdata := wdataReg\n113:       in.bits.mret := isMret\n\
      114:       in.bits.mnret := isMNret\n115:       in.bits.sret := isSret\n116:\
      \       in.bits.dret := isDret\n117:       in.bits.redirectFlush := redirectFlush\n\
      118:   }\n119:   csrMod.io.trapInst := trapInstMod.io.currentTrapInst\n120:\
      \   csrMod.io.fetchMalTval := trapTvalMod.io.tval\n121:   csrMod.io.fromMem.excpVA\
      \  := csrIn.memExceptionVAddr\n122:   csrMod.io.fromMem.excpGPA := csrIn.memExceptionGPAddr\n\
      123:   csrMod.io.fromMem.excpIsForVSnonLeafPTE := csrIn.memExceptionIsForVSnonLeafPTE\n\
      124: \n125:   csrMod.io.fromRob.trap.valid := csrIn.exception.valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 136-162
    context: "136:   csrMod.io.fromRob.trap.bits.trigger := csrIn.exception.bits.trigger\n\
      137:   csrMod.io.fromRob.trap.bits.isHls := csrIn.exception.bits.isHls\n138:\
      \   csrMod.io.fromRob.trap.bits.isFetchMalAddr := csrIn.exception.bits.isFetchMalAddr\n\
      139:   csrMod.io.fromRob.trap.bits.isForVSnonLeafPTE := csrIn.exception.bits.isForVSnonLeafPTE\n\
      140: \n141:   csrMod.io.fromRob.commit.fflags := setFflags\n142:   csrMod.io.fromRob.commit.fsDirty
      := setFsDirty\n143:   csrMod.io.fromRob.commit.vxsat.valid := setVxsat.valid\n\
      144:   csrMod.io.fromRob.commit.vxsat.bits := setVxsat.bits\n145:   csrMod.io.fromRob.commit.vsDirty
      := setVsDirty\n146:   csrMod.io.fromRob.commit.vstart := setVstart\n147:   csrMod.io.fromRob.commit.vl
      := vlFromPreg\n148:   // Todo: correct vtype\n149:   csrMod.io.fromRob.commit.vtype.valid
      := setVtype.valid\n150:   csrMod.io.fromRob.commit.vtype.bits.VILL := setVtype.bits(XLEN
      - 1)\n151:   csrMod.io.fromRob.commit.vtype.bits.VMA := setVtype.bits(7)\n152:\
      \   csrMod.io.fromRob.commit.vtype.bits.VTA := setVtype.bits(6)\n153:   csrMod.io.fromRob.commit.vtype.bits.VSEW
      := setVtype.bits(5, 3)\n154:   csrMod.io.fromRob.commit.vtype.bits.VLMUL :=
      setVtype.bits(2, 0)\n155: \n156:   csrMod.io.fromRob.commit.instNum.valid :=
      true.B  // Todo: valid control signal\n157:   csrMod.io.fromRob.commit.instNum.bits\
      \  := csrIn.perf.retiredInstr\n158: \n159:   csrMod.io.fromRob.robDeqPtr :=
      csrIn.robDeqPtr\n160: \n161:   csrMod.io.fromVecExcpMod.busy := io.csrin.get.fromVecExcpMod.busy\n\
      162: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 173-183
    context: "173:   csrMod.nonMaskableIRP.NMI_43 := csrIn.externalInterrupt.nmi.nmi_43\n\
      174:   csrMod.nonMaskableIRP.NMI_31 := csrIn.externalInterrupt.nmi.nmi_31\n\
      175: \n176:   csrMod.io.fromTop.hartId := io.csrin.get.hartId\n177:   csrMod.io.fromTop.clintTime
      := io.csrin.get.clintTime\n178:   csrMod.io.fromTop.l2FlushDone := io.csrin.get.l2FlushDone\n\
      179:   csrMod.io.fromTop.criticalErrorState := io.csrin.get.criticalErrorState\n\
      180:   private val csrModOutValid = csrMod.io.out.valid\n181:   private val
      csrModOut      = csrMod.io.out.bits\n182: \n183:   trapInstMod.io.fromDecode.trapInstInfo
      := RegNextWithEnable(io.csrin.get.trapInstInfo, hasInit = true)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 179-198
    context: "179:   csrMod.io.fromTop.criticalErrorState := io.csrin.get.criticalErrorState\n\
      180:   private val csrModOutValid = csrMod.io.out.valid\n181:   private val
      csrModOut      = csrMod.io.out.bits\n182: \n183:   trapInstMod.io.fromDecode.trapInstInfo
      := RegNextWithEnable(io.csrin.get.trapInstInfo, hasInit = true)\n184:   trapInstMod.io.fromRob.flush.valid
      := io.flush.valid\n185:   trapInstMod.io.fromRob.flush.bits.ftqPtr := io.flush.bits.ftqIdx\n\
      186:   trapInstMod.io.fromRob.flush.bits.ftqOffset := io.flush.bits.ftqOffset\n\
      187:   trapInstMod.io.fromRob.isInterrupt.valid := csrIn.exception.valid\n188:\
      \   trapInstMod.io.fromRob.isInterrupt.bits := csrIn.exception.bits.isInterrupt\n\
      189:   trapInstMod.io.faultCsrUop.valid         := csrMod.io.out.valid && (csrMod.io.out.bits.EX_II
      || csrMod.io.out.bits.EX_VI)\n190:   trapInstMod.io.faultCsrUop.bits.fuOpType
      := DataHoldBypass(io.in.bits.ctrl.fuOpType, io.in.fire)\n191:   trapInstMod.io.faultCsrUop.bits.imm\
      \      := DataHoldBypass(io.in.bits.data.imm, io.in.fire)\n192:   trapInstMod.io.faultCsrUop.bits.ftqInfo.ftqPtr\
      \    := DataHoldBypass(io.in.bits.ctrl.ftqIdx.get, io.in.fire)\n193:   trapInstMod.io.faultCsrUop.bits.ftqInfo.ftqOffset
      := DataHoldBypass(io.in.bits.ctrl.ftqOffset.get, io.in.fire)\n194:   // Clear
      trap instruction when instruction fault trap(EX_II, EX_VI) occurs.\n195:   trapInstMod.io.readClear
      := (csrMod.io.fromRob.trap match {\n196:     case t =>\n197:       t.valid &&
      !t.bits.isInterrupt && (t.bits.trapVec(EX_II) || t.bits.trapVec(EX_VI))\n198:\
      \   })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 198-208
    context: "198:   })\n199: \n200:   trapTvalMod.io.targetPc.valid := csrMod.io.out.bits.targetPcUpdate\n\
      201:   trapTvalMod.io.targetPc.bits := csrMod.io.out.bits.targetPc\n202:   trapTvalMod.io.clear
      := csrIn.exception.valid && csrIn.exception.bits.isFetchMalAddr\n203:   trapTvalMod.io.fromCtrlBlock.flush
      := io.flush\n204:   trapTvalMod.io.fromCtrlBlock.robDeqPtr := io.csrio.get.robDeqPtr\n\
      205: \n206:   val imsic = Module(new aia.IMSIC(soc.IMSICParams))\n207:   imsic.fromCSR.addr.valid
      := csrMod.toAIA.addr.valid\n208:   imsic.fromCSR.addr.bits.addr := csrMod.toAIA.addr.bits.addr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 230-244
    context: "230:   imsic.msiio.data := io.csrin.get.msiInfo.bits\n231:   io.csrio.get.msiAck
      := imsic.msiio.vld_ack\n232: \n233:   private val exceptionVec = WireInit(0.U.asTypeOf(ExceptionVec()))
      // Todo:\n234: \n235:   exceptionVec(EX_BP    ) := DataHoldBypass(isEbreak,
      false.B, io.in.fire)\n236:   exceptionVec(EX_MCALL ) := DataHoldBypass(isEcall
      && privState.isModeM, false.B, io.in.fire)\n237:   exceptionVec(EX_HSCALL) :=
      DataHoldBypass(isEcall && privState.isModeHS, false.B, io.in.fire)\n238:   exceptionVec(EX_VSCALL)
      := DataHoldBypass(isEcall && privState.isModeVS, false.B, io.in.fire)\n239:\
      \   exceptionVec(EX_UCALL ) := DataHoldBypass(isEcall && privState.isModeHUorVU,
      false.B, io.in.fire)\n240:   exceptionVec(EX_II    ) := csrMod.io.out.bits.EX_II\n\
      241:   exceptionVec(EX_VI    ) := csrMod.io.out.bits.EX_VI\n242: \n243:   val
      isXRet = valid && func === CSROpType.jmp && !isEcall && !isEbreak\n244: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 240-250
    context: "240:   exceptionVec(EX_II    ) := csrMod.io.out.bits.EX_II\n241:   exceptionVec(EX_VI\
      \    ) := csrMod.io.out.bits.EX_VI\n242: \n243:   val isXRet = valid && func
      === CSROpType.jmp && !isEcall && !isEbreak\n244: \n245:   flushPipe := csrMod.io.out.bits.flushPipe\n\
      246: \n247:   // tlb\n248:   val tlb = Wire(new TlbCsrBundle)\n249:   tlb.satp.changed\
      \  := csrMod.io.tlb.satpASIDChanged\n250:   tlb.satp.mode     := csrMod.io.tlb.satp.MODE.asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 280-313
    context: "280: \n281:   // pointer masking extension\n282:   tlb.pmm := csrMod.io.tlb.pmm\n\
      283: \n284:   /** Since some CSR read instructions are allowed to be pipelined,
      ready/valid signals should be modified */\n285:   io.in.ready := csrMod.io.in.ready
      // Todo: Async read imsic may block CSR\n286:   io.out.valid := csrModOutValid\n\
      287:   io.out.bits.ctrl.exceptionVec.get := exceptionVec\n288:   io.out.bits.ctrl.flushPipe.get
      := flushPipe\n289:   io.out.bits.res.data := csrMod.io.out.bits.rData\n290:\
      \ \n291:   /** initialize NewCSR's io_out_ready from wrapper's io */\n292: \
      \  csrMod.io.out.ready := io.out.ready\n293: \n294:   io.out.bits.res.redirect.get.valid
      := io.out.valid && RegEnable(isXRet, false.B, io.in.fire)\n295:   val redirect
      = io.out.bits.res.redirect.get.bits\n296:   redirect := 0.U.asTypeOf(redirect)\n\
      297:   redirect.level := RedirectLevel.flushAfter\n298:   redirect.robIdx :=
      robIdxReg\n299:   redirect.ftqIdx := RegEnable(io.in.bits.ctrl.ftqIdx.get, io.in.fire)\n\
      300:   redirect.ftqOffset := RegEnable(io.in.bits.ctrl.ftqOffset.get, io.in.fire)\n\
      301:   redirect.cfiUpdate.predTaken := true.B\n302:   redirect.cfiUpdate.taken
      := true.B\n303:   redirect.cfiUpdate.target := csrMod.io.out.bits.targetPc.pc\n\
      304:   redirect.cfiUpdate.backendIPF := csrMod.io.out.bits.targetPc.raiseIPF\n\
      305:   redirect.cfiUpdate.backendIAF := csrMod.io.out.bits.targetPc.raiseIAF\n\
      306:   redirect.cfiUpdate.backendIGPF := csrMod.io.out.bits.targetPc.raiseIGPF\n\
      307:   // Only mispred will send redirect to frontend\n308:   redirect.cfiUpdate.isMisPred
      := true.B\n309: \n310:   connectNonPipedCtrlSingal\n311: \n312:   override val
      criticalErrors = csrMod.getCriticalErrors\n313:   generateCriticalErrors()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 311-322
    context: "311: \n312:   override val criticalErrors = csrMod.getCriticalErrors\n\
      313:   generateCriticalErrors()\n314: \n315:   // Todo: summerize all difftest
      skip condition\n316:   csrOut.isPerfCnt  := io.out.valid && csrMod.io.out.bits.isPerfCnt
      && RegEnable(func =/= CSROpType.jmp, false.B, io.in.fire)\n317:   csrOut.fpu.frm\
      \    := csrMod.io.status.fpState.frm.asUInt\n318:   csrOut.vpu.vstart := csrMod.io.status.vecState.vstart.asUInt\n\
      319:   csrOut.vpu.vxrm   := csrMod.io.status.vecState.vxrm.asUInt\n320: \n321:\
      \   csrOut.isXRet := isXRet\n322: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 363-373
    context: "363:       custom.singlestep := csrMod.io.status.singleStepFlag\n364:\
      \       // trigger\n365:       custom.frontend_trigger := csrMod.io.status.frontendTrigger\n\
      366:       custom.mem_trigger      := csrMod.io.status.memTrigger\n367:    \
      \   // virtual mode\n368:       custom.virtMode := csrMod.io.status.privState.V.asBool\n\
      369:       // xstatus.fs field is off\n370:       custom.fsIsOff := csrMod.io.toDecode.illegalInst.fsIsOff\n\
      371:   }\n372: \n373:   csrOut.instrAddrTransType := csrMod.io.status.instrAddrTransType"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 379-389
    context: "379: class CSRInput(implicit p: Parameters) extends XSBundle with HasSoCParameter
      {\n380:   val hartId = Input(UInt(8.W))\n381:   val msiInfo = Input(ValidIO(UInt(soc.IMSICParams.MSI_INFO_WIDTH.W)))\n\
      382:   val criticalErrorState = Input(Bool())\n383:   val clintTime = Input(ValidIO(UInt(64.W)))\n\
      384:   val l2FlushDone = Input(Bool())\n385:   val trapInstInfo = Input(ValidIO(new
      TrapInstInfo))\n386:   val fromVecExcpMod = Input(new Bundle {\n387:     val
      busy = Bool()\n388:   })\n389: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/BranchUnit.scala
    lines: 5-15
    context: "5: import chisel3.util.log2Up\n6: import utility.{SignExt, ZeroExt}\n\
      7: import xiangshan.backend.decode.ImmUnion\n8: import xiangshan.backend.fu.{BranchModule,
      FuConfig, FuncUnit}\n9: import xiangshan.backend.datapath.DataConfig.VAddrData\n\
      10: import xiangshan.{RedirectLevel, SelImm, XSModule}\n11: \n12: class AddrAddModule(implicit
      p: Parameters) extends XSModule {\n13:   val io = IO(new Bundle {\n14:     val
      pcExtend = Input(UInt((VAddrBits + 1).W))\n15:     val taken = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/BranchUnit.scala
    lines: 12-22
    context: "12: class AddrAddModule(implicit p: Parameters) extends XSModule {\n\
      13:   val io = IO(new Bundle {\n14:     val pcExtend = Input(UInt((VAddrBits
      + 1).W))\n15:     val taken = Input(Bool())\n16:     val isRVC = Input(Bool())\n\
      17:     val imm = Input(UInt(32.W)) // branch inst only support 12 bits immediate
      num\n18:     val target = Output(UInt(XLEN.W))\n19:     val nextPcOffset = Input(UInt((log2Up(PredictWidth)
      + 1).W))\n20:   })\n21:   val immMinWidth = FuConfig.BrhCfg.immType.map(x =>
      SelImm.getImmUnion(x).len).max\n22:   print(s\"[Branch]: immMinWidth = $immMinWidth\\\
      n\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/BranchUnit.scala
    lines: 43-70
    context: "43:   addModule.io.taken := dataModule.io.taken\n44:   addModule.io.isRVC
      := io.in.bits.ctrl.preDecode.get.isRVC\n45:   addModule.io.nextPcOffset := io.in.bits.data.nextPcOffset.get\n\
      46: \n47:   io.out.valid := io.in.valid\n48:   io.in.ready := io.out.ready\n\
      49: \n50:   io.out.bits.res.data := 0.U\n51:   io.out.bits.res.redirect.get
      match {\n52:     case redirect =>\n53:       redirect.valid := io.out.valid
      && dataModule.io.mispredict\n54:       redirect.bits := 0.U.asTypeOf(io.out.bits.res.redirect.get.bits)\n\
      55:       redirect.bits.level := RedirectLevel.flushAfter\n56:       redirect.bits.robIdx
      := io.in.bits.ctrl.robIdx\n57:       redirect.bits.ftqIdx := io.in.bits.ctrl.ftqIdx.get\n\
      58:       redirect.bits.ftqOffset := io.in.bits.ctrl.ftqOffset.get\n59:    \
      \   redirect.bits.fullTarget := addModule.io.target\n60:       redirect.bits.cfiUpdate.isMisPred
      := dataModule.io.mispredict\n61:       redirect.bits.cfiUpdate.taken := dataModule.io.taken\n\
      62:       redirect.bits.cfiUpdate.predTaken := dataModule.io.pred_taken\n63:\
      \       redirect.bits.cfiUpdate.target := addModule.io.target\n64:       redirect.bits.cfiUpdate.pc
      := io.in.bits.data.pc.get\n65:       redirect.bits.cfiUpdate.backendIAF := io.instrAddrTransType.get.checkAccessFault(addModule.io.target)\n\
      66:       redirect.bits.cfiUpdate.backendIPF := io.instrAddrTransType.get.checkPageFault(addModule.io.target)\n\
      67:       redirect.bits.cfiUpdate.backendIGPF := io.instrAddrTransType.get.checkGuestPageFault(addModule.io.target)\n\
      68:   }\n69:   connect0LatencyCtrlSingal\n70: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/FCVT.scala
    lines: 36-47
    context: "36: \n37:   val widen = opcode(4, 3) // 0->single 1->widen 2->norrow
      => width of result\n38:   val isSingleCvt = !widen(1) & !widen(0)\n39:   val
      isWidenCvt = !widen(1) & widen(0)\n40:   val isNarrowCvt = widen(1) & !widen(0)\n\
      41:   val fire = io.in.valid\n42:   val fireReg = GatedValidRegNext(fire)\n\
      43: \n44:   // output width 8 16 32 64\n45:   val output1H = Wire(UInt(4.W))\n\
      46:   output1H := chisel3.util.experimental.decode.decoder(\n47:     widen ##
      sew,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/FCVT.scala
    lines: 74-84
    context: "74:   val outIsInt = !outCtrl.fuOpType(6)\n75:   val outIsMvInst = outCtrl.fuOpType
      === FuOpType.FMVXF\n76: \n77:   // modules\n78:   val fcvt = Module(new FPCVT(XLEN))\n\
      79:   fcvt.io.fire := fire\n80:   fcvt.io.src := src0\n81:   fcvt.io.opType
      := opcode(7, 0)\n82:   fcvt.io.sew := sew\n83:   fcvt.io.rm := vfcvtRm\n84:\
      \   fcvt.io.isFpToVecInst := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/FCVT.scala
    lines: 85-99
    context: "85:   fcvt.io.isFround := Cat(isFoundnx, isFround)\n86:   fcvt.io.isFcvtmod
      := isFcvtmod\n87: \n88: \n89:   //cycle2\n90:   val isNarrowCycle2 = RegEnable(RegEnable(isNarrowCvt,
      fire), fireReg)\n91:   val outputWidth1HCycle2 = RegEnable(RegEnable(outputWidth1H,
      fire), fireReg)\n92: \n93:   val fcvtResult = fcvt.io.result\n94:   io.out.bits.res.fflags.get
      := Mux(outIsMvInst, 0.U, fcvt.io.fflags)\n95: \n96:   //fmv box\n97:   val result_fmv
      = Mux1H(Seq(\n98:     (sew === VSew.e8) -> Fill(56, src0(7)) ## src0(7, 0),\n\
      99:     (sew === VSew.e16) -> Fill(48, src0(15)) ## src0(15, 0),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/FCVT.scala
    lines: 101-111
    context: "101:     (sew === VSew.e64) -> src0,\n102:   ))\n103:   // for scalar
      f2i cvt inst\n104:   val isFpToInt32 = outIs32bits && outIsInt\n105:   // for
      f2i mv inst\n106:   val result = Mux(outIsMvInst, RegEnable(RegEnable(result_fmv,
      fire), fireReg),\n107:     // for scalar fp32 fp16 result\n108:     Mux(\n109:\
      \       outIs32bits && !outIsInt,\n110:       Cat(Fill(32, 1.U), fcvtResult(31,0)),\n\
      111:       Mux(outIs16bits && !outIsInt, Cat(Fill(48, 1.U), fcvtResult(15,0)),
      fcvtResult)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VSet.scala
    lines: 17-27
    context: "17:   protected val in = io.in.bits\n18:   protected val out = io.out.bits\n\
      19: \n20:   protected val vsetModule = Module(new VsetModule)\n21: \n22:   protected
      val flushed = io.in.bits.ctrl.robIdx.needFlush(io.flush)\n23: \n24:   protected
      val avlImm = Imm_VSETIVLI().getAvl(in.data.src(1))\n25:   protected val avl
      = Mux(VSETOpType.isVsetivli(in.ctrl.fuOpType), avlImm, in.data.src(0))\n26:\
      \ \n27:   protected val instVType: InstVType = Mux(VSETOpType.isVsetivli(in.ctrl.fuOpType),
      Imm_VSETIVLI().getVType(in.data.src(1)), Imm_VSETVLI().getVType(in.data.src(1)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VSet.scala
    lines: 29-39
    context: "29:   protected val vtype: VsetVType = Mux(VSETOpType.isVsetvl(in.ctrl.fuOpType),
      VsetVType.fromVtypeStruct(in.data.src(1).asTypeOf(new VtypeStruct())), vtypeImm)\n\
      30: \n31:   vsetModule.io.in.func := in.ctrl.fuOpType\n32:   connect0LatencyCtrlSingal\n\
      33:   io.out.valid := io.in.valid\n34:   io.in.ready := io.out.ready\n35: }\n\
      36: \n37: \n38: /**\n39:   * Wrapper of VsetModule"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/FDivSqrt.scala
    lines: 20-36
    context: "20:   private val src1 = inData.src(1)\n21: \n22:   // modules\n23:\
      \   private val fdiv = Module(new FloatDivider)\n24: \n25:   val fp_aIsFpCanonicalNAN\
      \  = fp_fmt === VSew.e32 && !src0.head(32).andR ||\n26:                    \
      \           fp_fmt === VSew.e16 && !src0.head(48).andR\n27:   val fp_bIsFpCanonicalNAN\
      \  = fp_fmt === VSew.e32 && !src1.head(32).andR ||\n28:                    \
      \           fp_fmt === VSew.e16 && !src1.head(48).andR\n29: \n30:   val thisRobIdx
      = Wire(new RobPtr)\n31:   when(io.in.ready){\n32:     thisRobIdx := io.in.bits.ctrl.robIdx\n\
      33:   }.otherwise{\n34:     thisRobIdx := outCtrl.robIdx\n35:   }\n36: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/FDivSqrt.scala
    lines: 32-44
    context: "32:     thisRobIdx := io.in.bits.ctrl.robIdx\n33:   }.otherwise{\n34:\
      \     thisRobIdx := outCtrl.robIdx\n35:   }\n36: \n37:   fdiv.io.start_valid_i\
      \  := io.in.valid\n38:   fdiv.io.finish_ready_i := io.out.ready & io.out.valid\n\
      39:   fdiv.io.flush_i        := thisRobIdx.needFlush(io.flush)\n40:   fdiv.io.fp_format_i\
      \    := fp_fmt\n41:   fdiv.io.opa_i          := src0\n42:   fdiv.io.opb_i  \
      \        := src1\n43:   fdiv.io.is_sqrt_i      := opcode\n44:   fdiv.io.rm_i\
      \           := rm"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/FDivSqrt.scala
    lines: 50-62
    context: "50:       (outCtrl.fpu.get.fmt === VSew.e16) -> Cat(Fill(48, 1.U), fdiv.io.fpdiv_res_o(15,
      0)),\n51:       (outCtrl.fpu.get.fmt === VSew.e32) -> Cat(Fill(32, 1.U), fdiv.io.fpdiv_res_o(31,
      0)),\n52:       (outCtrl.fpu.get.fmt === VSew.e64) -> fdiv.io.fpdiv_res_o\n\
      53:     )\n54:   )\n55:   private val fflagsData = fdiv.io.fflags_o\n56: \n\
      57:   io.in.ready  := fdiv.io.start_ready_o\n58:   io.out.valid := fdiv.io.finish_valid_o\n\
      59: \n60:   io.out.bits.res.fflags.get := fflagsData\n61:   io.out.bits.res.data\
      \       := resultData\n62: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFDivSqrt.scala
    lines: 47-85
    context: "47:   private val fflagsData = Wire(Vec(numVecModule, UInt(20.W)))\n\
      48:   val fp_aIsFpCanonicalNAN = Wire(Vec(numVecModule, Bool()))\n49:   val
      fp_bIsFpCanonicalNAN = Wire(Vec(numVecModule, Bool()))\n50: \n51:   val thisRobIdx
      = Wire(new RobPtr)\n52:   when(io.in.ready){\n53:     thisRobIdx := io.in.bits.ctrl.robIdx\n\
      54:   }.otherwise{\n55:     thisRobIdx := outCtrl.robIdx\n56:   }\n57:   vfdivs.zipWithIndex.foreach
      {\n58:     case (mod, i) =>\n59:       mod.io.start_valid_i  := io.in.valid\n\
      60:       mod.io.finish_ready_i := io.out.ready & io.out.valid\n61:       mod.io.flush_i\
      \        := thisRobIdx.needFlush(io.flush)\n62:       mod.io.fp_format_i   \
      \ := vsew\n63:       mod.io.opa_i          := vs2Split.io.outVec64b(i)\n64:\
      \       mod.io.opb_i          := vs1Split.io.outVec64b(i)\n65:       mod.io.frs2_i\
      \         := 0.U     // already vf -> vv\n66:       mod.io.frs1_i         :=
      0.U     // already vf -> vv\n67:       mod.io.is_frs2_i      := false.B // already
      vf -> vv\n68:       mod.io.is_frs1_i      := false.B // already vf -> vv\n69:\
      \       mod.io.is_sqrt_i      := opcode\n70:       mod.io.rm_i           :=
      rm\n71:       mod.io.is_vec_i       := true.B // Todo\n72:       resultData(i)
      := mod.io.fpdiv_res_o\n73:       fflagsData(i) := mod.io.fflags_o\n74:     \
      \  fp_aIsFpCanonicalNAN(i) := vecCtrl.fpu.isFpToVecInst & (\n75:         ((vsew
      === VSew.e32) & (!vs2Split.io.outVec64b(i).head(32).andR)) |\n76:          \
      \ ((vsew === VSew.e16) & (!vs2Split.io.outVec64b(i).head(48).andR))\n77:   \
      \      )\n78:       fp_bIsFpCanonicalNAN(i) := vecCtrl.fpu.isFpToVecInst & (\n\
      79:         ((vsew === VSew.e32) & (!vs1Split.io.outVec64b(i).head(32).andR))
      |\n80:           ((vsew === VSew.e16) & (!vs1Split.io.outVec64b(i).head(48).andR))\n\
      81:         )\n82:       mod.io.fp_aIsFpCanonicalNAN := fp_aIsFpCanonicalNAN(i)\n\
      83:       mod.io.fp_bIsFpCanonicalNAN := fp_bIsFpCanonicalNAN(i)\n84:   }\n\
      85: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFDivSqrt.scala
    lines: 81-92
    context: "81:         )\n82:       mod.io.fp_aIsFpCanonicalNAN := fp_aIsFpCanonicalNAN(i)\n\
      83:       mod.io.fp_bIsFpCanonicalNAN := fp_bIsFpCanonicalNAN(i)\n84:   }\n\
      85: \n86:   io.in.ready  := vfdivs.map(_.io.start_ready_o).reduce(_&_)\n87:\
      \   io.out.valid := vfdivs.map(_.io.finish_valid_o).reduce(_&_)\n88:   val outEew
      = outVecCtrl.vsew\n89:   val outVuopidx = outVecCtrl.vuopIdx(2, 0)\n90:   val
      vlMax = ((VLEN / 8).U >> outEew).asUInt\n91:   val lmulAbs = Mux(outVecCtrl.vlmul(2),
      (~outVecCtrl.vlmul(1, 0)).asUInt + 1.U, outVecCtrl.vlmul(1, 0))\n92:   val outVlFix
      = Mux(outVecCtrl.fpu.isFpToVecInst, 1.U, outVl)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VFDivSqrt.scala
    lines: 132-144
    context: "132:   )\n133:   allFFlagsEn := (fflagsEn & vlMaskEn).asTypeOf(allFFlagsEn)\n\
      134: \n135:   val allFFlags = fflagsData.asTypeOf(Vec(4 * numVecModule, UInt(5.W)))\n\
      136:   val outFFlags = allFFlagsEn.zip(allFFlags).map {\n137:     case (en,
      fflags) => Mux(en, fflags, 0.U(5.W))\n138:   }.reduce(_ | _)\n139:   io.out.bits.res.fflags.get
      := outFFlags\n140: \n141:   val resultDataUInt = resultData.asUInt\n142:   mgu.io.in.vd
      := resultDataUInt\n143:   mgu.io.in.oldVd := outOldVd\n144:   mgu.io.in.mask
      := maskToMgu"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VPPU.scala
    lines: 79-85
    context: "79:       subIO.in.bits.old_vd      := oldVd\n80:       subIO.in.bits.mask\
      \        := mask\n81:   }\n82: \n83:   io.out.bits.res.data := vperms.io.out.vd\n\
      84:   io.out.bits.res.vxsat.foreach(_ := vperms.io.out.vxsat)\n85: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/DivUnit.scala
    lines: 25-41
    context: "25:       ZeroExt(x(31, 0), xlen)\n26:     ),\n27:     x\n28:   )\n\
      29: \n30:   val robIdxReg = RegEnable(io.in.bits.ctrl.robIdx, io.in.fire)\n\
      31:   val ctrlReg = RegEnable(ctrl, io.in.fire)\n32: \n33:   val divDataModule
      = Module(new SRT16DividerDataModule(cfg.destDataBits))\n34: \n35:   val kill_w
      = io.in.bits.ctrl.robIdx.needFlush(io.flush)\n36:   val kill_r = !divDataModule.io.in_ready
      && robIdxReg.needFlush(io.flush)\n37: \n38:   divDataModule.io.valid := io.in.valid\n\
      39:   divDataModule.io.src(0) := divInputCvtFunc(io.in.bits.data.src(0))\n40:\
      \   divDataModule.io.src(1) := divInputCvtFunc(io.in.bits.data.src(1))\n41:\
      \   divDataModule.io.sign := ctrl.sign"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/DivUnit.scala
    lines: 41-54
    context: "41:   divDataModule.io.sign := ctrl.sign\n42:   divDataModule.io.kill_w
      := kill_w\n43:   divDataModule.io.kill_r := kill_r\n44:   divDataModule.io.isHi
      := ctrlReg.isHi\n45:   divDataModule.io.isW := ctrlReg.isW\n46:   divDataModule.io.out_ready
      := io.out.ready\n47: \n48:   val validNext = divDataModule.io.out_validNext
      // if high, io.valid will assert next cycle\n49: \n50:   io.in.ready := divDataModule.io.in_ready\n\
      51:   io.out.valid := divDataModule.io.out_valid\n52:   io.out.bits.res.data
      := divDataModule.io.out_data\n53:   connectNonPipedCtrlSingal\n54: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/Multiplier.scala
    lines: 108-123
    context: "108:       case 4 =>\n109:         val c53 = Module(new C53)\n110: \
      \        for((x, y) <- c53.io.in.take(4) zip col){\n111:           x := y\n\
      112:         }\n113:         c53.io.in.last := (if(cin.nonEmpty) cin.head else
      0.U)\n114:         sum = Seq(c53.io.out(0).asBool) ++ (if(cin.nonEmpty) cin.drop(1)
      else Nil)\n115:         cout1 = Seq(c53.io.out(1).asBool)\n116:         cout2
      = Seq(c53.io.out(2).asBool)\n117:       case n =>\n118:         val cin_1 =
      if(cin.nonEmpty) Seq(cin.head) else Nil\n119:         val cin_2 = if(cin.nonEmpty)
      cin.drop(1) else Nil\n120:         val (s_1, c_1_1, c_1_2) = addOneColumn(col
      take 4, cin_1)\n121:         val (s_2, c_2_1, c_2_2) = addOneColumn(col drop
      4, cin_2)\n122:         sum = s_1 ++ s_2\n123:         cout1 = c_1_1 ++ c_2_1"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/Branch.scala
    lines: 25-35
    context: "25: class BranchModule(implicit p: Parameters) extends XSModule {\n\
      26:   val io = IO(new Bundle() {\n27:     val src = Vec(2, Input(UInt(XLEN.W)))\n\
      28:     val func = Input(FuOpType())\n29:     val pred_taken = Input(Bool())\n\
      30:     val taken, mispredict = Output(Bool())\n31:   })\n32:   val (src1, src2,
      func) = (io.src(0), io.src(1), io.func)\n33: \n34:   val subModule = Module(new
      SubModule)\n35:   subModule.io.src(0) := src1"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/Branch.scala
    lines: 45-51
    context: "45:     BRUOpType.getBranchType(BRUOpType.bltu) -> sltu\n46:   )\n47:\
      \   val taken = LookupTree(BRUOpType.getBranchType(func), branchOpTable) ^ BRUOpType.isBranchInvert(func)\n\
      48: \n49:   io.taken := taken\n50:   io.mispredict := io.pred_taken ^ taken\n\
      51: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 63-73
    context: "63:   srcNeedCopy   : Boolean = false,\n64:   latency       : HasFuLatency
      = CertainLatency(0),// two field (base latency, extra latency(option))\n65:\
      \   hasInputBuffer: (Boolean, Int, Boolean) = (false, 0, false),\n66:   exceptionOut\
      \  : Seq[Int] = Seq(),\n67:   hasLoadError  : Boolean = false,\n68:   flushPipe\
      \     : Boolean = false,\n69:   replayInst    : Boolean = false,\n70:   trigger\
      \       : Boolean = false,\n71:   needSrcFrm    : Boolean = false,\n72:   needSrcVxrm\
      \   : Boolean = false,\n73:   writeVType    : Boolean = false,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 101-111
    context: "101:   def numV0Src  : Int = srcData.map(_.count(x => V0RegSrcDataSet.contains(x))).fold(0)(_
      max _)\n102:   def numVlSrc  : Int = srcData.map(_.count(x => VlRegSrcDataSet.contains(x))).fold(0)(_
      max _)\n103:   def numRegSrc : Int = srcData.map(_.count(x => RegSrcDataSet.contains(x))).fold(0)(_
      max _)\n104:   def numSrc    : Int = srcData.map(_.length).fold(0)(_ max _)\n\
      105: \n106:   def readFp: Boolean = numFpSrc > 0\n107: \n108:   def fuSel(uop:
      ExuInput): Bool = {\n109:     // Don't add more shit here!!!\n110:     // Todo:
      add new FuType to distinguish f2i, f2f\n111:     uop.fuType === this.fuType.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 141-151
    context: "141:   def genSrcDataVec: Seq[UInt] = {\n142:     getSrcMaxWidthVec.map(w
      => UInt(w.W))\n143:   }\n144: \n145:   // csr's redirect also uses redirect
      bundle\n146:   def hasRedirect: Boolean = Seq(FuType.jmp, FuType.brh, FuType.csr).contains(fuType)\n\
      147: \n148:   def hasPredecode: Boolean = Seq(FuType.jmp, FuType.brh, FuType.csr,
      FuType.ldu).contains(fuType)\n149: \n150:   def needTargetPc: Boolean = Seq(FuType.jmp,
      FuType.brh).contains(fuType)\n151: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 202-212
    context: "202:     * @param tips tips if get failed\n203:     * @return the index
      of special src data\n204:     */\n205:   protected def getSpecialSrcIdx(data:
      DataConfig, tips: String): Int = {\n206:     val srcIdxVec = srcData.map(x =>
      x.indexOf(data))\n207:     val idx0 = srcIdxVec.head\n208:     for (idx <- srcIdxVec)
      {\n209:       require(idx >= 0 && idx == idx0, tips + \", and at the same index.\"\
      )\n210:     }\n211:     idx0\n212:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 302-312
    context: "302:     ),\n303:     piped = false,\n304:     writeIntRf = true,\n\
      305:     latency = UncertainLatency(),\n306:     exceptionOut = Seq(illegalInstr,
      virtualInstr, breakPoint, ecallU, ecallS, ecallVS, ecallM),\n307:     flushPipe
      = true,\n308:   )\n309: \n310:   val AluCfg: FuConfig = FuConfig (\n311:   \
      \  name = \"alu\",\n312:     fuType = FuType.alu,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 352-362
    context: "352:       Seq(IntData(), IntData()),\n353:     ),\n354:     piped =
      false,\n355:     latency = UncertainLatency(),\n356:     exceptionOut = Seq(illegalInstr,
      virtualInstr),\n357:     flushPipe = true\n358:   )\n359: \n360:   // Todo:
      split it to simple bitmap exu and complex bku\n361:   val BkuCfg: FuConfig =
      FuConfig (\n362:     name = \"bku\","
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 422-432
    context: "422:     piped = false, // Todo: check it\n423:     writeIntRf = true,\n\
      424:     writeFpRf = true,\n425:     latency = UncertainLatency(3),\n426:  \
      \   exceptionOut = Seq(loadAddrMisaligned, loadAccessFault, loadPageFault, loadGuestPageFault,
      breakPoint, hardwareError),\n427:     flushPipe = true,\n428:     replayInst
      = true,\n429:     hasLoadError = true,\n430:     trigger = true,\n431:     immType
      = Set(SelImm.IMM_I),\n432:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 439-449
    context: "439:       Seq(IntData()),\n440:     ),\n441:     piped = false,\n442:\
      \     latency = UncertainLatency(),\n443:     exceptionOut = Seq(storeAddrMisaligned,
      storeAccessFault, storePageFault, storeGuestPageFault, breakPoint, hardwareError),\n\
      444:     flushPipe = true,\n445:     trigger = true,\n446:     immType = Set(SelImm.IMM_S),\n\
      447:   )\n448: \n449:   val StdCfg: FuConfig = FuConfig ("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 468-478
    context: "468:     piped = false, // Todo: check it\n469:     writeIntRf = true,\n\
      470:     writeFpRf = true,\n471:     latency = UncertainLatency(3),\n472:  \
      \   exceptionOut = Seq(loadAddrMisaligned, loadAccessFault, loadPageFault, loadGuestPageFault,
      breakPoint, hardwareError),\n473:     flushPipe = true,\n474:     replayInst
      = true,\n475:     hasLoadError = true,\n476:     immType = Set(SelImm.IMM_I),\n\
      477:   )\n478: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 691-703
    context: "691:     exceptionOut = Seq(illegalInstr),\n692:     needSrcFrm = true,\n\
      693:   )\n694: \n695:   val FaluCfg = FuConfig(\n696:     name = \"falu\",\n\
      697:     fuType = FuType.falu,\n698:     fuGen = (p: Parameters, cfg: FuConfig)
      => Module(new FAlu(cfg)(p).suggestName(\"Falu\")),\n699:     srcData = Seq(\n\
      700:       Seq(FpData(), FpData()),\n701:     ),\n702:     piped = true,\n703:\
      \     writeFpRf = true,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 765-775
    context: "765:     writeVecRf = true,\n766:     writeV0Rf = true,\n767:     writeVlRf
      = true,\n768:     latency = UncertainLatency(),\n769:     exceptionOut = Seq(loadAddrMisaligned,
      loadAccessFault, loadPageFault, loadGuestPageFault, breakPoint, hardwareError),\n\
      770:     flushPipe = true,\n771:     replayInst = true,\n772:     trigger =
      true,\n773:     hasLoadError = true,\n774:     vconfigWakeUp = true,\n775: \
      \    maskWakeUp = true,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 784-794
    context: "784:       Seq(VecData(), VecData(), VecData(), V0Data(), VlData()),\
      \  //vs1, vs2, vd_old, v0, vconfig\n785:     ),\n786:     piped = false,\n787:\
      \     latency = UncertainLatency(),\n788:     exceptionOut = Seq(storeAddrMisaligned,
      storeAccessFault, storePageFault, storeGuestPageFault, breakPoint, hardwareError),\n\
      789:     flushPipe = true,\n790:     replayInst = true,\n791:     trigger =
      true,\n792:     hasLoadError = true,\n793:     vconfigWakeUp = true,\n794: \
      \    maskWakeUp = true,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 806-816
    context: "806:     writeVecRf = true,\n807:     writeV0Rf = true,\n808:     writeVlRf
      = true,\n809:     latency = UncertainLatency(),\n810:     exceptionOut = Seq(loadAddrMisaligned,
      loadAccessFault, loadPageFault, breakPoint, hardwareError),\n811:     flushPipe
      = true,\n812:     replayInst = true,\n813:     trigger = true,\n814:     hasLoadError
      = true,\n815:     vconfigWakeUp = true,\n816:     maskWakeUp = true,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 825-835
    context: "825:       Seq(VecData(), VecData(), VecData(), V0Data(), VlData()),
      //vs1, vs2, vd_old, v0, vconfig\n826:     ),\n827:     piped = false,\n828:\
      \     latency = UncertainLatency(),\n829:     exceptionOut = Seq(storeAddrMisaligned,
      storeAccessFault, storePageFault, breakPoint, hardwareError),\n830:     flushPipe
      = true,\n831:     replayInst = true,\n832:     trigger = true,\n833:     hasLoadError
      = true,\n834:     vconfigWakeUp = true,\n835:     maskWakeUp = true,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/util/Trigger.scala
    lines: 31-41
    context: "31:       this.data.asTypeOf(new MControlData).timing\n32:     }\n33:\
      \   }\n34:   object Tdata1Bundle extends Tdata1Bundle {\n35:     def apply():
      Tdata1Bundle = new Tdata1Bundle\n36:     def Read(rdata: UInt) : UInt = rdata\n\
      37:     def Write(wdata: UInt, tdata1: UInt, chainable: Bool, debug_mode: Bool)
      : UInt = {\n38:       val tdata1_old = WireInit(tdata1.asTypeOf(new Tdata1Bundle))\n\
      39:       val tdata1_new = Wire(new Tdata1Bundle)\n40:       val wdata_new =
      WireInit(wdata.asTypeOf(new Tdata1Bundle))\n41:       tdata1_new.type_ := wdata_new.type_.legalize"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/util/Trigger.scala
    lines: 106-116
    context: "106: \n107:     def isFetchTrigger: Bool = this.execute\n108:     def
      isMemAccTrigger: Bool = this.store || this.load\n109:   }\n110:   object MControlData
      {\n111:     def Read(rdata: UInt) : UInt = rdata\n112:     def Write(wdata:
      UInt, tdata1data: UInt, chainable: Bool) : UInt = {\n113:       val mcontrol_old
      = WireInit(tdata1data.asTypeOf(new MControlData))\n114:       val tdata1_new
      = WireInit(wdata.asTypeOf(new Tdata1Bundle))\n115:       val mcontrol_new =
      WireInit(tdata1_new.data.asTypeOf(new MControlData))\n116:       val wdata_new
      = WireInit(wdata.asTypeOf(new MControlData))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/util/Trigger.scala
    lines: 211-221
    context: "211:     for (i <- 1 until triggerNum) { // the 0th trigger always timing
      same, not chain, timing ok\n212:       trigger2TimingSameVec(i) := timingVec(i
      - 1) === timingVec(i)\n213:       trigger2ChainVec(i) := chainVec(i - 1) &&
      !chainVec(i)\n214:       trigger2TimingOkVec(i) := trigger2ChainVec(i) && trigger2TimingSameVec(i)
      || !chainVec(i - 1)\n215:     }\n216:     canFireVec.zipWithIndex.foreach {\n\
      217:       case (canFire, i) => canFire := trigger2ChainOkVec(i) && trigger2TimingOkVec(i)
      && hitVec(i) && !chainVec(i)\n218:     }\n219:   }\n220: \n221:   /**"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/util/CSRConst.scala
    lines: 30-40
    context: "30:   /** 0x5C5-0x5E5 for cache instruction register*/\n31:   val Scachebase\
      \    = 0x5C5\n32: \n33:   // Machine level PMA TODO: remove this\n34:   val
      PmacfgBase    = 0x7C0\n35:   val PmaaddrBase   = 0x7C8 // 64 entry at most\n\
      36: \n37:   // Machine level Bitmap Check(Custom Read/Write)\n38:   val Mbmc
      = 0xBC2\n39: \n40:   def privEcall  = 0x000.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/util/CSRConst.scala
    lines: 87-97
    context: "87:     IRQ_UEIP, IRQ_USIP, IRQ_UTIP,\n88:     IRQ_VSEIP, IRQ_VSSIP,
      IRQ_VSTIP, IRQ_SGEIP\n89:   )\n90: \n91:   def csrAccessPermissionCheck(addr:
      UInt, wen: Bool, mode: UInt, virt: Bool, hasH: Bool): UInt = {\n92:     val
      readOnly = addr(11, 10) === \"b11\".U\n93:     val lowestAccessPrivilegeLevel
      = addr(9,8)\n94:     val priv = Mux(mode === ModeS, ModeH, mode)\n95:     val
      ret = Wire(Bool()) //0.U: normal, 1.U: illegal_instruction, 2.U: virtual instruction\n\
      96:     when (lowestAccessPrivilegeLevel === ModeH && !hasH){\n97:       ret
      := 1.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/util/CSRConst.scala
    lines: 93-103
    context: "93:     val lowestAccessPrivilegeLevel = addr(9,8)\n94:     val priv
      = Mux(mode === ModeS, ModeH, mode)\n95:     val ret = Wire(Bool()) //0.U: normal,
      1.U: illegal_instruction, 2.U: virtual instruction\n96:     when (lowestAccessPrivilegeLevel
      === ModeH && !hasH){\n97:       ret := 1.U\n98:     }.elsewhen (readOnly &&
      wen) {\n99:       ret := 1.U\n100:     }.elsewhen (priv < lowestAccessPrivilegeLevel)
      {\n101:       when(virt && lowestAccessPrivilegeLevel <= ModeH){\n102:     \
      \    ret := 2.U\n103:       }.otherwise{"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/util/DebugCSR.scala
    lines: 43-53
    context: "43:     private def prv_offset        = 0\n44:     def init: UInt =
      (\n45:       (DEBUGVER_SPEC.litValue << debugver_offset) | /* Debug implementation
      as it described in 0.13 draft */\n46:       (0L << stopcount_offset) |     \
      \               /* Stop count updating has not been supported */\n47:      \
      \ (0L << stoptime_offset) |                     /* Stop time updating has not
      been supported */\n48:       (0L << mprven_offset) |                       /*
      Whether use mstatus.perven as mprven */\n49:       (ModeM.litValue << prv_offset)\n\
      50:     ).U\n51:   }\n52: }\n53: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/util/CSA.scala
    lines: 32-42
    context: "32:     val (a, b) = (io.in(0)(i), io.in(1)(i))\n33:     val sum = a
      ^ b\n34:     val cout = a & b\n35:     t := Cat(cout, sum)\n36:   }\n37:   io.out.zipWithIndex.foreach({case(x,
      i) => x := Cat(temp.reverse map(_(i)))})\n38: }\n39: \n40: class CSA3_2(len:
      Int) extends CarrySaveAdderMToN(3, 2)(len){\n41:   val temp = Wire(Vec(len,
      UInt(2.W)))\n42:   for((t, i) <- temp.zipWithIndex){"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/util/CSA.scala
    lines: 45-55
    context: "45:     val a_and_b = a & b\n46:     val sum = a_xor_b ^ cin\n47:  \
      \   val cout = a_and_b | (a_xor_b & cin)\n48:     t := Cat(cout, sum)\n49: \
      \  }\n50:   io.out.zipWithIndex.foreach({case(x, i) => x := Cat(temp.reverse
      map(_(i)))})\n51: }\n52: \n53: class CSA5_3(len: Int)extends CarrySaveAdderMToN(5,
      3)(len){\n54:   val FAs = Array.fill(2)(Module(new CSA3_2(len)))\n55:   FAs(0).io.in
      := io.in.take(3)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/Radix2Divider.scala
    lines: 34-45
    context: "34:     val s = a(len - 1) && sign\n35:     (s, Mux(s, -a, a))\n36:\
      \   }\n37: \n38:   val s_idle :: s_log2 :: s_shift :: s_compute :: s_finish
      :: Nil = Enum(5)\n39:   val state = RegInit(s_idle)\n40:   val newReq = (state
      === s_idle) && io.in.fire\n41: \n42:   val (a, b) = (io.in.bits.src(0), io.in.bits.src(1))\n\
      43:   val divBy0 = b === 0.U(len.W)\n44:   val divBy0Reg = RegEnable(divBy0,
      newReq)\n45: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/Radix2Divider.scala
    lines: 57-69
    context: "57:   val aValx2Reg = RegEnable(Cat(aVal, \"b0\".U), newReq)\n58:  \
      \ val ctrlReg = RegEnable(ctrl, newReq)\n59:   val uopReg = RegEnable(uop, newReq)\n\
      60: \n61:   val cnt = Counter(len)\n62:   when (newReq && !io.in.bits.uop.robIdx.needFlush(io.redirectIn))
      {\n63:     state := s_log2\n64:   } .elsewhen (state === s_log2) {\n65:    \
      \ // `canSkipShift` is calculated as following:\n66:     //   bEffectiveBit
      = Log2(bVal, XLEN) + 1.U\n67:     //   aLeadingZero = 64.U - aEffectiveBit =
      64.U - (Log2(aVal, XLEN) + 1.U)\n68:     //   canSkipShift = aLeadingZero +
      bEffectiveBit\n69:     //     = 64.U - (Log2(aVal, XLEN) + 1.U) + Log2(bVal,
      XLEN) + 1.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/Radix2Divider.scala
    lines: 72-99
    context: "72:     val canSkipShift = (64.U | Log2(bReg)) - Log2(aValx2Reg)\n73:\
      \     // When divide by 0, the quotient should be all 1's.\n74:     // Therefore
      we can not shift in 0s here.\n75:     // We do not skip any shift to avoid this.\n\
      76:     cnt.value := Mux(divBy0Reg, 0.U, Mux(canSkipShift >= (len-1).U, (len-1).U,
      canSkipShift))\n77:     state := s_shift\n78:   } .elsewhen (state === s_shift)
      {\n79:     shiftReg := aValx2Reg << cnt.value\n80:     state := s_compute\n\
      81:   } .elsewhen (state === s_compute) {\n82:     val enough = hi.asUInt >=
      bReg.asUInt\n83:     shiftReg := Cat(Mux(enough, hi - bReg, hi)(len - 1, 0),
      lo, enough)\n84:     cnt.inc()\n85:     when (cnt.value === (len-1).U) { state
      := s_finish }\n86:   } .elsewhen (state === s_finish) {\n87:     when(io.out.ready){\n\
      88:       state := s_idle\n89:     }\n90:   }\n91: \n92:   val kill = state=/=s_idle
      && uopReg.robIdx.needFlush(io.redirectIn)\n93:   when(kill){\n94:     state
      := s_idle\n95:   }\n96: \n97:   val r = hi(len, 1)\n98:   val resQ = Mux(qSignReg,
      -lo, lo)\n99:   val resR = Mux(aSignReg, -r, r)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/Radix2Divider.scala
    lines: 101-108
    context: "101:   val xlen = io.out.bits.data.getWidth\n102:   val res = Mux(ctrlReg.isHi,
      resR, resQ)\n103:   io.out.bits.data := Mux(ctrlReg.isW, SignExt(res(31,0),xlen),
      res)\n104:   io.out.bits.uop := uopReg\n105: \n106:   io.out.valid := state
      === s_finish\n107:   io.in.ready := state === s_idle\n108: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 22-32
    context: "22:   val rfWen       = OptionWrapper(cfg.needIntWen, Bool())\n23: \
      \  val fpWen       = OptionWrapper(cfg.needFpWen,  Bool())\n24:   val vecWen\
      \      = OptionWrapper(cfg.needVecWen, Bool())\n25:   val v0Wen       = OptionWrapper(cfg.needV0Wen,
      Bool())\n26:   val vlWen       = OptionWrapper(cfg.needVlWen, Bool())\n27: \
      \  val flushPipe   = OptionWrapper(cfg.flushPipe,  Bool())\n28:   val preDecode\
      \   = OptionWrapper(cfg.hasPredecode, new PreDecodeInfo)\n29:   val ftqIdx \
      \     = OptionWrapper(cfg.needPc || cfg.replayInst || cfg.isSta || cfg.isCsr,
      new FtqPtr)\n30:   val ftqOffset   = OptionWrapper(cfg.needPc || cfg.replayInst
      || cfg.isSta || cfg.isCsr, UInt(log2Up(PredictWidth).W))\n31:   val predictInfo
      = OptionWrapper(cfg.needPdInfo, new Bundle {\n32:     val target    = UInt(VAddrData().dataWidth.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 43-54
    context: "43:   val fpWen         = OptionWrapper(cfg.needFpWen,  Bool())\n44:\
      \   val vecWen        = OptionWrapper(cfg.needVecWen, Bool())\n45:   val v0Wen\
      \         = OptionWrapper(cfg.needV0Wen, Bool())\n46:   val vlWen         =
      OptionWrapper(cfg.needVlWen, Bool())\n47:   val exceptionVec  = OptionWrapper(cfg.exceptionOut.nonEmpty,
      ExceptionVec())\n48:   val flushPipe     = OptionWrapper(cfg.flushPipe,  Bool())\n\
      49:   val replay        = OptionWrapper(cfg.replayInst, Bool())\n50:   val preDecode\
      \     = OptionWrapper(cfg.hasPredecode, new PreDecodeInfo)\n51:   val fpu  \
      \         = OptionWrapper(cfg.writeFflags, new FPUCtrlSignals)\n52:   val vpu\
      \           = OptionWrapper(cfg.needVecCtrl, new VPUCtrlSignals)\n53: }\n54: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 51-61
    context: "51:   val fpu           = OptionWrapper(cfg.writeFflags, new FPUCtrlSignals)\n\
      52:   val vpu           = OptionWrapper(cfg.needVecCtrl, new VPUCtrlSignals)\n\
      53: }\n54: \n55: class FuncUnitDataInput(cfg: FuConfig)(implicit p: Parameters)
      extends XSBundle {\n56:   val src       = MixedVec(cfg.genSrcDataVec)\n57: \
      \  val imm       = UInt(cfg.destDataBits.W)\n58:   val pc        = OptionWrapper(cfg.needPc,
      UInt(VAddrData().dataWidth.W))\n59:   val nextPcOffset = OptionWrapper(cfg.needPc,
      UInt((log2Up(PredictWidth) + 1).W))\n60: \n61:   def getSrcVConfig : UInt =
      src(cfg.vconfigIdx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 62-74
    context: "62:   def getSrcMask    : UInt = src(cfg.maskSrcIdx)\n63: }\n64: \n\
      65: class FuncUnitDataOutput(cfg: FuConfig)(implicit p: Parameters) extends
      XSBundle {\n66:   val data      = UInt(cfg.destDataBits.W)\n67:   val fflags\
      \    = OptionWrapper(cfg.writeFflags, UInt(5.W))\n68:   val vxsat     = OptionWrapper(cfg.writeVxsat,
      Vxsat())\n69:   val redirect  = OptionWrapper(cfg.hasRedirect, ValidIO(new Redirect))\n\
      70: }\n71: \n72: class FuncUnitInput(cfg: FuConfig)(implicit p: Parameters)
      extends XSBundle {\n73:   val needCtrlPipe = cfg.latency.latencyVal.nonEmpty
      && (!cfg.isStd)\n74:   val ctrl = new FuncUnitCtrlInput(cfg)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 86-96
    context: "86:   val perfDebugInfo = new PerfDebugInfo()\n87:   val debug_seqNum
      = InstSeqNum()\n88: }\n89: \n90: class FuncUnitIO(cfg: FuConfig)(implicit p:
      Parameters) extends XSBundle {\n91:   val flush = Flipped(ValidIO(new Redirect))\n\
      92:   val in = Flipped(DecoupledIO(new FuncUnitInput(cfg)))\n93:   val out =
      DecoupledIO(new FuncUnitOutput(cfg))\n94:   val csrin = OptionWrapper(cfg.isCsr,
      new CSRInput)\n95:   val csrio = OptionWrapper(cfg.isCsr, new CSRFileIO)\n96:\
      \   val csrToDecode = OptionWrapper(cfg.isCsr, Output(new CSRToDecode))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 109-147
    context: "109:   PerfCCT.updateInstPos(io.out.bits.debug_seqNum, PerfCCT.InstPos.AtBypassVal.id.U,
      io.out.valid, clock, reset)\n110:   val criticalErrors = Seq((\"none\", false.B))\n\
      111: \n112:   // should only be used in non-piped fu\n113:   def connectNonPipedCtrlSingal:
      Unit = {\n114:     io.out.bits.ctrl.robIdx := RegEnable(io.in.bits.ctrl.robIdx,
      io.in.fire)\n115:     io.out.bits.ctrl.pdest  := RegEnable(io.in.bits.ctrl.pdest,
      io.in.fire)\n116:     io.out.bits.ctrl.rfWen  .foreach(_ := RegEnable(io.in.bits.ctrl.rfWen.get,
      io.in.fire))\n117:     io.out.bits.ctrl.fpWen  .foreach(_ := RegEnable(io.in.bits.ctrl.fpWen.get,
      io.in.fire))\n118:     io.out.bits.ctrl.vecWen .foreach(_ := RegEnable(io.in.bits.ctrl.vecWen.get,
      io.in.fire))\n119:     io.out.bits.ctrl.v0Wen .foreach(_ := RegEnable(io.in.bits.ctrl.v0Wen.get,
      io.in.fire))\n120:     io.out.bits.ctrl.vlWen .foreach(_ := RegEnable(io.in.bits.ctrl.vlWen.get,
      io.in.fire))\n121:     // io.out.bits.ctrl.flushPipe should be connected in
      fu\n122:     io.out.bits.ctrl.preDecode.foreach(_ := RegEnable(io.in.bits.ctrl.preDecode.get,
      io.in.fire))\n123:     io.out.bits.ctrl.fpu      .foreach(_ := RegEnable(io.in.bits.ctrl.fpu.get,
      io.in.fire))\n124:     io.out.bits.ctrl.vpu      .foreach(_ := RegEnable(io.in.bits.ctrl.vpu.get,
      io.in.fire))\n125:     io.out.bits.perfDebugInfo := RegEnable(io.in.bits.perfDebugInfo,
      io.in.fire)\n126:     io.out.bits.debug_seqNum := RegEnable(io.in.bits.debug_seqNum,
      io.in.fire)\n127:   }\n128: \n129:   def connectNonPipedCtrlSingalForCSR: Unit
      = {\n130:     io.out.bits.ctrl.robIdx := DataHoldBypass(io.in.bits.ctrl.robIdx,
      io.in.fire)\n131:     io.out.bits.ctrl.pdest := DataHoldBypass(io.in.bits.ctrl.pdest,
      io.in.fire)\n132:     io.out.bits.ctrl.rfWen.foreach(_ := DataHoldBypass(io.in.bits.ctrl.rfWen.get,
      io.in.fire))\n133:     io.out.bits.ctrl.fpWen.foreach(_ := DataHoldBypass(io.in.bits.ctrl.fpWen.get,
      io.in.fire))\n134:     io.out.bits.ctrl.vecWen.foreach(_ := DataHoldBypass(io.in.bits.ctrl.vecWen.get,
      io.in.fire))\n135:     io.out.bits.ctrl.v0Wen.foreach(_ := DataHoldBypass(io.in.bits.ctrl.v0Wen.get,
      io.in.fire))\n136:     io.out.bits.ctrl.vlWen.foreach(_ := DataHoldBypass(io.in.bits.ctrl.vlWen.get,
      io.in.fire))\n137:     // io.out.bits.ctrl.flushPipe should be connected in
      fu\n138:     io.out.bits.ctrl.preDecode.foreach(_ := DataHoldBypass(io.in.bits.ctrl.preDecode.get,
      io.in.fire))\n139:     io.out.bits.ctrl.fpu.foreach(_ := DataHoldBypass(io.in.bits.ctrl.fpu.get,
      io.in.fire))\n140:     io.out.bits.ctrl.vpu.foreach(_ := DataHoldBypass(io.in.bits.ctrl.vpu.get,
      io.in.fire))\n141:     io.out.bits.perfDebugInfo := DataHoldBypass(io.in.bits.perfDebugInfo,
      io.in.fire)\n142:     io.out.bits.debug_seqNum := DataHoldBypass(io.in.bits.debug_seqNum,
      io.in.fire)\n143:   }\n144: \n145:   def connect0LatencyCtrlSingal: Unit = {\n\
      146:     io.out.bits.ctrl.robIdx := io.in.bits.ctrl.robIdx\n147:     io.out.bits.ctrl.pdest
      := io.in.bits.ctrl.pdest"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 143-161
    context: "143:   }\n144: \n145:   def connect0LatencyCtrlSingal: Unit = {\n146:\
      \     io.out.bits.ctrl.robIdx := io.in.bits.ctrl.robIdx\n147:     io.out.bits.ctrl.pdest
      := io.in.bits.ctrl.pdest\n148:     io.out.bits.ctrl.rfWen.foreach(_ := io.in.bits.ctrl.rfWen.get)\n\
      149:     io.out.bits.ctrl.fpWen.foreach(_ := io.in.bits.ctrl.fpWen.get)\n150:\
      \     io.out.bits.ctrl.vecWen.foreach(_ := io.in.bits.ctrl.vecWen.get)\n151:\
      \     io.out.bits.ctrl.v0Wen.foreach(_ := io.in.bits.ctrl.v0Wen.get)\n152: \
      \    io.out.bits.ctrl.vlWen.foreach(_ := io.in.bits.ctrl.vlWen.get)\n153:  \
      \   // io.out.bits.ctrl.flushPipe should be connected in fu\n154:     io.out.bits.ctrl.preDecode.foreach(_
      := io.in.bits.ctrl.preDecode.get)\n155:     io.out.bits.ctrl.fpu.foreach(_ :=
      io.in.bits.ctrl.fpu.get)\n156:     io.out.bits.ctrl.vpu.foreach(_ := io.in.bits.ctrl.vpu.get)\n\
      157:     io.out.bits.perfDebugInfo := io.in.bits.perfDebugInfo\n158:     io.out.bits.debug_seqNum
      := io.in.bits.debug_seqNum\n159:   }\n160: }\n161: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 167-178
    context: "167: \n168:   val latdiff :Int = cfg.latency.extraLatencyVal.getOrElse(0)\n\
      169:   val preLat :Int = latency - latdiff\n170:   require(latency >= 0 && latdiff
      >=0)\n171: \n172:   def pipelineReg(init: FuncUnitInput , valid:Bool, ready:
      Bool,latency: Int, flush:ValidIO[Redirect]): (Seq[FuncUnitInput],Seq[Bool],Seq[Bool])={\n\
      173:     val rdyVec = Seq.fill(latency)(Wire(Bool())) :+ ready\n174:     val
      validVec = valid +: Seq.fill(latency)(RegInit(false.B))\n175:     val ctrlVec
      = init.ctrl +: Seq.fill(latency)(Reg(chiselTypeOf(io.in.bits.ctrl)))\n176: \
      \    val dataVec = init.data +: Seq.fill(latency)(Reg(chiselTypeOf(io.in.bits.data)))\n\
      177:     val perfVec = init.perfDebugInfo +: Seq.fill(latency)(Reg(chiselTypeOf(io.in.bits.perfDebugInfo)))\n\
      178:     val seqNumVec = init.debug_seqNum +: Seq.fill(latency)(Reg(chiselTypeOf(io.in.bits.debug_seqNum)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 178-188
    context: "178:     val seqNumVec = init.debug_seqNum +: Seq.fill(latency)(Reg(chiselTypeOf(io.in.bits.debug_seqNum)))\n\
      179: \n180:     val robIdxVec = ctrlVec.map(_.robIdx)\n181: \n182:     // if
      flush(0), valid 0 will not given, so set flushVec(0) to false.B\n183:     val
      flushVec = validVec.zip(robIdxVec).map(x => x._1 && x._2.needFlush(flush))\n\
      184: \n185:     for (i <- 0 until latency) {\n186:       rdyVec(i) := !validVec(i
      + 1) || rdyVec(i + 1).asTypeOf(Bool())\n187:     }\n188:     for (i <- 1 to
      latency) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 197-209
    context: "197: \n198:     (ctrlVec.zip(dataVec).zip(perfVec).zip(seqNumVec).map{\n\
      199:       case(((ctrl,data), perf), debug_seqNum) => {\n200:         val out
      = Wire(new FuncUnitInput(cfg))\n201:         out.ctrl := ctrl\n202:        \
      \ out.ctrlPipe.foreach(_ := 0.U.asTypeOf(out.ctrlPipe.get))\n203:         out.validPipe.foreach(_
      := 0.U.asTypeOf(out.validPipe.get))\n204:         out.dataPipe.foreach(_ :=
      0.U.asTypeOf(out.dataPipe.get))\n205:         out.data := data\n206:       \
      \  out.perfDebugInfo := perf\n207:         out.debug_seqNum := debug_seqNum\n\
      208:         out\n209:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 207-217
    context: "207:         out.debug_seqNum := debug_seqNum\n208:         out\n209:\
      \       }\n210:     },validVec, rdyVec)\n211:   }\n212:   val (pipeReg : Seq[FuncUnitInput],
      validVecThisFu ,rdyVec ) = pipelineReg(io.in.bits, io.in.valid,io.out.ready,preLat,
      io.flush)\n213:   val validVec = io.in.bits.validPipe.get.zip(validVecThisFu).map(x
      => x._1 && x._2)\n214:   val ctrlVec = io.in.bits.ctrlPipe.get\n215:   val dataVec
      = io.in.bits.dataPipe.get\n216:   val perfVec = pipeReg.map(_.perfDebugInfo)\n\
      217:   val seqNumVec = pipeReg.map(_.debug_seqNum)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 217-229
    context: "217:   val seqNumVec = pipeReg.map(_.debug_seqNum)\n218: \n219: \n220:\
      \   val fixtiminginit = Wire(new FuncUnitInput(cfg))\n221:   fixtiminginit.ctrl
      := ctrlVec.last\n222:   fixtiminginit.ctrlPipe.foreach(_ := 0.U.asTypeOf(fixtiminginit.ctrlPipe.get))\n\
      223:   fixtiminginit.validPipe.foreach(_ := 0.U.asTypeOf(fixtiminginit.validPipe.get))\n\
      224:   fixtiminginit.dataPipe.foreach(_ := 0.U.asTypeOf(fixtiminginit.dataPipe.get))\n\
      225:   fixtiminginit.data := dataVec.last\n226:   fixtiminginit.perfDebugInfo
      := perfVec.last\n227:   fixtiminginit.debug_seqNum := seqNumVec.last\n228: \n\
      229:   // fixtiming pipelinereg"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 225-235
    context: "225:   fixtiminginit.data := dataVec.last\n226:   fixtiminginit.perfDebugInfo
      := perfVec.last\n227:   fixtiminginit.debug_seqNum := seqNumVec.last\n228: \n\
      229:   // fixtiming pipelinereg\n230:   val (fixpipeReg : Seq[FuncUnitInput],
      fixValidVec, fixRdyVec) = pipelineReg(fixtiminginit, validVec.last,rdyVec.head
      ,latdiff, io.flush)\n231:   val fixDataVec = fixpipeReg.map(_.data)\n232:  \
      \ val fixPerfVec = fixpipeReg.map(_.perfDebugInfo)\n233:   val fixSeqNumVec
      = fixpipeReg.map(_.debug_seqNum)\n234:   val pcVec = fixDataVec.map(_.pc)\n\
      235: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 231-252
    context: "231:   val fixDataVec = fixpipeReg.map(_.data)\n232:   val fixPerfVec
      = fixpipeReg.map(_.perfDebugInfo)\n233:   val fixSeqNumVec = fixpipeReg.map(_.debug_seqNum)\n\
      234:   val pcVec = fixDataVec.map(_.pc)\n235: \n236:   io.in.ready := fixRdyVec.head\n\
      237:   io.out.valid := fixValidVec.last\n238: \n239:   io.out.bits.ctrl.robIdx
      := ctrlVec.last.robIdx\n240:   io.out.bits.ctrl.pdest := ctrlVec.last.pdest\n\
      241:   io.out.bits.ctrl.rfWen.foreach(_ := ctrlVec.last.rfWen.get)\n242:   io.out.bits.ctrl.fpWen.foreach(_
      := ctrlVec.last.fpWen.get)\n243:   io.out.bits.ctrl.vecWen.foreach(_ := ctrlVec.last.vecWen.get)\n\
      244:   io.out.bits.ctrl.v0Wen.foreach(_ := ctrlVec.last.v0Wen.get)\n245:   io.out.bits.ctrl.vlWen.foreach(_
      := ctrlVec.last.vlWen.get)\n246:   io.out.bits.ctrl.fpu.foreach(_ := ctrlVec.last.fpu.get)\n\
      247:   io.out.bits.ctrl.vpu.foreach(_ := ctrlVec.last.vpu.get)\n248:   io.out.bits.perfDebugInfo
      := fixPerfVec.last\n249:   io.out.bits.debug_seqNum := fixSeqNumVec.last\n250:\
      \ \n251:   // vstart illegal\n252:   if (cfg.exceptionOut.nonEmpty) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/Jump.scala
    lines: 24-36
    context: "24: import xiangshan._\n25: import xiangshan.backend._\n26: import xiangshan.backend.decode.ImmUnion\n\
      27: import xiangshan.backend.decode.isa._\n28: \n29: trait HasRedirectOut {
      this: XSModule =>\n30:   val redirectOutValid = IO(Output(Bool()))\n31:   val
      redirectOut = IO(Output(new Redirect))\n32: }\n33: \n34: class JumpDataModule(implicit
      p: Parameters) extends XSModule {\n35:   val io = IO(new Bundle() {\n36:   \
      \  val src = Input(UInt(XLEN.W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuType.scala
    lines: 38-48
    context: "38:   val div = addType(name = \"div\")\n39:   val fence = addType(name
      = \"fence\")\n40:   val bku = addType(name = \"bku\")\n41: \n42:   // fp\n43:\
      \   val falu = addType(name = \"falu\")\n44:   val fmac = addType(name = \"\
      fmac\")\n45:   val fcvt = addType(name = \"fcvt\")\n46:   val fDivSqrt = addType(name
      = \"fDivSqrt\")\n47: \n48:   // ls"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuType.scala
    lines: 59-71
    context: "59:   val vfpu = addType(name = \"vfpu\") // will be deleted\n60:  \
      \ val vfalu = addType(name = \"vfalu\")\n61:   val vfma = addType(name = \"\
      vfma\")\n62:   val vfdiv = addType(name = \"vfdiv\")\n63:   val vfcvt = addType(name
      = \"vfcvt\")\n64:   val vsetiwi = addType(name = \"vsetiwi\") // vset read rs
      write rd\n65:   val vsetiwf = addType(name = \"vsetiwf\") // vset read rs write
      vconfig\n66:   val vsetfwf = addType(name = \"vsetfwf\") // vset read old vl
      write vconfig\n67: \n68:   // vec ls\n69:   val vldu = addType(name = \"vldu\"\
      )\n70:   val vstu = addType(name = \"vstu\")\n71:   val vsegldu = addType(name
      = \"vsegldu\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuType.scala
    lines: 120-130
    context: "120:   }\n121:   def is0latency(fuType: UInt): Bool = {\n122:     val
      fuTypes = FuConfig.allConfigs.filter(_.latency == CertainLatency(0)).map(_.fuType)\n\
      123:     FuTypeOrR(fuType, fuTypes)\n124:   }\n125:   val fpArithAll = Seq(falu,
      fcvt, fmac, fDivSqrt, f2v)\n126:   val scalaMemAll = Seq(ldu, stu, mou)\n127:\
      \   val vecOPI = Seq(vipu, vialuF, vppu, vimac, vidiv)\n128:   val vecOPF =
      Seq(vfpu, vfalu, vfma, vfdiv, vfcvt)\n129:   val vecVSET = Seq(vsetiwi, vsetiwf,
      vsetfwf)\n130:   val vecArith = vecOPI ++ vecOPF"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuType.scala
    lines: 201-211
    context: "201: \n202:   def isVArithMem(fuType: UInt): Bool = FuTypeOrR(fuType,
      vecArithOrMem) // except vset\n203: \n204:   def isDivSqrt(fuType: UInt): Bool
      = FuTypeOrR(fuType, div, fDivSqrt)\n205: \n206:   def storeIsAMO(fuType: UInt):
      Bool = FuTypeOrR(fuType, mou)\n207: \n208:   def isVppu(fuType: UInt): Bool
      = FuTypeOrR(fuType, vppu)\n209: \n210:   def isScalaNeedFrm(fuType: UInt): Bool
      = FuTypeOrR(fuType, scalaNeedFrm)\n211: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuType.scala
    lines: 210-233
    context: "210:   def isScalaNeedFrm(fuType: UInt): Bool = FuTypeOrR(fuType, scalaNeedFrm)\n\
      211: \n212:   def isVectorNeedFrm(fuType: UInt): Bool = FuTypeOrR(fuType, vectorNeedFrm)\n\
      213: \n214:   object FuTypeOrR {\n215:     def apply(fuType: UInt, fu0: OHType,
      fus: OHType*): Bool = {\n216:       apply(fuType, fu0 +: fus)\n217:     }\n\
      218: \n219:     def apply(fuType: UInt, fus: Seq[OHType]): Bool = {\n220:  \
      \     fus.map(x => fuType(x.id)).fold(false.B)(_ || _)\n221:     }\n222: \n\
      223:     def apply(fuType: OHType, fu0: OHType, fus: OHType*): Boolean = {\n\
      224:       apply(fuType, fu0 +: fus)\n225:     }\n226: \n227:     def apply(fuTupe:
      OHType, fus: Seq[OHType]): Boolean = {\n228:       fus.map(x => x == fuTupe).fold(false)(_
      || _)\n229:     }\n230:   }\n231: \n232:   val functionNameMap = Map(\n233:\
      \     jmp -> \"jmp\","
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/fpu/Bundles.scala
    lines: 3-9
    context: "3: import utils.NamedUInt\n4: \n5: object Bundles {\n6:   object Frm
      extends NamedUInt(3)\n7: \n8:   object Fflags extends NamedUInt(5)\n9: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/fpu/IntToFP.scala
    lines: 56-71
    context: "56:   mux.data := intValue\n57:   mux.exc := 0.U\n58: \n59:   when(s2_wflags){\n\
      60:     val i2fResults = for(t <- FPU.ftypes.take(3)) yield {\n61:       val
      i2f = Module(new scalar.IntToFP(t.expWidth, t.precision))\n62:       i2f.io.sign
      := ~s2_typ(0)\n63:       i2f.io.long := s2_typ(1)\n64:       i2f.io.int := intValue\n\
      65:       i2f.io.rm := rmReg\n66:       (i2f.io.result, i2f.io.fflags)\n67:\
      \     }\n68:     val (data, exc) = i2fResults.unzip\n69:     mux.data := VecInit(data)(s2_tag)\n\
      70:     mux.exc := VecInit(exc)(s2_tag)\n71:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/fpu/IntToFP.scala
    lines: 72-82
    context: "72: \n73:   // stage3\n74:   val s3_out = RegEnable(mux, regEnables(1))\n\
      75:   val s3_tag = RegEnable(s2_tag, regEnables(1))\n76: \n77:   io.out.fflags
      := s3_out.exc\n78:   io.out.data := FPU.box(s3_out.data, s3_tag)\n79: }\n80:\
      \ \n81: class IntToFP(cfg: FuConfig)(implicit p: Parameters) extends FPUPipelineModule(cfg)
      {\n82:   override def latency: Int = cfg.latency.latencyVal.get"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/fpu/FPUSubModule.scala
    lines: 36-46
    context: "36:       val fpCtrl = new FPUCtrlSignals\n37:       val rm = UInt(3.W)\n\
      38:     })\n39:     val out = Output(new Bundle() {\n40:       val data = UInt(64.W)\n\
      41:       val fflags = UInt(5.W)\n42:     })\n43:   })\n44: \n45:   val rm =
      Mux(io.in.fpCtrl.rm === \"b111\".U, io.in.rm, io.in.fpCtrl.rm)\n46: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/fpu/FPUSubModule.scala
    lines: 51-64
    context: "51:   val dataModule: FPUDataModule\n52:   def connectDataModule = {\n\
      53:     for (i <- 0 until dataModule.io.in.src.length) {\n54:       dataModule.io.in.src(i)
      := (if (i < io.in.bits.data.src.length) io.in.bits.data.src(i) else 0.U)\n55:\
      \     }\n56:     io.in.bits.ctrl.fpu.foreach(_ <> dataModule.io.in.fpCtrl)\n\
      57:     dataModule.io.in.rm <> io.frm.get\n58:     io.out.bits.res.data := dataModule.io.out.data\n\
      59:     io.out.bits.res.fflags.get := dataModule.io.out.fflags\n60:   }\n61:\
      \   def invert_sign(x: UInt, len: Int) = {\n62:     Cat(\n63:       !x(len-1),
      x(len-2, 0)\n64:     )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/fpu/FpNonPipedFuncUnit.scala
    lines: 7-16
    context: "7: import xiangshan.backend.fu.{FuConfig, FuncUnit}\n8: \n9: class FpNonPipedFuncUnit(cfg:
      FuConfig)(implicit p: Parameters) extends FuncUnit(cfg)\n10:   with FpFuncUnitAlias\n\
      11: {\n12:   protected val outCtrl     = DataHoldBypass(io.in.bits.ctrl, io.in.fire)\n\
      13:   protected val outData     = DataHoldBypass(io.in.bits.data, io.in.fire)\n\
      14: \n15:   connectNonPipedCtrlSingal\n16: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/fpu/IntFPToVec.scala
    lines: 77-89
    context: "77:     Cat(0.U, Fill(3, 1.U), 1.U, 0.U(3.W)),\n78:     Cat(0.U, Fill(5,
      1.U), 1.U, 0.U(9.W)),\n79:     Cat(0.U, Fill(8, 1.U), 1.U, 0.U(22.W))\n80: \
      \  )\n81:   private val isFpCanonicalNAN = Seq(\n82:     !scalaData.head(56).andR,\n\
      83:     !scalaData.head(48).andR,\n84:     !scalaData.head(32).andR\n85:   )\n\
      86: \n87:   private val fpData = Mux1H(Seq(\n88:     (vsew === VSew.e8)  ->
      Cat(Fill(56, 1.U), scalaData( 7, 0)),\n89:     (vsew === VSew.e16) -> Cat(Fill(48,
      1.U), scalaData(15, 0)),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/fpu/FPU.scala
    lines: 4-16
    context: "4: import chisel3.util._\n5: import fudian.FloatPoint\n6: \n7: object
      FPU {\n8: \n9:   case class FType(expWidth: Int, precision: Int) {\n10:    \
      \ val sigWidth = precision - 1\n11:     val len = expWidth + precision\n12:\
      \   }\n13: \n14:   val f16 = FType(5, 11)\n15:   val f32 = FType(8, 24)\n16:\
      \   val f64 = FType(11, 53)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/fpu/FPU.scala
    lines: 28-39
    context: "28:   def unbox(x: UInt, typeTag: UInt): UInt = {\n29:     require(x.getWidth
      == 64)\n30:     require(typeTag.getWidth == ftypeWidth)\n31:     Mux1H(Seq(\n\
      32:       (typeTag === D) -> x,\n33:       (typeTag === S) -> Mux(x.head(32).andR,
      x(f32.len - 1, 0), FloatPoint.defaultNaNUInt(f32.expWidth, f32.precision)),\n\
      34:       (typeTag === H) -> Mux(x.head(48).andR, x(f16.len - 1, 0), FloatPoint.defaultNaNUInt(f16.expWidth,
      f16.precision)),\n35:     ))\n36:   }\n37: \n38:   def box(x: UInt, typeTag:
      UInt): UInt = {\n39:     require(x.getWidth == 64)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 35-45
    context: "35: import utils.MathUtils.{BigIntGenMask, BigIntNot}\n36: import xiangshan.backend.trace._\n\
      37: import freechips.rocketchip.rocket.CSRs\n38: \n39: class FpuCsrIO extends
      Bundle {\n40:   val fflags = Output(Valid(UInt(5.W)))\n41:   val isIllegal =
      Output(Bool())\n42:   val dirty_fs = Output(Bool())\n43:   val frm = Input(UInt(3.W))\n\
      44: }\n45: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 139-149
    context: "139:   with SdtrigExt\n140:   with DebugCSR\n141: {\n142:   val csrio
      = io.csrio.get\n143: \n144:   val flushPipe = Wire(Bool())\n145: \n146:   val
      (valid, src1, src2, func) = (\n147:     io.in.valid,\n148:     io.in.bits.data.src(0),\n\
      149:     io.in.bits.data.imm,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 318-328
    context: "318: \n319:   val mipWMask = vssip_Mask | ((1 << 9) | (1 << 5) | (1
      << 1)).U(XLEN.W)\n320:   val mieWMask = mip_mie_WMask_H | \"haaa\".U(XLEN.W)\n\
      321: \n322:   def getMisaMxl(mxl: BigInt): BigInt = mxl << (XLEN - 2)\n323:\
      \   def getMisaExt(ext: Char): Long = 1 << (ext.toInt - 'a'.toInt)\n324:   var
      extList = List('a', 's', 'i', 'u')\n325:   if (HasMExtension) { extList = extList
      :+ 'm' }\n326:   if (HasCExtension) { extList = extList :+ 'c' }\n327:   if
      (HasHExtension) { extList = extList :+ 'h' }\n328:   if (HasFPU) { extList =
      extList ++ List('f', 'd') }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 325-336
    context: "325:   if (HasMExtension) { extList = extList :+ 'm' }\n326:   if (HasCExtension)
      { extList = extList :+ 'c' }\n327:   if (HasHExtension) { extList = extList
      :+ 'h' }\n328:   if (HasFPU) { extList = extList ++ List('f', 'd') }\n329: \
      \  if (HasVPU) { extList = extList :+ 'v' }\n330:   val misaInitVal = getMisaMxl(2)
      | extList.foldLeft(0L)((sum, i) => sum | getMisaExt(i)) //\"h8000000000141185\"\
      .U\n331:   val misa = RegInit(UInt(XLEN.W), misaInitVal.U)\n332:   println(s\"\
      [CSR] supported isa ext: $extList\")\n333: \n334:   // MXL = 2          | 0
      | EXT = b 00 0000 0100 0001 0001 0000 0101\n335:   // (XLEN-1, XLEN-2) |   |(25,
      0)  ZY XWVU TSRQ PONM LKJI HGFE DCBA\n336: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 338-353
    context: "338:   val menvcfg = RegInit(UInt(XLEN.W), 0.U)\n339: \n340:   val mvendorid
      = RegInit(UInt(XLEN.W), 0.U) // this is a non-commercial implementation\n341:\
      \   val marchid = RegInit(UInt(XLEN.W), 25.U) // architecture id for XiangShan
      is 25; see https://github.com/riscv/riscv-isa-manual/blob/master/marchid.md\n\
      342:   val mimpid = RegInit(UInt(XLEN.W), 0.U) // provides a unique encoding
      of the version of the processor implementation\n343:   val mhartid = Reg(UInt(XLEN.W))
      // the hardware thread running the code\n344:   when (RegNext(RegNext(reset.asBool)
      && !reset.asBool)) {\n345:     mhartid := csrio.hartId\n346:   }\n347:   val
      mconfigptr = RegInit(UInt(XLEN.W), 0.U) // the read-only pointer pointing to
      the platform config structure, 0 for not supported.\n348:   val mstatus = RegInit(\"\
      ha00002200\".U(XLEN.W))\n349: \n350:   // mstatus Value Table\n351:   // | sd\
      \   | Read Only\n352:   // | pad1 | WPRI\n353:   // | sxl  | hardlinked to 10,
      use 00 to pass xv6 test"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 365-383
    context: "365:   // | vs   | 01 |\n366:   // | spp  | 0 |\n367:   // | pie  |
      0000 | pie.h is used as UBE\n368:   // | ie   | 0000 | uie hardlinked to 0,
      as N ext is not implemented\n369: \n370:   val mstatusStruct = mstatus.asTypeOf(new
      MstatusStruct)\n371:   def mstatusUpdateSideEffect(mstatus: UInt): UInt = {\n\
      372:     val mstatusOld = WireInit(mstatus.asTypeOf(new MstatusStruct))\n373:\
      \     // Cat(sd, other)\n374:     val mstatusNew = Cat(\n375:       mstatusOld.xs
      === ContextStatus.dirty || mstatusOld.fs === ContextStatus.dirty || mstatusOld.vs
      === ContextStatus.dirty,\n376:       mstatus(XLEN-2, 0)\n377:     )\n378:  \
      \   mstatusNew\n379:   }\n380:   def vsstatusUpdateSideEffect(vsstatus: UInt):
      UInt = {\n381:     val vsstatusOld = WireInit(vsstatus.asTypeOf(new MstatusStruct))\n\
      382:     val vsstatusNew = Cat(vsstatusOld.xs === \"b11\".U || vsstatusOld.fs
      === \"b11\".U, vsstatus(XLEN-2, 0))\n383:     vsstatusNew"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 381-391
    context: "381:     val vsstatusOld = WireInit(vsstatus.asTypeOf(new MstatusStruct))\n\
      382:     val vsstatusNew = Cat(vsstatusOld.xs === \"b11\".U || vsstatusOld.fs
      === \"b11\".U, vsstatus(XLEN-2, 0))\n383:     vsstatusNew\n384:   }\n385:  \
      \ val mstatusWMask = (~ZeroExt((\n386:     GenMask(63)           | // SD is
      read-only\n387:     (if(HasHExtension)\n388:         GenMask(62, 40)    // WPRI\n\
      389:       else\n390:         GenMask(62, 38)  )| // WPRI\n391:     GenMask(35,
      32)       | // SXL and UXL cannot be changed"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 388-398
    context: "388:         GenMask(62, 40)    // WPRI\n389:       else\n390:     \
      \    GenMask(62, 38)  )| // WPRI\n391:     GenMask(35, 32)       | // SXL and
      UXL cannot be changed\n392:     GenMask(31, 23)       | // WPRI\n393:     GenMask(16,
      15)       | // XS is read-only\n394:     GenMask(6)            | // UBE, always
      little-endian (0)\n395:     GenMask(4)            | // WPRI\n396:     GenMask(2)\
      \            | // WPRI\n397:     GenMask(0)              // WPRI\n398:   ),
      64)).asUInt"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 418-433
    context: "418:   // !WARNNING: pmp and pma CSRs are not checked in difftest.\n\
      419: \n420:   // Supervisor-Level CSRs\n421: \n422:   val sstatusWNmask: BigInt
      = (\n423:     BigIntGenMask(63)     | // SD is read-only\n424:     BigIntGenMask(62,
      34) | // WPRI\n425:     BigIntGenMask(33, 32) | // UXL is hard-wired to 64(b10)\n\
      426:     BigIntGenMask(31, 20) | // WPRI\n427:     BigIntGenMask(17)     | //
      WPRI\n428:     BigIntGenMask(16, 15) | // XS is read-only to zero\n429:    \
      \ BigIntGenMask(12, 11) | // WPRI\n430:     BigIntGenMask(7)      | // WPRI\n\
      431:     BigIntGenMask(6)      | // UBE is always little-endian (0)\n432:  \
      \   BigIntGenMask(4, 2)   | // WPRI\n433:     BigIntGenMask(0)        // WPRI"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 629-639
    context: "629: \n630:   // fcsr\n631:   class FcsrStruct extends Bundle {\n632:\
      \     val reserved = UInt((XLEN-3-5).W)\n633:     val frm = UInt(3.W)\n634:\
      \     val fflags = UInt(5.W)\n635:     assert(this.getWidth == XLEN)\n636: \
      \  }\n637:   val fcsr = RegInit(0.U(XLEN.W))\n638:   // set mstatus->sd and
      mstatus->fs when true\n639:   val csrw_dirty_fp_state = WireInit(false.B)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 648-660
    context: "648: \n649:   def fflags_wfn(update: Boolean)(wdata: UInt): UInt = {\n\
      650:     val fcsrOld = fcsr.asTypeOf(new FcsrStruct)\n651:     val fcsrNew =
      WireInit(fcsrOld)\n652:     if (update) {\n653:       fcsrNew.fflags := wdata(4,0)
      | fcsrOld.fflags\n654:     } else {\n655:       fcsrNew.fflags := wdata(4,0)\n\
      656:     }\n657:     fcsrNew.asUInt\n658:   }\n659:   def fflags_rfn(rdata:UInt):
      UInt = rdata(4,0)\n660: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 659-673
    context: "659:   def fflags_rfn(rdata:UInt): UInt = rdata(4,0)\n660: \n661:  \
      \ def fcsr_wfn(wdata: UInt): UInt = {\n662:     val fcsrOld = WireInit(fcsr.asTypeOf(new
      FcsrStruct))\n663:     csrw_dirty_fp_state := true.B\n664:     Cat(fcsrOld.reserved,
      wdata.asTypeOf(fcsrOld).frm, wdata.asTypeOf(fcsrOld).fflags)\n665:   }\n666:\
      \ \n667:   val fcsrMapping = Map(\n668:     MaskedRegMap(Fflags, fcsr, wfn =
      fflags_wfn(update = false), rfn = fflags_rfn),\n669:     MaskedRegMap(Frm, fcsr,
      wfn = frm_wfn, rfn = frm_rfn),\n670:     MaskedRegMap(Fcsr, fcsr, wfn = fcsr_wfn)\n\
      671:   )\n672: \n673:   // Vector extension CSRs"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 760-775
    context: "760:   val csrevents = perfEvents.slice(24, 29)\n761:   val hpm_hc =
      HPerfMonitor(csrevents, hpmEvents)\n762:   val mcountinhibit = RegInit(0.U(XLEN.W))\n\
      763:   val mcycle = RegInit(0.U(XLEN.W))\n764:   mcycle := mcycle + 1.U\n765:\
      \   val minstret = RegInit(0.U(XLEN.W))\n766:   val perf_events = csrio.perf.perfEventsFrontend
      ++\n767:                     csrio.perf.perfEventsBackend ++\n768:         \
      \            csrio.perf.perfEventsLsu ++\n769:                     hpm_hc.getPerf\n\
      770:   minstret := minstret + RegNext(csrio.perf.retiredInstr)\n771:   for(i
      <- 0 until 29){\n772:     perfCnts(i) := Mux(mcountinhibit(i+3) | !perfEventscounten(i),
      perfCnts(i), perfCnts(i) + perf_events(i).value)\n773:   }\n774: \n775:   //
      CSR reg map"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 781-794
    context: "781:     // TODO: support Unprivileged Counter/Timers CSRs (\"Zicntr\"\
      \ and \"Zihpm\")\n782:     // Unprivileged Counter/Timers\n783:     MaskedRegMap(Cycle,
      mcycle),\n784:     // We don't support read time CSR.\n785:     // MaskedRegMap(Time,
      mtime),\n786:     MaskedRegMap(Instret, minstret),\n787: \n788:     //--- Supervisor
      Trap Setup ---\n789:     MaskedRegMap(Sstatus, mstatus, sstatusWmask, mstatusUpdateSideEffect,
      sstatusRmask),\n790:     // MaskedRegMap(Sedeleg, Sedeleg),\n791:     // MaskedRegMap(Sideleg,
      Sideleg),\n792:     MaskedRegMap(Sie, mie, sieMask, MaskedRegMap.NoSideEffect,
      sieMask),\n793:     MaskedRegMap(Stvec, stvec, stvecMask, MaskedRegMap.NoSideEffect,
      stvecMask),\n794:     MaskedRegMap(Scounteren, scounteren, scounterenMask),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 822-833
    context: "822: \n823:     //--- Machine Configuration Registers ---\n824:    \
      \ MaskedRegMap(Menvcfg, menvcfg),\n825: \n826:     //--- Machine Trap Setup
      ---\n827:     MaskedRegMap(Mstatus, mstatus, mstatusWMask, mstatusUpdateSideEffect),\n\
      828:     MaskedRegMap(Misa, misa, 0.U, MaskedRegMap.Unwritable), // now whole
      misa is unchangeable\n829:     MaskedRegMap(Medeleg, medeleg, medelegWMask),\n\
      830:     MaskedRegMap(Mideleg, mideleg, midelegWMask),\n831:     MaskedRegMap(Mie,
      mie, mieWMask),\n832:     MaskedRegMap(Mtvec, mtvec, mtvecMask, MaskedRegMap.NoSideEffect,
      mtvecMask),\n833:     MaskedRegMap(Mcounteren, mcounteren, mcounterenMask),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 844-854
    context: "844:     // Todo: support chain length = 2\n845:     MaskedRegMap(Tdata1,
      tdata1RegVec(tselectPhy),\n846:       WritableMask,\n847:       x => Tdata1Bundle.Write(x,
      tdata1RegVec(tselectPhy), newTriggerChainIsLegal, debug_mode = debugMode),\n\
      848:       WritableMask,\n849:       x => Tdata1Bundle.Read(x)),\n850:     MaskedRegMap(Tdata2,
      tdata2RegVec(tselectPhy)),\n851:     MaskedRegMap(Tinfo, tinfo, 0.U(XLEN.W),
      MaskedRegMap.Unwritable),\n852: \n853:     //--- Debug Mode ---\n854:     MaskedRegMap(Dcsr,
      dcsr, dcsrMask, dcsrUpdateSideEffect),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 855-865
    context: "855:     MaskedRegMap(Dpc, dpc),\n856:     MaskedRegMap(Dscratch0, dscratch0),\n\
      857:     MaskedRegMap(Dscratch1, dscratch1),\n858:     MaskedRegMap(Mcountinhibit,
      mcountinhibit),\n859:     MaskedRegMap(Mcycle, mcycle),\n860:     MaskedRegMap(Minstret,
      minstret),\n861:   )\n862: \n863:   // hypervisor csr map\n864:   val hcsrMapping
      = Map(\n865:     //--- Hypervisor Trap Setup ---"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1014-1024
    context: "1014:   val perfcntPermitted = perfcntPermissionCheck(addr, privilegeMode,
      mcounteren, scounteren)\n1015:   val permitted = Mux(addrInPerfCnt, perfcntPermitted,
      modePermitted) && Mux(virtMode, vaccessPermitted, accessPermitted)\n1016:  \
      \ MaskedRegMap.generate(mapping, addr, rdata_tmp, wen && permitted, wdata)\n\
      1017:   rdata := Mux(is_vsip_ie, ZeroExt(rdata_tmp >> 1, XLEN), rdata_tmp)\n\
      1018:   io.out.bits.res.data := rdata\n1019:   io.out.bits.ctrl.flushPipe.get
      := flushPipe\n1020:   connect0LatencyCtrlSingal\n1021: \n1022:   // send distribute
      csr a w signal\n1023:   csrio.customCtrl.distribute_csr.w.valid := wen && permitted\n\
      1024:   csrio.customCtrl.distribute_csr.w.bits.data := wdata"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1022-1033
    context: "1022:   // send distribute csr a w signal\n1023:   csrio.customCtrl.distribute_csr.w.valid
      := wen && permitted\n1024:   csrio.customCtrl.distribute_csr.w.bits.data :=
      wdata\n1025:   csrio.customCtrl.distribute_csr.w.bits.addr := addr\n1026: \n\
      1027:   when (RegNext(csrio.fpu.fflags.valid)) {\n1028:     fcsr := fflags_wfn(update
      = true)(RegEnable(csrio.fpu.fflags.bits, csrio.fpu.fflags.valid))\n1029:   }\n\
      1030:   when(RegNext(csrio.vpu.set_vxsat.valid)) {\n1031:     vcsr := vxsat_wfn(update
      = true)(RegEnable(csrio.vpu.set_vxsat.bits, csrio.vpu.set_vxsat.valid))\n1032:\
      \   }\n1033: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1031-1044
    context: "1031:     vcsr := vxsat_wfn(update = true)(RegEnable(csrio.vpu.set_vxsat.bits,
      csrio.vpu.set_vxsat.valid))\n1032:   }\n1033: \n1034:   // set fs and sd in
      mstatus\n1035:   when (csrw_dirty_fp_state || RegNext(csrio.fpu.dirty_fs)) {\n\
      1036:     val mstatusNew = WireInit(mstatus.asTypeOf(new MstatusStruct))\n1037:\
      \     mstatusNew.fs := \"b11\".U\n1038:     mstatusNew.sd := true.B\n1039: \
      \    mstatus := mstatusNew.asUInt\n1040:     when(virtMode){\n1041:       val
      vsstatusNew = WireInit(vsstatus.asTypeOf(new MstatusStruct))\n1042:       vsstatusNew.fs
      := \"b11\".U\n1043:       vsstatusNew.sd := true.B\n1044:       vsstatus :=
      vsstatusNew.asUInt"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1053-1066
    context: "1053:     vtype := RegEnable(csrio.vpu.set_vtype.bits, csrio.vpu.set_vtype.valid)\n\
      1054:   }\n1055:   vl := csrio.vpu.vl\n1056:   // set vs and sd in mstatus\n\
      1057:   when(csrw_dirty_vs_state || RegNext(csrio.vpu.dirty_vs)) {\n1058:  \
      \   val mstatusNew = WireInit(mstatus.asTypeOf(new MstatusStruct))\n1059:  \
      \   mstatusNew.vs := ContextStatus.dirty\n1060:     mstatusNew.sd := true.B\n\
      1061:     mstatus := mstatusNew.asUInt\n1062:   }\n1063: \n1064:   csrio.vpu.vstart
      := vstart\n1065:   csrio.vpu.vxrm := vcsr.asTypeOf(new VcsrStruct).vxrm\n1066: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1138-1149
    context: "1138:   tlbBundle.priv.imode := privilegeMode\n1139:   tlbBundle.priv.dmode
      := Mux((debugMode && dcsr.asTypeOf(new DcsrStruct).mprven || !debugMode) &&
      mstatusStruct.mprv.asBool, mstatusStruct.mpp, privilegeMode)\n1140: \n1141:\
      \   // Branch control\n1142:   val retTarget = WireInit(0.U)\n1143:   val resetSatp
      = (addr === Satp.U || addr === Hgatp.U || addr === Vsatp.U) && wen // write
      to satp will cause the pipeline be flushed\n1144:   val writeVstart = addr ===
      Vstart.U && wen // write to vstart will cause the pipeline be flushed\n1145:\
      \   dontTouch(writeVstart)\n1146: \n1147:   val w_fcsr_change_rm = wen && addr
      === Fcsr.U && wdata(7, 5) =/= fcsr(7, 5)\n1148:   val w_frm_change_rm = wen
      && addr === Frm.U && wdata(2, 0) =/= fcsr(7, 5)\n1149:   val frm_change = w_fcsr_change_rm
      || w_frm_change_rm"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1146-1156
    context: "1146: \n1147:   val w_fcsr_change_rm = wen && addr === Fcsr.U && wdata(7,
      5) =/= fcsr(7, 5)\n1148:   val w_frm_change_rm = wen && addr === Frm.U && wdata(2,
      0) =/= fcsr(7, 5)\n1149:   val frm_change = w_fcsr_change_rm || w_frm_change_rm\n\
      1150:   val isXRet = valid && func === CSROpType.jmp && !isEcall && !isEbreak\n\
      1151:   flushPipe := resetSatp || frm_change || isXRet || frontendTriggerUpdate
      || writeVstart\n1152: \n1153:   private val illegalRetTarget = WireInit(false.B)\n\
      1154:   when(valid) {\n1155:     when(isDret) {\n1156:       retTarget := dpc(VAddrBits
      - 1, 0)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1168-1183
    context: "1168:   }\n1169: \n1170:   // Mux tree for regs\n1171:   when(valid)
      {\n1172:     when(isDret) {\n1173:       val mstatusNew = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1174:       val debugModeNew = WireInit(debugMode)\n1175: \
      \      when(dcsr.asTypeOf(new DcsrStruct).prv =/= ModeM) {\n1176:         mstatusNew.mprv
      := 0.U\n1177:       } //If the new privilege mode is less privileged than M-mode,
      MPRV in mstatus is cleared.\n1178:       mstatus := mstatusNew.asUInt\n1179:\
      \       privilegeMode := dcsr.asTypeOf(new DcsrStruct).prv\n1180:       debugModeNew
      := false.B\n1181:       debugIntrEnable := true.B\n1182:       debugMode :=
      debugModeNew\n1183:       XSDebug(\"Debug Mode: Dret executed, returning to
      %x.\", retTarget)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1180-1206
    context: "1180:       debugModeNew := false.B\n1181:       debugIntrEnable :=
      true.B\n1182:       debugMode := debugModeNew\n1183:       XSDebug(\"Debug Mode:
      Dret executed, returning to %x.\", retTarget)\n1184:     }.elsewhen(isMret &&
      !illegalMret) {\n1185:       val mstatusOld = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1186:       val mstatusNew = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1187:       mstatusNew.ie.m := mstatusOld.pie.m\n1188:    \
      \   privilegeMode := mstatusOld.mpp\n1189:       if (HasHExtension) {\n1190:\
      \         virtMode := mstatusOld.mpv\n1191:         mstatusNew.mpv := 0.U\n\
      1192:       }\n1193:       mstatusNew.pie.m := true.B\n1194:       mstatusNew.mpp
      := ModeU\n1195:       when(mstatusOld.mpp =/= ModeM) {\n1196:         mstatusNew.mprv
      := 0.U\n1197:       }\n1198:       mstatus := mstatusNew.asUInt\n1199:     }.elsewhen(isSret
      && !illegalSret && !illegalSModeSret && !illegalVSModeSret) {\n1200:       val
      mstatusOld = WireInit(mstatus.asTypeOf(new MstatusStruct))\n1201:       val
      mstatusNew = WireInit(mstatus.asTypeOf(new MstatusStruct))\n1202:       val
      hstatusOld = WireInit(hstatus.asTypeOf(new HstatusStruct))\n1203:       val
      hstatusNew = WireInit(hstatus.asTypeOf(new HstatusStruct))\n1204:       val
      vsstatusOld = WireInit(vsstatus.asTypeOf(new MstatusStruct))\n1205:       val
      vsstatusNew = WireInit(vsstatus.asTypeOf(new MstatusStruct))\n1206:       when(virtMode
      === 0.U) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1204-1221
    context: "1204:       val vsstatusOld = WireInit(vsstatus.asTypeOf(new MstatusStruct))\n\
      1205:       val vsstatusNew = WireInit(vsstatus.asTypeOf(new MstatusStruct))\n\
      1206:       when(virtMode === 0.U) {\n1207:         virtMode := hstatusOld.spv\n\
      1208:         hstatusNew.spv := 0.U\n1209:         mstatusNew.ie.s := mstatusOld.pie.s\n\
      1210:         privilegeMode := Cat(0.U(1.W), mstatusOld.spp)\n1211:        \
      \ mstatusNew.pie.s := true.B\n1212:         mstatusNew.spp := ModeU\n1213: \
      \        when(mstatusOld.spp =/= ModeM) {\n1214:           mstatusNew.mprv :=
      0.U\n1215:         }\n1216:         mstatus := mstatusNew.asUInt\n1217:    \
      \     hstatus := hstatusNew.asUInt\n1218:       }.otherwise {\n1219:       \
      \  privilegeMode := vsstatusOld.spp\n1220:         vsstatusNew.spp := ModeU\n\
      1221:         vsstatusNew.ie.s := vsstatusOld.pie.s"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1221-1241
    context: "1221:         vsstatusNew.ie.s := vsstatusOld.pie.s\n1222:         vsstatusNew.pie.s
      := 1.U\n1223:         vsstatus := vsstatusNew.asUInt\n1224:       }\n1225: \
      \    }.elsewhen(isUret) {\n1226:       val mstatusOld = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1227:       val mstatusNew = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1228:       // mstatusNew.mpp.m := ModeU //TODO: add mode U\n\
      1229:       mstatusNew.ie.u := mstatusOld.pie.u\n1230:       privilegeMode :=
      ModeU\n1231:       mstatusNew.pie.u := true.B\n1232:       mstatus := mstatusNew.asUInt\n\
      1233:     }\n1234:   }\n1235: \n1236:   io.in.ready := true.B\n1237:   io.out.valid
      := valid\n1238: \n1239:   // In this situation, hart will enter debug mode instead
      of handling a breakpoint exception simply.\n1240:   // Ebreak block instructions
      backwards, so it's ok to not keep extra info to distinguish between breakpoint\n\
      1241:   // exception and enter-debug-mode exception."
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1328-1338
    context: "1328:   val triggerFireOH = PriorityEncoderOH(triggerCanFireVec)\n1329:\
      \   val triggerFireAction = PriorityMux(triggerFireOH, tdata1WireVec.map(_.getTriggerAction)).asUInt\n\
      1330: \n1331: \n1332:   XSDebug(hasSingleStep, \"Debug Mode: single step exception\\\
      n\")\n1333:   XSDebug(hasTriggerFire, p\"Debug Mode: trigger fire, frontend
      hit vec ${Binary(csrio.exception.bits.trigger.frontendHit.asUInt)} \" +\n1334:\
      \     p\"backend hit vec ${Binary(csrio.exception.bits.trigger.backendHit.asUInt)}\\\
      n\")\n1335: \n1336:   val hasExceptionVec = csrio.exception.bits.exceptionVec\n\
      1337:   val regularExceptionNO = ExceptionNO.priorities.foldRight(0.U)((i: Int,
      sum: UInt) => Mux(hasExceptionVec(i), i.U, sum))\n1338:   val exceptionNO =
      Mux(hasSingleStep || hasTriggerFire, 3.U, regularExceptionNO)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1348-1360
    context: "1348: \n1349:   XSDebug(hasExceptionIntr, \"int/exc: pc %x int (%d):%x
      exc: (%d):%x\\n\",\n1350:     dexceptionPC, intrNO, intrVec, exceptionNO, hasExceptionVec.asUInt\n\
      1351:   )\n1352:   XSDebug(hasExceptionIntr,\n1353:     \"pc %x mstatus %x mideleg
      %x medeleg %x mode %x\\n\",\n1354:     dexceptionPC,\n1355:     mstatus,\n1356:\
      \     mideleg,\n1357:     medeleg,\n1358:     privilegeMode\n1359:   )\n1360: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1431-1441
    context: "1431: \n1432:   val clearTval_h = !updateTval_h || hasIntr\n1433:  \
      \ val isHyperInst = csrio.exception.bits.isHls\n1434:   // ctrl block will use
      theses later for flush\n1435:   val isXRetFlag = RegInit(false.B)\n1436:   when
      (DelayN(io.flush.valid, 5)) {\n1437:     isXRetFlag := false.B\n1438:   }.elsewhen
      (isXRet) {\n1439:     isXRetFlag := true.B\n1440:   }\n1441:   csrio.isXRet
      := isXRetFlag"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1459-1470
    context: "1459:       ((hasDebugTrap && !debugMode) || ebreakEnterParkLoop) ->
      debugTrapTarget\n1460:     )),\n1461:     isXRetFlag || csrio.exception.valid)\n\
      1462: \n1463:   when(hasExceptionIntr) {\n1464:     val mstatusOld = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1465:     val mstatusNew = WireInit(mstatus.asTypeOf(new MstatusStruct))\n\
      1466:     val hstatusOld = WireInit(hstatus.asTypeOf(new HstatusStruct))\n1467:\
      \     val hstatusNew = WireInit(hstatus.asTypeOf(new HstatusStruct))\n1468:\
      \     val vsstatusOld = WireInit(vsstatus.asTypeOf(new MstatusStruct))\n1469:\
      \     val vsstatusNew = WireInit(vsstatus.asTypeOf(new MstatusStruct))\n1470:\
      \     val dcsrNew = WireInit(dcsr.asTypeOf(new DcsrStruct))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1511-1523
    context: "1511:         hstatusNew.spvp := privilegeMode\n1512:       }\n1513:\
      \       virtMode := false.B\n1514:       scause := causeNO\n1515:       sepc
      := Mux(hasInstrPageFault || hasInstrAccessFault, iexceptionPC, dexceptionPC)\n\
      1516:       mstatusNew.spp := privilegeMode\n1517:       mstatusNew.pie.s :=
      mstatusOld.ie.s\n1518:       mstatusNew.ie.s := false.B\n1519:       privilegeMode
      := ModeS\n1520:       when (clearTval) { stval := 0.U }\n1521:       when (clearTval_h)
      {htval := 0.U}\n1522:     }.otherwise {\n1523:       val virt = Mux(mstatusOld.mprv.asBool,
      mstatusOld.mpv, virtMode)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1520-1544
    context: "1520:       when (clearTval) { stval := 0.U }\n1521:       when (clearTval_h)
      {htval := 0.U}\n1522:     }.otherwise {\n1523:       val virt = Mux(mstatusOld.mprv.asBool,
      mstatusOld.mpv, virtMode)\n1524:       // to do hld st\n1525:       mstatusNew.gva
      := (hasInstGuestPageFault || hasLoadGuestPageFault || hasStoreGuestPageFault
      ||\n1526:       ((virt.asBool || isHyperInst) && ((hasException && 0.U <= exceptionNO
      && exceptionNO <= 7.U && exceptionNO =/= 2.U)\n1527:         || hasInstrPageFault
      || hasLoadPageFault || hasStorePageFault)))\n1528:       mstatusNew.mpv := virtMode\n\
      1529:       virtMode := false.B\n1530:       mcause := causeNO\n1531:      \
      \ mepc := Mux(hasInstrPageFault || hasInstrAccessFault, iexceptionPC, dexceptionPC)\n\
      1532:       mstatusNew.mpp := privilegeMode\n1533:       mstatusNew.pie.m :=
      mstatusOld.ie.m\n1534:       mstatusNew.ie.m := false.B\n1535:       privilegeMode
      := ModeM\n1536:       when (clearTval) { mtval := 0.U }\n1537:       when (clearTval_h)
      {mtval2 := 0.U}\n1538:     }\n1539:     mstatus := mstatusNew.asUInt\n1540:\
      \     vsstatus := vsstatusNew.asUInt\n1541:     hstatus := hstatusNew.asUInt\n\
      1542:     debugMode := debugModeNew\n1543:   }\n1544: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1576-1587
    context: "1576:   // Always instantiate basic difftest modules.\n1577:   if (env.AlwaysBasicDiff
      || env.EnableDifftest) {\n1578:     val difftest = DifftestModule(new DiffCSRState)\n\
      1579:     difftest.coreid := csrio.hartId\n1580:     difftest.privilegeMode
      := privilegeMode\n1581:     difftest.mstatus := mstatus\n1582:     difftest.sstatus
      := mstatus & sstatusRmask\n1583:     difftest.mepc := mepc\n1584:     difftest.sepc
      := sepc\n1585:     difftest.mtval:= mtval\n1586:     difftest.stval:= stval\n\
      1587:     difftest.mtvec := mtvec"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/Fence.scala
    lines: 28-38
    context: "28:   val fencei = Output(Bool())\n29:   val sbuffer = new FenceToSbuffer\n\
      30: }\n31: \n32: class FenceToSbuffer extends Bundle {\n33:   val flushSb =
      Output(Bool())\n34:   val sbIsEmpty = Input(Bool())\n35: }\n36: \n37: class
      Fence(cfg: FuConfig)(implicit p: Parameters) extends FuncUnit(cfg) {\n38: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/Fence.scala
    lines: 44-54
    context: "44:     io.in.bits.data.src(0)\n45:   )\n46: \n47:   val s_idle :: s_wait
      :: s_tlb :: s_icache :: s_fence :: s_nofence :: Nil = Enum(6)\n48: \n49:   val
      state = RegInit(s_idle)\n50:   /* fsm\n51:    * s_idle    : init state, send
      sbflush\n52:    * s_wait  : send sbflush, wait for sbEmpty\n53:    * s_tlb \
      \  : flush tlb, just hold one cycle\n54:    * s_icache: flush icache, just hold
      one cycle"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/Fence.scala
    lines: 54-98
    context: "54:    * s_icache: flush icache, just hold one cycle\n55:    * s_fence
      : do nothing, for timing optimiaztion\n56:    * s_nofence: do nothing , for
      Svinval extension\n57:    */\n58: \n59:   val sbuffer = toSbuffer.flushSb\n\
      60:   val sbEmpty = toSbuffer.sbIsEmpty\n61:   val uop = RegEnable(io.in.bits,
      io.in.fire)\n62:   val func = uop.ctrl.fuOpType\n63: \n64:   // NOTE: icache
      & tlb & sbuffer must receive flush signal at any time\n65:   sbuffer      :=
      state === s_wait\n66:   fencei       := state === s_icache\n67:   sfence.valid
      := state === s_tlb && (func === FenceOpType.sfence || func === FenceOpType.hfence_v
      || func === FenceOpType.hfence_g)\n68:   sfence.bits.rs1  := uop.data.imm(4,
      0) === 0.U\n69:   sfence.bits.rs2  := uop.data.imm(9, 5) === 0.U\n70:   sfence.bits.flushPipe
      := uop.ctrl.flushPipe.get\n71:   sfence.bits.hv := func === FenceOpType.hfence_v\n\
      72:   sfence.bits.hg := func === FenceOpType.hfence_g\n73:   sfence.bits.addr
      := RegEnable(io.in.bits.data.src(0), io.in.fire)\n74:   sfence.bits.id   :=
      RegEnable(io.in.bits.data.src(1), io.in.fire)\n75: \n76:   when (state === s_idle
      && io.in.valid) { state := s_wait }\n77:   when (state === s_wait && func ===
      FenceOpType.fencei && sbEmpty) { state := s_icache }\n78:   when (state ===
      s_wait && ((func === FenceOpType.sfence || func === FenceOpType.hfence_g ||
      func === FenceOpType.hfence_v) && sbEmpty)) { state := s_tlb }\n79:   when (state
      === s_wait && func === FenceOpType.fence  && sbEmpty) { state := s_fence }\n\
      80:   when (state === s_wait && func === FenceOpType.nofence  && sbEmpty) {
      state := s_nofence }\n81:   when (state =/= s_idle && state =/= s_wait) { state
      := s_idle }\n82: \n83:   io.in.ready := state === s_idle\n84:   io.out.valid
      := state =/= s_idle && state =/= s_wait\n85:   io.out.bits.res.data := 0.U\n\
      86:   io.out.bits.ctrl.robIdx := uop.ctrl.robIdx\n87:   io.out.bits.ctrl.pdest
      := uop.ctrl.pdest\n88:   io.out.bits.ctrl.flushPipe.get := uop.ctrl.flushPipe.get\n\
      89:   io.out.bits.ctrl.exceptionVec.get := 0.U.asTypeOf(io.out.bits.ctrl.exceptionVec.get)\n\
      90:   io.out.bits.perfDebugInfo := io.in.bits.perfDebugInfo\n91:   io.out.bits.debug_seqNum
      := io.in.bits.debug_seqNum\n92: \n93:   XSDebug(io.in.valid, p\"In(${io.in.valid}
      ${io.in.ready}) state:${state} InrobIdx:${io.in.bits.ctrl.robIdx}\\n\")\n94:\
      \   XSDebug(state =/= s_idle, p\"state:${state} sbuffer(flush:${sbuffer} empty:${sbEmpty})
      fencei:${fencei} sfence:${sfence}\\n\")\n95:   XSDebug(io.out.valid, p\" Out(${io.out.valid}
      ${io.out.ready}) state:${state} OutrobIdx:${io.out.bits.ctrl.robIdx}\\n\")\n\
      96: \n97:   assert(!io.out.valid || io.out.ready, \"when fence is out valid,
      out ready should always be true\")\n98: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/PMA.scala
    lines: 75-93
    context: "75: \n76:     val blankCfg = PMXLEN == 32\n77:     val cfg_index_wrapper
      = (0 until num by 4).zip((0 until num by 4).map(a => blankCfg || (a % pmaCfgPerCSR
      == 0)))\n78:     val cfg_map = (cfg_index_wrapper).map{ case(i, notempty) =>
      {\n79: //      println(s\"tlbpma i:$i notempty:$notempty\")\n80:       RegField.apply(n
      = PMXLEN, r = RegReadFn{(ivalid, oready) =>\n81:         val r_ready = Wire(Bool())\n\
      82:         val o_valid = Wire(Bool())\n83:         val v_reg = ValidHold(r_ready
      && ivalid, o_valid && oready, false.B)\n84:         r_ready := !v_reg\n85: \
      \        o_valid := v_reg\n86: \n87:         if (notempty) { (r_ready, o_valid,
      pmaCfgMerged(pmaCfgIndex(i))) }\n88:         else { (r_ready, o_valid, 0.U)
      }\n89:       }, w = RegWriteFn((valid, data) => {\n90:         if (notempty)
      { when (valid) { pmaCfgMerged(pmaCfgIndex(i)) := write_cfg_vec(mask, addr, i,
      pmaCfgMerged(pmaCfgIndex(i)))(data) } }\n91:         true.B\n92:       }), desc
      = RegFieldDesc(s\"MMPMA_config_${i}\", s\"pma config register #${i}\"))\n93:\
      \     }}"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/PMA.scala
    lines: 119-129
    context: "119:       MemMap(\"h00_2000_0000\", \"h00_2FFF_FFFF\",   \"h0\", \"\
      Reserved\",    \"RW\"),\n120:       MemMap(\"h00_3000_0000\", \"h00_3000_FFFF\"\
      ,   \"h0\", \"DMA\",         \"RW\"),\n121:       MemMap(\"h00_3001_0000\",
      \"h00_3004_FFFF\",   \"h0\", \"GPU\",         \"RWC\"),\n122:       MemMap(\"\
      h00_3005_0000\", \"h00_3006_FFFF\",   \"h0\", \"USB/SDMMC\",   \"RW\"),\n123:\
      \       MemMap(\"h00_3007_0000\", \"h00_30FF_FFFF\",   \"h0\", \"Reserved\"\
      ,    \"RW\"),\n124:       MemMap(\"h00_3100_0000\", \"h00_3111_FFFF\",   \"\
      h0\", \"MMIO\",        \"RW\"),\n125:       MemMap(\"h00_3112_0000\", \"h00_37FF_FFFF\"\
      ,   \"h0\", \"Reserved\",    \"RW\"),\n126:       MemMap(\"h00_3800_0000\",
      \"h00_3800_FFFF\",   \"h0\", \"CLINT\",       \"RW\"),\n127:       MemMap(\"\
      h00_3801_0000\", \"h00_3801_FFFF\",   \"h0\", \"BEU\",         \"RW\"),\n128:\
      \       MemMap(\"h00_3802_0000\", \"h00_3802_0FFF\",   \"h0\", \"DebugModule\"\
      , \"RWX\"),\n129:       MemMap(\"h00_3802_1000\", \"h00_3802_1FFF\",   \"h0\"\
      , \"MMPMA\",       \"RW\"),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/PMA.scala
    lines: 166-176
    context: "166:       cfg_list.append(PMPConfigUInt(conf.l, conf.c, conf.atomic,
      conf.a, conf.x, conf.w, conf.r))\n167:       addr_list.append(genAddr(addr))\n\
      168:       mask_list.append(genMask(addr, conf.a))\n169:     }\n170: \n171:\
      \     PMAConfigs.foreach(addPMA)\n172:     while (cfg_list.length < 16) {\n\
      173:       addPMA(PMAConfigEntry(0))\n174:     }\n175: \n176:     val cfgInitMerge
      = Seq.tabulate(num / 8)(i => {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/PMA.scala
    lines: 208-222
    context: "208: }\n209: \n210: trait PMACheckMethod extends PMPConst {\n211:  \
      \ def pma_check(cmd: UInt, cfg: PMPConfig) = {\n212:     val resp = Wire(new
      PMPRespBundle)\n213:     resp.ld := TlbCmd.isRead(cmd) && !cfg.r\n214:     resp.st
      := Mux(TlbCmd.isAmo(cmd), !cfg.atomic || !cfg.w, Mux(TlbCmd.isWrite(cmd), !cfg.w,
      false.B))\n215:     resp.instr := TlbCmd.isExec(cmd) && !cfg.x\n216:     //TODO
      We require that a `PMA` can generate an mmio response only if the address has
      the appropriate `PMA` permissions.\n217:     resp.mmio := !cfg.c && !(resp.ld
      || resp.st || resp.instr)\n218:     resp.atomic := cfg.atomic\n219:     resp\n\
      220:   }\n221: \n222:   def pma_match_res(leaveHitMux: Boolean = false, valid:
      Bool = true.B)("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/PMA.scala
    lines: 235-245
    context: "235: \n236:     val pmaDefault = WireInit(0.U.asTypeOf(new PMPEntry()))\n\
      237:     val match_vec = Wire(Vec(num+1, Bool()))\n238:     val cfg_vec = Wire(Vec(num+1,
      new PMPEntry()))\n239: \n240:     pmaEntries.zip(pmaDefault +: pmaEntries.take(num-1)).zipWithIndex.foreach{
      case ((pma, last_pma), i) =>\n241:       val is_match = pma.is_match(addr, size,
      lgMaxSize, last_pma)\n242:       val aligned = pma.aligned(addr, size, lgMaxSize,
      last_pma)\n243: \n244:       val cur = WireInit(pma)\n245:       cur.cfg.r :=
      aligned && pma.cfg.r"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/vector/Mgu.scala
    lines: 95-105
    context: "95: \n96:   // mask vd is at most 16 bits\n97:   private val maskOldVdBits
      = splitVdMask(oldVd, SewOH(info.eew))(vdIdx)\n98:   private val maskBits = splitVdMask(in.mask,
      SewOH(info.eew))(vdIdx)\n99:   private val maskVecByte = Wire(Vec(numBytes,
      UInt(1.W)))\n100:   maskVecByte.zipWithIndex.foreach { case (mask, i) =>\n101:\
      \     mask := Mux(maskBits(i), vd(i), Mux(info.ma, 1.U, maskOldVdBits(i)))\n\
      102:   }\n103:   private val maskVd = maskVecByte.asUInt\n104: \n105:   // the
      result of mask-generating inst"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/vector/Mgu.scala
    lines: 202-213
    context: "202:   val dstMask = Bool()\n203: }\n204: \n205: object VerilogMgu extends
      App {\n206:   println(\"Generating the Mgu hardware\")\n207:   val (config,
      firrtlOpts, firtoolOpts) = ArgParser.parse(args)\n208:   val p = config.alterPartial({case
      XSCoreParamsKey => config(XSTileKey).head})\n209: \n210:   emitVerilog(new Mgu(128)(p),
      Array(\"--target-dir\", \"build/vifu\", \"--full-stacktrace\"))\n211: }\n212:\
      \ \n213: class MguTest extends AnyFlatSpec with ChiselScalatestTester with Matchers
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/vector/Mgtu.scala
    lines: 38-48
    context: "38: \n39:   /*\n40:    * Mask destination tail elements are always treated
      as tail-agnostic, regardless of the setting of vta\n41:    */\n42:   private
      val vdWithTail = Wire(Vec(vlen, UInt(1.W)))\n43:   vdWithTail.zipWithIndex.foreach{
      case (bit, idx) =>\n44:     bit := Mux(idx.U < vl, vd(idx), 1.U)\n45:   }\n\
      46: \n47:   io.out.vd := vdWithTail.asUInt\n48: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/vector/utils/VecDataSplitModule.scala
    lines: 22-31
    context: "22:   vec8b  := inData.asTypeOf(vec8b)\n23:   vec16b := inData.asTypeOf(vec16b)\n\
      24:   vec32b := inData.asTypeOf(vec32b)\n25:   vec64b := inData.asTypeOf(vec64b)\n\
      26: \n27:   io.outVec64b.zip(vec64b).foreach { case(sink, source) => sink :=
      source }\n28:   io.outVec32b.zip(vec32b).foreach { case(sink, source) => sink
      := source }\n29:   io.outVec16b.zip(vec16b).foreach { case(sink, source) =>
      sink := source }\n30:   io.outVec8b .zip(vec8b) .foreach { case(sink, source)
      => sink := source }\n31: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/vector/VecNonPipedFuncUnit.scala
    lines: 18-29
    context: "18: \n19:   protected val vs2 = src1\n20:   protected val vs1 = src0\n\
      21:   protected val oldVd = inData.src(2)\n22: \n23:   protected val outCtrl\
      \     = DataHoldBypass(io.in.bits.ctrl, io.in.fire)\n24:   protected val outData\
      \     = DataHoldBypass(io.in.bits.data, io.in.fire)\n25: \n26:   protected val
      outVecCtrl  = outCtrl.vpu.get\n27:   protected val outVm       = outVecCtrl.vm\n\
      28: \n29:   // vadc.vv, vsbc.vv need this"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT16Divider.scala
    lines: 38-52
    context: "38: \n39: class SRT16DividerDataModule(len: Int) extends Module {\n\
      40:   val io = IO(new Bundle() {\n41:     val src = Vec(2, Input(UInt(len.W)))\n\
      42:     val valid, sign, kill_w, kill_r, isHi, isW = Input(Bool())\n43:    \
      \ val in_ready = Output(Bool())\n44:     val out_valid = Output(Bool())\n45:\
      \     val out_validNext = Output(Bool())\n46:     val out_data = Output(UInt(len.W))\n\
      47:     val out_ready = Input(Bool())\n48:   })\n49: \n50:   // consts\n51:\
      \   val lzc_width = log2Up(len)\n52:   val itn_len = 1 + len + 2 + 1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT16Divider.scala
    lines: 51-62
    context: "51:   val lzc_width = log2Up(len)\n52:   val itn_len = 1 + len + 2 +
      1\n53: \n54:   val (a, d, sign, valid, kill_w, kill_r, isHi, isW) =\n55:   \
      \  (io.src(0), io.src(1), io.sign, io.valid, io.kill_w, io.kill_r, io.isHi,
      io.isW)\n56:   val in_fire = valid && io.in_ready\n57:   val out_fire = io.out_ready
      && io.out_valid\n58:   val newReq = in_fire\n59:   val s_idle :: s_pre_0 ::
      s_pre_1 :: s_iter :: s_post_0 :: s_post_1 :: s_finish :: Nil = Enum(7)\n60:\
      \   val quot_neg_2 :: quot_neg_1 :: quot_0 :: quot_pos_1 :: quot_pos_2 :: Nil
      = Enum(5)\n61: \n62: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT16Divider.scala
    lines: 58-68
    context: "58:   val newReq = in_fire\n59:   val s_idle :: s_pre_0 :: s_pre_1 ::
      s_iter :: s_post_0 :: s_post_1 :: s_finish :: Nil = Enum(7)\n60:   val quot_neg_2
      :: quot_neg_1 :: quot_0 :: quot_pos_1 :: quot_pos_2 :: Nil = Enum(5)\n61: \n\
      62: \n63:   val state = RegInit((1 << s_idle.litValue.toInt).U(7.W))\n64: \n\
      65:   // reused wires\n66: //  val aNormAbs = Wire(UInt((len + 1).W)) // Inputs
      of xNormAbs regs below\n67: //  val dNormAbs = Wire(UInt((len + 1).W))\n68:\
      \   val quotIter = Wire(UInt(len.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT16Divider.scala
    lines: 80-117
    context: "80:   val special = Wire(Bool())\n81: \n82:   // reused regs\n83: //\
      \  val aNormAbsReg = RegEnable(aNormAbs, newReq | state(s_pre_0) | state(s_post_0))
      // reg for normalized a & d and rem & rem+d\n84: //  val dNormAbsReg = RegEnable(dNormAbs,
      newReq | state(s_pre_0) | state(s_post_0))\n85:   val quotIterReg = RegEnable(quotIter,
      state(s_pre_1) | state(s_iter) | state(s_post_0))\n86:   val quotM1IterReg =
      RegEnable(quotM1Iter, state(s_pre_1) | state(s_iter) | state(s_post_0))\n87:\
      \   val specialReg = RegEnable(special, state(s_pre_1))\n88:   val aReg = RegEnable(a,
      in_fire)\n89: \n90:   when(kill_r) {\n91:     state := UIntToOH(s_idle, 7)\n\
      92:   } .elsewhen(state(s_idle) && in_fire && !kill_w) {\n93:     state := UIntToOH(s_pre_0,
      7)\n94:   } .elsewhen(state(s_pre_0)) { // leading zero detection\n95:     state
      := UIntToOH(s_pre_1, 7)\n96:   } .elsewhen(state(s_pre_1)) { // shift a/b\n\
      97:     state := Mux(special, UIntToOH(s_post_1, 7), UIntToOH(s_iter, 7))\n\
      98:   } .elsewhen(state(s_iter)) { // (ws[j+1], wc[j+1]) = 4(ws[j],wc[j]) -
      q(j+1)*d\n99:     state := Mux(finalIter, UIntToOH(s_post_0, 7), UIntToOH(s_iter,
      7))\n100:   } .elsewhen(state(s_post_0)) { // if rem < 0, rem = rem + d\n101:\
      \     state := UIntToOH(s_post_1, 7)\n102:   } .elsewhen(state(s_post_1)) {\n\
      103:     state := UIntToOH(s_finish, 7)\n104:   } .elsewhen(state(s_finish)
      && io.out_ready) {\n105:     state := UIntToOH(s_idle, 7)\n106:   } .otherwise
      {\n107:     state := state\n108:   }\n109: \n110:   // io.in_ready := state(s_idle)\n\
      111:   aInverter := -Mux(state(s_idle), a, quotIterReg) // 64, 0\n112:   dInverter
      := -Mux(state(s_idle), d, quotM1IterReg) // 64, 0\n113: \n114:   val aSign =
      io.sign && a(len - 1) // 1\n115:   val dSign = io.sign && d(len - 1)\n116: \
      \  val dSignReg = RegEnable(dSign, newReq)\n117: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT16Divider.scala
    lines: 121-132
    context: "121:   val dAbsReg = RegEnable(dAbs, newReq)\n122: \n123:   val aNorm
      = (aAbsReg(len - 1, 0) << aLZC(lzc_width - 1, 0))(len - 1, 0) // 64, 65\n124:\
      \   val dNorm = (dAbsReg(len - 1, 0) << dLZC(lzc_width - 1, 0))(len - 1, 0)\n\
      125: \n126:   val aNormReg = RegEnable(aNorm, state(s_pre_0))\n127:   val dNormReg
      = RegEnable(dNorm, state(s_pre_0))\n128: \n129: //  aNormAbs := Mux1H(Seq(\n\
      130: //    state(s_idle) -> Cat(0.U(1.W), aAbs), // 65, 0\n131: //    state(s_pre_0)
      -> Cat(0.U(1.W), aNorm), // 65, 0\n132: //    state(s_post_0) -> rNext(len +
      3, 3) // remainder 65, 64. highest is sign bit"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT16Divider.scala
    lines: 140-151
    context: "140:   // Second cycle, state is pre_0\n141:   // calculate lzc and
      move div* and lzc diff check if no_iter_needed\n142: \n143:   aLZC := PriorityEncoder(aAbsReg(len
      - 1, 0).asBools.reverse)\n144:   dLZC := PriorityEncoder(dAbsReg(len - 1, 0).asBools.reverse)\n\
      145:   val aLZCReg = RegEnable(aLZC, state(s_pre_0)) // 7, 0\n146:   val dLZCReg
      = RegEnable(dLZC, state(s_pre_0))\n147: \n148:   val lzcWireDiff = Cat(0.U(1.W),
      dLZC(lzc_width - 1, 0)) - Cat(0.U(1.W), aLZC(lzc_width - 1, 0)) // 7, 0\n149:\
      \   val lzcRegDiff = Cat(0.U(1.W), dLZCReg(lzc_width - 1, 0)) - Cat(0.U(1.W),
      aLZCReg(lzc_width - 1, 0))\n150: //  val lzcDiff = Mux(state(s_pre_0), lzcWireDiff,
      lzcRegDiff)\n151: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT16Divider.scala
    lines: 152-163
    context: "152:   // special case:\n153:   // divisor is 1 or -1; dividend has
      less bits than divisor; divisor is zero\n154:   // s_pre_0:\n155:   val dIsOne
      = dLZC(lzc_width - 1, 0).andR\n156:   val dIsZero = ~dNormReg.orR\n157:   val
      aIsZero = RegEnable(aLZC(lzc_width), state(s_pre_0))\n158:   val aTooSmall =
      RegEnable(aLZC(lzc_width) | lzcWireDiff(lzc_width), state(s_pre_0))\n159:  \
      \ special := dIsOne | dIsZero | aTooSmall\n160: \n161:   val quotSpecial = Mux(dIsZero,
      VecInit(Seq.fill(len)(true.B)).asUInt,\n162:                             Mux(aTooSmall,
      0.U,\n163:                               Mux(dSignReg, -aReg, aReg) //  signed
      2^(len-1)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT16Divider.scala
    lines: 161-177
    context: "161:   val quotSpecial = Mux(dIsZero, VecInit(Seq.fill(len)(true.B)).asUInt,\n\
      162:                             Mux(aTooSmall, 0.U,\n163:                 \
      \              Mux(dSignReg, -aReg, aReg) //  signed 2^(len-1)\n164:       \
      \                      ))\n165:   val remSpecial = Mux(dIsZero || aTooSmall,
      aReg, 0.U)\n166:   val quotSpecialReg = RegEnable(quotSpecial, state(s_pre_1))\n\
      167:   val remSpecialReg = RegEnable(remSpecial, state(s_pre_1))\n168: \n169:\
      \   // s_pre_1\n170:   val quotSign = Mux(state(s_idle), aSign ^ dSign, true.B)
      // if not s_idle then must be s_pre_1 & dIsZero, and that we have\n171:   val
      rSign = aSign\n172:   val quotSignReg = RegEnable(quotSign, in_fire | (state(s_pre_1)
      & dIsZero))\n173:   val rSignReg = RegEnable(rSign, in_fire)\n174: \n175:  \
      \ val rShift = lzcRegDiff(0)\n176:   val oddIter = lzcRegDiff(1) ^ lzcRegDiff(0)\n\
      177:   val iterNum = Wire(UInt((lzc_width - 2).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT16Divider.scala
    lines: 173-184
    context: "173:   val rSignReg = RegEnable(rSign, in_fire)\n174: \n175:   val rShift
      = lzcRegDiff(0)\n176:   val oddIter = lzcRegDiff(1) ^ lzcRegDiff(0)\n177:  \
      \ val iterNum = Wire(UInt((lzc_width - 2).W))\n178:   val iterNumReg = RegEnable(iterNum,
      state(s_pre_1) | state(s_iter))\n179:   iterNum := Mux(state(s_pre_1), (lzcRegDiff
      + 1.U) >> 2, iterNumReg -% 1.U)\n180:   finalIter := iterNumReg === 0.U\n181:\
      \ \n182:   val rSumInit = Cat(0.U(3.W), Mux(rShift, Cat(0.U(1.W), aNormReg),
      Cat(aNormReg, 0.U(1.W)))) //(1, 67), 0.001xxx\n183:   val rCarryInit = 0.U(itn_len.W)\n\
      184: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT16Divider.scala
    lines: 241-253
    context: "241:   val rCarryIter = Wire(UInt(itn_len.W)) // (1, 67)\n242:   val
      rSumIter = Wire(UInt(itn_len.W))\n243:   // val r3wsIter = Wire(UInt(13.W))\n\
      244:   // val r3wcIter = Wire(UInt(13.W))\n245:   // Input Regs of whole Spec
      + Sel + sum adder block\n246:   val qPrevReg = RegEnable(Mux(state(s_pre_1),
      qInit, qNext2), state(s_pre_1) | state(s_iter))\n247:   val rSumReg = RegEnable(Mux(state(s_pre_1),
      rSumInit, rSumIter), state(s_pre_1) | state(s_iter)) // (1, 67)\n248:   val
      rCarryReg = RegEnable(Mux(state(s_pre_1), rCarryInit, rCarryIter), state(s_pre_1)
      | state(s_iter))\n249: \n250:   // Give values to the regs and wires above...\n\
      251:   val dForLookup = dPos(len-2, len-4)\n252:   mNeg := VecInit(Cat(SignExt(MuxLookup(dNormReg(len-2,
      len-4), \"b00000000\".U(7.W))(mLookUpTable2.minus_m(0)), 11), 0.U(1.W)), //
      (2, 5) -> (6, 6)\n253:                   Cat(SignExt(MuxLookup(dNormReg(len-2,
      len-4), \"b00000000\".U(7.W))(mLookUpTable2.minus_m(1)), 10) ,0.U(2.W)), //
      (3, 4) -> (6, 6)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT16Divider.scala
    lines: 270-283
    context: "270:   r3wc := rCarryReg(itn_len-1, itn_len-13)\n271: \n272:   r2ws
      := rSumReg(itn_len-1, itn_len-10)\n273:   r2wc := rCarryReg(itn_len-1, itn_len-10)\n\
      274: \n275:   val udNegReg = RegEnable(udNeg, state(s_pre_1))\n276: //  val
      rudNegReg = RegEnable(rudNeg, state(s_pre_1))\n277:   val rudPmNegReg = RegEnable(rudPmNeg,
      state(s_pre_1))\n278:   val r2udPmNegReg = RegEnable(r2udPmNeg, state(s_pre_1))\n\
      279: \n280:   def DetectSign(signs: UInt, name: String): UInt = {\n281:    \
      \ val qVec = Wire(Vec(5, Bool())).suggestName(name)\n282:     qVec(quot_neg_2)
      := signs(0) && signs(1) && signs(2)\n283:     qVec(quot_neg_1) := ~signs(0)
      && signs(1) && signs(2)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT16Divider.scala
    lines: 359-373
    context: "359:   //                       Mux(quotSignReg, aInverter, quotIterReg)))\n\
      360:   // quotM1Iter := Mux(state(s_pre_1),\n361:   //                     \
      \  0.U(len.W), Mux(state(s_iter), quotM1IterNext,\n362:   //               \
      \          Mux(quotSignReg, dInverter, quotM1IterReg)))\n363: \n364:   quotIter
      := Mux(state(s_iter), quotIterNext,\n365:                     Mux(state(s_pre_1),
      0.U(len.W),\n366:                       Mux(quotSignReg, aInverter, quotIterReg)))\n\
      367:   quotM1Iter := Mux(state(s_iter), quotM1IterNext,\n368:              \
      \         Mux(state(s_pre_1), 0.U(len.W),\n369:                         Mux(quotSignReg,
      dInverter, quotM1IterReg)))\n370:   // finally, to the recovery stages!\n371:\
      \ \n372:   when(rSignReg) {\n373:     rNext := ~rSumReg + ~rCarryReg + 2.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT16Divider.scala
    lines: 374-385
    context: "374:     rNextPd := ~rSumReg + ~rCarryReg + ~Cat(0.U(1.W), dNormReg,
      0.U(3.W)) + 3.U\n375:   } .otherwise {\n376:     rNext := rSumReg + rCarryReg\n\
      377:     rNextPd := rSumReg + rCarryReg + Cat(0.U(1.W), dNormReg, 0.U(3.W))\n\
      378:   }\n379:   val rNextReg = RegEnable(rNext(len + 3, 3), state(s_post_0))\n\
      380:   val rNextPdReg = RegEnable(rNextPd(len + 3, 3), state(s_post_0))\n381:\
      \   dontTouch(rNextReg)\n382:   // post_1\n383:   val r = rNextReg\n384:   val
      rPd = rNextPdReg\n385:   val rIsZero = ~(r.orR)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT16Divider.scala
    lines: 388-399
    context: "388:   val rightShifter = Module(new RightShifter(len, lzc_width))\n\
      389:   rightShifter.io.in := rPreShifted\n390:   rightShifter.io.shiftNum :=
      dLZCReg\n391:   rightShifter.io.msb := Mux(~(rPreShifted.orR), 0.U, rSignReg)\n\
      392:   val rShifted = rightShifter.io.out\n393:   val rFinal = RegEnable(Mux(specialReg,
      remSpecialReg, rShifted), state(s_post_1))// right shifted remainder. shift
      by the number of bits divisor is shifted\n394:   val qFinal = RegEnable(Mux(specialReg,
      quotSpecialReg, Mux(needCorr, quotM1IterReg, quotIterReg)), state(s_post_1))\n\
      395:   val res = Mux(isHi, rFinal, qFinal)\n396:   io.out_data := Mux(isW,\n\
      397:     SignExt(res(31, 0), len),\n398:     res\n399:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/SRT16Divider.scala
    lines: 395-407
    context: "395:   val res = Mux(isHi, rFinal, qFinal)\n396:   io.out_data := Mux(isW,\n\
      397:     SignExt(res(31, 0), len),\n398:     res\n399:   )\n400:   io.in_ready
      := state(s_idle)\n401:   io.out_valid := state(s_finish)\n402:   io.out_validNext
      := state(s_post_1)\n403: }\n404: \n405: object mLookUpTable2 {\n406:   // Usage
      :\n407:   // result := decoder(QMCMinimizer, index, mLookupTable.xxx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 2-12
    context: "2: \n3: import chisel3._\n4: import chisel3.util._\n5: import chisel3.util.experimental.decode.TruthTable\n\
      6: import freechips.rocketchip.rocket.CSRs\n7: import xiangshan.backend.fu.NewCSR.CSRBundles.{Counteren,
      PrivState}\n8: import xiangshan.backend.fu.NewCSR.CSRDefines._\n9: import org.chipsalliance.cde.config.Parameters\n\
      10: import system.HasSoCParameter\n11: \n12: class CSRPermitModule(implicit
      p: Parameters) extends Module {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 17-27
    context: "17:   val sLevelPermitMod = Module(new SLevelPermitModule)\n18:   val
      privilegePermitMod = Module(new PrivilegePermitModule)\n19:   val virtualLevelPermitMod
      = Module(new VirtualLevelPermitModule)\n20:   val indirectCSRPermitMod = Module(new
      IndirectCSRPermitModule)\n21: \n22:   xRetPermitMod.io.in.privState := io.in.privState\n\
      23:   xRetPermitMod.io.in.debugMode := io.in.debugMode\n24:   xRetPermitMod.io.in.xRet\
      \      := io.in.xRet\n25:   xRetPermitMod.io.in.status    := io.in.status\n\
      26: \n27:   mLevelPermitMod.io.in.csrAccess  := io.in.csrAccess"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 23-33
    context: "23:   xRetPermitMod.io.in.debugMode := io.in.debugMode\n24:   xRetPermitMod.io.in.xRet\
      \      := io.in.xRet\n25:   xRetPermitMod.io.in.status    := io.in.status\n\
      26: \n27:   mLevelPermitMod.io.in.csrAccess  := io.in.csrAccess\n28:   mLevelPermitMod.io.in.privState\
      \  := io.in.privState\n29:   mLevelPermitMod.io.in.status     := io.in.status\n\
      30:   mLevelPermitMod.io.in.xcounteren := io.in.xcounteren\n31:   mLevelPermitMod.io.in.xenvcfg\
      \    := io.in.xenvcfg\n32:   mLevelPermitMod.io.in.xstateen   := io.in.xstateen\n\
      33:   mLevelPermitMod.io.in.aia        := io.in.aia"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 31-50
    context: "31:   mLevelPermitMod.io.in.xenvcfg    := io.in.xenvcfg\n32:   mLevelPermitMod.io.in.xstateen\
      \   := io.in.xstateen\n33:   mLevelPermitMod.io.in.aia        := io.in.aia\n\
      34: \n35:   sLevelPermitMod.io.in.csrAccess  := io.in.csrAccess\n36:   sLevelPermitMod.io.in.privState\
      \  := io.in.privState\n37:   sLevelPermitMod.io.in.xcounteren := io.in.xcounteren\n\
      38:   sLevelPermitMod.io.in.xstateen   := io.in.xstateen\n39: \n40:   privilegePermitMod.io.in.csrAccess
      := io.in.csrAccess\n41:   privilegePermitMod.io.in.privState := io.in.privState\n\
      42:   privilegePermitMod.io.in.debugMode := io.in.debugMode\n43: \n44:   virtualLevelPermitMod.io.in.csrAccess\
      \   := io.in.csrAccess\n45:   virtualLevelPermitMod.io.in.privState   := io.in.privState\n\
      46:   virtualLevelPermitMod.io.in.status      := io.in.status\n47:   virtualLevelPermitMod.io.in.xcounteren\
      \  := io.in.xcounteren\n48:   virtualLevelPermitMod.io.in.xenvcfg     := io.in.xenvcfg\n\
      49:   virtualLevelPermitMod.io.in.xstateen    := io.in.xstateen\n50:   virtualLevelPermitMod.io.in.aia\
      \         := io.in.aia"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 48-58
    context: "48:   virtualLevelPermitMod.io.in.xenvcfg     := io.in.xenvcfg\n49:\
      \   virtualLevelPermitMod.io.in.xstateen    := io.in.xstateen\n50:   virtualLevelPermitMod.io.in.aia\
      \         := io.in.aia\n51: \n52:   indirectCSRPermitMod.io.in.csrAccess :=
      io.in.csrAccess\n53:   indirectCSRPermitMod.io.in.privState := io.in.privState\n\
      54:   indirectCSRPermitMod.io.in.aia       := io.in.aia\n55:   indirectCSRPermitMod.io.in.xstateen\
      \  := io.in.xstateen\n56: \n57:   private val (ren, wen) = (\n58:     io.in.csrAccess.ren,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 69-80
    context: "69:   val pPermit_EX_VI = privilegePermitMod.io.out.privilege_EX_VI\n\
      70: \n71:   val vPermit_EX_II = virtualLevelPermitMod.io.out.virtualLevelPermit_EX_II\n\
      72:   val vPermit_EX_VI = virtualLevelPermitMod.io.out.virtualLevelPermit_EX_VI\n\
      73: \n74:   val indirectPermit_EX_II = indirectCSRPermitMod.io.out.indirectCSR_EX_II\n\
      75:   val indirectPermit_EX_VI = indirectCSRPermitMod.io.out.indirectCSR_EX_VI\n\
      76: \n77:   val directPermit_illegal = mPermit_EX_II || sPermit_EX_II || pPermit_EX_II
      || pPermit_EX_VI || vPermit_EX_II || vPermit_EX_VI\n78: \n79:   val csrAccess_EX_II
      = csrAccess && (\n80:     (mPermit_EX_II || sPermit_EX_II || pPermit_EX_II ||
      vPermit_EX_II) ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 102-112
    context: "102: }\n103: \n104: class XRetPermitModule extends Module {\n105:  \
      \ val io = IO(new Bundle() {\n106:     val in = Input(new Bundle {\n107:   \
      \    val privState = new PrivState\n108:       val debugMode = Bool()\n109:\
      \       val xRet = new xRetIO\n110:       val status = new statusIO\n111:  \
      \   })\n112:     val out = Output(new Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 117-128
    context: "117:       val hasLegalSret  = Bool()\n118:       val hasLegalDret \
      \ = Bool()\n119:     })\n120:   })\n121: \n122:   private val (privState, debugMode)
      = (\n123:     io.in.privState,\n124:     io.in.debugMode,\n125:   )\n126: \n\
      127:   private val (mnret, mret, sret, dret) = (\n128:     io.in.xRet.mnret,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 134-151
    context: "134:   private val (tsr, vtsr) = (\n135:     io.in.status.tsr,\n136:\
      \     io.in.status.vtsr,\n137:   )\n138: \n139:   private val mnret_EX_II =
      mnret && !privState.isModeM\n140:   private val mnretIllegal =  mnret_EX_II\n\
      141: \n142:   private val mret_EX_II = mret && !privState.isModeM\n143:   private
      val mretIllegal = mret_EX_II\n144: \n145:   private val sret_EX_II = sret &&
      (privState.isModeHU || privState.isModeHS && tsr)\n146:   private val sret_EX_VI
      = sret && (privState.isModeVU || privState.isModeVS && vtsr)\n147:   private
      val sretIllegal = sret_EX_II || sret_EX_VI\n148: \n149:   private val dret_EX_II
      = dret && !debugMode\n150:   private val dretIllegal = dret_EX_II\n151: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 159-169
    context: "159: \n160: class MLevelPermitModule extends Module {\n161:   val io
      = IO(new Bundle() {\n162:     val in = Input(new Bundle {\n163:       val csrAccess
      = new csrAccessIO\n164:       val privState = new PrivState\n165:       val
      status = new statusIO\n166:       val xcounteren = new xcounterenIO\n167:  \
      \     val xenvcfg = new xenvcfgIO\n168:       val xstateen = new xstateenIO\n\
      169:       val aia = new aiaIO"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 173-186
    context: "173:       val hasLegalWriteFcsr = Bool()\n174:       val hasLegalWriteVcsr
      = Bool()\n175:     })\n176:   })\n177: \n178:   private val (wen, addr, privState)
      = (\n179:     io.in.csrAccess.wen,\n180:     io.in.csrAccess.addr,\n181:   \
      \  io.in.privState,\n182:   )\n183: \n184:   private val tvm = io.in.status.tvm\n\
      185: \n186:   private val mcounteren = io.in.xcounteren.mcounteren"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 183-196
    context: "183: \n184:   private val tvm = io.in.status.tvm\n185: \n186:   private
      val mcounteren = io.in.xcounteren.mcounteren\n187: \n188:   private val mstateen0
      = io.in.xstateen.mstateen0\n189:   private val mstateen1 = io.in.xstateen.mstateen1\n\
      190:   private val mstateen2 = io.in.xstateen.mstateen2\n191:   private val
      mstateen3 = io.in.xstateen.mstateen3\n192: \n193:   private val mcounterenTM
      = mcounteren(1)\n194: \n195:   private val menvcfg = io.in.xenvcfg.menvcfg\n\
      196: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 205-215
    context: "205: \n206:   private val mvienSEIE = io.in.aia.mvienSEIE\n207: \n208:\
      \   private val csrIsRO = addr(11, 10) === \"b11\".U\n209:   private val csrIsHPM
      = addr >= CSRs.cycle.U && addr <= CSRs.hpmcounter31.U\n210:   private val csrIsFp
      = Seq(CSRs.fflags, CSRs.frm, CSRs.fcsr).map(_.U === addr).reduce(_ || _)\n211:\
      \   private val csrIsVec = Seq(CSRs.vstart, CSRs.vxsat, CSRs.vxrm, CSRs.vcsr,
      CSRs.vtype).map(_.U === addr).reduce(_ || _)\n212:   private val csrIsWritableVec
      = Seq(CSRs.vstart, CSRs.vxsat, CSRs.vxrm, CSRs.vcsr).map(_.U === addr).reduce(_
      || _)\n213:   private val counterAddr = addr(4, 0) // 32 counters\n214: \n215:\
      \   private val rwIllegal = csrIsRO && wen"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 212-223
    context: "212:   private val csrIsWritableVec = Seq(CSRs.vstart, CSRs.vxsat, CSRs.vxrm,
      CSRs.vcsr).map(_.U === addr).reduce(_ || _)\n213:   private val counterAddr
      = addr(4, 0) // 32 counters\n214: \n215:   private val rwIllegal = csrIsRO &&
      wen\n216: \n217:   private val fsEffectiveOff = sFSIsOff && !privState.isVirtual
      || sOrVsFSIsOff && privState.isVirtual\n218:   private val vsEffectiveOff =
      sVSIsOff && !privState.isVirtual || sOrVsVSIsOff && privState.isVirtual\n219:\
      \ \n220:   private val fpOff_EX_II  = csrIsFp  && fsEffectiveOff\n221:   private
      val vecOff_EX_II = csrIsVec && vsEffectiveOff\n222: \n223:   private val fpVec_EX_II
      = fpOff_EX_II || vecOff_EX_II"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 220-236
    context: "220:   private val fpOff_EX_II  = csrIsFp  && fsEffectiveOff\n221: \
      \  private val vecOff_EX_II = csrIsVec && vsEffectiveOff\n222: \n223:   private
      val fpVec_EX_II = fpOff_EX_II || vecOff_EX_II\n224: \n225:   private val rwStimecmp_EX_II
      = !privState.isModeM && (!mcounterenTM || !menvcfgSTCE) && (addr === CSRs.vstimecmp.U
      || addr === CSRs.stimecmp.U)\n226: \n227:   private val accessHPM_EX_II = csrIsHPM
      && !privState.isModeM && !mcounteren(counterAddr)\n228: \n229:   private val
      rwSatp_EX_II = privState.isModeHS && tvm && (addr === CSRs.satp.U || addr ===
      CSRs.hgatp.U)\n230: \n231:   private val rwStopei_EX_II = privState.isModeHS
      && mvienSEIE && (addr === CSRs.stopei.U)\n232: \n233:   /**\n234:    * Sm/Ssstateen
      begin\n235:    */\n236:   // SE bit 63"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 233-248
    context: "233:   /**\n234:    * Sm/Ssstateen begin\n235:    */\n236:   // SE bit
      63\n237:   private val accessStateen_EX_II = (\n238:     mstateen0.SE0.asBool
      +: Seq(mstateen1, mstateen2, mstateen3).map(_.SE.asBool)\n239:     ).zipWithIndex.map{
      case(se, i) => {\n240:     val csrIsHstateen = addr === (CSRs.hstateen0 + i).U\n\
      241:     val csrIsSstateen = addr === (CSRs.sstateen0 + i).U\n242:     val csrIsStateen
      = csrIsHstateen || csrIsSstateen\n243:     csrIsStateen && !privState.isModeM
      && !se\n244:   }}.reduce(_ || _)\n245: \n246:   // ENVCFG bit 62\n247:   private
      val csrIsHenvcfg = addr === CSRs.henvcfg.U\n248:   private val csrIsSenvcfg
      = addr === CSRs.senvcfg.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 245-255
    context: "245: \n246:   // ENVCFG bit 62\n247:   private val csrIsHenvcfg = addr
      === CSRs.henvcfg.U\n248:   private val csrIsSenvcfg = addr === CSRs.senvcfg.U\n\
      249:   private val csrIsEnvcfg = csrIsHenvcfg || csrIsSenvcfg\n250:   private
      val accessEnvcfg_EX_II = csrIsEnvcfg && !privState.isModeM && !mstateen0.ENVCFG.asBool\n\
      251: \n252:   // CSRIND bit 60 indirect reg (Sscsrind extensions), this is not
      implemented\n253:   // csr addr S: [0x150, 0x157]     VS: [0x250, 0x257]\n254:\
      \   private val csrIsSi = Ireg.isInSCsrInd(addr)\n255:   private val csrIsVSi
      = Ireg.isInVSCsrInd(addr)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 252-262
    context: "252:   // CSRIND bit 60 indirect reg (Sscsrind extensions), this is
      not implemented\n253:   // csr addr S: [0x150, 0x157]     VS: [0x250, 0x257]\n\
      254:   private val csrIsSi = Ireg.isInSCsrInd(addr)\n255:   private val csrIsVSi
      = Ireg.isInVSCsrInd(addr)\n256:   private val csrIsIND = csrIsSi || csrIsVSi\n\
      257:   private val accessIND_EX_II = csrIsIND && !privState.isModeM && !mstateen0.CSRIND.asBool\n\
      258: \n259:   // AIA bit 59\n260:   private val ssAiaHaddr = Seq(CSRs.hvien.U,
      CSRs.hvictl.U, CSRs.hviprio1.U, CSRs.hviprio2.U)\n261:   private val ssAiaVSaddr
      = addr === CSRs.vstopi.U\n262:   private val ssAiaSaddr = addr === CSRs.stopi.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 259-269
    context: "259:   // AIA bit 59\n260:   private val ssAiaHaddr = Seq(CSRs.hvien.U,
      CSRs.hvictl.U, CSRs.hviprio1.U, CSRs.hviprio2.U)\n261:   private val ssAiaVSaddr
      = addr === CSRs.vstopi.U\n262:   private val ssAiaSaddr = addr === CSRs.stopi.U\n\
      263:   private val csrIsAIA = ssAiaHaddr.map(_ === addr).reduce(_ || _) || ssAiaVSaddr
      || ssAiaSaddr\n264:   private val accessAIA_EX_II = csrIsAIA && !privState.isModeM
      && !mstateen0.AIA.asBool\n265: \n266:   // IMSIC bit 58 (Ssaia extension)\n\
      267:   private val csrIsStopei = addr === CSRs.stopei.U\n268:   private val
      csrIsVStopei = addr === CSRs.vstopei.U\n269:   private val csrIsTpoie = csrIsStopei
      || csrIsVStopei"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 265-275
    context: "265: \n266:   // IMSIC bit 58 (Ssaia extension)\n267:   private val
      csrIsStopei = addr === CSRs.stopei.U\n268:   private val csrIsVStopei = addr
      === CSRs.vstopei.U\n269:   private val csrIsTpoie = csrIsStopei || csrIsVStopei\n\
      270:   private val accessTopie_EX_II = csrIsTpoie && !privState.isModeM && !mstateen0.IMSIC.asBool\n\
      271: \n272:   // CONTEXT bit 57 context reg (Sdtrig extensions)\n273:   private
      val csrIsHcontext = addr === CSRs.hcontext.U\n274:   private val csrIsScontext
      = addr === CSRs.scontext.U\n275:   private val csrIsContext = csrIsHcontext
      || csrIsScontext"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 271-281
    context: "271: \n272:   // CONTEXT bit 57 context reg (Sdtrig extensions)\n273:\
      \   private val csrIsHcontext = addr === CSRs.hcontext.U\n274:   private val
      csrIsScontext = addr === CSRs.scontext.U\n275:   private val csrIsContext =
      csrIsHcontext || csrIsScontext\n276:   private val accessContext_EX_II = csrIsContext
      && !privState.isModeM && !mstateen0.CONTEXT.asBool\n277: \n278:   // P1P13 bit
      56, Read-only 0\n279: \n280:   // Custom bit 0\n281:   // csr addr HVS: [0x6c0,
      0x6ff], [0xac0, 0xaff], [0xec0, 0xeff]"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 283-293
    context: "283:   // [0x5c0, 0x5ff], [0x9c0, 0x9ff], [0xdc0, 0xdff]\n284:   private
      val csrIsSCustom   = (addr(11, 10) =/= \"b00\".U) && (addr(9, 8) === \"b01\"\
      .U) && (addr(7, 6) === \"b11\".U)\n285:   // [0x800, 0x8ff], [0xcc0, 0xcff]\n\
      286:   private val csrIsUCustom   = (addr(11, 8) === \"b1000\".U) || (addr(11,
      6) === \"b110011\".U)\n287:   private val allCustom      = csrIsHVSCustom ||
      csrIsSCustom || csrIsUCustom\n288:   private val accessCustom_EX_II = allCustom
      && !privState.isModeM && !mstateen0.C.asBool\n289: \n290:   private val xstateControlAccess_EX_II
      = accessStateen_EX_II || accessEnvcfg_EX_II || accessIND_EX_II || accessAIA_EX_II
      ||\n291:     accessTopie_EX_II || accessContext_EX_II || accessCustom_EX_II\n\
      292:   /**\n293:    * Sm/Ssstateen end"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 301-311
    context: "301: \n302: class SLevelPermitModule extends Module {\n303:   val io
      = IO(new Bundle() {\n304:     val in = Input(new Bundle {\n305:       val csrAccess
      = new csrAccessIO\n306:       val privState = new PrivState\n307:       val
      xcounteren = new xcounterenIO\n308:       val xstateen = new xstateenIO\n309:\
      \     })\n310:     val out = Output(new Bundle {\n311:       val sLevelPermit_EX_II
      = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 310-322
    context: "310:     val out = Output(new Bundle {\n311:       val sLevelPermit_EX_II
      = Bool()\n312:     })\n313:   })\n314: \n315:   private val (addr, privState)
      = (\n316:     io.in.csrAccess.addr,\n317:     io.in.privState,\n318:   )\n319:\
      \ \n320:   private val scounteren = io.in.xcounteren.scounteren\n321: \n322:\
      \   private val sstateen0 = io.in.xstateen.sstateen0"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 322-335
    context: "322:   private val sstateen0 = io.in.xstateen.sstateen0\n323: \n324:\
      \   private val csrIsHPM = addr >= CSRs.cycle.U && addr <= CSRs.hpmcounter31.U\n\
      325:   private val counterAddr = addr(4, 0) // 32 counters\n326: \n327:   private
      val accessHPM_EX_II = csrIsHPM && privState.isModeHU && !scounteren(counterAddr)\n\
      328: \n329:   private val csrIsUCustom   = (addr(11, 8) === \"b1000\".U) ||
      (addr(11, 6) === \"b110011\".U)\n330:   private val accessCustom_EX_II = csrIsUCustom
      && privState.isModeHU && !sstateen0.C.asBool\n331: \n332:   io.out.sLevelPermit_EX_II
      := accessHPM_EX_II || accessCustom_EX_II\n333: }\n334: \n335: class PrivilegePermitModule
      extends Module {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 334-344
    context: "334: \n335: class PrivilegePermitModule extends Module {\n336:   val
      io = IO(new Bundle() {\n337:     val in = Input(new Bundle {\n338:       val
      csrAccess = new csrAccessIO\n339:       val privState = new PrivState\n340:\
      \       val debugMode = Bool()\n341:     })\n342:     val out = Output(new Bundle
      {\n343:       val privilege_EX_II = Bool()\n344:       val privilege_EX_VI =
      Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 343-355
    context: "343:       val privilege_EX_II = Bool()\n344:       val privilege_EX_VI
      = Bool()\n345:     })\n346:   })\n347: \n348:   private val (addr, privState,
      debugMode) = (\n349:     io.in.csrAccess.addr,\n350:     io.in.privState,\n\
      351:     io.in.debugMode\n352:   )\n353: \n354:   private val accessTable =
      TruthTable(Seq(\n355:     //       V PRVM ADDR"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 365-375
    context: "365:     BitPat(\"b0__11___10\") -> BitPat.Y(), // M  access H\n366:\
      \     BitPat(\"b0__11___11\") -> BitPat.Y(), // M  access M\n367:   ), BitPat.N())\n\
      368: \n369:   private val regularPrivilegeLegal = chisel3.util.experimental.decode.decoder(\n\
      370:     privState.V.asUInt ## privState.PRVM.asUInt ## addr(9, 8),\n371:  \
      \   accessTable\n372:   ).asBool\n373: \n374:   private val csrIsM = addr(9,
      8) === \"b11\".U\n375:   private val isDebugReg   = addr(11, 4) === \"h7b\"\
      .U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 373-384
    context: "373: \n374:   private val csrIsM = addr(9, 8) === \"b11\".U\n375:  \
      \ private val isDebugReg   = addr(11, 4) === \"h7b\".U\n376:   private val privilegeLegal
      = Mux(isDebugReg, debugMode, regularPrivilegeLegal || debugMode)\n377: \n378:\
      \   io.out.privilege_EX_II := !privilegeLegal && (!privState.isVirtual || csrIsM)\n\
      379:   io.out.privilege_EX_VI := !privilegeLegal && privState.isVirtual && !csrIsM\n\
      380: }\n381: \n382: class VirtualLevelPermitModule(implicit val p: Parameters)
      extends Module with HasSoCParameter {\n383:   val io = IO(new Bundle() {\n384:\
      \     val in = Input(new Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 381-391
    context: "381: \n382: class VirtualLevelPermitModule(implicit val p: Parameters)
      extends Module with HasSoCParameter {\n383:   val io = IO(new Bundle() {\n384:\
      \     val in = Input(new Bundle {\n385:       val csrAccess = new csrAccessIO\n\
      386:       val privState = new PrivState\n387:       val status = new statusIO\n\
      388:       val xcounteren = new xcounterenIO\n389:       val xenvcfg = new xenvcfgIO\n\
      390:       val xstateen = new xstateenIO\n391:       val aia = new aiaIO"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 394-407
    context: "394:       val virtualLevelPermit_EX_II = Bool()\n395:       val virtualLevelPermit_EX_VI
      = Bool()\n396:     })\n397:   })\n398: \n399:   private val (wen, addr, privState)
      = (\n400:     io.in.csrAccess.wen,\n401:     io.in.csrAccess.addr,\n402:   \
      \  io.in.privState,\n403:   )\n404: \n405:   private val (vtvm, vgein) = (\n\
      406:     io.in.status.vtvm,\n407:     io.in.status.vgein,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 429-451
    context: "429:   private val hvictlVTI = io.in.aia.hvictlVTI\n430: \n431:   private
      val csrIsHPM = addr >= CSRs.cycle.U && addr <= CSRs.hpmcounter31.U\n432:   private
      val counterAddr = addr(4, 0) // 32 counters\n433: \n434:   private val rwSatp_EX_VI
      = privState.isModeVS && vtvm && (addr === CSRs.satp.U)\n435: \n436:   private
      val rwVStopei_EX_II = (privState.isModeM || privState.isModeHS) && (addr ===
      CSRs.vstopei.U) && (vgein === 0.U || vgein > soc.IMSICParams.geilen.U)\n437:\
      \   private val rwStopei_EX_VI = privState.isModeVS && (addr === CSRs.stopei.U)
      && (vgein === 0.U || vgein > soc.IMSICParams.geilen.U)\n438: \n439:   private
      val rwSip_Sie_EX_VI = privState.isModeVS && hvictlVTI && (addr === CSRs.sip.U
      || addr === CSRs.sie.U)\n440: \n441:   private val rwStimecmp_EX_VI = privState.isModeVS
      && (addr === CSRs.stimecmp.U) &&\n442:     (!hcounterenTM || !henvcfgSTCE ||
      wen && hvictlVTI)\n443: \n444:   private val accessHPM_EX_VI = csrIsHPM && (\n\
      445:       privState.isModeVS && !hcounteren(counterAddr) ||\n446:       privState.isModeVU
      && (!hcounteren(counterAddr) || !scounteren(counterAddr))\n447:     )\n448:\
      \ \n449:   /**\n450:    * Sm/Ssstateen begin\n451:    */"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 453-485
    context: "453:   //  SE0 bit 63\n454:   private val accessStateen_EX_VI = (\n\
      455:     hstateen0.SE0.asBool +: Seq(hstateen1, hstateen2, hstateen3).map(_.SE.asBool)\n\
      456:     ).zipWithIndex.map{case(se, i) => {\n457:     val csrIsSstateen = addr
      === (CSRs.sstateen0 + i).U\n458:     csrIsSstateen && privState.isVirtual &&
      !se\n459:   }}.reduce(_ || _)\n460: \n461:   // ENVCFG bit 62\n462:   private
      val csrIsSenvcfg = addr === CSRs.senvcfg.U\n463:   private val accessEnvcfg_EX_VI
      = csrIsSenvcfg && privState.isVirtual && !hstateen0.ENVCFG.asBool\n464: \n465:\
      \   // CSRIND bit 60 indirect reg (Sscsrind extensions), this is not implemented\n\
      466:   // csr addr S: [0x150, 0x157]\n467:   private val csrIsSi = Ireg.isInSCsrInd(addr)\n\
      468:   private val accessIND_EX_VI = csrIsSi && privState.isVirtual && !hstateen0.CSRIND.asBool\n\
      469: \n470:   // AIA bit 59\n471:   private val ssAiaSaddr = addr === CSRs.stopi.U\n\
      472:   private val accessAIA_EX_VI = ssAiaSaddr && privState.isVirtual && !hstateen0.AIA.asBool\n\
      473: \n474:   // IMSIC bit 58 (Ssaia extension)\n475:   private val csrIsStopei
      = addr === CSRs.stopei.U\n476:   private val accessTopie_EX_VI = csrIsStopei
      && privState.isVirtual && !hstateen0.IMSIC.asBool\n477: \n478:   // CONTEXT
      bit 57 context reg (Sdtrig extensions)\n479:   private val csrIsScontext = addr
      === CSRs.scontext.U\n480:   private val accessContext_EX_VI = csrIsScontext
      && privState.isVirtual && !hstateen0.CONTEXT.asBool\n481: \n482:   // P1P13
      bit 56, Read-only 0\n483: \n484:   // Custom bit 0\n485:   // [0x5c0, 0x5ff],
      [0x9c0, 0x9ff], [0xdc0, 0xdff]"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 484-495
    context: "484:   // Custom bit 0\n485:   // [0x5c0, 0x5ff], [0x9c0, 0x9ff], [0xdc0,
      0xdff]\n486:   private val csrIsSCustom   = (addr(11, 10) =/= \"b00\".U) &&
      (addr(9, 8) === \"b01\".U) && (addr(7, 6) === \"b11\".U)\n487:   // [0x800,
      0x8ff], [0xcc0, 0xcff]\n488:   private val csrIsUCustom   = (addr(11, 8) ===
      \"b1000\".U) || (addr(11, 6) === \"b110011\".U)\n489:   private val accessCustom_EX_VI
      = (csrIsSCustom || csrIsUCustom) && privState.isVirtual && !hstateen0.C.asBool
      ||\n490:     csrIsUCustom && privState.isModeVU && hstateen0.C.asBool && !sstateen0.C.asBool\n\
      491: \n492:   private val xstateControlAccess_EX_VI = accessStateen_EX_VI ||
      accessEnvcfg_EX_VI || accessIND_EX_VI || accessAIA_EX_VI ||\n493:     accessTopie_EX_VI
      || accessContext_EX_VI || accessCustom_EX_VI\n494: \n495:   io.out.virtualLevelPermit_EX_II
      := rwVStopei_EX_II"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 498-530
    context: "498: \n499: class IndirectCSRPermitModule extends Module {\n500:   val
      io = IO(new Bundle() {\n501:     val in = Input(new Bundle {\n502:       val
      csrAccess = new csrAccessIO\n503:       val privState = new PrivState\n504:\
      \       val aia = new aiaIO\n505:       val xstateen = new xstateenIO\n506:\
      \     })\n507:     val out = Output(new Bundle {\n508:       val indirectCSR_EX_II
      = Bool()\n509:       val indirectCSR_EX_VI = Bool()\n510:     })\n511:   })\n\
      512: \n513:   private val (addr, privState) = (\n514:     io.in.csrAccess.addr,\n\
      515:     io.in.privState,\n516:   )\n517: \n518:   private val (miselect, siselect,
      vsiselect) = (\n519:     io.in.aia.miselect,\n520:     io.in.aia.siselect,\n\
      521:     io.in.aia.vsiselect,\n522:   )\n523: \n524:   private val (mstateen0,
      hstateen0) = (\n525:     io.in.xstateen.mstateen0,\n526:     io.in.xstateen.hstateen0,\n\
      527:   )\n528: \n529:   private val mvienSEIE = io.in.aia.mvienSEIE\n530: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 527-538
    context: "527:   )\n528: \n529:   private val mvienSEIE = io.in.aia.mvienSEIE\n\
      530: \n531:   private val rwMireg_EX_II = (\n532:       Iselect.isInAIA(miselect)
      && Iselect.isOdd(miselect) ||\n533:       Iselect.isInOthers(miselect)\n534:\
      \     ) && addr === CSRs.mireg.U\n535: \n536:   private val rwMireg2_6_EX_II
      = Ireg.isInMireg2_6(addr)\n537: \n538:   private val rwSireg_EX_II = ("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 534-562
    context: "534:     ) && addr === CSRs.mireg.U\n535: \n536:   private val rwMireg2_6_EX_II
      = Ireg.isInMireg2_6(addr)\n537: \n538:   private val rwSireg_EX_II = (\n539:\
      \       !privState.isVirtual && (\n540:         Iselect.isInAIA(siselect) &&
      Iselect.isOdd(siselect) ||\n541:         Iselect.isInOthers(siselect)\n542:\
      \       ) ||\n543:       privState.isModeHS && (\n544:         mvienSEIE &&
      Iselect.isInImsic(siselect) ||\n545:         !mstateen0.AIA.asBool && Iselect.isInAIA(siselect)
      ||\n546:         !mstateen0.IMSIC.asBool && Iselect.isInImsic(siselect)\n547:\
      \       ) ||\n548:       privState.isVirtual && (\n549:         Iselect.isInOthers(vsiselect)
      ||\n550:         !mstateen0.AIA.asBool && Iselect.isInAIA(vsiselect) ||\n551:\
      \         !mstateen0.IMSIC.asBool && Iselect.isInImsic(vsiselect)\n552:    \
      \   )\n553:     ) && addr === CSRs.sireg.U\n554: \n555:   private val rwSireg_EX_VI
      = privState.isVirtual && (Iselect.isInAIA(vsiselect) || Iselect.isInImsic(vsiselect)
      && !hstateen0.IMSIC.asBool) && addr === CSRs.sireg.U\n556: \n557:   private
      val rwSireg2_6_EX_VI = privState.isVirtual && (Iselect.isInAIA(vsiselect) ||
      Iselect.isInImsic(vsiselect)) && Ireg.isInSireg2_6(addr)\n558: \n559:   private
      val rwSireg2_6_EX_II = Ireg.isInSireg2_6(addr) && !rwSireg2_6_EX_VI\n560: \n\
      561:   private val rwVSireg_EX_II = (\n562:       !Iselect.isInImsic(vsiselect)
      ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 558-574
    context: "558: \n559:   private val rwSireg2_6_EX_II = Ireg.isInSireg2_6(addr)
      && !rwSireg2_6_EX_VI\n560: \n561:   private val rwVSireg_EX_II = (\n562:   \
      \    !Iselect.isInImsic(vsiselect) ||\n563:       !privState.isModeM && !mstateen0.IMSIC.asBool\n\
      564:     ) && addr === CSRs.vsireg.U\n565: \n566:   private val rwVSireg2_6_EX_II
      = Ireg.isInVSireg2_6(addr)\n567: \n568:   io.out.indirectCSR_EX_II := rwMireg_EX_II
      || rwMireg2_6_EX_II || rwSireg_EX_II || rwSireg2_6_EX_II || rwVSireg_EX_II ||
      rwVSireg2_6_EX_II\n569:   io.out.indirectCSR_EX_VI := rwSireg_EX_VI || rwSireg2_6_EX_VI\n\
      570: }\n571: \n572: class csrAccessIO extends Bundle {\n573:   val ren   = Bool()\n\
      574:   val wen   = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 619-632
    context: "619:   val henvcfg = UInt(64.W)\n620: }\n621: \n622: class xstateenIO
      extends Bundle {\n623:   // Sm/Ssstateen: to control state access\n624:   val
      mstateen0 = new Mstateen0Bundle\n625:   val mstateen1 = new MstateenNonZeroBundle\n\
      626:   val mstateen2 = new MstateenNonZeroBundle\n627:   val mstateen3 = new
      MstateenNonZeroBundle\n628:   val hstateen0 = new Hstateen0Bundle\n629:   val
      hstateen1 = new HstateenNonZeroBundle\n630:   val hstateen2 = new HstateenNonZeroBundle\n\
      631:   val hstateen3 = new HstateenNonZeroBundle\n632:   val sstateen0 = new
      Sstateen0Bundle"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 631-641
    context: "631:   val hstateen3 = new HstateenNonZeroBundle\n632:   val sstateen0
      = new Sstateen0Bundle\n633: }\n634: \n635: class aiaIO extends Bundle {\n636:\
      \   val miselect = UInt(64.W)\n637:   val siselect = UInt(64.W)\n638:   val
      vsiselect = UInt(64.W)\n639:   val mvienSEIE = Bool()\n640:   val hvictlVTI
      = Bool()\n641: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 641-651
    context: "641: }\n642: \n643: class CSRPermitIO extends Bundle {\n644:   val in
      = Input(new Bundle {\n645:     val csrAccess = new csrAccessIO\n646:     val
      privState = new PrivState\n647:     val debugMode = Bool()\n648:     val xRet
      = new xRetIO\n649:     val status = new statusIO\n650:     val xcounteren =
      new xcounterenIO\n651:     val xenvcfg = new xenvcfgIO"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPMP.scala
    lines: 49-64
    context: "49: \n50:   val pmpCSROutMap: SeqMap[Int, UInt] = SeqMap.from(\n51:\
      \     pmpCSRMods.map(csr => csr.addr -> csr.regOut.asInstanceOf[CSRBundle].asUInt).iterator\n\
      52:   )\n53: \n54:   private val pmpCfgRead = Cat(pmpcfgs.map(_.rdata(7, 0)).reverse)\n\
      55: \n56:   pmpCSRMods.foreach { mod =>\n57:     mod match {\n58:       case
      m: HasPMPCfgRSink =>\n59:         m.cfgRData := pmpCfgRead\n60:       case _
      =>\n61:     }\n62:   }\n63: }\n64: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 34-50
    context: "34:     }\n35:     reg.BCLEAR := Mux(reg.BCLEAR.asBool, 0.U, Mux(wen
      && wdata.BCLEAR.asBool, 1.U, 0.U))\n36:   })\n37:     .setAddr(Mbmc))  else\
      \  None\n38: \n39:   val mstatus = Module(new MstatusModule)\n40:     .setAddr(CSRs.mstatus)\n\
      41: \n42:   val misa = Module(new CSRModule(\"Misa\", new MisaBundle))\n43:\
      \     .setAddr(CSRs.misa)\n44: \n45:   println(s\"[CSR] supported isa ext: ${misa.bundle.getISAString}\"\
      )\n46: \n47:   val medeleg = Module(new CSRModule(\"Medeleg\", new MedelegBundle))\n\
      48:     .setAddr(CSRs.medeleg)\n49: \n50:   val mideleg = Module(new CSRModule(\"\
      Mideleg\", new MidelegBundle))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 98-108
    context: "98:     when(fromHie.SGEIE.valid) {\n99:       reg.SGEIE := fromHie.SGEIE.bits\n\
      100:     }\n101: \n102:     // bit 13~63 LCIP\n103:     reg.getLocal lazyZip
      fromSie.getLocal lazyZip fromVSie.getLocal foreach { case (rLCIE, sieLCIE, vsieLCIE)
      =>\n104:       when (sieLCIE.valid || vsieLCIE.valid) {\n105:         rLCIE
      := Mux1H(Seq(\n106:           sieLCIE .valid -> sieLCIE .bits,\n107:       \
      \    vsieLCIE.valid -> vsieLCIE.bits,\n108:         ))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 108-118
    context: "108:         ))\n109:       }\n110:     }\n111: \n112:     // 14~63
      read only 0\n113:     regOut.getLocal.filterNot(_.lsb == InterruptNO.COI).foreach(_
      := 0.U)\n114:   }).setAddr(CSRs.mie)\n115: \n116:   val mtvec = Module(new CSRModule(\"\
      Mtvec\", new XtvecBundle))\n117:     .setAddr(CSRs.mtvec)\n118: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 162-172
    context: "162:     // write from sip\n163:     when (fromSip.SSIP.valid) {\n164:\
      \       reg.SSIP := fromSip.SSIP.bits\n165:     }\n166: \n167:     reg.getLocal
      lazyZip fromSip.getLocal lazyZip fromVSip.getLocal foreach { case (rLCIP, sipLCIP,
      vsipLCIP) =>\n168:       // sip should assert valid when mideleg=0 && mvien=1\n\
      169:       when (sipLCIP.valid || vsipLCIP.valid) {\n170:         rLCIP := Mux1H(Seq(\n\
      171:           sipLCIP .valid -> sipLCIP .bits,\n172:           vsipLCIP.valid
      -> vsipLCIP.bits,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 323-341
    context: "323:       reg := reg\n324:     }\n325:   }).setAddr(CSRs.mcycle)\n\
      326: \n327: \n328:   val minstret = Module(new CSRModule(\"Minstret\") with
      HasMachineCounterControlBundle with HasRobCommitBundle {\n329:     when(w.wen)
      {\n330:       reg := w.wdata\n331:     }.elsewhen(!this.mcountinhibit.IR &&
      robCommit.instNum.valid) {\n332:       reg := reg.ALL.asUInt + robCommit.instNum.bits\n\
      333:     }.otherwise {\n334:       reg := reg\n335:     }\n336:   }).setAddr(CSRs.minstret)\n\
      337: \n338:   val mhpmcounters: Seq[CSRModule[_]] = (3 to 0x1F).map(num =>\n\
      339:     Module(new CSRModule(s\"Mhpmcounter$num\", new MhpmcounterBundle) with
      HasMachineCounterControlBundle with HasPerfCounterBundle {\n340:       val countingInhibit
      = this.mcountinhibit.asUInt(num) | !countingEn\n341:       val counterAdd =
      reg.ALL.asUInt +& perf.value"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 346-356
    context: "346:       }.otherwise {\n347:         reg := reg\n348:       }\n349:\
      \       // Count overflow never results from writes to the mhpmcountern or mhpmeventn
      registers, only from\n350:       // hardware increments of counter registers.\n\
      351:       toMhpmeventOF := !countingInhibit & counterAdd.head(1)\n352:    \
      \ }).setAddr(CSRs.mhpmcounter3 - 3 + num)\n353:   )\n354: \n355:   val mvendorid
      = Module(new CSRModule(\"Mvendorid\", new CSRBundle {\n356:     val ALL = RO(63,
      0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 379-395
    context: "379:   val mconfigptr = Module(new CSRModule(\"Mconfigptr\", new CSRBundle
      {\n380:     val ALL = RO(63, 0)\n381:   }))\n382:     .setAddr(CSRs.mconfigptr)\n\
      383: \n384:   val mstateen0 = Module(new CSRModule(\"Mstateen0\", new Mstateen0Bundle)).setAddr(CSRs.mstateen0)\n\
      385: \n386:   val mstateen1 = Module(new CSRModule(\"Mstateen1\", new MstateenNonZeroBundle)).setAddr(CSRs.mstateen1)\n\
      387: \n388:   val mstateen2 = Module(new CSRModule(\"Mstateen2\", new MstateenNonZeroBundle)).setAddr(CSRs.mstateen2)\n\
      389: \n390:   val mstateen3 = Module(new CSRModule(\"Mstateen3\", new MstateenNonZeroBundle)).setAddr(CSRs.mstateen3)\n\
      391: \n392:   // smrnmi extension\n393:   val mnepc = Module(new CSRModule(\"\
      Mnepc\", new Epc) with TrapEntryMNEventSinkBundle {\n394:     rdata := SignExt(Cat(reg.epc.asUInt,
      0.U(1.W)), XLEN)\n395:   })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 421-432
    context: "421:     }\n422:   })\n423:     .setAddr(CSRs.mcontext)\n424: \n425:\
      \   val machineLevelCSRMods: Seq[CSRModule[_]] = Seq(\n426:     mstatus,\n427:\
      \     misa,\n428:     medeleg,\n429:     mideleg,\n430:     mie,\n431:     mtvec,\n\
      432:     mcounteren,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 441-451
    context: "441:     mip,\n442:     mtinst,\n443:     mtval2,\n444:     mseccfg,\n\
      445:     mcycle,\n446:     minstret,\n447:     mvendorid,\n448:     marchid,\n\
      449:     mimpid,\n450:     mhartid,\n451:     mconfigptr,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 447-460
    context: "447:     mvendorid,\n448:     marchid,\n449:     mimpid,\n450:     mhartid,\n\
      451:     mconfigptr,\n452:     mstateen0,\n453:     mstateen1,\n454:     mstateen2,\n\
      455:     mstateen3,\n456:     mnepc,\n457:     mncause,\n458:     mnstatus,\n\
      459:     mnscratch,\n460:     mcontext,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 507-517
    context: "507:   val SD   = CSRROField     (63,\n508:     (_, _) => FS === ContextStatus.Dirty
      || VS === ContextStatus.Dirty\n509:   )\n510: }\n511: \n512: class MstatusModule(implicit
      override val p: Parameters) extends CSRModule(\"MStatus\", new MstatusBundle)\n\
      513:   with TrapEntryMEventSinkBundle\n514:   with TrapEntryHSEventSinkBundle\n\
      515:   with DretEventSinkBundle\n516:   with MretEventSinkBundle\n517:   with
      MNretEventSinkBundle"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 517-527
    context: "517:   with MNretEventSinkBundle\n518:   with SretEventSinkBundle\n\
      519:   with HasRobCommitBundle\n520:   with HasMachineEnvBundle\n521: {\n522:\
      \   val mstatus = IO(Output(bundle))\n523:   val sstatus = IO(Output(new SstatusBundle))\n\
      524:   val sstatusRdata = IO(Output(UInt(64.W)))\n525: \n526:   val wAliasSstatus
      = IO(Input(new CSRAddrWriteBundle(new SstatusBundle)))\n527:   for ((name, field)
      <- wAliasSstatus.wdataFields.elements) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 532-547
    context: "532:   }\n533: \n534:   // write connection\n535:   reconnectReg()\n\
      536: \n537:   when (robCommit.fsDirty || writeFCSR) {\n538:     assert(reg.FS
      =/= ContextStatus.Off, \"The [m|s]status.FS should not be Off when set dirty,
      please check decode\")\n539:     reg.FS := ContextStatus.Dirty\n540:   }\n541:\
      \ \n542:   when (robCommit.vsDirty || writeVCSR || robCommit.vstart.valid &&
      robCommit.vstart.bits =/= 0.U) {\n543:     assert(reg.VS =/= ContextStatus.Off,
      \"The [m|s]status.VS should not be Off when set dirty, please check decode\"\
      )\n544:     reg.VS := ContextStatus.Dirty\n545:   }\n546:   // when MDT is explicitly
      written by 1, clear MIE\n547:   // only when reg.MDT is zero or wdata.MDT is
      zero , MIE can be explicitly written by 1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 565-578
    context: "565:   // SDT and SIE is the same as MDT and MIE\n566:   when (writeSDT)
      {\n567:     reg.SIE := false.B\n568:   }\n569:   // read connection\n570:  \
      \ mstatus :|= regOut\n571:   sstatus := mstatus\n572:   sstatus.SDT := regOut.SDT
      && menvcfg.DTE\n573:   rdata := mstatus.asUInt\n574:   sstatusRdata := sstatus.asUInt\n\
      575: }\n576: \n577: class MnstatusBundle extends CSRBundle {\n578:   val NMIE\
      \   = CSRRWField  (3).withReset(1.U) // as opensbi not support smrnmi, we init
      nmie open"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 584-596
    context: "584: class MisaBundle extends CSRBundle {\n585:   // Todo: reset with
      ISA string\n586:   val A = RO( 0).withReset(1.U) // Atomic extension\n587: \
      \  val B = RO( 1).withReset(1.U) // B extension\n588:   val C = RO( 2).withReset(1.U)
      // Compressed extension\n589:   val D = RO( 3).withReset(1.U) // Double-precision
      floating-point extension\n590:   val E = RO( 4).withReset(0.U) // RV32E/64E
      base ISA\n591:   val F = RO( 5).withReset(1.U) // Single-precision floating-point
      extension\n592:   val G = RO( 6).withReset(0.U) // Reserved\n593:   val H =
      RO( 7).withReset(1.U) // Hypervisor extension\n594:   val I = RO( 8).withReset(1.U)
      // RV32I/64I/128I base ISA\n595:   val J = RO( 9).withReset(0.U) // Reserved\n\
      596:   val K = RO(10).withReset(0.U) // Reserved"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 597-607
    context: "597:   val L = RO(11).withReset(0.U) // Reserved\n598:   val M = RO(12).withReset(1.U)
      // Integer Multiply/Divide extensi\n599:   val N = RO(13).withReset(0.U) //
      Tentatively reserved for User-Level Interrupts extension\n600:   val O = RO(14).withReset(0.U)
      // Reserved\n601:   val P = RO(15).withReset(0.U) // Tentatively reserved for
      Packed-SIMD extension\n602:   val Q = RO(16).withReset(0.U) // Quad-precision
      floating-point extension\n603:   val R = RO(17).withReset(0.U) // Reserved\n\
      604:   val S = RO(18).withReset(1.U) // Supervisor mode implemented\n605:  \
      \ val T = RO(19).withReset(0.U) // Reserved\n606:   val U = RO(20).withReset(1.U)
      // User mode implemented\n607:   val V = RO(21).withReset(1.U) // Vector extension"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 613-623
    context: "613: \n614:   def getISAString = this.getFields.filter(x => x != MXL
      && x.init.litValue == 1).sortBy(_.lsb).map(x => ('A' + x.msb).toChar).mkString\n\
      615: }\n616: \n617: class MedelegBundle extends ExceptionBundle {\n618:   this.getALL.foreach(_.setRW().withReset(0.U))\n\
      619:   this.EX_MCALL.setRO().withReset(0.U) // never delegate machine level
      ecall\n620:   this.EX_DBLTRP.setRO().withReset(0.U)// double trap is not delegatable\n\
      621: }\n622: \n623: class MidelegBundle extends InterruptBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 619-644
    context: "619:   this.EX_MCALL.setRO().withReset(0.U) // never delegate machine
      level ecall\n620:   this.EX_DBLTRP.setRO().withReset(0.U)// double trap is not
      delegatable\n621: }\n622: \n623: class MidelegBundle extends InterruptBundle
      {\n624:   this.getALL.foreach(_.setRW().withReset(0.U))\n625:   // Don't delegate
      Machine level interrupts\n626:   this.getM.foreach(_.setRO().withReset(0.U))\n\
      627:   // Ref: 13.4.2. Machine Interrupt Delegation Register (mideleg)\n628:\
      \   // When the hypervisor extension is implemented, bits 10, 6, and 2 of mideleg
      (corresponding to the standard VS-level\n629:   // interrupts) are each read-only
      one.\n630:   this.getVS.foreach(_.setRO().withReset(1.U))\n631:   // bit 12
      of mideleg (corresponding to supervisor-level guest external interrupts) is
      also read-only one.\n632:   // VS-level interrupts and guest external interrupts
      are always delegated past M-mode to HS-mode.\n633:   this.SGEI.setRO().withReset(1.U)\n\
      634:   this.getLocal.foreach(_.setRO().withReset(0.U))\n635:   this.LCOFI.setRW().withReset(0.U)\n\
      636: }\n637: \n638: class MieBundle extends InterruptEnableBundle {\n639:  \
      \ this.getNonLocal.foreach(_.setRW().withReset(0.U))\n640:   this.LCOFIE.setRW().withReset(0.U)\n\
      641: }\n642: \n643: class MipBundle extends InterruptPendingBundle {\n644: \
      \  // Ref: riscv privileged spec - 18.4.3. Machine Interrupt (mip and mie) Registers"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 647-658
    context: "647:   // We implement SGEIP, VSEIP, VSTIP, and VSSIP in mip are registers,\n\
      648:   // while these bits in hip are aliases for the same bits in mip.\n649:\
      \   //\n650:   // Ref: riscv interrupt spec - 2.1 Machine-level CSRs\n651: \
      \  // Existing CSRs mie, mip, and mideleg are widended to 64 bits to support
      a total of 64 interrupt causes.\n652:   this.getHS.foreach(_.setRW().withReset(0.U))\n\
      653:   this.getVS.foreach(_.setRW().withReset(0.U))\n654:   this.LCOFIP.setRW().withReset(0.U)\n\
      655: }\n656: \n657: class MvienBundle extends InterruptEnableBundle {\n658:\
      \   // Ref: riscv interrupt spec - 5.3 Interrupt filtering and virtual interrupts
      for supervisor level"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 659-675
    context: "659:   // It is strongly recommended that bit 9 of mvien be writable.\n\
      660:   // It is strongly recommended that bit 1 of mvien also be writable.\n\
      661:   // A bit in mvien can be set to 1 only for major interrupts 1, 9, and
      1363.\n662:   this.SSIE.setRW().withReset(0.U)\n663:   this.SEIE.setRW().withReset(0.U)\n\
      664:   this.getLocal.foreach(_.setRW().withReset(0.U))\n665:   this.LCOFIE.setRO().withReset(0.U)\n\
      666: }\n667: \n668: class MvipBundle extends InterruptPendingBundle {\n669:\
      \   this.getHS.foreach(_.setRW().withReset(0.U))\n670:   this.getLocal.foreach(_.setRW().withReset(0.U))\n\
      671:   this.LCOFIP.setRO().withReset(0.U)\n672: }\n673: \n674: class Epc extends
      CSRBundle {\n675:   val epc = RW(63, 1).withReset(0.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 707-717
    context: "707:   val VSEIE = ValidIO(RW(0))\n708:   val SGEIE = ValidIO(RW(0))\n\
      709: }\n710: \n711: class MvipToMip extends IpValidBundle {\n712:   this.getHS.foreach(_.bits.setRW())\n\
      713: }\n714: \n715: class HipToMip extends IpValidBundle {\n716:   // Only hip.VSSIP
      is writable\n717:   this.VSSIP.bits.setRW()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 795-805
    context: "795: trait HasMachineCounterControlBundle { self: CSRModule[_] =>\n\
      796:   val mcountinhibit = IO(Input(new McountinhibitBundle))\n797: }\n798:\
      \ \n799: trait HasRobCommitBundle { self: CSRModule[_] =>\n800:   val robCommit
      = IO(Input(new RobCommitCSR))\n801:   val writeFCSR = IO(Input(Bool()))\n802:\
      \   val writeVCSR = IO(Input(Bool()))\n803:   val isVirtMode = IO(Input(Bool()))\n\
      804: }\n805: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 820-826
    context: "820: trait HasLocalInterruptReqBundle { self: CSRModule[_] =>\n821:\
      \   val lcofiReq = IO(Input(Bool()))\n822: }\n823: \n824: trait HasMachineFlushL2Bundle
      { self: CSRModule[_] =>\n825:   val l2FlushDone = IO(Input(Bool()))\n826: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 6-16
    context: "6: import freechips.rocketchip.rocket.CSRs\n7: import org.chipsalliance.cde.config.Parameters\n\
      8: import top.{ArgParser, Generator}\n9: import utility._\n10: import utils.OptionWrapper\n\
      11: import xiangshan.backend.fu.NewCSR.CSRBundles.{CSRCustomState, PrivState,
      RobCommitCSR}\n12: import xiangshan.backend.fu.NewCSR.CSRDefines._\n13: import
      xiangshan.backend.fu.NewCSR.CSREnumTypeImplicitCast._\n14: import xiangshan.backend.fu.NewCSR.CSREvents.{CSREvents,
      DretEventSinkBundle, EventUpdatePrivStateOutput, MNretEventSinkBundle, MretEventSinkBundle,
      SretEventSinkBundle, SretEventSDTSinkBundle,  TargetPCBundle, TrapEntryDEventSinkBundle,
      TrapEntryEventInput, TrapEntryHSEventSinkBundle, TrapEntryMEventSinkBundle,
      TrapEntryMNEventSinkBundle, TrapEntryVSEventSinkBundle}\n15: import xiangshan.backend.fu.fpu.Bundles.Frm\n\
      16: import xiangshan.backend.fu.vector.Bundles.{Vl, Vstart, Vxrm, Vxsat}"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 80-90
    context: "80:   val wdata = UInt(64.W)\n81:   val mnret = Input(Bool())\n82: \
      \  val mret = Input(Bool())\n83:   val sret = Input(Bool())\n84:   val dret
      = Input(Bool())\n85:   val redirectFlush = Input(Bool())\n86: }\n87: \n88: class
      NewCSROutput(implicit p: Parameters) extends Bundle {\n89:   val EX_II = Bool()\n\
      90:   val EX_VI = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 86-96
    context: "86: }\n87: \n88: class NewCSROutput(implicit p: Parameters) extends
      Bundle {\n89:   val EX_II = Bool()\n90:   val EX_VI = Bool()\n91:   val flushPipe
      = Bool()\n92:   val rData = UInt(64.W)\n93:   val targetPcUpdate = Bool()\n\
      94:   val targetPc = new TargetPCBundle\n95:   val regOut = UInt(64.W)\n96:\
      \   // perf"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 121-131
    context: "121: \n122:   val io = IO(new Bundle {\n123:     val fromTop = Input(new
      Bundle {\n124:       val hartId = UInt(hartIdLen.W)\n125:       val clintTime
      = Input(ValidIO(UInt(64.W)))\n126:       val l2FlushDone = Input(Bool())\n127:\
      \       val criticalErrorState = Input(Bool())\n128:     })\n129:     val in
      = Flipped(DecoupledIO(new NewCSRInput))\n130:     val trapInst = Input(ValidIO(UInt(InstWidth.W)))\n\
      131:     val fromMem = Input(new Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 146-156
    context: "146:         val isInterrupt = Bool()\n147:         val isHls = Bool()\n\
      148:         val isFetchMalAddr = Bool()\n149:         val isForVSnonLeafPTE
      = Bool()\n150:       })\n151:       val commit = Input(new RobCommitCSR)\n152:\
      \       val robDeqPtr = Input(new RobPtr)\n153:     })\n154: \n155:     val
      fromVecExcpMod = Input(new Bundle {\n156:       val busy = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 159-173
    context: "159:     val perf = Input(new PerfCounterIO)\n160: \n161:     /** Output
      should be a DecoupledIO, since now CSR writing to integer register file might
      be blocked (by arbiter) */\n162:     val out = DecoupledIO(new NewCSROutput)\n\
      163:     val status = Output(new Bundle {\n164:       val privState = new PrivState\n\
      165:       val interrupt = Bool()\n166:       val wfiEvent = Bool()\n167:  \
      \     // fp\n168:       val fpState = new Bundle {\n169:         val off = Bool()\n\
      170:         val frm = Frm()\n171:       }\n172:       // vec\n173:       val
      vecState = new Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 222-232
    context: "222:       }\n223:     })\n224: \n225:     val toDecode = new CSRToDecode\n\
      226: \n227:     val fetchMalTval = Input(UInt(XLEN.W))\n228: \n229:     val
      distributedWenLegal = Output(Bool())\n230:   })\n231: \n232:   val toAIA   =
      IO(Output(new CSRToAIABundle))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 246-256
    context: "246: \n247:   val ren   = io.in.bits.ren && valid\n248:   val raddr
      = io.in.bits.addr\n249: \n250:   // flush\n251:   val redirectFlush = io.in.bits.redirectFlush\n\
      252: \n253:   val hasTrap = io.fromRob.trap.valid\n254:   val trapVec = io.fromRob.trap.bits.trapVec\n\
      255:   val trapPC = io.fromRob.trap.bits.pc\n256:   val trapPCGPA = io.fromRob.trap.bits.pcGPA"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 280-296
    context: "280:   val unprivCountUpdate  = !debugModeStopCount && debugModeStopCountNext\n\
      281: \n282:   val criticalErrorStateInCSR = Wire(Bool())\n283:   val criticalErrorState
      = RegEnable(true.B, false.B, io.fromTop.criticalErrorState || criticalErrorStateInCSR)\n\
      284: \n285:   private val privState = Wire(new PrivState)\n286:   privState.PRVM
      := PRVM\n287:   privState.V := V\n288: \n289:   private val isModeM        \
      \      = privState.isModeM\n290:   private val (isModeHS, isModeHU) = (privState.isModeHS,
      privState.isModeHU)\n291:   private val (isModeVS, isModeVU) = (privState.isModeVS,
      privState.isModeVU)\n292: \n293:   val permitMod = Module(new CSRPermitModule)\n\
      294:   val sstcIRGen = Module(new SstcInterruptGen)\n295:   val commidIdMod
      = Module(new CommitIDModule(40, hartIdLen))\n296: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 356-368
    context: "356:   when(nonMaskableIRP.NMI_31) {\n357:     nmip.NMI_31 := true.B\n\
      358:   }\n359: \n360:   val intrMod = Module(new InterruptFilter)\n361:   intrMod.io.in.privState
      := privState\n362:   intrMod.io.in.mstatusMIE := mstatus.regOut.MIE.asBool\n\
      363:   intrMod.io.in.sstatusSIE := mstatus.regOut.SIE.asBool\n364:   intrMod.io.in.vsstatusSIE
      := vsstatus.regOut.SIE.asBool\n365:   intrMod.io.in.mip := mip.rdataFields\n\
      366:   intrMod.io.in.mie := mie.regOut\n367:   intrMod.io.in.mideleg := mideleg.regOut\n\
      368:   intrMod.io.in.sip := sip.regOut"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 411-422
    context: "411:   trapHandleMod.io.in.trapInfo.bits.nmi := nmi\n412:   trapHandleMod.io.in.trapInfo.bits.intrVec
      := intrVec\n413:   trapHandleMod.io.in.trapInfo.bits.isInterrupt := trapIsInterrupt\n\
      414:   trapHandleMod.io.in.trapInfo.bits.irToHS := irToHS\n415:   trapHandleMod.io.in.trapInfo.bits.irToVS
      := irToVS\n416:   trapHandleMod.io.in.privState := privState\n417:   trapHandleMod.io.in.mstatus\
      \  := mstatus.regOut\n418:   trapHandleMod.io.in.vsstatus := vsstatus.regOut\n\
      419:   trapHandleMod.io.in.mnstatus := mnstatus.regOut\n420:   trapHandleMod.io.in.mideleg\
      \  := mideleg.regOut\n421:   trapHandleMod.io.in.medeleg  := medeleg.regOut\n\
      422:   trapHandleMod.io.in.hideleg  := hideleg.regOut"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 470-480
    context: "470: \n471:   permitMod.io.in.csrAccess.ren := ren && valid\n472:  \
      \ permitMod.io.in.csrAccess.wen := wen\n473:   permitMod.io.in.csrAccess.addr
      := addr\n474: \n475:   permitMod.io.in.privState := privState\n476:   permitMod.io.in.debugMode
      := debugMode\n477: \n478:   permitMod.io.in.xRet.mnret := io.in.bits.mnret &&
      valid\n479:   permitMod.io.in.xRet.mret  := io.in.bits.mret  && valid\n480:\
      \   permitMod.io.in.xRet.sret  := io.in.bits.sret  && valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 478-491
    context: "478:   permitMod.io.in.xRet.mnret := io.in.bits.mnret && valid\n479:\
      \   permitMod.io.in.xRet.mret  := io.in.bits.mret  && valid\n480:   permitMod.io.in.xRet.sret\
      \  := io.in.bits.sret  && valid\n481:   permitMod.io.in.xRet.dret  := io.in.bits.dret\
      \  && valid\n482: \n483:   permitMod.io.in.status.tsr := mstatus.regOut.TSR.asBool\n\
      484:   permitMod.io.in.status.vtsr := hstatus.regOut.VTSR.asBool\n485: \n486:\
      \   permitMod.io.in.status.tvm  := mstatus.regOut.TVM.asBool\n487:   permitMod.io.in.status.vtvm
      := hstatus.regOut.VTVM.asBool\n488: \n489:   permitMod.io.in.status.vgein :=
      hstatus.regOut.VGEIN.asUInt\n490: \n491:   permitMod.io.in.xcounteren.mcounteren
      := mcounteren.rdata"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 490-503
    context: "490: \n491:   permitMod.io.in.xcounteren.mcounteren := mcounteren.rdata\n\
      492:   permitMod.io.in.xcounteren.hcounteren := hcounteren.rdata\n493:   permitMod.io.in.xcounteren.scounteren
      := scounteren.rdata\n494: \n495:   permitMod.io.in.xstateen.mstateen0 := mstateen0.rdata\n\
      496:   permitMod.io.in.xstateen.mstateen1 := mstateen1.rdata\n497:   permitMod.io.in.xstateen.mstateen2
      := mstateen2.rdata\n498:   permitMod.io.in.xstateen.mstateen3 := mstateen3.rdata\n\
      499:   permitMod.io.in.xstateen.hstateen0 := hstateen0.rdata\n500:   permitMod.io.in.xstateen.hstateen1
      := hstateen1.rdata\n501:   permitMod.io.in.xstateen.hstateen2 := hstateen2.rdata\n\
      502:   permitMod.io.in.xstateen.hstateen3 := hstateen3.rdata\n503:   permitMod.io.in.xstateen.sstateen0
      := sstateen0.rdata"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 503-518
    context: "503:   permitMod.io.in.xstateen.sstateen0 := sstateen0.rdata\n504: \n\
      505:   permitMod.io.in.xenvcfg.menvcfg := menvcfg.rdata\n506:   permitMod.io.in.xenvcfg.henvcfg
      := henvcfg.rdata\n507: \n508:   permitMod.io.in.status.mstatusFSOff  :=  mstatus.regOut.FS
      === ContextStatus.Off\n509:   permitMod.io.in.status.mstatusVSOff  :=  mstatus.regOut.VS
      === ContextStatus.Off\n510:   permitMod.io.in.status.vsstatusFSOff := vsstatus.regOut.FS
      === ContextStatus.Off\n511:   permitMod.io.in.status.vsstatusVSOff := vsstatus.regOut.VS
      === ContextStatus.Off\n512: \n513:   permitMod.io.in.aia.miselect := miselect.rdata\n\
      514:   permitMod.io.in.aia.siselect := siselect.rdata\n515:   permitMod.io.in.aia.vsiselect
      := vsiselect.rdata\n516:   permitMod.io.in.aia.mvienSEIE := mvien.regOut.SEIE.asBool\n\
      517:   permitMod.io.in.aia.hvictlVTI := hvictl.regOut.VTI.asBool\n518: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 528-548
    context: "528:   sstcIRGen.i.menvcfg.STCE  := menvcfg.regOut.STCE.asBool\n529:\
      \   sstcIRGen.i.henvcfg.wen   := GatedValidRegNext(henvcfg.w.wen)\n530:   sstcIRGen.i.henvcfg.STCE\
      \  := henvcfg.regOut.STCE.asBool\n531:   sstcIRGen.i.htimedeltaWen := GatedValidRegNext(htimedelta.w.wen)\n\
      532: \n533:   miregiprios.foreach { mod =>\n534:     mod.w.wen := mireg.w.wen
      && (miselect.regOut.ALL.asUInt === mod.addr.U)\n535:     mod.w.wdata := wdata\n\
      536:   }\n537: \n538:   siregiprios.foreach { mod =>\n539:     mod.w.wen :=
      sireg.w.wen && (siselect.regOut.ALL.asUInt === mod.addr.U)\n540:     mod.w.wdata
      := wdata\n541:   }\n542: \n543:   iregiprios.foreach { mod =>\n544:     mod
      match {\n545:       case m: HasIeBundle =>\n546:         m.mie := mie.regOut\n\
      547:         m.sie := sie.regOut\n548:       case _ =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 549-574
    context: "549:     }\n550:   }\n551: \n552:   mhartid.hartid := this.io.fromTop.hartId\n\
      553: \n554:   pmpcfgs.zipWithIndex.foreach { case (mod, i) =>\n555:     mod.w.wen\
      \   := wenLegalReg && (addr === (CSRs.pmpcfg0 + i / 8 * 2).U)\n556:     mod.w.wdata
      := pmpEntryMod.io.out.pmpCfgWData(8*((i%8)+1)-1,8*(i%8))\n557:   }\n558: \n\
      559:   pmpaddr.zipWithIndex.foreach { case (mod, i) =>\n560:     mod.w.wen \
      \  := wenLegalReg && (addr === (CSRs.pmpaddr0 + i).U)\n561:     mod.w.wdata
      := pmpEntryMod.io.out.pmpAddrWData(i)\n562:   }\n563: \n564:   pmacfgs.zipWithIndex.foreach
      { case (mod, i) =>\n565:     mod.w.wen   := wenLegalReg && (addr === (CSRConst.PmacfgBase
      + i / 8 * 2).U)\n566:     mod.w.wdata := pmaEntryMod.io.out.pmaCfgWdata(8*((i%8)+1)-1,8*(i%8))\n\
      567:   }\n568: \n569:   csrMods.foreach { mod =>\n570:     mod match {\n571:\
      \       case m: HypervisorBundle =>\n572:         m.hstatus := hstatus.regOut\n\
      573:       case _ =>\n574:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 597-614
    context: "597:       case _ =>\n598:     }\n599:     mod match {\n600:       case
      m: HasRobCommitBundle =>\n601:         // Todo: move RegNext from ROB to CSR\n\
      602:         m.robCommit.instNum := io.fromRob.commit.instNum\n603:        \
      \ m.robCommit.fflags  := RegNextWithEnable(io.fromRob.commit.fflags)\n604: \
      \        m.robCommit.fsDirty := GatedValidRegNext(io.fromRob.commit.fsDirty)\n\
      605:         m.robCommit.vsDirty := GatedValidRegNext(io.fromRob.commit.vsDirty)\n\
      606:         m.robCommit.vxsat   := RegNextWithEnable(io.fromRob.commit.vxsat)\n\
      607:         m.robCommit.vtype   := RegNextWithEnable(io.fromRob.commit.vtype)\n\
      608:         m.robCommit.vl      := RegNext          (io.fromRob.commit.vl)\n\
      609:         m.robCommit.vstart  := RegNextWithEnable(io.fromRob.commit.vstart)\n\
      610:         m.writeFCSR         := writeFpLegal\n611:         m.writeVCSR \
      \        := writeVecLegal\n612:         m.isVirtMode        := V.asUInt.asBool\n\
      613:       case _ =>\n614:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 697-709
    context: "697:         // cycle from mcycle\n698:         m.mHPM.cycle := mcycle.rdata\n\
      699:         // time from clint\n700:         m.mHPM.time  := io.fromTop.clintTime\n\
      701:         // instret from minstret\n702:         m.mHPM.instret := minstret.rdata\n\
      703:         // VS-Mode or VU-Mode\n704:         m.v := privState.isVirtual\n\
      705:         m.nextV := nextV.isOneOf(VirtMode.On)\n706:         m.htimedelta
      := htimedelta.rdata\n707:         m.mHPM.hpmcounters.zip(mhpmcounters).map{\n\
      708:           case(counter, mcounter) => counter := mcounter.rdata\n709:  \
      \       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 751-761
    context: "751:         m.ofVec := VecInit(mhpmevents.map{ event =>\n752:     \
      \      val mhpmevent = Wire(new MhpmeventBundle)\n753:           mhpmevent :=
      event.rdata\n754:           mhpmevent.OF.asBool\n755:         }).asUInt\n756:\
      \         m.privState := privState\n757:         m.mcounteren := mcounteren.rdata\n\
      758:         m.hcounteren := hcounteren.rdata\n759:       case _ =>\n760:  \
      \   }\n761:     mod match {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 758-773
    context: "758:         m.hcounteren := hcounteren.rdata\n759:       case _ =>\n\
      760:     }\n761:     mod match {\n762:       case m: HasStateenBundle =>\n763:\
      \         m.fromMstateen0 := mstateen0.regOut\n764:         m.fromMstateen1
      := mstateen1.regOut\n765:         m.fromMstateen2 := mstateen2.regOut\n766:\
      \         m.fromMstateen3 := mstateen3.regOut\n767:         m.fromHstateen0
      := hstateen0.regOut\n768:         m.privState     := privState\n769:       case
      _ =>\n770:     }\n771:     mod match {\n772:       case m: HasDebugStopBundle
      =>\n773:         m.debugModeStopCount := debugModeStopCount"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 780-795
    context: "780:         m.nmip := nmip.asUInt.orR\n781:       case _ =>\n782: \
      \    }\n783:     mod match {\n784:       case m: HasMachineFlushL2Bundle =>\n\
      785:         m.l2FlushDone := io.fromTop.l2FlushDone\n786:       case _ =>\n\
      787:     }\n788:   }\n789: \n790:   csrMods.foreach { mod =>\n791:     println(s\"\
      ${mod.modName}: \")\n792:     println(mod.dumpFields)\n793:   }\n794: \n795:\
      \   trapEntryMNEvent.valid  := ((hasTrap && nmi) || dbltrpToMN) && !entryDebugMode
      && !debugMode && mnstatus.regOut.NMIE"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 795-805
    context: "795:   trapEntryMNEvent.valid  := ((hasTrap && nmi) || dbltrpToMN) &&
      !entryDebugMode && !debugMode && mnstatus.regOut.NMIE\n796:   trapEntryMEvent
      .valid  := hasTrap && entryPrivState.isModeM && !dbltrpToMN && !entryDebugMode
      && !debugMode && !nmi && mnstatus.regOut.NMIE\n797:   trapEntryHSEvent.valid\
      \  := hasTrap && entryPrivState.isModeHS && !entryDebugMode && !debugMode &&
      mnstatus.regOut.NMIE\n798:   trapEntryVSEvent.valid  := hasTrap && entryPrivState.isModeVS
      && !entryDebugMode && !debugMode && mnstatus.regOut.NMIE\n799: \n800:   Seq(trapEntryMEvent,
      trapEntryMNEvent, trapEntryHSEvent, trapEntryVSEvent, trapEntryDEvent).foreach
      { eMod =>\n801:     eMod.in match {\n802:       case in: TrapEntryEventInput
      =>\n803:         in.causeNO := trapHandleMod.io.out.causeNO\n804:         in.trapPc
      := trapPC\n805:         in.trapPcGPA := trapPCGPA // only used by trapEntryMEvent
      & trapEntryHSEvent"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 802-812
    context: "802:       case in: TrapEntryEventInput =>\n803:         in.causeNO
      := trapHandleMod.io.out.causeNO\n804:         in.trapPc := trapPC\n805:    \
      \     in.trapPcGPA := trapPCGPA // only used by trapEntryMEvent & trapEntryHSEvent\n\
      806:         in.trapInst := io.trapInst\n807:         in.fetchMalTval := io.fetchMalTval\n\
      808:         in.isCrossPageIPF := trapIsCrossPageIPF\n809:         in.isHls
      := trapIsHls\n810:         in.isFetchMalAddr := trapIsFetchMalAddr\n811:   \
      \      in.isFetchBkpt := trapIsFetchBkpt\n812:         in.trapIsForVSnonLeafPTE
      := trapIsForVSnonLeafPTE"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 813-829
    context: "813:         in.hasDTExcp := hasDTExcp\n814: \n815:         in.iMode.PRVM
      := PRVM\n816:         in.iMode.V := V\n817:         // when NMIE is zero, force
      to behave as MPRV is zero\n818:         in.dMode.PRVM := Mux(mstatus.regOut.MPRV.asBool
      && mnstatus.regOut.NMIE.asBool, mstatus.regOut.MPP, PRVM)\n819:         in.dMode.V
      := V.asUInt.asBool || mstatus.regOut.MPRV && mnstatus.regOut.NMIE.asBool &&
      (mstatus.regOut.MPP =/= PrivMode.M) && mstatus.regOut.MPV\n820: \n821:     \
      \    in.privState := privState\n822:         in.mstatus := mstatus.regOut\n\
      823:         in.hstatus := hstatus.regOut\n824:         in.sstatus := mstatus.sstatus\n\
      825:         in.vsstatus := vsstatus.regOut\n826:         in.pcFromXtvec :=
      trapHandleMod.io.out.pcFromXtvec\n827: \n828:         in.menvcfg := menvcfg.regOut\n\
      829:         in.henvcfg := henvcfg.regOut"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 847-857
    context: "847:   }\n848: \n849:   mnretEvent.valid := legalMNret\n850:   mnretEvent.in
      match {\n851:     case in =>\n852:       in.mstatus := mstatus.regOut\n853:\
      \       in.vsstatus := vsstatus.regOut\n854:       in.mnepc   := mnepc.regOut\n\
      855:       in.mnstatus:= mnstatus.regOut\n856:       in.satp := satp.regOut\n\
      857:       in.vsatp := vsatp.regOut"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 859-869
    context: "859:   }\n860: \n861:   mretEvent.valid := legalMret\n862:   mretEvent.in
      match {\n863:     case in =>\n864:       in.mstatus := mstatus.regOut\n865:\
      \       in.vsstatus := vsstatus.regOut\n866:       in.mepc := mepc.regOut\n\
      867:       in.satp := satp.regOut\n868:       in.vsatp := vsatp.regOut\n869:\
      \       in.hgatp := hgatp.regOut"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 870-881
    context: "870:   }\n871: \n872:   sretEvent.valid := legalSret\n873:   sretEvent.in
      match {\n874:     case in =>\n875:       in.privState := privState\n876:   \
      \    in.mstatus := mstatus.regOut\n877:       in.hstatus := hstatus.regOut\n\
      878:       in.vsstatus := vsstatus.regOut\n879:       in.sepc := sepc.regOut\n\
      880:       in.vsepc := vsepc.regOut\n881:       in.satp := satp.regOut"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 886-896
    context: "886:   dretEvent.valid := legalDret\n887:   dretEvent.in match {\n888:\
      \     case in =>\n889:       in.dcsr := dcsr.regOut\n890:       in.dpc  := dpc.regOut\n\
      891:       in.mstatus := mstatus.regOut\n892:       in.vsstatus := vsstatus.regOut\n\
      893:       in.satp := satp.regOut\n894:       in.vsatp := vsatp.regOut\n895:\
      \       in.hgatp := hgatp.regOut\n896:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 897-907
    context: "897: \n898:   PRVM := MuxCase(\n899:     PRVM,\n900:     events.filter(_.out.isInstanceOf[EventUpdatePrivStateOutput]).map
      {\n901:       x => x.out match {\n902:         case xx: EventUpdatePrivStateOutput
      => (xx.privState.valid -> xx.privState.bits.PRVM)\n903:       }\n904:     }\n\
      905:   )\n906: \n907:   nextV := MuxCase("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 906-916
    context: "906: \n907:   nextV := MuxCase(\n908:     V,\n909:     events.filter(_.out.isInstanceOf[EventUpdatePrivStateOutput]).map
      {\n910:       x => x.out match {\n911:         case xx: EventUpdatePrivStateOutput
      => (xx.privState.valid -> xx.privState.bits.V)\n912:       }\n913:     }\n914:\
      \   )\n915: \n916:   debugMode := MuxCase("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 941-961
    context: "941:   )\n942: \n943:   val resetSatp = WireInit(false.B)\n944:   //
      flush\n945:   if (HasBitmapCheck) {\n946:     resetSatp := Cat(Seq(satp, vsatp,
      hgatp, mbmc.get).map(_.addr.U === addr)).orR && wenLegalReg // write to satp
      will cause the pipeline be flushed\n947:   } else {\n948:     resetSatp := Cat(Seq(satp,
      vsatp, hgatp).map(_.addr.U === addr)).orR && wenLegalReg // write to satp will
      cause the pipeline be flushed\n949:   }\n950: \n951:   val floatStatusOnOff
      = mstatus.w.wen && (\n952:     mstatus.w.wdataFields.FS === ContextStatus.Off
      && mstatus.regOut.FS =/= ContextStatus.Off ||\n953:     mstatus.w.wdataFields.FS
      =/= ContextStatus.Off && mstatus.regOut.FS === ContextStatus.Off\n954:   ) ||
      mstatus.wAliasSstatus.wen && (\n955:     mstatus.wAliasSstatus.wdataFields.FS
      === ContextStatus.Off && mstatus.regOut.FS =/= ContextStatus.Off ||\n956:  \
      \   mstatus.wAliasSstatus.wdataFields.FS =/= ContextStatus.Off && mstatus.regOut.FS
      === ContextStatus.Off\n957:   ) || vsstatus.w.wen && (\n958:     vsstatus.w.wdataFields.FS
      === ContextStatus.Off && vsstatus.regOut.FS =/= ContextStatus.Off ||\n959: \
      \    vsstatus.w.wdataFields.FS =/= ContextStatus.Off && vsstatus.regOut.FS ===
      ContextStatus.Off\n960:   )\n961: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 957-972
    context: "957:   ) || vsstatus.w.wen && (\n958:     vsstatus.w.wdataFields.FS
      === ContextStatus.Off && vsstatus.regOut.FS =/= ContextStatus.Off ||\n959: \
      \    vsstatus.w.wdataFields.FS =/= ContextStatus.Off && vsstatus.regOut.FS ===
      ContextStatus.Off\n960:   )\n961: \n962:   val vectorStatusOnOff = mstatus.w.wen
      && (\n963:     mstatus.w.wdataFields.VS === ContextStatus.Off && mstatus.regOut.VS
      =/= ContextStatus.Off ||\n964:     mstatus.w.wdataFields.VS =/= ContextStatus.Off
      && mstatus.regOut.VS === ContextStatus.Off\n965:   ) || mstatus.wAliasSstatus.wen
      && (\n966:     mstatus.wAliasSstatus.wdataFields.VS === ContextStatus.Off &&
      mstatus.regOut.VS =/= ContextStatus.Off ||\n967:     mstatus.wAliasSstatus.wdataFields.VS
      =/= ContextStatus.Off && mstatus.regOut.VS === ContextStatus.Off\n968:   ) ||
      vsstatus.w.wen && (\n969:     vsstatus.w.wdataFields.VS === ContextStatus.Off
      && vsstatus.regOut.VS =/= ContextStatus.Off ||\n970:     vsstatus.w.wdataFields.VS
      =/= ContextStatus.Off && vsstatus.regOut.VS === ContextStatus.Off\n971:   )\n\
      972: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 982-992
    context: "982:   val frmWdataReserved = fcsr.wAliasFfm.wdata(2) && fcsr.wAliasFfm.wdata(1,
      0).orR\n983:   val fcsrWdataReserved = fcsr.w.wdata(7) && fcsr.w.wdata(6, 5).orR\n\
      984:   val frmChange = fcsr.wAliasFfm.wen && (!frmIsReserved && frmWdataReserved
      || frmIsReserved && !frmWdataReserved) ||\n985:     fcsr.w.wen && (!frmIsReserved
      && fcsrWdataReserved || frmIsReserved && !fcsrWdataReserved)\n986: \n987:  \
      \ val flushPipe = resetSatp ||\n988:     triggerFrontendChange || floatStatusOnOff
      || vectorStatusOnOff ||\n989:     vstartChange || frmChange\n990: \n991:   /**\n\
      992:    * Look up id in vsMapS and sMapVS."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1028-1041
    context: "1028:   private val noCSRIllegalReg = RegEnable(noCSRIllegal, ren ||
      wen)\n1029: \n1030:   private val s_idle :: s_waitIMSIC :: s_finish :: Nil =
      Enum(3)\n1031: \n1032:   /** the state machine of newCSR module */\n1033:  \
      \ private val state = RegInit(s_idle)\n1034:   /** the next state of newCSR
      */\n1035:   private val stateNext = WireInit(state)\n1036:   state := stateNext\n\
      1037: \n1038:   /**\n1039:    * Asynchronous access operation of CSR. Check
      whether an access is asynchronous when read/write-enable is high.\n1040:   \
      \ * AIA registers are designed to be access asynchronously, so newCSR will wait
      for response.\n1041:    **/"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1038-1048
    context: "1038:   /**\n1039:    * Asynchronous access operation of CSR. Check
      whether an access is asynchronous when read/write-enable is high.\n1040:   \
      \ * AIA registers are designed to be access asynchronously, so newCSR will wait
      for response.\n1041:    **/\n1042:   private val asyncAccess = (wen || ren)
      && !(permitMod.io.out.EX_II || permitMod.io.out.EX_VI) && (\n1043:     mireg.addr.U
      === addr && miselect.inIMSICRange ||\n1044:     sireg.addr.U === addr && ((!V.asUInt.asBool
      && siselect.inIMSICRange) || (V.asUInt.asBool && vsiselect.inIMSICRange)) ||\n\
      1045:     vsireg.addr.U === addr && vsiselect.inIMSICRange\n1046:   )\n1047:\
      \ \n1048:   /** State machine of newCSR */"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1044-1077
    context: "1044:     sireg.addr.U === addr && ((!V.asUInt.asBool && siselect.inIMSICRange)
      || (V.asUInt.asBool && vsiselect.inIMSICRange)) ||\n1045:     vsireg.addr.U
      === addr && vsiselect.inIMSICRange\n1046:   )\n1047: \n1048:   /** State machine
      of newCSR */\n1049:   switch(state) {\n1050:     is(s_idle) {\n1051:       when(valid
      && redirectFlush) {\n1052:         stateNext := s_idle\n1053:       }.elsewhen(valid
      && asyncAccess) {\n1054:         stateNext := s_waitIMSIC\n1055:       }.elsewhen(valid)
      {\n1056:         stateNext := s_finish\n1057:       }\n1058:     }\n1059:  \
      \   is(s_waitIMSIC) {\n1060:       when(redirectFlush) {\n1061:         stateNext
      := s_idle\n1062:       }.elsewhen(fromAIA.rdata.valid) {\n1063:         when(io.out.ready)
      {\n1064:           stateNext := s_idle\n1065:         }.otherwise {\n1066: \
      \          stateNext := s_finish\n1067:         }\n1068:       }\n1069:    \
      \ }\n1070:     is(s_finish) {\n1071:       when(redirectFlush || io.out.ready)
      {\n1072:         stateNext := s_idle\n1073:       }\n1074:     }\n1075:   }\n\
      1076: \n1077: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1079-1089
    context: "1079:   private val imsicIllegal = fromAIA.rdata.valid && fromAIA.rdata.bits.illegal\n\
      1080:   private val imsic_EX_II = imsicIllegal && !V.asUInt.asBool\n1081:  \
      \ private val imsic_EX_VI = imsicIllegal && V.asUInt.asBool\n1082: \n1083: \
      \  /** Set io.in.ready when state machine is ready to receive a new request
      synchronously */\n1084:   io.in.ready := (state === s_idle)\n1085: \n1086: \
      \  /**\n1087:    * Valid signal of newCSR output.\n1088:    * When in IDLE state,
      when input_valid is high, we set it.\n1089:    * When in waitIMSIC state, and
      the next state is IDLE, we set it."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1088-1102
    context: "1088:    * When in IDLE state, when input_valid is high, we set it.\n\
      1089:    * When in waitIMSIC state, and the next state is IDLE, we set it.\n\
      1090:    **/\n1091: \n1092:   /** Data that have been read before,and should
      be stored because output not fired */\n1093:   val normalCSRValid = state ===
      s_idle && valid && !asyncAccess\n1094:   val waitIMSICValid = state === s_waitIMSIC
      && fromAIA.rdata.valid\n1095:   val claimAIA = mtopei.w.wen | stopei.w.wen |
      vstopei.w.wen\n1096: \n1097:   io.out.valid := (waitIMSICValid || state ===
      s_finish) && !redirectFlush\n1098:   io.out.bits.EX_II := DataHoldBypass(Mux1H(Seq(\n\
      1099:     normalCSRValid -> (permitMod.io.out.EX_II || noCSRIllegal),\n1100:\
      \     waitIMSICValid -> imsic_EX_II,\n1101:   )), false.B, normalCSRValid ||
      waitIMSICValid)\n1102:   io.out.bits.EX_VI := DataHoldBypass(Mux1H(Seq("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1101-1118
    context: "1101:   )), false.B, normalCSRValid || waitIMSICValid)\n1102:   io.out.bits.EX_VI
      := DataHoldBypass(Mux1H(Seq(\n1103:     normalCSRValid -> permitMod.io.out.EX_VI,\n\
      1104:     waitIMSICValid -> imsic_EX_VI,\n1105:   )), false.B, normalCSRValid
      || waitIMSICValid)\n1106:   io.out.bits.flushPipe := flushPipe\n1107: \n1108:\
      \   /** Prepare read data for output */\n1109:   io.out.bits.rData := DataHoldBypass(\n\
      1110:     Mux1H(Seq(\n1111:       (io.in.fire || claimAIA) -> rdata,\n1112:\
      \       fromAIA.rdata.valid -> fromAIA.rdata.bits.data\n1113:     )), 0.U(64.W),
      io.in.fire || fromAIA.rdata.valid || claimAIA)\n1114:   io.out.bits.regOut :=
      regOut\n1115:   io.out.bits.targetPc := DataHoldBypass(\n1116:     Mux(trapEntryDEvent.out.targetPc.valid,\n\
      1117:       trapEntryDEvent.out.targetPc.bits,\n1118:       Mux1H(Seq("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1126-1140
    context: "1126:         trapEntryVSEvent.out.targetPc.valid -> trapEntryVSEvent.out.targetPc.bits)\n\
      1127:       )\n1128:     ),\n1129:   needTargetUpdate)\n1130:   io.out.bits.targetPcUpdate
      := needTargetUpdate\n1131:   io.out.bits.isPerfCnt := DataHoldBypass(addrInPerfCnt,
      false.B, io.in.fire)\n1132: \n1133:   io.status.privState := privState\n1134:\
      \   io.status.fpState.frm := fcsr.frm\n1135:   io.status.fpState.off := mstatus.regOut.FS
      === ContextStatus.Off\n1136:   io.status.vecState.vstart := vstart.rdata.asUInt\n\
      1137:   io.status.vecState.vxsat := vcsr.vxsat\n1138:   io.status.vecState.vxrm
      := vcsr.vxrm\n1139:   io.status.vecState.vcsr := vcsr.rdata.asUInt\n1140:  \
      \ io.status.vecState.vl := vl.rdata.asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1136-1148
    context: "1136:   io.status.vecState.vstart := vstart.rdata.asUInt\n1137:   io.status.vecState.vxsat
      := vcsr.vxsat\n1138:   io.status.vecState.vxrm := vcsr.vxrm\n1139:   io.status.vecState.vcsr
      := vcsr.rdata.asUInt\n1140:   io.status.vecState.vl := vl.rdata.asUInt\n1141:\
      \   io.status.vecState.vtype := vtype.rdata.asUInt // Todo: check correct\n\
      1142:   io.status.vecState.vlenb := vlenb.rdata.asUInt\n1143:   io.status.vecState.off
      := mstatus.regOut.VS === ContextStatus.Off\n1144:   io.status.interrupt := intrMod.io.out.interruptVec.valid\n\
      1145:   io.status.wfiEvent := debugIntr || (mie.rdata.asUInt & mip.rdata.asUInt).orR
      || nmip.asUInt.orR\n1146:   io.status.debugMode := debugMode\n1147:   io.status.singleStepFlag
      := !debugMode && dcsr.regOut.STEP\n1148: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1159-1171
    context: "1159:     val tdata1Wire = Wire(new Tdata1Bundle)\n1160:     tdata1Wire
      := mod.rdata\n1161:     tdata1Wire\n1162:   }}\n1163: \n1164:   val triggerCanRaiseBpExp
      = !(privState.isModeM && !mstatus.regOut.MIE ||\n1165:     medeleg.regOut.EX_BP
      && privState.isModeHS && !mstatus.sstatus.SIE ||\n1166:     medeleg.regOut.EX_BP
      && hedeleg.regOut.EX_BP && privState.isModeVS && !vsstatus.regOut.SIE)\n1167:\
      \ \n1168:   val debugMod = Module(new Debug)\n1169:   debugMod.io.in.trapInfo.valid\
      \            := hasTrap\n1170:   debugMod.io.in.trapInfo.bits.trapVec     :=
      trapVec.asUInt\n1171:   debugMod.io.in.trapInfo.bits.isDebugIntr := debug"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1171-1181
    context: "1171:   debugMod.io.in.trapInfo.bits.isDebugIntr := debug\n1172:   debugMod.io.in.trapInfo.bits.isInterrupt
      := trapIsInterrupt\n1173:   debugMod.io.in.trapInfo.bits.trigger     := trigger\n\
      1174:   debugMod.io.in.trapInfo.bits.singleStep  := singleStep\n1175:   debugMod.io.in.trapInfo.bits.criticalErrorState
      := criticalErrorState\n1176:   debugMod.io.in.privState                 := privState\n\
      1177:   debugMod.io.in.debugMode                 := debugMode\n1178:   debugMod.io.in.dcsr\
      \                      := dcsr.regOut\n1179:   debugMod.io.in.tselect      \
      \             := tselect.regOut\n1180:   debugMod.io.in.tdata1Vec          \
      \       := tdata1Vec\n1181:   debugMod.io.in.tdata1Selected            := tdata1.rdata"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1232-1242
    context: "1232: \n1233:   // trace\n1234:   val privForTrace = Mux(debugMode,\n\
      1235:     Priv.D,\n1236:     Mux1H(\n1237:       Seq(privState.isModeM, privState.isModeHS,
      privState.isModeVS, privState.isModeHU, privState.isModeVU),\n1238:       Seq(Priv.M,\
      \            Priv.HS,            Priv.VS,            Priv.HU,            Priv.VU)\n\
      1239:     )\n1240:   )\n1241:   val xret = legalDret || legalMNret || legalMret
      || legalSret\n1242:   val currentPriv = privForTrace"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1243-1257
    context: "1243:   val lastPriv = RegEnable(privForTrace, Priv.M, (xret || io.fromRob.trap.valid))\n\
      1244: \n1245:   io.status.traceCSR.lastPriv       := lastPriv\n1246:   io.status.traceCSR.currentPriv\
      \    := privForTrace\n1247:   io.status.traceCSR.cause := Mux1H(\n1248:    \
      \ Seq(privState.isModeM, privState.isModeHS, privState.isModeVS),\n1249:   \
      \  Seq(mcause.rdata,      scause.rdata,       vscause.rdata)\n1250:   )\n1251:\
      \   io.status.traceCSR.tval  := Mux1H(\n1252:     Seq(privState.isModeM, privState.isModeHS,
      privState.isModeVS),\n1253:     Seq(mtval.rdata,       stval.rdata,        vstval.rdata)\n\
      1254:   )\n1255:   \n1256:   /**\n1257:    * perf_begin"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1291-1305
    context: "1291:     \n1292:     val mhpmevent = Wire(new MhpmeventBundle)\n1293:\
      \     mhpmevent := mhpmevents(i).rdata\n1294:     lcofiReqVec(i) := ofFromPerfCntVec(i)
      && !mhpmevent.OF.asBool\n1295: \n1296:     countingEn(i) := (privState.isModeM
      && !mhpmevent.MINH) ||\n1297:       (privState.isModeHS && !mhpmevent.SINH)\
      \  ||\n1298:       (privState.isModeHU && !mhpmevent.UINH)  ||\n1299:      \
      \ (privState.isModeVS && !mhpmevent.VSINH) ||\n1300:       (privState.isModeVU
      && !mhpmevent.VUINH)\n1301:   }\n1302: \n1303:   val lcofiReq = lcofiReqVec.asUInt.orR\n\
      1304:   mip match {\n1305:     case m: HasLocalInterruptReqBundle =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1353-1373
    context: "1353:   io.status.custom.fusion_enable           := srnctl.regOut.FUSION_ENABLE.asBool\n\
      1354:   io.status.custom.wfi_enable              := srnctl.regOut.WFI_ENABLE.asBool
      && (!io.status.singleStepFlag) && !debugMode\n1355: \n1356:   io.status.custom.power_down_enable
      := mcorepwr.regOut.POWER_DOWN_ENABLE.asBool\n1357: \n1358:   io.status.custom.flush_l2_enable
      := mflushpwr.regOut.FLUSH_L2_ENABLE.asBool\n1359: \n1360:   io.status.instrAddrTransType.bare
      := privState.isModeM ||\n1361:     (!privState.isVirtual && satp.regOut.MODE
      === SatpMode.Bare) ||\n1362:     (privState.isVirtual && vsatp.regOut.MODE ===
      SatpMode.Bare && hgatp.regOut.MODE === HgatpMode.Bare)\n1363:   io.status.instrAddrTransType.sv39
      := !privState.isModeM && !privState.isVirtual && satp.regOut.MODE === SatpMode.Sv39
      ||\n1364:     privState.isVirtual && vsatp.regOut.MODE === SatpMode.Sv39\n1365:\
      \   io.status.instrAddrTransType.sv48 := !privState.isModeM && !privState.isVirtual
      && satp.regOut.MODE === SatpMode.Sv48 ||\n1366:     privState.isVirtual && vsatp.regOut.MODE
      === SatpMode.Sv48\n1367:   io.status.instrAddrTransType.sv39x4 := privState.isVirtual
      && vsatp.regOut.MODE === SatpMode.Bare && hgatp.regOut.MODE === HgatpMode.Sv39x4\n\
      1368:   io.status.instrAddrTransType.sv48x4 := privState.isVirtual && vsatp.regOut.MODE
      === SatpMode.Bare && hgatp.regOut.MODE === HgatpMode.Sv48x4\n1369:   assert(PopCount(io.status.instrAddrTransType.asUInt)
      === 1.U, \"Exactly one inst trans type should be asserted\")\n1370: \n1371:\
      \   private val csrAccess = wenLegalReg || RegNext(ren)\n1372: \n1373:   private
      val imsicAddrValid ="
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1369-1384
    context: "1369:   assert(PopCount(io.status.instrAddrTransType.asUInt) === 1.U,
      \"Exactly one inst trans type should be asserted\")\n1370: \n1371:   private
      val csrAccess = wenLegalReg || RegNext(ren)\n1372: \n1373:   private val imsicAddrValid
      =\n1374:     csrAccess &&  addr === CSRs.mireg.U &&  miselect.inIMSICRange ||\n\
      1375:     csrAccess &&  addr === CSRs.sireg.U && !isModeVS && siselect.inIMSICRange
      ||\n1376:     csrAccess && (addr === CSRs.sireg.U &&  isModeVS || addr === CSRs.vsireg.U)
      && vsiselect.inIMSICRange\n1377: \n1378:   private val imsicAddr = Mux1H(Seq(\n\
      1379:     (csrAccess &&  addr === CSRs.mireg.U) -> miselect.rdata,\n1380:  \
      \   (csrAccess &&  addr === CSRs.sireg.U && !isModeVS) -> siselect.rdata,\n\
      1381:     (csrAccess && (addr === CSRs.sireg.U &&  isModeVS || addr === CSRs.vsireg.U))
      -> vsiselect.rdata,\n1382:   ))\n1383: \n1384:   private val imsicAddrPrivState
      = Mux1H(Seq("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1380-1396
    context: "1380:     (csrAccess &&  addr === CSRs.sireg.U && !isModeVS) -> siselect.rdata,\n\
      1381:     (csrAccess && (addr === CSRs.sireg.U &&  isModeVS || addr === CSRs.vsireg.U))
      -> vsiselect.rdata,\n1382:   ))\n1383: \n1384:   private val imsicAddrPrivState
      = Mux1H(Seq(\n1385:     (csrAccess &&  addr === CSRs.mireg.U) -> PrivState.ModeM,\n\
      1386:     (csrAccess &&  addr === CSRs.sireg.U && !isModeVS) -> PrivState.ModeHS,\n\
      1387:     (csrAccess && (addr === CSRs.sireg.U &&  isModeVS || addr === CSRs.vsireg.U))
      -> PrivState.ModeVS,\n1388:   ))\n1389: \n1390:   private val imsicWdataValid
      =\n1391:     mireg.w.wen  && miselect.inIMSICRange ||\n1392:     sireg.w.wen\
      \  && siselect.inIMSICRange ||\n1393:     vsireg.w.wen && vsiselect.inIMSICRange\n\
      1394: \n1395:   toAIA.addr.valid     := imsicAddrValid\n1396:   toAIA.addr.bits.addr
      := imsicAddr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1415-1426
    context: "1415:   if (HasBitmapCheck) {\n1416:     io.tlb.mbmc := mbmc.get.rdata\n\
      1417:   } else {\n1418:     io.tlb.mbmc := DontCare\n1419:   }\n1420:   io.tlb.mxr\
      \  :=  mstatus.regOut.MXR.asBool\n1421:   io.tlb.sum  :=  mstatus.regOut.SUM.asBool\n\
      1422:   io.tlb.vmxr := vsstatus.regOut.MXR.asBool\n1423:   io.tlb.vsum := vsstatus.regOut.SUM.asBool\n\
      1424:   io.tlb.spvp :=  hstatus.regOut.SPVP.asBool\n1425: \n1426:   io.tlb.imode
      := PRVM.asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1424-1440
    context: "1424:   io.tlb.spvp :=  hstatus.regOut.SPVP.asBool\n1425: \n1426:  \
      \ io.tlb.imode := PRVM.asUInt\n1427:   // when NMIE is zero, force to behave
      as MPRV is zero\n1428:   io.tlb.dmode := Mux(\n1429:     (debugMode && dcsr.regOut.MPRVEN
      || !debugMode) && mstatus.regOut.MPRV && mnstatus.regOut.NMIE,\n1430:     mstatus.regOut.MPP.asUInt,\n\
      1431:     PRVM.asUInt\n1432:   )\n1433:   io.tlb.dvirt := Mux(\n1434:     (debugMode
      && dcsr.regOut.MPRVEN || !debugMode) && mstatus.regOut.MPRV && mnstatus.regOut.NMIE
      && mstatus.regOut.MPP =/= PrivMode.M,\n1435:     mstatus.regOut.MPV.asUInt,\n\
      1436:     V.asUInt\n1437:   )\n1438:   io.tlb.mPBMTE := RegNext(menvcfg.regOut.PBMTE.asBool)\n\
      1439:   io.tlb.hPBMTE := RegNext(henvcfg.regOut.PBMTE.asBool)\n1440:   io.tlb.pmm.mseccfg
      := RegNext(mseccfg.regOut.PMM.asUInt)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1441-1465
    context: "1441:   io.tlb.pmm.menvcfg := RegNext(menvcfg.regOut.PMM.asUInt)\n1442:\
      \   io.tlb.pmm.henvcfg := RegNext(henvcfg.regOut.PMM.asUInt)\n1443:   io.tlb.pmm.hstatus
      := RegNext(hstatus.regOut.HUPMM.asUInt)\n1444:   io.tlb.pmm.senvcfg := RegNext(senvcfg.regOut.PMM.asUInt)\n\
      1445: \n1446:   io.toDecode.illegalInst.sfenceVMA  := isModeHS && mstatus.regOut.TVM\
      \  || isModeHU\n1447:   io.toDecode.virtualInst.sfenceVMA  := isModeVS && hstatus.regOut.VTVM
      || isModeVU\n1448:   io.toDecode.illegalInst.sfencePart := isModeHU\n1449: \
      \  io.toDecode.virtualInst.sfencePart := isModeVU\n1450:   io.toDecode.illegalInst.hfenceGVMA
      := isModeHS && mstatus.regOut.TVM || isModeHU\n1451:   io.toDecode.illegalInst.hfenceVVMA
      := isModeHU\n1452:   io.toDecode.virtualInst.hfence     := isModeVS || isModeVU\n\
      1453:   io.toDecode.illegalInst.hlsv       := isModeHU && !hstatus.regOut.HU\n\
      1454:   io.toDecode.virtualInst.hlsv       := isModeVS || isModeVU\n1455:  \
      \ io.toDecode.illegalInst.fsIsOff    := mstatus.regOut.FS === ContextStatus.Off
      || (isModeVS || isModeVU) && vsstatus.regOut.FS === ContextStatus.Off\n1456:\
      \   io.toDecode.illegalInst.vsIsOff    := mstatus.regOut.VS === ContextStatus.Off
      || (isModeVS || isModeVU) && vsstatus.regOut.VS === ContextStatus.Off\n1457:\
      \   io.toDecode.illegalInst.wfi        := isModeHU || !isModeM && mstatus.regOut.TW\n\
      1458:   io.toDecode.virtualInst.wfi        := isModeVS && !mstatus.regOut.TW
      && hstatus.regOut.VTW || isModeVU && !mstatus.regOut.TW\n1459:   io.toDecode.illegalInst.wrs_nto\
      \    := !isModeM && mstatus.regOut.TW\n1460:   io.toDecode.virtualInst.wrs_nto\
      \    := privState.V && !mstatus.regOut.TW && hstatus.regOut.VTW\n1461:   io.toDecode.illegalInst.frm\
      \        := frmIsReserved\n1462:   // Ref: The RISC-V Instruction Set Manual
      Volume I - 20.5. Control and Status Register State\n1463:   io.toDecode.illegalInst.cboZ\
      \       := !isModeM && !menvcfg.regOut.CBZE || isModeHU && !senvcfg.regOut.CBZE\n\
      1464:   io.toDecode.virtualInst.cboZ       := menvcfg.regOut.CBZE && (\n1465:\
      \     isModeVS && !henvcfg.regOut.CBZE ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1476-1488
    context: "1476:   io.toDecode.virtualInst.cboI       := menvcfg.regOut.CBIE =/=
      EnvCBIE.Off && (\n1477:     isModeVS && henvcfg.regOut.CBIE === EnvCBIE.Off
      ||\n1478:     isModeVU &&(henvcfg.regOut.CBIE === EnvCBIE.Off || senvcfg.regOut.CBIE
      === EnvCBIE.Off)\n1479:   )\n1480:   io.toDecode.special.cboI2F := !io.toDecode.illegalInst.cboI
      && !io.toDecode.virtualInst.cboI && (\n1481:     menvcfg.regOut.CBIE === EnvCBIE.Flush
      && !isModeM ||\n1482:     senvcfg.regOut.CBIE === EnvCBIE.Flush && (isModeHU
      || isModeVU) ||\n1483:     henvcfg.regOut.CBIE === EnvCBIE.Flush && (isModeVS
      || isModeVU)\n1484:   )\n1485: \n1486:   io.distributedWenLegal := wenLegalReg
      && !noCSRIllegalReg\n1487:   io.status.criticalErrorState := criticalErrorState
      && !dcsr.regOut.CETRIG.asBool\n1488: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1501-1511
    context: "1501:     }.elsewhen (!io.fromVecExcpMod.busy) {\n1502:       pendingTrap
      := false.B\n1503:     }\n1504: \n1505:     val hartId = io.fromTop.hartId\n\
      1506:     val trapValid = pendingTrap && !io.fromVecExcpMod.busy\n1507:    \
      \ val trapNO = Mux(virtualInterruptIsHvictlInject && hasTrap, hvictl.regOut.IID.asUInt,
      trapHandleMod.io.out.causeNO.ExceptionCode.asUInt)\n1508:     val interrupt
      = trapHandleMod.io.out.causeNO.Interrupt.asBool\n1509:     val hasNMI = nmi
      && hasTrap\n1510:     val interruptNO = Mux(interrupt, trapNO, 0.U)\n1511: \
      \    val exceptionNO = Mux(!interrupt, trapNO, 0.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1526-1536
    context: "1526:       isBare -> barePC,\n1527:     ))\n1528: \n1529:     val diffArchEvent
      = DifftestModule(new DiffArchEvent, delay = 3, dontCare = true)\n1530:     diffArchEvent.coreid
      := hartId\n1531:     diffArchEvent.valid := trapValid\n1532:     diffArchEvent.interrupt
      := RegEnable(interruptNO, hasTrap)\n1533:     diffArchEvent.exception := RegEnable(exceptionNO,
      hasTrap)\n1534:     diffArchEvent.exceptionPC := RegEnable(exceptionPC, hasTrap)\n\
      1535:     diffArchEvent.hasNMI := RegEnable(hasNMI, hasTrap)\n1536:     diffArchEvent.virtualInterruptIsHvictlInject
      := RegNext(virtualInterruptIsHvictlInject && hasTrap)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1539-1549
    context: "1539:     if (env.EnableDifftest) {\n1540:       diffArchEvent.exceptionInst
      := RegEnable(io.fromRob.trap.bits.instr, hasTrap)\n1541:     }\n1542: \n1543:\
      \     val diffCriticalErrorEvent = DifftestModule(new DiffCriticalErrorEvent,
      delay = 4, dontCare = true)\n1544:     diffCriticalErrorEvent.valid := io.status.criticalErrorState
      && trapValid\n1545:     diffCriticalErrorEvent.coreid := hartId\n1546:     diffCriticalErrorEvent.criticalError
      := io.status.criticalErrorState\n1547: \n1548:     val diffCSRState = DifftestModule(new
      DiffCSRState)\n1549:     diffCSRState.coreid         := hartId"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1545-1557
    context: "1545:     diffCriticalErrorEvent.coreid := hartId\n1546:     diffCriticalErrorEvent.criticalError
      := io.status.criticalErrorState\n1547: \n1548:     val diffCSRState = DifftestModule(new
      DiffCSRState)\n1549:     diffCSRState.coreid         := hartId\n1550:     diffCSRState.privilegeMode\
      \  := privState.PRVM.asUInt\n1551:     diffCSRState.mstatus        := mstatus.rdata.asUInt\n\
      1552:     diffCSRState.sstatus        := mstatus.sstatus.asUInt\n1553:     diffCSRState.mepc\
      \           := mepc.rdata.asUInt\n1554:     diffCSRState.sepc           := sepc.rdata.asUInt\n\
      1555:     diffCSRState.mtval          := mtval.rdata.asUInt\n1556:     diffCSRState.stval\
      \          := stval.rdata.asUInt\n1557:     diffCSRState.mtvec          := mtvec.rdata.asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1584-1594
    context: "1584:     diffVecCSRState.coreid := hartId\n1585:     diffVecCSRState.vstart
      := vstart.rdata.asUInt\n1586:     diffVecCSRState.vxsat := vcsr.vxsat.asUInt\n\
      1587:     diffVecCSRState.vxrm := vcsr.vxrm.asUInt\n1588:     diffVecCSRState.vcsr
      := vcsr.rdata.asUInt\n1589:     diffVecCSRState.vl := RegNext(io.fromRob.commit.vl)\n\
      1590:     diffVecCSRState.vtype := vtype.rdata.asUInt\n1591:     diffVecCSRState.vlenb
      := vlenb.rdata.asUInt\n1592: \n1593:     val diffFpCSRState = DifftestModule(new
      DiffFpCSRState)\n1594:     diffFpCSRState.coreid := hartId"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1594-1604
    context: "1594:     diffFpCSRState.coreid := hartId\n1595:     diffFpCSRState.fcsr
      := fcsr.rdata.asUInt\n1596: \n1597:     val diffHCSRState = DifftestModule(new
      DiffHCSRState)\n1598:     diffHCSRState.coreid      := hartId\n1599:     diffHCSRState.virtMode\
      \    := privState.V.asBool\n1600:     diffHCSRState.mtval2      := mtval2.rdata.asUInt\n\
      1601:     diffHCSRState.mtinst      := mtinst.rdata.asUInt\n1602:     diffHCSRState.hstatus\
      \     := hstatus.rdata.asUInt\n1603:     diffHCSRState.hideleg     := hideleg.rdata.asUInt\n\
      1604:     diffHCSRState.hedeleg     := hedeleg.rdata.asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1666-1677
    context: "1666:     diffSyncAIAEvent.vstopei := vstopei.rdata\n1667:     diffSyncAIAEvent.hgeip
      := hgeip.rdata\n1668: \n1669:     val diffCustomMflushpwr = DifftestModule(new
      DiffSyncCustomMflushpwrEvent)\n1670:     diffCustomMflushpwr.coreid := hartId\n\
      1671:     diffCustomMflushpwr.valid := RegNext(io.fromTop.l2FlushDone) =/= io.fromTop.l2FlushDone\n\
      1672:     diffCustomMflushpwr.l2FlushDone := io.fromTop.l2FlushDone\n1673: \
      \  }\n1674: }\n1675: \n1676: trait IpIeAliasConnect {\n1677:   self: NewCSR
      with MachineLevel with SupervisorLevel with VirtualSupervisorLevel with HypervisorLevel
      =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1691-1711
    context: "1691:   mie.fromVSie := vsie.toMie\n1692:   sie.fromVSie := vsie.toSie\n\
      1693: }\n1694: \n1695: object NewCSRMain extends App {\n1696:   val (config,
      firrtlOpts, firtoolOpts) = ArgParser.parse(\n1697:     args :+ \"--disable-always-basic-diff\"\
      \ :+ \"--dump-fir\" :+ \"--fpga-platform\" :+ \"--target\" :+ \"verilog\")\n\
      1698: \n1699:   val defaultConfig = config.alterPartial({\n1700:     // Get
      XSCoreParams and pass it to the \"small module\"\n1701:     case XSCoreParamsKey
      => config(XSTileKey).head\n1702:   })\n1703: \n1704:   Generator.execute(\n\
      1705:     firrtlOpts :+ \"--full-stacktrace\" :+ \"--target-dir\" :+ \"backend\"\
      ,\n1706:     new NewCSR()(defaultConfig),\n1707:     firtoolOpts\n1708:   )\n\
      1709: \n1710:   println(\"done\")\n1711: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/SupervisorLevel.scala
    lines: 29-39
    context: "29:     // There are no regs in CSR sie.\n30:     val mieIsAlias = mideleg\n\
      31:     val usingReg   = ~mideleg & mvien\n32:     regOut := (mieIsAlias & mie)
      | (usingReg & reg)\n33: \n34:     bundle.getFields.map(_.lsb).foreach { num
      =>\n35:       val wtMie  = toMie.getByNum(num)\n36:       val vsieWt = fromVSie.getByNum(num)\n\
      37: \n38:       wtMie.specifyField(\n39:         _.valid := wen && mieIsAlias(num)
      && wtMie.bits.isRW.B,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/SupervisorLevel.scala
    lines: 51-61
    context: "51:       }.otherwise {\n52:         reg(num) := reg(num)\n53:     \
      \  }\n54:     }\n55: \n56:     regOut.getFields.foreach { field =>\n57:    \
      \   if (field.isHardWired) {\n58:         field := field.getHardWireValue\n\
      59:       }\n60:     }\n61:   })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/SupervisorLevel.scala
    lines: 103-113
    context: "103: \n104:     dontTouch(mvipIsAlias)\n105: \n106:     regOut := mipIsAlias
      & mip | (mvipIsAlias & mvip)\n107: \n108:     bundle.getFields.map(_.lsb).foreach
      { num =>\n109:       val wtMip  = toMip.getByNum(num)\n110:       val wtMvip
      = toMvip.getByNum(num)\n111: \n112:       wtMip.specifyField(\n113:        \
      \ _.valid := wen && mipIsAlias(num) && wtMip.bits.isRW.B,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/SupervisorLevel.scala
    lines: 118-128
    context: "118:         _.valid := wen && mvipIsAlias(num) && wtMvip.bits.isRW.B,\n\
      119:         _.bits  := wen && mvipIsAlias(num) && wtMvip.bits.isRW.B &< wdata(num),\n\
      120:       )\n121:     }\n122: \n123:     regOut.getFields.foreach { field =>\n\
      124:       if (field.isHardWired) {\n125:         field := field.getHardWireValue\n\
      126:       }\n127:     }\n128:   })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/SupervisorLevel.scala
    lines: 153-165
    context: "153:   val scountovf = Module(new CSRModule(\"Scountovf\", new CSRBundle
      {\n154:     override val len: Int = 32\n155:     val OFVEC = RO(31, 3).withReset(0.U)\n\
      156:   }) with HasMhpmeventOfBundle {\n157:     regOut.OFVEC := Mux1H(Seq(\n\
      158:       privState.isModeM  -> ofVec,\n159:       privState.isModeHS -> (mcounteren.HPM.asUInt
      & ofVec),\n160:       privState.isModeVS -> (mcounteren.HPM.asUInt & hcounteren.HPM.asUInt
      & ofVec),\n161:     ))\n162:   }).setAddr(CSRs.scountovf)\n163: \n164:   val
      sstateen0 = Module(new CSRModule(\"Sstateen0\", new Sstateen0Bundle) with HasStateenBundle
      {\n165:     // For every bit in an mstateen CSR that is zero (whether read-only
      zero or set to zero), the same bit"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/SupervisorLevel.scala
    lines: 164-174
    context: "164:   val sstateen0 = Module(new CSRModule(\"Sstateen0\", new Sstateen0Bundle)
      with HasStateenBundle {\n165:     // For every bit in an mstateen CSR that is
      zero (whether read-only zero or set to zero), the same bit\n166:     // appears
      as read-only zero in the matching hstateen and sstateen CSRs. For every bit
      in an hstateen\n167:     // CSR that is zero (whether read-only zero or set
      to zero), the same bit appears as read-only zero in\n168:     // sstateen when
      accessed in VS-mode.\n169:     regOut := Mux(privState.isVirtual, fromHstateen0.asUInt,
      fromMstateen0.asUInt) & reg.asUInt\n170:   }).setAddr(CSRs.sstateen0)\n171:\
      \ \n172:   // sstateen[1|2|3] read-only zero\n173:   val sstateen1 = Module(new
      CSRModule(\"Sstateen1\", new SstateenNonZeroBundle)).setAddr(CSRs.sstateen1)\n\
      174: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/SupervisorLevel.scala
    lines: 197-207
    context: "197:     sstateen3,\n198:     scontext,\n199:   )\n200: \n201:   val
      supervisorLevelCSRMap: SeqMap[Int, (CSRAddrWriteBundle[_], UInt)] = SeqMap(\n\
      202:     CSRs.sstatus -> (mstatus.wAliasSstatus, mstatus.sstatusRdata),\n203:\
      \   ) ++ SeqMap.from(\n204:     supervisorLevelCSRMods.map(csr => (csr.addr
      -> (csr.w, csr.rdata))).iterator\n205:   )\n206: \n207:   val supervisorLevelCSROutMap:
      SeqMap[Int, UInt] = SeqMap("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/SupervisorLevel.scala
    lines: 203-213
    context: "203:   ) ++ SeqMap.from(\n204:     supervisorLevelCSRMods.map(csr =>
      (csr.addr -> (csr.w, csr.rdata))).iterator\n205:   )\n206: \n207:   val supervisorLevelCSROutMap:
      SeqMap[Int, UInt] = SeqMap(\n208:     CSRs.sstatus -> mstatus.sstatus.asUInt,\n\
      209:   ) ++ SeqMap.from(\n210:     supervisorLevelCSRMods.map(csr => (csr.addr
      -> csr.regOut.asInstanceOf[CSRBundle].asUInt)).iterator\n211:   )\n212: }\n\
      213: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/SupervisorLevel.scala
    lines: 225-239
    context: "225:   val UXL  = XLENField      (33, 32).withReset(XLENField.XLEN64)\n\
      226:   val SD   = CSRROField     (63, (_, _) => FS === ContextStatus.Dirty ||
      VS === ContextStatus.Dirty)\n227: }\n228: \n229: class SieBundle extends InterruptEnableBundle
      {\n230:   this.getHS.foreach(_.setRW().withReset(0.U))\n231:   this.STIE.setRO().withReset(0.U)\n\
      232:   this.getLocal.foreach(_.setRW().withReset(0.U))\n233:   this.getM .foreach(_.setHardWired(0.U))\n\
      234:   this.getVS.foreach(_.setHardWired(0.U))\n235:   this.SGEIE.setHardWired(0.U)\n\
      236: }\n237: \n238: class SipBundle extends InterruptPendingBundle {\n239: \
      \  // All pending bits in sip are aliases of mip or read-only 0"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/SupervisorLevel.scala
    lines: 235-246
    context: "235:   this.SGEIE.setHardWired(0.U)\n236: }\n237: \n238: class SipBundle
      extends InterruptPendingBundle {\n239:   // All pending bits in sip are aliases
      of mip or read-only 0\n240:   this.getM .foreach(_.setHardWired(0.U))\n241:\
      \   this.getVS.foreach(_.setHardWired(0.U))\n242:   this.SGEIP.setHardWired(0.U)\n\
      243: }\n244: \n245: class SatpBundle extends CSRBundle {\n246:   val MODE =
      SatpMode(63, 60, null).withReset(SatpMode.Bare)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/SupervisorLevel.scala
    lines: 263-281
    context: "263:   this.LCOFIP.bits.setRW()\n264: }\n265: \n266: class SipToMvip
      extends IpValidBundle {\n267:   this.SSIP.bits.setRW()\n268:   this.getLocal.foreach(_.bits.setRW())\n\
      269: }\n270: \n271: class SieToMie extends IeValidBundle {\n272:   this.getHS.foreach(_.bits.setRW())\n\
      273:   this.getLocal.foreach(_.bits.setRW())\n274: }\n275: \n276: trait HasMhpmeventOfBundle
      { self: CSRModule[_] =>\n277:   val ofVec = IO(Input(UInt(perfCntNum.W)))\n\
      278:   val privState = IO(Input(new PrivState))\n279:   val mcounteren = IO(Input(new
      Counteren))\n280:   val hcounteren = IO(Input(new Counteren))\n281: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPMA.scala
    lines: 43-58
    context: "43: \n44:   val pmaCSROutMap: SeqMap[Int, UInt] = SeqMap.from(\n45:\
      \     pmpCSRMods.map(csr => csr.addr -> csr.regOut.asInstanceOf[CSRBundle].asUInt).iterator\n\
      46:   )\n47: \n48:   private val pmaCfgRead = Cat(pmacfgs.map(_.rdata(7, 0)).reverse)\n\
      49: \n50:   pmaCSRMods.foreach { mod =>\n51:     mod match {\n52:       case
      m: HasPMACfgRSink =>\n53:         m.cfgRData := pmaCfgRead\n54:       case _
      =>\n55:     }\n56:   }\n57: }\n58: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/SretEvent.scala
    lines: 4-14
    context: "4: import chisel3.util._\n5: import org.chipsalliance.cde.config.Parameters\n\
      6: import utility.{SignExt, ZeroExt}\n7: import xiangshan.ExceptionNO\n8: import
      xiangshan.ExceptionNO._\n9: import xiangshan.backend.fu.NewCSR.CSRBundles.{CauseBundle,
      OneFieldBundle, PrivState}\n10: import xiangshan.backend.fu.NewCSR.CSRConfig.{VaddrMaxWidth,
      XLEN}\n11: import xiangshan.backend.fu.NewCSR.CSRDefines.{HgatpMode, PrivMode,
      SatpMode, VirtMode}\n12: import xiangshan.backend.fu.NewCSR._\n13: import xiangshan.AddrTransType\n\
      14: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/SretEvent.scala
    lines: 13-23
    context: "13: import xiangshan.AddrTransType\n14: \n15: \n16: class SretEventOutput
      extends Bundle with EventUpdatePrivStateOutput with EventOutputBase {\n17: \
      \  // Todo: write sstatus instead of mstatus\n18:   val mstatus = ValidIO((new
      MstatusBundle).addInEvent(_.SIE, _.SPIE, _.SPP, _.MPRV, _.MDT, _.SDT))\n19:\
      \   val hstatus = ValidIO((new HstatusBundle).addInEvent(_.SPV))\n20:   val
      vsstatus = ValidIO((new SstatusBundle).addInEvent(_.SIE, _.SPIE, _.SPP))\n21:\
      \   val targetPc = ValidIO(new TargetPCBundle)\n22: }\n23: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/SretEvent.scala
    lines: 24-35
    context: "24: class SretEventSDTOutput extends Bundle with EventOutputBase {\n\
      25:   val vsstatus = ValidIO((new SstatusBundle).addInEvent(_.SDT))\n26: }\n\
      27: \n28: class SretEventInput extends Bundle {\n29:   val privState = Input(new
      PrivState)\n30:   val mstatus   = Input(new MstatusBundle)\n31:   val hstatus\
      \   = Input(new HstatusBundle)\n32:   val vsstatus  = Input(new SstatusBundle)\n\
      33:   val sepc      = Input(new Epc())\n34:   val vsepc     = Input(new Epc())\n\
      35:   val satp      = Input(new SatpBundle)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/SretEvent.scala
    lines: 44-54
    context: "44:   val outSDT = IO(new SretEventSDTOutput)\n45: \n46:   private val
      satp = in.satp\n47:   private val vsatp = in.vsatp\n48:   private val hgatp
      = in.hgatp\n49:   private val nextPrivState = out.privState.bits\n50: \n51:\
      \   private val instrAddrTransType = AddrTransType(\n52:     bare = (!nextPrivState.isVirtual
      && satp.MODE === SatpMode.Bare) ||\n53:            (nextPrivState.isVirtual
      && vsatp.MODE === SatpMode.Bare && hgatp.MODE === HgatpMode.Bare),\n54:    \
      \ sv39 = !nextPrivState.isVirtual && satp.MODE === SatpMode.Sv39 ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/SretEvent.scala
    lines: 57-70
    context: "57:            nextPrivState.isVirtual && vsatp.MODE === SatpMode.Sv48,\n\
      58:     sv39x4 = nextPrivState.isVirtual && vsatp.MODE === SatpMode.Bare &&
      hgatp.MODE === HgatpMode.Sv39x4,\n59:     sv48x4 = nextPrivState.isVirtual &&
      vsatp.MODE === SatpMode.Bare && hgatp.MODE === HgatpMode.Sv48x4\n60:   )\n61:\
      \ \n62:   private val sretInM     = in.privState.isModeM\n63:   private val
      sretInHS    = in.privState.isModeHS\n64:   private val sretInHSorM = sretInM
      || sretInHS\n65:   private val sretInVS    = in.privState.isModeVS\n66: \n67:\
      \   private val xepc = Mux1H(Seq(\n68:     sretInHSorM -> in.sepc,\n69:    \
      \ sretInVS    -> in.vsepc,\n70:   )).asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/SretEvent.scala
    lines: 68-86
    context: "68:     sretInHSorM -> in.sepc,\n69:     sretInVS    -> in.vsepc,\n\
      70:   )).asUInt\n71: \n72: \n73:   private val outPrivState   = Wire(new PrivState)\n\
      74:   outPrivState.PRVM := Mux1H(Seq(\n75:     // SPP is not PrivMode enum type,
      so asUInt\n76:     sretInHSorM -> in.mstatus.SPP.asUInt,\n77:     sretInVS \
      \   -> in.vsstatus.SPP.asUInt,\n78:   ))\n79:   outPrivState.V := Mux1H(Seq(\n\
      80:     sretInHSorM -> in.hstatus.SPV,\n81:     sretInVS    -> in.privState.V,
      // keep\n82:   ))\n83: \n84:   private val sretToVU    = outPrivState.isModeVU\n\
      85:   private val sretToVS    = outPrivState.isModeVS\n86:   private val sretToU\
      \     = outPrivState.isModeHU"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/SretEvent.scala
    lines: 86-99
    context: "86:   private val sretToU     = outPrivState.isModeHU\n87: \n88:   out
      := DontCare\n89:   outSDT := DontCare\n90: \n91:   out.privState.valid := valid\n\
      92:   out.targetPc .valid := valid\n93: \n94:   out.privState.bits      := outPrivState\n\
      95: \n96:   // hstatus\n97:   out.hstatus.valid           := valid && sretInHSorM\n\
      98:   out.hstatus.bits.SPV        := VirtMode.Off\n99: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/SretEvent.scala
    lines: 96-112
    context: "96:   // hstatus\n97:   out.hstatus.valid           := valid && sretInHSorM\n\
      98:   out.hstatus.bits.SPV        := VirtMode.Off\n99: \n100:   // sstatus\n\
      101:   out.mstatus.valid           := valid && sretInHSorM\n102:   out.mstatus.bits.SPP\
      \        := PrivMode.U.asUInt(0, 0) // SPP is not PrivMode enum type, so asUInt
      and shrink the width\n103:   out.mstatus.bits.SIE        := in.mstatus.SPIE\n\
      104:   out.mstatus.bits.SPIE       := 1.U\n105:   out.mstatus.bits.MPRV    \
      \   := 0.U // sret will always leave M mode\n106:   out.mstatus.bits.MDT   \
      \     := Mux(sretInM, 0.U, in.mstatus.MDT.asBool) // when execute return in
      M mode, set MDT 0\n107:   out.mstatus.bits.SDT        := MuxCase(in.mstatus.SDT.asBool,
      Seq(\n108:     sretInHS   -> 0.U, // sret will alway leave M mode\n109:    \
      \ (sretInM && (sretToU || sretToVS || sretToVU))    -> 0.U\n110:   ))\n111:\
      \ \n112: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/DretEvent.scala
    lines: 9-19
    context: "9: import xiangshan.AddrTransType\n10: \n11: \n12: class DretEventOutput
      extends Bundle with EventUpdatePrivStateOutput with EventOutputBase {\n13: \
      \  val dcsr = ValidIO((new DcsrBundle).addInEvent(_.V, _.PRV))\n14:   val mstatus
      = ValidIO((new MstatusBundle).addInEvent(_.MPRV, _.MDT, _.SDT))\n15:   val vsstatus
      = ValidIO((new SstatusBundle).addInEvent(_.SDT))\n16:   val debugMode = ValidIO(Bool())\n\
      17:   val debugIntrEnable = ValidIO(Bool())\n18:   val targetPc = ValidIO(new
      TargetPCBundle)\n19: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/DretEvent.scala
    lines: 19-29
    context: "19: }\n20: \n21: class DretEventInput extends Bundle {\n22:   val dcsr
      = Input(new DcsrBundle)\n23:   val dpc = Input(new Epc)\n24:   val mstatus =
      Input(new MstatusBundle)\n25:   val vsstatus = Input(new SstatusBundle)\n26:\
      \   val satp = Input(new SatpBundle)\n27:   val vsatp = Input(new SatpBundle)\n\
      28:   val hgatp = Input(new HgatpBundle)\n29: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/DretEvent.scala
    lines: 33-43
    context: "33:   val out = IO(new DretEventOutput)\n34: \n35:   private val satp
      = in.satp\n36:   private val vsatp = in.vsatp\n37:   private val hgatp = in.hgatp\n\
      38:   private val nextPrivState = out.privState.bits\n39: \n40:   private val
      instrAddrTransType = AddrTransType(\n41:     bare = nextPrivState.isModeM ||\n\
      42:            (!nextPrivState.isVirtual && satp.MODE === SatpMode.Bare) ||\n\
      43:            (nextPrivState.isVirtual && vsatp.MODE === SatpMode.Bare && hgatp.MODE
      === HgatpMode.Bare),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/DretEvent.scala
    lines: 50-72
    context: "50:   )\n51: \n52:   out := DontCare\n53: \n54:   out.debugMode.valid\
      \       := valid\n55:   out.privState.valid       := valid\n56:   out.dcsr.valid\
      \            := valid\n57:   out.mstatus.valid         := valid\n58:   out.vsstatus.valid\
      \        := valid\n59:   out.debugIntrEnable.valid := valid\n60:   out.targetPc.valid\
      \        := valid\n61: \n62:   out.privState.bits.PRVM     := in.dcsr.PRV.asUInt\n\
      63:   out.privState.bits.V        := Mux(in.dcsr.PRV === PrivMode.M, VirtMode.Off.asUInt,
      in.dcsr.V.asUInt)\n64:   out.mstatus.bits.MPRV       := Mux(!out.privState.bits.isModeM,
      0.U, in.mstatus.MPRV.asUInt)\n65:   out.mstatus.bits.MDT        := Mux(!out.privState.bits.isModeM,
      0.U, in.mstatus.MDT.asBool)\n66:   out.mstatus.bits.SDT        := Mux(out.privState.bits.isVirtual
      || out.privState.bits.isModeHU, 0.U, in.mstatus.SDT.asBool)\n67:   out.vsstatus.bits.SDT\
      \       := Mux(out.privState.bits.isModeVU, 0.U, in.vsstatus.SDT.asBool)\n68:\
      \   out.debugMode.bits          := false.B\n69:   out.debugIntrEnable.bits \
      \   := true.B\n70:   out.targetPc.bits.pc        := in.dpc.asUInt\n71:   out.targetPc.bits.raiseIPF\
      \  := instrAddrTransType.checkPageFault(in.dpc.asUInt)\n72:   out.targetPc.bits.raiseIAF\
      \  := instrAddrTransType.checkAccessFault(in.dpc.asUInt)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryDEvent.scala
    lines: 5-15
    context: "5: import org.chipsalliance.cde.config.Parameters\n6: import utility.{SignExt,
      ZeroExt}\n7: import xiangshan.{ExceptionNO, HasXSParameter, TriggerAction}\n\
      8: import xiangshan.ExceptionNO._\n9: import xiangshan.backend.fu.NewCSR\n10:
      import xiangshan.backend.fu.NewCSR.CSRBundles.{CauseBundle, OneFieldBundle,
      PrivState}\n11: import xiangshan.backend.fu.NewCSR.CSRConfig.{VaddrMaxWidth,
      XLEN}\n12: import xiangshan.backend.fu.NewCSR.CSRDefines.SatpMode\n13: import
      xiangshan.backend.fu.NewCSR._\n14: \n15: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryDEvent.scala
    lines: 80-94
    context: "80:   out.dcsr.valid              := valid\n81:   out.dpc.valid    \
      \           := valid\n82:   // !debugMode trap || debugMode hasExp\n83:   out.targetPc.valid\
      \          := valid || hasExceptionInDmode\n84:   out.debugMode.valid      \
      \   := valid\n85:   out.privState.valid         := valid\n86:   out.debugIntrEnable.valid\
      \   := valid\n87: \n88:   out.dcsr.bits.V             := current.privState.V.asUInt\n\
      89:   out.dcsr.bits.PRV           := current.privState.PRVM.asUInt\n90:   out.dcsr.bits.CAUSE\
      \         := Mux(hasDebugIntr, causeIntr, causeExp)\n91:   out.dpc.bits.epc\
      \            := trapPC(63, 1)\n92: \n93:   out.targetPc.bits.pc        := debugPc\n\
      94:   out.targetPc.bits.raiseIPF  := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryDEvent.scala
    lines: 93-103
    context: "93:   out.targetPc.bits.pc        := debugPc\n94:   out.targetPc.bits.raiseIPF\
      \  := false.B\n95:   out.targetPc.bits.raiseIAF  := false.B\n96:   out.targetPc.bits.raiseIGPF
      := false.B\n97:   out.debugMode.bits          := true.B\n98:   out.privState.bits\
      \          := PrivState.ModeM\n99:   out.debugIntrEnable.bits    := false.B\n\
      100: \n101: }\n102: \n103: trait TrapEntryDEventSinkBundle extends EventSinkBundle
      { self: CSRModule[_ <: CSRBundle] =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/MNretEvent.scala
    lines: 4-14
    context: "4: import chisel3.util._\n5: import org.chipsalliance.cde.config.Parameters\n\
      6: import utility.{SignExt, ZeroExt}\n7: import xiangshan.ExceptionNO\n8: import
      xiangshan.ExceptionNO._\n9: import xiangshan.backend.fu.NewCSR.CSRBundles.{CauseBundle,
      OneFieldBundle, PrivState}\n10: import xiangshan.backend.fu.NewCSR.CSRConfig.{VaddrMaxWidth,
      XLEN}\n11: import xiangshan.backend.fu.NewCSR.CSRDefines.{HgatpMode, PrivMode,
      SatpMode, VirtMode}\n12: import xiangshan.backend.fu.NewCSR._\n13: import xiangshan.AddrTransType\n\
      14: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/MNretEvent.scala
    lines: 13-23
    context: "13: import xiangshan.AddrTransType\n14: \n15: \n16: class MNretEventOutput
      extends Bundle with EventUpdatePrivStateOutput with EventOutputBase {\n17: \
      \  val mnstatus  = ValidIO((new MnstatusBundle).addInEvent(_.MNPP, _.MNPV, _.NMIE))\n\
      18:   val mstatus   = ValidIO((new MstatusBundle).addInEvent(_.MPRV, _.MDT,
      _.SDT))\n19:   val vsstatus  = ValidIO((new SstatusBundle).addInEvent(_.SDT))\n\
      20:   val targetPc  = ValidIO(new TargetPCBundle)\n21: }\n22: \n23: class MNretEventInput
      extends Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/MNretEvent.scala
    lines: 20-30
    context: "20:   val targetPc  = ValidIO(new TargetPCBundle)\n21: }\n22: \n23:
      class MNretEventInput extends Bundle {\n24:   val mnstatus = Input(new MnstatusBundle)\n\
      25:   val mstatus  = Input(new MstatusBundle)\n26:   val mnepc    = Input(new
      Epc())\n27:   val satp     = Input(new SatpBundle)\n28:   val vsatp    = Input(new
      SatpBundle)\n29:   val hgatp    = Input(new HgatpBundle)\n30:   val vsstatus
      = Input(new SstatusBundle)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/MNretEvent.scala
    lines: 35-45
    context: "35:   val out = IO(new MNretEventOutput)\n36: \n37:   private val satp
      = in.satp\n38:   private val vsatp = in.vsatp\n39:   private val hgatp = in.hgatp\n\
      40:   private val nextPrivState = out.privState.bits\n41: \n42:   private val
      instrAddrTransType = AddrTransType(\n43:     bare = nextPrivState.isModeM ||\n\
      44:            (!nextPrivState.isVirtual && satp.MODE === SatpMode.Bare) ||\n\
      45:            (nextPrivState.isVirtual && vsatp.MODE === SatpMode.Bare && hgatp.MODE
      === HgatpMode.Bare),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/MNretEvent.scala
    lines: 49-59
    context: "49:            nextPrivState.isVirtual && vsatp.MODE === SatpMode.Sv48,\n\
      50:     sv39x4 = nextPrivState.isVirtual && vsatp.MODE === SatpMode.Bare &&
      hgatp.MODE === HgatpMode.Sv39x4,\n51:     sv48x4 = nextPrivState.isVirtual &&
      vsatp.MODE === SatpMode.Bare && hgatp.MODE === HgatpMode.Sv48x4\n52:   )\n53:\
      \ \n54:   val outPrivState   = Wire(new PrivState)\n55:   outPrivState.PRVM
      := in.mnstatus.MNPP\n56:   outPrivState.V    := Mux(in.mnstatus.MNPP === PrivMode.M,
      VirtMode.Off.asUInt, in.mnstatus.MNPV.asUInt)\n57: \n58:   val mnretToM  = outPrivState.isModeM\n\
      59:   val mnretToS  = outPrivState.isModeHS"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/MNretEvent.scala
    lines: 59-82
    context: "59:   val mnretToS  = outPrivState.isModeHS\n60:   val mnretToVU = outPrivState.isModeVU\n\
      61: \n62:   out := DontCare\n63: \n64:   out.privState.valid := valid\n65: \
      \  out.mnstatus .valid := valid\n66:   out.mstatus  .valid := valid\n67:   out.vsstatus
      .valid := valid\n68:   out.targetPc .valid := valid\n69: \n70:   out.privState.bits\
      \          := outPrivState\n71:   out.mnstatus.bits.MNPP      := PrivMode.U\n\
      72:   out.mnstatus.bits.MNPV      := VirtMode.Off.asUInt\n73:   out.mnstatus.bits.NMIE\
      \      := 1.U\n74:   out.mstatus.bits.MPRV       := Mux(in.mnstatus.MNPP =/=
      PrivMode.M, 0.U, in.mstatus.MPRV.asUInt)\n75:   // clear MDT when mnret to below
      M\n76:   out.mstatus.bits.MDT        := Mux(mnretToM, in.mstatus.MDT.asBool,
      0.U)\n77:   out.mstatus.bits.SDT        := Mux(mnretToM || mnretToS, in.mstatus.SDT.asBool,
      0.U)\n78:   out.vsstatus.bits.SDT       := Mux(mnretToVU, 0.U, in.vsstatus.SDT.asBool)\n\
      79:   out.targetPc.bits.pc        := in.mnepc.asUInt\n80:   out.targetPc.bits.raiseIPF\
      \  := instrAddrTransType.checkPageFault(in.mnepc.asUInt)\n81:   out.targetPc.bits.raiseIAF\
      \  := instrAddrTransType.checkAccessFault(in.mnepc.asUInt)\n82:   out.targetPc.bits.raiseIGPF
      := instrAddrTransType.checkGuestPageFault(in.mnepc.asUInt)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryHSEvent.scala
    lines: 3-13
    context: "3: import chisel3._\n4: import chisel3.util._\n5: import org.chipsalliance.cde.config.Parameters\n\
      6: import utility.{SignExt, ZeroExt}\n7: import xiangshan.ExceptionNO\n8: import
      xiangshan.backend.fu.NewCSR.CSRBundles.{CauseBundle, OneFieldBundle, PrivState}\n\
      9: import xiangshan.backend.fu.NewCSR.CSRConfig.{VaddrMaxWidth, XLEN}\n10: import
      xiangshan.backend.fu.NewCSR.CSRDefines.SatpMode\n11: import xiangshan.backend.fu.NewCSR._\n\
      12: import xiangshan.AddrTransType\n13: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryHSEvent.scala
    lines: 13-23
    context: "13: \n14: \n15: class TrapEntryHSEventOutput extends Bundle with EventUpdatePrivStateOutput
      with EventOutputBase  {\n16: \n17:   // Todo: use sstatus instead of mstatus\n\
      18:   val mstatus = ValidIO((new MstatusBundle ).addInEvent(_.SPP, _.SPIE, _.SIE,
      _.SDT))\n19:   val hstatus = ValidIO((new HstatusBundle ).addInEvent(_.SPV,
      _.SPVP, _.GVA))\n20:   val sepc    = ValidIO((new Epc           ).addInEvent(_.epc))\n\
      21:   val scause  = ValidIO((new CauseBundle   ).addInEvent(_.Interrupt, _.ExceptionCode))\n\
      22:   val stval   = ValidIO((new OneFieldBundle).addInEvent(_.ALL))\n23:   val
      htval   = ValidIO((new OneFieldBundle).addInEvent(_.ALL))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryHSEvent.scala
    lines: 90-100
    context: "90:     (tvalFillMemVaddr || isLSGuestExcp ) -> trapMemVA,\n91:    \
      \ (tvalFillInst                      ) -> trapInst,\n92:   ))\n93: \n94:   private
      val tval2 = Mux1H(Seq(\n95:     (isFetchGuestExcp && isFetchMalAddr        \
      \            ) -> in.fetchMalTval,\n96:     (isFetchGuestExcp && !isFetchMalAddr
      && !fetchCrossPage) -> trapPCGPA,\n97:     (isFetchGuestExcp && !isFetchMalAddr
      && fetchCrossPage ) -> (trapPCGPA + 2.U),\n98:     (isLSGuestExcp          \
      \                               ) -> trapMemGPA,\n99:   ))\n100: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryHSEvent.scala
    lines: 106-117
    context: "106:     sv48x4 = false.B\n107:   )\n108: \n109:   out := DontCare\n\
      110: \n111:   out.privState.valid := valid\n112:   out.mstatus  .valid := valid\n\
      113:   out.hstatus  .valid := valid\n114:   out.sepc     .valid := valid\n115:\
      \   out.scause   .valid := valid\n116:   out.stval    .valid := valid\n117:\
      \   out.htval    .valid := valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryHSEvent.scala
    lines: 116-140
    context: "116:   out.stval    .valid := valid\n117:   out.htval    .valid := valid\n\
      118:   out.htinst   .valid := valid\n119:   out.targetPc .valid := valid\n120:\
      \ \n121:   out.privState.bits            := PrivState.ModeHS\n122:   // mstatus\n\
      123:   out.mstatus.bits.SPP          := current.privState.PRVM.asUInt(0, 0)
      // SPP is not PrivMode enum type, so asUInt and shrink the width\n124:   out.mstatus.bits.SPIE\
      \         := current.sstatus.SIE\n125:   out.mstatus.bits.SIE          := 0.U\n\
      126:   out.mstatus.bits.SDT          := in.menvcfg.DTE.asBool // when DTE open
      set SDT to 1, else SDT is readonly 0\n127:   // hstatus\n128:   out.hstatus.bits.SPV\
      \          := current.privState.V\n129:     // SPVP is not PrivMode enum type,
      so asUInt and shrink the width\n130:   out.hstatus.bits.SPVP         := Mux(!current.privState.isVirtual,
      in.hstatus.SPVP.asUInt, current.privState.PRVM.asUInt(0, 0))\n131:   out.hstatus.bits.GVA\
      \          := tvalFillGVA\n132:   out.sepc.bits.epc             := Mux(isFetchMalAddr,
      in.fetchMalTval(63, 1), trapPC(63, 1))\n133:   out.scause.bits.Interrupt   \
      \  := isInterrupt\n134:   out.scause.bits.ExceptionCode := highPrioTrapNO\n\
      135:   out.stval.bits.ALL            := Mux(isFetchMalAddrExcp, in.fetchMalTval,
      tval)\n136:   out.htval.bits.ALL            := tval2 >> 2\n137:   out.htinst.bits.ALL\
      \           := Mux(isFetchGuestExcp && in.trapIsForVSnonLeafPTE || isLSGuestExcp
      && in.memExceptionIsForVSnonLeafPTE, 0x3000.U, 0.U)\n138:   out.targetPc.bits.pc\
      \          := in.pcFromXtvec\n139:   out.targetPc.bits.raiseIPF    := instrAddrTransType.checkPageFault(in.pcFromXtvec)\n\
      140:   out.targetPc.bits.raiseIAF    := instrAddrTransType.checkAccessFault(in.pcFromXtvec)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryMEvent.scala
    lines: 3-13
    context: "3: import chisel3._\n4: import chisel3.util._\n5: import org.chipsalliance.cde.config.Parameters\n\
      6: import utility.SignExt\n7: import xiangshan.ExceptionNO\n8: import xiangshan.backend.fu.NewCSR.CSRBundles.{CauseBundle,
      OneFieldBundle, PrivState}\n9: import xiangshan.backend.fu.NewCSR.CSRConfig.{VaddrMaxWidth,
      XLEN}\n10: import xiangshan.backend.fu.NewCSR._\n11: import xiangshan.AddrTransType\n\
      12: \n13: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryMEvent.scala
    lines: 11-21
    context: "11: import xiangshan.AddrTransType\n12: \n13: \n14: class TrapEntryMEventOutput
      extends Bundle with EventUpdatePrivStateOutput with EventOutputBase  {\n15:\
      \ \n16:   val mstatus   = ValidIO((new MstatusBundle ).addInEvent(_.MPV, _.MPP,
      _.GVA, _.MPIE, _.MIE, _.MDT))\n17:   val mepc      = ValidIO((new Epc      \
      \     ).addInEvent(_.epc))\n18:   val mcause    = ValidIO((new CauseBundle \
      \  ).addInEvent(_.Interrupt, _.ExceptionCode))\n19:   val mtval     = ValidIO((new
      OneFieldBundle).addInEvent(_.ALL))\n20:   val mtval2    = ValidIO((new OneFieldBundle).addInEvent(_.ALL))\n\
      21:   val mtinst    = ValidIO((new OneFieldBundle).addInEvent(_.ALL))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryMEvent.scala
    lines: 88-98
    context: "88:     (tvalFillMemVaddr || isLSGuestExcp ) -> trapMemVA,\n89:    \
      \ (tvalFillInst                      ) -> trapInst,\n90:   ))\n91: \n92:   private
      val tval2 = Mux1H(Seq(\n93:     (isFetchGuestExcp && isFetchMalAddr        \
      \            ) -> in.fetchMalTval,\n94:     (isFetchGuestExcp && !isFetchMalAddr
      && !fetchCrossPage) -> trapPCGPA,\n95:     (isFetchGuestExcp && !isFetchMalAddr
      && fetchCrossPage ) -> (trapPCGPA + 2.U),\n96:     (isLSGuestExcp          \
      \                               ) -> trapMemGPA,\n97:   ))\n98: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryMEvent.scala
    lines: 98-109
    context: "98: \n99:   private val precause = Cat(isInterrupt, highPrioTrapNO)\n\
      100: \n101:   out := DontCare\n102: \n103:   out.privState.valid := valid\n\
      104:   out.mstatus  .valid := valid\n105:   out.mepc     .valid := valid\n106:\
      \   out.mcause   .valid := valid\n107:   out.mtval    .valid := valid\n108:\
      \   out.mtval2   .valid := valid\n109:   out.mtinst   .valid := valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryMEvent.scala
    lines: 107-127
    context: "107:   out.mtval    .valid := valid\n108:   out.mtval2   .valid := valid\n\
      109:   out.mtinst   .valid := valid\n110:   out.targetPc .valid := valid\n111:\
      \ \n112:   out.privState.bits            := PrivState.ModeM\n113:   out.mstatus.bits.MPV\
      \          := current.privState.V\n114:   out.mstatus.bits.MPP          := current.privState.PRVM\n\
      115:   out.mstatus.bits.GVA          := tvalFillGVA\n116:   out.mstatus.bits.MPIE\
      \         := current.mstatus.MIE\n117:   out.mstatus.bits.MIE          := 0.U\n\
      118:   out.mstatus.bits.MDT          := 1.U\n119:   out.mepc.bits.epc      \
      \       := Mux(isFetchMalAddr, in.fetchMalTval(63, 1), trapPC(63, 1))\n120:\
      \   out.mcause.bits.Interrupt     := isInterrupt && !isDTExcp\n121:   out.mcause.bits.ExceptionCode
      := Mux(isDTExcp, ExceptionNO.EX_DT.U, highPrioTrapNO)\n122:   out.mtval.bits.ALL\
      \            := Mux(isFetchMalAddrExcp, in.fetchMalTval, tval)\n123:   out.mtval2.bits.ALL\
      \           := Mux(isDTExcp, precause, tval2 >> 2)\n124:   out.mtinst.bits.ALL\
      \           := Mux(isFetchGuestExcp && in.trapIsForVSnonLeafPTE || isLSGuestExcp
      && in.memExceptionIsForVSnonLeafPTE, 0x3000.U, 0.U)\n125:   out.targetPc.bits.pc\
      \          := in.pcFromXtvec\n126:   out.targetPc.bits.raiseIPF    := false.B\n\
      127:   out.targetPc.bits.raiseIAF    := AddrTransType(bare = true).checkAccessFault(in.pcFromXtvec)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/CSREvent.scala
    lines: 3-13
    context: "3: import chisel3._\n4: import chisel3.util._\n5: import org.chipsalliance.cde.config.Parameters\n\
      6: import utility.{SignExt, ZeroExt}\n7: import xiangshan.HasXSParameter\n8:
      import xiangshan.backend.fu.NewCSR.CSRBundles.{CauseBundle, PrivState}\n9: import
      xiangshan.backend.fu.NewCSR.CSRConfig._\n10: import xiangshan.backend.fu.NewCSR.CSRDefines.{HgatpMode,
      SatpMode}\n11: import xiangshan.backend.fu.NewCSR._\n12: \n13: trait CSREvents
      { self: NewCSR =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/CSREvent.scala
    lines: 39-49
    context: "39:     sretEvent,\n40:     dretEvent,\n41:     mnretEvent,\n42:   )\n\
      43: \n44:   events.foreach(x => dontTouch(x.out))\n45: \n46:   val trapEntryEvents:
      Seq[Module with CSREventBase] = Seq(\n47:     trapEntryDEvent,\n48:     trapEntryMEvent,\n\
      49:     trapEntryHSEvent,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/CSREvent.scala
    lines: 50-60
    context: "50:     trapEntryVSEvent,\n51:   )\n52: }\n53: \n54: trait EventUpdatePrivStateOutput
      {\n55:   val privState = ValidIO(new PrivState)\n56: }\n57: \n58: trait EventOutputBase
      {\n59:   import scala.reflect.runtime.{universe => ru}\n60: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/CSREvent.scala
    lines: 72-82
    context: "72:   val valid = IO(Input(Bool()))\n73:   val in: Bundle\n74:   val
      out: Bundle\n75: \n76:   def genTrapVA(\n77:     transMode: PrivState,\n78:\
      \     satp: SatpBundle,\n79:     vsatp: SatpBundle,\n80:     hgatp: HgatpBundle,\n\
      81:     addr: UInt,\n82:   ) = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/CSREvent.scala
    lines: 119-129
    context: "119: class TrapEntryEventInput(implicit val p: Parameters) extends Bundle
      with HasXSParameter {\n120:   val causeNO = Input(new CauseBundle)\n121:   val
      trapPc = Input(UInt(VaddrMaxWidth.W))\n122:   val trapPcGPA = Input(UInt(PAddrBitsMax.W))\n\
      123:   val trapInst = Input(ValidIO(UInt(InstWidth.W)))\n124:   val fetchMalTval
      = Input(UInt(XLEN.W))\n125:   val isCrossPageIPF = Input(Bool())\n126:   val
      isHls = Input(Bool())\n127:   val isFetchMalAddr = Input(Bool())\n128:   val
      isFetchBkpt = Input(Bool())\n129:   val trapIsForVSnonLeafPTE = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/CSREvent.scala
    lines: 128-143
    context: "128:   val isFetchBkpt = Input(Bool())\n129:   val trapIsForVSnonLeafPTE
      = Input(Bool())\n130:   val hasDTExcp = Input(Bool())\n131: \n132:   // always
      current privilege\n133:   val iMode = Input(new PrivState())\n134:   // take
      MRPV into consideration\n135:   val dMode = Input(new PrivState())\n136:   //
      status\n137:   val privState = Input(new PrivState)\n138:   val mstatus = Input(new
      MstatusBundle)\n139:   val hstatus = Input(new HstatusBundle)\n140:   val sstatus
      = Input(new SstatusBundle)\n141:   val vsstatus = Input(new SstatusBundle)\n\
      142:   // envcfg\n143:   val menvcfg = Input(new MEnvCfg)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/CSREvent.scala
    lines: 157-167
    context: "157:   val hvictlIID = Input(UInt(HIIDWidth.W))\n158: }\n159: \n160:
      trait EventSinkBundle { self: CSRModule[_ <: CSRBundle] =>\n161:   protected
      def addUpdateBundleInCSREnumType(updateBundle: ValidIO[CSRBundle]): Unit = {\n\
      162:     (reg.asInstanceOf[CSRBundle].getFields zip updateBundle.bits.getFields).foreach
      { case (sink, source) =>\n163:       if (updateBundle.bits.eventFields.contains(source))
      {\n164:         sink.addOtherUpdate(updateBundle.valid, source)\n165:      \
      \ }\n166:     }\n167:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryVSEvent.scala
    lines: 3-13
    context: "3: import chisel3._\n4: import chisel3.util._\n5: import org.chipsalliance.cde.config.Parameters\n\
      6: import utility.{SignExt, ZeroExt}\n7: import xiangshan.ExceptionNO._\n8:
      import xiangshan.backend.fu.NewCSR.CSRBundles.{CauseBundle, OneFieldBundle,
      PrivState}\n9: import xiangshan.backend.fu.NewCSR.CSRConfig.{VaddrMaxWidth,
      XLEN}\n10: import xiangshan.backend.fu.NewCSR.CSRDefines.{HgatpMode, SatpMode}\n\
      11: import xiangshan.backend.fu.NewCSR._\n12: import xiangshan.AddrTransType\n\
      13: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryVSEvent.scala
    lines: 24-34
    context: "24: class TrapEntryVSEventModule(implicit val p: Parameters) extends
      Module with CSREventBase {\n25:   val in = IO(new TrapEntryEventInput)\n26:\
      \   val out = IO(new TrapEntryVSEventOutput)\n27: \n28:   when (valid) {\n29:\
      \     assert(in.privState.isVirtual, \"The mode must be VU or VS when entry
      VS mode\")\n30:   }\n31: \n32:   private val current = in\n33:   private val
      iMode = current.iMode\n34:   private val dMode = current.dMode"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryVSEvent.scala
    lines: 107-117
    context: "107:     sv48x4 = vsatp.MODE === SatpMode.Bare && hgatp.MODE === HgatpMode.Sv48x4\n\
      108:   )\n109: \n110:   out := DontCare\n111: \n112:   out.privState.valid :=
      valid\n113: \n114:   out.vsstatus .valid := valid\n115:   out.vsepc    .valid
      := valid\n116:   out.vscause  .valid := valid\n117:   out.vstval   .valid :=
      valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryVSEvent.scala
    lines: 115-135
    context: "115:   out.vsepc    .valid := valid\n116:   out.vscause  .valid := valid\n\
      117:   out.vstval   .valid := valid\n118:   out.targetPc .valid := valid\n119:\
      \ \n120:   out.privState.bits             := PrivState.ModeVS\n121:   // vsstatus\n\
      122:   out.vsstatus.bits.SPP          := current.privState.PRVM.asUInt(0, 0)
      // SPP is not PrivMode enum type, so asUInt and shrink the width\n123:   out.vsstatus.bits.SPIE\
      \         := current.vsstatus.SIE\n124:   out.vsstatus.bits.SIE          :=
      0.U\n125:   out.vsstatus.bits.SDT          := in.henvcfg.DTE.asBool // when
      DTE open set SDT to 1, else SDT is readonly 0\n126:   // SPVP is not PrivMode
      enum type, so asUInt and shrink the width\n127:   out.vsepc.bits.epc       \
      \      := Mux(isFetchMalAddr, in.fetchMalTval(63, 1), trapPC(63, 1))\n128: \
      \  out.vscause.bits.Interrupt     := isInterrupt\n129:   out.vscause.bits.ExceptionCode
      := Mux(virtualInterruptIsHvictlInject, hvictlIID, highPrioTrapNO)\n130:   out.vstval.bits.ALL\
      \            := Mux(isFetchMalAddrExcp, in.fetchMalTval, tval)\n131:   out.targetPc.bits.pc\
      \           := in.pcFromXtvec\n132:   out.targetPc.bits.raiseIPF     := instrAddrTransType.checkPageFault(in.pcFromXtvec)\n\
      133:   out.targetPc.bits.raiseIAF     := instrAddrTransType.checkAccessFault(in.pcFromXtvec)\n\
      134:   out.targetPc.bits.raiseIGPF    := instrAddrTransType.checkGuestPageFault(in.pcFromXtvec)\n\
      135: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/MretEvent.scala
    lines: 4-14
    context: "4: import chisel3.util._\n5: import org.chipsalliance.cde.config.Parameters\n\
      6: import utility.{SignExt, ZeroExt}\n7: import xiangshan.ExceptionNO\n8: import
      xiangshan.ExceptionNO._\n9: import xiangshan.backend.fu.NewCSR.CSRBundles.{CauseBundle,
      OneFieldBundle, PrivState}\n10: import xiangshan.backend.fu.NewCSR.CSRConfig.{VaddrMaxWidth,
      XLEN}\n11: import xiangshan.backend.fu.NewCSR.CSRDefines.{HgatpMode, PrivMode,
      SatpMode, VirtMode}\n12: import xiangshan.backend.fu.NewCSR._\n13: import xiangshan.AddrTransType\n\
      14: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/MretEvent.scala
    lines: 12-22
    context: "12: import xiangshan.backend.fu.NewCSR._\n13: import xiangshan.AddrTransType\n\
      14: \n15: \n16: class MretEventOutput extends Bundle with EventUpdatePrivStateOutput
      with EventOutputBase {\n17:   val mstatus  = ValidIO((new MstatusBundle).addInEvent(_.MPP,
      _.MPV, _.MIE, _.MPIE, _.MPRV, _.MDT, _.SDT))\n18:   val vsstatus = ValidIO((new
      SstatusBundle).addInEvent(_.SDT))\n19:   val targetPc = ValidIO(new TargetPCBundle)\n\
      20: }\n21: \n22: class MretEventInput extends Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/MretEvent.scala
    lines: 18-28
    context: "18:   val vsstatus = ValidIO((new SstatusBundle).addInEvent(_.SDT))\n\
      19:   val targetPc = ValidIO(new TargetPCBundle)\n20: }\n21: \n22: class MretEventInput
      extends Bundle {\n23:   val mstatus  = Input(new MstatusBundle)\n24:   val vsstatus
      = Input(new SstatusBundle)\n25:   val mepc     = Input(new Epc())\n26:   val
      satp     = Input(new SatpBundle)\n27:   val vsatp    = Input(new SatpBundle)\n\
      28:   val hgatp    = Input(new HgatpBundle)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/MretEvent.scala
    lines: 33-43
    context: "33:   val out = IO(new MretEventOutput)\n34: \n35:   private val satp
      = in.satp\n36:   private val vsatp = in.vsatp\n37:   private val hgatp = in.hgatp\n\
      38:   private val nextPrivState = out.privState.bits\n39: \n40:   private val
      instrAddrTransType = AddrTransType(\n41:     bare = nextPrivState.isModeM ||\n\
      42:            (!nextPrivState.isVirtual && satp.MODE === SatpMode.Bare) ||\n\
      43:            (nextPrivState.isVirtual && vsatp.MODE === SatpMode.Bare && hgatp.MODE
      === HgatpMode.Bare),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/MretEvent.scala
    lines: 46-58
    context: "46:     sv48 = !nextPrivState.isModeM && !nextPrivState.isVirtual &&
      satp.MODE === SatpMode.Sv48 ||\n47:            nextPrivState.isVirtual && vsatp.MODE
      === SatpMode.Sv48,\n48:     sv39x4 = nextPrivState.isVirtual && vsatp.MODE ===
      SatpMode.Bare && hgatp.MODE === HgatpMode.Sv39x4,\n49:     sv48x4 = nextPrivState.isVirtual
      && vsatp.MODE === SatpMode.Bare && hgatp.MODE === HgatpMode.Sv48x4\n50:   )\n\
      51:   val outPrivState   = Wire(new PrivState)\n52:   outPrivState.PRVM := in.mstatus.MPP\n\
      53:   outPrivState.V    := Mux(in.mstatus.MPP === PrivMode.M, VirtMode.Off.asUInt,
      in.mstatus.MPV.asUInt)\n54: \n55:   val mretToM  = outPrivState.isModeM\n56:\
      \   val mretToS  = outPrivState.isModeHS\n57:   val mretToVu = outPrivState.isModeVU\n\
      58: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/MretEvent.scala
    lines: 56-79
    context: "56:   val mretToS  = outPrivState.isModeHS\n57:   val mretToVu = outPrivState.isModeVU\n\
      58: \n59:   out := DontCare\n60: \n61:   out.privState.valid := valid\n62: \
      \  out.mstatus  .valid := valid\n63:   out.targetPc .valid := valid\n64: \n\
      65:   out.privState.bits          := outPrivState\n66:   out.mstatus.bits.MPP\
      \        := PrivMode.U\n67:   out.mstatus.bits.MPV        := VirtMode.Off.asUInt\n\
      68:   out.mstatus.bits.MIE        := in.mstatus.MPIE\n69:   out.mstatus.bits.MPIE\
      \       := 1.U\n70:   out.mstatus.bits.MPRV       := Mux(in.mstatus.MPP =/=
      PrivMode.M, 0.U, in.mstatus.MPRV.asUInt)\n71:   // clear MDT when return mret
      always execute in M mode\n72:   out.mstatus.bits.MDT    := 0.U\n73:   // clear
      sstatus.SDT when return mode below M and HS\n74:   out.mstatus.bits.SDT    :=
      Mux(mretToM || mretToS, in.mstatus.SDT.asBool, 0.U)\n75:   // clear vsstatus.SDT
      when return to VU\n76:   out.vsstatus.bits.SDT   := Mux(mretToVu, 0.U, in.vsstatus.SDT.asBool)\n\
      77: \n78:   out.targetPc.bits.pc        := in.mepc.asUInt\n79:   out.targetPc.bits.raiseIPF\
      \  := instrAddrTransType.checkPageFault(in.mepc.asUInt)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryMNEvent.scala
    lines: 3-13
    context: "3: import chisel3._\n4: import chisel3.util._\n5: import org.chipsalliance.cde.config.Parameters\n\
      6: import utility.SignExt\n7: import xiangshan.ExceptionNO\n8: import xiangshan.backend.fu.NewCSR.CSRBundles.{CauseBundle,
      OneFieldBundle, PrivState}\n9: import xiangshan.backend.fu.NewCSR.CSRConfig.{VaddrMaxWidth,
      XLEN}\n10: import xiangshan.backend.fu.NewCSR._\n11: import xiangshan.AddrTransType\n\
      12: \n13: class TrapEntryMNEventOutput extends Bundle with EventUpdatePrivStateOutput
      with EventOutputBase  {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryMNEvent.scala
    lines: 39-49
    context: "39:     hgatp,\n40:     in.trapPc,\n41:   )\n42:   out := DontCare\n\
      43: \n44:   out.privState.valid := valid\n45:   out.mnstatus.valid  := valid\n\
      46:   out.mnepc.valid     := valid\n47:   out.mncause.valid   := valid\n48:\
      \   out.targetPc.valid  := valid\n49: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSREvents/TrapEntryMNEvent.scala
    lines: 45-59
    context: "45:   out.mnstatus.valid  := valid\n46:   out.mnepc.valid     := valid\n\
      47:   out.mncause.valid   := valid\n48:   out.targetPc.valid  := valid\n49:\
      \ \n50:   out.privState.bits             := PrivState.ModeM\n51:   out.mnstatus.bits.MNPP\
      \         := current.privState.PRVM\n52:   out.mnstatus.bits.MNPV         :=
      current.privState.V\n53:   out.mnstatus.bits.NMIE         := 0.U\n54:   out.mnepc.bits.epc\
      \             := Mux(isFetchMalAddr, in.fetchMalTval(63, 1), trapPC(63, 1))\n\
      55:   out.mncause.bits.Interrupt     := isInterrupt\n56:   out.mncause.bits.ExceptionCode
      := highPrioTrapNO\n57:   out.targetPc.bits.pc           := in.pcFromXtvec\n\
      58:   out.targetPc.bits.raiseIPF     := false.B\n59:   out.targetPc.bits.raiseIAF\
      \     := AddrTransType(bare = true).checkAccessFault(in.pcFromXtvec)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRFields.scala
    lines: 111-121
    context: "111:   def rNoFilter: CSRRfnType = null\n112: \n113:   def rWithFilter(rFilter:
      (UInt, Seq[Data]) => UInt): CSRRfnType =\n114:     (oriV: UInt, seq: Seq[Data])
      => rFilter(oriV, seq)\n115: \n116:   def rFixValue(value: UInt): CSRRfnType
      = {\n117:     (_, _) => value\n118:   }\n119: }\n120: \n121: class CSREnumType("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRModule.scala
    lines: 24-34
    context: "24:   protected val reg = (if (bundle.needReset) RegInit(bundle, bundle.init)
      else Reg(bundle))\n25: \n26:   protected val wen = w.wen\n27:   protected val
      wdata = w.wdataFields\n28: \n29:   bundle.elements.foreach { case (str, field:
      CSREnumType) =>\n30:     val wfield = wdata.elements(str).asInstanceOf[CSREnumType]\n\
      31:     field.rwType match {\n32:       case WARLType(wfn, _) =>\n33:      \
      \   field.addOtherUpdate(wen && wfield.isLegal, wdata.elements(str).asInstanceOf[CSREnumType])\n\
      34:       case WLRLType(wfn, _) =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRModule.scala
    lines: 61-71
    context: "61:       field := field\n62:     }\n63:   }\n64: \n65:   private def
      wfn(reg: CSRBundle): Unit = {\n66:     reg.elements.foreach { case (str, field:
      CSREnumType) =>\n67:       if (!field.isRef) {\n68:         wfnField(field,
      str)\n69:       }\n70:     }\n71:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSROoORead.scala
    lines: 6-16
    context: "6:   /**\n7:    * \"Read only\" CSRs that can be fully pipelined when
      read in CSRR instruction.\n8:    * Only read by csr instructions.\n9:    */\n\
      10:   val waitForwardInOrderCsrReadList = List(\n11:     CSRs.fflags,\n12: \
      \    CSRs.fcsr,\n13:     CSRs.vxsat,\n14:     CSRs.vcsr,\n15:     CSRs.vstart,\n\
      16:     CSRs.sstatus,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSROoORead.scala
    lines: 13-23
    context: "13:     CSRs.vxsat,\n14:     CSRs.vcsr,\n15:     CSRs.vstart,\n16: \
      \    CSRs.sstatus,\n17:     CSRs.vsstatus,\n18:     CSRs.mstatus,\n19:     CSRs.hstatus,\n\
      20:     CSRs.mnstatus,\n21:     CSRs.dcsr,\n22:     CSRs.vtype,\n23:     CSRs.mireg,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/PMAEntryModule.scala
    lines: 27-37
    context: "27:   require(NumPMA >= 16, \"The number of PMA should be greater than
      or equal to 16.\")\n28: \n29:   val pmaAddrInit = VecInit(Seq.fill(p(PMParameKey).NumPMA)(0.U((PMPAddrWidth-PMPOffBits).W)))\n\
      30:   val pmaMaskInit = VecInit(Seq.fill(p(PMParameKey).NumPMA)(0.U(PMPAddrWidth.W)))\n\
      31: \n32:   pmaAddrInit.zip(pmaMaskInit).zip(pmaInit).foreach { case ((addr,
      mask), init) =>\n33:     addr := genAddr(init).U((PMPAddrWidth-PMPOffBits).W)\n\
      34:     mask := genMask(init.a, genAddr(init))\n35:   }\n36: \n37:   val pmaAddr
      = RegInit(pmaAddrInit)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRAIA.scala
    lines: 12-22
    context: "12: import xiangshan.XSBundle\n13: \n14: import scala.collection.immutable.SeqMap\n\
      15: \n16: trait CSRAIA { self: NewCSR with HypervisorLevel =>\n17:   val miselect
      = Module(new CSRModule(\"Miselect\", new MISelectBundle) with HasISelectBundle
      {\n18:     private val value = reg.ALL.asUInt\n19:     inIMSICRange := value
      >= 0x70.U && value < 0x100.U\n20:     isIllegal :=\n21:       value < 0x30.U
      ||\n22:       value >= 0x30.U && value < 0x40.U && value(0) === 1.U ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRAIA.scala
    lines: 21-31
    context: "21:       value < 0x30.U ||\n22:       value >= 0x30.U && value < 0x40.U
      && value(0) === 1.U ||\n23:       value >= 0x40.U && value < 0x70.U ||\n24:\
      \       value >= 0x100.U\n25:   })\n26:     .setAddr(CSRs.miselect)\n27: \n\
      28:   val mireg = Module(new CSRModule(\"Mireg\") with HasIregSink {\n29:  \
      \   rdata := iregRead.mireg\n30:   })\n31:     .setAddr(CSRs.mireg)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRAIA.scala
    lines: 156-166
    context: "156:   val siregiprios: Seq[CSRModule[_]] = Seq(siprio0, siprio2) ++:
      siprios\n157: \n158:   val iregiprios = miregiprios ++ siregiprios\n159: \n\
      160:   val aiaCSRMods = Seq(\n161:     miselect,\n162:     mireg,\n163:    \
      \ mtopei,\n164:     mtopi,\n165:     siselect,\n166:     sireg,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRAIA.scala
    lines: 179-189
    context: "179:   val aiaCSROutMap: SeqMap[Int, UInt] = SeqMap.from(\n180:    \
      \ aiaCSRMods.map(csr => (csr.addr -> csr.regOut.asInstanceOf[CSRBundle].asUInt)).iterator\n\
      181:   )\n182: \n183:   private val miregRData: UInt = Mux1H(\n184:     miregiprios.map(prio
      => (miselect.rdata.asUInt === prio.addr.U) -> prio.rdata)\n185:   )\n186: \n\
      187:   private val siregRData: UInt = Mux1H(\n188:     siregiprios.map(prio
      => (siselect.rdata.asUInt === prio.addr.U) -> prio.rdata)\n189:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRAIA.scala
    lines: 186-196
    context: "186: \n187:   private val siregRData: UInt = Mux1H(\n188:     siregiprios.map(prio
      => (siselect.rdata.asUInt === prio.addr.U) -> prio.rdata)\n189:   )\n190: \n\
      191:   aiaCSRMods.foreach { mod =>\n192:     mod match {\n193:       case m:
      HasIregSink =>\n194:         m.iregRead.mireg := miregRData\n195:         m.iregRead.sireg
      := siregRData\n196:         m.iregRead.vsireg := 0.U // Todo: IMSIC"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapTvalMod.scala
    lines: 9-19
    context: "9: import xiangshan.backend.rob.RobPtr\n10: \n11: class TrapTvalMod(implicit
      p: Parameters) extends XSModule with HasCircularQueuePtrHelper {\n12:   val
      io = IO(new Bundle {\n13:     val fromCtrlBlock = Input(new Bundle {\n14:  \
      \     val flush = ValidIO(new Redirect)\n15:       val robDeqPtr = Input(new
      RobPtr)\n16:     })\n17: \n18:     val targetPc = Input(ValidIO(new TargetPCBundle))\n\
      19:     val clear = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapTvalMod.scala
    lines: 22-33
    context: "22: \n23:   private val valid = RegInit(false.B)\n24:   private val
      tval = Reg(UInt(XLEN.W))\n25:   private val robIdx = Reg(new RobPtr)\n26: \n\
      27:   private val updateFromFlush = io.fromCtrlBlock.flush.valid && io.fromCtrlBlock.flush.bits.cfiUpdate.hasBackendFault\n\
      28:   private val clearFromFlush = io.fromCtrlBlock.flush.valid && !io.fromCtrlBlock.flush.bits.cfiUpdate.hasBackendFault\n\
      29: \n30:   when(io.targetPc.valid && io.targetPc.bits.raiseFault) {\n31:  \
      \   valid := true.B\n32:     tval := io.targetPc.bits.pc\n33:     robIdx :=
      io.fromCtrlBlock.robDeqPtr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapTvalMod.scala
    lines: 30-44
    context: "30:   when(io.targetPc.valid && io.targetPc.bits.raiseFault) {\n31:\
      \     valid := true.B\n32:     tval := io.targetPc.bits.pc\n33:     robIdx :=
      io.fromCtrlBlock.robDeqPtr\n34:   }.elsewhen(valid) {\n35:     when(updateFromFlush
      && isBefore(io.fromCtrlBlock.flush.bits.robIdx, robIdx)) {\n36:       valid
      := true.B\n37:       tval := io.fromCtrlBlock.flush.bits.fullTarget\n38:   \
      \    robIdx := io.fromCtrlBlock.flush.bits.robIdx\n39:     }.elsewhen(clearFromFlush
      && isBefore(io.fromCtrlBlock.flush.bits.robIdx, robIdx) || io.clear) {\n40:\
      \       valid := false.B\n41:     }\n42:   }.otherwise {\n43:     when(updateFromFlush)
      {\n44:       valid := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapTvalMod.scala
    lines: 40-51
    context: "40:       valid := false.B\n41:     }\n42:   }.otherwise {\n43:    \
      \ when(updateFromFlush) {\n44:       valid := true.B\n45:       tval := io.fromCtrlBlock.flush.bits.fullTarget\n\
      46:       robIdx := io.fromCtrlBlock.flush.bits.robIdx\n47:     }\n48:   }\n\
      49: \n50:   io.tval := tval\n51: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptBundle.scala
    lines: 580-590
    context: "580:   def getNonRW = getAll.filterNot(_.bits.isRW)\n581: \n582:   def
      getByNum(num: Int) = getAll.find(_.bits.lsb == num).get\n583: \n584:   def connectZeroNonRW
      : this.type = {\n585:     this.getNonRW.foreach(_.specifyField(\n586:      \
      \ _.valid := false.B,\n587:       _.bits  := DontCare\n588:     ))\n589:   \
      \  this\n590:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptBundle.scala
    lines: 684-694
    context: "684:   def getNonRW = getAll.filterNot(_.bits.isRW)\n685: \n686:   def
      getByNum(num: Int) = getAll.find(_.bits.lsb == num).get\n687: \n688:   def connectZeroNonRW
      : this.type = {\n689:     this.getNonRW.foreach(_.specifyField(\n690:      \
      \ _.valid := false.B,\n691:       _.bits  := DontCare,\n692:     ))\n693:  \
      \   this\n694:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/DebugLevel.scala
    lines: 97-107
    context: "97: \n98:   private val tdata2Rdata = Mux1H(\n99:     tdata2RegVec.zipWithIndex.map{case
      (mod, idx) => (tselect.rdata === idx.U) -> mod.rdata}\n100:   )\n101: \n102:\
      \   debugCSRMods.foreach { mod =>\n103:     mod match {\n104:       case m:
      HasTdataSink =>\n105:         m.tdataRead.tdata1 := tdata1Rdata\n106:      \
      \   m.tdataRead.tdata2 := tdata2Rdata\n107:       case _ =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRCustom.scala
    lines: 39-52
    context: "39:   // mcorepwr: Core Power Down Status Enable\n40:   val mcorepwr
      = Module(new CSRModule(\"Mcorepwr\", new McorepwrBundle))\n41:     .setAddr(0xBC0)\n\
      42: \n43:   // mflushpwr: Flush L2 Cache Enable\n44:   val mflushpwr = Module(new
      CSRModule(\"Mflushpwr\", new MflushpwrBundle)\n45:     with HasMachineFlushL2Bundle\n\
      46:   {\n47:     regOut.L2_FLUSH_DONE := l2FlushDone\n48:   })\n49:     .setAddr(0xBC1)\n\
      50: \n51:   val customCSRMods = Seq(\n52:     sbpctl,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRCustom.scala
    lines: 53-63
    context: "53:     spfctl,\n54:     slvpredctl,\n55:     smblockctl,\n56:     srnctl,\n\
      57:     mcorepwr,\n58:     mflushpwr,\n59:   )\n60: \n61:   val customCSRMap:
      SeqMap[Int, (CSRAddrWriteBundle[_ <: CSRBundle], UInt)] = SeqMap.from(\n62:\
      \     customCSRMods.map(csr => (csr.addr -> (csr.w -> csr.rdata))).iterator\n\
      63:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRCustom.scala
    lines: 107-117
    context: "107:   val HD_MISALIGN_ST_ENABLE            = RW(   8).withReset(true.B)\
      \  // Enable hardware store misalign.\n108:   val UNCACHE_WRITE_OUTSTANDING_ENABLE
      = RW(   7).withReset(false.B)  // Enable uncache write outstanding (0).\n109:\
      \   val CACHE_ERROR_ENABLE               = RW(   6).withReset(true.B)   // Enable
      cache error after reset (CE).\n110:   val SOFT_PREFETCH_ENABLE             =
      RW(   5).withReset(true.B)   // Enable soft-prefetch after reset (SP).\n111:\
      \   val LDLD_VIO_CHECK_ENABLE            = RW(   4).withReset(true.B)   // Enable
      load load violation check after reset (LVC).\n112:   val SBUFFER_THRESHOLD \
      \               = SbufferThreshold(3, 0).withReset(SbufferThreshold.initValue)
      // Store buffer flush threshold (Th).\n113: }\n114: \n115: class SrnctlBundle
      extends CSRBundle {\n116:   val WFI_ENABLE     = RW(2).withReset(true.B)\n117:\
      \   val FUSION_ENABLE  = RW(0).withReset(true.B)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRCustom.scala
    lines: 121-131
    context: "121:   val POWER_DOWN_ENABLE = RW(0).withReset(false.B)\n122: }\n123:\
      \ \n124: class MflushpwrBundle extends CSRBundle {\n125:   val FLUSH_L2_ENABLE
      = RW(0).withReset(false.B)\n126:   val L2_FLUSH_DONE   = RO(1).withReset(false.B)\n\
      127: }\n128: \n129: object SbufferThreshold extends CSREnum with RWApply {\n\
      130:   val initValue = Value(7.U)\n131: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Unprivileged.scala
    lines: 6-16
    context: "6: import utility.GatedValidRegNext\n7: import xiangshan.backend.fu.NewCSR.CSRDefines.{CSRROField
      => RO, CSRRWField => RW, CSRWARLField => WARL}\n8: import xiangshan.backend.fu.NewCSR.CSRFunc._\n\
      9: import xiangshan.backend.fu.vector.Bundles._\n10: import xiangshan.backend.fu.NewCSR.CSRConfig._\n\
      11: import xiangshan.backend.fu.fpu.Bundles.{Fflags, Frm}\n12: import xiangshan.backend.fu.NewCSR.CSREnumTypeImplicitCast._\n\
      13: \n14: import scala.collection.immutable.SeqMap\n15: \n16: trait Unprivileged
      { self: NewCSR with MachineLevel with SupervisorLevel =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Unprivileged.scala
    lines: 23-35
    context: "23:     val NV = WARL(4, wNoFilter)\n24:     val FRM = WARL(7, 5, wNoFilter).withReset(0.U)\n\
      25:   }) with HasRobCommitBundle {\n26:     val wAliasFflags = IO(Input(new
      CSRAddrWriteBundle(new CSRFFlagsBundle)))\n27:     val wAliasFfm = IO(Input(new
      CSRAddrWriteBundle(new CSRFrmBundle)))\n28:     val fflags = IO(Output(Fflags()))\n\
      29:     val frm = IO(Output(Frm()))\n30:     val fflagsRdata = IO(Output(Fflags()))\n\
      31:     val frmRdata = IO(Output(Frm()))\n32: \n33:     for (wAlias <- Seq(wAliasFflags,
      wAliasFfm)) {\n34:       for ((name, field) <- wAlias.wdataFields.elements)
      {\n35:         reg.elements(name).asInstanceOf[CSREnumType].addOtherUpdate("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Unprivileged.scala
    lines: 40-62
    context: "40:     }\n41: \n42:     // write connection\n43:     reconnectReg()\n\
      44: \n45:     when (robCommit.fflags.valid) {\n46:       reg.NX := robCommit.fflags.bits(0)
      || reg.NX\n47:       reg.UF := robCommit.fflags.bits(1) || reg.UF\n48:     \
      \  reg.OF := robCommit.fflags.bits(2) || reg.OF\n49:       reg.DZ := robCommit.fflags.bits(3)
      || reg.DZ\n50:       reg.NV := robCommit.fflags.bits(4) || reg.NV\n51:     }\n\
      52: \n53:     // read connection\n54:     fflags := reg.asUInt(4, 0)\n55:  \
      \   frm := reg.FRM.asUInt\n56: \n57:     fflagsRdata := fflags.asUInt\n58: \
      \    frmRdata := frm.asUInt\n59:   }).setAddr(CSRs.fcsr)\n60: \n61:   // vec\n\
      62:   val vstart = Module(new CSRModule(\"Vstart\", new CSRBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Unprivileged.scala
    lines: 66-79
    context: "66:   }) with HasRobCommitBundle {\n67:     // Todo make The use of
      vstart values greater than the largest element index for the current SEW setting
      is reserved.\n68:     // Not trap\n69:     when (wen) {\n70:       reg.vstart
      := this.w.wdata(VlWidth - 2, 0)\n71:     }.elsewhen (robCommit.vsDirty && !robCommit.vstart.valid)
      {\n72:       reg.vstart := 0.U\n73:     }.elsewhen (robCommit.vstart.valid)
      {\n74:       reg.vstart := robCommit.vstart.bits\n75:     }.otherwise {\n76:\
      \       reg := reg\n77:     }\n78:   })\n79:     .setAddr(CSRs.vstart)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Unprivileged.scala
    lines: 101-112
    context: "101:     }\n102: \n103:     // write connection\n104:     reconnectReg()\n\
      105: \n106:     when(robCommit.vxsat.valid) {\n107:       reg.VXSAT := reg.VXSAT.asBool
      || robCommit.vxsat.bits.asBool\n108:     }\n109: \n110:     // read connection\n\
      111:     vxsat := reg.VXSAT.asUInt\n112:     vxrm  := reg.VXRM.asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Unprivileged.scala
    lines: 116-127
    context: "116:     val VL = RO(VlWidth - 1, 0).withReset(0.U)\n117:   }))\n118:\
      \     .setAddr(CSRs.vl)\n119: \n120:   val vtype = Module(new CSRModule(\"Vtype\"\
      , new CSRVTypeBundle) with HasRobCommitBundle {\n121:     when(robCommit.vtype.valid)
      {\n122:       reg := robCommit.vtype.bits\n123:     }\n124:   })\n125:     .setAddr(CSRs.vtype)\n\
      126: \n127:   val vlenb = Module(new CSRModule(\"Vlenb\", new CSRBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Unprivileged.scala
    lines: 191-201
    context: "191:       regOut := Mux(debugModeStopCount, reg.asUInt, mHPM.hpmcounters(num
      - 3))\n192:     }).setAddr(CSRs.cycle + num)\n193:   )\n194: \n195:   val unprivilegedCSRMap:
      SeqMap[Int, (CSRAddrWriteBundle[_], UInt)] = SeqMap(\n196:     CSRs.fflags ->
      (fcsr.wAliasFflags -> fcsr.fflagsRdata),\n197:     CSRs.frm    -> (fcsr.wAliasFfm\
      \    -> fcsr.frmRdata),\n198:     CSRs.fcsr   -> (fcsr.w            -> fcsr.rdata),\n\
      199:     CSRs.vstart -> (vstart.w          -> vstart.rdata),\n200:     CSRs.vxsat\
      \  -> (vcsr.wAliasVxsat  -> vcsr.vxsat),\n201:     CSRs.vxrm   -> (vcsr.wAliasVxrm\
      \   -> vcsr.vxrm),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Unprivileged.scala
    lines: 219-229
    context: "219:     time,\n220:     instret,\n221:   ) ++ hpmcounters\n222: \n\
      223:   val unprivilegedCSROutMap: SeqMap[Int, UInt] = SeqMap(\n224:     CSRs.fflags\
      \  -> fcsr.fflags.asUInt,\n225:     CSRs.frm     -> fcsr.frm.asUInt,\n226: \
      \    CSRs.fcsr    -> fcsr.rdata.asUInt,\n227:     CSRs.vstart  -> vstart.rdata.asUInt,\n\
      228:     CSRs.vxsat   -> vcsr.vxsat.asUInt,\n229:     CSRs.vxrm    -> vcsr.vxrm.asUInt,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CommitIDModule.scala
    lines: 20-30
    context: "20:       |  input dirty\n21:       |);\n22:       |  wire _dummy_unused
      = 1'b1;\n23:       |`ifndef SYNTHESIS\n24:       |  initial begin\n25:     \
      \  |    $$fwrite(32'h80000001, \"Core %d's Commit SHA is: %h, dirty: %d\\\\\
      n\", hartID, commitID, dirty);\n26:       |  end\n27:       |`endif\n28:   \
      \    |\n29:       |endmodule\n30:       |\"\"\".stripMargin"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRBundle.scala
    lines: 46-56
    context: "46: \n47:   @inline\n48:   def init: this.type = {\n49:     val init
      = Wire(this)\n50:     suppressEnumCastWarning {\n51:       init.elements.foreach
      { case (str, field: CSREnumType) =>\n52:         field := (if (field.init !=
      null) field.factory(field.init.asUInt) else field.factory(0.U))\n53:       }\n\
      54:     }\n55:     init.asInstanceOf[this.type]\n56:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRBundle.scala
    lines: 86-96
    context: "86:   }\n87: \n88:   override def cloneType: CSRBundle.this.type = {\n\
      89:     val ret = super.cloneType\n90:     //\n91:     (ret.getFields zip this.getFields).foreach
      { case (l, r) =>\n92:       if (this.eventFields.contains(r)) {\n93:       \
      \  ret.eventFields += l\n94:       }\n95:     }\n96:     ret"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRBundle.scala
    lines: 154-162
    context: "154: }\n155: \n156: object ChiselRecordForField {\n157:   implicit class
      AddRecordSpecifyFields[T <: Record](val x: T) {\n158:     def specifyField(elemFns:
      (T => Unit)*): Unit = {\n159:       elemFns.foreach(_.apply(x))\n160:     }\n\
      161:   }\n162: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Debug.scala
    lines: 2-12
    context: "2: \n3: import chisel3._\n4: import chisel3.util._\n5: import org.chipsalliance.cde.config.Parameters\n\
      6: import xiangshan.cache.HasDCacheParameters\n7: import xiangshan.backend.fu.NewCSR.CSRBundles.PrivState\n\
      8: import xiangshan.backend.fu.util.SdtrigExt\n9: import xiangshan._\n10: import
      utils._\n11: \n12: class Debug(implicit val p: Parameters) extends Module with
      HasXSParameter {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Debug.scala
    lines: 18-28
    context: "18:   private val isDebugIntr     = trapInfo.bits.isDebugIntr\n19: \
      \  private val trapVec         = trapInfo.bits.trapVec\n20:   private val singleStep\
      \      = trapInfo.bits.singleStep\n21:   private val trigger         = io.in.trapInfo.bits.trigger\n\
      22: \n23:   private val privState = io.in.privState\n24:   private val debugMode
      = io.in.debugMode\n25: \n26:   private val dcsr = io.in.dcsr\n27:   private
      val tselect = io.in.tselect\n28:   private val tdata1Selected = io.in.tdata1Selected"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Debug.scala
    lines: 48-62
    context: "48:   // debug_exception_ebreak\n49:   val hasExp = hasTrap && !trapIsInterrupt\n\
      50:   val breakPoint = trapVec(ExceptionNO.breakPoint).asBool\n51:   val isEbreak
      = hasExp && breakPoint && !TriggerAction.isExp(trigger)\n52:   val ebreakEnterDebugMode
      =\n53:     (privState.isModeM && dcsr.EBREAKM.asBool) ||\n54:       (privState.isModeHS
      && dcsr.EBREAKS.asBool) ||\n55:       (privState.isModeHU && dcsr.EBREAKU.asBool)
      ||\n56:       (privState.isModeVS && dcsr.EBREAKVS.asBool) ||\n57:       (privState.isModeVU
      && dcsr.EBREAKVU.asBool)\n58:   val hasDebugEbreakException = isEbreak && ebreakEnterDebugMode\n\
      59: \n60:   // debug_exception_trigger\n61:   val mcontrol6WireVec = tdata1Vec.map{
      mod => {\n62:     val mcontrol6Wire = Wire(new Mcontrol6)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Debug.scala
    lines: 99-113
    context: "99:     tdata1Update && tdata1TypeWdata.isLegal && mcontrol6Wdata.isMemAccTrigger
      ||\n100:       mcontrol6Selected.isMemAccTrigger && triggerUpdate\n101: \n102:\
      \   val triggerEnableVec = tdata1Vec.zip(mcontrol6WireVec).map { case(tdata1,
      mcontrol6) =>\n103:     tdata1.TYPE.isLegal && (\n104:       mcontrol6.M &&
      privState.isModeM  ||\n105:         mcontrol6.S && privState.isModeHS ||\n106:\
      \         mcontrol6.U && privState.isModeHU ||\n107:         mcontrol6.VS &&
      privState.isModeVS ||\n108:         mcontrol6.VU && privState.isModeVU)\n109:\
      \   }\n110: \n111:   val fetchTriggerEnableVec = triggerEnableVec.zip(mcontrol6WireVec).map
      {\n112:     case (tEnable, mod) => tEnable && mod.isFetchTrigger\n113:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Debug.scala
    lines: 150-160
    context: "150:       val singleStep = Bool()\n151:       val trigger = TriggerAction()\n\
      152:       val criticalErrorState = Bool()\n153:     })\n154: \n155:     val
      privState = new PrivState\n156:     val debugMode = Bool()\n157: \n158:    \
      \ val dcsr = new DcsrBundle\n159:     val tselect = new TselectBundle(TriggerNum)\n\
      160:     val tdata1Selected = new Tdata1Bundle"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/VirtualSupervisorLevel.scala
    lines: 26-41
    context: "26:       with DretEventSinkBundle\n27:       with TrapEntryVSEventSinkBundle\n\
      28:       with HasRobCommitBundle\n29:       with HasVirtualSupervisorEnvBundle\n\
      30:     {\n31:       when ((robCommit.fsDirty || writeFCSR) && isVirtMode) {\n\
      32:         assert(reg.FS =/= ContextStatus.Off, \"The vsstatus.FS should not
      be Off when set dirty, please check decode\")\n33:         reg.FS := ContextStatus.Dirty\n\
      34:       }\n35: \n36:       when ((robCommit.vsDirty || writeVCSR || robCommit.vstart.valid
      && robCommit.vstart.bits =/= 0.U) && isVirtMode) {\n37:         assert(reg.VS
      =/= ContextStatus.Off, \"The vsstatus.VS should not be Off when set dirty, please
      check decode\")\n38:         reg.VS := ContextStatus.Dirty\n39:       }\n40:\
      \       // when menvcfg or henvcfg.DTE close,  vsstatus.SDT is read-only\n41:\
      \       val writeSDT = Wire(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/VirtualSupervisorLevel.scala
    lines: 69-79
    context: "69: \n70:     regOut :=\n71:       shiftedIE |\n72:       (shiftedUsingReg
      & reg)\n73: \n74:     bundle.getVS.map(_.lsb).foreach { vsNum =>\n75:      \
      \ // vsie.SSIE(1) map mie.VSSIE(1)\n76:       val sNum = vsNum - 1\n77:    \
      \   val wtMie = toMie.getByNum(vsNum)\n78:       val wtSie = toSie.getByNum(vsNum)\n\
      79:       val r = reg(sNum)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/VirtualSupervisorLevel.scala
    lines: 93-103
    context: "93:       }.otherwise {\n94:         r := r\n95:       }\n96:     }\n\
      97: \n98:     bundle.getNonVS.map(_.lsb).foreach { num =>\n99:       val wtMie
      = toMie.getByNum(num)\n100:       val wtSie = toSie.getByNum(num)\n101: \n102:\
      \       val r = reg(num)\n103: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/VirtualSupervisorLevel.scala
    lines: 116-126
    context: "116:       }.otherwise {\n117:         r := r\n118:       }\n119:  \
      \   }\n120: \n121:     regOut.getFields.foreach { field =>\n122:       if (field.isHardWired)
      {\n123:         field := field.getHardWireValue\n124:       }\n125:     }\n\
      126:   }).setAddr(CSRs.vsie)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/VirtualSupervisorLevel.scala
    lines: 160-171
    context: "160: \n161:     val originIP = mideleg & hideleg & mip | (~mideleg &
      hideleg & mvien & mvip) | (~hideleg & hvien & hvip)\n162:     val shiftedIP
      = Cat(originIP(63, InterruptNO.COI), 0.U(1.W), originIP(InterruptNO.SGEI, InterruptNO.SSI))\n\
      163: \n164:     regOut := shiftedIP\n165:     regOut.getM.foreach(_ := 0.U)\n\
      166:     regOut.getVS.foreach(_ := 0.U)\n167:     regOut.SGEIP := 0.U\n168:\
      \ \n169:     toHvip.VSSIP.valid := wen && hideleg.VSSI\n170:     toHvip.VSSIP.bits\
      \  := wdata.SSIP\n171: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/VirtualSupervisorLevel.scala
    lines: 169-179
    context: "169:     toHvip.VSSIP.valid := wen && hideleg.VSSI\n170:     toHvip.VSSIP.bits\
      \  := wdata.SSIP\n171: \n172:     wdata.getLocal lazyZip\n173:       (toMip.getLocal
      lazyZip toMvip.getLocal lazyZip toHvip.getLocal) lazyZip\n174:       (mideleg.getLocal
      lazyZip hideleg.getLocal lazyZip mvien.getLocal lazyZip hvien.getLocal) foreach
      {\n175:         case (wLCIP, (toMipLCIP, toMvipLCIP, toHvipLCIP), (midelegBit,
      hidelegBit, mvienBit, hvienBit)) =>\n176:           toMipLCIP .valid := wen
      &&  hidelegBit &&  midelegBit\n177:           toMvipLCIP.valid := wen &&  hidelegBit
      && !midelegBit &&  mvienBit\n178:           toHvipLCIP.valid := wen && !hidelegBit
      &&                 hvienBit\n179:           toMipLCIP .bits := wLCIP"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/VirtualSupervisorLevel.scala
    lines: 179-189
    context: "179:           toMipLCIP .bits := wLCIP\n180:           toMvipLCIP.bits
      := wLCIP\n181:           toHvipLCIP.bits := wLCIP\n182:     }\n183: \n184: \
      \    regOut.getFields.foreach { field =>\n185:       if (field.isHardWired)
      {\n186:         field := field.getHardWireValue\n187:       }\n188:     }\n\
      189:   }).setAddr(CSRs.vsip)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/VirtualSupervisorLevel.scala
    lines: 234-244
    context: "234:     vsip,\n235:     vstimecmp,\n236:     vsatp,\n237:   )\n238:\
      \ \n239:   virtualSupervisorCSRMods.foreach(mod =>\n240:     require(mod.addr
      > 0, s\"The address of ${mod.modName} has not been set, you can use setAddr(CSRAddr)
      to set it.\"))\n241: \n242:   val virtualSupervisorCSRMap: SeqMap[Int, (CSRAddrWriteBundle[_],
      UInt)] = SeqMap.from(\n243:     virtualSupervisorCSRMods.map(csr => (csr.addr
      -> (csr.w -> csr.rdata)))\n244:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/VirtualSupervisorLevel.scala
    lines: 269-307
    context: "269:   val vsMapS: SeqMap[Int, Int] = SeqMap.from(sMapVS.map(x => (x._2
      -> x._1)))\n270: }\n271: \n272: class VSipBundle extends InterruptPendingBundle
      {\n273:   // All pending bits in vsip are aliases of mip/mvip/hvip or read-only
      0\n274:   this.getM.foreach(_.setHardWired(0.U))\n275:   this.getVS.foreach(_.setHardWired(0.U))\n\
      276:   this.SGEIP.setHardWired(0.U)\n277: }\n278: \n279: class VSieBundle extends
      InterruptEnableBundle {\n280:   this.getLocal.foreach(_.setRW().withReset(0.U))\n\
      281:   this.getM .foreach(_.setHardWired(0.U))\n282:   this.getVS.foreach(_.setHardWired(0.U))\n\
      283:   this.SGEIE.setHardWired(0.U)\n284: }\n285: \n286: class VSipToMvip extends
      IpValidBundle {\n287:   this.getLocal.foreach(_.bits.setRW())\n288: }\n289:\
      \ \n290: class VSipToHvip extends IpValidBundle {\n291:   this.VSSIP.bits.setRW()\n\
      292:   this.getLocal.foreach(_.bits.setRW())\n293: }\n294: \n295: class VSieToMie
      extends IeValidBundle {\n296:   this.getVS.foreach(_.bits.setRW())\n297:   this.getLocal.foreach(_.bits.setRW())\n\
      298: }\n299: \n300: class VSieToSie extends IeValidBundle {\n301:   this.getVS.foreach(_.bits.setRW())\n\
      302:   this.getLocal.foreach(_.bits.setRW())\n303: }\n304: \n305: class VSipToHip
      extends Bundle {\n306:   val SSIP = ValidIO(RW(0))\n307:   val STIP = ValidIO(RW(0))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRIND.scala
    lines: 123-133
    context: "123:   def isInOthers(iselect: UInt): Bool = !(isInAIA(iselect) || isInImsic(iselect))\n\
      124:   def isOdd(iselect: UInt): Bool = iselect(0) === 1.U\n125: }\n126: \n\
      127: object Ireg {\n128:   def isInMCsrInd(ireg: UInt): Bool = ireg >= CSRs.miselect.U
      && ireg <= CSRs.mireg6.U && ireg =/= CSRs.miph.U\n129:   def isInSCsrInd(ireg:
      UInt): Bool = ireg >= CSRs.siselect.U && ireg <= CSRs.sireg6.U && ireg =/= CSRs.siph.U\n\
      130:   def isInVSCsrInd(ireg: UInt): Bool = ireg >= CSRs.vsiselect.U && ireg
      <= CSRs.vsireg6.U && ireg =/= CSRs.vsiph.U\n131:   def isInMiregX(ireg: UInt):
      Bool = ireg >= CSRs.mireg.U && ireg <= CSRs.mireg6.U && ireg =/= CSRs.miph.U\n\
      132:   def isInSiregX(ireg: UInt): Bool = ireg >= CSRs.sireg.U && ireg <= CSRs.sireg6.U
      && ireg =/= CSRs.siph.U\n133:   def isInVSiregX(ireg: UInt): Bool = ireg >=
      CSRs.vsireg.U && ireg <= CSRs.vsireg6.U && ireg =/= CSRs.vsiph.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRBundles.scala
    lines: 4-14
    context: "4: import chisel3.util._\n5: import chisel3.experimental.BundleLiterals._\n\
      6: import org.chipsalliance.cde.config.Parameters\n7: import xiangshan.backend.fu.NewCSR.CSRDefines.{CSRROField
      => RO, CSRRWField => RW, CSRWARLField => WARL, _}\n8: import xiangshan.backend.fu.NewCSR.CSRFunc._\n\
      9: import xiangshan.backend.fu.fpu.Bundles.Fflags\n10: import xiangshan.backend.fu.vector.Bundles.{Vl,
      Vstart, Vxsat}\n11: import xiangshan.frontend.BPUCtrl\n12: import xiangshan.mem.prefetch.PrefetchCtrl\n\
      13: import chisel3.experimental.noPrefix\n14: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRBundles.scala
    lines: 56-66
    context: "56:     val SSE   =      RO(     3)           .withReset(0.U) // Zicfiss
      extension Enable in S mode\n57:     val LPE   =      RO(     2)           .withReset(0.U)
      // Zicfilp extension\n58:     val FIOM  =      RO(     0)           .withReset(0.U)
      // Fence of I/O implies Memory\n59:   }\n60: \n61:   class PrivState extends
      Bundle { self =>\n62:     val PRVM = PrivMode(0)\n63:     val V    = VirtMode(0)\n\
      64: \n65:     def isModeM: Bool = isModeMImpl()\n66: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRBundles.scala
    lines: 118-133
    context: "118:       def apply(): Bool = v\n119:     }\n120: \n121:     // VU
      < VS < HS < M\n122:     // HU < HS < M\n123:     def < (that: PrivState): Bool
      = {\n124:       (this.isVirtual && (that.isModeM || that.isModeHS)) ||\n125:\
      \         (this.V === that.V && this.PRVM < that.PRVM)\n126:     }\n127: \n\
      128:     def > (that: PrivState): Bool = {\n129:       (that.isVirtual && (this.isModeM
      || this.isModeHS)) ||\n130:         (that.V === this.V && that.PRVM < this.PRVM)\n\
      131:     }\n132:   }\n133: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRBundles.scala
    lines: 129-160
    context: "129:       (that.isVirtual && (this.isModeM || this.isModeHS)) ||\n\
      130:         (that.V === this.V && that.PRVM < this.PRVM)\n131:     }\n132:\
      \   }\n133: \n134:   object PrivState {\n135:     def ModeM: PrivState = WireInit((new
      PrivState).Lit(\n136:       _.PRVM -> PrivMode.M,\n137:       _.V    -> VirtMode.Off,\n\
      138:     ))\n139: \n140:     def ModeHS: PrivState = WireInit((new PrivState).Lit(\n\
      141:       _.PRVM -> PrivMode.S,\n142:       _.V    -> VirtMode.Off,\n143: \
      \    ))\n144: \n145:     def ModeHU: PrivState = WireInit((new PrivState).Lit(\n\
      146:       _.PRVM -> PrivMode.U,\n147:       _.V    -> VirtMode.Off,\n148: \
      \    ))\n149: \n150:     def ModeVS: PrivState = WireInit((new PrivState).Lit(\n\
      151:       _.PRVM -> PrivMode.S,\n152:       _.V    -> VirtMode.On,\n153:  \
      \   ))\n154: \n155:     def ModeVU: PrivState = WireInit((new PrivState).Lit(\n\
      156:       _.PRVM -> PrivMode.U,\n157:       _.V    -> VirtMode.On,\n158:  \
      \   ))\n159:   }\n160: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRBundles.scala
    lines: 159-169
    context: "159:   }\n160: \n161:   class RobCommitCSR(implicit p: Parameters) extends
      Bundle {\n162:     // need contain 8x8\n163:     val instNum = ValidIO(UInt(7.W))\n\
      164:     val fflags  = ValidIO(Fflags())\n165:     val fsDirty = Bool()\n166:\
      \     val vxsat   = ValidIO(Vxsat())\n167:     val vsDirty = Bool()\n168:  \
      \   val vtype   = ValidIO(new CSRVTypeBundle)\n169:     val vl      = Vl()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapHandleModule.scala
    lines: 1-11
    context: "1: package xiangshan.backend.fu.NewCSR\n2: \n3: import chisel3._\n4:
      import chisel3.util._\n5: import xiangshan.ExceptionNO\n6: import xiangshan.backend.fu.NewCSR.CSRBundles.{CauseBundle,
      PrivState, XtvecBundle}\n7: import xiangshan.backend.fu.NewCSR.CSRDefines.XtvecMode\n\
      8: import xiangshan.backend.fu.NewCSR.CSRBundleImplicitCast._\n9: \n10: \n11:
      class TrapHandleModule extends Module {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapHandleModule.scala
    lines: 10-21
    context: "10: \n11: class TrapHandleModule extends Module {\n12:   val io = IO(new
      TrapHandleIO)\n13: \n14:   private val trapInfo = io.in.trapInfo\n15:   private
      val privState = io.in.privState\n16:   private val mstatus  = io.in.mstatus\n\
      17:   private val vsstatus = io.in.vsstatus\n18:   private val mnstatus = io.in.mnstatus\n\
      19:   private val mideleg = io.in.mideleg.asUInt\n20:   private val hideleg
      = io.in.hideleg.asUInt\n21:   private val medeleg = io.in.medeleg.asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapHandleModule.scala
    lines: 35-45
    context: "35: \n36:   private val irToHS = io.in.trapInfo.bits.irToHS\n37:   private
      val irToVS = io.in.trapInfo.bits.irToVS\n38: \n39:   private val highestPrioEXVec
      = Wire(Vec(64, Bool()))\n40:   highestPrioEXVec.zipWithIndex.foreach { case
      (excp, i) =>\n41:     if (ExceptionNO.priorities.contains(i)) {\n42:       val
      higherEXSeq = ExceptionNO.getHigherExcpThan(i)\n43:       excp := (\n44:   \
      \      higherEXSeq.nonEmpty.B && Cat(higherEXSeq.map(num => !hasEXVec(num))).andR
      ||\n45:         higherEXSeq.isEmpty.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapHandleModule.scala
    lines: 66-77
    context: "66: \n67:   private val  mHasTrap =  mHasEX ||  mHasIR\n68:   private
      val hsHasTrap = hsHasEX || hsHasIR\n69:   private val vsHasTrap = vsHasEX ||
      vsHasIR\n70: \n71:   private val handleTrapUnderHS = !privState.isModeM && hsHasTrap\n\
      72:   private val handleTrapUnderVS = privState.isVirtual && vsHasTrap\n73:\
      \   private val handleTrapUnderM = !handleTrapUnderVS && !handleTrapUnderHS\n\
      74: \n75:   // Todo: support more interrupt and exception\n76:   private val
      exceptionRegular = OHToUInt(highestPrioEX)\n77:   private val interruptNO =
      highestPrioIR"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapHandleModule.scala
    lines: 78-89
    context: "78:   private val exceptionNO = Mux(trapInfo.bits.singleStep, ExceptionNO.breakPoint.U,
      exceptionRegular)\n79: \n80:   private val causeNO = Mux(hasIR, interruptNO,
      exceptionNO)\n81: \n82:   // sm/ssdbltrp\n83:   private val m_EX_DT  = handleTrapUnderM\
      \  && mstatus.MDT.asBool  && hasTrap\n84:   private val s_EX_DT  = handleTrapUnderHS
      && mstatus.SDT.asBool  && hasTrap\n85:   private val vs_EX_DT = handleTrapUnderVS
      && vsstatus.SDT.asBool && hasTrap\n86: \n87:   private val dbltrpToMN = m_EX_DT
      && mnstatus.NMIE.asBool // NMI not allow double trap\n88:   private val hasDTExcp\
      \  = m_EX_DT || s_EX_DT || vs_EX_DT\n89: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapHandleModule.scala
    lines: 99-111
    context: "99:     interruptNO - 1.U, // map VSSIP, VSTIP, VSEIP to SSIP, STIP,
      SEIP\n100:     interruptNO,\n101:   )\n102:   private val pcFromXtvec = Cat(xtvec.addr.asUInt
      + Mux(xtvec.mode === XtvecMode.Vectored && hasIR, adjustinterruptNO(5, 0), 0.U),
      0.U(2.W))\n103: \n104:   io.out.entryPrivState := MuxCase(default = PrivState.ModeM,
      mapping = Seq(\n105:     traptoVS -> PrivState.ModeVS,\n106:     trapToHS ->
      PrivState.ModeHS,\n107:   ))\n108: \n109:   io.out.causeNO.Interrupt := hasIR\n\
      110:   io.out.causeNO.ExceptionCode := causeNO\n111:   io.out.pcFromXtvec :=
      pcFromXtvec"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapHandleModule.scala
    lines: 124-135
    context: "124:       val singleStep = Bool()\n125:       // trap to x mode\n126:\
      \       val irToHS = Bool()\n127:       val irToVS = Bool()\n128:     })\n129:\
      \     val privState = new PrivState\n130:     val mstatus = new MstatusBundle\n\
      131:     val vsstatus = new SstatusBundle\n132:     val mnstatus = new MnstatusBundle\n\
      133:     val mideleg = new MidelegBundle\n134:     val medeleg = new MedelegBundle\n\
      135:     val hideleg = new HidelegBundle"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapHandleModule.scala
    lines: 141-151
    context: "141:     val stvec = Input(new XtvecBundle)\n142:     val vstvec = Input(new
      XtvecBundle)\n143:   })\n144: \n145:   val out = new Bundle {\n146:     val
      entryPrivState = new PrivState\n147:     val causeNO = new CauseBundle\n148:\
      \     val dbltrpToMN = Bool()\n149:     val hasDTExcp = Bool()\n150:     val
      pcFromXtvec = UInt(64.W)\n151:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/HypervisorLevel.scala
    lines: 26-36
    context: "26: \n27:   val hideleg = Module(new CSRModule(\"Hideleg\", new HidelegBundle)\n\
      28:     with HasIpIeBundle\n29:   {\n30:     regOut := reg & mideleg\n31:  \
      \   regOut.getLocal.zip(reg.getLocal).zip(mideleg.getLocal).zip(mvien.getLocal).foreach
      {\n32:       case (((regOutLCI, regLCI), midelegLCI), mvienLCI) =>\n33:    \
      \     regOutLCI := regLCI && (midelegLCI || mvienLCI)\n34:     }\n35:   })\n\
      36:     .setAddr(CSRs.hideleg)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/HypervisorLevel.scala
    lines: 41-51
    context: "41:   {\n42:     val toMie = IO(new HieToMie)\n43: \n44:     val mieIsAlias
      = mideleg\n45: \n46:     bundle.getFields.map(_.lsb).foreach { num =>\n47: \
      \      val wtMie  = toMie.getByNum(num)\n48:       wtMie.specifyField(\n49:\
      \         _.valid := wen && mieIsAlias(num) && wtMie.bits.isRW.B,\n50:     \
      \    _.bits  := wen && mieIsAlias(num) && wtMie.bits.isRW.B &< wdata(num),\n\
      51:       )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/HypervisorLevel.scala
    lines: 119-129
    context: "119:         fromHip.VSSIP.valid -> fromHip.VSSIP.bits,\n120:      \
      \   fromVSip.VSSIP.valid -> fromVSip.VSSIP.bits,\n121:       ))\n122:     }\n\
      123: \n124:     reg.getLocal zip fromVSip.getLocal foreach { case (rLCIP, vsipLCIP)
      =>\n125:       // sip should assert valid when hideleg=0 && hvien=1\n126:  \
      \     when(vsipLCIP.valid) {\n127:         rLCIP := vsipLCIP.bits\n128:    \
      \   }\n129:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/HypervisorLevel.scala
    lines: 168-190
    context: "168:     .setAddr(CSRs.hgeip)\n169: \n170:   val hstateen0 = Module(new
      CSRModule(\"Hstateen0\", new Hstateen0Bundle) with HasStateenBundle {\n171:\
      \     // For every bit in an mstateen CSR that is zero (whether read-only zero
      or set to zero), the same bit\n172:     // appears as read-only zero in the
      matching hstateen and sstateen CSRs.\n173:     regOut := reg.asUInt & fromMstateen0.asUInt\n\
      174:   }).setAddr(CSRs.hstateen0)\n175: \n176:   val hstateen1 = Module(new
      CSRModule(\"Hstateen1\", new HstateenNonZeroBundle) with HasStateenBundle {\n\
      177:     regOut := reg.asUInt & fromMstateen1.asUInt\n178:   }).setAddr(CSRs.hstateen1)\n\
      179: \n180:   val hstateen2 = Module(new CSRModule(\"Hstateen2\", new HstateenNonZeroBundle)
      with HasStateenBundle {\n181:     regOut := reg.asUInt & fromMstateen2.asUInt\n\
      182:   }).setAddr(CSRs.hstateen2)\n183: \n184:   val hstateen3 = Module(new
      CSRModule(\"Hstateen3\", new HstateenNonZeroBundle) with HasStateenBundle {\n\
      185:     regOut := reg.asUInt & fromMstateen3.asUInt\n186:   }).setAddr(CSRs.hstateen3)\n\
      187: \n188:   val hcontext = Module(new CSRModule(\"Hcontext\", new McontextBundle)
      {\n189:     val fromMcontext = IO(Input(new McontextBundle))\n190:     val toMcontext\
      \   = IO(ValidIO(new McontextBundle))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/HypervisorLevel.scala
    lines: 250-261
    context: "250:   with SretEventSinkBundle\n251:   with TrapEntryHSEventSinkBundle\n\
      252: \n253: class HvipBundle extends InterruptPendingBundle {\n254:   // VSSIP,
      VSTIP, VSEIP, localIP is writable\n255:   this.getVS.foreach(_.setRW().withReset(0.U))\n\
      256:   this.getLocal.foreach(_.setRW().withReset(0.U))\n257:   this.LCOFIP.setRO().withReset(0.U)\n\
      258: }\n259: \n260: class HieBundle extends InterruptEnableBundle {\n261:  \
      \ // All bits in hie are RO, since all registers implemented in mie."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/HypervisorLevel.scala
    lines: 271-281
    context: "271: class HvienBundle extends InterruptEnableBundle {\n272:   // Ref:
      riscv interrupt spec - 6.3.2 Virtual interrupts for VS level\n273:   // Bits
      12:0 of hvien are reserved and must be read-only zeros.\n274:   // For interrupt
      numbers 1363, implementations may freely choose which bits of hvien are writable\n\
      275:   // and which bits are read-only zero or one.\n276:   this.getLocal.foreach(_.setRW().withReset(0.U))\n\
      277:   this.LCOFIE.setRO().withReset(0.U)\n278: }\n279: \n280: class HgeieBundle(implicit
      val p: Parameters) extends CSRBundle with HasSoCParameter {\n281:   val ie =
      RW(soc.IMSICParams.geilen, 1).withReset(0.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/HypervisorLevel.scala
    lines: 286-296
    context: "286:   val ip = RO(soc.IMSICParams.geilen, 1)\n287:   // bit 0 is read
      only 0\n288: }\n289: \n290: class HedelegBundle extends ExceptionBundle {\n\
      291:   this.getALL.foreach(_.setRW().withReset(0.U))\n292:   // The default
      configs are RW\n293:   this.EX_HSCALL.setRO().withReset(0.U)\n294:   this.EX_VSCALL.setRO().withReset(0.U)\n\
      295:   this.EX_MCALL .setRO().withReset(0.U)\n296:   this.EX_IGPF  .setRO().withReset(0.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/HypervisorLevel.scala
    lines: 299-309
    context: "299:   this.EX_SGPF  .setRO().withReset(0.U)\n300:   this.EX_DBLTRP.setRO().withReset(0.U)
      // double trap is not delegatable\n301: }\n302: \n303: class HidelegBundle extends
      InterruptBundle {\n304:   this.getALL.foreach(_.setRW().withReset(0.U))\n305:\
      \   // default RW\n306:   this.SSI .setRO().withReset(0.U)\n307:   this.MSI
      .setRO().withReset(0.U)\n308:   this.STI .setRO().withReset(0.U)\n309:   this.MTI
      .setRO().withReset(0.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/HypervisorLevel.scala
    lines: 308-318
    context: "308:   this.STI .setRO().withReset(0.U)\n309:   this.MTI .setRO().withReset(0.U)\n\
      310:   this.SEI .setRO().withReset(0.U)\n311:   this.MEI .setRO().withReset(0.U)\n\
      312:   this.SGEI.setRO().withReset(0.U)\n313:   this.getLocal.foreach(_.setRO().withReset(0.U))\n\
      314:   this.LCOFI.setRW().withReset(0.U)\n315: }\n316: \n317: class HipToHvip
      extends Bundle {\n318:   val VSSIP = ValidIO(RW(0))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/HypervisorLevel.scala
    lines: 321-331
    context: "321: class SipToHvip extends ToAliasIpLocalPart {\n322: \n323: }\n324:\
      \ \n325: class HieToMie extends IeValidBundle {\n326:   this.getVS.foreach(_.bits.setRW())\n\
      327:   this.SGEIE.bits.setRW()\n328: }\n329: \n330: class HvictlBundle extends
      CSRBundle {\n331:   // Virtual Trap Interrupt control"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapInstMod.scala
    lines: 20-30
    context: "20:     val fromDecode = Input(new Bundle {\n21:       val trapInstInfo
      = ValidIO(new TrapInstInfo)\n22:     })\n23: \n24:     val fromRob = Input(new
      Bundle {\n25:       val flush = ValidIO(new FtqInfo)\n26:       val isInterrupt
      = ValidIO(Bool())\n27:     })\n28: \n29:     val faultCsrUop = Input(ValidIO(new
      Bundle {\n30:       val fuOpType = FuOpType()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapInstMod.scala
    lines: 36-46
    context: "36:     val currentTrapInst = Output(ValidIO(UInt(32.W)))\n37:   })\n\
      38: \n39:   // alias\n40:   // delay flush one cycle to alias fromrob trap\n\
      41:   val flush = RegNext(io.fromRob.flush)\n42:   val newTrapInstInfo = io.fromDecode.trapInstInfo\n\
      43: \n44:   val valid = RegInit(false.B)\n45:   val trapInstInfo = Reg(new TrapInstInfo)\n\
      46: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapInstMod.scala
    lines: 56-68
    context: "56:   val newCSRInst = WireInit(0.U.asTypeOf(new TrapInstInfo))\n57:\
      \   newCSRInst.instr := csrInst\n58:   newCSRInst.ftqPtr := io.faultCsrUop.bits.ftqInfo.ftqPtr\n\
      59:   newCSRInst.ftqOffset := io.faultCsrUop.bits.ftqInfo.ftqOffset\n60: \n\
      61:   when (flush.valid && valid ) {\n62:     when (trapInstInfo.needFlush(flush.bits.ftqPtr,
      flush.bits.ftqOffset)) {\n63:       when (newCSRInstValid && !newCSRInst.needFlush(flush.bits.ftqPtr,
      flush.bits.ftqOffset)) {\n64:         // when flush and CSR exception happen
      together\n65:         trapInstInfo := newCSRInst\n66:       }.otherwise {\n\
      67:         valid := false.B\n68:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapInstMod.scala
    lines: 67-77
    context: "67:         valid := false.B\n68:       }\n69:     }.elsewhen(io.readClear)
      {\n70:       // as flush has been delay ,read clear and flush in the same cycle\n\
      71:       valid := false.B\n72:     }.elsewhen (trapInstInfo.sameInst(flush.bits.ftqPtr,
      flush.bits.ftqOffset) && io.fromRob.isInterrupt.valid && io.fromRob.isInterrupt.bits)
      {\n73:       // check whether the exception store is attached with an interrupt\n\
      74:       valid := false.B\n75:     }\n76:   }.elsewhen(newCSRInstValid) {\n\
      77:     valid := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 3-13
    context: "3: import chisel3._\n4: import chisel3.util._\n5: import utility.{DelayN,
      GatedValidRegNext}\n6: import utils._\n7: import xiangshan.ExceptionNO\n8: import
      xiangshan.backend.fu.NewCSR.CSRBundles.{CauseBundle, PrivState, XtvecBundle}\n\
      9: import xiangshan.backend.fu.NewCSR.CSRDefines.{PrivMode, XtvecMode}\n10:
      import xiangshan.backend.fu.NewCSR.InterruptNO\n11: \n12: \n13: class InterruptFilter
      extends Module {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 11-22
    context: "11: \n12: \n13: class InterruptFilter extends Module {\n14:   val io
      = IO(new InterruptFilterIO)\n15: \n16:   val privState = io.in.privState\n17:\
      \   val mstatusMIE = io.in.mstatusMIE\n18:   val sstatusSIE = io.in.sstatusSIE\n\
      19:   val vsstatusSIE = io.in.vsstatusSIE\n20:   val mip = io.in.mip\n21:  \
      \ val mie = io.in.mie\n22:   val mideleg = io.in.mideleg"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 35-46
    context: "35:   val hviprio1 = io.in.hviprio1\n36:   val hviprio2 = io.in.hviprio2\n\
      37:   val miprios = io.in.miprios\n38:   val hsiprios = io.in.hsiprios\n39:\
      \   val hviprios = Cat(hviprio2.asUInt, hviprio1.asUInt)\n40:   val fromAIAValid
      = io.in.fromAIA.meip || io.in.fromAIA.seip\n41:   val platformValid = io.in.platform.meip
      || io.in.platform.seip\n42: \n43:   /**\n44:    * Sort by implemented interrupt
      default priority\n45:    * index low, priority high\n46:    */"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 59-81
    context: "59:   val mtopigather = mip & mie & (~mideleg).asUInt\n60:   val hstopigather
      = hsip & hsie & (~hideleg).asUInt\n61:   val vstopigather = vsip & vsie & NoSEIMask\n\
      62: \n63:   val flag = RegInit(false.B)\n64:   when (platformValid) {\n65: \
      \    flag := true.B\n66:   }.elsewhen(fromAIAValid) {\n67:     flag := false.B\n\
      68:   }\n69: \n70:   val mipriosSort = Wire(Vec(InterruptNO.interruptDefaultPrio.size,
      new IpriosSort))\n71:   mipriosSort.zip(InterruptNO.interruptDefaultPrio).zipWithIndex.foreach
      { case ((iprio, defaultPrio), i) =>\n72:     iprio.idx := i.U\n73:     when
      (mtopigather(defaultPrio)) {\n74:       iprio.enable := true.B\n75:       when
      (defaultPrio.U === InterruptNO.MEI.U) {\n76:         iprio.isZero := platformValid
      || flag\n77:         val mtopeiGreaterThan255 = mtopei.IPRIO.asUInt(10, 8).orR\n\
      78:         iprio.greaterThan255 := mtopeiGreaterThan255\n79:         iprio.prioNum
      := mtopei.IPRIO.asUInt(7, 0)\n80:       }.otherwise {\n81:         iprio.isZero
      := !miprios(7 + 8 * defaultPrio, 8 * defaultPrio).orR"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 88-103
    context: "88:       iprio.greaterThan255 := false.B\n89:       iprio.prioNum :=
      0.U\n90:     }\n91:   }\n92:   val hsipriosSort = Wire(Vec(InterruptNO.interruptDefaultPrio.size,
      new IpriosSort))\n93:   hsipriosSort.zip(InterruptNO.interruptDefaultPrio).zipWithIndex.foreach
      { case ((iprio, defaultPrio), i) =>\n94:     iprio.idx := i.U\n95:     when
      (hstopigather(defaultPrio)) {\n96:       iprio.enable := true.B\n97:       when
      (defaultPrio.U === InterruptNO.SEI.U) {\n98:         iprio.isZero := platformValid
      || flag\n99:         val stopeiGreaterThan255 = stopei.IPRIO.asUInt(10, 8).orR\n\
      100:         iprio.greaterThan255 := stopeiGreaterThan255\n101:         iprio.prioNum
      := stopei.IPRIO.asUInt(7, 0)\n102:       }.otherwise {\n103:         iprio.isZero
      := !hsiprios(7 + 8 * defaultPrio, 8 * defaultPrio).orR"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 110-120
    context: "110:       iprio.greaterThan255 := false.B\n111:       iprio.prioNum
      := 0.U\n112:     }\n113:   }\n114:   val hvipriosSort = Wire(Vec(InterruptNO.interruptDefaultPrio.size,
      new IpriosSort))\n115:   hvipriosSort.zip(InterruptNO.interruptDefaultPrio).zipWithIndex.foreach
      { case ((iprio, defaultPrio), i) =>\n116:     iprio.idx := i.U\n117:     when(vstopigather(defaultPrio))
      {\n118:       iprio.enable := true.B\n119:       iprio.isZero := true.B\n120:\
      \       iprio.greaterThan255 := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 148-158
    context: "148:     select\n149:   }\n150: \n151:   def findIndex(input: UInt):
      UInt = {\n152:     val select = WireInit(0.U(log2Up(InterruptNO.interruptDefaultPrio.length).W))\n\
      153:     InterruptNO.interruptDefaultPrio.zipWithIndex.foreach { case (value,
      i) =>\n154:       when (input === value.U) {\n155:         select := i.U\n156:\
      \       }\n157:     }\n158:     select"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 211-221
    context: "211:   private val meiPrioIdx = InterruptNO.getPrioIdxInGroup(_.interruptDefaultPrio)(_.MEI).U\n\
      212:   private val seiPrioIdx = InterruptNO.getPrioIdxInGroup(_.interruptDefaultPrio)(_.SEI).U\n\
      213:   private val vseiPrioIdx = InterruptNO.getPrioIdxInGroup(_.interruptDefaultPrio)(_.VSEI).U\n\
      214: \n215:   private val mipriosTmp = Wire(Vec(8, new IpriosSort))\n216:  \
      \ mipriosSortTmp.zipWithIndex.foreach { case (iprios, i) =>\n217:     val ipriosTmp
      = highIprio(iprios, meiPrioIdx)\n218:     mipriosTmp(i) := ipriosTmp\n219: \
      \  }\n220: \n221:   private val hsipriosTmp = Wire(Vec(8, new IpriosSort))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 217-227
    context: "217:     val ipriosTmp = highIprio(iprios, meiPrioIdx)\n218:     mipriosTmp(i)
      := ipriosTmp\n219:   }\n220: \n221:   private val hsipriosTmp = Wire(Vec(8,
      new IpriosSort))\n222:   hsipriosSortTmp.zipWithIndex.foreach { case (iprios,
      i) =>\n223:     val ipriosTmp = highIprio(iprios, seiPrioIdx)\n224:     hsipriosTmp(i)
      := ipriosTmp\n225:   }\n226: \n227:   private val hvipriosTmp = Wire(Vec(8,
      new IpriosSort))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 223-233
    context: "223:     val ipriosTmp = highIprio(iprios, seiPrioIdx)\n224:     hsipriosTmp(i)
      := ipriosTmp\n225:   }\n226: \n227:   private val hvipriosTmp = Wire(Vec(8,
      new IpriosSort))\n228:   hvipriosSortTmp.zipWithIndex.foreach { case (iprios,
      i) =>\n229:     val ipriosTmp = highIprio(iprios, vseiPrioIdx)\n230:     hvipriosTmp(i)
      := ipriosTmp\n231:   }\n232: \n233:   private val mipriosReg = Reg(Vec(8, new
      IpriosSort))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 461-471
    context: "461:       ))\n462:     )\n463:   )\n464: \n465:   val mIRVecTmp = Mux(\n\
      466:     privState.isModeM && mstatusMIE || privState < PrivState.ModeM,\n467:\
      \     io.out.mtopi.IID.asUInt,\n468:     0.U\n469:   )\n470: \n471:   val hsIRVecTmp
      = Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 467-477
    context: "467:     io.out.mtopi.IID.asUInt,\n468:     0.U\n469:   )\n470: \n471:\
      \   val hsIRVecTmp = Mux(\n472:     privState.isModeHS && sstatusSIE || privState
      < PrivState.ModeHS,\n473:     io.out.stopi.IID.asUInt,\n474:     0.U\n475: \
      \  )\n476: \n477:   val vsIRVecTmp = Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 473-483
    context: "473:     io.out.stopi.IID.asUInt,\n474:     0.U\n475:   )\n476: \n477:\
      \   val vsIRVecTmp = Mux(\n478:     privState.isModeVS && vsstatusSIE || privState
      < PrivState.ModeVS,\n479:     io.out.vstopi.IID.asUInt,\n480:     0.U\n481:\
      \   )\n482: \n483:   val mIRNotZero  = mIRVecTmp.orR"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 510-520
    context: "510:   val vsMapHostIRVec = OHToUInt(vsMapHostIRVecTmp)\n511: \n512:\
      \   dontTouch(vsMapHostIRVec)\n513: \n514:   val nmiVecTmp = Wire(Vec(64, Bool()))\n\
      515:   nmiVecTmp.zipWithIndex.foreach { case (irq, i) =>\n516:     if (NonMaskableIRNO.interruptDefaultPrio.contains(i))
      {\n517:       val higherIRSeq = NonMaskableIRNO.getIRQHigherThan(i)\n518:  \
      \     irq := (\n519:         higherIRSeq.nonEmpty.B && Cat(higherIRSeq.map(num
      => !io.in.nmiVec(num))).andR ||\n520:           higherIRSeq.isEmpty.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 534-544
    context: "534: \n535:   val normalIntrVec = mIRVec | hsIRVec | vsMapHostIRVec\n\
      536:   val intrVec = Mux(disableAllIntr, 0.U, Mux(io.in.nmi, nmiVec, normalIntrVec))\n\
      537: \n538:   // virtual interrupt with hvictl injection\n539:   val vsIRModeCond
      = privState.isModeVS && vsstatusSIE || privState < PrivState.ModeVS\n540:  \
      \ val SelectCandidate5 = onlyC5EnableReg || C3C5EnableReg ||\n541:         \
      \                 C1C5EnableReg && (iprioC1 === iprioC2C5 && !hvictlReg.DPR.asBool
      || iprioC1 > iprioC2C5)\n542:   // delay at least 6 cycles to maintain the atomic
      of sret/mret\n543:   // 65bit indict current interrupt is NMI\n544:   val intrVecReg
      = RegInit(0.U(8.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptFilter.scala
    lines: 575-586
    context: "575:   dontTouch(vsIRVec)\n576: }\n577: \n578: class InterruptFilterIO
      extends Bundle {\n579:   val in = Input(new Bundle {\n580:     val privState
      = new PrivState\n581:     val mstatusMIE  = Bool()\n582:     val sstatusSIE\
      \  = Bool()\n583:     val vsstatusSIE = Bool()\n584:     val mip = new MipBundle\n\
      585:     val mie = new MieBundle\n586:     val mideleg = new MidelegBundle"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/StateEnBundle.scala
    lines: 1-10
    context: "1: package xiangshan.backend.fu.NewCSR\n2: \n3: import chisel3._\n4:
      import xiangshan.backend.fu.NewCSR.CSRDefines.{CSRROField => RO, CSRRWField
      => RW}\n5: import xiangshan.backend.fu.NewCSR.CSRBundles.PrivState\n6: \n7:\
      \ \n8: class Sstateen0Bundle extends CSRBundle {\n9:   override val len: Int
      = 32\n10:   val JVT  = RO(2).withReset(0.U) // jvt CSR in Zcmt extension"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/StateEnBundle.scala
    lines: 6-27
    context: "6: \n7: \n8: class Sstateen0Bundle extends CSRBundle {\n9:   override
      val len: Int = 32\n10:   val JVT  = RO(2).withReset(0.U) // jvt CSR in Zcmt
      extension\n11:   val FCSR = RO(1).withReset(0.U) // fp inst op 'x' register
      not f in Zfinx, Zdinx; misa.F =1 -> RO 0; misa.F=0 & this=0 -> V/EX_II\n12:\
      \   val C    = RW(0)                // custom state enable, [m|h|s]stateen is
      standard, not custom.\n13: }\n14: \n15: class Hstateen0Bundle extends Sstateen0Bundle
      {\n16:   override val len: Int = 64\n17:   val SE0     = RW(63)            \
      \    // m: [h|s]stateen                h: sstateen\n18:   val ENVCFG  = RW(62)\
      \                // m: [h|s]envcfg                 h: senvcfg\n19:   // Bits
      in any stateen CSR that are defined to control state that a hart doesnt implement
      are read-only\n20:   // zeros for that hart. Smcsrind/Sscsrind is not implemented.\n\
      21:   val CSRIND  = RW(60)                // m: [vs|s]iselect, [vs|s]ireg* \
      \ h: siselect, sireg*\n22:   val AIA     = RW(59)                // all other
      state added by the AIA and not controlled by bits 60 and 58\n23:   val IMSIC\
      \   = RW(58)                // m: [vs|s]topei                 h: stopei\n24:\
      \   val CONTEXT = RW(57)                // m: [h|s]context in Sdtrig      h:
      scontext\n25: }\n26: \n27: class Mstateen0Bundle extends Hstateen0Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/StateEnBundle.scala
    lines: 23-42
    context: "23:   val IMSIC   = RW(58)                // m: [vs|s]topei        \
      \         h: stopei\n24:   val CONTEXT = RW(57)                // m: [h|s]context
      in Sdtrig      h: scontext\n25: }\n26: \n27: class Mstateen0Bundle extends Hstateen0Bundle
      {\n28:   override val SE0     = RW(63).withReset(0.U) // m: [h|s]stateen   \
      \             h: sstateen\n29:   override val ENVCFG  = RW(62).withReset(0.U)
      // m: [h|s]envcfg                 h: senvcfg\n30:   // Bits in any stateen CSR
      that are defined to control state that a hart doesnt implement are read-only\n\
      31:   // zeros for that hart. Smcsrind/Sscsrind is not implemented.\n32:   override
      val CSRIND  = RW(60).withReset(0.U) // m: [vs|s]iselect, [vs|s]ireg*  h: siselect,
      sireg*\n33:   override val AIA     = RW(59).withReset(0.U) // all other state
      added by the AIA and not controlled by bits 60 and 58\n34:   override val IMSIC\
      \   = RW(58).withReset(0.U) // m: [vs|s]topei                 h: stopei\n35:\
      \   override val CONTEXT = RW(57).withReset(0.U) // m: [h|s]context in Sdtrig\
      \      h: scontext\n36:   val P1P13            = RO(56).withReset(0.U) // hedelegh
      in Priv Spec V1.13\n37:   override val C       = RW(0).withReset(0.U)  // custom
      state enable, [m|h|s]stateen is standard, not custom.\n38: }\n39: \n40: class
      SstateenNonZeroBundle extends CSRBundle {  // for sstateen[1|2|3]\n41:   override
      val len = 32\n42:   val ALL = RO(31, 0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/StateEnBundle.scala
    lines: 43-59
    context: "43: }\n44: \n45: class HstateenNonZeroBundle extends CSRBundle {  //
      for hstateen[1|2|3]\n46:   val SE = RW(63)\n47: }\n48: class MstateenNonZeroBundle
      extends HstateenNonZeroBundle {  // for mstateen[1|2|3]\n49:   override val
      SE = RW(63).withReset(0.U)\n50: }\n51: \n52: trait HasStateenBundle { self:
      CSRModule[_] =>\n53:   val fromMstateen0 = IO(Input(new Mstateen0Bundle))\n\
      54:   val fromMstateen1 = IO(Input(new MstateenNonZeroBundle))\n55:   val fromMstateen2
      = IO(Input(new MstateenNonZeroBundle))\n56:   val fromMstateen3 = IO(Input(new
      MstateenNonZeroBundle))\n57:   val fromHstateen0 = IO(Input(new Hstateen0Bundle))\n\
      58:   val privState     = IO(Input(new PrivState))\n59: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRDefines.scala
    lines: 154-167
    context: "154:     val XLEN64 = Value(2.U)\n155:     val XLEN128 = Value(3.U)\n\
      156:   }\n157: \n158:   object XtvecMode extends CSREnum with WARLApply {\n\
      159:     val Direct = Value(0.U)\n160:     val Vectored = Value(1.U)\n161: \n\
      162:     override def isLegal(enumeration: CSREnumType): Bool = enumeration.isOneOf(Direct,
      Vectored)\n163:   }\n164: \n165:   object SatpMode extends CSREnum with WARLApply
      {\n166:     val Bare = Value(0.U)\n167:     val Sv39 = Value(8.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRDefines.scala
    lines: 183-196
    context: "183:     override def isLegal(enumeration: CSREnumType): Bool = enumeration.isOneOf(Bare,
      Sv39x4, Sv48x4)\n184:   }\n185: \n186:   object EnvCBIE extends CSREnum with
      WARLApply {\n187:     val Off   = Value(\"b00\".U)\n188:     val Flush = Value(\"\
      b01\".U)\n189:     val Inval = Value(\"b11\".U)\n190: \n191:     override def
      isLegal(enumeration: CSREnumType): Bool = enumeration.isOneOf(Off, Flush, Inval)\n\
      192:   }\n193: \n194:   object EnvPMM extends CSREnum with WARLApply {\n195:\
      \     val Disable  = Value(\"b00\".U)\n196:     val PMLEN7   = Value(\"b10\"\
      .U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/PMP.scala
    lines: 376-386
    context: "376:     this.size := size\n377:     this.cmd := cmd\n378:   }\n379:\
      \ \n380:   def apply(addr: UInt): Unit = { // req minimal permission and req
      align size\n381:     apply(addr, lgMaxSize.U, TlbCmd.read)\n382:   }\n383: \n\
      384: }\n385: \n386: class PMPRespBundle(implicit p: Parameters) extends PMPBundle
      {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/PMP.scala
    lines: 385-395
    context: "385: \n386: class PMPRespBundle(implicit p: Parameters) extends PMPBundle
      {\n387:   val ld = Output(Bool())\n388:   val st = Output(Bool())\n389:   val
      instr = Output(Bool())\n390:   val mmio = Output(Bool())\n391:   val atomic
      = Output(Bool())\n392: \n393:   def |(resp: PMPRespBundle): PMPRespBundle =
      {\n394:     val res = Wire(new PMPRespBundle())\n395:     res.ld := this.ld
      || resp.ld"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/PMP.scala
    lines: 393-403
    context: "393:   def |(resp: PMPRespBundle): PMPRespBundle = {\n394:     val res
      = Wire(new PMPRespBundle())\n395:     res.ld := this.ld || resp.ld\n396:   \
      \  res.st := this.st || resp.st\n397:     res.instr := this.instr || resp.instr\n\
      398:     res.mmio := this.mmio || resp.mmio\n399:     res.atomic := this.atomic
      || resp.atomic\n400:     res\n401:   }\n402: }\n403: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/PMP.scala
    lines: 402-415
    context: "402: }\n403: \n404: trait PMPCheckMethod extends PMPConst {\n405:  \
      \ def pmp_check(cmd: UInt, cfg: PMPConfig) = {\n406:     val resp = Wire(new
      PMPRespBundle)\n407:     resp.ld := TlbCmd.isRead(cmd) && !TlbCmd.isAmo(cmd)
      && !cfg.r\n408:     resp.st := (TlbCmd.isWrite(cmd) || TlbCmd.isAmo(cmd)) &&
      !cfg.w\n409:     resp.instr := TlbCmd.isExec(cmd) && !cfg.x\n410:     resp.mmio
      := false.B\n411:     resp.atomic := false.B\n412:     resp\n413:   }\n414: \n\
      415:   def pmp_match_res(leaveHitMux: Boolean = false, valid: Bool = true.B)("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/PMP.scala
    lines: 429-439
    context: "429:     pmpDefault.cfg.x := passThrough\n430: \n431:     val match_vec
      = Wire(Vec(num+1, Bool()))\n432:     val cfg_vec = Wire(Vec(num+1, new PMPEntry()))\n\
      433: \n434:     pmpEntries.zip(pmpDefault +: pmpEntries.take(num-1)).zipWithIndex.foreach{
      case ((pmp, last_pmp), i) =>\n435:       val is_match = pmp.is_match(addr, size,
      lgMaxSize, last_pmp)\n436:       val ignore = passThrough && !pmp.cfg.l\n437:\
      \       val aligned = pmp.aligned(addr, size, lgMaxSize, last_pmp)\n438: \n\
      439:       val cur = WireInit(pmp)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/PMP.scala
    lines: 479-489
    context: "479:   }\n480: }\n481: \n482: class PMPCheckIO(lgMaxSize: Int)(implicit
      p: Parameters) extends PMPBundle {\n483:   val check_env = Input(new PMPCheckerEnv())\n\
      484:   val req = Flipped(Valid(new PMPReqBundle(lgMaxSize))) // usage: assign
      the valid to fire signal\n485:   val resp = new PMPRespBundle()\n486: \n487:\
      \   def apply(cmode: Bool, mode: UInt, pmp: Vec[PMPEntry], pma: Vec[PMPEntry],
      req: Valid[PMPReqBundle]) = {\n488:     check_env.apply(cmode, mode, pmp, pma)\n\
      489:     this.req := req"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/PMP.scala
    lines: 508-518
    context: "508:   }\n509: }\n510: \n511: class PMPCheckv2IO(lgMaxSize: Int)(implicit
      p: Parameters) extends PMPBundle {\n512:   val check_env = Input(new PMPCheckerEnv())\n\
      513:   val req = Flipped(Valid(new PMPReqBundle(lgMaxSize))) // usage: assign
      the valid to fire signal\n514:   val resp = Output(new PMPConfig())\n515: \n\
      516:   def apply(cmode: Bool, mode: UInt, pmp: Vec[PMPEntry], pma: Vec[PMPEntry],
      valid: Bool, addr: UInt) = {\n517:     check_env.apply(cmode, mode, pmp, pma)\n\
      518:     req_apply(valid, addr)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/PMP.scala
    lines: 577-587
    context: "577:     val resp = Wire(new PMPRespBundle)\n578:     val keyid_nz =
      if (PMPKeyIDBits > 0) addr(PMPAddrBits-1, PMPAddrBits-PMPKeyIDBits) =/= 0.U
      else false.B\n579:     resp.ld := keyid_nz && !io.check_env.cmode && (io.check_env.mode
      < 3.U)\n580:     resp.st := keyid_nz && !io.check_env.cmode && (io.check_env.mode
      < 3.U)\n581:     resp.instr := keyid_nz && !io.check_env.cmode && (io.check_env.mode
      < 3.U)\n582:     resp.mmio := false.B\n583:     resp.atomic := false.B\n584:\
      \     if (leaveHitMux) {\n585:       RegEnable(resp, valid)\n586:     } else
      {\n587:       resp"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/Bku.scala
    lines: 205-215
    context: "205: \n206:   val iaesSboxIn = InverseShiftRows(src1Bytes, src2Bytes)\n\
      207:   val iaesSboxMid  = Reg(Vec(8, Vec(18, Bool())))\n208:   val iaesSboxOut
      = Wire(Vec(8, UInt(8.W)))\n209: \n210:   aesSboxOut.zip(aesSboxMid).zip(aesSboxIn)foreach
      { case ((out, mid), in) =>\n211:     when (io.regEnable) {\n212:       mid :=
      SboxInv(SboxAesTop(in))\n213:     }\n214:     out := SboxAesOut(mid)\n215: \
      \  }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/Bku.scala
    lines: 212-222
    context: "212:       mid := SboxInv(SboxAesTop(in))\n213:     }\n214:     out
      := SboxAesOut(mid)\n215:   }\n216: \n217:   iaesSboxOut.zip(iaesSboxMid).zip(iaesSboxIn)foreach
      { case ((out, mid), in) =>\n218:     when (io.regEnable) {\n219:       mid :=
      SboxInv(SboxIaesTop(in))\n220:     }\n221:     out := SboxIaesOut(mid)\n222:\
      \   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/Bku.scala
    lines: 243-253
    context: "243:   val ksSboxOut = Wire(Vec(4, UInt(8.W)))\n244:   ksSboxIn(0) :=
      Mux(src2(3,0) === \"ha\".U, src1Bytes(4), src1Bytes(5))\n245:   ksSboxIn(1)
      := Mux(src2(3,0) === \"ha\".U, src1Bytes(5), src1Bytes(6))\n246:   ksSboxIn(2)
      := Mux(src2(3,0) === \"ha\".U, src1Bytes(6), src1Bytes(7))\n247:   ksSboxIn(3)
      := Mux(src2(3,0) === \"ha\".U, src1Bytes(7), src1Bytes(4))\n248:   ksSboxOut.zip(ksSboxTop).zip(ksSboxIn).foreach{
      case ((out, top), in) =>\n249:     when (io.regEnable) {\n250:       top :=
      SboxAesTop(in)\n251:     }\n252:     out := SboxAesOut(SboxInv(top))\n253: \
      \    }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/Bku.scala
    lines: 351-361
    context: "351:   cryptoModule.io.func := func\n352:   cryptoModule.io.regEnable
      := regEnable(1)\n353: \n354: \n355:   // CountModule, ClmulModule, MiscModule,
      and CryptoModule have a latency of 1 cycle\n356:   val funcReg = RegEnable(func,
      io.in.fire)\n357:   val result = Mux(funcReg(5), cryptoModule.io.out,\n358:\
      \                   Mux(funcReg(3), countModule.io.out,\n359:              \
      \         Mux(funcReg(2),miscModule.io.out, clmulModule.io.out)))\n360: \n361:\
      \   io.out.bits.res.data := RegEnable(result, regEnable(2))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regcache/RegCache.scala
    lines: 58-68
    context: "58:   MemRegCacheAgeTimer.io.validInfo := MemRegCache.io.validInfo\n\
      59: \n60:   io.readPorts\n61:   .lazyZip(IntRegCache.io.readPorts.lazyZip(MemRegCache.io.readPorts))\n\
      62:   .lazyZip(IntRegCacheAgeTimer.io.readPorts.lazyZip(MemRegCacheAgeTimer.io.readPorts))\n\
      63:   .foreach{ case (r_in, (r_int, r_mem), (r_int_at, r_mem_at)) => \n64: \
      \    val in_addr = RegEnable(r_in.addr, r_in.ren)\n65:     val int_ren = GatedValidRegNext(r_in.ren
      & ~r_in.addr(RegCacheIdxWidth - 1))\n66:     val mem_ren = GatedValidRegNext(r_in.ren
      & r_in.addr(RegCacheIdxWidth - 1))\n67:     r_int.ren  := int_ren\n68:     r_mem.ren\
      \  := mem_ren"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regcache/RegCache.scala
    lines: 75-109
    context: "75:     r_mem_at.addr := in_addr(RegCacheIdxWidth - 2, 0)\n76:   }\n\
      77: \n78:   val writePorts = Wire(chiselTypeOf(io.writePorts))\n79: \n80:  \
      \ IntRegCache.io.writePorts.zip(writePorts.take(IntRegCacheWriteSize)).foreach{
      case (w_int, w_in) => \n81:     w_int.wen  := w_in.wen\n82:     w_int.addr :=
      w_in.addr(RegCacheIdxWidth - 2, 0)\n83:     w_int.data := w_in.data\n84:   \
      \  w_int.tag.foreach(_ := w_in.tag.get)\n85:   }\n86: \n87:   MemRegCache.io.writePorts.zip(writePorts.takeRight(MemRegCacheWriteSize)).foreach{
      case (w_mem, w_in) => \n88:     w_mem.wen  := w_in.wen\n89:     w_mem.addr :=
      w_in.addr(RegCacheIdxWidth - 2, 0)\n90:     w_mem.data := w_in.data\n91:   \
      \  w_mem.tag.foreach(_ := w_in.tag.get)\n92:   }\n93: \n94:   IntRegCacheAgeTimer.io.writePorts.zip(writePorts.take(IntRegCacheWriteSize)).foreach{
      case (w_int, w_in) => \n95:     w_int.wen  := w_in.wen\n96:     w_int.addr :=
      w_in.addr(RegCacheIdxWidth - 2, 0)\n97:   }\n98: \n99:   MemRegCacheAgeTimer.io.writePorts.zip(writePorts.takeRight(MemRegCacheWriteSize)).foreach{
      case (w_mem, w_in) => \n100:     w_mem.wen  := w_in.wen\n101:     w_mem.addr
      := w_in.addr(RegCacheIdxWidth - 2, 0)\n102:   }\n103: \n104:   io.toWakeupQueueRCIdx.zipWithIndex.foreach{
      case (rcIdx, i) => \n105:     if (i < IntRegCacheWriteSize) {\n106:       rcIdx
      := Cat(\"b0\".U, IntRegCacheRepRCIdx(i))\n107:     }\n108:     else {\n109:\
      \       rcIdx := Cat(\"b1\".U, MemRegCacheRepRCIdx(i - IntRegCacheWriteSize))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regcache/RegCache.scala
    lines: 110-120
    context: "110:     }\n111:   }\n112: \n113:   val delayToWakeupQueueRCIdx = RegNextN(io.toWakeupQueueRCIdx,
      3)\n114:   writePorts := io.writePorts\n115:   writePorts.zip(delayToWakeupQueueRCIdx).foreach{
      case (w, rcIdx) => \n116:     w.addr := rcIdx\n117:   }\n118: }\n119: \n120:
      class RegCacheIO()(implicit p: Parameters, params: BackendParams) extends XSBundle
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regcache/RegCacheAgeTimer.scala
    lines: 50-60
    context: "50: \n51:   val ageTimer = RegInit(VecInit((0 until numEntries).map(i
      => (i / (numEntries / 4)).U(2.W))))\n52:   val ageTimerNext = Seq.fill(numEntries)(Wire(UInt(2.W)))\n\
      53: \n54:   val ageTimerExtra = RegInit(VecInit((0 until 4).map(_.U(2.W))))\n\
      55:   ageTimerExtra.foreach(i => i := i + 1.U)\n56: \n57:   val hasReadReq =
      (0 until numEntries).map{ i => \n58:     io.readPorts.map(r => r.ren && r.addr
      === i.U).reduce(_ || _)\n59:   }\n60:   val hasWriteReq = (0 until numEntries).map{
      i => "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regcache/AgeDetector.scala
    lines: 62-72
    context: "62: \n63:   val rowOnesSum = (0 until numEntries).map(i => \n64:   \
      \  PopCount((0 until numEntries).map(j => get_age(i, j)))\n65:   )\n66: \n67:\
      \   io.out.zipWithIndex.foreach { case (out, idx) =>\n68:     out := PriorityMux(rowOnesSum.map(_
      === (numEntries - idx).U).zip((0 until numEntries).map(_.U)))\n69:     assert(PopCount(rowOnesSum.map(_
      === (numEntries - idx).U)) === 1.U, s\"row sum of replace entry ($idx) is not
      one-hot\")\n70:   }\n71: }\n72: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regcache/RegCacheTagModule.scala
    lines: 56-66
    context: "56:     val validVec = Vec(numEntries, Output(Bool()))\n57:     val
      tagVec = Vec(numEntries, Output(UInt(tagWidth.W)))\n58:     val loadDependencyVec
      = Vec(numEntries, Vec(LoadPipelineWidth, Output(UInt(LoadDependencyWidth.W))))\n\
      59:   })\n60: \n61:   println(s\"[RegCacheTagModule] $name: size: $numEntries,
      read: $numReadPorts, write: $numWritePorts\")\n62: \n63:   val v   = RegInit(VecInit(Seq.fill(numEntries)(false.B)))\n\
      64:   val tag = Reg(Vec(numEntries, UInt(tagWidth.W)))\n65:   val loadDependency
      = Reg(Vec(numEntries, Vec(LoadPipelineWidth, UInt(LoadDependencyWidth.W))))\n\
      66: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regcache/RegCacheDataModule.scala
    lines: 50-60
    context: "50:     val readPorts = Vec(numReadPorts, new RCReadPort(dataWidth,
      addrWidth))\n51:     val writePorts = Vec(numWritePorts, new RCWritePort(dataWidth,
      addrWidth, tagWidth, backendParams.debugEn))\n52:     val validInfo = Vec(numEntries,
      Output(Bool()))\n53:   })\n54: \n55:   println(s\"[RegCache] $name: size: $numEntries,
      read: $numReadPorts, write: $numWritePorts\")\n56: \n57:   val v   = RegInit(VecInit(Seq.fill(numEntries)(false.B)))\n\
      58:   val mem = Reg(Vec(numEntries, UInt(dataWidth.W)))\n59:   val tag = OptionWrapper(backendParams.debugEn,
      Reg(Vec(numEntries, UInt(tagWidth.W))))\n60: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regcache/RegCacheDataModule.scala
    lines: 59-69
    context: "59:   val tag = OptionWrapper(backendParams.debugEn, Reg(Vec(numEntries,
      UInt(tagWidth.W))))\n60: \n61:   for ((r, i) <- io.readPorts.zipWithIndex) {\n\
      62:     r.data := mem(r.addr)\n63:     when (r.ren) {\n64:       assert(v(r.addr),
      s\"$name readPorts $i read a invalid entry\")\n65:     }\n66:   }\n67: \n68:\
      \   val writePorts = io.writePorts\n69:   for (i <- writePorts.indices) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regcache/RegCacheTagTable.scala
    lines: 48-58
    context: "48:                                                    RegCacheIdxWidth
      - 1, IntPhyRegIdxWidth))\n49: \n50:   // read\n51:   io.readPorts\n52:   .lazyZip(IntRCTagTable.io.readPorts.lazyZip(MemRCTagTable.io.readPorts))\n\
      53:   .foreach{ case (r_in, (r_int, r_mem)) => \n54:     r_int.ren  := r_in.ren\n\
      55:     r_mem.ren  := r_in.ren\n56:     r_int.tag  := r_in.tag\n57:     r_mem.tag\
      \  := r_in.tag\n58:     val matchAlloc = io.allocPregs.map(x => x.valid && r_in.tag
      === x.bits).reduce(_ || _)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regcache/RegCacheTagTable.scala
    lines: 64-75
    context: "64:   val wakeupFromIQNeedWriteRC = io.wakeupFromIQ.filter(_.bits.params.needWriteRegCache)\n\
      65:   val shiftLoadDependency = Wire(Vec(wakeupFromIQNeedWriteRC.size, Vec(LoadPipelineWidth,
      UInt(LoadDependencyWidth.W))))\n66: \n67:   require(wakeupFromIQNeedWriteRC.size
      == IntRegCacheWriteSize + MemRegCacheWriteSize, \"wakeup size should be equal
      to RC write size\")\n68: \n69:   shiftLoadDependency.zip(wakeupFromIQNeedWriteRC.map(_.bits.loadDependency)).zip(backendParams.intSchdParams.get.wakeUpInExuSources.map(_.name)).foreach
      {\n70:     case ((deps, originalDeps), name) => deps.zip(originalDeps).zipWithIndex.foreach
      {\n71:       case ((dep, originalDep), deqPortIdx) =>\n72:         if (backendParams.getLdExuIdx(backendParams.allExuParams.find(_.name
      == name).get) == deqPortIdx)\n73:           dep := 1.U\n74:         else\n75:\
      \           dep := originalDep << 1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regcache/RegCacheTagTable.scala
    lines: 75-85
    context: "75:           dep := originalDep << 1\n76:     }\n77:   }\n78: \n79:\
      \   (IntRCTagTable.io.writePorts ++ MemRCTagTable.io.writePorts).lazyZip(wakeupFromIQNeedWriteRC).lazyZip(shiftLoadDependency)\n\
      80:   .foreach{ case (w, wakeup, ldDp) => \n81:     w.wen  := wakeup.valid &&
      wakeup.bits.rfWen && !LoadShouldCancel(Some(wakeup.bits.loadDependency), io.ldCancel)
      && !(wakeup.bits.is0Lat && io.og0Cancel(wakeup.bits.params.exuIdx))\n82:   \
      \  w.addr := wakeup.bits.rcDest.get(RegCacheIdxWidth - 2, 0)\n83:     w.tag\
      \  := wakeup.bits.pdest\n84:     w.loadDependency := ldDp\n85:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regcache/RegCacheTagTable.scala
    lines: 102-112
    context: "102:   val cancelVec = allocVec.lazyZip(replaceVec).lazyZip(ldCancelVec).lazyZip((IntRCTagTable.io.validVec
      ++ MemRCTagTable.io.validVec))\n103:   .map{ case (alloc, rep, ldCancel, v)
      => \n104:     (alloc || rep || ldCancel) && v\n105:   }\n106: \n107:   (IntRCTagTable.io.cancelVec
      ++ MemRCTagTable.io.cancelVec).zip(cancelVec).foreach{ case (cancelIn, cancel)
      => \n108:     cancelIn := cancel\n109:   }\n110: }\n111: \n112: class RegCacheTagTableIO(numReadPorts:
      Int)(implicit p: Parameters) extends XSBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regcache/RegCacheTagTable.scala
    lines: 111-121
    context: "111: \n112: class RegCacheTagTableIO(numReadPorts: Int)(implicit p:
      Parameters) extends XSBundle {\n113: \n114:   val readPorts = Vec(numReadPorts,
      new RCTagTableReadPort(RegCacheIdxWidth, IntPhyRegIdxWidth))\n115: \n116:  \
      \ val wakeupFromIQ: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]] = Flipped(backendParams.intSchdParams.get.genIQWakeUpInValidBundle)\n\
      117: \n118:   // set preg state to invalid\n119:   val allocPregs = Vec(RenameWidth,
      Flipped(ValidIO(UInt(IntPhyRegIdxWidth.W))))\n120: \n121:   // cancelFromDatapath"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 23-33
    context: "23: import utility._\n24: import utils._\n25: import xiangshan.ExceptionNO._\n\
      26: import xiangshan._\n27: import xiangshan.backend.Bundles.{DecodedInst, DynInst,
      ExceptionInfo, ExuOutput, ExuVec, StaticInst, TrapInstInfo}\n28: import xiangshan.backend.ctrlblock.{DebugLSIO,
      DebugLsInfoBundle, LsTopdownInfo, MemCtrl, RedirectGenerator}\n29: import xiangshan.backend.datapath.DataConfig.{FpData,
      IntData, V0Data, VAddrData, VecData, VlData}\n30: import xiangshan.backend.decode.{DecodeStage,
      FusionDecoder}\n31: import xiangshan.backend.dispatch.{CoreDispatchTopDownIO}\n\
      32: import xiangshan.backend.dispatch.NewDispatch\n33: import xiangshan.backend.fu.vector.Bundles.{VType,
      Vl}"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 32-42
    context: "32: import xiangshan.backend.dispatch.NewDispatch\n33: import xiangshan.backend.fu.vector.Bundles.{VType,
      Vl}\n34: import xiangshan.backend.fu.wrapper.CSRToDecode\n35: import xiangshan.backend.rename.{Rename,
      RenameTableWrapper, SnapshotGenerator}\n36: import xiangshan.backend.rob.{Rob,
      RobCSRIO, RobCoreTopDownIO, RobDebugRollingIO, RobLsqIO, RobPtr}\n37: import
      xiangshan.frontend.{FtqPtr, FtqRead, Ftq_RF_Components}\n38: import xiangshan.mem.{LqPtr,
      LsqEnqIO, SqPtr}\n39: import xiangshan.backend.issue.{FpScheduler, IntScheduler,
      MemScheduler, VfScheduler}\n40: import xiangshan.backend.trace._\n41: \n42:
      class CtrlToFtqIO(implicit p: Parameters) extends XSBundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 39-49
    context: "39: import xiangshan.backend.issue.{FpScheduler, IntScheduler, MemScheduler,
      VfScheduler}\n40: import xiangshan.backend.trace._\n41: \n42: class CtrlToFtqIO(implicit
      p: Parameters) extends XSBundle {\n43:   val rob_commits = Vec(CommitWidth,
      Valid(new RobCommitInfo))\n44:   val redirect = Valid(new Redirect)\n45:   val
      ftqIdxAhead = Vec(BackendRedirectNum, Valid(new FtqPtr))\n46:   val ftqIdxSelOH
      = Valid(UInt((BackendRedirectNum).W))\n47: }\n48: \n49: class CtrlBlock(params:
      BackendParams)(implicit p: Parameters) extends LazyModule {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 66-78
    context: "66:   with HasCircularQueuePtrHelper\n67:   with HasPerfEvents\n68:\
      \   with HasCriticalErrors\n69: {\n70:   val pcMemRdIndexes = new NamedIndexes(Seq(\n\
      71:     \"redirect\"  -> 1,\n72:     \"memPred\"   -> 1,\n73:     \"robFlush\"\
      \  -> 1,\n74:     \"bjuPc\"     -> params.BrhCnt,\n75:     \"bjuTarget\" ->
      params.BrhCnt,\n76:     \"load\"      -> params.LduCnt,\n77:     \"hybrid\"\
      \    -> params.HyuCnt,\n78:     \"store\"     -> (if(EnableStorePrefetchSMS)
      params.StaCnt else 0),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 80-90
    context: "80:   ))\n81: \n82:   private val numPcMemRead = pcMemRdIndexes.maxIdx\n\
      83: \n84:   // now pcMem read for exu is moved to PcTargetMem (OG0)\n85:   println(s\"\
      pcMem read num: $numPcMemRead\")\n86: \n87:   val io = IO(new CtrlBlockIO())\n\
      88: \n89:   val dispatch = Module(new NewDispatch)\n90:   val gpaMem = wrapper.gpaMem.module"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 90-100
    context: "90:   val gpaMem = wrapper.gpaMem.module\n91:   val decode = Module(new
      DecodeStage)\n92:   val fusionDecoder = Module(new FusionDecoder)\n93:   val
      rat = Module(new RenameTableWrapper)\n94:   val rename = Module(new Rename)\n\
      95:   val redirectGen = Module(new RedirectGenerator)\n96:   private def hasRen:
      Boolean = true\n97:   private val pcMem = Module(new SyncDataModuleTemplate(new
      Ftq_RF_Components, FtqSize, numPcMemRead, 1, \"BackendPC\", hasRen = hasRen))\n\
      98:   private val rob = wrapper.rob.module\n99:   private val memCtrl = Module(new
      MemCtrl(params))\n100: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 98-131
    context: "98:   private val rob = wrapper.rob.module\n99:   private val memCtrl
      = Module(new MemCtrl(params))\n100: \n101:   private val disableFusion = decode.io.csrCtrl.singlestep
      || !decode.io.csrCtrl.fusion_enable\n102: \n103:   private val s0_robFlushRedirect
      = rob.io.flushOut\n104:   private val s1_robFlushRedirect = Wire(Valid(new Redirect))\n\
      105:   s1_robFlushRedirect.valid := GatedValidRegNext(s0_robFlushRedirect.valid,
      false.B)\n106:   s1_robFlushRedirect.bits := RegEnable(s0_robFlushRedirect.bits,
      s0_robFlushRedirect.valid)\n107: \n108:   pcMem.io.ren.get(pcMemRdIndexes(\"\
      robFlush\").head) := s0_robFlushRedirect.valid\n109:   pcMem.io.raddr(pcMemRdIndexes(\"\
      robFlush\").head) := s0_robFlushRedirect.bits.ftqIdx.value\n110:   private val
      s1_robFlushPc = pcMem.io.rdata(pcMemRdIndexes(\"robFlush\").head).startAddr
      + (RegEnable(s0_robFlushRedirect.bits.ftqOffset, s0_robFlushRedirect.valid)
      << instOffsetBits)\n111:   private val s3_redirectGen = redirectGen.io.stage2Redirect\n\
      112:   private val s1_s3_redirect = Mux(s1_robFlushRedirect.valid, s1_robFlushRedirect,
      s3_redirectGen)\n113:   private val s2_s4_pendingRedirectValid = RegInit(false.B)\n\
      114:   when (s1_s3_redirect.valid) {\n115:     s2_s4_pendingRedirectValid :=
      true.B\n116:   }.elsewhen (GatedValidRegNext(io.frontend.toFtq.redirect.valid))
      {\n117:     s2_s4_pendingRedirectValid := false.B\n118:   }\n119: \n120:   //
      Redirect will be RegNext at ExuBlocks and IssueBlocks\n121:   val s2_s4_redirect
      = RegNextWithEnable(s1_s3_redirect)\n122:   val s3_s5_redirect = RegNextWithEnable(s2_s4_redirect)\n\
      123: \n124:   private val delayedNotFlushedWriteBack = io.fromWB.wbData.map(x
      => {\n125:     val valid = x.valid\n126:     val killedByOlder = x.bits.robIdx.needFlush(Seq(s1_s3_redirect,
      s2_s4_redirect))\n127:     val delayed = Wire(Valid(new ExuOutput(x.bits.params)))\n\
      128:     delayed.valid := GatedValidRegNext(valid && !killedByOlder)\n129: \
      \    delayed.bits := RegEnable(x.bits, x.valid)\n130:     delayed.bits.debugInfo.writebackTime
      := GTimer()\n131:     delayed"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 135-145
    context: "135:     x.valid := GatedValidRegNext(io.fromWB.wbData(i).valid)\n136:\
      \     x.bits := delayedNotFlushedWriteBack(i).bits\n137:   }\n138:   val delayedNotFlushedWriteBackNeedFlush
      = Wire(Vec(params.allExuParams.filter(_.needExceptionGen).length, Bool()))\n\
      139:   delayedNotFlushedWriteBackNeedFlush := delayedNotFlushedWriteBack.filter(_.bits.params.needExceptionGen).map{
      x =>\n140:     x.bits.exceptionVec.get.asUInt.orR || x.bits.flushPipe.getOrElse(false.B)
      || x.bits.replay.getOrElse(false.B) ||\n141:       (if (x.bits.trigger.nonEmpty)
      TriggerAction.isDmode(x.bits.trigger.get) else false.B)\n142:   }\n143: \n144:\
      \   val wbDataNoStd = io.fromWB.wbData.filter(!_.bits.params.hasStdFu)\n145:\
      \   val intScheWbData = io.fromWB.wbData.filter(_.bits.params.schdType.isInstanceOf[IntScheduler])"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 149-159
    context: "149:   val i2vWbData = intScheWbData.filter(_.bits.params.writeVecRf)\n\
      150:   val f2vWbData = fpScheWbData.filter(_.bits.params.writeVecRf)\n151: \
      \  val memVloadWbData = io.fromWB.wbData.filter(x => x.bits.params.schdType.isInstanceOf[MemScheduler]
      && x.bits.params.hasVLoadFu)\n152:   private val delayedNotFlushedWriteBackNums
      = wbDataNoStd.map(x => {\n153:     val valid = x.valid\n154:     val killedByOlder
      = x.bits.robIdx.needFlush(Seq(s1_s3_redirect, s2_s4_redirect, s3_s5_redirect))\n\
      155:     val delayed = Wire(Valid(UInt(io.fromWB.wbData.size.U.getWidth.W)))\n\
      156:     delayed.valid := GatedValidRegNext(valid && !killedByOlder)\n157: \
      \    val isIntSche = intCanCompress.contains(x)\n158:     val isFpSche = fpScheWbData.contains(x)\n\
      159:     val isVfSche = vfScheWbData.contains(x)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 174-184
    context: "174:       memVloadWbData\n175:     } else {\n176:       Seq(x)\n177:\
      \     }\n178:     val sameRobidxBools = VecInit(canSameRobidxWbData.map( wb
      => {\n179:       val killedByOlderThat = wb.bits.robIdx.needFlush(Seq(s1_s3_redirect,
      s2_s4_redirect, s3_s5_redirect))\n180:       (wb.bits.robIdx === x.bits.robIdx)
      && wb.valid && x.valid && !killedByOlderThat && !killedByOlder\n181:     }).toSeq)\n\
      182:     delayed.bits := RegEnable(PopCount(sameRobidxBools), x.valid)\n183:\
      \     delayed\n184:   }).toSeq"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 182-201
    context: "182:     delayed.bits := RegEnable(PopCount(sameRobidxBools), x.valid)\n\
      183:     delayed\n184:   }).toSeq\n185: \n186:   private val exuPredecode =
      VecInit(\n187:     io.fromWB.wbData.filter(_.bits.redirect.nonEmpty).map(x =>
      x.bits.predecodeInfo.get).toSeq\n188:   )\n189: \n190:   private val exuRedirects:
      Seq[ValidIO[Redirect]] = io.fromWB.wbData.filter(_.bits.redirect.nonEmpty).map(x
      => {\n191:     val hasCSR = x.bits.params.hasCSR\n192:     val out = Wire(Valid(new
      Redirect()))\n193:     out.valid := x.valid && x.bits.redirect.get.valid &&
      (x.bits.redirect.get.bits.cfiUpdate.isMisPred || x.bits.redirect.get.bits.cfiUpdate.hasBackendFault)
      && !x.bits.robIdx.needFlush(Seq(s1_s3_redirect, s2_s4_redirect))\n194:     out.bits
      := x.bits.redirect.get.bits\n195:     out.bits.debugIsCtrl := true.B\n196: \
      \    out.bits.debugIsMemVio := false.B\n197:     // for fix timing, next cycle
      assgin\n198:     if (!hasCSR) {\n199:       out.bits.cfiUpdate.backendIAF :=
      false.B\n200:       out.bits.cfiUpdate.backendIPF := false.B\n201:       out.bits.cfiUpdate.backendIGPF
      := false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 200-227
    context: "200:       out.bits.cfiUpdate.backendIPF := false.B\n201:       out.bits.cfiUpdate.backendIGPF
      := false.B\n202:     }\n203:     out\n204:   }).toSeq\n205:   private val oldestOneHot
      = Redirect.selectOldestRedirect(exuRedirects)\n206:   private val CSROH = VecInit(io.fromWB.wbData.filter(_.bits.redirect.nonEmpty).map(x
      => x.bits.params.hasCSR.B))\n207:   private val oldestExuRedirectIsCSR = oldestOneHot
      === CSROH\n208:   private val oldestExuRedirect = Mux1H(oldestOneHot, exuRedirects)\n\
      209:   private val oldestExuPredecode = Mux1H(oldestOneHot, exuPredecode)\n\
      210: \n211:   private val memViolation = io.fromMem.violation\n212:   val loadReplay
      = Wire(ValidIO(new Redirect))\n213:   loadReplay.valid := GatedValidRegNext(memViolation.valid)\n\
      214:   loadReplay.bits := RegEnable(memViolation.bits, memViolation.valid)\n\
      215:   loadReplay.bits.debugIsCtrl := false.B\n216:   loadReplay.bits.debugIsMemVio
      := true.B\n217: \n218:   pcMem.io.ren.get(pcMemRdIndexes(\"redirect\").head)
      := memViolation.valid\n219:   pcMem.io.raddr(pcMemRdIndexes(\"redirect\").head)
      := memViolation.bits.ftqIdx.value\n220:   pcMem.io.ren.get(pcMemRdIndexes(\"\
      memPred\").head) := memViolation.valid\n221:   pcMem.io.raddr(pcMemRdIndexes(\"\
      memPred\").head) := memViolation.bits.stFtqIdx.value\n222:   redirectGen.io.memPredPcRead.data
      := pcMem.io.rdata(pcMemRdIndexes(\"memPred\").head).startAddr + (RegEnable(memViolation.bits.stFtqOffset,
      memViolation.valid) << instOffsetBits)\n223: \n224:   for ((pcMemIdx, i) <-
      pcMemRdIndexes(\"bjuPc\").zipWithIndex) {\n225:     val ren = io.toDataPath.pcToDataPathIO.fromDataPathValid(i)\n\
      226:     val raddr = io.toDataPath.pcToDataPathIO.fromDataPathFtqPtr(i).value\n\
      227:     val roffset = io.toDataPath.pcToDataPathIO.fromDataPathFtqOffset(i)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 267-277
    context: "267:       pcMem.io.ren.get(pcMemIdx) := io.memStPcRead(i).valid\n268:\
      \       pcMem.io.raddr(pcMemIdx) := io.memStPcRead(i).ptr.value\n269:      \
      \ io.memStPcRead(i).data := pcMem.io.rdata(pcMemIdx).startAddr + (RegEnable(io.memStPcRead(i).offset,
      io.memStPcRead(i).valid) << instOffsetBits)\n270:     }\n271:   } else {\n272:\
      \     io.memStPcRead.foreach(_.data := 0.U)\n273:   }\n274: \n275:   /**\n276:\
      \    * trace begin\n277:    */"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 294-309
    context: "294:     io.fromCSR.traceCSR.currentPriv\n295:   )\n296:   io.traceCoreInterface.toEncoder.trap.cause
      := io.fromCSR.traceCSR.cause.asUInt\n297:   io.traceCoreInterface.toEncoder.trap.tval\
      \  := io.fromCSR.traceCSR.tval.asUInt\n298:   io.traceCoreInterface.toEncoder.priv\
      \       := tracePriv\n299:   (0 until TraceGroupNum).foreach(i => {\n300:  \
      \   io.traceCoreInterface.toEncoder.groups(i).valid := trace.io.out.toEncoder.blocks(i).valid\n\
      301:     io.traceCoreInterface.toEncoder.groups(i).bits.iaddr := tracePcStart(i)\n\
      302:     io.traceCoreInterface.toEncoder.groups(i).bits.ftqOffset.foreach(_
      := trace.io.out.toEncoder.blocks(i).bits.ftqOffset.getOrElse(0.U))\n303:   \
      \  io.traceCoreInterface.toEncoder.groups(i).bits.itype := trace.io.out.toEncoder.blocks(i).bits.tracePipe.itype\n\
      304:     io.traceCoreInterface.toEncoder.groups(i).bits.iretire := trace.io.out.toEncoder.blocks(i).bits.tracePipe.iretire\n\
      305:     io.traceCoreInterface.toEncoder.groups(i).bits.ilastsize := trace.io.out.toEncoder.blocks(i).bits.tracePipe.ilastsize\n\
      306:   })\n307:   /**\n308:    * trace end\n309:    */"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 307-337
    context: "307:   /**\n308:    * trace end\n309:    */\n310: \n311: \n312:   redirectGen.io.hartId
      := io.fromTop.hartId\n313:   redirectGen.io.oldestExuRedirect.valid := GatedValidRegNext(oldestExuRedirect.valid)\n\
      314:   redirectGen.io.oldestExuRedirect.bits := RegEnable(oldestExuRedirect.bits,
      oldestExuRedirect.valid)\n315:   redirectGen.io.oldestExuRedirectIsCSR := RegEnable(oldestExuRedirectIsCSR,
      oldestExuRedirect.valid)\n316:   redirectGen.io.instrAddrTransType := RegNext(io.fromCSR.instrAddrTransType)\n\
      317:   redirectGen.io.oldestExuOutPredecode.valid := GatedValidRegNext(oldestExuPredecode.valid)\n\
      318:   redirectGen.io.oldestExuOutPredecode := RegEnable(oldestExuPredecode,
      oldestExuPredecode.valid)\n319:   redirectGen.io.loadReplay <> loadReplay\n\
      320:   val loadRedirectOffset = Mux(memViolation.bits.flushItself(), 0.U, Mux(memViolation.bits.isRVC,
      2.U, 4.U))\n321:   val loadRedirectPcFtqOffset = RegEnable((memViolation.bits.ftqOffset
      << instOffsetBits).asUInt +& loadRedirectOffset, memViolation.valid)\n322: \
      \  val loadRedirectPcRead = pcMem.io.rdata(pcMemRdIndexes(\"redirect\").head).startAddr
      + loadRedirectPcFtqOffset\n323: \n324:   redirectGen.io.loadReplay.bits.cfiUpdate.pc
      := loadRedirectPcRead\n325:   val load_target = loadRedirectPcRead\n326:   redirectGen.io.loadReplay.bits.cfiUpdate.target
      := load_target\n327: \n328:   redirectGen.io.robFlush := s1_robFlushRedirect\n\
      329: \n330:   val s5_flushFromRobValidAhead = DelayN(s1_robFlushRedirect.valid,
      4)\n331:   val s6_flushFromRobValid = GatedValidRegNext(s5_flushFromRobValidAhead)\n\
      332:   val frontendFlushBits = RegEnable(s1_robFlushRedirect.bits, s1_robFlushRedirect.valid)
      // ??\n333:   // When ROB commits an instruction with a flush, we notify the
      frontend of the flush without the commit.\n334:   // Flushes to frontend may
      be delayed by some cycles and commit before flush causes errors.\n335:   //
      Thus, we make all flush reasons to behave the same as exceptions for frontend.\n\
      336:   for (i <- 0 until CommitWidth) {\n337:     // why flushOut: instructions
      with flushPipe are not commited to frontend"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 334-358
    context: "334:   // Flushes to frontend may be delayed by some cycles and commit
      before flush causes errors.\n335:   // Thus, we make all flush reasons to behave
      the same as exceptions for frontend.\n336:   for (i <- 0 until CommitWidth)
      {\n337:     // why flushOut: instructions with flushPipe are not commited to
      frontend\n338:     // If we commit them to frontend, it will cause flush after
      commit, which is not acceptable by frontend.\n339:     val s1_isCommit = rob.io.commits.commitValid(i)
      && rob.io.commits.isCommit && !s0_robFlushRedirect.valid\n340:     io.frontend.toFtq.rob_commits(i).valid
      := GatedValidRegNext(s1_isCommit)\n341:     io.frontend.toFtq.rob_commits(i).bits
      := RegEnable(rob.io.commits.info(i), s1_isCommit)\n342:   }\n343:   io.frontend.toFtq.redirect.valid
      := s6_flushFromRobValid || s3_redirectGen.valid\n344:   io.frontend.toFtq.redirect.bits
      := Mux(s6_flushFromRobValid, frontendFlushBits, s3_redirectGen.bits)\n345: \
      \  io.frontend.toFtq.ftqIdxSelOH.valid := s6_flushFromRobValid || redirectGen.io.stage2Redirect.valid\n\
      346:   io.frontend.toFtq.ftqIdxSelOH.bits := Cat(s6_flushFromRobValid, redirectGen.io.stage2oldestOH
      & Fill(NumRedirect + 1, !s6_flushFromRobValid))\n347: \n348:   //jmp/brh, sel
      oldest first, only use one read port\n349:   io.frontend.toFtq.ftqIdxAhead(0).valid
      := RegNext(oldestExuRedirect.valid) && !s1_robFlushRedirect.valid && !s5_flushFromRobValidAhead\n\
      350:   io.frontend.toFtq.ftqIdxAhead(0).bits := RegEnable(oldestExuRedirect.bits.ftqIdx,
      oldestExuRedirect.valid)\n351:   //loadreplay\n352:   io.frontend.toFtq.ftqIdxAhead(NumRedirect).valid
      := loadReplay.valid && !s1_robFlushRedirect.valid && !s5_flushFromRobValidAhead\n\
      353:   io.frontend.toFtq.ftqIdxAhead(NumRedirect).bits := loadReplay.bits.ftqIdx\n\
      354:   //exception\n355:   io.frontend.toFtq.ftqIdxAhead.last.valid := s5_flushFromRobValidAhead\n\
      356:   io.frontend.toFtq.ftqIdxAhead.last.bits := frontendFlushBits.ftqIdx\n\
      357: \n358:   // Be careful here:"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 361-374
    context: "361:   // T2: csr.redirect.valid\n362:   // T3: csr.exception.valid\n\
      363:   // T4: csr.trapTarget\n364:   // T5: ctrlBlock.trapTarget\n365:   //
      T6: io.frontend.toFtq.stage2Redirect.valid\n366:   val s2_robFlushPc = RegEnable(Mux(s1_robFlushRedirect.bits.flushItself(),\n\
      367:     s1_robFlushPc, // replay inst\n368:     s1_robFlushPc + Mux(s1_robFlushRedirect.bits.isRVC,
      2.U, 4.U) // flush pipe\n369:   ), s1_robFlushRedirect.valid)\n370:   private
      val s5_csrIsTrap = DelayN(rob.io.exception.valid, 4)\n371:   private val s5_trapTargetFromCsr
      = io.robio.csr.trapTarget\n372: \n373:   val flushTarget = Mux(s5_csrIsTrap,
      s5_trapTargetFromCsr.pc, s2_robFlushPc)\n374:   val s5_trapTargetIAF = Mux(s5_csrIsTrap,
      s5_trapTargetFromCsr.raiseIAF, false.B)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 372-387
    context: "372: \n373:   val flushTarget = Mux(s5_csrIsTrap, s5_trapTargetFromCsr.pc,
      s2_robFlushPc)\n374:   val s5_trapTargetIAF = Mux(s5_csrIsTrap, s5_trapTargetFromCsr.raiseIAF,
      false.B)\n375:   val s5_trapTargetIPF = Mux(s5_csrIsTrap, s5_trapTargetFromCsr.raiseIPF,
      false.B)\n376:   val s5_trapTargetIGPF = Mux(s5_csrIsTrap, s5_trapTargetFromCsr.raiseIGPF,
      false.B)\n377:   when (s6_flushFromRobValid) {\n378:     io.frontend.toFtq.redirect.bits.level
      := RedirectLevel.flush\n379:     io.frontend.toFtq.redirect.bits.cfiUpdate.target
      := RegEnable(flushTarget, s5_flushFromRobValidAhead)\n380:     io.frontend.toFtq.redirect.bits.cfiUpdate.backendIAF
      := RegEnable(s5_trapTargetIAF, s5_flushFromRobValidAhead)\n381:     io.frontend.toFtq.redirect.bits.cfiUpdate.backendIPF
      := RegEnable(s5_trapTargetIPF, s5_flushFromRobValidAhead)\n382:     io.frontend.toFtq.redirect.bits.cfiUpdate.backendIGPF
      := RegEnable(s5_trapTargetIGPF, s5_flushFromRobValidAhead)\n383:   }\n384: \n\
      385:   for (i <- 0 until DecodeWidth) {\n386:     gpaMem.io.fromIFU := io.frontend.fromIfu\n\
      387:     gpaMem.io.exceptionReadAddr.valid := rob.io.readGPAMemAddr.valid"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 391-404
    context: "391: \n392:   // vtype commit\n393:   decode.io.fromCSR := io.fromCSR.toDecode\n\
      394:   decode.io.fromRob.isResumeVType := rob.io.toDecode.isResumeVType\n395:\
      \   decode.io.fromRob.walkToArchVType := rob.io.toDecode.walkToArchVType\n396:\
      \   decode.io.fromRob.commitVType := rob.io.toDecode.commitVType\n397:   decode.io.fromRob.walkVType
      := rob.io.toDecode.walkVType\n398: \n399:   decode.io.redirect := s1_s3_redirect.valid
      || s2_s4_pendingRedirectValid\n400: \n401:   // add decode Buf for in.ready
      better timing\n402:   /**\n403:    * Decode buffer: when decode.io.in cannot
      accept all insts, use this buffer to temporarily store insts that cannot\n404:\
      \    * be sent to DecodeStage."
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 419-429
    context: "419: \n420:   /** Insts input from frontend, in vector of DecodeWidth
      */\n421:   val decodeFromFrontend = io.frontend.cfVec\n422: \n423:   /** Insts
      in buffer that is not ready but valid in decodeBufValid */\n424:   val decodeBufNotAccept
      = VecInit(decodeBufValid.zip(decode.io.in).map(x => x._1 && !x._2.ready))\n\
      425: \n426:   /** Number of insts in decode buffer that is accepted. All accepted
      insts are before the first unaccepted one. */\n427:   val decodeBufAcceptNum
      = PriorityMuxDefault(decodeBufNotAccept.zip(Seq.tabulate(DecodeWidth)(i => i.U)),
      DecodeWidth.U)\n428: \n429:   /** Input valid insts from frontend that is not
      ready to be accepted, or decoder prefer insts in decode buffer */"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 425-435
    context: "425: \n426:   /** Number of insts in decode buffer that is accepted.
      All accepted insts are before the first unaccepted one. */\n427:   val decodeBufAcceptNum
      = PriorityMuxDefault(decodeBufNotAccept.zip(Seq.tabulate(DecodeWidth)(i => i.U)),
      DecodeWidth.U)\n428: \n429:   /** Input valid insts from frontend that is not
      ready to be accepted, or decoder prefer insts in decode buffer */\n430:   val
      decodeFromFrontendNotAccept = VecInit(decodeFromFrontend.zip(decode.io.in).map(x
      => decodeBufValid(0) || x._1.valid && !x._2.ready))\n431: \n432:   /** Number
      of input insts that is accepted.\n433:    * All accepted insts are before the
      first unaccepted one. */\n434:   val decodeFromFrontendAcceptNum = PriorityMuxDefault(decodeFromFrontendNotAccept.zip(Seq.tabulate(DecodeWidth)(i
      => i.U)), DecodeWidth.U)\n435: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 459-469
    context: "459:    *   decodeBufValid(0) is false, decodeFromFrontendNotAccept.drop(i)
      has some true signals\n460:    *     decodeFromFrontend(i+decodeFromFrontendAcceptNum)\n\
      461:    */\n462:   for (i <- 0 until DecodeWidth) {\n463:     // decodeBufValid
      update\n464:     when(decode.io.redirect || decodeBufValid(0) && decodeBufValid(i)
      && decode.io.in(i).ready && !VecInit(decodeBufNotAccept.drop(i)).asUInt.orR)
      {\n465:       decodeBufValid(i) := false.B\n466:     }.elsewhen(decodeBufValid(i)
      && VecInit(decodeBufNotAccept.drop(i)).asUInt.orR) {\n467:       decodeBufValid(i)
      := Mux(decodeBufAcceptNum > DecodeWidth.U - 1.U - i.U, false.B, decodeBufValid(i.U
      + decodeBufAcceptNum))\n468:     }.elsewhen(!decodeBufValid(0) && VecInit(decodeFromFrontendNotAccept.drop(i)).asUInt.orR)
      {\n469:       decodeBufValid(i) := Mux(decodeFromFrontendAcceptNum > DecodeWidth.U
      - 1.U - i.U, false.B, decodeFromFrontend(i.U + decodeFromFrontendAcceptNum).valid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 491-503
    context: "491:    *\n492:    *   decode.io.in(i).bits:\n493:    *     decodeBufValid(i)
      is true : decodeBufBits(i)             | from decode buffer\n494:    *     \
      \                    false : decodeConnectFromFrontend(i) | from frontend\n\
      495:    */\n496:   decode.io.in.zipWithIndex.foreach { case (decodeIn, i) =>\n\
      497:     decodeIn.valid := Mux(decodeBufValid(0), decodeBufValid(i), decodeFromFrontend(i).valid)\n\
      498:     decodeFromFrontend(i).ready := decodeFromFrontend(0).valid && !decodeBufValid(0)
      && decodeFromFrontend(i).valid && !decode.io.redirect\n499:     decodeIn.bits
      := Mux(decodeBufValid(i), decodeBufBits(i), decodeConnectFromFrontend(i))\n\
      500:   }\n501:   /** no valid instr in decode buffer && no valid instr from
      frontend --> can accept new instr from frontend */\n502:   io.frontend.canAccept
      := !decodeBufValid(0) || !decodeFromFrontend(0).valid\n503:   decode.io.csrCtrl
      := RegNext(io.csrCtrl)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 512-551
    context: "512:   // snapshot check\n513:   class CFIRobIdx extends Bundle {\n\
      514:     val robIdx = Vec(RenameWidth, new RobPtr)\n515:     val isCFI = Vec(RenameWidth,
      Bool())\n516:   }\n517:   val genSnapshot = Cat(rename.io.out.map(out => out.fire
      && out.bits.snapshot)).orR\n518:   val snpt = Module(new SnapshotGenerator(0.U.asTypeOf(new
      CFIRobIdx)))\n519:   snpt.io.enq := genSnapshot\n520:   snpt.io.enqData.robIdx
      := rename.io.out.map(_.bits.robIdx)\n521:   snpt.io.enqData.isCFI := rename.io.out.map(_.bits.snapshot)\n\
      522:   snpt.io.deq := snpt.io.valids(snpt.io.deqPtr.value) && rob.io.commits.isCommit
      &&\n523:     Cat(rob.io.commits.commitValid.zip(rob.io.commits.robIdx).map(x
      => x._1 && x._2 === snpt.io.snapshots(snpt.io.deqPtr.value).robIdx.head)).orR\n\
      524:   snpt.io.redirect := s1_s3_redirect.valid\n525:   val flushVec = VecInit(snpt.io.snapshots.map
      { snapshot =>\n526:     val notCFIMask = snapshot.isCFI.map(~_)\n527:     val
      shouldFlush = snapshot.robIdx.map(robIdx => robIdx >= s1_s3_redirect.bits.robIdx
      || robIdx.value === s1_s3_redirect.bits.robIdx.value)\n528:     val shouldFlushMask
      = (1 to RenameWidth).map(shouldFlush take _ reduce (_ || _))\n529:     s1_s3_redirect.valid
      && Cat(shouldFlushMask.zip(notCFIMask).map(x => x._1 | x._2)).andR\n530:   })\n\
      531:   val flushVecNext = flushVec zip snpt.io.valids map (x => GatedValidRegNext(x._1
      && x._2, false.B))\n532:   snpt.io.flushVec := flushVecNext\n533: \n534:   val
      redirectRobidx = s1_s3_redirect.bits.robIdx\n535:   val useSnpt = VecInit.tabulate(RenameSnapshotNum){
      case idx =>\n536:     val snptRobidx = snpt.io.snapshots(idx).robIdx.head\n\
      537:     // (redirectRobidx.value =/= snptRobidx.value) for only flag diffrence\n\
      538:     snpt.io.valids(idx) && ((redirectRobidx > snptRobidx) && (redirectRobidx.value
      =/= snptRobidx.value) ||\n539:       !s1_s3_redirect.bits.flushItself() && redirectRobidx
      === snptRobidx)\n540:   }.reduceTree(_ || _)\n541:   val snptSelect = MuxCase(\n\
      542:     0.U(log2Ceil(RenameSnapshotNum).W),\n543:     (1 to RenameSnapshotNum).map(i
      => (snpt.io.enqPtr - i.U).value).map{case idx =>\n544:       val thisSnapRobidx
      = snpt.io.snapshots(idx).robIdx.head\n545:       (snpt.io.valids(idx) && (redirectRobidx
      > thisSnapRobidx && (redirectRobidx.value =/= thisSnapRobidx.value) ||\n546:\
      \         !s1_s3_redirect.bits.flushItself() && redirectRobidx === thisSnapRobidx),
      idx)\n547:     }\n548:   )\n549: \n550:   rob.io.snpt.snptEnq := DontCare\n\
      551:   rob.io.snpt.snptDeq := snpt.io.deq"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 549-564
    context: "549: \n550:   rob.io.snpt.snptEnq := DontCare\n551:   rob.io.snpt.snptDeq
      := snpt.io.deq\n552:   rob.io.snpt.useSnpt := useSnpt\n553:   rob.io.snpt.snptSelect
      := snptSelect\n554:   rob.io.snpt.flushVec := flushVecNext\n555:   rat.io.snpt.snptEnq
      := genSnapshot\n556:   rat.io.snpt.snptDeq := snpt.io.deq\n557:   rat.io.snpt.useSnpt
      := useSnpt\n558:   rat.io.snpt.snptSelect := snptSelect\n559:   rat.io.snpt.flushVec
      := flushVec\n560: \n561:   val decodeHasException = decode.io.out.map(x => x.bits.exceptionVec.asUInt.orR
      || (!TriggerAction.isNone(x.bits.trigger)))\n562:   // fusion decoder\n563:\
      \   fusionDecoder.io.disableFusion := disableFusion\n564:   for (i <- 0 until
      DecodeWidth) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 563-573
    context: "563:   fusionDecoder.io.disableFusion := disableFusion\n564:   for (i
      <- 0 until DecodeWidth) {\n565:     fusionDecoder.io.in(i).valid := decode.io.out(i).valid
      && !decodeHasException(i)\n566:     fusionDecoder.io.in(i).bits := decode.io.out(i).bits.instr\n\
      567:     if (i > 0) {\n568:       fusionDecoder.io.inReady(i - 1) := decode.io.out(i).ready\n\
      569:     }\n570:   }\n571: \n572:   private val decodePipeRename = Wire(Vec(RenameWidth,
      DecoupledIO(new DecodedInst)))\n573:   for (i <- 0 until RenameWidth) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 569-582
    context: "569:     }\n570:   }\n571: \n572:   private val decodePipeRename = Wire(Vec(RenameWidth,
      DecoupledIO(new DecodedInst)))\n573:   for (i <- 0 until RenameWidth) {\n574:\
      \     PipelineConnect(decode.io.out(i), decodePipeRename(i), rename.io.in(i).ready,\n\
      575:       s1_s3_redirect.valid || s2_s4_pendingRedirectValid, moduleName =
      Some(\"decodePipeRenameModule\"))\n576: \n577:     decodePipeRename(i).ready
      := rename.io.in(i).ready\n578:     rename.io.in(i).valid := decodePipeRename(i).valid
      && !fusionDecoder.io.clear(i)\n579:     rename.io.in(i).bits := decodePipeRename(i).bits\n\
      580:     dispatch.io.renameIn(i).valid := decodePipeRename(i).valid && !fusionDecoder.io.clear(i)
      && !decodePipeRename(i).bits.isMove\n581:     dispatch.io.renameIn(i).bits :=
      decodePipeRename(i).bits\n582:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 584-594
    context: "584:   for (i <- 0 until RenameWidth - 1) {\n585:     fusionDecoder.io.dec(i)
      := decodePipeRename(i).bits\n586:     rename.io.fusionInfo(i) := fusionDecoder.io.info(i)\n\
      587: \n588:     // update the first RenameWidth - 1 instructions\n589:     decode.io.fusion(i)
      := fusionDecoder.io.out(i).valid && rename.io.out(i).fire\n590:     // TODO:
      remove this dirty code for ftq update\n591:     val sameFtqPtr = rename.io.in(i).bits.ftqPtr.value
      === rename.io.in(i + 1).bits.ftqPtr.value\n592:     val ftqOffset0 = rename.io.in(i).bits.ftqOffset\n\
      593:     val ftqOffset1 = rename.io.in(i + 1).bits.ftqOffset\n594:     val ftqOffsetDiff
      = ftqOffset1 - ftqOffset0"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 597-607
    context: "597:     val cond3 = !sameFtqPtr && ftqOffset1 === 0.U\n598:     val
      cond4 = !sameFtqPtr && ftqOffset1 === 1.U\n599:     when (fusionDecoder.io.out(i).valid)
      {\n600:       fusionDecoder.io.out(i).bits.update(rename.io.in(i).bits)\n601:\
      \       fusionDecoder.io.out(i).bits.update(dispatch.io.renameIn(i).bits)\n\
      602:       rename.io.in(i).bits.commitType := Mux(cond1, 4.U, Mux(cond2, 5.U,
      Mux(cond3, 6.U, 7.U)))\n603:     }\n604:     XSError(fusionDecoder.io.out(i).valid
      && !cond1 && !cond2 && !cond3 && !cond4, p\"new condition $sameFtqPtr $ftqOffset0
      $ftqOffset1\\n\")\n605:   }\n606: \n607:   // memory dependency predict"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 607-619
    context: "607:   // memory dependency predict\n608:   // when decode, send fold
      pc to mdp\n609:   private val mdpFlodPcVecVld = Wire(Vec(DecodeWidth, Bool()))\n\
      610:   private val mdpFlodPcVec = Wire(Vec(DecodeWidth, UInt(MemPredPCWidth.W)))\n\
      611:   for (i <- 0 until DecodeWidth) {\n612:     mdpFlodPcVecVld(i) := decode.io.out(i).fire
      || GatedValidRegNext(decode.io.out(i).fire)\n613:     mdpFlodPcVec(i) := Mux(\n\
      614:       decode.io.out(i).fire,\n615:       decode.io.in(i).bits.foldpc,\n\
      616:       rename.io.in(i).bits.foldpc\n617:     )\n618:   }\n619: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 616-636
    context: "616:       rename.io.in(i).bits.foldpc\n617:     )\n618:   }\n619: \n\
      620:   // currently, we only update mdp info when isReplay\n621:   memCtrl.io.redirect
      := s1_s3_redirect\n622:   memCtrl.io.csrCtrl := io.csrCtrl                 \
      \         // RegNext in memCtrl\n623:   memCtrl.io.stIn := io.fromMem.stIn \
      \                       // RegNext in memCtrl\n624:   memCtrl.io.memPredUpdate
      := redirectGen.io.memPredUpdate  // RegNext in memCtrl\n625:   memCtrl.io.mdpFoldPcVecVld
      := mdpFlodPcVecVld\n626:   memCtrl.io.mdpFlodPcVec := mdpFlodPcVec\n627:   memCtrl.io.dispatchLFSTio
      <> dispatch.io.lfst\n628: \n629:   rat.io.redirect := s1_s3_redirect.valid\n\
      630:   rat.io.rabCommits := rob.io.rabCommits\n631:   rat.io.diffCommits.foreach(_
      := rob.io.diffCommits.get)\n632:   rat.io.intRenamePorts := rename.io.intRenamePorts\n\
      633:   rat.io.fpRenamePorts := rename.io.fpRenamePorts\n634:   rat.io.vecRenamePorts
      := rename.io.vecRenamePorts\n635:   rat.io.v0RenamePorts := rename.io.v0RenamePorts\n\
      636:   rat.io.vlRenamePorts := rename.io.vlRenamePorts"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 633-647
    context: "633:   rat.io.fpRenamePorts := rename.io.fpRenamePorts\n634:   rat.io.vecRenamePorts
      := rename.io.vecRenamePorts\n635:   rat.io.v0RenamePorts := rename.io.v0RenamePorts\n\
      636:   rat.io.vlRenamePorts := rename.io.vlRenamePorts\n637: \n638:   rename.io.redirect
      := s1_s3_redirect\n639:   rename.io.rabCommits := rob.io.rabCommits\n640:  \
      \ rename.io.singleStep := GatedValidRegNext(io.csrCtrl.singlestep)\n641:   rename.io.waittable
      := (memCtrl.io.waitTable2Rename zip decode.io.out).map{ case(waittable2rename,
      decodeOut) =>\n642:     RegEnable(waittable2rename, decodeOut.fire)\n643:  \
      \ }\n644:   rename.io.ssit := memCtrl.io.ssit2Rename\n645:   // disble mdp\n\
      646:   dispatch.io.lfst.resp := 0.U.asTypeOf(dispatch.io.lfst.resp)\n647:  \
      \ rename.io.waittable := 0.U.asTypeOf(rename.io.waittable)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 655-669
    context: "655:   rename.io.int_old_pdest := rat.io.int_old_pdest\n656:   rename.io.fp_old_pdest
      := rat.io.fp_old_pdest\n657:   rename.io.vec_old_pdest := rat.io.vec_old_pdest\n\
      658:   rename.io.v0_old_pdest := rat.io.v0_old_pdest\n659:   rename.io.vl_old_pdest
      := rat.io.vl_old_pdest\n660:   rename.io.debug_int_rat.foreach(_ := rat.io.debug_int_rat.get)\n\
      661:   rename.io.debug_fp_rat.foreach(_ := rat.io.debug_fp_rat.get)\n662:  \
      \ rename.io.debug_vec_rat.foreach(_ := rat.io.debug_vec_rat.get)\n663:   rename.io.debug_v0_rat.foreach(_
      := rat.io.debug_v0_rat.get)\n664:   rename.io.debug_vl_rat.foreach(_ := rat.io.debug_vl_rat.get)\n\
      665:   rename.io.stallReason.in <> decode.io.stallReason.out\n666:   rename.io.snpt.snptEnq
      := DontCare\n667:   rename.io.snpt.snptDeq := snpt.io.deq\n668:   rename.io.snpt.useSnpt
      := useSnpt\n669:   rename.io.snpt.snptSelect := snptSelect"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 666-684
    context: "666:   rename.io.snpt.snptEnq := DontCare\n667:   rename.io.snpt.snptDeq
      := snpt.io.deq\n668:   rename.io.snpt.useSnpt := useSnpt\n669:   rename.io.snpt.snptSelect
      := snptSelect\n670:   rename.io.snptIsFull := snpt.io.valids.asUInt.andR\n671:\
      \   rename.io.snpt.flushVec := flushVecNext\n672:   rename.io.snptLastEnq.valid
      := !isEmpty(snpt.io.enqPtr, snpt.io.deqPtr)\n673:   rename.io.snptLastEnq.bits
      := snpt.io.snapshots((snpt.io.enqPtr - 1.U).value).robIdx.head\n674: \n675:\
      \   val renameOut = Wire(chiselTypeOf(rename.io.out))\n676:   renameOut <> rename.io.out\n\
      677:   // pass all snapshot in the first element for correctness of blockBackward\n\
      678:   renameOut.tail.foreach(_.bits.snapshot := false.B)\n679:   renameOut.head.bits.snapshot
      := Mux(isFull(snpt.io.enqPtr, snpt.io.deqPtr),\n680:     false.B,\n681:    \
      \ Cat(rename.io.out.map(out => out.valid && out.bits.snapshot)).orR\n682:  \
      \ )\n683: \n684:   // pipeline between rename and dispatch"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 680-692
    context: "680:     false.B,\n681:     Cat(rename.io.out.map(out => out.valid &&
      out.bits.snapshot)).orR\n682:   )\n683: \n684:   // pipeline between rename
      and dispatch\n685:   PipeGroupConnect(renameOut, dispatch.io.fromRename, s1_s3_redirect.valid,
      dispatch.io.toRenameAllFire, \"renamePipeDispatch\")\n686: \n687:   dispatch.io.redirect
      := s1_s3_redirect\n688:   val enqRob = Wire(chiselTypeOf(rob.io.enq))\n689:\
      \   enqRob.canAccept := rob.io.enq.canAccept\n690:   enqRob.canAcceptForDispatch
      := rob.io.enq.canAcceptForDispatch\n691:   enqRob.isEmpty := rob.io.enq.isEmpty\n\
      692:   enqRob.resp := rob.io.enq.resp"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 690-700
    context: "690:   enqRob.canAcceptForDispatch := rob.io.enq.canAcceptForDispatch\n\
      691:   enqRob.isEmpty := rob.io.enq.isEmpty\n692:   enqRob.resp := rob.io.enq.resp\n\
      693:   enqRob.needAlloc := RegNext(dispatch.io.enqRob.needAlloc)\n694:   enqRob.req.zip(dispatch.io.enqRob.req).map
      { case (sink, source) =>\n695:     sink.valid := RegNext(source.valid && !rob.io.redirect.valid)\n\
      696:     sink.bits := RegEnable(source.bits, source.valid)\n697:   }\n698: \
      \  dispatch.io.enqRob.canAccept := enqRob.canAcceptForDispatch && !enqRob.req.map(x
      => x.valid && x.bits.blockBackward && enqRob.canAccept).reduce(_ || _)\n699:\
      \   dispatch.io.enqRob.canAcceptForDispatch := enqRob.canAcceptForDispatch\n\
      700:   dispatch.io.enqRob.isEmpty := enqRob.isEmpty && !enqRob.req.map(_.valid).reduce(_
      || _)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 699-709
    context: "699:   dispatch.io.enqRob.canAcceptForDispatch := enqRob.canAcceptForDispatch\n\
      700:   dispatch.io.enqRob.isEmpty := enqRob.isEmpty && !enqRob.req.map(_.valid).reduce(_
      || _)\n701:   dispatch.io.enqRob.resp := enqRob.resp\n702:   rob.io.enq.needAlloc
      := enqRob.needAlloc\n703:   rob.io.enq.req := enqRob.req\n704:   dispatch.io.robHead
      := rob.io.debugRobHead\n705:   dispatch.io.stallReason <> rename.io.stallReason.out\n\
      706:   dispatch.io.lqCanAccept := io.lqCanAccept\n707:   dispatch.io.sqCanAccept
      := io.sqCanAccept\n708:   dispatch.io.fromMem.lcommit := io.fromMemToDispatch.lcommit\n\
      709:   dispatch.io.fromMem.scommit := io.fromMemToDispatch.scommit"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 729-750
    context: "729:   dispatch.io.robFull := rob.io.robFull\n730:   dispatch.io.singleStep
      := GatedValidRegNext(io.csrCtrl.singlestep)\n731: \n732:   val toIssueBlockUops
      = Seq(io.toIssueBlock.intUops, io.toIssueBlock.fpUops, io.toIssueBlock.vfUops,
      io.toIssueBlock.memUops).flatten\n733:   toIssueBlockUops.zip(dispatch.io.toIssueQueues).map(x
      => x._1 <> x._2)\n734:   io.toIssueBlock.flush   <> s2_s4_redirect\n735: \n\
      736:   pcMem.io.wen.head   := GatedValidRegNext(io.frontend.fromFtq.pc_mem_wen)\n\
      737:   pcMem.io.waddr.head := RegEnable(io.frontend.fromFtq.pc_mem_waddr, io.frontend.fromFtq.pc_mem_wen)\n\
      738:   pcMem.io.wdata.head := RegEnable(io.frontend.fromFtq.pc_mem_wdata, io.frontend.fromFtq.pc_mem_wen)\n\
      739: \n740:   io.toDataPath.flush := s2_s4_redirect\n741:   io.toExuBlock.flush
      := s2_s4_redirect\n742: \n743: \n744:   rob.io.hartId := io.fromTop.hartId\n\
      745:   rob.io.redirect := s1_s3_redirect\n746:   rob.io.writeback := delayedNotFlushedWriteBack\n\
      747:   rob.io.exuWriteback := delayedWriteBack\n748:   rob.io.writebackNums
      := VecInit(delayedNotFlushedWriteBackNums)\n749:   rob.io.writebackNeedFlush
      := delayedNotFlushedWriteBackNeedFlush\n750:   rob.io.readGPAMemData := gpaMem.io.exceptionReadData"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 748-758
    context: "748:   rob.io.writebackNums := VecInit(delayedNotFlushedWriteBackNums)\n\
      749:   rob.io.writebackNeedFlush := delayedNotFlushedWriteBackNeedFlush\n750:\
      \   rob.io.readGPAMemData := gpaMem.io.exceptionReadData\n751:   rob.io.fromVecExcpMod.busy
      := io.fromVecExcpMod.busy\n752: \n753:   io.redirect := s1_s3_redirect\n754:\
      \ \n755:   // rob to int block\n756:   io.robio.csr <> rob.io.csr\n757:   //
      When wfi is disabled, it will not block ROB commit.\n758:   rob.io.csr.wfiEvent
      := io.robio.csr.wfiEvent"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 771-785
    context: "771:   rob.io.wfi.safeFromMem := io.toMem.wfi.wfiSafe\n772: \n773: \
      \  // rob to mem block\n774:   io.robio.lsq <> rob.io.lsq\n775: \n776:   io.diff_int_rat.foreach(_
      := rat.io.diff_int_rat.get)\n777:   io.diff_fp_rat .foreach(_ := rat.io.diff_fp_rat.get)\n\
      778:   io.diff_vec_rat.foreach(_ := rat.io.diff_vec_rat.get)\n779:   io.diff_v0_rat
      .foreach(_ := rat.io.diff_v0_rat.get)\n780:   io.diff_vl_rat .foreach(_ := rat.io.diff_vl_rat.get)\n\
      781: \n782:   rob.io.debug_ls := io.robio.debug_ls\n783:   rob.io.debugHeadLsIssue
      := io.robio.robHeadLsIssue\n784:   rob.io.lsTopdownInfo := io.robio.lsTopdownInfo\n\
      785:   rob.io.csr.criticalErrorState := io.robio.csr.criticalErrorState"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 789-799
    context: "789:   io.robio.robDeqPtr := rob.io.robDeqPtr\n790: \n791:   io.robio.storeDebugInfo
      <> rob.io.storeDebugInfo\n792: \n793:   // rob to backend\n794:   io.robio.commitVType
      := rob.io.toDecode.commitVType\n795:   // exu block to decode\n796:   decode.io.vsetvlVType
      := io.toDecode.vsetvlVType\n797:   // backend to decode\n798:   decode.io.vstart
      := io.toDecode.vstart\n799:   // backend to rob"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 805-817
    context: "805:   io.toVecExcpMod.excpInfo       := rob.io.toVecExcpMod.excpInfo\n\
      806:   // T  : rat receive rabCommit\n807:   // T+1: rat return oldPdest\n808:\
      \   io.toVecExcpMod.ratOldPest match {\n809:     case fromRat =>\n810:     \
      \  (0 until RabCommitWidth).foreach { idx =>\n811:         val v0Valid = RegNext(\n\
      812:           rat.io.rabCommits.isCommit &&\n813:           rat.io.rabCommits.isWalk
      &&\n814:           rat.io.rabCommits.commitValid(idx) &&\n815:           rat.io.rabCommits.info(idx).v0Wen\n\
      816:         )\n817:         fromRat.v0OldVdPdest(idx).valid := RegNext(v0Valid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 815-825
    context: "815:           rat.io.rabCommits.info(idx).v0Wen\n816:         )\n817:\
      \         fromRat.v0OldVdPdest(idx).valid := RegNext(v0Valid)\n818:        \
      \ fromRat.v0OldVdPdest(idx).bits := RegEnable(rat.io.v0_old_pdest(idx), v0Valid)\n\
      819:         val vecValid = RegNext(\n820:           rat.io.rabCommits.isCommit
      &&\n821:           rat.io.rabCommits.isWalk &&\n822:           rat.io.rabCommits.commitValid(idx)
      &&\n823:           rat.io.rabCommits.info(idx).vecWen\n824:         )\n825:\
      \         fromRat.vecOldVdPdest(idx).valid := RegNext(vecValid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 856-866
    context: "856:     val toDecode = Input(new CSRToDecode)\n857:     val traceCSR
      = Input(new TraceCSR)\n858:     val instrAddrTransType = Input(new AddrTransType)\n\
      859:   }\n860:   val toIssueBlock = new Bundle {\n861:     val flush = ValidIO(new
      Redirect)\n862:     val intUopsNum = backendParams.intSchdParams.get.issueBlockParams.map(_.numEnq).sum\n\
      863:     val fpUopsNum = backendParams.fpSchdParams.get.issueBlockParams.map(_.numEnq).sum\n\
      864:     val vfUopsNum = backendParams.vfSchdParams.get.issueBlockParams.map(_.numEnq).sum\n\
      865:     val memUopsNum = backendParams.memSchdParams.get.issueBlockParams.filter(x
      => x.StdCnt == 0).map(_.numEnq).sum\n866:     val intUops = Vec(intUopsNum,
      DecoupledIO(new DynInst))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 905-919
    context: "905:       val vlFromVfIsZero   = Input(Bool())\n906:       val vlFromVfIsVlmax\
      \  = Input(Bool())\n907:     }\n908:   }\n909:   val toDataPath = new Bundle
      {\n910:     val flush = ValidIO(new Redirect)\n911:     val pcToDataPathIO =
      new PcToDataPathIO(params)\n912:   }\n913:   val toExuBlock = new Bundle {\n\
      914:     val flush = ValidIO(new Redirect)\n915:   }\n916:   val toCSR = new
      Bundle {\n917:     val trapInstInfo = Output(ValidIO(new TrapInstInfo))\n918:\
      \   }\n919:   val fromWB = new Bundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 915-933
    context: "915:   }\n916:   val toCSR = new Bundle {\n917:     val trapInstInfo
      = Output(ValidIO(new TrapInstInfo))\n918:   }\n919:   val fromWB = new Bundle
      {\n920:     val wbData = Flipped(MixedVec(params.genWrite2CtrlBundles))\n921:\
      \   }\n922:   val redirect = ValidIO(new Redirect)\n923:   val fromMem = new
      Bundle {\n924:     val stIn = Vec(params.StaExuCnt, Flipped(ValidIO(new DynInst)))
      // use storeSetHit, ssid, robIdx\n925:     val violation = Flipped(ValidIO(new
      Redirect))\n926:   }\n927:   val memStPcRead = Vec(params.StaCnt, Flipped(new
      FtqRead(UInt(VAddrBits.W))))\n928:   val memHyPcRead = Vec(params.HyuCnt, Flipped(new
      FtqRead(UInt(VAddrBits.W))))\n929: \n930:   val csrCtrl = Input(new CustomCSRCtrlIO)\n\
      931:   val robio = new Bundle {\n932:     val csr = new RobCSRIO\n933:     val
      exception = ValidIO(new ExceptionInfo)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 934-944
    context: "934:     val lsq = new RobLsqIO\n935:     val lsTopdownInfo = Vec(params.LduCnt
      + params.HyuCnt, Input(new LsTopdownInfo))\n936:     val debug_ls = Input(new
      DebugLSIO())\n937:     val robHeadLsIssue = Input(Bool())\n938:     val robDeqPtr
      = Output(new RobPtr)\n939:     val commitVType = new Bundle {\n940:       val
      vtype = Output(ValidIO(VType()))\n941:       val hasVsetvl = Output(Bool())\n\
      942:     }\n943:     // store event difftest information\n944:     val storeDebugInfo
      = Vec(EnsbufferWidth, new Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/NewPipelineConnect.scala
    lines: 22-35
    context: "22: class NewPipelineConnectPipe[T <: Data](gen: T) extends Module {\n\
      23:   val io = IO(new Bundle() {\n24:     val in = Flipped(DecoupledIO(gen.cloneType))\n\
      25:     val out = DecoupledIO(gen.cloneType)\n26:     val rightOutFire = Input(Bool())\n\
      27:     val isFlush = Input(Bool())\n28:   })\n29: \n30:   NewPipelineConnect.connect(io.in,
      io.out, io.rightOutFire, io.isFlush)\n31: }\n32: \n33: object NewPipelineConnect
      {\n34:   def connect[T <: Data](\n35:                           left: DecoupledIO[T],"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/NewPipelineConnect.scala
    lines: 33-52
    context: "33: object NewPipelineConnect {\n34:   def connect[T <: Data](\n35:\
      \                           left: DecoupledIO[T],\n36:                     \
      \      right: DecoupledIO[T],\n37:                           rightOutFire: Bool,\n\
      38:                           isFlush: Bool\n39:                         ):
      T = {\n40:     val valid = RegInit(false.B)\n41: \n42:     left.ready := right.ready
      || !valid\n43:     val data = RegEnable(left.bits, left.fire)\n44: \n45:   \
      \  when (rightOutFire) { valid := false.B }\n46:     when (left.fire) { valid
      := true.B }\n47:     when (isFlush) { valid := false.B }\n48: \n49:     right.bits
      := data\n50:     right.valid := valid\n51: \n52:     data"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/NewPipelineConnect.scala
    lines: 54-64
    context: "54: \n55:   def apply[T <: Data](\n56:                         left:
      DecoupledIO[T],\n57:                         right: DecoupledIO[T],\n58:   \
      \                      rightOutFire: Bool,\n59:                         isFlush:
      Bool,\n60:                         moduleName: Option[String] = None\n61:  \
      \                     ): Option[T] = {\n62:     if (moduleName.isDefined) {\n\
      63:       val pipeline = Module(new NewPipelineConnectPipe(left.bits))\n64:\
      \       pipeline.suggestName(moduleName.get)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/NewPipelineConnect.scala
    lines: 62-77
    context: "62:     if (moduleName.isDefined) {\n63:       val pipeline = Module(new
      NewPipelineConnectPipe(left.bits))\n64:       pipeline.suggestName(moduleName.get)\n\
      65:       pipeline.io.in <> left\n66:       pipeline.io.rightOutFire := rightOutFire\n\
      67:       pipeline.io.isFlush := isFlush\n68:       pipeline.io.out <> right\n\
      69:       pipeline.io.out.ready := right.ready\n70:       None\n71:     }\n\
      72:     else {\n73:       // do not use module here to please DCE\n74:     \
      \  Some(connect(left, right, rightOutFire, isFlush))\n75:     }\n76:   }\n77:
      }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WakeUpConfig.scala
    lines: 13-23
    context: "13: \n14:   def getExuParam(exus: Seq[ExeUnitParams]) : ExeUnitParams
      = {\n15:     val filteredExus = exus.filter(_.name == this.name)\n16:     require(filteredExus.nonEmpty,
      s\"No exu named $name\")\n17:     require(filteredExus.size == 1, s\"Exu $name
      should be unique\")\n18:     filteredExus.head\n19:   }\n20: }\n21: \n22: class
      WakeUpSource(val name: String) extends WakeUpPoint {\n23:   def genIQWakeUpValidBundle(backendParam:
      BackendParams)(implicit p: Parameters): ValidIO[IssueQueueIQWakeUpBundle] =
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbFuBusyTable.scala
    lines: 25-36
    context: "25:   private val intSchdBusyTable = io.in.intSchdBusyTable\n26:   private
      val fpSchdBusyTable = io.in.fpSchdBusyTable\n27:   private val vfSchdBusyTable
      = io.in.vfSchdBusyTable\n28:   private val memSchdBusyTable = io.in.memSchdBusyTable\n\
      29:   private val intRespRead = io.out.intRespRead\n30:   private val fpRespRead
      = io.out.fpRespRead\n31:   private val vfRespRead = io.out.vfRespRead\n32: \
      \  private val memRespRead = io.out.memRespRead\n33:   private val intAllWbConflictFlag
      = io.out.wbConflictRead.flatten.flatten.map(_.intConflict)\n34:   private val
      fpAllWbConflictFlag = io.out.wbConflictRead.flatten.flatten.map(_.fpConflict)\n\
      35:   private val vfAllWbConflictFlag = io.out.wbConflictRead.flatten.flatten.map(_.vfConflict)\n\
      36:   private val v0AllWbConflictFlag = io.out.wbConflictRead.flatten.flatten.map(_.v0Conflict)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbFuBusyTable.scala
    lines: 46-60
    context: "46:   private val fpAllDeqRespSet = (intSchdBusyTable ++ fpSchdBusyTable
      ++ vfSchdBusyTable ++ memSchdBusyTable).flatten.map(_.fpDeqRespSet)\n47:   private
      val vfAllDeqRespSet = (intSchdBusyTable ++ fpSchdBusyTable ++ vfSchdBusyTable
      ++ memSchdBusyTable).flatten.map(_.vfDeqRespSet)\n48:   private val v0AllDeqRespSet
      = (intSchdBusyTable ++ fpSchdBusyTable ++ vfSchdBusyTable ++ memSchdBusyTable).flatten.map(_.v0DeqRespSet)\n\
      49:   private val vlAllDeqRespSet = (intSchdBusyTable ++ fpSchdBusyTable ++
      vfSchdBusyTable ++ memSchdBusyTable).flatten.map(_.vlDeqRespSet)\n50: \n51:\
      \   private val intAllRespRead = (intRespRead ++ fpRespRead ++ vfRespRead ++
      memRespRead).flatten.map(_.intWbBusyTable)\n52:   private val fpAllRespRead
      = (intRespRead ++ fpRespRead ++ vfRespRead ++ memRespRead).flatten.map(_.fpWbBusyTable)\n\
      53:   private val vfAllRespRead = (intRespRead ++ fpRespRead ++ vfRespRead ++
      memRespRead).flatten.map(_.vfWbBusyTable)\n54:   private val v0AllRespRead =
      (intRespRead ++ fpRespRead ++ vfRespRead ++ memRespRead).flatten.map(_.v0WbBusyTable)\n\
      55:   private val vlAllRespRead = (intRespRead ++ fpRespRead ++ vfRespRead ++
      memRespRead).flatten.map(_.vlWbBusyTable)\n56: \n57:   private val allExuParams
      = params.allExuParams\n58:   private val intAllBusyTableWithParms = intAllBusyTable.zip(allExuParams).toSeq\n\
      59:   private val fpAllBusyTableWithParms = fpAllBusyTable.zip(allExuParams).toSeq\n\
      60:   private val vfAllBusyTableWithParms = vfAllBusyTable.zip(allExuParams).toSeq"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbFuBusyTable.scala
    lines: 95-105
    context: "95:       case _ => throw new IllegalArgumentException(s\"WbConfig ${wbType}
      is not permitted\")\n96:     }\n97:   }\n98: \n99:   def writeBusyTable(wtBusyTable:
      Map[Int, Option[UInt]], busyTableWithParams: Seq[(Option[UInt], ExeUnitParams)],
      wbType: PregWB) = {\n100:     wtBusyTable.foreach { case (portId, busyTable)
      =>\n101:       if (busyTable.nonEmpty) {\n102:         busyTable.get := busyTableWithParams.filter
      { case (busyTable, p) => hitWbPort(busyTable, p, portId, wbType) }.map(_._1.get).reduce(_
      | _)\n103:       }\n104:     }\n105:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbFuBusyTable.scala
    lines: 103-113
    context: "103:       }\n104:     }\n105:   }\n106: \n107:   def writeConflict(wtConflict:
      Map[Int, Option[Bool]], deqRespSetWithParams: Seq[(Option[UInt], ExeUnitParams)],
      wbType: PregWB) = {\n108:     wtConflict.foreach { case (portId, conflict) =>\n\
      109:       if (conflict.nonEmpty) {\n110:         val deqRespSel = deqRespSetWithParams.filter
      { case (deqRespSet, p) => hitWbPort(deqRespSet, p, portId, wbType) }.map(_._1.get)\n\
      111:         val width = deqRespSel.map(x => x.getWidth).max\n112:         val
      deqRespSelUnify = deqRespSel.map(x => x.asTypeOf(UInt(width.W))).toSeq\n113:\
      \         conflict.get := (0 until width).map { case i =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbFuBusyTable.scala
    lines: 115-125
    context: "115:         }.reduce(_ | _)\n116:       }\n117:     }\n118:   }\n119:\
      \ \n120:   def readRes[T <: Data](sink: IndexedSeq[Option[T]], source: Map[Int,
      Option[T]], wbType: PregWB) = {\n121:     for (i <- 0 until sink.size) {\n122:\
      \       if (sink(i).nonEmpty) {\n123:         sink(i).get := source.map { case
      (portId, src) =>\n124:           if (hitWbPort(src, allExuParams(i), portId,
      wbType)) {\n125:             src.get.asTypeOf(sink(i).get).asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbFuBusyTable.scala
    lines: 144-176
    context: "144:   writeConflict(fpConflict, fpAllDeqRespSetWithParms, FpWB())\n\
      145:   writeConflict(vfConflict, vfAllDeqRespSetWithParms, VfWB())\n146:   writeConflict(v0Conflict,
      v0AllDeqRespSetWithParms, V0WB())\n147:   writeConflict(vlConflict, vlAllDeqRespSetWithParms,
      VlWB())\n148:   //read wbPort fuBusyTable to per exe\n149:   readRes(intAllRespRead,
      intWbBusyTable, IntWB())\n150:   readRes(fpAllRespRead, fpWbBusyTable, FpWB())\n\
      151:   readRes(vfAllRespRead, vfWbBusyTable, VfWB())\n152:   readRes(v0AllRespRead,
      v0WbBusyTable, V0WB())\n153:   readRes(vlAllRespRead, vlWbBusyTable, VlWB())\n\
      154:   //read wbPort conflict to dataPath\n155:   readRes(intAllWbConflictFlag,
      intConflict, IntWB())\n156:   readRes(fpAllWbConflictFlag, fpConflict, FpWB())\n\
      157:   readRes(vfAllWbConflictFlag, vfConflict, VfWB())\n158:   readRes(v0AllWbConflictFlag,
      v0Conflict, V0WB())\n159:   readRes(vlAllWbConflictFlag, vlConflict, VlWB())\n\
      160: }\n161: \n162: class WbFuBusyTableIO(implicit p: Parameters, params: BackendParams)
      extends XSBundle {\n163:   val in = new Bundle {\n164:     val intSchdBusyTable
      = MixedVec(params.intSchdParams.get.issueBlockParams.map(x => Input(x.genWbFuBusyTableWriteBundle)))\n\
      165:     val fpSchdBusyTable = MixedVec(params.fpSchdParams.get.issueBlockParams.map(x
      => Input(x.genWbFuBusyTableWriteBundle)))\n166:     val vfSchdBusyTable = MixedVec(params.vfSchdParams.get.issueBlockParams.map(x
      => Input(x.genWbFuBusyTableWriteBundle)))\n167:     val memSchdBusyTable = MixedVec(params.memSchdParams.get.issueBlockParams.map(x
      => Input(x.genWbFuBusyTableWriteBundle)))\n168:   }\n169:   val out = new Bundle
      {\n170:     val intRespRead = MixedVec(params.intSchdParams.get.issueBlockParams.map(x
      => Output(x.genWbFuBusyTableReadBundle)))\n171:     val fpRespRead = MixedVec(params.fpSchdParams.get.issueBlockParams.map(x
      => Output(x.genWbFuBusyTableReadBundle)))\n172:     val vfRespRead = MixedVec(params.vfSchdParams.get.issueBlockParams.map(x
      => Output(x.genWbFuBusyTableReadBundle)))\n173:     val memRespRead = MixedVec(params.memSchdParams.get.issueBlockParams.map(x
      => Output(x.genWbFuBusyTableReadBundle)))\n174:     val wbConflictRead = MixedVec(params.allSchdParams.map(x
      => MixedVec(x.issueBlockParams.map(x => Output(x.genWbConflictBundle())))))\n\
      175:   }\n176: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 7-17
    context: "7: import utility.XSError\n8: import xiangshan.backend.BackendParams\n\
      9: import xiangshan.backend.Bundles.{ExuOutput, WriteBackBundle}\n10: import
      xiangshan.backend.datapath.DataConfig._\n11: import xiangshan.backend.regfile.RfWritePortWithConfig\n\
      12: import xiangshan.{Redirect, XSBundle, XSModule}\n13: import xiangshan.SrcType.v0\n\
      14: import xiangshan.backend.fu.vector.Bundles.Vstart\n15: \n16: class WbArbiterDispatcherIO[T
      <: Data](private val gen: T, n: Int) extends Bundle {\n17:   val in = Flipped(DecoupledIO(gen))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 27-48
    context: "27: \n28:   private val acceptVec: Vec[Bool] = VecInit(acceptCond(io.in.bits)._1)\n\
      29: \n30:   XSError(io.in.valid && PopCount(acceptVec) > 1.U, p\"[ExeUnit] accept
      vec should no more than 1, ${Binary(acceptVec.asUInt)} \")\n31: \n32:   io.out.zipWithIndex.foreach
      { case (out, i) =>\n33:     out.valid := acceptVec(i) && io.in.valid\n34:  \
      \   out.bits := io.in.bits\n35:   }\n36: \n37:   io.in.ready := Cat(io.out.zip(acceptVec).map{
      case(out, canAccept) => out.ready && canAccept}).orR || acceptCond(io.in.bits)._2\n\
      38: }\n39: \n40: class WbArbiterIO()(implicit p: Parameters, params: WbArbiterParams)
      extends XSBundle {\n41:   val flush = Flipped(ValidIO(new Redirect))\n42:  \
      \ val in: MixedVec[DecoupledIO[WriteBackBundle]] = Flipped(params.genInput)\n\
      43:   val out: MixedVec[ValidIO[WriteBackBundle]] = params.genOutput\n44: \n\
      45:   def inGroup: Map[Int, Seq[DecoupledIO[WriteBackBundle]]] = in.groupBy(_.bits.params.port).map(x
      => (x._1, x._2.sortBy(_.bits.params.priority).toSeq))\n46: }\n47: \n48: class
      RealWBCollideChecker(params: WbArbiterParams)(implicit p: Parameters) extends
      XSModule {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 50-60
    context: "50: \n51:   private val inGroup: Map[Int, Seq[DecoupledIO[WriteBackBundle]]]
      = io.inGroup\n52: \n53:   private val arbiters: Seq[Option[RealWBArbiter[WriteBackBundle]]]
      = Seq.tabulate(params.numOut) { x => {\n54:     if (inGroup.contains(x)) {\n\
      55:       Some(Module(new RealWBArbiter(new WriteBackBundle(inGroup.values.head.head.bits.params,
      backendParams), inGroup(x).length)))\n56:     } else {\n57:       None\n58:\
      \     }\n59:   }}\n60: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 56-68
    context: "56:     } else {\n57:       None\n58:     }\n59:   }}\n60: \n61:   arbiters.zipWithIndex.foreach
      { case (arb, i) =>\n62:     if (arb.nonEmpty) {\n63:       arb.get.io.in.zip(inGroup(i)).foreach
      { case (arbIn, wbIn) =>\n64:         arbIn <> wbIn\n65:       }\n66:     }\n\
      67:   }\n68: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 64-77
    context: "64:         arbIn <> wbIn\n65:       }\n66:     }\n67:   }\n68: \n69:\
      \   io.out.zip(arbiters).foreach { case (wbOut, arb) =>\n70:     if (arb.nonEmpty)
      {\n71:       val arbOut = arb.get.io.out\n72:       arbOut.ready := true.B\n\
      73:       wbOut.valid := arbOut.valid\n74:       wbOut.bits := arbOut.bits\n\
      75:     } else {\n76:       wbOut := 0.U.asTypeOf(wbOut)\n77:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 81-91
    context: "81:     (params.wbCfgs.indices zip params.wbCfgs.map(_.port)).toMap\n\
      82:   }\n83: }\n84: \n85: class WbDataPathIO()(implicit p: Parameters, params:
      BackendParams) extends XSBundle {\n86:   val flush = Flipped(ValidIO(new Redirect()))\n\
      87: \n88:   val fromTop = new Bundle {\n89:     val hartId = Input(UInt(8.W))\n\
      90:   }\n91: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 87-103
    context: "87: \n88:   val fromTop = new Bundle {\n89:     val hartId = Input(UInt(8.W))\n\
      90:   }\n91: \n92:   val fromIntExu: MixedVec[MixedVec[DecoupledIO[ExuOutput]]]
      = Flipped(params.intSchdParams.get.genExuOutputDecoupledBundle)\n93: \n94: \
      \  val fromFpExu: MixedVec[MixedVec[DecoupledIO[ExuOutput]]] = Flipped(params.fpSchdParams.get.genExuOutputDecoupledBundle)\n\
      95: \n96:   val fromVfExu: MixedVec[MixedVec[DecoupledIO[ExuOutput]]] = Flipped(params.vfSchdParams.get.genExuOutputDecoupledBundle)\n\
      97: \n98:   val fromMemExu: MixedVec[MixedVec[DecoupledIO[ExuOutput]]] = Flipped(params.memSchdParams.get.genExuOutputDecoupledBundle)\n\
      99: \n100:   val fromCSR = Input(new Bundle {\n101:     val vstart = Vstart()\n\
      102:   })\n103: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 99-125
    context: "99: \n100:   val fromCSR = Input(new Bundle {\n101:     val vstart =
      Vstart()\n102:   })\n103: \n104:   val toIntPreg = Flipped(MixedVec(Vec(params.numPregWb(IntData()),\n\
      105:     new RfWritePortWithConfig(params.intPregParams.dataCfg, params.intPregParams.addrWidth))))\n\
      106: \n107:   val toFpPreg = Flipped(MixedVec(Vec(params.numPregWb(FpData()),\n\
      108:     new RfWritePortWithConfig(params.fpPregParams.dataCfg, params.fpPregParams.addrWidth))))\n\
      109: \n110:   val toVfPreg = Flipped(MixedVec(Vec(params.numPregWb(VecData()),\n\
      111:     new RfWritePortWithConfig(params.vfPregParams.dataCfg, params.vfPregParams.addrWidth))))\n\
      112: \n113:   val toV0Preg = Flipped(MixedVec(Vec(params.numPregWb(V0Data()),\n\
      114:     new RfWritePortWithConfig(params.v0PregParams.dataCfg, params.v0PregParams.addrWidth))))\n\
      115: \n116:   val toVlPreg = Flipped(MixedVec(Vec(params.numPregWb(VlData()),\n\
      117:     new RfWritePortWithConfig(params.vlPregParams.dataCfg, params.vlPregParams.addrWidth))))\n\
      118: \n119:   val toCtrlBlock = new Bundle {\n120:     val writeback: MixedVec[ValidIO[ExuOutput]]
      = params.genWrite2CtrlBundles\n121:   }\n122: }\n123: \n124: class WbDataPath(params:
      BackendParams)(implicit p: Parameters) extends XSModule {\n125:   val io = IO(new
      WbDataPathIO()(p, params))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 126-137
    context: "126: \n127:   // split\n128:   val fromExuPre = collection.mutable.Seq()
      ++ (io.fromIntExu ++ io.fromFpExu ++ io.fromVfExu ++ io.fromMemExu).flatten\n\
      129:   val fromExuVld: Seq[DecoupledIO[ExuOutput]] = fromExuPre.filter(_.bits.params.hasVLoadFu).toSeq\n\
      130:   val vldMgu: Seq[VldMergeUnit] = fromExuVld.map(x => Module(new VldMergeUnit(x.bits.params)))\n\
      131:   vldMgu.zip(fromExuVld).foreach{ case (mgu, exu) =>\n132:     mgu.io.flush
      := io.flush\n133:     mgu.io.writeback <> exu\n134:     // Since xs will flush
      pipe, when vstart is not 0 and execute vector mem inst, the value of vstart
      in CSR is the\n135:     // first element of this vector instruction. When exception
      occurs, the vstart in writeback bundle is the new one,\n136:     // So this
      vstart should never be used as the beginning of vector mem operation.\n137:\
      \     mgu.io.writeback.bits.vls.get.vpu.vstart := io.fromCSR.vstart"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 137-147
    context: "137:     mgu.io.writeback.bits.vls.get.vpu.vstart := io.fromCSR.vstart\n\
      138:   }\n139:   val wbReplaceVld = fromExuPre\n140:   val vldIdx: Seq[Int]
      = vldMgu.map(x => fromExuPre.indexWhere(_.bits.params == x.params))\n141:  \
      \ println(\"vldIdx: \" + vldIdx)\n142:   vldIdx.zip(vldMgu).foreach{ case (id,
      wb) =>\n143:     wbReplaceVld.update(id, wb.io.writebackAfterMerge)\n144:  \
      \ }\n145:   val fromExu = Wire(chiselTypeOf(MixedVecInit(wbReplaceVld.toSeq)))\n\
      146: \n147:   // io.fromExuPre ------------------------------------------------------------>
      fromExu"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 145-158
    context: "145:   val fromExu = Wire(chiselTypeOf(MixedVecInit(wbReplaceVld.toSeq)))\n\
      146: \n147:   // io.fromExuPre ------------------------------------------------------------>
      fromExu\n148:   //               \\                                        \
      \                 /\n149:   //                -> vldMgu.io.writeback -> vldMgu.io.writebackAfterMerge
      /\n150:   (fromExu zip wbReplaceVld).foreach { case (sink, source) =>\n151:\
      \     sink.valid := source.valid\n152:     sink.bits := source.bits\n153:  \
      \   source.ready := sink.ready\n154:   }\n155: \n156:   // fromExu -> ArbiterInput\n\
      157:   val intArbiterInputsWire = Wire(chiselTypeOf(fromExu))\n158:   val intArbiterInputsWireY
      = intArbiterInputsWire.filter(_.bits.params.writeIntRf)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 181-191
    context: "181:     val v0Wen  = exuOutput.v0Wen.getOrElse(false.B)\n182:     val
      vlWen  = exuOutput.vlWen.getOrElse(false.B)\n183:     (Seq(intWen, fpwen, vecWen,
      v0Wen, vlWen), !intWen && !fpwen && !vecWen && !v0Wen && !vlWen)\n184:   }\n\
      185: \n186:   intArbiterInputsWire.zip(fpArbiterInputsWire).zip(vfArbiterInputsWire).zip(v0ArbiterInputsWire).zip(vlArbiterInputsWire).zip(fromExu).foreach
      {\n187:     case (((((intArbiterInput, fpArbiterInput), vfArbiterInput), v0ArbiterInput),
      vlArbiterInput), exuOut) =>\n188:       val writeCond = acceptCond(exuOut.bits)\n\
      189:       val intWrite = Wire(Bool())\n190:       val fpWrite = Wire(Bool())\n\
      191:       val vfWrite = Wire(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 219-247
    context: "219:       println(s\"[WbDataPath] exu: ${exuOut.bits.params.exuIdx},
      uncertain: ${exuOut.bits.params.hasUncertainLatency}, certain: ${exuOut.bits.params.latencyCertain}\"\
      )\n220: \n221:       // only EXUs with uncertain latency need result of arbiter\n\
      222:       // the result data can be maintained until getting success in arbiter\n\
      223:       if (exuOut.bits.params.hasUncertainLatency) {\n224:         exuOut.ready
      := intArbiterInput.ready && intWrite || fpArbiterInput.ready && fpWrite || vfArbiterInput.ready
      && vfWrite || v0ArbiterInput.ready && v0Write || vlArbiterInput.ready && vlWrite
      || notWrite\n225:       } else {\n226:         exuOut.ready := true.B\n227:\
      \ \n228:         // for EXUs with certain latency, if the request fails in arbiter,
      the result data will be permanently lost\n229:         when (intWrite) {\n230:\
      \           assert(intArbiterInput.ready, s\"exu ${exuOut.bits.params.exuIdx}
      failed to write int regfile\\n\")\n231:         }\n232:         when(fpWrite)
      {\n233:           assert(fpArbiterInput.ready, s\"exu ${exuOut.bits.params.exuIdx}
      failed to write fp regfile\\n\")\n234:         }\n235:         when (vfWrite)
      {\n236:           assert(vfArbiterInput.ready, s\"exu ${exuOut.bits.params.exuIdx}
      failed to write vf regfile\\n\")\n237:         }\n238:         when (v0Write)
      {\n239:           assert(v0ArbiterInput.ready, s\"exu ${exuOut.bits.params.exuIdx}
      failed to write v0 regfile\\n\")\n240:         }\n241:         when (vlWrite)
      {\n242:           assert(vlArbiterInput.ready, s\"exu ${exuOut.bits.params.exuIdx}
      failed to write vl regfile\\n\")\n243:         }\n244:       }\n245:       //
      the ports not writting back pregs are always ready\n246:       // the ports
      set highest priority are always ready\n247:       if (exuOut.bits.params.hasNoDataWB
      || exuOut.bits.params.isHighestWBPriority) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 243-260
    context: "243:         }\n244:       }\n245:       // the ports not writting back
      pregs are always ready\n246:       // the ports set highest priority are always
      ready\n247:       if (exuOut.bits.params.hasNoDataWB || exuOut.bits.params.isHighestWBPriority)
      {\n248:         exuOut.ready := true.B\n249:       }\n250:   }\n251:   intArbiterInputsWireN.foreach(_.ready
      := false.B)\n252:   fpArbiterInputsWireN.foreach(_.ready := false.B)\n253: \
      \  vfArbiterInputsWireN.foreach(_.ready := false.B)\n254:   v0ArbiterInputsWireN.foreach(_.ready
      := false.B)\n255:   vlArbiterInputsWireN.foreach(_.ready := false.B)\n256: \n\
      257:   println(s\"[WbDataPath] write int preg: \" +\n258:     s\"IntExu(${io.fromIntExu.flatten.count(_.bits.params.writeIntRf)})
      \" +\n259:     s\"FpExu(${io.fromFpExu.flatten.count(_.bits.params.writeIntRf)})
      \" +\n260:     s\"VfExu(${io.fromVfExu.flatten.count(_.bits.params.writeIntRf)})
      \" +"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 296-346
    context: "296:   println(s\"[WbDataPath] vf preg write back port num: ${vfWbArbiter.io.out.size},
      active port: ${vfWbArbiter.io.inGroup.keys.toSeq.sorted}\")\n297:   println(s\"\
      [WbDataPath] v0 preg write back port num: ${v0WbArbiter.io.out.size}, active
      port: ${v0WbArbiter.io.inGroup.keys.toSeq.sorted}\")\n298:   println(s\"[WbDataPath]
      vl preg write back port num: ${vlWbArbiter.io.out.size}, active port: ${vlWbArbiter.io.inGroup.keys.toSeq.sorted}\"\
      )\n299: \n300:   // module assign\n301:   intWbArbiter.io.flush <> io.flush\n\
      302:   require(intWbArbiter.io.in.size == intArbiterInputsWireY.size, s\"intWbArbiter
      input size: ${intWbArbiter.io.in.size}, all int wb size: ${intArbiterInputsWireY.size}\"\
      )\n303:   intWbArbiter.io.in.zip(intArbiterInputsWireY).foreach { case (arbiterIn,
      in) =>\n304:     arbiterIn.valid := in.valid && in.bits.intWen.get\n305:   \
      \  in.ready := arbiterIn.ready\n306:     arbiterIn.bits.fromExuOutput(in.bits,
      \"int\")\n307:   }\n308:   private val intWbArbiterOut = intWbArbiter.io.out\n\
      309: \n310:   fpWbArbiter.io.flush <> io.flush\n311:   require(fpWbArbiter.io.in.size
      == fpArbiterInputsWireY.size, s\"fpWbArbiter input size: ${fpWbArbiter.io.in.size},
      all fp wb size: ${fpArbiterInputsWireY.size}\")\n312:   fpWbArbiter.io.in.zip(fpArbiterInputsWireY).foreach
      { case (arbiterIn, in) =>\n313:     arbiterIn.valid := in.valid && (in.bits.fpWen.getOrElse(false.B))\n\
      314:     in.ready := arbiterIn.ready\n315:     arbiterIn.bits.fromExuOutput(in.bits,
      \"fp\")\n316:   }\n317:   private val fpWbArbiterOut = fpWbArbiter.io.out\n\
      318: \n319:   vfWbArbiter.io.flush <> io.flush\n320:   require(vfWbArbiter.io.in.size
      == vfArbiterInputsWireY.size, s\"vfWbArbiter input size: ${vfWbArbiter.io.in.size},
      all vf wb size: ${vfArbiterInputsWireY.size}\")\n321:   vfWbArbiter.io.in.zip(vfArbiterInputsWireY).foreach
      { case (arbiterIn, in) =>\n322:     arbiterIn.valid := in.valid && (in.bits.vecWen.getOrElse(false.B))\n\
      323:     in.ready := arbiterIn.ready\n324:     arbiterIn.bits.fromExuOutput(in.bits,
      \"vf\")\n325:   }\n326:   private val vfWbArbiterOut = vfWbArbiter.io.out\n\
      327: \n328:   v0WbArbiter.io.flush <> io.flush\n329:   require(v0WbArbiter.io.in.size
      == v0ArbiterInputsWireY.size, s\"v0WbArbiter input size: ${v0WbArbiter.io.in.size},
      all v0 wb size: ${v0ArbiterInputsWireY.size}\")\n330:   v0WbArbiter.io.in.zip(v0ArbiterInputsWireY).foreach
      { case (arbiterIn, in) =>\n331:     arbiterIn.valid := in.valid && (in.bits.v0Wen.getOrElse(false.B))\n\
      332:     in.ready := arbiterIn.ready\n333:     arbiterIn.bits.fromExuOutput(in.bits,
      \"v0\")\n334:   }\n335:   private val v0WbArbiterOut = v0WbArbiter.io.out\n\
      336: \n337:   vlWbArbiter.io.flush <> io.flush\n338:   require(vlWbArbiter.io.in.size
      == vlArbiterInputsWireY.size, s\"vlWbArbiter input size: ${vlWbArbiter.io.in.size},
      all vl wb size: ${vlArbiterInputsWireY.size}\")\n339:   vlWbArbiter.io.in.zip(vlArbiterInputsWireY).foreach
      { case (arbiterIn, in) =>\n340:     arbiterIn.valid := in.valid && (in.bits.vlWen.getOrElse(false.B))\n\
      341:     in.ready := arbiterIn.ready\n342:     arbiterIn.bits.fromExuOutput(in.bits,
      \"vl\")\n343:   }\n344:   private val vlWbArbiterOut = vlWbArbiter.io.out\n\
      345: \n346:   // WB -> CtrlBlock"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 352-372
    context: "352:   private val vfExuWBs = WireInit(MixedVecInit(vfExuInputs))\n\
      353:   private val memExuInputs = io.fromMemExu.flatten.toSeq\n354:   private
      val memExuWBs = WireInit(MixedVecInit(memExuInputs))\n355: \n356:   // only
      fired port can write back to ctrl block\n357:   (intExuWBs zip intExuInputs).foreach
      { case (wb, input) => wb.valid := input.fire }\n358:   (fpExuWBs zip fpExuInputs).foreach
      { case (wb, input) => wb.valid := input.fire }\n359:   (vfExuWBs zip vfExuInputs).foreach
      { case (wb, input) => wb.valid := input.fire }\n360:   (memExuWBs zip memExuInputs).foreach
      { case (wb, input) => wb.valid := input.fire }\n361: \n362:   // io assign\n\
      363:   private val toIntPreg: MixedVec[RfWritePortWithConfig] = MixedVecInit(intWbArbiterOut.map(x
      => x.bits.asIntRfWriteBundle(x.fire)).toSeq)\n364:   private val toFpPreg: MixedVec[RfWritePortWithConfig]
      = MixedVecInit(fpWbArbiterOut.map(x => x.bits.asFpRfWriteBundle(x.fire)).toSeq)\n\
      365:   private val toVfPreg: MixedVec[RfWritePortWithConfig] = MixedVecInit(vfWbArbiterOut.map(x
      => x.bits.asVfRfWriteBundle(x.fire)).toSeq)\n366:   private val toV0Preg: MixedVec[RfWritePortWithConfig]
      = MixedVecInit(v0WbArbiterOut.map(x => x.bits.asV0RfWriteBundle(x.fire)).toSeq)\n\
      367:   private val toVlPreg: MixedVec[RfWritePortWithConfig] = MixedVecInit(vlWbArbiterOut.map(x
      => x.bits.asVlRfWriteBundle(x.fire)).toSeq)\n368: \n369:   private val wb2Ctrl
      = intExuWBs ++ fpExuWBs ++ vfExuWBs ++ memExuWBs\n370: \n371:   io.toIntPreg
      := toIntPreg\n372:   io.toFpPreg := toFpPreg"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 371-384
    context: "371:   io.toIntPreg := toIntPreg\n372:   io.toFpPreg := toFpPreg\n373:\
      \   io.toVfPreg := toVfPreg\n374:   io.toV0Preg := toV0Preg\n375:   io.toVlPreg
      := toVlPreg\n376:   io.toCtrlBlock.writeback.zip(wb2Ctrl).foreach { case (sink,
      source) =>\n377:     sink.valid := source.valid\n378:     sink.bits := source.bits\n\
      379:     source.ready := true.B\n380:   }\n381: \n382:   // debug\n383:   if(backendParams.debugEn)
      {\n384:     dontTouch(intArbiterInputsWire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 388-401
    context: "388:     dontTouch(vlArbiterInputsWire)\n389:   }\n390: \n391:   //
      difftest\n392:   if (env.EnableDifftest || env.AlwaysBasicDiff) {\n393:    \
      \ intWbArbiterOut.foreach(out => {\n394:       val difftest = DifftestModule(new
      DiffIntWriteback(IntPhyRegs))\n395:       difftest.coreid := io.fromTop.hartId\n\
      396:       difftest.valid := out.fire && out.bits.rfWen\n397:       difftest.address
      := out.bits.pdest\n398:       difftest.data := out.bits.data\n399:     })\n\
      400:   }\n401: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 398-411
    context: "398:       difftest.data := out.bits.data\n399:     })\n400:   }\n401:\
      \ \n402:   if (env.EnableDifftest || env.AlwaysBasicDiff) {\n403:     fpWbArbiterOut.foreach(out
      => {\n404:       val difftest = DifftestModule(new DiffFpWriteback(FpPhyRegs))\n\
      405:       difftest.coreid := io.fromTop.hartId\n406:       difftest.valid :=
      out.fire // all fp instr will write fp rf\n407:       difftest.address := out.bits.pdest\n\
      408:       difftest.data := out.bits.data\n409:     })\n410:   }\n411: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 408-421
    context: "408:       difftest.data := out.bits.data\n409:     })\n410:   }\n411:\
      \ \n412:   if (env.EnableDifftest || env.AlwaysBasicDiff) {\n413:     vfWbArbiterOut.foreach(out
      => {\n414:       val difftest = DifftestModule(new DiffVecWriteback(VfPhyRegs))\n\
      415:       difftest.coreid := io.fromTop.hartId\n416:       difftest.valid :=
      out.fire\n417:       difftest.address := out.bits.pdest\n418:       difftest.data(0)
      := out.bits.data(63, 0)\n419:       difftest.data(1) := out.bits.data(127, 64)\n\
      420:     })\n421:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 419-432
    context: "419:       difftest.data(1) := out.bits.data(127, 64)\n420:     })\n\
      421:   }\n422: \n423:   if (env.EnableDifftest || env.AlwaysBasicDiff) {\n424:\
      \     v0WbArbiterOut.foreach(out => {\n425:       val difftest = DifftestModule(new
      DiffVecV0Writeback(V0PhyRegs))\n426:       difftest.coreid := io.fromTop.hartId\n\
      427:       difftest.valid := out.fire\n428:       difftest.address := out.bits.pdest\n\
      429:       difftest.data(0) := out.bits.data(63, 0)\n430:       difftest.data(1)
      := out.bits.data(127, 64)\n431:     })\n432:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/BypassNetwork.scala
    lines: 24-41
    context: "24:   val fromDataPath = new FromDataPath\n25:   val toExus = new ToExus\n\
      26:   val fromExus = new FromExus\n27: \n28:   class FromDataPath extends Bundle
      {\n29:     val int: MixedVec[MixedVec[DecoupledIO[ExuInput]]] = Flipped(intSchdParams.genExuInputBundle)\n\
      30:     val fp : MixedVec[MixedVec[DecoupledIO[ExuInput]]] = Flipped(fpSchdParams.genExuInputBundle)\n\
      31:     val vf : MixedVec[MixedVec[DecoupledIO[ExuInput]]] = Flipped(vfSchdParams.genExuInputBundle)\n\
      32:     val mem: MixedVec[MixedVec[DecoupledIO[ExuInput]]] = Flipped(memSchdParams.genExuInputBundle)\n\
      33:     val immInfo: Vec[ImmInfo] = Input(Vec(params.allExuParams.size, new
      ImmInfo))\n34:     val rcData: MixedVec[MixedVec[Vec[UInt]]] = MixedVec(\n35:\
      \       Seq(intSchdParams, fpSchdParams, vfSchdParams, memSchdParams).map(schd
      => schd.issueBlockParams.map(iq => \n36:         MixedVec(iq.exuBlockParams.map(exu
      => Input(Vec(exu.numRegSrc, UInt(exu.srcDataBitsMax.W)))))\n37:       )).flatten\n\
      38:     )\n39:   }\n40: \n41:   class ToExus extends Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/BypassNetwork.scala
    lines: 37-65
    context: "37:       )).flatten\n38:     )\n39:   }\n40: \n41:   class ToExus extends
      Bundle {\n42:     val int: MixedVec[MixedVec[DecoupledIO[ExuInput]]] = intSchdParams.genExuInputCopySrcBundle\n\
      43:     val fp : MixedVec[MixedVec[DecoupledIO[ExuInput]]] = fpSchdParams.genExuInputCopySrcBundle\n\
      44:     val vf : MixedVec[MixedVec[DecoupledIO[ExuInput]]] = vfSchdParams.genExuInputCopySrcBundle\n\
      45:     val mem: MixedVec[MixedVec[DecoupledIO[ExuInput]]] = memSchdParams.genExuInputCopySrcBundle\n\
      46:   }\n47: \n48:   class FromExus extends Bundle {\n49:     val int: MixedVec[MixedVec[ValidIO[ExuBypassBundle]]]
      = Flipped(intSchdParams.genExuBypassValidBundle)\n50:     val fp : MixedVec[MixedVec[ValidIO[ExuBypassBundle]]]
      = Flipped(fpSchdParams.genExuBypassValidBundle)\n51:     val vf : MixedVec[MixedVec[ValidIO[ExuBypassBundle]]]
      = Flipped(vfSchdParams.genExuBypassValidBundle)\n52:     val mem: MixedVec[MixedVec[ValidIO[ExuBypassBundle]]]
      = Flipped(memSchdParams.genExuBypassValidBundle)\n53: \n54:     def connectExuOutput(\n\
      55:       getSinkVecN: FromExus => MixedVec[MixedVec[ValidIO[ExuBypassBundle]]]\n\
      56:     )(\n57:       sourceVecN: MixedVec[MixedVec[DecoupledIO[ExuOutput]]]\n\
      58:     ): Unit = {\n59:       getSinkVecN(this).zip(sourceVecN).foreach { case
      (sinkVec, sourcesVec) =>\n60:         sinkVec.zip(sourcesVec).foreach { case
      (sink, source) =>\n61:           sink.valid := source.valid\n62:           sink.bits.intWen
      := source.bits.intWen.getOrElse(false.B)\n63:           sink.bits.pdest := source.bits.pdest\n\
      64:           sink.bits.data := source.bits.data(0)\n65:         }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/BypassNetwork.scala
    lines: 81-91
    context: "81:   private val immInfo = io.fromDataPath.immInfo\n82: \n83:   println(s\"\
      [BypassNetwork] RCData num: ${fromDPsRCData.size}\")\n84: \n85:   // (exuIdx,
      srcIdx, bypassExuIdx)\n86:   private val forwardOrBypassValidVec3: MixedVec[Vec[Vec[Bool]]]
      = MixedVecInit(\n87:     fromDPs.map { (x: DecoupledIO[ExuInput]) =>\n88:  \
      \     println(s\"[BypassNetwork] ${x.bits.params.name} numRegSrc: ${x.bits.params.numRegSrc}\"\
      )\n89:       VecInit(x.bits.exuSources.map(_.map(_.toExuOH(x.bits.params))).getOrElse(\n\
      90:         // TODO: remove tmp max 1 for fake HYU1\n91:         VecInit(Seq.fill(x.bits.params.numRegSrc
      max 1)(VecInit(0.U(params.numExu.W).asBools)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/BypassNetwork.scala
    lines: 128-145
    context: "128: \n129:   println(s\"[BypassNetwork] HasBypass2SourceExuNum: ${fromDPsHasBypass2Source.size}
      HasBypass2SinkExuNum: ${fromDPsHasBypass2Sink.size} bypass2DataVecSize: ${bypass2DataVec.length}\"\
      )\n130:   println(s\"[BypassNetwork] HasBypass2SourceExu: ${fromDPsHasBypass2Source}\"\
      )\n131:   println(s\"[BypassNetwork] HasBypass2SinkExu: ${fromDPsHasBypass2Sink}\"\
      )\n132: \n133:   toExus.zip(fromDPs).foreach { case (sink, source) =>\n134:\
      \     connectSamePort(sink.bits, source.bits)\n135:     sink.valid := source.valid\n\
      136:     source.ready := sink.ready\n137:   }\n138: \n139:   toExus.zipWithIndex.foreach
      { case (exuInput, exuIdx) =>\n140:     exuInput.bits.src.zipWithIndex.foreach
      { case (src, srcIdx) =>\n141:       val imm = ImmExtractor(\n142:         immInfo(exuIdx).imm,\n\
      143:         immInfo(exuIdx).immType,\n144:         exuInput.bits.params.destDataBitsMax,\n\
      145:         exuInput.bits.params.immType.map(_.litValue)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/BypassNetwork.scala
    lines: 147-177
    context: "147:       val immLoadSrc0 = SignExt(ImmUnion.U.toImm32(immInfo(exuIdx).imm(immInfo(exuIdx).imm.getWidth
      - 1, ImmUnion.I.len)), XLEN)\n148:       val exuParm = exuInput.bits.params\n\
      149:       val isIntScheduler = exuParm.isIntExeUnit\n150:       val isReadVfRf=
      exuParm.readVfRf\n151:       val dataSource = exuInput.bits.dataSources(srcIdx)\n\
      152:       val isWakeUpSink = params.allIssueParams.filter(_.exuBlockParams.contains(exuParm)).head.exuBlockParams.map(_.isIQWakeUpSink).reduce(_
      || _)\n153:       val readForward = if (isWakeUpSink) dataSource.readForward
      else false.B\n154:       val readBypass = if (isWakeUpSink) dataSource.readBypass
      else false.B\n155:       val readZero = if (isIntScheduler) dataSource.readZero
      else false.B\n156:       val readV0 = if (srcIdx < 3 && isReadVfRf) dataSource.readV0
      else false.B\n157:       val readRegOH = exuInput.bits.dataSources(srcIdx).readRegOH\n\
      158:       val readRegCache = if (exuParm.needReadRegCache) exuInput.bits.dataSources(srcIdx).readRegCache
      else false.B\n159:       val readImm = if (exuParm.immType.nonEmpty || exuParm.hasLoadExu)
      exuInput.bits.dataSources(srcIdx).readImm else false.B\n160:       val bypass2ExuIdx
      = fromDPsHasBypass2Sink.indexOf(exuIdx)\n161:       println(s\"${exuParm.name}:
      bypass2ExuIdx is ${bypass2ExuIdx}\")\n162:       val readBypass2 = if (bypass2ExuIdx
      >= 0) dataSource.readBypass2 else false.B\n163:       src := Mux1H(\n164:  \
      \       Seq(\n165:           readForward    -> Mux1H(forwardOrBypassValidVec3(exuIdx)(srcIdx),
      forwardDataVec),\n166:           readBypass     -> Mux1H(forwardOrBypassValidVec3(exuIdx)(srcIdx),
      bypassDataVec),\n167:           readBypass2    -> (if (bypass2ExuIdx >= 0) Mux1H(bypass2ValidVec3(bypass2ExuIdx)(srcIdx),
      bypass2DataVec) else 0.U),\n168:           readZero       -> 0.U,\n169:    \
      \       readV0         -> (if (srcIdx < 3 && isReadVfRf) exuInput.bits.src(3)
      else 0.U),\n170:           readRegOH      -> fromDPs(exuIdx).bits.src(srcIdx),\n\
      171:           readRegCache   -> fromDPsRCData(exuIdx)(srcIdx),\n172:      \
      \     readImm        -> (if (exuParm.hasLoadExu && srcIdx == 0) immLoadSrc0
      else imm)\n173:         )\n174:       )\n175:     }\n176:     if (exuInput.bits.params.hasBrhFu)
      {\n177:       val immWidth = exuInput.bits.params.immType.map(x => SelImm.getImmUnion(x).len).max"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/BypassNetwork.scala
    lines: 186-196
    context: "186:       val immBJU = imm + Mux(isJALR, 0.U, (exuInput.bits.ftqOffset.getOrElse(0.U)
      << instOffsetBits).asUInt)\n187:       exuInput.bits.imm := immBJU\n188:   \
      \    exuInput.bits.nextPcOffset.get := nextPcOffset\n189:     }\n190:     exuInput.bits.copySrc.get.map(
      copysrc =>\n191:       copysrc.zip(exuInput.bits.src).foreach{ case(copy, src)
      => copy := src}\n192:     )\n193:   }\n194: \n195:   // to reg cache\n196: \
      \  private val forwardIntWenVec = VecInit("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/BypassNetwork.scala
    lines: 210-221
    context: "210:     fromExus.zip(bypassDataVec).filter(_._1.bits.params.needWriteRegCache).map(_._2)\n\
      211:   )\n212: \n213:   println(s\"[BypassNetwork] WriteRegCacheExuNum: ${forwardIntWenVec.size}\"\
      )\n214: \n215:   io.toDataPath.zipWithIndex.foreach{ case (x, i) => \n216: \
      \    x.wen := bypassIntWenVec(i)\n217:     x.addr := DontCare\n218:     x.data
      := bypassRCDataVec(i)\n219:     x.tag.foreach(_ := bypassTagVec(i))\n220:  \
      \ }\n221: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFWBConflictChecker.scala
    lines: 2-12
    context: "2: \n3: import org.chipsalliance.cde.config.Parameters\n4: import chisel3._\n\
      5: import chisel3.util._\n6: import utils.OptionWrapper\n7: import utils.SeqUtils.MixedVec2\n\
      8: import xiangshan.backend.BackendParams\n9: import xiangshan.backend.datapath.DataConfig._\n\
      10: import xiangshan.backend.datapath.WbConfig.{NoWB, PregWB}\n11: import xiangshan.backend.regfile.PregParams\n\
      12: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFWBConflictChecker.scala
    lines: 12-22
    context: "12: \n13: case class RFWBCollideCheckerParams (\n14:   inWbCfgs: Seq[Seq[Set[PregWB]]],\n\
      15:   pregParams: PregParams,\n16: ) {\n17:   def genInputBundle: MixedVec2[DecoupledIO[RFWBCollideCheckerBundle]]
      = {\n18:     val pregWidth = pregParams.addrWidth\n19:     utils.SeqUtils.mapToMixedVec2(this.filteredCfgs,
      (wb: PregWB) => DecoupledIO(new RFWBCollideCheckerBundle(wb, pregWidth)))\n\
      20:   }\n21: \n22:   def filteredCfgs: Seq[Seq[PregWB]] = inWbCfgs.map(_.map(x
      =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFWBConflictChecker.scala
    lines: 36-46
    context: "36:   def this(pregWidth_ : Int) = this(None, pregWidth_)\n37: }\n38:\
      \ \n39: class RFWBCollideCheckerIO(val params: RFWBCollideCheckerParams)(implicit
      p: Parameters) extends Bundle {\n40:   private val pregWidth = params.pregParams.addrWidth\n\
      41:   val in: MixedVec2[DecoupledIO[RFWBCollideCheckerBundle]] = Flipped(params.genInputBundle)\n\
      42:   val out = Vec(params.portMax + 1, Valid(new RFWBCollideCheckerBundle(pregWidth)))\n\
      43: }\n44: \n45: private object ArbiterCtrl {\n46:   def apply(request: Seq[Bool]):
      Seq[Bool] = request.length match {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFWBConflictChecker.scala
    lines: 44-54
    context: "44: \n45: private object ArbiterCtrl {\n46:   def apply(request: Seq[Bool]):
      Seq[Bool] = request.length match {\n47:     case 0 => Seq()\n48:     case 1
      => Seq(true.B)\n49:     case _ => request.head +: request.tail.init.scanLeft(request.head)(_
      || _).map(!_)\n50:   }\n51: }\n52: \n53: // when io.in.valid is false.B, io.in.ready
      is true.B\n54: class WBArbiter[T <: Data](val gen: T, val n: Int) extends Module
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFWBConflictChecker.scala
    lines: 67-77
    context: "67:   val isFull             = RegInit(VecInit(Seq.fill(n)(false.B)))\n\
      68:   val cancelCounterNext  = Wire(Vec(n, UInt(CounterWidth.W)))\n69:   val
      isFullNext         = Wire(Vec(n, Bool()))\n70:   val hasFull            = RegInit(false.B)\n\
      71:   val hasFullReq         = Wire(Bool())\n72:   val finalValid         =
      Wire(Vec(n, Bool()))\n73: \n74:   cancelCounter := cancelCounterNext\n75:  \
      \ isFull        := isFullNext\n76:   hasFull       := isFullNext.asUInt.orR\n\
      77:   hasFullReq    := io.in.zip(isFull).map{case (in, full) => in.valid &&
      full}.reduce(_ || _)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFWBConflictChecker.scala
    lines: 74-88
    context: "74:   cancelCounter := cancelCounterNext\n75:   isFull        := isFullNext\n\
      76:   hasFull       := isFullNext.asUInt.orR\n77:   hasFullReq    := io.in.zip(isFull).map{case
      (in, full) => in.valid && full}.reduce(_ || _)\n78: \n79:   cancelCounterNext.zip(isFullNext).zip(cancelCounter).zip(isFull).zipWithIndex.foreach{
      case ((((cntNext, fullNext), cnt), full), i) =>\n80:     when (io.in(i).valid
      && !io.in(i).ready) {\n81:       cntNext   := Mux(cnt === CounterThreshold.U,
      CounterThreshold.U, cnt + 1.U)\n82:       fullNext  := cnt(CounterWidth - 1,
      1).andR  // counterNext === CounterThreshold.U\n83:     }.elsewhen (io.in(i).valid
      && io.in(i).ready) {\n84:       cntNext   := 0.U\n85:       fullNext  := false.B\n\
      86:     }.otherwise {\n87:       cntNext   := cnt\n88:       fullNext  := full"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFWBConflictChecker.scala
    lines: 87-102
    context: "87:       cntNext   := cnt\n88:       fullNext  := full\n89:     }\n\
      90:   }\n91: \n92:   finalValid := io.in.zipWithIndex.map{ case (in, i) => in.valid
      && (!hasFull || !hasFullReq || isFull(i)) }\n93: \n94:   io.chosen := (n - 1).asUInt\n\
      95:   io.out.bits := io.in(n - 1).bits\n96:   for (i <- n - 2 to 0 by -1) {\n\
      97:     when(finalValid(i)) {\n98:       io.chosen := i.asUInt\n99:       io.out.bits
      := io.in(i).bits\n100:     }\n101:   }\n102: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFWBConflictChecker.scala
    lines: 102-115
    context: "102: \n103:   // in_valid    grant      ready\n104:   // 0         \
      \  *          1\n105:   // 1           0          0\n106:   // 1           1\
      \          1\n107:   val grant = ArbiterCtrl(finalValid)\n108:   for (((in,
      g), v) <- io.in.zip(grant).zip(finalValid))\n109:     in.ready := (g && v ||
      !in.valid) && io.out.ready\n110:   io.out.valid := !grant.last || finalValid.last\n\
      111: }\n112: \n113: // used in WbDataPath\n114: class RealWBArbiter[T <: Data](val
      gen: T, val n: Int) extends Module {\n115:   val io = IO(new ArbiterIO(gen,
      n))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFWBConflictChecker.scala
    lines: 123-133
    context: "123:     }\n124:   }\n125: \n126:   val grant = ArbiterCtrl(io.in.map(_.valid))\n\
      127:   for ((in, g) <- io.in.zip(grant))\n128:     in.ready := (g || !in.valid)
      && io.out.ready\n129:   io.out.valid := !grant.last || io.in.last.valid\n130:
      }\n131: \n132: abstract class RFWBCollideCheckerBase(params: RFWBCollideCheckerParams)(implicit
      p: Parameters) extends Module {\n133:   protected def portRange: Range"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFWBConflictChecker.scala
    lines: 152-164
    context: "152:       ))\n153:     )\n154:   }\n155: \n156:   // connection of
      IntWB or VfWB\n157:   arbiters.zipWithIndex.foreach { case (arb, portIdx) =>\n\
      158:     if (arb.nonEmpty) {\n159:       arb.get.io.in.zip(inGroup(portIdx)).foreach
      { case (arbiterIn, ioIn) =>\n160:         arbiterIn <> ioIn\n161:       }\n\
      162:     }\n163:   }\n164: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFWBConflictChecker.scala
    lines: 163-180
    context: "163:   }\n164: \n165:   // connection of NoWB\n166:   io.in.map(_.map(x
      =>\n167:     if (x.bits.wbCfg.get.isInstanceOf[NoWB]) {\n168:       x.ready
      := true.B\n169:     }\n170:   ))\n171: \n172:   io.out.zip(arbiters).foreach
      { case (out, arb) =>\n173:     if (arb.nonEmpty) {\n174:       val arbOut =
      arb.get.io.out\n175:       arbOut.ready := true.B\n176:       out.valid := arbOut.valid\n\
      177:       out.bits := arbOut.bits\n178:     } else {\n179:       out := 0.U.asTypeOf(out)\n\
      180:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RdConfig.scala
    lines: 12-26
    context: "12: \n13:   case class IntRD(port: Int = -1, priority: Int = Int.MaxValue)
      extends RdConfig() {\n14:     override def getDataConfig = IntData()\n15:  \
      \ }\n16: \n17:   case class FpRD(port: Int = -1, priority: Int = Int.MaxValue)
      extends RdConfig() {\n18:     override def getDataConfig = FpData()\n19:   }\n\
      20: \n21:   case class VfRD(port: Int = -1, priority: Int = Int.MaxValue) extends
      RdConfig() {\n22:     override def getDataConfig = VecData()\n23:   }\n24: \n\
      25:   case class V0RD(port: Int = -1, priority: Int = Int.MaxValue) extends
      RdConfig() {\n26:     override def getDataConfig = V0Data()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/VldMergeUnit.scala
    lines: 11-21
    context: "11: import yunsuan.vector.SewOH\n12: \n13: class VldMergeUnit(val params:
      ExeUnitParams)(implicit p: Parameters) extends XSModule {\n14:   val io = IO(new
      VldMergeUnitIO(params))\n15: \n16:   io.writeback.ready := io.writebackAfterMerge.ready\n\
      17: \n18:   val wbReg = Reg(Valid(new ExuOutput(params)))\n19:   val mgu = Module(new
      VldMgu(VLEN))\n20:   val vdAfterMerge = Wire(UInt(VLEN.W))\n21: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/VldMergeUnit.scala
    lines: 17-28
    context: "17: \n18:   val wbReg = Reg(Valid(new ExuOutput(params)))\n19:   val
      mgu = Module(new VldMgu(VLEN))\n20:   val vdAfterMerge = Wire(UInt(VLEN.W))\n\
      21: \n22:   val wbFire = !io.writeback.bits.robIdx.needFlush(io.flush) && io.writeback.fire\n\
      23:   wbReg.bits := Mux(io.writeback.fire, io.writeback.bits, wbReg.bits)\n\
      24:   wbReg.valid := wbFire\n25:   mgu.io.in.vd := wbReg.bits.data(0)\n26: \
      \  // oldVd is contained in data and is already masked with new data\n27:  \
      \ mgu.io.in.oldVd := wbReg.bits.data(0)\n28:   mgu.io.in.mask := Mux(wbReg.bits.vls.get.vpu.vm,
      Fill(VLEN, 1.U(1.W)), wbReg.bits.vls.get.vpu.vmask)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/VldMergeUnit.scala
    lines: 42-56
    context: "42:   //For the uop whose vl is modified by first-only-fault, the data
      written back can be used directly\n43:   vdAfterMerge := Mux(wbReg.bits.vlWen.getOrElse(false.B),
      wbReg.bits.data(0), mgu.io.out.vd)\n44: \n45:   io.writebackAfterMerge.valid
      := wbReg.valid\n46:   io.writebackAfterMerge.bits := wbReg.bits\n47:   io.writebackAfterMerge.bits.vecWen.foreach(_
      := wbReg.bits.vecWen.get)\n48:   io.writebackAfterMerge.bits.v0Wen.foreach(_
      := wbReg.bits.v0Wen.get)\n49:   io.writebackAfterMerge.bits.data := VecInit(Seq.fill(params.wbPathNum)(vdAfterMerge))\n\
      50: }\n51: \n52: class VldMergeUnitIO(param: ExeUnitParams)(implicit p: Parameters)
      extends XSBundle {\n53:   val flush = Flipped(ValidIO(new Redirect))\n54:  \
      \ val writeback = Flipped(DecoupledIO(new ExuOutput(param)))\n55:   val writebackAfterMerge
      = DecoupledIO(new ExuOutput(param))\n56: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/PcTargetMem.scala
    lines: 26-38
    context: "26:   private def hasRen: Boolean = true\n27:   private val targetMem
      = Module(new SyncDataModuleTemplate(new Ftq_RF_Components, FtqSize, numTargetMemRead,
      1, hasRen = hasRen))\n28:   private val targetPCVec : Vec[UInt] = Wire(Vec(params.numTargetReadPort,
      UInt(VAddrData().dataWidth.W)))\n29:   private val pcVec       : Vec[UInt] =
      Wire(Vec(params.numPcMemReadPort, UInt(VAddrData().dataWidth.W)))\n30: \n31:\
      \   targetMem.io.wen.head := GatedValidRegNext(io.fromFrontendFtq.pc_mem_wen)\n\
      32:   targetMem.io.waddr.head := RegEnable(io.fromFrontendFtq.pc_mem_waddr,
      io.fromFrontendFtq.pc_mem_wen)\n33:   targetMem.io.wdata.head := RegEnable(io.fromFrontendFtq.pc_mem_wdata,
      io.fromFrontendFtq.pc_mem_wen)\n34: \n35:   private val newestEn: Bool = io.fromFrontendFtq.newest_entry_en\n\
      36:   private val newestTarget: UInt = io.fromFrontendFtq.newest_entry_target\n\
      37: \n38:   for (i <- 0 until params.numTargetReadPort) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/Og2ForVector.scala
    lines: 19-65
    context: "19:   private val toExu               = io.toVfArithExu ++ io.toVecMemExu\n\
      20:   private val toIQOg2Resp         = io.toVfIQOg2Resp ++ io.toMemIQOg2Resp\n\
      21: \n22:   private val s1_validVec2        = fromOg1.map(_.map(_.valid))\n\
      23:   private val s1_dataVec2         = fromOg1.map(_.map(_.bits))\n24:   private
      val s1_readyVec2        = fromOg1.map(_.map(_.ready))\n25:   private val toExuFire\
      \           = toExu.map(_.map(_.fire))\n26:   private val toExuReady       \
      \   = toExu.map(_.map(_.ready))\n27:   private val og2IQNum: Int       = fromOg1.size\n\
      28:   private val og2IQPerExuNum      = fromOg1.map(_.size).toSeq\n29: \n30:\
      \   val s2_toExuValid               = Reg(MixedVec(\n31:     s1_validVec2.map(x
      => MixedVec(x.map(_.cloneType).toSeq)).toSeq\n32:   ))\n33:   val s2_toExuData\
      \                = Reg(MixedVec(\n34:     s1_dataVec2.map(x => MixedVec(x.map(_.cloneType).toSeq)).toSeq\n\
      35:   ))\n36: \n37:   for(i <- 0 until og2IQNum) {\n38:     for (j <- 0 until
      og2IQPerExuNum(i)) {\n39:       val s2_flush = s1_dataVec2(i)(j).robIdx.needFlush(Seq(io.flush,
      RegNextWithEnable(io.flush)))\n40:       val s1_ldCancel = LoadShouldCancel(s1_dataVec2(i)(j).loadDependency,
      io.ldCancel)\n41:       when(s1_validVec2(i)(j) && s1_readyVec2(i)(j) && !s2_flush
      && !s1_ldCancel) {\n42:         s2_toExuValid(i)(j) := true.B\n43:         s2_toExuData(i)(j)
      := s1_dataVec2(i)(j)\n44:         s2_toExuData(i)(j).loadDependency.foreach(_
      := s1_dataVec2(i)(j).loadDependency.get.map(_ << 1))\n45:       }.otherwise
      {\n46:         s2_toExuValid(i)(j) := false.B\n47:       }\n48:       s1_readyVec2(i)(j)
      := true.B\n49:       toExu(i)(j).valid := s2_toExuValid(i)(j)\n50:       toExu(i)(j).bits
      := s2_toExuData(i)(j)\n51:     }\n52:   }\n53:   toIQOg2Resp.zipWithIndex.foreach
      {\n54:     case (toIQ, iqId) =>\n55:       toIQ.zipWithIndex.foreach {\n56:\
      \         case (og2Resp, exuId) =>\n57:           val og2Failed = s2_toExuValid(iqId)(exuId)
      && !toExuReady(iqId)(exuId)\n58:           og2Resp.valid := s2_toExuValid(iqId)(exuId)\n\
      59:           og2Resp.bits.robIdx := s2_toExuData(iqId)(exuId).robIdx\n60: \
      \          og2Resp.bits.uopIdx.foreach(_ := s2_toExuData(iqId)(exuId).vpu.get.vuopIdx)\n\
      61:           og2Resp.bits.resp := Mux(og2Failed, RespType.block, \n62:    \
      \         if (og2Resp.bits.params match { case x => x.isVecMemIQ })\n63:   \
      \            RespType.uncertain\n64:             else\n65:               RespType.success"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/Og2ForVector.scala
    lines: 63-77
    context: "63:               RespType.uncertain\n64:             else\n65:    \
      \           RespType.success\n66:           )\n67:           og2Resp.bits.fuType
      := s2_toExuData(iqId)(exuId).fuType\n68:           og2Resp.bits.sqIdx.foreach(_
      := 0.U.asTypeOf(new SqPtr))\n69:           og2Resp.bits.lqIdx.foreach(_ := 0.U.asTypeOf(new
      LqPtr))\n70:       }\n71:   }\n72:   io.toBypassNetworkImmInfo := io.fromOg1ImmInfo.zip(s1_validVec2.flatten).map{\n\
      73:     case (imm, valid) => RegEnable(imm, valid)\n74:   }\n75: }\n76: \n77:
      class Og2ForVectorIO(params: BackendParams)(implicit p: Parameters) extends
      XSBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/Og2ForVector.scala
    lines: 76-93
    context: "76: \n77: class Og2ForVectorIO(params: BackendParams)(implicit p: Parameters)
      extends XSBundle {\n78:   private val vfSchdParams = params.schdParams(VfScheduler())\n\
      79:   private val memSchdParams = params.schdParams(MemScheduler())\n80: \n\
      81:   val flush: ValidIO[Redirect]                                    = Flipped(ValidIO(new
      Redirect))\n82:   val ldCancel                                             \
      \       = Vec(backendParams.LduCnt + backendParams.HyuCnt, Flipped(new LoadCancelIO))\n\
      83: \n84:   val fromOg1VfArith: MixedVec[MixedVec[DecoupledIO[ExuInput]]]  \
      \ = Flipped(vfSchdParams.genExuInputBundle)\n85:   val fromOg1VecMem: MixedVec[MixedVec[DecoupledIO[ExuInput]]]\
      \    = Flipped(MixedVec(memSchdParams.issueBlockParams.filter(_.needOg2Resp).map(_.genExuInputDecoupledBundle)))\n\
      86:   val fromOg1ImmInfo: Vec[ImmInfo]                                = Input(Vec(params.allIssueParams.filter(_.needOg2Resp).flatMap(_.exuBlockParams).size,
      new ImmInfo))\n87: \n88:   val toVfArithExu                                \
      \                = MixedVec(vfSchdParams.genExuInputBundle)\n89:   val toVecMemExu\
      \                                                 = MixedVec(memSchdParams.issueBlockParams.filter(_.needOg2Resp).map(_.genExuInputDecoupledBundle))\n\
      90:   val toVfIQOg2Resp                                               = MixedVec(vfSchdParams.issueBlockParams.map(_.genOG2RespBundle))\n\
      91:   val toMemIQOg2Resp                                              = MixedVec(memSchdParams.issueBlockParams.filter(_.needOg2Resp).map(_.genOG2RespBundle))\n\
      92:   val toBypassNetworkImmInfo: Vec[ImmInfo]                        = Output(Vec(params.allIssueParams.filter(_.needOg2Resp).flatMap(_.exuBlockParams).size,
      new ImmInfo))\n93: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 49-63
    context: "49: \n50:   println(s\"[DataPath] IntIQ(${fromIntIQ.size}), FpIQ(${fromFpIQ.size}),
      VecIQ(${fromVfIQ.size}), MemIQ(${fromMemIQ.size})\")\n51:   println(s\"[DataPath]
      IntExu(${fromIntIQ.map(_.size).sum}), FpExu(${fromFpIQ.map(_.size).sum}), VecExu(${fromVfIQ.map(_.size).sum}),
      MemExu(${fromMemIQ.map(_.size).sum})\")\n52: \n53:   // just refences for convience\n\
      54:   private val fromIQ: Seq[MixedVec[DecoupledIO[IssueQueueIssueBundle]]]
      = (fromIntIQ ++ fromFpIQ ++ fromVfIQ ++ fromMemIQ).toSeq\n55: \n56:   private
      val toIQs = toIntIQ ++ toFpIQ ++ toVfIQ ++ toMemIQ\n57: \n58:   private val
      toExu: Seq[MixedVec[DecoupledIO[ExuInput]]] = (toIntExu ++ toFpExu ++ toVfExu
      ++ toMemExu).toSeq\n59: \n60:   private val fromFlattenIQ: Seq[DecoupledIO[IssueQueueIssueBundle]]
      = fromIQ.flatten\n61: \n62:   private val toFlattenExu: Seq[DecoupledIO[ExuInput]]
      = toExu.flatten\n63: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 71-95
    context: "71:   private val fpRFReadArbiter = Module(new FpRFReadArbiter(backendParams))\n\
      72:   private val vfRFReadArbiter = Module(new VfRFReadArbiter(backendParams))\n\
      73:   private val v0RFReadArbiter = Module(new V0RFReadArbiter(backendParams))\n\
      74:   private val vlRFReadArbiter = Module(new VlRFReadArbiter(backendParams))\n\
      75: \n76:   private val og0FailedVec2: MixedVec[Vec[Bool]] = Wire(MixedVec(fromIQ.map(x
      => Vec(x.size, Bool())).toSeq))\n77:   private val og1FailedVec2: MixedVec[Vec[Bool]]
      = Wire(MixedVec(fromIQ.map(x => Vec(x.size, Bool())).toSeq))\n78: \n79:   //
      port -> win\n80:   private val intRdArbWinner: Seq2[MixedVec[Bool]] = intRFReadArbiter.io.in.map(_.map(x
      => MixedVecInit(x.map(_.ready).toSeq)).toSeq).toSeq\n81:   private val fpRdArbWinner:
      Seq2[MixedVec[Bool]] = fpRFReadArbiter.io.in.map(_.map(x => MixedVecInit(x.map(_.ready).toSeq)).toSeq).toSeq\n\
      82:   private val vfRdArbWinner: Seq2[MixedVec[Bool]] = vfRFReadArbiter.io.in.map(_.map(x
      => MixedVecInit(x.map(_.ready).toSeq)).toSeq).toSeq\n83:   private val v0RdArbWinner:
      Seq2[MixedVec[Bool]] = v0RFReadArbiter.io.in.map(_.map(x => MixedVecInit(x.map(_.ready).toSeq)).toSeq).toSeq\n\
      84:   private val vlRdArbWinner: Seq2[MixedVec[Bool]] = vlRFReadArbiter.io.in.map(_.map(x
      => MixedVecInit(x.map(_.ready).toSeq)).toSeq).toSeq\n85: \n86:   private val
      intWbNotBlock: Seq[MixedVec[Bool]] = intWbBusyArbiter.io.in.map(x => MixedVecInit(x.map(_.ready).toSeq)).toSeq\n\
      87:   private val fpWbNotBlock: Seq[MixedVec[Bool]] = fpWbBusyArbiter.io.in.map(x
      => MixedVecInit(x.map(_.ready).toSeq)).toSeq\n88:   private val vfWbNotBlock:
      Seq[MixedVec[Bool]] = vfWbBusyArbiter.io.in.map(x => MixedVecInit(x.map(_.ready).toSeq)).toSeq\n\
      89:   private val v0WbNotBlock: Seq[MixedVec[Bool]] = v0WbBusyArbiter.io.in.map(x
      => MixedVecInit(x.map(_.ready).toSeq)).toSeq\n90:   private val vlWbNotBlock:
      Seq[MixedVec[Bool]] = vlWbBusyArbiter.io.in.map(x => MixedVecInit(x.map(_.ready).toSeq)).toSeq\n\
      91: \n92:   private val intRdNotBlock: Seq2[Bool] = intRdArbWinner.map(_.map(_.asUInt.andR))\n\
      93:   private val fpRdNotBlock: Seq2[Bool] = fpRdArbWinner.map(_.map(_.asUInt.andR))\n\
      94:   private val vfRdNotBlock: Seq2[Bool] = vfRdArbWinner.map(_.map(_.asUInt.andR))\n\
      95:   private val v0RdNotBlock: Seq2[Bool] = v0RdArbWinner.map(_.map(_.asUInt.andR))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 96-106
    context: "96:   private val vlRdNotBlock: Seq2[Bool] = vlRdArbWinner.map(_.map(_.asUInt.andR))\n\
      97: \n98:   private val intRFReadReq: Seq3[ValidIO[RfReadPortWithConfig]] =
      fromIQ.map(x => x.map(xx => xx.bits.getRfReadValidBundle(xx.valid)).toSeq).toSeq\n\
      99:   private val fpRFReadReq: Seq3[ValidIO[RfReadPortWithConfig]] = fromIQ.map(x
      => x.map(xx => xx.bits.getRfReadValidBundle(xx.valid)).toSeq).toSeq\n100:  \
      \ private val vfRFReadReq: Seq3[ValidIO[RfReadPortWithConfig]] = fromIQ.map(x
      => x.map(xx => xx.bits.getRfReadValidBundle(xx.valid)).toSeq).toSeq\n101:  \
      \ private val v0RFReadReq: Seq3[ValidIO[RfReadPortWithConfig]] = fromIQ.map(x
      => x.map(xx => xx.bits.getRfReadValidBundle(xx.valid)).toSeq).toSeq\n102:  \
      \ private val vlRFReadReq: Seq3[ValidIO[RfReadPortWithConfig]] = fromIQ.map(x
      => x.map(xx => xx.bits.getRfReadValidBundle(xx.valid)).toSeq).toSeq\n103: \n\
      104:   private val allDataSources: Seq[Seq[Vec[DataSource]]] = fromIQ.map(x
      => x.map(xx => xx.bits.common.dataSources).toSeq)\n105:   private val allNumRegSrcs:
      Seq[Seq[Int]] = fromIQ.map(x => x.map(xx => xx.bits.exuParams.numRegSrc).toSeq)\n\
      106: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 102-117
    context: "102:   private val vlRFReadReq: Seq3[ValidIO[RfReadPortWithConfig]]
      = fromIQ.map(x => x.map(xx => xx.bits.getRfReadValidBundle(xx.valid)).toSeq).toSeq\n\
      103: \n104:   private val allDataSources: Seq[Seq[Vec[DataSource]]] = fromIQ.map(x
      => x.map(xx => xx.bits.common.dataSources).toSeq)\n105:   private val allNumRegSrcs:
      Seq[Seq[Int]] = fromIQ.map(x => x.map(xx => xx.bits.exuParams.numRegSrc).toSeq)\n\
      106: \n107:   intRFReadArbiter.io.in.zip(intRFReadReq).zipWithIndex.foreach
      { case ((arbInSeq2, inRFReadReqSeq2), iqIdx) =>\n108:     arbInSeq2.zip(inRFReadReqSeq2).zipWithIndex.foreach
      { case ((arbInSeq, inRFReadReqSeq), exuIdx) =>\n109:       val srcIndices: Seq[Int]
      = fromIQ(iqIdx)(exuIdx).bits.exuParams.getRfReadSrcIdx(IntData())\n110:    \
      \   for (srcIdx <- 0 until fromIQ(iqIdx)(exuIdx).bits.exuParams.numRegSrc) {\n\
      111:         if (srcIndices.contains(srcIdx) && inRFReadReqSeq.isDefinedAt(srcIdx))
      {\n112:           arbInSeq(srcIdx).valid := inRFReadReqSeq(srcIdx).valid &&
      allDataSources(iqIdx)(exuIdx)(srcIdx).readReg\n113:           arbInSeq(srcIdx).bits.addr
      := inRFReadReqSeq(srcIdx).bits.addr\n114:         } else {\n115:           arbInSeq(srcIdx).valid
      := false.B\n116:           arbInSeq(srcIdx).bits.addr := 0.U\n117:         }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 116-131
    context: "116:           arbInSeq(srcIdx).bits.addr := 0.U\n117:         }\n118:\
      \       }\n119:     }\n120:   }\n121:   fpRFReadArbiter.io.in.zip(fpRFReadReq).zipWithIndex.foreach
      { case ((arbInSeq2, inRFReadReqSeq2), iqIdx) =>\n122:     arbInSeq2.zip(inRFReadReqSeq2).zipWithIndex.foreach
      { case ((arbInSeq, inRFReadReqSeq), exuIdx) =>\n123:       val srcIndices: Seq[Int]
      = FpRegSrcDataSet.flatMap(data => fromIQ(iqIdx)(exuIdx).bits.exuParams.getRfReadSrcIdx(data)).toSeq.sorted\n\
      124:       for (srcIdx <- 0 until fromIQ(iqIdx)(exuIdx).bits.exuParams.numRegSrc)
      {\n125:         if (srcIndices.contains(srcIdx) && inRFReadReqSeq.isDefinedAt(srcIdx))
      {\n126:           arbInSeq(srcIdx).valid := inRFReadReqSeq(srcIdx).valid &&
      allDataSources(iqIdx)(exuIdx)(srcIdx).readReg\n127:           arbInSeq(srcIdx).bits.addr
      := inRFReadReqSeq(srcIdx).bits.addr\n128:         } else {\n129:           arbInSeq(srcIdx).valid
      := false.B\n130:           arbInSeq(srcIdx).bits.addr := 0.U\n131:         }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 131-146
    context: "131:         }\n132:       }\n133:     }\n134:   }\n135: \n136:   vfRFReadArbiter.io.in.zip(vfRFReadReq).zipWithIndex.foreach
      { case ((arbInSeq2, inRFReadReqSeq2), iqIdx) =>\n137:     arbInSeq2.zip(inRFReadReqSeq2).zipWithIndex.foreach
      { case ((arbInSeq, inRFReadReqSeq), exuIdx) =>\n138:       val srcIndices: Seq[Int]
      = VecRegSrcDataSet.flatMap(data => fromIQ(iqIdx)(exuIdx).bits.exuParams.getRfReadSrcIdx(data)).toSeq.sorted\n\
      139:       for (srcIdx <- 0 until fromIQ(iqIdx)(exuIdx).bits.exuParams.numRegSrc)
      {\n140:         if (srcIndices.contains(srcIdx) && inRFReadReqSeq.isDefinedAt(srcIdx))
      {\n141:           arbInSeq(srcIdx).valid := inRFReadReqSeq(srcIdx).valid &&
      allDataSources(iqIdx)(exuIdx)(srcIdx).readReg\n142:           arbInSeq(srcIdx).bits.addr
      := inRFReadReqSeq(srcIdx).bits.addr\n143:         } else {\n144:           arbInSeq(srcIdx).valid
      := false.B\n145:           arbInSeq(srcIdx).bits.addr := 0.U\n146:         }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 146-161
    context: "146:         }\n147:       }\n148:     }\n149:   }\n150: \n151:   v0RFReadArbiter.io.in.zip(v0RFReadReq).zipWithIndex.foreach
      { case ((arbInSeq2, inRFReadReqSeq2), iqIdx) =>\n152:     arbInSeq2.zip(inRFReadReqSeq2).zipWithIndex.foreach
      { case ((arbInSeq, inRFReadReqSeq), exuIdx) =>\n153:       val srcIndices: Seq[Int]
      = V0RegSrcDataSet.flatMap(data => fromIQ(iqIdx)(exuIdx).bits.exuParams.getRfReadSrcIdx(data)).toSeq.sorted\n\
      154:       for (srcIdx <- 0 until fromIQ(iqIdx)(exuIdx).bits.exuParams.numRegSrc)
      {\n155:         if (srcIndices.contains(srcIdx) && inRFReadReqSeq.isDefinedAt(srcIdx))
      {\n156:           arbInSeq(srcIdx).valid := inRFReadReqSeq(srcIdx).valid &&
      allDataSources(iqIdx)(exuIdx)(srcIdx).readReg\n157:           arbInSeq(srcIdx).bits.addr
      := inRFReadReqSeq(srcIdx).bits.addr\n158:         } else {\n159:           arbInSeq(srcIdx).valid
      := false.B\n160:           arbInSeq(srcIdx).bits.addr := 0.U\n161:         }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 161-176
    context: "161:         }\n162:       }\n163:     }\n164:   }\n165: \n166:   vlRFReadArbiter.io.in.zip(vlRFReadReq).zipWithIndex.foreach
      { case ((arbInSeq2, inRFReadReqSeq2), iqIdx) =>\n167:     arbInSeq2.zip(inRFReadReqSeq2).zipWithIndex.foreach
      { case ((arbInSeq, inRFReadReqSeq), exuIdx) =>\n168:       val srcIndices: Seq[Int]
      = VlRegSrcDataSet.flatMap(data => fromIQ(iqIdx)(exuIdx).bits.exuParams.getRfReadSrcIdx(data)).toSeq.sorted\n\
      169:       for (srcIdx <- 0 until fromIQ(iqIdx)(exuIdx).bits.exuParams.numRegSrc)
      {\n170:         if (srcIndices.contains(srcIdx) && inRFReadReqSeq.isDefinedAt(srcIdx))
      {\n171:           arbInSeq(srcIdx).valid := inRFReadReqSeq(srcIdx).valid &&
      allDataSources(iqIdx)(exuIdx)(srcIdx).readReg\n172:           arbInSeq(srcIdx).bits.addr
      := inRFReadReqSeq(srcIdx).bits.addr\n173:         } else {\n174:           arbInSeq(srcIdx).valid
      := false.B\n175:           arbInSeq(srcIdx).bits.addr := 0.U\n176:         }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 182-217
    context: "182:   private val fpRFWriteReq: Seq2[Bool] = fromIQ.map(x => x.map(xx
      => xx.valid && xx.bits.common.fpWen.getOrElse(false.B)).toSeq).toSeq\n183: \
      \  private val vfRFWriteReq: Seq2[Bool] = fromIQ.map(x => x.map(xx => xx.valid
      && xx.bits.common.vecWen.getOrElse(false.B)).toSeq).toSeq\n184:   private val
      v0RFWriteReq: Seq2[Bool] = fromIQ.map(x => x.map(xx => xx.valid && xx.bits.common.v0Wen.getOrElse(false.B)).toSeq).toSeq\n\
      185:   private val vlRFWriteReq: Seq2[Bool] = fromIQ.map(x => x.map(xx => xx.valid
      && xx.bits.common.vlWen.getOrElse(false.B)).toSeq).toSeq\n186: \n187:   intWbBusyArbiter.io.in.zip(intRFWriteReq).foreach
      { case (arbInSeq, inRFWriteReqSeq) =>\n188:     arbInSeq.zip(inRFWriteReqSeq).foreach
      { case (arbIn, inRFWriteReq) =>\n189:       arbIn.valid := inRFWriteReq\n190:\
      \     }\n191:   }\n192: \n193:   fpWbBusyArbiter.io.in.zip(fpRFWriteReq).foreach
      { case (arbInSeq, inRFWriteReqSeq) =>\n194:     arbInSeq.zip(inRFWriteReqSeq).foreach
      { case (arbIn, inRFWriteReq) =>\n195:       arbIn.valid := inRFWriteReq\n196:\
      \     }\n197:   }\n198: \n199:   vfWbBusyArbiter.io.in.zip(vfRFWriteReq).foreach
      { case (arbInSeq, inRFWriteReqSeq) =>\n200:     arbInSeq.zip(inRFWriteReqSeq).foreach
      { case (arbIn, inRFWriteReq) =>\n201:       arbIn.valid := inRFWriteReq\n202:\
      \     }\n203:   }\n204: \n205:   v0WbBusyArbiter.io.in.zip(v0RFWriteReq).foreach
      { case (arbInSeq, inRFWriteReqSeq) =>\n206:     arbInSeq.zip(inRFWriteReqSeq).foreach
      { case (arbIn, inRFWriteReq) =>\n207:       arbIn.valid := inRFWriteReq\n208:\
      \     }\n209:   }\n210: \n211:   vlWbBusyArbiter.io.in.zip(vlRFWriteReq).foreach
      { case (arbInSeq, inRFWriteReqSeq) =>\n212:     arbInSeq.zip(inRFWriteReqSeq).foreach
      { case (arbIn, inRFWriteReq) =>\n213:       arbIn.valid := inRFWriteReq\n214:\
      \     }\n215:   }\n216: \n217:   private val intSchdParams = params.schdParams(IntScheduler())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 267-283
    context: "267:   io.fromPcTargetMem.fromDataPathFtqPtr := pcReadFtqPtr\n268: \
      \  io.fromPcTargetMem.fromDataPathFtqOffset := pcReadFtqOffset\n269: \n270:\
      \   private val intDiffRead: Option[(Vec[UInt], Vec[UInt])] =\n271:     OptionWrapper(backendParams.basicDebugEn,
      (Wire(Vec(32, UInt(intSchdParams.pregIdxWidth.W))), Wire(Vec(32, UInt(XLEN.W)))))\n\
      272:   private val fpDiffRead: Option[(Vec[UInt], Vec[UInt])] =\n273:     OptionWrapper(backendParams.basicDebugEn,
      (Wire(Vec(32, UInt(fpSchdParams.pregIdxWidth.W))), Wire(Vec(32, UInt(XLEN.W)))))\n\
      274:   private val vfDiffRead: Option[(Vec[UInt], Vec[UInt])] =\n275:     OptionWrapper(backendParams.basicDebugEn,
      (Wire(Vec(31, UInt(vfSchdParams.pregIdxWidth.W))), Wire(Vec(31, UInt(VLEN.W)))))\n\
      276:   private val v0DiffRead: Option[(Vec[UInt], Vec[UInt])] =\n277:     OptionWrapper(backendParams.basicDebugEn,
      (Wire(Vec(1, UInt(log2Up(V0PhyRegs).W))), Wire(Vec(1, UInt(V0Data().dataWidth.W)))))\n\
      278:   private val vlDiffRead: Option[(Vec[UInt], Vec[UInt])] =\n279:     OptionWrapper(backendParams.basicDebugEn,
      (Wire(Vec(1, UInt(log2Up(VlPhyRegs).W))), Wire(Vec(1, UInt(VlData().dataWidth.W)))))\n\
      280: \n281:   private val fpDiffReadData: Option[Vec[UInt]] =\n282:     OptionWrapper(backendParams.basicDebugEn,
      Wire(Vec(32, UInt(XLEN.W))))\n283:   private val vecDiffReadData: Option[Vec[UInt]]
      ="
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 284-313
    context: "284:     OptionWrapper(backendParams.basicDebugEn, Wire(Vec(64, UInt(64.W))))
      // v0 = Cat(Vec(1), Vec(0))\n285:   private val vlDiffReadData: Option[UInt]
      =\n286:     OptionWrapper(backendParams.basicDebugEn, Wire(UInt(VlData().dataWidth.W)))\n\
      287: \n288: \n289:   fpDiffReadData.foreach(_ := fpDiffRead\n290:     .get._2\n\
      291:     .slice(0, 32)\n292:     .map(_(63, 0))\n293:   ) // fp only used [63,
      0]\n294:   vecDiffReadData.foreach(_ := \n295:     v0DiffRead\n296:     .get._2\n\
      297:     .slice(0, 1)\n298:     .map(x => Seq(x(63, 0), x(127, 64))).flatten
      ++ \n299:     vfDiffRead\n300:     .get._2\n301:     .slice(0, 31)\n302:   \
      \  .map(x => Seq(x(63, 0), x(127, 64))).flatten\n303:   )\n304:   vlDiffReadData.foreach(_
      := vlDiffRead\n305:     .get._2(0)\n306:   )\n307: \n308:   io.diffVl.foreach(_
      := vlDiffReadData.get)\n309: \n310:   IntRegFileSplit(\"IntRegFile\", intSchdParams.numPregs,
      splitNum = 4, intRfRaddr, intRfRdata, intRfWen, intRfWaddr, intRfWdata,\n311:\
      \     bankNum = 1,\n312:     debugReadAddr = intDiffRead.map(_._1),\n313:  \
      \   debugReadData = intDiffRead.map(_._2)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 312-337
    context: "312:     debugReadAddr = intDiffRead.map(_._1),\n313:     debugReadData
      = intDiffRead.map(_._2)\n314:   )\n315:   FpRegFileSplit(\"FpRegFile\", fpSchdParams.numPregs,
      splitNum = 4, fpRfRaddr, fpRfRdata, fpRfWen, fpRfWaddr, fpRfWdata,\n316:   \
      \  bankNum = 1,\n317:     debugReadAddr = fpDiffRead.map(_._1),\n318:     debugReadData
      = fpDiffRead.map(_._2)\n319:   )\n320:   VfRegFile(\"VfRegFile\", vfSchdParams.numPregs,
      vfRfSplitNum, vfRfRaddr, vfRfRdata, vfRfWen, vfRfWaddr, vfRfWdata,\n321:   \
      \  debugReadAddr = vfDiffRead.map(_._1),\n322:     debugReadData = vfDiffRead.map(_._2)\n\
      323:   )\n324:   VfRegFile(\"V0RegFile\", V0PhyRegs, v0RfSplitNum, v0RfRaddr,
      v0RfRdata, v0RfWen, v0RfWaddr, v0RfWdata,\n325:     debugReadAddr = v0DiffRead.map(_._1),\n\
      326:     debugReadData = v0DiffRead.map(_._2)\n327:   )\n328:   FpRegFile(\"\
      VlRegFile\", VlPhyRegs, vlRfRaddr, vlRfRdata, vlRfWen, vlRfWaddr, vlRfWdata,\n\
      329:     bankNum = 1,\n330:     isVlRegfile = true,\n331:     debugReadAddr
      = vlDiffRead.map(_._1),\n332:     debugReadData = vlDiffRead.map(_._2)\n333:\
      \   )\n334: \n335:   intRfWaddr := io.fromIntWb.map(x => RegEnable(x.addr, x.wen)).toSeq\n\
      336:   intRfWdata := io.fromIntWb.map(x => RegEnable(x.data, x.wen)).toSeq\n\
      337:   intRfWen := RegNext(VecInit(io.fromIntWb.map(_.wen).toSeq))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 354-364
    context: "354:       fpRfRaddr(portIdx) := 0.U\n355:   }\n356: \n357:   vfRfWaddr
      := io.fromVfWb.map(x => RegEnable(x.addr, x.wen)).toSeq\n358:   vfRfWdata :=
      io.fromVfWb.map(x => RegEnable(x.data, x.wen)).toSeq\n359:   vfRfWen.foreach(_.zip(io.fromVfWb.map(x
      => RegNext(x.wen))).foreach { case (wenSink, wenSource) => wenSink := wenSource
      } )\n360: \n361:   for (portIdx <- vfRfRaddr.indices) {\n362:     if (vfRFReadArbiter.io.out.isDefinedAt(portIdx))\n\
      363:       vfRfRaddr(portIdx) := vfRFReadArbiter.io.out(portIdx).bits.addr\n\
      364:     else"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 365-375
    context: "365:       vfRfRaddr(portIdx) := 0.U\n366:   }\n367: \n368:   v0RfWaddr
      := io.fromV0Wb.map(x => RegEnable(x.addr, x.wen)).toSeq\n369:   v0RfWdata :=
      io.fromV0Wb.map(x => RegEnable(x.data, x.wen)).toSeq\n370:   v0RfWen.foreach(_.zip(io.fromV0Wb.map(x
      => RegNext(x.wen))).foreach { case (wenSink, wenSource) => wenSink := wenSource
      } )\n371: \n372:   for (portIdx <- v0RfRaddr.indices) {\n373:     if (v0RFReadArbiter.io.out.isDefinedAt(portIdx))\n\
      374:       v0RfRaddr(portIdx) := v0RFReadArbiter.io.out(portIdx).bits.addr\n\
      375:     else"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 397-407
    context: "397:   }\n398: \n399:   for (i <- fromVecExcp.w.indices) {\n400:   \
      \  when (fromVecExcp.w(i).valid && !fromVecExcp.w(i).bits.isV0) {\n401:    \
      \   val vecWrPort = vecExcpUseVecWrPorts(i)\n402:       vfRfWen.foreach(_(vecWrPort)
      := true.B)\n403:       vfRfWaddr(vecWrPort) := fromVecExcp.w(i).bits.newVdAddr\n\
      404:       vfRfWdata(vecWrPort) := fromVecExcp.w(i).bits.newVdData\n405:   \
      \  }\n406:     if (i % maxMergeNumPerCycle == 0) {\n407:       when(fromVecExcp.w(i).valid
      && fromVecExcp.w(i).bits.isV0) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 404-414
    context: "404:       vfRfWdata(vecWrPort) := fromVecExcp.w(i).bits.newVdData\n\
      405:     }\n406:     if (i % maxMergeNumPerCycle == 0) {\n407:       when(fromVecExcp.w(i).valid
      && fromVecExcp.w(i).bits.isV0) {\n408:         val v0WrPort = v0WrPortsIter.next()\n\
      409:         v0RfWen.foreach(_(v0WrPort) := true.B)\n410:         v0RfWaddr(v0WrPort)
      := fromVecExcp.w(i).bits.newVdAddr\n411:         v0RfWdata(v0WrPort) := fromVecExcp.w(i).bits.newVdData\n\
      412:       }\n413:     }\n414:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 423-447
    context: "423:     else\n424:       vlRfRaddr(portIdx) := 0.U\n425:   }\n426:\
      \ \n427: \n428:   intDiffRead.foreach { case (addr, _) =>\n429:     addr :=
      io.diffIntRat.get\n430:   }\n431: \n432:   fpDiffRead.foreach { case (addr,
      _) =>\n433:     addr := io.diffFpRat.get\n434:   }\n435: \n436:   vfDiffRead.foreach
      { case (addr, _) =>\n437:     addr := io.diffVecRat.get\n438:   }\n439:   v0DiffRead.foreach
      { case (addr, _) =>\n440:     addr := io.diffV0Rat.get\n441:   }\n442:   vlDiffRead.foreach
      { case (addr, _) =>\n443:     addr := io.diffVlRat.get\n444:   }\n445: \n446:\
      \   println(s\"[DataPath] \" +\n447:     s\"has intDiffRead: ${intDiffRead.nonEmpty},
      \" +"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 443-456
    context: "443:     addr := io.diffVlRat.get\n444:   }\n445: \n446:   println(s\"\
      [DataPath] \" +\n447:     s\"has intDiffRead: ${intDiffRead.nonEmpty}, \" +\n\
      448:     s\"has fpDiffRead: ${fpDiffRead.nonEmpty}, \" +\n449:     s\"has vecDiffRead:
      ${vfDiffRead.nonEmpty}, \" +\n450:     s\"has v0DiffRead: ${v0DiffRead.nonEmpty},
      \" +\n451:     s\"has vlDiffRead: ${vlDiffRead.nonEmpty}\")\n452: \n453:   //
      regcache\n454:   private val regCache = Module(new RegCache())\n455: \n456:\
      \   def IssueBundle2RCReadPort(issue: DecoupledIO[IssueQueueIssueBundle]): Vec[RCReadPort]
      = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 453-463
    context: "453:   // regcache\n454:   private val regCache = Module(new RegCache())\n\
      455: \n456:   def IssueBundle2RCReadPort(issue: DecoupledIO[IssueQueueIssueBundle]):
      Vec[RCReadPort] = {\n457:     val readPorts = Wire(Vec(issue.bits.exuParams.numIntSrc,
      new RCReadPort(params.intSchdParams.get.rfDataWidth, RegCacheIdxWidth)))\n458:\
      \     readPorts.zipWithIndex.foreach{ case (r, idx) =>\n459:       r.ren  :=
      issue.valid && issue.bits.common.dataSources(idx).readRegCache\n460:       r.addr
      := issue.bits.rcIdx.get(idx)\n461:       r.data := DontCare\n462:     }\n463:\
      \     readPorts"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 468-490
    context: "468:   private val regCacheReadData = regCache.io.readPorts.map(_.data)\n\
      469: \n470:   println(s\"[DataPath] regCache readPorts size: ${regCache.io.readPorts.size},
      regCacheReadReq size: ${regCacheReadReq.size}\")\n471:   require(regCache.io.readPorts.size
      == regCacheReadReq.size, \"reg cache's readPorts size should be equal to regCacheReadReq\"\
      )\n472: \n473:   regCache.io.readPorts.zip(regCacheReadReq).foreach{ case (r,
      req) => \n474:     r.ren := req.ren\n475:     r.addr := req.addr\n476:   }\n\
      477: \n478:   val s1_RCReadData: MixedVec[MixedVec[Vec[UInt]]] = Wire(MixedVec(toExu.map(x
      => MixedVec(x.map(_.bits.src.cloneType).toSeq))))\n479:   s1_RCReadData.foreach(_.foreach(_.foreach(_
      := 0.U)))\n480:   s1_RCReadData.zip(toExu).filter(_._2.map(_.bits.params.isIntExeUnit).reduce(_
      || _)).flatMap(_._1).flatten\n481:     .zip(regCacheReadData.take(params.getIntExuRCReadSize)).foreach{
      case (s1_data, rdata) => \n482:       s1_data := rdata\n483:     }\n484:   s1_RCReadData.zip(toExu).filter(_._2.map(x
      => x.bits.params.isMemExeUnit && x.bits.params.readIntRf).reduce(_ || _)).flatMap(_._1).flatten\n\
      485:     .zip(regCacheReadData.takeRight(params.getMemExuRCReadSize)).foreach{
      case (s1_data, rdata) => \n486:       s1_data := rdata\n487:     }\n488: \n\
      489:   println(s\"[DataPath] s1_RCReadData.int.size: ${s1_RCReadData.zip(toExu).filter(_._2.map(_.bits.params.isIntExeUnit).reduce(_
      || _)).flatMap(_._1).flatten.size}, RCRdata.int.size: ${params.getIntExuRCReadSize}\"\
      )\n490:   println(s\"[DataPath] s1_RCReadData.mem.size: ${s1_RCReadData.zip(toExu).filter(_._2.map(x
      => x.bits.params.isMemExeUnit && x.bits.params.readIntRf).reduce(_ || _)).flatMap(_._1).flatten.size},
      RCRdata.mem.size: ${params.getMemExuRCReadSize}\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 491-508
    context: "491: \n492:   io.toWakeupQueueRCIdx := regCache.io.toWakeupQueueRCIdx\n\
      493:   io.toBypassNetworkRCData := s1_RCReadData\n494:   regCache.io.writePorts
      := io.fromBypassNetwork\n495: \n496:   val s1_addrOHs = Reg(MixedVec(\n497:\
      \     fromIQ.map(x => MixedVec(x.map(_.bits.addrOH.cloneType).toSeq)).toSeq\n\
      498:   ))\n499:   val s1_toExuValid: MixedVec[MixedVec[Bool]] = Reg(MixedVec(\n\
      500:     toExu.map(x => MixedVec(x.map(_.valid.cloneType).toSeq)).toSeq\n501:\
      \   ))\n502:   val s1_toExuData: MixedVec[MixedVec[ExuInput]] = Reg(MixedVec(toExu.map(x
      => MixedVec(x.map(_.bits.cloneType).toSeq)).toSeq))\n503:   val s1_immInfo =
      Reg(MixedVec(toExu.map(x => MixedVec(x.map(x => new ImmInfo).toSeq)).toSeq))\n\
      504:   s1_immInfo.zip(fromIQ).map { case (s1Vec, s0Vec) =>\n505:     s1Vec.zip(s0Vec).map
      { case (s1, s0) =>\n506:       s1.imm := Mux(s0.valid, s0.bits.common.imm, s1.imm)\n\
      507:       s1.immType := Mux(s0.valid, s0.bits.immType, s1.immType)\n508:  \
      \   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 508-575
    context: "508:     }\n509:   }\n510:   io.og1ImmInfo.zip(s1_immInfo.flatten).map{
      case(out, reg) =>\n511:     out := reg\n512:   }\n513:   val s1_toExuReady =
      Wire(MixedVec(toExu.map(x => MixedVec(x.map(_.ready.cloneType).toSeq))))\n514:\
      \   val s1_srcType: MixedVec[MixedVec[Vec[UInt]]] = MixedVecInit(fromIQ.map(x
      => MixedVecInit(x.map(xx => RegEnable(xx.bits.srcType, xx.fire)).toSeq)))\n\
      515: \n516:   val s1_intPregRData: MixedVec[MixedVec[Vec[UInt]]] = Wire(MixedVec(toExu.map(x
      => MixedVec(x.map(_.bits.src.cloneType).toSeq))))\n517:   val s1_fpPregRData:
      MixedVec[MixedVec[Vec[UInt]]] = Wire(MixedVec(toExu.map(x => MixedVec(x.map(_.bits.src.cloneType).toSeq))))\n\
      518:   val s1_vfPregRData: MixedVec[MixedVec[Vec[UInt]]] = Wire(MixedVec(toExu.map(x
      => MixedVec(x.map(_.bits.src.cloneType).toSeq))))\n519:   val s1_v0PregRData:
      MixedVec[MixedVec[Vec[UInt]]] = Wire(MixedVec(toExu.map(x => MixedVec(x.map(_.bits.src.cloneType).toSeq))))\n\
      520:   val s1_vlPregRData: MixedVec[MixedVec[Vec[UInt]]] = Wire(MixedVec(toExu.map(x
      => MixedVec(x.map(_.bits.src.cloneType).toSeq))))\n521: \n522:   val rfrPortConfigs
      = schdParams.map(_.issueBlockParams).flatten.map(_.exuBlockParams.map(_.rfrPortConfigs))\n\
      523: \n524:   println(s\"[DataPath] s1_intPregRData.flatten.flatten.size: ${s1_intPregRData.flatten.flatten.size},
      intRfRdata.size: ${intRfRdata.size}\")\n525:   s1_intPregRData.foreach(_.foreach(_.foreach(_
      := 0.U)))\n526:   s1_intPregRData.zip(rfrPortConfigs).foreach { case (iqRdata,
      iqCfg) =>\n527:       iqRdata.zip(iqCfg).foreach { case (iuRdata, iuCfg) =>\n\
      528:         iuRdata.zip(iuCfg)\n529:           .filter { case (_, cfg) => cfg.count(_.isInstanceOf[IntRD])
      > 0 }\n530:           .foreach { case (sink, cfg) => sink := intRfRdata(cfg.find(_.isInstanceOf[IntRD]).get.port)
      }\n531:       }\n532:   }\n533: \n534:   println(s\"[DataPath] s1_fpPregRData.flatten.flatten.size:
      ${s1_fpPregRData.flatten.flatten.size}, fpRfRdata.size: ${fpRfRdata.size}\"\
      )\n535:   s1_fpPregRData.foreach(_.foreach(_.foreach(_ := 0.U)))\n536:   s1_fpPregRData.zip(rfrPortConfigs).foreach
      { case (iqRdata, iqCfg) =>\n537:       iqRdata.zip(iqCfg).foreach { case (iuRdata,
      iuCfg) =>\n538:         iuRdata.zip(iuCfg)\n539:           .filter { case (_,
      cfg) => cfg.count(_.isInstanceOf[FpRD]) > 0 }\n540:           .foreach { case
      (sink, cfg) => sink := fpRfRdata(cfg.find(_.isInstanceOf[FpRD]).get.port) }\n\
      541:       }\n542:   }\n543: \n544:   println(s\"[DataPath] s1_vfPregRData.flatten.flatten.size:
      ${s1_vfPregRData.flatten.flatten.size}, vfRfRdata.size: ${vfRfRdata.size}\"\
      )\n545:   s1_vfPregRData.foreach(_.foreach(_.foreach(_ := 0.U)))\n546:   s1_vfPregRData.zip(rfrPortConfigs).foreach{
      case(iqRdata, iqCfg) =>\n547:       iqRdata.zip(iqCfg).foreach{ case(iuRdata,
      iuCfg) =>\n548:         iuRdata.zip(iuCfg)\n549:           .filter { case (_,
      cfg) => cfg.count(_.isInstanceOf[VfRD]) > 0 }\n550:           .foreach { case
      (sink, cfg) => sink := vfRfRdata(cfg.find(_.isInstanceOf[VfRD]).get.port) }\n\
      551:       }\n552:   }\n553: \n554:   println(s\"[DataPath] s1_v0PregRData.flatten.flatten.size:
      ${s1_v0PregRData.flatten.flatten.size}, v0RfRdata.size: ${v0RfRdata.size}\"\
      )\n555:   s1_v0PregRData.foreach(_.foreach(_.foreach(_ := 0.U)))\n556:   s1_v0PregRData.zip(rfrPortConfigs).foreach{
      case(iqRdata, iqCfg) =>\n557:       iqRdata.zip(iqCfg).foreach{ case(iuRdata,
      iuCfg) =>\n558:         iuRdata.zip(iuCfg)\n559:           .filter { case (_,
      cfg) => cfg.count(_.isInstanceOf[V0RD]) > 0 }\n560:           .foreach { case
      (sink, cfg) => sink := v0RfRdata(cfg.find(_.isInstanceOf[V0RD]).get.port) }\n\
      561:       }\n562:   }\n563: \n564:   println(s\"[DataPath] s1_vlPregRData.flatten.flatten.size:
      ${s1_vlPregRData.flatten.flatten.size}, vlRfRdata.size: ${vlRfRdata.size}\"\
      )\n565:   s1_vlPregRData.foreach(_.foreach(_.foreach(_ := 0.U)))\n566:   s1_vlPregRData.zip(rfrPortConfigs).foreach{
      case(iqRdata, iqCfg) =>\n567:       iqRdata.zip(iqCfg).foreach{ case(iuRdata,
      iuCfg) =>\n568:         iuRdata.zip(iuCfg)\n569:           .filter { case (_,
      cfg) => cfg.count(_.isInstanceOf[VlRD]) > 0 }\n570:           .foreach { case
      (sink, cfg) => sink := vlRfRdata(cfg.find(_.isInstanceOf[VlRD]).get.port) }\n\
      571:       }\n572:   }\n573: \n574:   val og0_cancel_no_load = VecInit(og0FailedVec2.flatten.zip(params.allExuParams).filter(!_._2.hasLoadFu).map(_._1).toSeq)\n\
      575:   val exuParamsNoLoad = fromIQ.flatten.zip(params.allExuParams).filter(!_._2.hasLoadFu)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 578-602
    context: "578:   val og0_cancel_delay = RegNext(VecInit(og0_cancel_no_load.zip(is_0latency).map(x
      => x._1 && x._2)))\n579:   for (i <- fromIQ.indices) {\n580:     for (j <- fromIQ(i).indices)
      {\n581:       // IQ(s0) --[Ctrl]--> s1Reg ---------- begin\n582:       // refs\n\
      583:       val s1_valid = s1_toExuValid(i)(j)\n584:       val s1_ready = s1_toExuReady(i)(j)\n\
      585:       val s1_data = s1_toExuData(i)(j)\n586:       val s1_addrOH = s1_addrOHs(i)(j)\n\
      587:       val s0 = fromIQ(i)(j) // s0\n588:       PerfCCT.updateInstPos(s0.bits.common.debug_seqNum,
      PerfCCT.InstPos.AtIssueArb.id.U, s0.valid, clock, reset)\n589:       PerfCCT.updateInstPos(s1_data.debug_seqNum,
      PerfCCT.InstPos.AtIssueReadReg.id.U, s1_valid, clock, reset)\n590: \n591:  \
      \     val srcNotBlock = Wire(Bool())\n592:       srcNotBlock := s0.bits.common.dataSources.zip(intRdArbWinner(i)(j)
      zip fpRdArbWinner(i)(j) zip vfRdArbWinner(i)(j) zip v0RdArbWinner(i)(j) zip
      vlRdArbWinner(i)(j)).map {\n593:         case (source, ((((win_int, win_fp),
      win_vf), win_v0), win_vl)) =>\n594:         !source.readReg || win_int && win_fp
      && win_vf && win_v0 && win_vl\n595:       }.fold(true.B)(_ && _)\n596:     \
      \  val notBlock = srcNotBlock && intWbNotBlock(i)(j) && fpWbNotBlock(i)(j) &&
      vfWbNotBlock(i)(j) && v0WbNotBlock(i)(j) && vlWbNotBlock(i)(j)\n597:       val
      s1_flush = s0.bits.common.robIdx.needFlush(Seq(io.flush, RegNextWithEnable(io.flush)))\n\
      598:       val s1_cancel = og1FailedVec2(i)(j)\n599:       val s0_cancel = Wire(Bool())\n\
      600:       if (s0.bits.exuParams.isIQWakeUpSink) {\n601:         val exuOHNoLoad
      = s0.bits.common.exuSources.get.map(x => x.toExuOH(s0.bits.exuParams).zip(params.allExuParams).filter(!_._2.hasLoadFu).map(_._1))\n\
      602:         s0_cancel := exuOHNoLoad.zip(s0.bits.common.dataSources).map{"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 602-615
    context: "602:         s0_cancel := exuOHNoLoad.zip(s0.bits.common.dataSources).map{\n\
      603:           case (exuOH, dataSource) => (VecInit(exuOH).asUInt & og0_cancel_delay.asUInt).orR
      && dataSource.readForward\n604:         }.reduce(_ || _) && s0.valid\n605: \
      \      } else s0_cancel := false.B\n606:       val s0_ldCancel = LoadShouldCancel(s0.bits.common.loadDependency,
      io.ldCancel)\n607:       when (s0.fire && !s1_flush && !s0_ldCancel) {\n608:\
      \         s1_valid := true.B\n609:       }.otherwise {\n610:         s1_valid
      := false.B\n611:       }\n612:       when (s0.valid) {\n613:         s1_data.fromIssueBundle(s0.bits)
      // no src data here\n614:         s1_addrOH := s0.bits.addrOH\n615:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 611-639
    context: "611:       }\n612:       when (s0.valid) {\n613:         s1_data.fromIssueBundle(s0.bits)
      // no src data here\n614:         s1_addrOH := s0.bits.addrOH\n615:       }\n\
      616:       s0.ready := notBlock && !s0_cancel\n617:       // IQ(s0) --[Ctrl]-->
      s1Reg ---------- end\n618:     }\n619:   }\n620: \n621:   private val fromIQFire
      = fromIQ.map(_.map(_.fire))\n622:   private val toExuFire = toExu.map(_.map(_.fire))\n\
      623:   toIQs.zipWithIndex.foreach {\n624:     case(toIQ, iqIdx) =>\n625:   \
      \    toIQ.zipWithIndex.foreach {\n626:         case (toIU, iuIdx) =>\n627: \
      \          // IU: issue unit\n628:           val og0resp = toIU.og0resp\n629:\
      \           og0FailedVec2(iqIdx)(iuIdx)   := fromIQ(iqIdx)(iuIdx).valid && !fromIQ(iqIdx)(iuIdx).ready\n\
      630:           og0resp.valid                 := og0FailedVec2(iqIdx)(iuIdx)\n\
      631:           og0resp.bits.robIdx           := fromIQ(iqIdx)(iuIdx).bits.common.robIdx\n\
      632:           og0resp.bits.uopIdx.foreach(_ := fromIQ(iqIdx)(iuIdx).bits.common.vpu.get.vuopIdx)\n\
      633:           og0resp.bits.sqIdx.foreach(_ := 0.U.asTypeOf(new SqPtr))\n634:\
      \           og0resp.bits.lqIdx.foreach(_ := 0.U.asTypeOf(new LqPtr))\n635: \
      \          og0resp.bits.resp             := RespType.block\n636:           og0resp.bits.fuType\
      \           := fromIQ(iqIdx)(iuIdx).bits.common.fuType\n637: \n638:        \
      \   val og1resp = toIU.og1resp\n639:           og1FailedVec2(iqIdx)(iuIdx) \
      \  := s1_toExuValid(iqIdx)(iuIdx) && !s1_toExuReady(iqIdx)(iuIdx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 637-649
    context: "637: \n638:           val og1resp = toIU.og1resp\n639:           og1FailedVec2(iqIdx)(iuIdx)\
      \   := s1_toExuValid(iqIdx)(iuIdx) && !s1_toExuReady(iqIdx)(iuIdx)\n640:   \
      \        og1resp.valid                 := s1_toExuValid(iqIdx)(iuIdx)\n641:\
      \           og1resp.bits.robIdx           := s1_toExuData(iqIdx)(iuIdx).robIdx\n\
      642:           og1resp.bits.uopIdx.foreach(_ := s1_toExuData(iqIdx)(iuIdx).vpu.get.vuopIdx)\n\
      643:           og1resp.bits.sqIdx.foreach(_ :=  0.U.asTypeOf(new SqPtr))\n644:\
      \           og1resp.bits.lqIdx.foreach(_ :=  0.U.asTypeOf(new LqPtr))\n645:\
      \           // respType:  success    -> IQ entry clear\n646:           //  \
      \          uncertain  -> IQ entry no action\n647:           //            block\
      \      -> IQ entry issued set false, then re-issue\n648:           // hyu, lda
      and sta are uncertain at OG1 stage\n649:           // and all vector arith exu
      should check success in og2 stage"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 659-669
    context: "659:   }\n660: \n661:   io.og0Cancel := og0FailedVec2.flatten.zip(params.allExuParams).map{
      case (cancel, params) => \n662:                     if (params.isIQWakeUpSource
      && params.latencyCertain && params.wakeUpFuLatancySet.contains(0)) cancel else
      false.B\n663:                   }.toSeq\n664:   io.og1Cancel := toFlattenExu.map(x
      => x.valid && !x.fire)\n665: \n666: \n667:   if (backendParams.debugEn){\n668:\
      \     dontTouch(og0_cancel_no_load)\n669:     dontTouch(is_0latency)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 674-684
    context: "674:       // s1Reg --[Ctrl]--> exu(s1) ---------- begin\n675:     \
      \  // refs\n676:       val sinkData = toExu(i)(j).bits\n677:       // assign\n\
      678:       toExu(i)(j).valid := s1_toExuValid(i)(j)\n679:       s1_toExuReady(i)(j)
      := toExu(i)(j).ready\n680:       sinkData := s1_toExuData(i)(j)\n681:      \
      \ // s1Reg --[Ctrl]--> exu(s1) ---------- end\n682: \n683:       // s1Reg --[Data]-->
      exu(s1) ---------- begin\n684:       // data source1: preg read data"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 751-764
    context: "751:   }\n752: \n753:   val vf_regcache_size = 48\n754:   val vf_regcache_tag
      = RegInit(VecInit(Seq.fill(vf_regcache_size)(0.U(vfSchdParams.pregIdxWidth.W))))\n\
      755:   val vf_regcache_enqPtr = RegInit(0.U(log2Up(vf_regcache_size).W))\n756:\
      \   vf_regcache_enqPtr := vf_regcache_enqPtr + PopCount(vfRfWen.head)\n757:\
      \   for (i <- vfRfWen.indices) {\n758:     when (vfRfWen.head(i)) {\n759:  \
      \     vf_regcache_tag(vf_regcache_enqPtr + PopCount(vfRfWen.head.take(i))) :=
      vfRfWaddr(i)\n760:     }\n761:   }\n762: \n763:   v0RdPortsIter = vecExcpUseV0RdPorts.iterator\n\
      764:   for (i <- toVecExcp.rdata.indices) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 799-813
    context: "799:   XSPerfAccumulate(s\"FpRFReadBeforeArb\", PopCount(fpRFReadArbiter.io.in.flatten.flatten.map(_.valid)))\n\
      800:   XSPerfAccumulate(s\"FpRFReadAfterArb\", PopCount(fpRFReadArbiter.io.out.map(_.valid)))\n\
      801:   XSPerfAccumulate(s\"VfRFReadBeforeArb\", PopCount(vfRFReadArbiter.io.in.flatten.flatten.map(_.valid)))\n\
      802:   XSPerfAccumulate(s\"VfRFReadAfterArb\", PopCount(vfRFReadArbiter.io.out.map(_.valid)))\n\
      803:   XSPerfAccumulate(s\"IntUopBeforeArb\", PopCount(fromIntIQ.flatten.map(_.valid)))\n\
      804:   XSPerfAccumulate(s\"IntUopAfterArb\", PopCount(fromIntIQ.flatten.map(_.fire)))\n\
      805:   XSPerfAccumulate(s\"MemUopBeforeArb\", PopCount(fromMemIQ.flatten.map(_.valid)))\n\
      806:   XSPerfAccumulate(s\"MemUopAfterArb\", PopCount(fromMemIQ.flatten.map(_.fire)))\n\
      807:   XSPerfAccumulate(s\"VfUopBeforeArb\", PopCount(fromVfIQ.flatten.map(_.valid)))\n\
      808:   XSPerfAccumulate(s\"VfUopAfterArb\", PopCount(fromVfIQ.flatten.map(_.fire)))\n\
      809: \n810:   XSPerfHistogram(s\"IntRFReadBeforeArb_hist\", PopCount(intRFReadArbiter.io.in.flatten.flatten.map(_.valid)),
      true.B, 0, 16, 2)\n811:   XSPerfHistogram(s\"IntRFReadAfterArb_hist\", PopCount(intRFReadArbiter.io.out.map(_.valid)),
      true.B, 0, 16, 2)\n812:   XSPerfHistogram(s\"FpRFReadBeforeArb_hist\", PopCount(fpRFReadArbiter.io.in.flatten.flatten.map(_.valid)),
      true.B, 0, 16, 2)\n813:   XSPerfHistogram(s\"FpRFReadAfterArb_hist\", PopCount(fpRFReadArbiter.io.out.map(_.valid)),
      true.B, 0, 16, 2)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 812-845
    context: "812:   XSPerfHistogram(s\"FpRFReadBeforeArb_hist\", PopCount(fpRFReadArbiter.io.in.flatten.flatten.map(_.valid)),
      true.B, 0, 16, 2)\n813:   XSPerfHistogram(s\"FpRFReadAfterArb_hist\", PopCount(fpRFReadArbiter.io.out.map(_.valid)),
      true.B, 0, 16, 2)\n814:   XSPerfHistogram(s\"VfRFReadBeforeArb_hist\", PopCount(vfRFReadArbiter.io.in.flatten.flatten.map(_.valid)),
      true.B, 0, 16, 2)\n815:   XSPerfHistogram(s\"VfRFReadAfterArb_hist\", PopCount(vfRFReadArbiter.io.out.map(_.valid)),
      true.B, 0, 16, 2)\n816:   XSPerfHistogram(s\"IntUopBeforeArb_hist\", PopCount(fromIntIQ.flatten.map(_.valid)),
      true.B, 0, 8, 2)\n817:   XSPerfHistogram(s\"IntUopAfterArb_hist\", PopCount(fromIntIQ.flatten.map(_.fire)),
      true.B, 0, 8, 2)\n818:   XSPerfHistogram(s\"MemUopBeforeArb_hist\", PopCount(fromMemIQ.flatten.map(_.valid)),
      true.B, 0, 8, 2)\n819:   XSPerfHistogram(s\"MemUopAfterArb_hist\", PopCount(fromMemIQ.flatten.map(_.fire)),
      true.B, 0, 8, 2)\n820:   XSPerfHistogram(s\"VfUopBeforeArb_hist\", PopCount(fromVfIQ.flatten.map(_.valid)),
      true.B, 0, 8, 2)\n821:   XSPerfHistogram(s\"VfUopAfterArb_hist\", PopCount(fromVfIQ.flatten.map(_.fire)),
      true.B, 0, 8, 2)\n822: \n823:   // datasource perf counter (after arbiter)\n\
      824:   fromIQ.foreach(iq => iq.foreach{exu => \n825:     val exuParams = exu.bits.exuParams\n\
      826:     if (exuParams.isIntExeUnit) {\n827:       for (i <- 0 until 2) {\n\
      828:         XSPerfAccumulate(s\"INT_ExuId${exuParams.exuIdx}_src${i}_dataSource_forward\"\
      ,  exu.fire && exu.bits.common.dataSources(i).readForward)\n829:         XSPerfAccumulate(s\"\
      INT_ExuId${exuParams.exuIdx}_src${i}_dataSource_bypass\",   exu.fire && exu.bits.common.dataSources(i).readBypass)\n\
      830:         XSPerfAccumulate(s\"INT_ExuId${exuParams.exuIdx}_src${i}_dataSource_regcache\"\
      , exu.fire && exu.bits.common.dataSources(i).readRegCache)\n831:         XSPerfAccumulate(s\"\
      INT_ExuId${exuParams.exuIdx}_src${i}_dataSource_reg\",      exu.fire && exu.bits.common.dataSources(i).readReg)\n\
      832:         XSPerfAccumulate(s\"INT_ExuId${exuParams.exuIdx}_src${i}_dataSource_zero\"\
      ,     exu.fire && exu.bits.common.dataSources(i).readZero)\n833:       }\n834:\
      \     }\n835:     if (exuParams.isMemExeUnit && exuParams.readIntRf) {\n836:\
      \       XSPerfAccumulate(s\"MEM_ExuId${exuParams.exuIdx}_src0_dataSource_forward\"\
      ,  exu.fire && exu.bits.common.dataSources(0).readForward)\n837:       XSPerfAccumulate(s\"\
      MEM_ExuId${exuParams.exuIdx}_src0_dataSource_bypass\",   exu.fire && exu.bits.common.dataSources(0).readBypass)\n\
      838:       XSPerfAccumulate(s\"MEM_ExuId${exuParams.exuIdx}_src0_dataSource_regcache\"\
      , exu.fire && exu.bits.common.dataSources(0).readRegCache)\n839:       XSPerfAccumulate(s\"\
      MEM_ExuId${exuParams.exuIdx}_src0_dataSource_reg\",      exu.fire && exu.bits.common.dataSources(0).readReg)\n\
      840:       XSPerfAccumulate(s\"MEM_ExuId${exuParams.exuIdx}_src0_dataSource_zero\"\
      ,     exu.fire && exu.bits.common.dataSources(0).readZero)\n841:     }\n842:\
      \   })\n843: \n844:   // Top-Down\n845:   def FewUops = 4"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 848-859
    context: "848:   val sqEmpty = io.topDownInfo.sqEmpty\n849:   val l1Miss = io.topDownInfo.l1Miss\n\
      850:   val l2Miss = io.topDownInfo.l2TopMiss.l2Miss\n851:   val l3Miss = io.topDownInfo.l2TopMiss.l3Miss\n\
      852: \n853:   val uopsIssued = fromIQ.flatten.map(_.fire).reduce(_ || _)\n854:\
      \   val uopsIssuedCnt = PopCount(fromIQ.flatten.map(_.fire))\n855:   val fewUopsIssued
      = (0 until FewUops).map(_.U === uopsIssuedCnt).reduce(_ || _)\n856: \n857: \
      \  val stallLoad = !uopsIssued\n858: \n859:   val noStoreIssued = !fromMemIQ.flatten.filter(memIq
      => memIq.bits.exuParams.fuConfigs.contains(FuConfig.StaCfg) ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 856-866
    context: "856: \n857:   val stallLoad = !uopsIssued\n858: \n859:   val noStoreIssued
      = !fromMemIQ.flatten.filter(memIq => memIq.bits.exuParams.fuConfigs.contains(FuConfig.StaCfg)
      ||\n860:                                                          memIq.bits.exuParams.fuConfigs.contains(FuConfig.StdCfg)\n\
      861:   ).map(_.fire).reduce(_ || _)\n862:   val stallStore = uopsIssued && noStoreIssued\n\
      863: \n864:   val stallLoadReg = DelayN(stallLoad, 2)\n865:   val stallStoreReg
      = DelayN(stallStore, 2)\n866: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 863-873
    context: "863: \n864:   val stallLoadReg = DelayN(stallLoad, 2)\n865:   val stallStoreReg
      = DelayN(stallStore, 2)\n866: \n867:   val memStallAnyLoad = stallLoadReg &&
      !lqEmpty\n868:   val memStallStore = stallStoreReg && !sqEmpty\n869:   val memStallL1Miss
      = memStallAnyLoad && l1Miss\n870:   val memStallL2Miss = memStallL1Miss && l2Miss\n\
      871:   val memStallL3Miss = memStallL2Miss && l3Miss\n872: \n873:   io.topDownInfo.noUopsIssued
      := stallLoad"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 871-881
    context: "871:   val memStallL3Miss = memStallL2Miss && l3Miss\n872: \n873:  \
      \ io.topDownInfo.noUopsIssued := stallLoad\n874: \n875:   XSPerfAccumulate(\"\
      exec_stall_cycle\",   fewUopsIssued)\n876:   XSPerfAccumulate(\"mem_stall_store\"\
      ,    memStallStore)\n877:   XSPerfAccumulate(\"mem_stall_l1miss\",   memStallL1Miss)\n\
      878:   XSPerfAccumulate(\"mem_stall_l2miss\",   memStallL2Miss)\n879:   XSPerfAccumulate(\"\
      mem_stall_l3miss\",   memStallL3Miss)\n880: \n881:   val perfEvents = Seq("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 878-888
    context: "878:   XSPerfAccumulate(\"mem_stall_l2miss\",   memStallL2Miss)\n879:\
      \   XSPerfAccumulate(\"mem_stall_l3miss\",   memStallL3Miss)\n880: \n881:  \
      \ val perfEvents = Seq(\n882:     (\"EXEC_STALL_CYCLE\",  fewUopsIssued),\n\
      883:     (\"MEMSTALL_STORE\",    memStallStore),\n884:     (\"MEMSTALL_L1MISS\"\
      ,   memStallL1Miss),\n885:     (\"MEMSTALL_L2MISS\",   memStallL2Miss),\n886:\
      \     (\"MEMSTALL_L3MISS\",   memStallL3Miss),\n887:   )\n888:   generatePerfEvent()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 895-928
    context: "895:   private val vfSchdParams = params.schdParams(VfScheduler())\n\
      896:   private val memSchdParams = params.schdParams(MemScheduler())\n897: \
      \  // bundles\n898:   val hartId = Input(UInt(8.W))\n899: \n900:   val flush:
      ValidIO[Redirect] = Flipped(ValidIO(new Redirect))\n901: \n902:   val wbConfictRead
      = Input(MixedVec(params.allSchdParams.map(x => MixedVec(x.issueBlockParams.map(x
      => x.genWbConflictBundle())))))\n903: \n904:   val fromIntIQ: MixedVec[MixedVec[DecoupledIO[IssueQueueIssueBundle]]]
      =\n905:     Flipped(MixedVec(intSchdParams.issueBlockParams.map(_.genIssueDecoupledBundle)))\n\
      906: \n907:   val fromFpIQ: MixedVec[MixedVec[DecoupledIO[IssueQueueIssueBundle]]]
      =\n908:     Flipped(MixedVec(fpSchdParams.issueBlockParams.map(_.genIssueDecoupledBundle)))\n\
      909: \n910:   val fromMemIQ: MixedVec[MixedVec[DecoupledIO[IssueQueueIssueBundle]]]
      =\n911:     Flipped(MixedVec(memSchdParams.issueBlockParams.map(_.genIssueDecoupledBundle)))\n\
      912: \n913:   val fromVfIQ = Flipped(MixedVec(vfSchdParams.issueBlockParams.map(_.genIssueDecoupledBundle)))\n\
      914: \n915:   val fromVecExcpMod = Input(new ExcpModToVprf(maxMergeNumPerCycle
      * 2, maxMergeNumPerCycle))\n916: \n917:   val toIntIQ = MixedVec(intSchdParams.issueBlockParams.map(_.genOGRespBundle))\n\
      918: \n919:   val toFpIQ = MixedVec(fpSchdParams.issueBlockParams.map(_.genOGRespBundle))\n\
      920: \n921:   val toMemIQ = MixedVec(memSchdParams.issueBlockParams.map(_.genOGRespBundle))\n\
      922: \n923:   val toVfIQ = MixedVec(vfSchdParams.issueBlockParams.map(_.genOGRespBundle))\n\
      924: \n925:   val toVecExcpMod = Output(new VprfToExcpMod(maxMergeNumPerCycle
      * 2))\n926: \n927:   val og0Cancel = Output(ExuVec())\n928: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 928-956
    context: "928: \n929:   val og1Cancel = Output(ExuVec())\n930: \n931:   val ldCancel
      = Vec(backendParams.LduCnt + backendParams.HyuCnt, Flipped(new LoadCancelIO))\n\
      932: \n933:   val toIntExu: MixedVec[MixedVec[DecoupledIO[ExuInput]]] = intSchdParams.genExuInputBundle\n\
      934: \n935:   val toFpExu: MixedVec[MixedVec[DecoupledIO[ExuInput]]] = MixedVec(fpSchdParams.genExuInputBundle)\n\
      936: \n937:   val toVecExu: MixedVec[MixedVec[DecoupledIO[ExuInput]]] = MixedVec(vfSchdParams.genExuInputBundle)\n\
      938: \n939:   val toMemExu: MixedVec[MixedVec[DecoupledIO[ExuInput]]] = memSchdParams.genExuInputBundle\n\
      940: \n941:   val og1ImmInfo: Vec[ImmInfo] = Output(Vec(params.allExuParams.size,
      new ImmInfo))\n942: \n943:   val fromIntWb: MixedVec[RfWritePortWithConfig]
      = MixedVec(params.genIntWriteBackBundle)\n944: \n945:   val fromFpWb: MixedVec[RfWritePortWithConfig]
      = MixedVec(params.genFpWriteBackBundle)\n946: \n947:   val fromVfWb: MixedVec[RfWritePortWithConfig]
      = MixedVec(params.genVfWriteBackBundle)\n948: \n949:   val fromV0Wb: MixedVec[RfWritePortWithConfig]
      = MixedVec(params.genV0WriteBackBundle)\n950: \n951:   val fromVlWb: MixedVec[RfWritePortWithConfig]
      = MixedVec(params.genVlWriteBackBundle)\n952: \n953:   val fromPcTargetMem =
      Flipped(new PcToDataPathIO(params))\n954: \n955:   val fromBypassNetwork: Vec[RCWritePort]
      = Vec(params.getIntExuRCWriteSize + params.getMemExuRCWriteSize, \n956:    \
      \ new RCWritePort(params.intSchdParams.get.rfDataWidth, RegCacheIdxWidth, params.intSchdParams.get.pregIdxWidth,
      params.debugEn)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 954-966
    context: "954: \n955:   val fromBypassNetwork: Vec[RCWritePort] = Vec(params.getIntExuRCWriteSize
      + params.getMemExuRCWriteSize, \n956:     new RCWritePort(params.intSchdParams.get.rfDataWidth,
      RegCacheIdxWidth, params.intSchdParams.get.pregIdxWidth, params.debugEn)\n957:\
      \   )\n958: \n959:   val toBypassNetworkRCData: MixedVec[MixedVec[Vec[UInt]]]
      = MixedVec(\n960:     Seq(intSchdParams, fpSchdParams, vfSchdParams, memSchdParams).map(schd
      => schd.issueBlockParams.map(iq => \n961:       MixedVec(iq.exuBlockParams.map(exu
      => Output(Vec(exu.numRegSrc, UInt(exu.srcDataBitsMax.W)))))\n962:     )).flatten\n\
      963:   )\n964: \n965:   val toWakeupQueueRCIdx: Vec[UInt] = Vec(params.getIntExuRCWriteSize
      + params.getMemExuRCWriteSize, \n966:     Output(UInt(RegCacheIdxWidth.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFReadArbiter.scala
    lines: 1-11
    context: "1: package xiangshan.backend.datapath\n2: \n3: import org.chipsalliance.cde.config.Parameters\n\
      4: import chisel3._\n5: import chisel3.util.{Arbiter, DecoupledIO, RRArbiter,
      Valid, PopCount}\n6: import utils.SeqUtils.{MixedVec3, Seq3}\n7: import utils.{OptionWrapper,
      SeqUtils}\n8: import xiangshan.backend.BackendParams\n9: import xiangshan.backend.datapath.DataConfig._\n\
      10: import xiangshan.backend.datapath.RdConfig._\n11: import xiangshan.backend.regfile.PregParams"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFReadArbiter.scala
    lines: 15-25
    context: "15:   inRdCfgs: Seq3[RdConfig],\n16:   pregParams: PregParams,\n17:
      ) {\n18:   require(inRdCfgs.nonEmpty)\n19: \n20:   def genInputBundle: MixedVec3[DecoupledIO[RFArbiterBundle]]
      = {\n21:     val pregWidth = pregParams.addrWidth\n22:     SeqUtils.mapToMixedVec3(this.inRdCfgs,
      (rd: RdConfig) => DecoupledIO(new RFArbiterBundle(rd, pregWidth)))\n23:   }\n\
      24: \n25:   def portMax: Int = inRdCfgs.flatten.flatten.map(_.port).max"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFReadArbiter.scala
    lines: 60-72
    context: "60:         inGroup(portIdx).size\n61:       ))\n62:     )\n63:   }\n\
      64: \n65:   arbiters.zipWithIndex.foreach { case (arbiter, portIdx) =>\n66:\
      \     if (arbiter.nonEmpty) {\n67:       arbiter.get.io.in.zip(inGroup(portIdx)).foreach
      { case (arbiterIn, ioIn) =>\n68:         arbiterIn <> ioIn\n69:       }\n70:\
      \     }\n71:   }\n72: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFReadArbiter.scala
    lines: 76-86
    context: "76:       PopCount(a.map(_.valid)) > 1.U\n77:     }\n78:     for (i
      <- hasConflict.indices) {\n79:       XSPerfAccumulate(s\"IntRFReadPort_${i}_Conflict\"\
      , PopCount(hasConflict(i)))\n80:     }\n81:     val hasRead0 = arbitersIn.map
      { case a =>\n82:       a.map(x => x.valid && x.bits.addr === 0.U).reduce(_ ||
      _)\n83:     }\n84:     val hasSameAddr = arbitersIn.map { case a =>\n85:   \
      \    if (a.size == 2) a(0).valid && a(1).valid && a(0).bits.addr === a(1).bits.addr\n\
      86:       else false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFReadArbiter.scala
    lines: 83-93
    context: "83:     }\n84:     val hasSameAddr = arbitersIn.map { case a =>\n85:\
      \       if (a.size == 2) a(0).valid && a(1).valid && a(0).bits.addr === a(1).bits.addr\n\
      86:       else false.B\n87:     }\n88:     val hasRead0Conflict = hasConflict.zip(hasRead0).map(x
      => x._1 && x._2)\n89:     val hasReadSameAddrConflict = hasConflict.zip(hasSameAddr).map(x
      => x._1 && x._2)\n90:     XSPerfAccumulate(\"IntRFRead0_conflict_count\", PopCount(hasRead0Conflict))\n\
      91:     XSPerfAccumulate(\"IntRFReadSameAddr_conflict_count\", PopCount(hasReadSameAddrConflict))\n\
      92:   }\n93: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFReadArbiter.scala
    lines: 92-102
    context: "92:   }\n93: \n94:   // connection of NoRD\n95:   io.in.map(_.map(_.map(x
      =>\n96:     if (x.bits.rdCfg.get.isInstanceOf[NoRD]) {\n97:       x.ready :=
      true.B\n98:     }\n99:   )))\n100: \n101:   for (portIdx <- io.out.indices)
      {\n102:     val arb = arbiters(portIdx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFReadArbiter.scala
    lines: 101-111
    context: "101:   for (portIdx <- io.out.indices) {\n102:     val arb = arbiters(portIdx)\n\
      103:     val out = io.out(portIdx)\n104:     if (arb.nonEmpty) {\n105:     \
      \  val arbOut = arb.get.io.out\n106:       arbOut.ready := true.B\n107:    \
      \   out.valid := arbOut.valid\n108:       out.bits := arbOut.bits\n109:    \
      \ } else {\n110:       out := 0.U.asTypeOf(out)\n111:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFReadArbiter.scala
    lines: 122-132
    context: "122: \n123: class FpRFReadArbiter(\n124:   backendParams: BackendParams\n\
      125: )(implicit\n126:   p: Parameters\n127: ) extends RFReadArbiterBase(RFRdArbParams(backendParams.getRdCfgs[FpRD],
      backendParams.fpPregParams)) {\n128:   override protected def portRange: Range
      = 0 to backendParams.getRdPortIndices(FpData()).max\n129: }\n130: \n131: class
      VfRFReadArbiter(\n132:   backendParams: BackendParams"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFReadArbiter.scala
    lines: 130-140
    context: "130: \n131: class VfRFReadArbiter(\n132:   backendParams: BackendParams\n\
      133: )(implicit\n134:   p: Parameters\n135: ) extends RFReadArbiterBase(RFRdArbParams(backendParams.getRdCfgs[VfRD],
      backendParams.vfPregParams)) {\n136:   override protected def portRange: Range
      = 0 to backendParams.getRdPortIndices(VecData()).max\n137: }\n138: \n139: class
      V0RFReadArbiter(\n140:   backendParams: BackendParams"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataSource.scala
    lines: 3-13
    context: "3: import chisel3._\n4: \n5: class DataSource extends Bundle {\n6: \
      \  val value = UInt(4.W)\n7: \n8:   def readReg: Bool = value(3)\n9: \n10: \
      \  def readRegOH: Bool = value === DataSource.reg\n11: \n12:   def readRegCache:
      Bool = value === DataSource.regcache\n13: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataSource.scala
    lines: 9-29
    context: "9: \n10:   def readRegOH: Bool = value === DataSource.reg\n11: \n12:\
      \   def readRegCache: Bool = value === DataSource.regcache\n13: \n14:   def
      readV0: Bool = value === DataSource.v0\n15: \n16:   def readZero: Bool = value
      === DataSource.zero\n17: \n18:   def readForward: Bool = value === DataSource.forward\n\
      19: \n20:   def readBypass: Bool = value === DataSource.bypass\n21: \n22:  \
      \ def readBypass2: Bool = value === DataSource.bypass2\n23: \n24:   def readImm:
      Bool = value === DataSource.imm\n25: \n26: }\n27: \n28: object DataSource {\n\
      29:   def apply() = new DataSource"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataSource.scala
    lines: 35-45
    context: "35:   def v0: UInt = \"b0101\".U\n36: \n37:   // read int preg addr
      is 0\n38:   def zero: UInt = \"b0000\".U\n39: \n40:   def forward: UInt = \"\
      b0001\".U\n41: \n42:   def bypass: UInt = \"b0010\".U\n43: \n44:   def bypass2:
      UInt = \"b0011\".U\n45: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiterParams.scala
    lines: 1-10
    context: "1: package xiangshan.backend.datapath\n2: \n3: import org.chipsalliance.cde.config.Parameters\n\
      4: import chisel3.Output\n5: import chisel3.util.{DecoupledIO, MixedVec, ValidIO,
      log2Up}\n6: import xiangshan.backend.BackendParams\n7: import xiangshan.backend.Bundles.WriteBackBundle\n\
      8: import xiangshan.backend.datapath.DataConfig._\n9: import xiangshan.backend.datapath.WbConfig._\n\
      10: import xiangshan.backend.regfile.PregParams"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiterParams.scala
    lines: 15-25
    context: "15:   backendParams: BackendParams,\n16: ) {\n17: \n18:   def numIn
      = wbCfgs.length\n19: \n20:   def numOut = wbCfgs.head match {\n21:     case
      _: WbConfig.IntWB => pregParams.numWrite.getOrElse(backendParams.getWbPortIndices(IntData()).size)\n\
      22:     case _: WbConfig.FpWB => pregParams.numWrite.getOrElse(backendParams.getWbPortIndices(FpData()).size)\n\
      23:     case _: WbConfig.VfWB => pregParams.numWrite.getOrElse(backendParams.getWbPortIndices(VecData()).size)\n\
      24:     case _: WbConfig.V0WB => pregParams.numWrite.getOrElse(backendParams.getWbPortIndices(V0Data()).size)\n\
      25:     case _: WbConfig.VlWB => pregParams.numWrite.getOrElse(backendParams.getWbPortIndices(VlData()).size)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiterParams.scala
    lines: 31-48
    context: "31:   def dataWidth = pregParams.dataCfg.dataWidth\n32: \n33:   def
      addrWidth = log2Up(pregParams.numEntries)\n34: \n35:   def genInput(implicit
      p: Parameters) = {\n36:     MixedVec(wbCfgs.map(x => DecoupledIO(new WriteBackBundle(x,
      backendParams))))\n37:   }\n38: \n39:   def genOutput(implicit p: Parameters):
      MixedVec[ValidIO[WriteBackBundle]] = {\n40:     Output(MixedVec(Seq.tabulate(numOut)
      {\n41:       x =>\n42:         ValidIO(new WriteBackBundle(\n43:           wbCfgs.head.dataCfg
      match {\n44:             case IntData() => IntWB(port = x)\n45:            \
      \ case FpData()  => FpWB(port = x)\n46:             case VecData() => VfWB(port
      = x)\n47:             case V0Data()  => V0WB(port = x)\n48:             case
      VlData()  => VlWB(port = x)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 67-83
    context: "67:     println(s\"[NewDispatch] ${fu.name} $iqidx\")\n68:   }\n69:\
      \   val sameIQIdxFus = fuMapIQIdx.map{ case (fu, iqidx) =>\n70:     fuMapIQIdx.filter(_._2
      == iqidx).map(_._1) -> iqidx\n71:   }.toSet.toSeq\n72:   val needMultiIQ = sameIQIdxFus.sortBy(_._1.head.fuType.id).filter(_._2.size
      > 1)\n73:   val needSingleIQ = sameIQIdxFus.sortBy(_._1.head.fuType.id).filter(_._2.size
      == 1)\n74:   needMultiIQ.map { case (fus, iqidx) =>\n75:     println(s\"[NewDispatch]
      needMultiIQ: ${fus.map(_.name)} $iqidx\")\n76:   }\n77:   needSingleIQ.map {
      case (fus, iqidx) =>\n78:     println(s\"[NewDispatch] needSingleIQ: ${fus.map(_.name)}
      $iqidx\")\n79:   }\n80:   val fuConfigsInExuParams = allExuParams.map(_.fuConfigs)\n\
      81:   val fuMapExuIdx = sortedFuConfigs.map { case fu => {\n82:     val fuInExuIdx
      = fuConfigsInExuParams.zipWithIndex.filter { case (f, i) => f.contains(fu) }.map(_._2)\n\
      83:     (fu -> fuInExuIdx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 84-95
    context: "84:     }\n85:   }\n86:   val sameExuIdxFus = fuMapExuIdx.map { case
      (fu, exuidx) =>\n87:     fuMapExuIdx.filter(_._2 == exuidx).map(_._1) -> exuidx\n\
      88:   }.toSet.toSeq\n89:   val needMultiExu = sameExuIdxFus.sortBy(_._1.head.fuType.id).filter(_._2.size
      > 1).filter{ x =>\n90:     x._1.map(y => fuMapIQIdx.filter(_._1 == y).head._2.size
      > 1).reduce(_ && _)\n91:   }\n92: \n93:   val exuNum = allExuParams.size\n94:\
      \   val maxIQSize = allIssueParams.map(_.numEntries).max\n95:   val IQEnqSum
      = allIssueParams.map(_.numEnq).sum"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 110-123
    context: "110:     val wbPregsFp = Vec(backendParams.numPregWb(FpData()), Flipped(ValidIO(UInt(PhyRegIdxWidth.W))))\n\
      111:     val wbPregsVec = Vec(backendParams.numPregWb(VecData()), Flipped(ValidIO(UInt(PhyRegIdxWidth.W))))\n\
      112:     val wbPregsV0 = Vec(backendParams.numPregWb(V0Data()), Flipped(ValidIO(UInt(PhyRegIdxWidth.W))))\n\
      113:     val wbPregsVl = Vec(backendParams.numPregWb(VlData()), Flipped(ValidIO(UInt(PhyRegIdxWidth.W))))\n\
      114:     val wakeUpAll = new Bundle {\n115:       val wakeUpInt: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]]
      = Flipped(backendParams.intSchdParams.get.genIQWakeUpOutValidBundle)\n116: \
      \      val wakeUpFp: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]] = Flipped(backendParams.fpSchdParams.get.genIQWakeUpOutValidBundle)\n\
      117:       val wakeUpVec: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]] = Flipped(backendParams.vfSchdParams.get.genIQWakeUpOutValidBundle)\n\
      118:       val wakeUpMem: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]] = Flipped(backendParams.memSchdParams.get.genIQWakeUpOutValidBundle)\n\
      119:     }\n120:     val og0Cancel = Input(ExuVec())\n121:     val ldCancel
      = Vec(backendParams.LdExuCnt, Flipped(new LoadCancelIO))\n122:     // to vlbusytable\n\
      123:     val vlWriteBackInfo = new Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 139-149
    context: "139:     //toMem\n140:     val toMem = new Bundle {\n141:       val
      lsqEnqIO = Flipped(new LsqEnqIO)\n142:     }\n143:     // redirect\n144:   \
      \  val redirect = Flipped(ValidIO(new Redirect))\n145:     // singleStep\n146:\
      \     val singleStep = Input(Bool())\n147:     // lfst\n148:     val lfst =
      new DispatchLFSTIO\n149: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 146-156
    context: "146:     val singleStep = Input(Bool())\n147:     // lfst\n148:    \
      \ val lfst = new DispatchLFSTIO\n149: \n150:     // perf only\n151:     val
      robHead = Input(new DynInst)\n152:     val stallReason = Flipped(new StallReasonIO(RenameWidth))\n\
      153:     val lqCanAccept = Input(Bool())\n154:     val sqCanAccept = Input(Bool())\n\
      155:     val robHeadNotReady = Input(Bool())\n156:     val robFull = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 161-171
    context: "161:   })\n162:   // Deq for std's IQ is not assigned in Dispatch2Iq,
      so add one more src for it.\n163:   val issueBlockParams = backendParams.allIssueParams\n\
      164:   val renameIn = io.renameIn\n165:   val fromRename = io.fromRename\n166:\
      \   io.toRenameAllFire := io.fromRename.map(x => !x.valid || x.fire).reduce(_
      && _)\n167:   val fromRenameUpdate = Wire(Vec(RenameWidth, Flipped(ValidIO(new
      DynInst))))\n168:   fromRenameUpdate := fromRename\n169:   val renameWidth =
      io.fromRename.size\n170:   val issueQueueCount = io.IQValidNumVec\n171:   val
      issueQueueNum = allIssueParams.size"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 265-275
    context: "265:   rcTagTable.io.og0Cancel := io.og0Cancel\n266:   rcTagTable.io.ldCancel
      := io.ldCancel\n267:   busyTables.zip(idxRegType).zipWithIndex.map { case ((b,
      idxseq), i) => {\n268:     val readAddr = VecInit(fromRename.map(x => x.bits.psrc.zipWithIndex.filter(xx
      => idxseq.contains(xx._2)).map(_._1)).flatten)\n269:     val readValid = VecInit(fromRename.map(x
      => x.bits.psrc.zipWithIndex.filter(xx => idxseq.contains(xx._2)).map(y => x.valid
      && SrcType.isXp(x.bits.srcType(y._2)))).flatten)\n270:     b.io.read.map(_.req).zip(readAddr).map(x
      => x._1 := x._2)\n271:     // only int src need srcLoadDependency, src0 src1\n\
      272:     if (i == 0) {\n273:       val srcLoadDependencyUpdate = fromRenameUpdate.map(x
      => x.bits.srcLoadDependency.zipWithIndex.filter(x => idxseq.contains(x._2)).map(_._1)).flatten\n\
      274:       val srcType = fromRenameUpdate.map(x => x.bits.srcType.zipWithIndex.filter(x
      => idxseq.contains(x._2)).map(_._1)).flatten\n275:       // for std, int src
      need srcLoadDependency, fp src donot need srcLoadDependency"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 271-281
    context: "271:     // only int src need srcLoadDependency, src0 src1\n272:   \
      \  if (i == 0) {\n273:       val srcLoadDependencyUpdate = fromRenameUpdate.map(x
      => x.bits.srcLoadDependency.zipWithIndex.filter(x => idxseq.contains(x._2)).map(_._1)).flatten\n\
      274:       val srcType = fromRenameUpdate.map(x => x.bits.srcType.zipWithIndex.filter(x
      => idxseq.contains(x._2)).map(_._1)).flatten\n275:       // for std, int src
      need srcLoadDependency, fp src donot need srcLoadDependency\n276:       srcLoadDependencyUpdate.lazyZip(b.io.read.map(_.loadDependency)).lazyZip(srcType).map{
      case (sink, source, srctype) =>\n277:         sink := Mux(SrcType.isXp(srctype),
      source, 0.U.asTypeOf(sink))\n278:       }\n279:       // only int src need rcTag\n\
      280:       val rcTagUpdate = fromRenameUpdate.map(x => x.bits.regCacheIdx.zipWithIndex.filter(x
      => idxseq.contains(x._2)).map(_._1)).flatten\n281:       rcTagUpdate.zip(rcTagTable.io.readPorts.map(_.addr)).map(x
      => x._1 := x._2)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 291-302
    context: "291:       for (k <- 0 until numRegType){\n292:         if (!idxRegType(k).contains(j))
      {\n293:           allSrcState(i)(j)(k) := false.B\n294:         }\n295:    \
      \     else {\n296:           val readidx = i * idxRegType(k).size + idxRegType(k).indexOf(j)\n\
      297:           val readEn = k match {\n298:             case 0 => SrcType.isXp(fromRename(i).bits.srcType(j))\n\
      299:             case 1 => SrcType.isFp(fromRename(i).bits.srcType(j))\n300:\
      \             case 2 => SrcType.isVp(fromRename(i).bits.srcType(j))\n301:  \
      \           case 3 => SrcType.isV0(fromRename(i).bits.srcType(j))\n302:    \
      \         case 4 => true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 299-309
    context: "299:             case 1 => SrcType.isFp(fromRename(i).bits.srcType(j))\n\
      300:             case 2 => SrcType.isVp(fromRename(i).bits.srcType(j))\n301:\
      \             case 3 => SrcType.isV0(fromRename(i).bits.srcType(j))\n302:  \
      \           case 4 => true.B\n303:           }\n304:           allSrcState(i)(j)(k)
      := readEn && busyTables(k).io.read(readidx).resp || SrcType.isImm(fromRename(i).bits.srcType(j))\n\
      305:         }\n306:       }\n307:     }\n308:   }\n309: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 312-323
    context: "312:   for (i <- 0 until renameWidth){\n313:     // numRegSrcVf - 1
      is old vd\n314:     var j = numRegSrcVf - 1\n315:     // 2 is type of vec\n\
      316:     var k = 2\n317:     val readidx = i * idxRegType(k).size + idxRegType(k).indexOf(j)\n\
      318:     val readEn = SrcType.isVp(fromRename(i).bits.srcType(j))\n319:    \
      \ val isDependOldVd = fromRename(i).bits.vpu.isDependOldVd\n320:     val isWritePartVd
      = fromRename(i).bits.vpu.isWritePartVd\n321:     val vta = fromRename(i).bits.vpu.vta\n\
      322:     val vma = fromRename(i).bits.vpu.vma\n323:     val vm = fromRename(i).bits.vpu.vm"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 323-335
    context: "323:     val vm = fromRename(i).bits.vpu.vm\n324:     val vlIsVlmax
      = vlBusyTable.io_vl_read.vlReadInfo(i).is_vlmax\n325:     val vlIsNonZero =
      vlBusyTable.io_vl_read.vlReadInfo(i).is_nonzero\n326:     val ignoreTail = vlIsVlmax
      && (vm =/= 0.U || vma) && !isWritePartVd\n327:     val ignoreWhole = (vm =/=
      0.U || vma) && vta\n328:     val ignoreOldVd = vlBusyTable.io.read(i).resp &&
      vlIsNonZero && !isDependOldVd && (ignoreTail || ignoreWhole)\n329:     ignoreOldVdVec(i)
      := readEn && ignoreOldVd\n330:     allSrcState(i)(j)(k) := readEn && (busyTables(k).io.read(readidx).resp
      || ignoreOldVd) || SrcType.isImm(fromRename(i).bits.srcType(j))\n331:   }\n\
      332: \n333:   // Singlestep should only commit one machine instruction after
      dret, and then hart enter debugMode according to singlestep exception.\n334:\
      \   val s_holdRobidx :: s_updateRobidx :: Nil = Enum(2)\n335:   val singleStepState
      = RegInit(s_updateRobidx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 339-349
    context: "339:   val robidxCanCommitStepping = WireInit(0.U.asTypeOf(fromRename(0).bits.robIdx))\n\
      340:   robidxStepReg := robidxCanCommitStepping\n341: \n342:   when(!io.singleStep)
      {\n343:     singleStepState := s_updateRobidx\n344:   }.elsewhen(io.singleStep
      && fromRename(0).fire && io.enqRob.req(0).valid) {\n345:     singleStepState
      := s_holdRobidx\n346:     robidxStepHold := fromRename(0).bits.robIdx\n347:\
      \   }\n348: \n349:   when(singleStepState === s_updateRobidx) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 347-357
    context: "347:   }\n348: \n349:   when(singleStepState === s_updateRobidx) {\n\
      350:     robidxCanCommitStepping := robidxStepHold\n351:   }.elsewhen(singleStepState
      === s_holdRobidx) {\n352:     when(io.redirect.valid){\n353:       robidxCanCommitStepping.flag
      := !robidxStepReg.flag\n354:     }.otherwise {\n355:       robidxCanCommitStepping
      := robidxStepReg\n356:     }\n357:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 355-369
    context: "355:       robidxCanCommitStepping := robidxStepReg\n356:     }\n357:\
      \   }\n358: \n359:   val minIQSelAll = Wire(Vec(needMultiExu.size, Vec(renameWidth,
      Vec(issueQueueNum, Bool()))))\n360:   needMultiExu.zipWithIndex.map{ case ((fus,
      exuidx), needMultiExuidx) => {\n361:     val suffix = fus.map(_.name).mkString(\"\
      _\")\n362:     val iqNum = exuidx.size\n363:     val iqidx = allIssueParams.map(_.exuBlockParams.map(_.fuConfigs).flatten.toSet.toSeq).zipWithIndex.filter{x
      => fus.toSet.subsetOf(x._1.toSet)}.map(_._2)\n364:     println(s\"[NewDispatch]
      ${fus.map(_.name)};iqidx:$iqidx;exuIdx:$exuidx\")\n365:     val compareMatrix
      = Wire(Vec(iqNum, Vec(iqNum, Bool()))).suggestName(s\"compareMatrix_$suffix\"\
      )\n366:     for (i <- 0 until iqNum) {\n367:       for (j <- 0 until iqNum)
      {\n368:         if (i == j) compareMatrix(i)(j) := false.B\n369:         else
      if (i < j) compareMatrix(i)(j) := issueQueueCount(exuidx(i)) < issueQueueCount(exuidx(j))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 427-437
    context: "427:                 Mux(fuTypeOH(i).asUInt.orR,\n428:             \
      \      Mux1H(fuTypeOH(i), minIQSelAll)(Mux1H(fuTypeOH(i), popFuTypeOH(i))),\n\
      429:                   Mux1H(fuTypeOHSingle(i), uopSelIQSingle)),\n430:    \
      \             0.U.asTypeOf(u)\n431:               )\n432:     }.elsewhen(io.fromRename(i).fire){\n\
      433:       u := 0.U.asTypeOf(u)\n434:     }\n435:   }}\n436:   val uopSelIQMatrix
      = Wire(Vec(renameWidth, Vec(issueQueueNum, UInt(renameWidth.U.getWidth.W))))\n\
      437:   uopSelIQMatrix.zipWithIndex.map{ case (u, i) => {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 446-456
    context: "446:   val lsqCanAccept = Wire(Bool())\n447:   for (i <- 0 until RenameWidth){\n\
      448:     // update valid logic\n449:     fromRenameUpdate(i).valid := fromRename(i).valid
      && allowDispatch(i) && !uopBlockByIQ(i) && thisCanActualOut(i) &&\n450:    \
      \   lsqCanAccept && !fromRename(i).bits.eliminatedMove && !fromRename(i).bits.hasException
      && !fromRenameUpdate(i).bits.singleStep\n451:     fromRename(i).ready := allowDispatch(i)
      && !uopBlockByIQ(i) && thisCanActualOut(i) && lsqCanAccept\n452:     // update
      src type if eliminate old vd\n453:     fromRenameUpdate(i).bits.srcType(numRegSrcVf
      - 1) := Mux(ignoreOldVdVec(i), SrcType.no, fromRename(i).bits.srcType(numRegSrcVf
      - 1))\n454:   }\n455:   for (i <- 0 until RenameWidth){\n456:     // check is
      drop amocas sta"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 485-495
    context: "485:     }\n486:   }}\n487:   temp = 0\n488:   val uopBlockMatrix =
      Wire(Vec(renameWidth, Vec(issueQueueNum, Bool())))\n489:   val uopBlockMatrixForAssign
      = allIssueParams.zipWithIndex.map { case (issue, iqidx) => {\n490:     val result
      = uopSelIQMatrix.map(_(iqidx)).map(x => Mux(io.toIssueQueues(temp).ready, x
      > issue.numEnq.U, x.orR))\n491:     temp = temp + issue.numEnq\n492:     result\n\
      493:   }}.transpose\n494:   uopBlockMatrix.zip(uopBlockMatrixForAssign).map(x
      => x._1 := VecInit(x._2))\n495:   uopBlockByIQ := uopBlockMatrix.map(_.reduce(_
      || _))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 513-528
    context: "513: \n514:   val lsqEnqCtrl = Module(new LsqEnqCtrl)\n515: \n516: \
      \  // TODO: check lsqEnqCtrl redirect logic\n517:   // here is RegNext because
      dispatch2iq use s2_s4_redirect, newDispatch use s1_s3_redirect\n518:   lsqEnqCtrl.io.redirect
      := RegNext(io.redirect)\n519:   lsqEnqCtrl.io.lcommit := io.fromMem.lcommit\n\
      520:   lsqEnqCtrl.io.scommit := io.fromMem.scommit\n521:   lsqEnqCtrl.io.lqCancelCnt
      := io.fromMem.lqCancelCnt\n522:   lsqEnqCtrl.io.sqCancelCnt := io.fromMem.sqCancelCnt\n\
      523:   lsqEnqCtrl.io.enq.iqAccept := io.fromRename.map(x => !x.valid || x.fire)\n\
      524:   io.toMem.lsqEnqIO <> lsqEnqCtrl.io.enqLsq\n525: \n526:   private val
      enqLsqIO = lsqEnqCtrl.io.enq\n527:   private val lqFreeCount = lsqEnqCtrl.io.lqFreeCount\n\
      528:   private val sqFreeCount = lsqEnqCtrl.io.sqFreeCount"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 686-696
    context: "686: \n687: \n688:   // enqLsq io\n689:   require(enqLsqIO.req.size
      == enqLsqIO.resp.size)\n690:   for (i <- enqLsqIO.req.indices) {\n691:     when(!io.fromRename(i).fire)
      {\n692:       enqLsqIO.needAlloc(i) := 0.U\n693:     }.elsewhen(isStoreVec(i)
      || isVStoreVec(i)) {\n694:       enqLsqIO.needAlloc(i) := 2.U // store | vstore\n\
      695:     }.elsewhen(isLoadVec(i) || isVLoadVec(i)){\n696:       enqLsqIO.needAlloc(i)
      := 1.U // load | vload"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 695-705
    context: "695:     }.elsewhen(isLoadVec(i) || isVLoadVec(i)){\n696:       enqLsqIO.needAlloc(i)
      := 1.U // load | vload\n697:     }.otherwise {\n698:       enqLsqIO.needAlloc(i)
      := 0.U\n699:     }\n700:     enqLsqIO.req(i).valid := io.fromRename(i).fire
      && !isAMOVec(i) && !isSegment(i) && !isfofFixVlUop(i)\n701:     enqLsqIO.req(i).bits
      := io.fromRename(i).bits\n702: \n703:     // This is to make it easier to calculate
      in LSQ.\n704:     // Both scalar instructions and vector instructions with FLOW
      equal to 1 have a NUM value of 1.\n705:     // But, the 'numLsElem' that is
      not a vector is set to 0 when passed to IQ"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 721-731
    context: "721:   val isWaitForward    = VecInit(fromRename.map(x => x.valid &&
      x.bits.waitForward))\n722: \n723:   val updatedUop = Wire(Vec(RenameWidth, new
      DynInst))\n724:   val checkpoint_id = RegInit(0.U(64.W))\n725:   checkpoint_id
      := checkpoint_id + PopCount((0 until RenameWidth).map(i =>\n726:     fromRename(i).fire\n\
      727:   ))\n728: \n729: \n730:   for (i <- 0 until RenameWidth) {\n731: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 734-744
    context: "734:     // For the LUI instruction: psrc(0) is from register file and
      should always be zero.\n735:     when (fromRename(i).bits.isLUI) {\n736:   \
      \    updatedUop(i).psrc(0) := 0.U\n737:     }\n738:     //TODO: vec ls mdp\n\
      739:     io.lfst.req(i).valid := fromRename(i).fire && updatedUop(i).storeSetHit\n\
      740:     io.lfst.req(i).bits.isstore := isStore(i)\n741:     io.lfst.req(i).bits.ssid
      := updatedUop(i).ssid\n742:     io.lfst.req(i).bits.robIdx := updatedUop(i).robIdx
      // speculatively assigned in rename\n743: \n744:     // override load delay
      ctrl signal with store set result"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 749-761
    context: "749:       updatedUop(i).loadWaitBit := isLs(i) && !isStore(i) && fromRename(i).bits.loadWaitBit\n\
      750:     }\n751:     // // update singleStep, singleStep exception only enable
      in next machine instruction.\n752:     updatedUop(i).singleStep := io.singleStep
      && (fromRename(i).bits.robIdx =/= robidxCanCommitStepping)\n753:     XSDebug(\n\
      754:       fromRename(i).fire &&\n755:         (TriggerAction.isDmode(updatedUop(i).trigger)
      || updatedUop(i).exceptionVec(breakPoint)), s\"Debug Mode: inst ${i} has frontend
      trigger exception\\n\")\n756:     XSDebug(fromRename(i).fire && updatedUop(i).singleStep,
      s\"Debug Mode: inst ${i} has single step exception\\n\")\n757:     if (env.EnableDifftest)
      {\n758:       // debug runahead hint\n759:       val debug_runahead_checkpoint_id
      = Wire(checkpoint_id.cloneType)\n760:       if(i == 0){\n761:         debug_runahead_checkpoint_id
      := checkpoint_id"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 759-769
    context: "759:       val debug_runahead_checkpoint_id = Wire(checkpoint_id.cloneType)\n\
      760:       if(i == 0){\n761:         debug_runahead_checkpoint_id := checkpoint_id\n\
      762:       } else {\n763:         debug_runahead_checkpoint_id := checkpoint_id
      + PopCount((0 until i).map(i =>\n764:           fromRename(i).fire\n765:   \
      \      ))\n766:       }\n767:     }\n768:   }\n769: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 767-786
    context: "767:     }\n768:   }\n769: \n770:   // store set perf count\n771:  \
      \ XSPerfAccumulate(\"waittable_load_wait\", PopCount((0 until RenameWidth).map(i
      =>\n772:     fromRename(i).fire && fromRename(i).bits.loadWaitBit && !isStore(i)
      && isLs(i)\n773:   )))\n774:   XSPerfAccumulate(\"storeset_load_wait\", PopCount((0
      until RenameWidth).map(i =>\n775:     fromRename(i).fire && updatedUop(i).loadWaitBit
      && !isStore(i) && isLs(i)\n776:   )))\n777:   XSPerfAccumulate(\"storeset_load_strict_wait\"\
      , PopCount((0 until RenameWidth).map(i =>\n778:     fromRename(i).fire && updatedUop(i).loadWaitBit
      && updatedUop(i).loadWaitStrict && !isStore(i) && isLs(i)\n779:   )))\n780:\
      \   XSPerfAccumulate(\"storeset_store_wait\", PopCount((0 until RenameWidth).map(i
      =>\n781:     fromRename(i).fire && updatedUop(i).loadWaitBit && isStore(i)\n\
      782:   )))\n783: \n784:   val allResourceReady = io.enqRob.canAccept\n785: \n\
      786:   // Instructions should enter dispatch queues in order."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 821-831
    context: "821: \n822:   // input for ROB, LSQ\n823:   for (i <- 0 until RenameWidth)
      {\n824:     // needAlloc no use, need deleted\n825:     io.enqRob.needAlloc(i)
      := fromRename(i).valid\n826:     io.enqRob.req(i).valid := fromRename(i).fire\n\
      827:     io.enqRob.req(i).bits := updatedUop(i)\n828:     io.enqRob.req(i).bits.hasException
      := updatedUop(i).hasException || updatedUop(i).singleStep\n829:     io.enqRob.req(i).bits.numWB
      := Mux(updatedUop(i).singleStep, 0.U, updatedUop(i).numWB)\n830:   }\n831: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 833-843
    context: "833:   val hasSpecialInstr = Cat((0 until RenameWidth).map(i => isBlockBackward(i))).orR\n\
      834: \n835:   private val canAccept = !hasValidInstr || !hasSpecialInstr &&
      io.enqRob.canAccept\n836: \n837:   val isWaitForwardOrBlockBackward = isWaitForward.asUInt.orR
      || isBlockBackward.asUInt.orR\n838:   val renameFireCnt = PopCount(fromRename.map(_.fire))\n\
      839: \n840:   val stall_rob = hasValidInstr && !io.enqRob.canAccept\n841:  \
      \ val stall_int_dq = hasValidInstr && io.enqRob.canAccept\n842:   val stall_int_dq0
      = hasValidInstr && io.enqRob.canAccept\n843:   val stall_int_dq1 = hasValidInstr
      && io.enqRob.canAccept"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 843-855
    context: "843:   val stall_int_dq1 = hasValidInstr && io.enqRob.canAccept\n844:\
      \   val stall_fp_dq = hasValidInstr && io.enqRob.canAccept\n845:   val stall_ls_dq
      = hasValidInstr && io.enqRob.canAccept\n846: \n847:   XSPerfAccumulate(\"in_valid_count\"\
      , PopCount(fromRename.map(_.valid)))\n848:   XSPerfAccumulate(\"in_fire_count\"\
      , PopCount(fromRename.map(_.fire)))\n849:   XSPerfAccumulate(\"in_valid_not_ready_count\"\
      , PopCount(fromRename.map(x => x.valid && !x.ready)))\n850:   XSPerfAccumulate(\"\
      wait_cycle\", !fromRename.head.valid && allResourceReady)\n851: \n852:   XSPerfAccumulate(\"\
      stall_cycle_rob\", stall_rob)\n853:   XSPerfAccumulate(\"stall_cycle_int_dq0\"\
      , stall_int_dq0)\n854:   XSPerfAccumulate(\"stall_cycle_int_dq1\", stall_int_dq1)\n\
      855:   XSPerfAccumulate(\"stall_cycle_fp_dq\", stall_fp_dq)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 874-885
    context: "874:   Mux(vioReplay, TopDownCounters.LoadVioReplayStall.id.U,\n875:\
      \   TopDownCounters.LoadL1Stall.id.U))))))))\n876: \n877:   val fusedVec = (0
      until RenameWidth).map{ case i =>\n878:     if (i == 0) false.B\n879:     else
      (io.fromRename(i-1).fire && !io.fromRename(i).valid &&\n880:          CommitType.isFused(io.fromRename(i-1).bits.commitType))\n\
      881:   }\n882: \n883:   val decodeReason = RegNextN(io.stallReason.reason, 2)\n\
      884:   val renameReason = RegNext(io.stallReason.reason)\n885: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 882-901
    context: "882: \n883:   val decodeReason = RegNextN(io.stallReason.reason, 2)\n\
      884:   val renameReason = RegNext(io.stallReason.reason)\n885: \n886:   val
      stallReason = Wire(chiselTypeOf(io.stallReason.reason))\n887:   val firedVec
      = fromRename.map(_.fire)\n888:   io.stallReason.backReason.valid := !canAccept\n\
      889:   io.stallReason.backReason.bits := TopDownCounters.OtherCoreStall.id.U\n\
      890:   stallReason.zip(io.stallReason.reason).zip(firedVec).zipWithIndex.zip(fusedVec).map
      { case ((((update, in), fire), idx), fused) =>\n891:     val headIsInt = FuType.isInt(io.robHead.getDebugFuType)\
      \  && io.robHeadNotReady\n892:     val headIsFp  = FuType.isFArith(io.robHead.getDebugFuType)\
      \   && io.robHeadNotReady\n893:     val headIsDiv = FuType.isDivSqrt(io.robHead.getDebugFuType)
      && io.robHeadNotReady\n894:     val headIsLd  = io.robHead.getDebugFuType ===
      FuType.ldu.U && io.robHeadNotReady || !io.lqCanAccept\n895:     val headIsSt\
      \  = io.robHead.getDebugFuType === FuType.stu.U && io.robHeadNotReady || !io.sqCanAccept\n\
      896:     val headIsAmo = io.robHead.getDebugFuType === FuType.mou.U && io.robHeadNotReady\n\
      897:     val headIsLs  = headIsLd || headIsSt\n898:     val robLsFull = io.robFull
      || !io.lqCanAccept || !io.sqCanAccept\n899: \n900:     import TopDownCounters._\n\
      901:     update := MuxCase(OtherCoreStall.id.U, Seq("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 898-908
    context: "898:     val robLsFull = io.robFull || !io.lqCanAccept || !io.sqCanAccept\n\
      899: \n900:     import TopDownCounters._\n901:     update := MuxCase(OtherCoreStall.id.U,
      Seq(\n902:       // fire\n903:       (fire || fused                        \
      \             ) -> NoStall.id.U          ,\n904:       // dispatch not stall
      / core stall from decode or rename\n905:       (in =/= OtherCoreStall.id.U &&
      in =/= NoStall.id.U ) -> in                    ,\n906:       // rob stall\n\
      907:       (headIsAmo                                         ) -> AtomicStall.id.U\
      \      ,\n908:       (headIsSt                                          ) ->
      StoreStall.id.U       ,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 913-927
    context: "913:       (renameReason(idx) =/= NoStall.id.U                ) -> renameReason(idx)\
      \     ,\n914:       (decodeReason(idx) =/= NoStall.id.U                ) ->
      decodeReason(idx)     ,\n915:     ))\n916:   }\n917: \n918:   TopDownCounters.values.foreach(ctr
      => XSPerfAccumulate(ctr.toString(), PopCount(stallReason.map(_ === ctr.id.U)),
      XSPerfLevel.CRITICAL))\n919: \n920:   val robTrueCommit = io.debugTopDown.fromRob.robTrueCommit\n\
      921:   TopDownCounters.values.foreach(ctr => XSPerfRolling(\"td_\"+ctr.toString(),
      PopCount(stallReason.map(_ === ctr.id.U)),\n922:                           \
      \                            robTrueCommit, 1000, clock, reset))\n923: \n924:\
      \   XSPerfHistogram(\"slots_fire\", PopCount(thisActualOut), true.B, 0, RenameWidth+1,
      1)\n925:   // Explaination: when out(0) not fire, PopCount(valid) is not meaningfull\n\
      926:   XSPerfHistogram(\"slots_valid_pure\", PopCount(io.enqRob.req.map(_.valid)),
      thisActualOut(0), 0, RenameWidth+1, 1)\n927:   XSPerfHistogram(\"slots_valid_rough\"\
      , PopCount(io.enqRob.req.map(_.valid)), true.B, 0, RenameWidth+1, 1)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 925-935
    context: "925:   // Explaination: when out(0) not fire, PopCount(valid) is not
      meaningfull\n926:   XSPerfHistogram(\"slots_valid_pure\", PopCount(io.enqRob.req.map(_.valid)),
      thisActualOut(0), 0, RenameWidth+1, 1)\n927:   XSPerfHistogram(\"slots_valid_rough\"\
      , PopCount(io.enqRob.req.map(_.valid)), true.B, 0, RenameWidth+1, 1)\n928: \n\
      929:   val perfEvents = Seq(\n930:     (\"dispatch_in\",                 PopCount(fromRename.map(_.valid
      && fromRename(0).ready))                       ),\n931:     (\"dispatch_empty\"\
      ,              !hasValidInstr                                              \
      \                   ),\n932:     (\"dispatch_utili\",              PopCount(fromRename.map(_.valid))\
      \                                              ),\n933:     (\"dispatch_waitinstr\"\
      ,          PopCount(fromRename.map(!_.valid && canAccept))                 \
      \               ),\n934:     (\"dispatch_stall_cycle_lsq\",    false.B     \
      \                                                                   ),\n935:\
      \     (\"dispatch_stall_cycle_rob\",    stall_rob                          \
      \                                            ),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 22-32
    context: "22: import chisel3.util._\n23: import freechips.rocketchip.diplomacy.{LazyModule,
      LazyModuleImp}\n24: import utility._\n25: import xiangshan.backend.fu.{CSRFileIO,
      FenceIO, FuncUnitInput}\n26: import xiangshan.backend.Bundles.{ExuInput, ExuOutput,
      MemExuInput, MemExuOutput}\n27: import xiangshan.{AddrTransType, FPUCtrlSignals,
      HasXSParameter, Redirect, XSBundle, XSModule}\n28: import xiangshan.backend.datapath.WbConfig.{PregWB,
      _}\n29: import xiangshan.backend.fu.FuType\n30: import xiangshan.backend.fu.vector.Bundles.{VType,
      Vxrm}\n31: import xiangshan.backend.fu.fpu.Bundles.Frm\n32: import xiangshan.backend.fu.wrapper.{CSRInput,
      CSRToDecode}"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 30-40
    context: "30: import xiangshan.backend.fu.vector.Bundles.{VType, Vxrm}\n31: import
      xiangshan.backend.fu.fpu.Bundles.Frm\n32: import xiangshan.backend.fu.wrapper.{CSRInput,
      CSRToDecode}\n33: \n34: class ExeUnitIO(params: ExeUnitParams)(implicit p: Parameters)
      extends XSBundle {\n35:   val flush = Flipped(ValidIO(new Redirect()))\n36:\
      \   val in = Flipped(DecoupledIO(new ExuInput(params, hasCopySrc = true)))\n\
      37:   val out = DecoupledIO(new ExuOutput(params))\n38:   val csrin = Option.when(params.hasCSR)(new
      CSRInput)\n39:   val csrio = Option.when(params.hasCSR)(new CSRFileIO)\n40:\
      \   val csrToDecode = Option.when(params.hasCSR)(Output(new CSRToDecode))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 67-77
    context: "67:     val module = cfg.fuGen(p, cfg)\n68:     module\n69:   })\n70:\
      \ \n71:   if (EnableClockGate) {\n72:     fuCfgs.zip(funcUnits).foreach { case
      (cfg, fu) =>\n73:       val clk_en = WireInit(false.B)\n74:       val fuVld_en
      = WireInit(false.B)\n75:       val fuVld_en_reg = RegInit(false.B)\n76:    \
      \   val uncer_en_reg = RegInit(false.B)\n77: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 81-91
    context: "81:       val uncerLat = cfg.latency.uncertainEnable.nonEmpty\n82: \
      \      val lat0 = (latReal == 0 && !uncerLat).asBool\n83:       val latN = (latReal
      >  0 && !uncerLat).asBool\n84: \n85:       val fuVldVec = (fu.io.in.valid &&
      latN) +: Seq.fill(latReal)(RegInit(false.B))\n86:       val fuRdyVec = Seq.fill(latReal)(Wire(Bool()))
      :+ fu.io.out.ready\n87: \n88:       for (i <- 0 until latReal) {\n89:      \
      \   fuRdyVec(i) := !fuVldVec(i + 1) || fuRdyVec(i + 1)\n90:       }\n91: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 97-117
    context: "97:         }\n98:       }\n99:       fuVld_en := fuVldVec.map(v =>
      v).reduce(_ || _)\n100:       fuVld_en_reg := fuVld_en\n101: \n102:       when(uncerLat.asBool
      && fu.io.in.fire) {\n103:         uncer_en_reg := true.B\n104:       }.elsewhen(uncerLat.asBool
      && fu.io.out.fire) {\n105:         uncer_en_reg := false.B\n106:       }\n107:\
      \ \n108:       when(lat0 && fu.io.in.fire) {\n109:         clk_en := true.B\n\
      110:       }.elsewhen(latN && fuVld_en || fuVld_en_reg) {\n111:         clk_en
      := true.B\n112:       }.elsewhen(uncerLat.asBool && fu.io.in.fire || uncer_en_reg)
      {\n113:         clk_en := true.B\n114:       }\n115: \n116:       if (cfg.ckAlwaysEn)
      {\n117:         clk_en := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 127-144
    context: "127:   val busy = RegInit(false.B)\n128:   if (exuParams.latencyCertain){\n\
      129:     busy := false.B\n130:   }\n131:   else {\n132:     val robIdx = RegEnable(io.in.bits.robIdx,
      io.in.fire)\n133:     when(io.in.fire && io.in.bits.robIdx.needFlush(io.flush))
      {\n134:       busy := false.B\n135:     }.elsewhen(busy && robIdx.needFlush(io.flush))
      {\n136:       busy := false.B\n137:     }.elsewhen(io.out.fire) {\n138:    \
      \   busy := false.B\n139:     }.elsewhen(io.in.fire) {\n140:       busy := true.B\n\
      141:     }\n142:   }\n143: \n144:   exuParams.wbPortConfigs.map{"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 205-219
    context: "205:         }\n206:       )\n207:     )\n208:   }\n209:   if(backendParams.debugEn)
      {\n210:     dontTouch(io.out.ready)\n211:   }\n212:   // rob flush --> funcUnits\n\
      213:   funcUnits.zipWithIndex.foreach { case (fu, i) =>\n214:     fu.io.flush
      <> io.flush\n215:   }\n216: \n217:   def acceptCond(input: ExuInput): Seq[Bool]
      = {\n218:     input.params.fuConfigs.map(_.fuSel(input))\n219:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 221-240
    context: "221:   val in1ToN = Module(new Dispatcher(new ExuInput(exuParams), funcUnits.length,
      acceptCond))\n222: \n223:   // ExeUnit.in <---> Dispatcher.in\n224:   in1ToN.io.in.valid
      := io.in.valid && !busy\n225:   in1ToN.io.in.bits := io.in.bits\n226:   io.in.ready
      := !busy && in1ToN.io.in.ready\n227: \n228:   def pipelineReg(init: ExuInput,
      valid: Bool, latency: Int, flush: ValidIO[Redirect]): (Seq[ExuInput], Seq[Bool])
      = {\n229:     val validVec = valid +: Seq.fill(latency)(RegInit(false.B))\n\
      230:     val inVec = init +: Seq.fill(latency)(Reg(new ExuInput(exuParams)))\n\
      231:     val robIdxVec = inVec.map(_.robIdx)\n232:     // if flush(0), valid
      0 will not given, so set flushVec(0) to false.B\n233:     val flushVec = validVec.zip(robIdxVec).map(x
      => x._1 && x._2.needFlush(flush))\n234:     for (i <- 1 to latency) {\n235:\
      \       validVec(i) := validVec(i - 1) && !flushVec(i - 1)\n236:       inVec(i)
      := inVec(i - 1)\n237:     }\n238:     (inVec, validVec)\n239:   }\n240:   val
      latencyMax = fuCfgs.map(_.latency.latencyVal.getOrElse(0)).max"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 236-273
    context: "236:       inVec(i) := inVec(i - 1)\n237:     }\n238:     (inVec, validVec)\n\
      239:   }\n240:   val latencyMax = fuCfgs.map(_.latency.latencyVal.getOrElse(0)).max\n\
      241:   val inPipe = pipelineReg(io.in.bits, io.in.valid, latencyMax, io.flush)\n\
      242:   // Dispatcher.out <---> FunctionUnits\n243:   in1ToN.io.out.zip(funcUnits.map(_.io.in)).foreach
      {\n244:     case (source: DecoupledIO[ExuInput], sink: DecoupledIO[FuncUnitInput])
      =>\n245:       sink.valid := source.valid\n246:       source.ready := sink.ready\n\
      247: \n248:       sink.bits.data.pc          .foreach(x => x := source.bits.pc.get)\n\
      249:       sink.bits.data.nextPcOffset.foreach(x => x := source.bits.nextPcOffset.get)\n\
      250:       sink.bits.data.imm         := source.bits.imm\n251:       sink.bits.ctrl.fuOpType\
      \    := source.bits.fuOpType\n252:       sink.bits.ctrl.robIdx      := source.bits.robIdx\n\
      253:       sink.bits.ctrl.pdest       := source.bits.pdest\n254:       sink.bits.ctrl.rfWen\
      \       .foreach(x => x := source.bits.rfWen.get)\n255:       sink.bits.ctrl.fpWen\
      \       .foreach(x => x := source.bits.fpWen.get)\n256:       sink.bits.ctrl.vecWen\
      \      .foreach(x => x := source.bits.vecWen.get)\n257:       sink.bits.ctrl.v0Wen\
      \       .foreach(x => x := source.bits.v0Wen.get)\n258:       sink.bits.ctrl.vlWen\
      \       .foreach(x => x := source.bits.vlWen.get)\n259:       sink.bits.ctrl.flushPipe\
      \   .foreach(x => x := source.bits.flushPipe.get)\n260:       sink.bits.ctrl.preDecode\
      \   .foreach(x => x := source.bits.preDecode.get)\n261:       sink.bits.ctrl.ftqIdx\
      \      .foreach(x => x := source.bits.ftqIdx.get)\n262:       sink.bits.ctrl.ftqOffset\
      \   .foreach(x => x := source.bits.ftqOffset.get)\n263:       sink.bits.ctrl.predictInfo
      .foreach(x => x := source.bits.predictInfo.get)\n264:       sink.bits.ctrl.fpu\
      \         .foreach(x => x := source.bits.fpu.get)\n265:       sink.bits.ctrl.vpu\
      \         .foreach(x => x := source.bits.vpu.get)\n266:       sink.bits.ctrl.vpu\
      \         .foreach(x => x.fpu.isFpToVecInst := 0.U)\n267:       sink.bits.ctrl.vpu\
      \         .foreach(x => x.fpu.isFP32Instr   := 0.U)\n268:       sink.bits.ctrl.vpu\
      \         .foreach(x => x.fpu.isFP64Instr   := 0.U)\n269:       sink.bits.perfDebugInfo\
      \    := source.bits.perfDebugInfo\n270:       sink.bits.debug_seqNum     :=
      source.bits.debug_seqNum\n271:   }\n272:   funcUnits.filter(_.cfg.latency.latencyVal.nonEmpty).map{
      fu =>\n273:     val latency = fu.cfg.latency.latencyVal.getOrElse(0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 276-305
    context: "276:       val source = inPipe._1(i)\n277:       fu.io.in.bits.validPipe.get(i)
      := inPipe._2(i)\n278:       sink.fuOpType := source.fuOpType\n279:       sink.robIdx
      := source.robIdx\n280:       sink.pdest := source.pdest\n281:       sink.rfWen.foreach(x
      => x := source.rfWen.get)\n282:       sink.fpWen.foreach(x => x := source.fpWen.get)\n\
      283:       sink.vecWen.foreach(x => x := source.vecWen.get)\n284:       sink.v0Wen.foreach(x
      => x := source.v0Wen.get)\n285:       sink.vlWen.foreach(x => x := source.vlWen.get)\n\
      286:       sink.flushPipe.foreach(x => x := source.flushPipe.get)\n287:    \
      \   sink.preDecode.foreach(x => x := source.preDecode.get)\n288:       sink.ftqIdx.foreach(x
      => x := source.ftqIdx.get)\n289:       sink.ftqOffset.foreach(x => x := source.ftqOffset.get)\n\
      290:       sink.predictInfo.foreach(x => x := source.predictInfo.get)\n291:\
      \       sink.fpu.foreach(x => x := source.fpu.get)\n292:       sink.vpu.foreach(x
      => x := source.vpu.get)\n293:       sink.vpu.foreach(x => x.fpu.isFpToVecInst
      := 0.U)\n294:       sink.vpu.foreach(x => x.fpu.isFP32Instr := 0.U)\n295:  \
      \     sink.vpu.foreach(x => x.fpu.isFP64Instr := 0.U)\n296:       val sinkData
      = fu.io.in.bits.dataPipe.get(i)\n297:       val sourceData = inPipe._1(i)\n\
      298:       sinkData.src.zip(sourceData.src).foreach { case (fuSrc, exuSrc) =>
      fuSrc := exuSrc }\n299:       sinkData.pc.foreach(x => x := sourceData.pc.get)\n\
      300:       sinkData.nextPcOffset.foreach(x => x := sourceData.nextPcOffset.get)\n\
      301:       sinkData.imm := sourceData.imm\n302:     }\n303:   }\n304: \n305:\
      \   funcUnits.zip(exuParams.idxCopySrc).map{ case(fu, idx) =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 301-313
    context: "301:       sinkData.imm := sourceData.imm\n302:     }\n303:   }\n304:\
      \ \n305:   funcUnits.zip(exuParams.idxCopySrc).map{ case(fu, idx) =>\n306: \
      \    (fu.io.in.bits.data.src).zip(io.in.bits.src).foreach { case(fuSrc, exuSrc)
      => fuSrc := exuSrc }\n307:     if(fu.cfg.srcNeedCopy) {\n308:       (fu.io.in.bits.data.src).zip(io.in.bits.copySrc.get(idx)).foreach
      { case(fuSrc, copySrc) => fuSrc := copySrc }\n309:     }\n310:   }\n311: \n\
      312:   private val OutresVecs = funcUnits.map { fu =>\n313:     def latDiff
      :Int = fu.cfg.latency.extraLatencyVal.getOrElse(0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 315-325
    context: "315:     for (i <- 1 to latDiff) {\n316:       OutresVec(i) := OutresVec(i
      - 1)\n317:     }\n318:     OutresVec\n319:   }\n320:   OutresVecs.foreach(vec
      => vec.foreach(res =>dontTouch(res)))\n321: \n322:   private val fuOutValidOH
      = funcUnits.map(_.io.out.valid)\n323:   XSError(PopCount(fuOutValidOH) > 1.U,
      p\"fuOutValidOH ${Binary(VecInit(fuOutValidOH).asUInt)} should be one-hot)\\\
      n\")\n324:   private val fuOutBitsVec = funcUnits.map(_.io.out.bits)\n325: \
      \  private val fuOutresVec = OutresVecs.map(_.last)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 321-331
    context: "321: \n322:   private val fuOutValidOH = funcUnits.map(_.io.out.valid)\n\
      323:   XSError(PopCount(fuOutValidOH) > 1.U, p\"fuOutValidOH ${Binary(VecInit(fuOutValidOH).asUInt)}
      should be one-hot)\\n\")\n324:   private val fuOutBitsVec = funcUnits.map(_.io.out.bits)\n\
      325:   private val fuOutresVec = OutresVecs.map(_.last)\n326:   private val
      fuRedirectVec: Seq[Option[ValidIO[Redirect]]] = fuOutresVec.map(_.redirect)\n\
      327: \n328:   // Assume that one fu can only write int or fp or vec,\n329: \
      \  // otherwise, wenVec should be assigned to wen in fu.\n330:   private val
      fuIntWenVec = funcUnits.map(x => x.cfg.needIntWen.B && x.io.out.bits.ctrl.rfWen.getOrElse(false.B))\n\
      331:   private val fuFpWenVec  = funcUnits.map( x => x.cfg.needFpWen.B  && x.io.out.bits.ctrl.fpWen.getOrElse(false.B))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 363-373
    context: "363: \n364:   val criticalErrors = funcUnits.filter(fu => fu.cfg.needCriticalErrors).flatMap(fu
      => fu.getCriticalErrors)\n365:   generateCriticalErrors()\n366: \n367:   io.out.valid
      := Cat(fuOutValidOH).orR\n368:   funcUnits.foreach(fu => fu.io.out.ready :=
      io.out.ready)\n369: \n370:   // select one fu's result\n371:   io.out.bits.data
      := VecInit(outDataVec.zip(outDataValidOH).map{ case(data, validOH) => Mux1H(validOH,
      data)})\n372:   io.out.bits.robIdx := Mux1H(fuOutValidOH, fuOutBitsVec.map(_.ctrl.robIdx))\n\
      373:   io.out.bits.pdest := Mux1H(fuOutValidOH, fuOutBitsVec.map(_.ctrl.pdest))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 369-393
    context: "369: \n370:   // select one fu's result\n371:   io.out.bits.data :=
      VecInit(outDataVec.zip(outDataValidOH).map{ case(data, validOH) => Mux1H(validOH,
      data)})\n372:   io.out.bits.robIdx := Mux1H(fuOutValidOH, fuOutBitsVec.map(_.ctrl.robIdx))\n\
      373:   io.out.bits.pdest := Mux1H(fuOutValidOH, fuOutBitsVec.map(_.ctrl.pdest))\n\
      374:   io.out.bits.intWen.foreach(x => x := Mux1H(fuOutValidOH, fuIntWenVec))\n\
      375:   io.out.bits.fpWen.foreach(x => x := Mux1H(fuOutValidOH, fuFpWenVec))\n\
      376:   io.out.bits.vecWen.foreach(x => x := Mux1H(fuOutValidOH, fuVecWenVec))\n\
      377:   io.out.bits.v0Wen.foreach(x => x := Mux1H(fuOutValidOH, fuV0WenVec))\n\
      378:   io.out.bits.vlWen.foreach(x => x := Mux1H(fuOutValidOH, fuVlWenVec))\n\
      379:   io.out.bits.redirect.foreach(x => x := Mux1H((fuOutValidOH zip fuRedirectVec).filter(_._2.isDefined).map(x
      => (x._1, x._2.get))))\n380:   io.out.bits.fflags.foreach(x => x := Mux1H(fuOutValidOH,
      fuOutresVec.map(_.fflags.getOrElse(0.U.asTypeOf(io.out.bits.fflags.get)))))\n\
      381:   io.out.bits.wflags.foreach(x => x := Mux1H(fuOutValidOH, fuOutBitsVec.map(_.ctrl.fpu.getOrElse(0.U.asTypeOf(new
      FPUCtrlSignals)).wflags)))\n382:   io.out.bits.vxsat.foreach(x => x := Mux1H(fuOutValidOH,
      fuOutresVec.map(_.vxsat.getOrElse(0.U.asTypeOf(io.out.bits.vxsat.get)))))\n\
      383:   io.out.bits.exceptionVec.foreach(x => x := Mux1H(fuOutValidOH, fuOutBitsVec.map(_.ctrl.exceptionVec.getOrElse(0.U.asTypeOf(io.out.bits.exceptionVec.get)))))\n\
      384:   io.out.bits.flushPipe.foreach(x => x := Mux1H(fuOutValidOH, fuOutBitsVec.map(_.ctrl.flushPipe.getOrElse(0.U.asTypeOf(io.out.bits.flushPipe.get)))))\n\
      385:   io.out.bits.replay.foreach(x => x := Mux1H(fuOutValidOH, fuOutBitsVec.map(_.ctrl.replay.getOrElse(0.U.asTypeOf(io.out.bits.replay.get)))))\n\
      386:   io.out.bits.predecodeInfo.foreach(x => x := Mux1H(fuOutValidOH, fuOutBitsVec.map(_.ctrl.preDecode.getOrElse(0.U.asTypeOf(io.out.bits.predecodeInfo.get)))))\n\
      387: \n388:   io.csrio.foreach(exuio => funcUnits.foreach(fu => fu.io.csrio.foreach{\n\
      389:     fuio =>\n390:       exuio <> fuio\n391:       fuio.exception := DelayN(exuio.exception,
      2)\n392:       fuio.robDeqPtr := DelayN(exuio.robDeqPtr, 2)\n393:   }))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 389-409
    context: "389:     fuio =>\n390:       exuio <> fuio\n391:       fuio.exception
      := DelayN(exuio.exception, 2)\n392:       fuio.robDeqPtr := DelayN(exuio.robDeqPtr,
      2)\n393:   }))\n394:   io.csrin.foreach(exuio => funcUnits.foreach(fu => fu.io.csrin.foreach{fuio
      => fuio := exuio}))\n395:   io.csrToDecode.foreach(toDecode => funcUnits.foreach(fu
      => fu.io.csrToDecode.foreach(fuOut => toDecode := fuOut)))\n396: \n397:   io.vtype.foreach(exuio
      => funcUnits.foreach(fu => fu.io.vtype.foreach(fuio => exuio := fuio)))\n398:\
      \   io.fenceio.foreach(exuio => funcUnits.foreach(fu => fu.io.fenceio.foreach(fuio
      => fuio <> exuio)))\n399:   io.frm.foreach(exuio => funcUnits.foreach(fu =>
      fu.io.frm.foreach(fuio => fuio <> exuio)))\n400:   io.vxrm.foreach(exuio =>
      funcUnits.foreach(fu => fu.io.vxrm.foreach(fuio => fuio <> exuio)))\n401:  \
      \ io.vlIsZero.foreach(exuio => funcUnits.foreach(fu => fu.io.vlIsZero.foreach(fuio
      => exuio := fuio)))\n402:   io.vlIsVlmax.foreach(exuio => funcUnits.foreach(fu
      => fu.io.vlIsVlmax.foreach(fuio => exuio := fuio)))\n403:   // RegNext for better
      timing and it should be fine\n404:   io.instrAddrTransType.foreach(exuio =>
      funcUnits.foreach(fu => fu.io.instrAddrTransType.foreach(fuio => fuio := RegNext(exuio))))\n\
      405: \n406:   // debug info\n407:   io.out.bits.debug     := 0.U.asTypeOf(io.out.bits.debug)\n\
      408:   io.out.bits.debug.isPerfCnt := funcUnits.map(_.io.csrio.map(_.isPerfCnt)).map(_.getOrElse(false.B)).reduce(_
      || _)\n409:   io.out.bits.debugInfo := Mux1H(fuOutValidOH, fuOutBitsVec.map(_.perfDebugInfo))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 425-444
    context: "425:   private val acceptVec: Vec[Bool] = VecInit(acceptCond(io.in.bits))\n\
      426: \n427:   XSError(io.in.valid && PopCount(acceptVec) > 1.U, p\"[ExeUnit]
      accept vec should no more than 1, ${Binary(acceptVec.asUInt)} \")\n428:   XSError(io.in.valid
      && PopCount(acceptVec) === 0.U, \"[ExeUnit] there is a inst not dispatched to
      any fu\")\n429: \n430:   io.out.zipWithIndex.foreach { case (out, i) =>\n431:\
      \     out.valid := acceptVec(i) && io.in.valid\n432:     out.bits := io.in.bits\n\
      433:   }\n434: \n435:   io.in.ready := Cat(io.out.map(_.ready)).andR\n436: }\n\
      437: \n438: class MemExeUnitIO (implicit p: Parameters) extends XSBundle {\n\
      439:   val flush = Flipped(ValidIO(new Redirect()))\n440:   val in = Flipped(DecoupledIO(new
      MemExuInput()))\n441:   val out = DecoupledIO(new MemExuOutput())\n442: }\n\
      443: \n444: class MemExeUnit(exuParams: ExeUnitParams)(implicit p: Parameters)
      extends XSModule {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 441-454
    context: "441:   val out = DecoupledIO(new MemExuOutput())\n442: }\n443: \n444:
      class MemExeUnit(exuParams: ExeUnitParams)(implicit p: Parameters) extends XSModule
      {\n445:   val io = IO(new MemExeUnitIO)\n446:   val fu = exuParams.fuConfigs.head.fuGen(p,
      exuParams.fuConfigs.head)\n447:   fu.io.flush             := io.flush\n448:\
      \   fu.io.in.valid          := io.in.valid\n449:   io.in.ready             :=
      fu.io.in.ready\n450: \n451:   fu.io.in.bits.ctrl.robIdx    := io.in.bits.uop.robIdx\n\
      452:   fu.io.in.bits.ctrl.pdest     := io.in.bits.uop.pdest\n453:   fu.io.in.bits.ctrl.fuOpType\
      \  := io.in.bits.uop.fuOpType\n454:   fu.io.in.bits.data.imm       := io.in.bits.uop.imm"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 450-465
    context: "450: \n451:   fu.io.in.bits.ctrl.robIdx    := io.in.bits.uop.robIdx\n\
      452:   fu.io.in.bits.ctrl.pdest     := io.in.bits.uop.pdest\n453:   fu.io.in.bits.ctrl.fuOpType\
      \  := io.in.bits.uop.fuOpType\n454:   fu.io.in.bits.data.imm       := io.in.bits.uop.imm\n\
      455:   fu.io.in.bits.data.src.zip(io.in.bits.src).foreach(x => x._1 := x._2)\n\
      456:   fu.io.in.bits.perfDebugInfo := io.in.bits.uop.debugInfo\n457:   fu.io.in.bits.debug_seqNum
      := io.in.bits.uop.debug_seqNum\n458: \n459:   io.out.valid            := fu.io.out.valid\n\
      460:   fu.io.out.ready         := io.out.ready\n461: \n462:   io.out.bits  \
      \           := 0.U.asTypeOf(io.out.bits) // dontCare other fields\n463:   io.out.bits.data\
      \        := fu.io.out.bits.res.data\n464:   io.out.bits.uop.robIdx  := fu.io.out.bits.ctrl.robIdx\n\
      465:   io.out.bits.uop.pdest   := fu.io.out.bits.ctrl.pdest"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExuBlock.scala
    lines: 5-15
    context: "5: import chisel3.util._\n6: import freechips.rocketchip.diplomacy.{LazyModule,
      LazyModuleImp}\n7: import xiangshan.backend.fu.{CSRFileIO, FenceIO}\n8: import
      xiangshan.backend.Bundles._\n9: import xiangshan.backend.issue.SchdBlockParams\n\
      10: import xiangshan.{HasXSParameter, Redirect, XSBundle}\n11: import utility._\n\
      12: import xiangshan.backend.fu.FuConfig.{AluCfg, BrhCfg}\n13: import xiangshan.backend.fu.vector.Bundles.{VType,
      Vxrm}\n14: import xiangshan.backend.fu.fpu.Bundles.Frm\n15: import xiangshan.backend.fu.wrapper.{CSRInput,
      CSRToDecode}"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExuBlock.scala
    lines: 33-68
    context: "33:   private val exus = wrapper.exus.map(_.module)\n34: \n35:   private
      val ins: collection.IndexedSeq[DecoupledIO[ExuInput]] = io.in.flatten\n36: \
      \  private val outs: collection.IndexedSeq[DecoupledIO[ExuOutput]] = io.out.flatten\n\
      37: \n38:   (ins zip exus zip outs).foreach { case ((input, exu), output) =>\n\
      39:     exu.io.flush <> io.flush\n40:     exu.io.csrio.foreach(exuio => io.csrio.get
      <> exuio)\n41:     exu.io.csrin.foreach(exuio => io.csrin.get <> exuio)\n42:\
      \     exu.io.fenceio.foreach(exuio => io.fenceio.get <> exuio)\n43:     exu.io.frm.foreach(exuio
      => exuio := RegNext(io.frm.get))  // each vf exu pipe frm from csr\n44:    \
      \ exu.io.vxrm.foreach(exuio => io.vxrm.get <> exuio)\n45:     exu.io.vlIsZero.foreach(exuio
      => io.vlIsZero.get := exuio)\n46:     exu.io.vlIsVlmax.foreach(exuio => io.vlIsVlmax.get
      := exuio)\n47:     exu.io.vtype.foreach(exuio => io.vtype.get := exuio)\n48:\
      \     exu.io.in <> input\n49:     output <> exu.io.out\n50:     io.csrToDecode.foreach(toDecode
      => exu.io.csrToDecode.foreach(exuOut => toDecode := exuOut))\n51: //    if (exu.wrapper.exuParams.fuConfigs.contains(AluCfg)
      || exu.wrapper.exuParams.fuConfigs.contains(BrhCfg)){\n52: //      XSPerfAccumulate(s\"\
      ${(exu.wrapper.exuParams.name)}_fire_cnt\", PopCount(exu.io.in.fire))\n53: //\
      \    }\n54:     XSPerfAccumulate(s\"${(exu.wrapper.exuParams.name)}_fire_cnt\"\
      , PopCount(exu.io.in.fire))\n55:   }\n56:   exus.find(_.io.csrio.nonEmpty).map(_.io.csrio.get).foreach
      { csrio =>\n57:     exus.map(_.io.instrAddrTransType.foreach(_ := csrio.instrAddrTransType))\n\
      58:   }\n59:   val aluFireSeq = exus.filter(_.wrapper.exuParams.fuConfigs.contains(AluCfg)).map(_.io.in.fire)\n\
      60:   for (i <- 0 until (aluFireSeq.size + 1)){\n61:     XSPerfAccumulate(s\"\
      alu_fire_${i}_cnt\", PopCount(aluFireSeq) === i.U)\n62:   }\n63:   val brhFireSeq
      = exus.filter(_.wrapper.exuParams.fuConfigs.contains(BrhCfg)).map(_.io.in.fire)\n\
      64:   for (i <- 0 until (brhFireSeq.size + 1)) {\n65:     XSPerfAccumulate(s\"\
      brh_fire_${i}_cnt\", PopCount(brhFireSeq) === i.U)\n66:   }\n67:   val criticalErrors
      = exus.filter(_.wrapper.exuParams.needCriticalErrors).flatMap(exu => exu.getCriticalErrors)\n\
      68:   generateCriticalErrors()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExuBlock.scala
    lines: 67-81
    context: "67:   val criticalErrors = exus.filter(_.wrapper.exuParams.needCriticalErrors).flatMap(exu
      => exu.getCriticalErrors)\n68:   generateCriticalErrors()\n69: }\n70: \n71:
      class ExuBlockIO(implicit p: Parameters, params: SchdBlockParams) extends XSBundle
      {\n72:   val flush = Flipped(ValidIO(new Redirect))\n73:   // in(i)(j): issueblock(i),
      exu(j)\n74:   val in: MixedVec[MixedVec[DecoupledIO[ExuInput]]] = Flipped(params.genExuInputCopySrcBundle)\n\
      75:   // out(i)(j): issueblock(i), exu(j).\n76:   val out: MixedVec[MixedVec[DecoupledIO[ExuOutput]]]
      = params.genExuOutputDecoupledBundle\n77: \n78:   val csrio = Option.when(params.hasCSR)(new
      CSRFileIO)\n79:   val csrin = Option.when(params.hasCSR)(new CSRInput)\n80:\
      \   val csrToDecode = Option.when(params.hasCSR)(Output(new CSRToDecode))\n\
      81: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnitParams.scala
    lines: 61-78
    context: "61:   val needOg2: Boolean = fuConfigs.map(_.needOg2).reduce(_ || _)\n\
      62:   val writeVfRf: Boolean = writeVecRf\n63:   val writeFflags: Boolean =
      fuConfigs.map(_.writeFflags).reduce(_ || _)\n64:   val writeVxsat: Boolean =
      fuConfigs.map(_.writeVxsat).reduce(_ || _)\n65:   val hasNoDataWB: Boolean =
      fuConfigs.map(_.hasNoDataWB).reduce(_ && _)\n66:   val hasRedirect: Boolean
      = fuConfigs.map(_.hasRedirect).reduce(_ || _)\n67:   val hasPredecode: Boolean
      = fuConfigs.map(_.hasPredecode).reduce(_ || _)\n68:   val exceptionOut: Seq[Int]
      = fuConfigs.map(_.exceptionOut).reduce(_ ++ _).distinct.sorted\n69:   val hasLoadError:
      Boolean = fuConfigs.map(_.hasLoadError).reduce(_ || _)\n70:   val flushPipe:
      Boolean = fuConfigs.map(_.flushPipe).reduce(_ || _)\n71:   val replayInst: Boolean
      = fuConfigs.map(_.replayInst).reduce(_ || _)\n72:   val trigger: Boolean = fuConfigs.map(_.trigger).reduce(_
      || _)\n73:   val needExceptionGen: Boolean = exceptionOut.nonEmpty || flushPipe
      || replayInst || trigger\n74:   val needPc: Boolean = fuConfigs.map(_.needPc).reduce(_
      || _)\n75:   val needTarget: Boolean = fuConfigs.map(_.needTargetPc).reduce(_
      || _)\n76:   val needPdInfo: Boolean = fuConfigs.map(_.needPdInfo).reduce(_
      || _)\n77:   val needSrcFrm: Boolean = fuConfigs.map(_.needSrcFrm).reduce(_
      || _)\n78:   val needSrcVxrm: Boolean = fuConfigs.map(_.needSrcVxrm).reduce(_
      || _)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnitParams.scala
    lines: 120-130
    context: "120:   val wbIndex: Seq[Int] = Seq(wbIntIndex, wbFpIndex, wbVecIndex,
      wbV0Index, wbVlIndex)\n121: \n122: \n123:   def copyNum: Int = {\n124:     val
      setIQ = mutable.Set[IssueBlockParams]()\n125:     iqWakeUpSourcePairs.map(_.sink).foreach{
      wakeupSink =>\n126:       backendParam.allIssueParams.map{ issueParams =>\n\
      127:         if (issueParams.exuBlockParams.contains(wakeupSink.getExuParam(backendParam.allExuParams)))
      {\n128:           setIQ.add(issueParams)\n129:         }\n130:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnitParams.scala
    lines: 248-258
    context: "248:   /**\n249:     * Check if this exu has fixed latency\n250:   \
      \  */\n251:   def isFixedLatency: Boolean = {\n252:     if (latencyCertain)\n\
      253:       return fuConfigs.map(x => x.latency.latencyVal.get == fuConfigs.head.latency.latencyVal.get).reduce(_
      && _)\n254:     false\n255:   }\n256: \n257:   def hasCSR: Boolean = fuConfigs.map(_.isCsr).reduce(_
      || _)\n258: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 33-43
    context: "33: import utility.sram.SramBroadcastBundle\n34: import xiangshan._\n\
      35: import xiangshan.backend.Bundles.{DynInst, IssueQueueIQWakeUpBundle, LoadShouldCancel,
      MemExuInput, MemExuOutput, VPUCtrlSignals}\n36: import xiangshan.backend.ctrlblock.{DebugLSIO,
      LsTopdownInfo}\n37: import xiangshan.backend.datapath.DataConfig.{IntData, VecData,
      FpData}\n38: import xiangshan.backend.datapath.RdConfig.{IntRD, VfRD}\n39: import
      xiangshan.backend.datapath.WbConfig._\n40: import xiangshan.backend.datapath.DataConfig._\n\
      41: import xiangshan.backend.datapath._\n42: import xiangshan.backend.dispatch.CoreDispatchTopDownIO\n\
      43: import xiangshan.backend.exu.ExuBlock"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 46-56
    context: "46: import xiangshan.backend.fu.NewCSR.PFEvent\n47: import xiangshan.backend.issue.EntryBundles._\n\
      48: import xiangshan.backend.issue.{Scheduler, SchedulerArithImp, SchedulerImpBase,
      SchedulerMemImp}\n49: import xiangshan.backend.rob.{RobCoreTopDownIO, RobDebugRollingIO,
      RobLsqIO, RobPtr}\n50: import xiangshan.backend.trace.TraceCoreInterface\n51:
      import xiangshan.frontend.{FtqPtr, FtqRead, PreDecodeInfo}\n52: import xiangshan.mem.{LqPtr,
      LsqEnqIO, SqPtr}\n53: \n54: import scala.collection.mutable\n55: \n56: class
      Backend(val params: BackendParams)(implicit p: Parameters) extends LazyModule"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 237-248
    context: "237:   wbFuBusyTable.io.in.intSchdBusyTable := intScheduler.io.wbFuBusyTable\n\
      238:   wbFuBusyTable.io.in.fpSchdBusyTable := fpScheduler.io.wbFuBusyTable\n\
      239:   wbFuBusyTable.io.in.vfSchdBusyTable := vfScheduler.io.wbFuBusyTable\n\
      240:   wbFuBusyTable.io.in.memSchdBusyTable := memScheduler.io.wbFuBusyTable\n\
      241:   intScheduler.io.fromWbFuBusyTable.fuBusyTableRead := wbFuBusyTable.io.out.intRespRead\n\
      242:   fpScheduler.io.fromWbFuBusyTable.fuBusyTableRead := wbFuBusyTable.io.out.fpRespRead\n\
      243:   vfScheduler.io.fromWbFuBusyTable.fuBusyTableRead := wbFuBusyTable.io.out.vfRespRead\n\
      244:   memScheduler.io.fromWbFuBusyTable.fuBusyTableRead := wbFuBusyTable.io.out.memRespRead\n\
      245:   dataPath.io.wbConfictRead := wbFuBusyTable.io.out.wbConflictRead\n246:\
      \ \n247:   private val og1Cancel = dataPath.io.og1Cancel\n248:   private val
      og0Cancel = dataPath.io.og0Cancel"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 354-364
    context: "354:     sink.wen := RegNext(source.wen)\n355:     sink.vlWen := RegNext(source.vlWen)\n\
      356:     sink.addr := RegEnable(source.addr, source.wen)\n357:   }\n358:   intScheduler.io.fromTop.hartId
      := io.fromTop.hartId\n359:   intScheduler.io.fromCtrlBlock.flush := ctrlBlock.io.toIssueBlock.flush\n\
      360:   intScheduler.io.fromDispatch.uops <> ctrlBlock.io.toIssueBlock.intUops\n\
      361:   intScheduler.io.intWriteBack := wbDataPath.io.toIntPreg\n362:   intScheduler.io.fpWriteBack
      := 0.U.asTypeOf(intScheduler.io.fpWriteBack)\n363:   intScheduler.io.vfWriteBack
      := 0.U.asTypeOf(intScheduler.io.vfWriteBack)\n364:   intScheduler.io.v0WriteBack
      := 0.U.asTypeOf(intScheduler.io.v0WriteBack)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 367-378
    context: "367:   intScheduler.io.fpWriteBackDelayed := 0.U.asTypeOf(intScheduler.io.fpWriteBackDelayed)\n\
      368:   intScheduler.io.vfWriteBackDelayed := 0.U.asTypeOf(intScheduler.io.vfWriteBackDelayed)\n\
      369:   intScheduler.io.v0WriteBackDelayed := 0.U.asTypeOf(intScheduler.io.v0WriteBackDelayed)\n\
      370:   intScheduler.io.vlWriteBackDelayed := 0.U.asTypeOf(intScheduler.io.vlWriteBackDelayed)\n\
      371:   intScheduler.io.fromDataPath.resp := dataPath.io.toIntIQ\n372:   intScheduler.io.fromSchedulers.wakeupVec.foreach
      { wakeup => wakeup := iqWakeUpMappedBundle(wakeup.bits.exuIdx) }\n373:   intScheduler.io.fromSchedulers.wakeupVecDelayed.foreach
      { wakeup => wakeup := iqWakeUpMappedBundleDelayed(wakeup.bits.exuIdx) }\n374:\
      \   intScheduler.io.fromDataPath.og0Cancel := og0Cancel\n375:   intScheduler.io.fromDataPath.og1Cancel
      := og1Cancel\n376:   intScheduler.io.ldCancel := io.mem.ldCancel\n377:   intScheduler.io.fromDataPath.replaceRCIdx.get
      := dataPath.io.toWakeupQueueRCIdx.take(params.getIntExuRCWriteSize)\n378:  \
      \ intScheduler.io.vlWriteBackInfo.vlFromIntIsZero := false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 379-389
    context: "379:   intScheduler.io.vlWriteBackInfo.vlFromIntIsVlmax := false.B\n\
      380:   intScheduler.io.vlWriteBackInfo.vlFromVfIsZero := false.B\n381:   intScheduler.io.vlWriteBackInfo.vlFromVfIsVlmax
      := false.B\n382: \n383:   fpScheduler.io.fromTop.hartId := io.fromTop.hartId\n\
      384:   fpScheduler.io.fromCtrlBlock.flush := ctrlBlock.io.toIssueBlock.flush\n\
      385:   fpScheduler.io.fromDispatch.uops <> ctrlBlock.io.toIssueBlock.fpUops\n\
      386:   fpScheduler.io.intWriteBack := 0.U.asTypeOf(fpScheduler.io.intWriteBack)\n\
      387:   fpScheduler.io.fpWriteBack := wbDataPath.io.toFpPreg\n388:   fpScheduler.io.vfWriteBack
      := 0.U.asTypeOf(fpScheduler.io.vfWriteBack)\n389:   fpScheduler.io.v0WriteBack
      := 0.U.asTypeOf(fpScheduler.io.v0WriteBack)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 392-403
    context: "392:   fpScheduler.io.fpWriteBackDelayed := fpWriteBackDelayed\n393:\
      \   fpScheduler.io.vfWriteBackDelayed := 0.U.asTypeOf(intScheduler.io.vfWriteBackDelayed)\n\
      394:   fpScheduler.io.v0WriteBackDelayed := 0.U.asTypeOf(intScheduler.io.v0WriteBackDelayed)\n\
      395:   fpScheduler.io.vlWriteBackDelayed := 0.U.asTypeOf(intScheduler.io.vlWriteBackDelayed)\n\
      396:   fpScheduler.io.fromDataPath.resp := dataPath.io.toFpIQ\n397:   fpScheduler.io.fromSchedulers.wakeupVec.foreach
      { wakeup => wakeup := iqWakeUpMappedBundle(wakeup.bits.exuIdx) }\n398:   fpScheduler.io.fromSchedulers.wakeupVecDelayed.foreach
      { wakeup => wakeup := iqWakeUpMappedBundleDelayed(wakeup.bits.exuIdx) }\n399:\
      \   fpScheduler.io.fromDataPath.og0Cancel := og0Cancel\n400:   fpScheduler.io.fromDataPath.og1Cancel
      := og1Cancel\n401:   fpScheduler.io.ldCancel := io.mem.ldCancel\n402:   fpScheduler.io.vlWriteBackInfo.vlFromIntIsZero
      := false.B\n403:   fpScheduler.io.vlWriteBackInfo.vlFromIntIsVlmax := false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 403-413
    context: "403:   fpScheduler.io.vlWriteBackInfo.vlFromIntIsVlmax := false.B\n\
      404:   fpScheduler.io.vlWriteBackInfo.vlFromVfIsZero := false.B\n405:   fpScheduler.io.vlWriteBackInfo.vlFromVfIsVlmax
      := false.B\n406: \n407:   memScheduler.io.fromTop.hartId := io.fromTop.hartId\n\
      408:   memScheduler.io.fromCtrlBlock.flush := ctrlBlock.io.toIssueBlock.flush\n\
      409:   memScheduler.io.fromDispatch.uops <> ctrlBlock.io.toIssueBlock.memUops\n\
      410:   memScheduler.io.intWriteBack := wbDataPath.io.toIntPreg\n411:   memScheduler.io.fpWriteBack
      := wbDataPath.io.toFpPreg\n412:   memScheduler.io.vfWriteBack := wbDataPath.io.toVfPreg\n\
      413:   memScheduler.io.v0WriteBack := wbDataPath.io.toV0Preg"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 424-434
    context: "424:   memScheduler.io.fromMem.get.lqDeqPtr := io.mem.lqDeqPtr\n425:\
      \   memScheduler.io.fromMem.get.sqCancelCnt := io.mem.sqCancelCnt\n426:   memScheduler.io.fromMem.get.lqCancelCnt
      := io.mem.lqCancelCnt\n427:   memScheduler.io.fromMem.get.stIssuePtr := io.mem.stIssuePtr\n\
      428:   require(memScheduler.io.fromMem.get.memWaitUpdateReq.robIdx.length ==
      io.mem.stIn.length)\n429:   memScheduler.io.fromMem.get.memWaitUpdateReq.robIdx.zip(io.mem.stIn).foreach
      { case (sink, source) =>\n430:     sink.valid := source.valid\n431:     sink.bits\
      \  := source.bits.robIdx\n432:   }\n433:   memScheduler.io.fromMem.get.memWaitUpdateReq.sqIdx
      := DontCare // TODO\n434:   memScheduler.io.fromDataPath.resp := dataPath.io.toMemIQ"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 435-446
    context: "435:   memScheduler.io.fromMem.get.ldaFeedback := io.mem.ldaIqFeedback\n\
      436:   memScheduler.io.fromMem.get.staFeedback := io.mem.staIqFeedback\n437:\
      \   memScheduler.io.fromMem.get.hyuFeedback := io.mem.hyuIqFeedback\n438:  \
      \ memScheduler.io.fromMem.get.vstuFeedback := io.mem.vstuIqFeedback\n439:  \
      \ memScheduler.io.fromMem.get.vlduFeedback := io.mem.vlduIqFeedback\n440:  \
      \ memScheduler.io.fromSchedulers.wakeupVec.foreach { wakeup => wakeup := iqWakeUpMappedBundle(wakeup.bits.exuIdx)
      }\n441:   memScheduler.io.fromSchedulers.wakeupVecDelayed.foreach { wakeup =>
      wakeup := iqWakeUpMappedBundleDelayed(wakeup.bits.exuIdx) }\n442:   memScheduler.io.fromDataPath.og0Cancel
      := og0Cancel\n443:   memScheduler.io.fromDataPath.og1Cancel := og1Cancel\n444:\
      \   memScheduler.io.ldCancel := io.mem.ldCancel\n445:   memScheduler.io.fromDataPath.replaceRCIdx.get
      := dataPath.io.toWakeupQueueRCIdx.takeRight(params.getMemExuRCWriteSize)\n446:\
      \   memScheduler.io.vlWriteBackInfo.vlFromIntIsZero := vlFromIntIsZero"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 448-458
    context: "448:   memScheduler.io.vlWriteBackInfo.vlFromVfIsZero := vlFromVfIsZero\n\
      449:   memScheduler.io.vlWriteBackInfo.vlFromVfIsVlmax := vlFromVfIsVlmax\n\
      450:   memScheduler.io.fromOg2Resp.get := og2ForVector.io.toMemIQOg2Resp\n451:\
      \ \n452:   vfScheduler.io.fromTop.hartId := io.fromTop.hartId\n453:   vfScheduler.io.fromCtrlBlock.flush
      := ctrlBlock.io.toIssueBlock.flush\n454:   vfScheduler.io.fromDispatch.uops
      <> ctrlBlock.io.toIssueBlock.vfUops\n455:   vfScheduler.io.intWriteBack := 0.U.asTypeOf(vfScheduler.io.intWriteBack)\n\
      456:   vfScheduler.io.fpWriteBack := 0.U.asTypeOf(vfScheduler.io.fpWriteBack)\n\
      457:   vfScheduler.io.vfWriteBack := wbDataPath.io.toVfPreg\n458:   vfScheduler.io.v0WriteBack
      := wbDataPath.io.toV0Preg"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 461-472
    context: "461:   vfScheduler.io.fpWriteBackDelayed := 0.U.asTypeOf(fpWriteBackDelayed)\n\
      462:   vfScheduler.io.vfWriteBackDelayed := vfWriteBackDelayed\n463:   vfScheduler.io.v0WriteBackDelayed
      := v0WriteBackDelayed\n464:   vfScheduler.io.vlWriteBackDelayed := vlWriteBackDelayed\n\
      465:   vfScheduler.io.fromDataPath.resp := dataPath.io.toVfIQ\n466:   vfScheduler.io.fromSchedulers.wakeupVec.foreach
      { wakeup => wakeup := iqWakeUpMappedBundle(wakeup.bits.exuIdx) }\n467:   vfScheduler.io.fromSchedulers.wakeupVecDelayed.foreach
      { wakeup => wakeup := iqWakeUpMappedBundleDelayed(wakeup.bits.exuIdx) }\n468:\
      \   vfScheduler.io.fromDataPath.og0Cancel := og0Cancel\n469:   vfScheduler.io.fromDataPath.og1Cancel
      := og1Cancel\n470:   vfScheduler.io.ldCancel := io.mem.ldCancel\n471:   vfScheduler.io.vlWriteBackInfo.vlFromIntIsZero
      := vlFromIntIsZero\n472:   vfScheduler.io.vlWriteBackInfo.vlFromIntIsVlmax :=
      vlFromIntIsVlmax"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 473-483
    context: "473:   vfScheduler.io.vlWriteBackInfo.vlFromVfIsZero := vlFromVfIsZero\n\
      474:   vfScheduler.io.vlWriteBackInfo.vlFromVfIsVlmax := vlFromVfIsVlmax\n475:\
      \   vfScheduler.io.fromOg2Resp.get := og2ForVector.io.toVfIQOg2Resp\n476: \n\
      477:   dataPath.io.hartId := io.fromTop.hartId\n478:   dataPath.io.flush :=
      ctrlBlock.io.toDataPath.flush\n479: \n480:   dataPath.io.fromIntIQ <> intScheduler.io.toDataPathAfterDelay\n\
      481:   dataPath.io.fromFpIQ <> fpScheduler.io.toDataPathAfterDelay\n482:   dataPath.io.fromVfIQ
      <> vfScheduler.io.toDataPathAfterDelay\n483:   dataPath.io.fromMemIQ <> memScheduler.io.toDataPathAfterDelay"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 489-503
    context: "489:   dataPath.io.fromIntWb := wbDataPath.io.toIntPreg\n490:   dataPath.io.fromFpWb
      := wbDataPath.io.toFpPreg\n491:   dataPath.io.fromVfWb := wbDataPath.io.toVfPreg\n\
      492:   dataPath.io.fromV0Wb := wbDataPath.io.toV0Preg\n493:   dataPath.io.fromVlWb
      := wbDataPath.io.toVlPreg\n494:   dataPath.io.diffIntRat.foreach(_ := ctrlBlock.io.diff_int_rat.get)\n\
      495:   dataPath.io.diffFpRat .foreach(_ := ctrlBlock.io.diff_fp_rat.get)\n496:\
      \   dataPath.io.diffVecRat.foreach(_ := ctrlBlock.io.diff_vec_rat.get)\n497:\
      \   dataPath.io.diffV0Rat .foreach(_ := ctrlBlock.io.diff_v0_rat.get)\n498:\
      \   dataPath.io.diffVlRat .foreach(_ := ctrlBlock.io.diff_vl_rat.get)\n499:\
      \   dataPath.io.fromBypassNetwork := bypassNetwork.io.toDataPath\n500:   dataPath.io.fromVecExcpMod.r
      := vecExcpMod.o.toVPRF.r\n501:   dataPath.io.fromVecExcpMod.w := vecExcpMod.o.toVPRF.w\n\
      502:   dataPath.io.topDownInfo.lqEmpty := DelayN(io.topDownInfo.lqEmpty, 2)\n\
      503:   dataPath.io.topDownInfo.sqEmpty := DelayN(io.topDownInfo.sqEmpty, 2)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 503-520
    context: "503:   dataPath.io.topDownInfo.sqEmpty := DelayN(io.topDownInfo.sqEmpty,
      2)\n504:   dataPath.io.topDownInfo.l1Miss := RegNext(io.topDownInfo.l1Miss)\n\
      505:   dataPath.io.topDownInfo.l2TopMiss.l2Miss := io.topDownInfo.l2TopMiss.l2Miss\n\
      506:   dataPath.io.topDownInfo.l2TopMiss.l3Miss := io.topDownInfo.l2TopMiss.l3Miss\n\
      507: \n508:   og2ForVector.io.flush := ctrlBlock.io.toDataPath.flush\n509: \
      \  og2ForVector.io.ldCancel := io.mem.ldCancel\n510:   og2ForVector.io.fromOg1VfArith
      <> dataPath.io.toVecExu\n511:   og2ForVector.io.fromOg1VecMem.zip(dataPath.io.toMemExu.zip(params.memSchdParams.get.issueBlockParams).filter(_._2.needOg2Resp).map(_._1))\n\
      512:     .foreach {\n513:       case (og1Mem, datapathMem) => og1Mem <> datapathMem\n\
      514:     }\n515:   og2ForVector.io.fromOg1ImmInfo := dataPath.io.og1ImmInfo.zip(params.allExuParams).filter(_._2.needOg2).map(_._1)\n\
      516: \n517:   println(s\"[Backend] BypassNetwork OG1 Mem Size: ${bypassNetwork.io.fromDataPath.mem.zip(params.memSchdParams.get.issueBlockParams).filterNot(_._2.needOg2Resp).size}\"\
      )\n518:   println(s\"[Backend] BypassNetwork OG2 Mem Size: ${bypassNetwork.io.fromDataPath.mem.zip(params.memSchdParams.get.issueBlockParams).filter(_._2.needOg2Resp).size}\"\
      )\n519:   println(s\"[Backend] bypassNetwork.io.fromDataPath.mem: ${bypassNetwork.io.fromDataPath.mem.size},
      dataPath.io.toMemExu: ${dataPath.io.toMemExu.size}\")\n520:   bypassNetwork.io.fromDataPath.int
      <> dataPath.io.toIntExu"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 519-538
    context: "519:   println(s\"[Backend] bypassNetwork.io.fromDataPath.mem: ${bypassNetwork.io.fromDataPath.mem.size},
      dataPath.io.toMemExu: ${dataPath.io.toMemExu.size}\")\n520:   bypassNetwork.io.fromDataPath.int
      <> dataPath.io.toIntExu\n521:   bypassNetwork.io.fromDataPath.fp <> dataPath.io.toFpExu\n\
      522:   bypassNetwork.io.fromDataPath.vf <> og2ForVector.io.toVfArithExu\n523:\
      \   bypassNetwork.io.fromDataPath.mem.lazyZip(params.memSchdParams.get.issueBlockParams).lazyZip(dataPath.io.toMemExu).filterNot(_._2.needOg2Resp)\n\
      524:     .map(x => (x._1, x._3)).foreach {\n525:       case (bypassMem, datapathMem)
      => bypassMem <> datapathMem\n526:     }\n527:   bypassNetwork.io.fromDataPath.mem.zip(params.memSchdParams.get.issueBlockParams).filter(_._2.needOg2Resp).map(_._1)\n\
      528:     .zip(og2ForVector.io.toVecMemExu).foreach {\n529:       case (bypassMem,
      og2Mem) => bypassMem <> og2Mem\n530:     }\n531:   bypassNetwork.io.fromDataPath.immInfo
      := dataPath.io.og1ImmInfo\n532:   bypassNetwork.io.fromDataPath.immInfo.zip(params.allExuParams).filter(_._2.needOg2).map(_._1)\n\
      533:     .zip(og2ForVector.io.toBypassNetworkImmInfo).foreach {\n534:      \
      \ case (immInfo, og2ImmInfo) => immInfo := og2ImmInfo\n535:     }\n536:   bypassNetwork.io.fromDataPath.rcData
      := dataPath.io.toBypassNetworkRCData\n537:   bypassNetwork.io.fromExus.connectExuOutput(_.int)(intExuBlock.io.out)\n\
      538:   bypassNetwork.io.fromExus.connectExuOutput(_.fp)(fpExuBlock.io.out)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 540-550
    context: "540: \n541:   require(bypassNetwork.io.fromExus.mem.flatten.size ==
      io.mem.writeBack.size,\n542:     s\"bypassNetwork.io.fromExus.mem.flatten.size(${bypassNetwork.io.fromExus.mem.flatten.size}:
      ${bypassNetwork.io.fromExus.mem.map(_.size)}, \" +\n543:     s\"io.mem.writeback(${io.mem.writeBack.size})\"\
      \n544:   )\n545:   bypassNetwork.io.fromExus.mem.flatten.zip(io.mem.writeBack).foreach
      { case (sink, source) =>\n546:     sink.valid := source.valid\n547:     sink.bits.intWen
      := source.bits.uop.rfWen && source.bits.isFromLoadUnit\n548:     sink.bits.pdest
      := source.bits.uop.pdest\n549:     sink.bits.data := source.bits.data\n550:\
      \   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 548-567
    context: "548:     sink.bits.pdest := source.bits.uop.pdest\n549:     sink.bits.data
      := source.bits.data\n550:   }\n551: \n552: \n553:   intExuBlock.io.flush :=
      ctrlBlock.io.toExuBlock.flush\n554:   for (i <- 0 until intExuBlock.io.in.length)
      {\n555:     for (j <- 0 until intExuBlock.io.in(i).length) {\n556:       val
      shouldLdCancel = LoadShouldCancel(bypassNetwork.io.toExus.int(i)(j).bits.loadDependency,
      io.mem.ldCancel)\n557:       NewPipelineConnect(\n558:         bypassNetwork.io.toExus.int(i)(j),
      intExuBlock.io.in(i)(j), intExuBlock.io.in(i)(j).fire,\n559:         Mux(\n\
      560:           bypassNetwork.io.toExus.int(i)(j).fire,\n561:           bypassNetwork.io.toExus.int(i)(j).bits.robIdx.needFlush(ctrlBlock.io.toExuBlock.flush)
      || shouldLdCancel,\n562:           intExuBlock.io.in(i)(j).bits.robIdx.needFlush(ctrlBlock.io.toExuBlock.flush)\n\
      563:         ),\n564:         Option(\"bypassNetwork2intExuBlock\")\n565:  \
      \     )\n566:     }\n567:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 572-582
    context: "572:   csrin.hartId := io.fromTop.hartId\n573:   csrin.msiInfo.valid
      := RegNext(io.fromTop.msiInfo.valid)\n574:   csrin.msiInfo.bits := RegEnable(io.fromTop.msiInfo.bits,
      io.fromTop.msiInfo.valid)\n575:   csrin.clintTime.valid := RegNext(io.fromTop.clintTime.valid)\n\
      576:   csrin.clintTime.bits := RegEnable(io.fromTop.clintTime.bits, io.fromTop.clintTime.valid)\n\
      577:   csrin.l2FlushDone := RegNext(io.fromTop.l2FlushDone)\n578:   csrin.trapInstInfo
      := ctrlBlock.io.toCSR.trapInstInfo\n579:   csrin.fromVecExcpMod.busy := vecExcpMod.o.status.busy\n\
      580:   csrin.criticalErrorState := backendCriticalError\n581: \n582:   private
      val csrio = intExuBlock.io.csrio.get"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 579-589
    context: "579:   csrin.fromVecExcpMod.busy := vecExcpMod.o.status.busy\n580: \
      \  csrin.criticalErrorState := backendCriticalError\n581: \n582:   private val
      csrio = intExuBlock.io.csrio.get\n583:   csrio.hartId := io.fromTop.hartId\n\
      584:   csrio.fpu.fflags := ctrlBlock.io.robio.csr.fflags\n585:   csrio.fpu.isIllegal
      := false.B // Todo: remove it\n586:   csrio.fpu.dirty_fs := ctrlBlock.io.robio.csr.dirty_fs\n\
      587:   csrio.vpu <> WireDefault(0.U.asTypeOf(csrio.vpu)) // Todo\n588: \n589:\
      \   val fromIntExuVsetVType = intExuBlock.io.vtype.getOrElse(0.U.asTypeOf((Valid(new
      VType))))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 590-602
    context: "590:   val fromVfExuVsetVType = vfExuBlock.io.vtype.getOrElse(0.U.asTypeOf((Valid(new
      VType))))\n591:   val fromVsetVType = Mux(fromIntExuVsetVType.valid, fromIntExuVsetVType.bits,
      fromVfExuVsetVType.bits)\n592:   val vsetvlVType = RegEnable(fromVsetVType,
      0.U.asTypeOf(new VType), fromIntExuVsetVType.valid || fromVfExuVsetVType.valid)\n\
      593:   ctrlBlock.io.toDecode.vsetvlVType := vsetvlVType\n594: \n595:   val commitVType
      = ctrlBlock.io.robio.commitVType.vtype\n596:   val hasVsetvl = ctrlBlock.io.robio.commitVType.hasVsetvl\n\
      597:   val vtype = VType.toVtypeStruct(Mux(hasVsetvl, vsetvlVType, commitVType.bits)).asUInt\n\
      598: \n599:   // csr not store the value of vl, so when using difftest we assign
      the value of vl to debugVl\n600:   val debugVl_s0 = WireInit(UInt(VlData().dataWidth.W),
      0.U)\n601:   val debugVl_s1 = WireInit(UInt(VlData().dataWidth.W), 0.U)\n602:\
      \   debugVl_s0 := dataPath.io.diffVl.getOrElse(0.U.asTypeOf(UInt(VlData().dataWidth.W)))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 604-614
    context: "604:   csrio.vpu.set_vxsat := ctrlBlock.io.robio.csr.vxsat\n605:   csrio.vpu.set_vstart.valid
      := ctrlBlock.io.robio.csr.vstart.valid\n606:   csrio.vpu.set_vstart.bits :=
      ctrlBlock.io.robio.csr.vstart.bits\n607:   ctrlBlock.io.toDecode.vstart := csrio.vpu.vstart\n\
      608:   //Todo here need change design\n609:   csrio.vpu.set_vtype.valid := commitVType.valid\n\
      610:   csrio.vpu.set_vtype.bits := ZeroExt(vtype, XLEN)\n611:   csrio.vpu.vl
      := ZeroExt(debugVl_s1, XLEN)\n612:   csrio.vpu.dirty_vs := ctrlBlock.io.robio.csr.dirty_vs\n\
      613:   csrio.exception := ctrlBlock.io.robio.exception\n614:   csrio.robDeqPtr
      := ctrlBlock.io.robio.robDeqPtr"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 621-640
    context: "621:   csrio.perf.ctrlInfo <> ctrlBlock.io.perfInfo.ctrlInfo\n622: \
      \  private val fenceio = intExuBlock.io.fenceio.get\n623:   io.fenceio <> fenceio\n\
      624: \n625:   // to fpExuBlock\n626:   fpExuBlock.io.flush := ctrlBlock.io.toExuBlock.flush\n\
      627:   for (i <- 0 until fpExuBlock.io.in.length) {\n628:     for (j <- 0 until
      fpExuBlock.io.in(i).length) {\n629:       val shouldLdCancel = LoadShouldCancel(bypassNetwork.io.toExus.fp(i)(j).bits.loadDependency,
      io.mem.ldCancel)\n630:       NewPipelineConnect(\n631:         bypassNetwork.io.toExus.fp(i)(j),
      fpExuBlock.io.in(i)(j), fpExuBlock.io.in(i)(j).fire,\n632:         Mux(\n633:\
      \           bypassNetwork.io.toExus.fp(i)(j).fire,\n634:           bypassNetwork.io.toExus.fp(i)(j).bits.robIdx.needFlush(ctrlBlock.io.toExuBlock.flush)
      || shouldLdCancel,\n635:           fpExuBlock.io.in(i)(j).bits.robIdx.needFlush(ctrlBlock.io.toExuBlock.flush)\n\
      636:         ),\n637:         Option(\"bypassNetwork2fpExuBlock\")\n638:   \
      \    )\n639:     }\n640:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 637-656
    context: "637:         Option(\"bypassNetwork2fpExuBlock\")\n638:       )\n639:\
      \     }\n640:   }\n641: \n642:   vfExuBlock.io.flush := ctrlBlock.io.toExuBlock.flush\n\
      643:   for (i <- 0 until vfExuBlock.io.in.size) {\n644:     for (j <- 0 until
      vfExuBlock.io.in(i).size) {\n645:       val shouldLdCancel = LoadShouldCancel(bypassNetwork.io.toExus.vf(i)(j).bits.loadDependency,
      io.mem.ldCancel)\n646:       NewPipelineConnect(\n647:         bypassNetwork.io.toExus.vf(i)(j),
      vfExuBlock.io.in(i)(j), vfExuBlock.io.in(i)(j).fire,\n648:         Mux(\n649:\
      \           bypassNetwork.io.toExus.vf(i)(j).fire,\n650:           bypassNetwork.io.toExus.vf(i)(j).bits.robIdx.needFlush(ctrlBlock.io.toExuBlock.flush)
      || shouldLdCancel,\n651:           vfExuBlock.io.in(i)(j).bits.robIdx.needFlush(ctrlBlock.io.toExuBlock.flush)\n\
      652:         ),\n653:         Option(\"bypassNetwork2vfExuBlock\")\n654:   \
      \    )\n655: \n656:     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 654-695
    context: "654:       )\n655: \n656:     }\n657:   }\n658: \n659:   intExuBlock.io.frm.foreach(_
      := csrio.fpu.frm)\n660:   fpExuBlock.io.frm.foreach(_ := csrio.fpu.frm)\n661:\
      \   fpExuBlock.io.vxrm.foreach(_ := csrio.vpu.vxrm)\n662:   vfExuBlock.io.frm.foreach(_
      := csrio.fpu.frm)\n663:   vfExuBlock.io.vxrm.foreach(_ := csrio.vpu.vxrm)\n\
      664: \n665:   wbDataPath.io.flush := ctrlBlock.io.redirect\n666:   wbDataPath.io.fromTop.hartId
      := io.fromTop.hartId\n667:   wbDataPath.io.fromIntExu <> intExuBlock.io.out\n\
      668:   wbDataPath.io.fromFpExu <> fpExuBlock.io.out\n669:   wbDataPath.io.fromVfExu
      <> vfExuBlock.io.out\n670:   wbDataPath.io.fromMemExu.flatten.zip(io.mem.writeBack).foreach
      { case (sink, source) =>\n671:     sink.valid := source.valid\n672:     source.ready
      := sink.ready\n673:     sink.bits.data   := VecInit(Seq.fill(sink.bits.params.wbPathNum)(source.bits.data))\n\
      674:     sink.bits.pdest  := source.bits.uop.pdest\n675:     sink.bits.robIdx
      := source.bits.uop.robIdx\n676:     sink.bits.intWen.foreach(_ := source.bits.uop.rfWen)\n\
      677:     sink.bits.fpWen.foreach(_ := source.bits.uop.fpWen)\n678:     sink.bits.vecWen.foreach(_
      := source.bits.uop.vecWen)\n679:     sink.bits.v0Wen.foreach(_ := source.bits.uop.v0Wen)\n\
      680:     sink.bits.vlWen.foreach(_ := source.bits.uop.vlWen)\n681:     sink.bits.exceptionVec.foreach(_
      := source.bits.uop.exceptionVec)\n682:     sink.bits.flushPipe.foreach(_ :=
      source.bits.uop.flushPipe)\n683:     sink.bits.replay.foreach(_ := source.bits.uop.replayInst)\n\
      684:     sink.bits.debug := source.bits.debug\n685:     sink.bits.debugInfo
      := source.bits.uop.debugInfo\n686:     sink.bits.debug_seqNum := source.bits.uop.debug_seqNum\n\
      687:     sink.bits.lqIdx.foreach(_ := source.bits.uop.lqIdx)\n688:     sink.bits.sqIdx.foreach(_
      := source.bits.uop.sqIdx)\n689:     sink.bits.predecodeInfo.foreach(_ := source.bits.uop.preDecodeInfo)\n\
      690:     sink.bits.vls.foreach(x => {\n691:       x.vdIdx := source.bits.vdIdx.get\n\
      692:       x.vdIdxInField := source.bits.vdIdxInField.get\n693:       x.vpu\
      \   := source.bits.uop.vpu\n694:       x.oldVdPsrc := source.bits.uop.psrc(2)\n\
      695:       x.isIndexed := VlduType.isIndexed(source.bits.uop.fuOpType)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 697-707
    context: "697:       x.isStrided := VlduType.isStrided(source.bits.uop.fuOpType)\n\
      698:       x.isWhole := VlduType.isWhole(source.bits.uop.fuOpType)\n699:   \
      \    x.isVecLoad := VlduType.isVecLd(source.bits.uop.fuOpType)\n700:       x.isVlm
      := VlduType.isMasked(source.bits.uop.fuOpType) && VlduType.isVecLd(source.bits.uop.fuOpType)\n\
      701:     })\n702:     sink.bits.trigger.foreach(_ := source.bits.uop.trigger)\n\
      703:   }\n704:   wbDataPath.io.fromCSR.vstart := csrio.vpu.vstart\n705: \n706:\
      \   vecExcpMod.i.fromExceptionGen := ctrlBlock.io.toVecExcpMod.excpInfo\n707:\
      \   vecExcpMod.i.fromRab.logicPhyRegMap := ctrlBlock.io.toVecExcpMod.logicPhyRegMap"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 720-730
    context: "720:     for (j <- toMem(i).indices) {\n721:       val shouldLdCancel
      = LoadShouldCancel(bypassNetwork.io.toExus.mem(i)(j).bits.loadDependency, io.mem.ldCancel)\n\
      722:       val needIssueTimeout = memExuBlocksHasLDU(i)(j) || memExuBlocksHasVecLoad(i)(j)\n\
      723:       val issueTimeout =\n724:         if (needIssueTimeout)\n725:    \
      \       Counter(0 until 16, toMem(i)(j).valid && !toMem(i)(j).fire, bypassNetwork.io.toExus.mem(i)(j).fire)._2\n\
      726:         else\n727:           false.B\n728: \n729:       if (memScheduler.io.loadFinalIssueResp(i).nonEmpty
      && memExuBlocksHasLDU(i)(j)) {\n730:         memScheduler.io.loadFinalIssueResp(i)(j).valid
      := issueTimeout"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 729-741
    context: "729:       if (memScheduler.io.loadFinalIssueResp(i).nonEmpty && memExuBlocksHasLDU(i)(j))
      {\n730:         memScheduler.io.loadFinalIssueResp(i)(j).valid := issueTimeout\n\
      731:         memScheduler.io.loadFinalIssueResp(i)(j).bits.fuType := toMem(i)(j).bits.fuType\n\
      732:         memScheduler.io.loadFinalIssueResp(i)(j).bits.resp := RespType.block\n\
      733:         memScheduler.io.loadFinalIssueResp(i)(j).bits.robIdx := toMem(i)(j).bits.robIdx\n\
      734:         memScheduler.io.loadFinalIssueResp(i)(j).bits.uopIdx.foreach(_
      := toMem(i)(j).bits.vpu.get.vuopIdx)\n735:         memScheduler.io.loadFinalIssueResp(i)(j).bits.sqIdx.foreach(_
      := toMem(i)(j).bits.sqIdx.get)\n736:         memScheduler.io.loadFinalIssueResp(i)(j).bits.lqIdx.foreach(_
      := toMem(i)(j).bits.lqIdx.get)\n737:       }\n738: \n739:       if (memScheduler.io.vecLoadFinalIssueResp(i).nonEmpty
      && memExuBlocksHasVecLoad(i)(j)) {\n740:         memScheduler.io.vecLoadFinalIssueResp(i)(j).valid
      := issueTimeout\n741:         memScheduler.io.vecLoadFinalIssueResp(i)(j).bits.fuType
      := toMem(i)(j).bits.fuType"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 739-759
    context: "739:       if (memScheduler.io.vecLoadFinalIssueResp(i).nonEmpty &&
      memExuBlocksHasVecLoad(i)(j)) {\n740:         memScheduler.io.vecLoadFinalIssueResp(i)(j).valid
      := issueTimeout\n741:         memScheduler.io.vecLoadFinalIssueResp(i)(j).bits.fuType
      := toMem(i)(j).bits.fuType\n742:         memScheduler.io.vecLoadFinalIssueResp(i)(j).bits.resp
      := RespType.block\n743:         memScheduler.io.vecLoadFinalIssueResp(i)(j).bits.robIdx
      := toMem(i)(j).bits.robIdx\n744:         memScheduler.io.vecLoadFinalIssueResp(i)(j).bits.uopIdx.foreach(_
      := toMem(i)(j).bits.vpu.get.vuopIdx)\n745:         memScheduler.io.vecLoadFinalIssueResp(i)(j).bits.sqIdx.foreach(_
      := toMem(i)(j).bits.sqIdx.get)\n746:         memScheduler.io.vecLoadFinalIssueResp(i)(j).bits.lqIdx.foreach(_
      := toMem(i)(j).bits.lqIdx.get)\n747:       }\n748: \n749:       NewPipelineConnect(\n\
      750:         bypassNetwork.io.toExus.mem(i)(j), toMem(i)(j), toMem(i)(j).fire,\n\
      751:         Mux(\n752:           bypassNetwork.io.toExus.mem(i)(j).fire,\n\
      753:           bypassNetwork.io.toExus.mem(i)(j).bits.robIdx.needFlush(ctrlBlock.io.toExuBlock.flush)
      || shouldLdCancel,\n754:           toMem(i)(j).bits.robIdx.needFlush(ctrlBlock.io.toExuBlock.flush)
      || issueTimeout\n755:         ),\n756:         Option(\"bypassNetwork2toMemExus\"\
      )\n757:       )\n758: \n759:       if (memScheduler.io.memAddrIssueResp(i).nonEmpty
      && memExuBlocksHasLDU(i)(j)) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 755-769
    context: "755:         ),\n756:         Option(\"bypassNetwork2toMemExus\")\n\
      757:       )\n758: \n759:       if (memScheduler.io.memAddrIssueResp(i).nonEmpty
      && memExuBlocksHasLDU(i)(j)) {\n760:         memScheduler.io.memAddrIssueResp(i)(j).valid
      := toMem(i)(j).fire && FuType.isLoad(toMem(i)(j).bits.fuType)\n761:        \
      \ memScheduler.io.memAddrIssueResp(i)(j).bits.fuType := toMem(i)(j).bits.fuType\n\
      762:         memScheduler.io.memAddrIssueResp(i)(j).bits.robIdx := toMem(i)(j).bits.robIdx\n\
      763:         memScheduler.io.memAddrIssueResp(i)(j).bits.sqIdx.foreach(_ :=
      toMem(i)(j).bits.sqIdx.get)\n764:         memScheduler.io.memAddrIssueResp(i)(j).bits.lqIdx.foreach(_
      := toMem(i)(j).bits.lqIdx.get)\n765:         memScheduler.io.memAddrIssueResp(i)(j).bits.resp
      := RespType.success // for load inst, firing at toMem means issuing successfully\n\
      766:       }\n767: \n768:       if (memScheduler.io.vecLoadIssueResp(i).nonEmpty
      && memExuBlocksHasVecLoad(i)(j)) {\n769:         memScheduler.io.vecLoadIssueResp(i)(j)
      match {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 766-776
    context: "766:       }\n767: \n768:       if (memScheduler.io.vecLoadIssueResp(i).nonEmpty
      && memExuBlocksHasVecLoad(i)(j)) {\n769:         memScheduler.io.vecLoadIssueResp(i)(j)
      match {\n770:           case resp =>\n771:             resp.valid := toMem(i)(j).fire
      && VlduType.isVecLd(toMem(i)(j).bits.fuOpType)\n772:             resp.bits.fuType
      := toMem(i)(j).bits.fuType\n773:             resp.bits.robIdx := toMem(i)(j).bits.robIdx\n\
      774:             resp.bits.uopIdx.get := toMem(i)(j).bits.vpu.get.vuopIdx\n\
      775:             resp.bits.sqIdx.get := toMem(i)(j).bits.sqIdx.get\n776:   \
      \          resp.bits.lqIdx.get := toMem(i)(j).bits.lqIdx.get"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 781-800
    context: "781:         }\n782:       }\n783:     }\n784:   }\n785: \n786:   io.mem.redirect
      := ctrlBlock.io.redirect\n787:   io.mem.issueUops.zip(toMem.flatten).foreach
      { case (sink, source) =>\n788:     val enableMdp = Constantin.createRecord(\"\
      EnableMdp\", true)\n789:     sink.valid := source.valid\n790:     source.ready
      := sink.ready\n791:     sink.bits.iqIdx              := source.bits.iqIdx\n\
      792:     sink.bits.isFirstIssue       := source.bits.isFirstIssue\n793:    \
      \ sink.bits.uop                := 0.U.asTypeOf(sink.bits.uop)\n794:     sink.bits.src\
      \                := 0.U.asTypeOf(sink.bits.src)\n795:     sink.bits.src.zip(source.bits.src).foreach
      { case (l, r) => l := r}\n796:     sink.bits.uop.fuType         := source.bits.fuType\n\
      797:     sink.bits.uop.fuOpType       := source.bits.fuOpType\n798:     sink.bits.uop.imm\
      \            := source.bits.imm\n799:     sink.bits.uop.robIdx         := source.bits.robIdx\n\
      800:     sink.bits.uop.pdest          := source.bits.pdest"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 801-811
    context: "801:     sink.bits.uop.rfWen          := source.bits.rfWen.getOrElse(false.B)\n\
      802:     sink.bits.uop.fpWen          := source.bits.fpWen.getOrElse(false.B)\n\
      803:     sink.bits.uop.vecWen         := source.bits.vecWen.getOrElse(false.B)\n\
      804:     sink.bits.uop.v0Wen          := source.bits.v0Wen.getOrElse(false.B)\n\
      805:     sink.bits.uop.vlWen          := source.bits.vlWen.getOrElse(false.B)\n\
      806:     sink.bits.uop.flushPipe      := source.bits.flushPipe.getOrElse(false.B)\n\
      807:     sink.bits.uop.pc             := source.bits.pc.getOrElse(0.U) + (source.bits.ftqOffset.getOrElse(0.U)
      << instOffsetBits)\n808:     sink.bits.uop.loadWaitBit    := Mux(enableMdp,
      source.bits.loadWaitBit.getOrElse(false.B), false.B)\n809:     sink.bits.uop.waitForRobIdx\
      \  := Mux(enableMdp, source.bits.waitForRobIdx.getOrElse(0.U.asTypeOf(new RobPtr)),
      0.U.asTypeOf(new RobPtr))\n810:     sink.bits.uop.storeSetHit    := Mux(enableMdp,
      source.bits.storeSetHit.getOrElse(false.B), false.B)\n811:     sink.bits.uop.loadWaitStrict
      := Mux(enableMdp, source.bits.loadWaitStrict.getOrElse(false.B), false.B)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 817-827
    context: "817:     sink.bits.uop.debugInfo      := source.bits.perfDebugInfo\n\
      818:     sink.bits.uop.debug_seqNum   := source.bits.debug_seqNum\n819:    \
      \ sink.bits.uop.vpu            := source.bits.vpu.getOrElse(0.U.asTypeOf(new
      VPUCtrlSignals))\n820:     sink.bits.uop.preDecodeInfo  := source.bits.preDecode.getOrElse(0.U.asTypeOf(new
      PreDecodeInfo))\n821:     sink.bits.uop.numLsElem      := source.bits.numLsElem.getOrElse(0.U)
      // Todo: remove this bundle, keep only the one below\n822:     sink.bits.flowNum.foreach(_\
      \  := source.bits.numLsElem.get)\n823:   }\n824:   io.mem.loadFastMatch := memScheduler.io.toMem.get.loadFastMatch.map(_.fastMatch)\n\
      825:   io.mem.loadFastImm := memScheduler.io.toMem.get.loadFastMatch.map(_.fastImm)\n\
      826:   io.mem.tlbCsr := csrio.tlb\n827:   io.mem.csrCtrl := csrio.customCtrl"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 824-837
    context: "824:   io.mem.loadFastMatch := memScheduler.io.toMem.get.loadFastMatch.map(_.fastMatch)\n\
      825:   io.mem.loadFastImm := memScheduler.io.toMem.get.loadFastMatch.map(_.fastImm)\n\
      826:   io.mem.tlbCsr := csrio.tlb\n827:   io.mem.csrCtrl := csrio.customCtrl\n\
      828:   io.mem.sfence := fenceio.sfence\n829:   io.mem.isStoreException := CommitType.lsInstIsStore(ctrlBlock.io.robio.exception.bits.commitType)\n\
      830:   io.mem.isVlsException := ctrlBlock.io.robio.exception.bits.vls\n831:\
      \ \n832:   io.mem.storePcRead.zipWithIndex.foreach { case (storePcRead, i) =>\n\
      833:     storePcRead := ctrlBlock.io.memStPcRead(i).data\n834:     ctrlBlock.io.memStPcRead(i).valid
      := io.mem.issueSta(i).valid\n835:     ctrlBlock.io.memStPcRead(i).ptr := io.mem.issueSta(i).bits.uop.ftqPtr\n\
      836:     ctrlBlock.io.memStPcRead(i).offset := io.mem.issueSta(i).bits.uop.ftqOffset\n\
      837:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 834-844
    context: "834:     ctrlBlock.io.memStPcRead(i).valid := io.mem.issueSta(i).valid\n\
      835:     ctrlBlock.io.memStPcRead(i).ptr := io.mem.issueSta(i).bits.uop.ftqPtr\n\
      836:     ctrlBlock.io.memStPcRead(i).offset := io.mem.issueSta(i).bits.uop.ftqOffset\n\
      837:   }\n838: \n839:   io.mem.hyuPcRead.zipWithIndex.foreach( { case (hyuPcRead,
      i) =>\n840:     hyuPcRead := ctrlBlock.io.memHyPcRead(i).data\n841:     ctrlBlock.io.memHyPcRead(i).valid
      := io.mem.issueHylda(i).valid\n842:     ctrlBlock.io.memHyPcRead(i).ptr := io.mem.issueHylda(i).bits.uop.ftqPtr\n\
      843:     ctrlBlock.io.memHyPcRead(i).offset := io.mem.issueHylda(i).bits.uop.ftqOffset\n\
      844:   })"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 841-851
    context: "841:     ctrlBlock.io.memHyPcRead(i).valid := io.mem.issueHylda(i).valid\n\
      842:     ctrlBlock.io.memHyPcRead(i).ptr := io.mem.issueHylda(i).bits.uop.ftqPtr\n\
      843:     ctrlBlock.io.memHyPcRead(i).offset := io.mem.issueHylda(i).bits.uop.ftqOffset\n\
      844:   })\n845: \n846:   ctrlBlock.io.robio.robHeadLsIssue := io.mem.issueUops.map(deq
      => deq.fire && deq.bits.uop.robIdx === ctrlBlock.io.robio.robDeqPtr).reduce(_
      || _)\n847: \n848:   // mem io\n849:   io.mem.robLsqIO <> ctrlBlock.io.robio.lsq\n\
      850:   io.mem.storeDebugInfo <> ctrlBlock.io.robio.storeDebugInfo\n851: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 982-992
    context: "982:   val writebackHyuSta = Vec(params.HyuCnt, Flipped(DecoupledIO(new
      MemExuOutput)))\n983:   val writebackVldu = Vec(params.VlduCnt, Flipped(DecoupledIO(new
      MemExuOutput(true))))\n984: \n985:   val s3_delayed_load_error = Input(Vec(LoadPipelineWidth,
      Bool()))\n986:   val stIn = Input(Vec(params.StaExuCnt, ValidIO(new DynInst())))\n\
      987:   val memoryViolation = Flipped(ValidIO(new Redirect))\n988:   val exceptionAddr
      = Input(new Bundle {\n989:     val vaddr = UInt(XLEN.W)\n990:     val gpaddr
      = UInt(XLEN.W)\n991:     val isForVSnonLeafPTE = Bool()\n992:   })"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 1006-1022
    context: "1006: \n1007:   val debugLS = Flipped(Output(new DebugLSIO))\n1008:\
      \ \n1009:   val lsTopdownInfo = Vec(params.LduCnt + params.HyuCnt, Flipped(Output(new
      LsTopdownInfo)))\n1010:   // Output\n1011:   val redirect = ValidIO(new Redirect)\
      \   // rob flush MemBlock\n1012:   val issueLda = MixedVec(Seq.fill(params.LduCnt)(DecoupledIO(new
      MemExuInput())))\n1013:   val issueSta = MixedVec(Seq.fill(params.StaCnt)(DecoupledIO(new
      MemExuInput())))\n1014:   val issueStd = MixedVec(Seq.fill(params.StdCnt)(DecoupledIO(new
      MemExuInput())))\n1015:   val issueHylda = MixedVec(Seq.fill(params.HyuCnt)(DecoupledIO(new
      MemExuInput())))\n1016:   val issueHysta = MixedVec(Seq.fill(params.HyuCnt)(DecoupledIO(new
      MemExuInput())))\n1017:   val issueVldu = MixedVec(Seq.fill(params.VlduCnt)(DecoupledIO(new
      MemExuInput(true))))\n1018: \n1019:   val loadFastMatch = Vec(params.LduCnt,
      Output(UInt(params.LduCnt.W)))\n1020:   val loadFastImm   = Vec(params.LduCnt,
      Output(UInt(12.W))) // Imm_I\n1021: \n1022:   val tlbCsr = Output(new TlbCsrBundle)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 1054-1064
    context: "1054: class TopToBackendBundle(implicit p: Parameters) extends XSBundle
      with HasSoCParameter {\n1055:   val hartId            = Output(UInt(hartIdLen.W))\n\
      1056:   val externalInterrupt = Output(new ExternalInterruptIO)\n1057:   val
      msiInfo           = Output(ValidIO(UInt(soc.IMSICParams.MSI_INFO_WIDTH.W)))\n\
      1058:   val clintTime         = Output(ValidIO(UInt(64.W)))\n1059:   val l2FlushDone\
      \       = Output(Bool())\n1060: }\n1061: \n1062: class BackendToTopBundle extends
      Bundle {\n1063:   val cpuHalted = Output(Bool())\n1064:   val cpuCriticalError
      = Output(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/PregParams.scala
    lines: 3-13
    context: "3: import chisel3.util.log2Up\n4: import xiangshan.backend.datapath.DataConfig._\n\
      5: \n6: abstract class PregParams {\n7:   val numEntries: Int\n8:   val numRead:
      Option[Int]\n9:   val numWrite: Option[Int]\n10:   val dataCfg: DataConfig\n\
      11:   val isFake: Boolean\n12: \n13:   def addrWidth = log2Up(numEntries)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/PregParams.scala
    lines: 13-23
    context: "13:   def addrWidth = log2Up(numEntries)\n14: }\n15: \n16: case class
      IntPregParams(\n17:   numEntries: Int,\n18:   numRead   : Option[Int],\n19:\
      \   numWrite  : Option[Int],\n20: ) extends PregParams {\n21: \n22:   val dataCfg:
      DataConfig = IntData()\n23:   val isFake: Boolean = false"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/PregParams.scala
    lines: 23-33
    context: "23:   val isFake: Boolean = false\n24: }\n25: \n26: case class FpPregParams(\n\
      27:                           numEntries: Int,\n28:                        \
      \   numRead   : Option[Int],\n29:                           numWrite  : Option[Int],\n\
      30:                         ) extends PregParams {\n31: \n32:   val dataCfg:
      DataConfig = FpData()\n33:   val isFake: Boolean = false"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/PregParams.scala
    lines: 33-43
    context: "33:   val isFake: Boolean = false\n34: }\n35: \n36: case class VfPregParams(\n\
      37:   numEntries: Int,\n38:   numRead   : Option[Int],\n39:   numWrite  : Option[Int],\n\
      40: ) extends PregParams {\n41: \n42:   val dataCfg: DataConfig = VecData()\n\
      43:   val isFake: Boolean = false"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/PregParams.scala
    lines: 43-53
    context: "43:   val isFake: Boolean = false\n44: }\n45: \n46: case class V0PregParams(\n\
      47:   numEntries: Int,\n48:   numRead   : Option[Int],\n49:   numWrite  : Option[Int],\n\
      50: ) extends PregParams {\n51: \n52:   val dataCfg: DataConfig = V0Data()\n\
      53:   val isFake: Boolean = false"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/PregParams.scala
    lines: 53-63
    context: "53:   val isFake: Boolean = false\n54: }\n55: \n56: case class VlPregParams(\n\
      57:   numEntries: Int,\n58:   numRead   : Option[Int],\n59:   numWrite  : Option[Int],\n\
      60: ) extends PregParams {\n61: \n62:   val dataCfg: DataConfig = VlData()\n\
      63:   val isFake: Boolean = false"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/PregParams.scala
    lines: 63-73
    context: "63:   val isFake: Boolean = false\n64: }\n65: \n66: case class NoPregParams()
      extends PregParams {\n67:   val numEntries: Int = 0\n68:   val numRead   : Option[Int]
      = None\n69:   val numWrite  : Option[Int] = None\n70: \n71:   val dataCfg: DataConfig
      = NoData()\n72:   val isFake: Boolean = false\n73: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/PregParams.scala
    lines: 72-82
    context: "72:   val isFake: Boolean = false\n73: }\n74: \n75: case class FakeIntPregParams(\n\
      76:   numEntries: Int,\n77:   numRead   : Option[Int],\n78:   numWrite  : Option[Int],\n\
      79: ) extends PregParams {\n80: \n81:   val dataCfg: DataConfig = FakeIntData()\n\
      82:   val isFake: Boolean = true"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/Regfile.scala
    lines: 22-32
    context: "22: import utils.OptionWrapper\n23: import xiangshan._\n24: import xiangshan.backend.datapath.DataConfig._\n\
      25: import xiangshan.backend.exu.ExeUnitParams\n26: \n27: class RfReadPort(dataWidth:
      Int, addrWidth: Int) extends Bundle {\n28:   val addr = Input(UInt(addrWidth.W))\n\
      29:   val data = Output(UInt(dataWidth.W))\n30: }\n31: \n32: class RfWritePort(dataWidth:
      Int, addrWidth: Int) extends Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/Regfile.scala
    lines: 37-50
    context: "37: \n38: class RfReadPortWithConfig(val rfReadDataCfg: DataConfig,
      addrWidth: Int) extends Bundle {\n39:   val addr: UInt = Input(UInt(addrWidth.W))\n\
      40:   val srcType: UInt = Input(UInt(3.W))\n41: \n42:   def readInt: Boolean
      = IntRegSrcDataSet.contains(rfReadDataCfg)\n43:   def readFp : Boolean = FpRegSrcDataSet
      .contains(rfReadDataCfg)\n44:   def readVec: Boolean = VecRegSrcDataSet.contains(rfReadDataCfg)\n\
      45:   def readVf : Boolean = VecRegSrcDataSet .contains(rfReadDataCfg)\n46:
      }\n47: \n48: class RfWritePortWithConfig(val rfWriteDataCfg: DataConfig, addrWidth:
      Int) extends Bundle {\n49:   val wen = Input(Bool())\n50:   val addr = Input(UInt(addrWidth.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/Regfile.scala
    lines: 72-92
    context: "72:   width: Int,\n73:   bankNum: Int = 1,\n74:   isVlRegfile: Boolean
      = false,\n75: ) extends Module {\n76:   val io = IO(new Bundle() {\n77:    \
      \ val readPorts = Vec(numReadPorts, new RfReadPort(len, width))\n78:     val
      writePorts = Vec(numWritePorts, new RfWritePort(len, width))\n79:     val debug_rports
      = Vec(65, new RfReadPort(len, width))\n80:   })\n81:   override def desiredName
      = name\n82:   println(name + \": size:\" + numPregs + \" read: \" + numReadPorts
      + \" write: \" + numWritePorts)\n83: \n84:   val mem_0 = if (isVlRegfile) RegInit(0.U(len.W))
      else Reg(UInt(len.W))\n85:   val mem = Reg(Vec(numPregs, UInt(len.W)))\n86:\
      \   val memForRead = Wire(Vec(numPregs, UInt(len.W)))\n87:   memForRead.zipWithIndex.map{
      case(m, i) =>\n88:     if (i == 0) m := mem_0\n89:     else m := mem(i)\n90:\
      \   }\n91:   require(Seq(1, 2, 4).contains(bankNum), \"bankNum must be 1 or
      2 or 4\")\n92:   for (r <- io.readPorts) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/Regfile.scala
    lines: 89-103
    context: "89:     else m := mem(i)\n90:   }\n91:   require(Seq(1, 2, 4).contains(bankNum),
      \"bankNum must be 1 or 2 or 4\")\n92:   for (r <- io.readPorts) {\n93:     if
      (bankNum == 1) {\n94:       r.data := memForRead(RegNext(r.addr))\n95:     }\n\
      96:     else {\n97:       val banks = (0 until bankNum).map { case i =>\n98:\
      \         memForRead.zipWithIndex.filter{ case (m, index) => (index % bankNum)
      == i }.map(_._1)\n99:       }\n100:       val bankWidth = bankNum.U.getWidth
      - 1\n101:       val hitBankWire = VecInit((0 until bankNum).map { case i =>
      r.addr(bankWidth - 1, 0) === i.U })\n102:       val hitBankReg = Reg(Vec(bankNum,
      Bool()))\n103:       hitBankReg := hitBankWire"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/Regfile.scala
    lines: 128-138
    context: "128:       }\n129:     }\n130:   }\n131: \n132:   for (rport <- io.debug_rports)
      {\n133:     rport.data := memForRead(rport.addr)\n134:   }\n135: }\n136: \n\
      137: object Regfile {\n138:   // non-return version"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/Regfile.scala
    lines: 166-176
    context: "166:     rdata := regfile.io.readPorts.zip(raddr).map { case (rport,
      addr) =>\n167:       rport.addr := addr\n168:       rport.data\n169:     }\n\
      170: \n171:     regfile.io.writePorts.zip(wen).zip(waddr).zip(wdata).foreach{
      case (((wport, en), addr), data) =>\n172:       wport.wen := en\n173:      \
      \ wport.addr := addr\n174:       wport.data := data\n175:     }\n176:     if
      (withReset) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/Regfile.scala
    lines: 239-253
    context: "239:     debugReadData: Option[Vec[UInt]],\n240:     withReset    :
      Boolean = false,\n241:     bankNum      : Int,\n242:  )(implicit p: Parameters):
      Unit = {\n243:     require(Seq(1, 2, 4, 8).contains(splitNum))\n244:     val
      rdataVec = Wire(Vec(splitNum, Vec(rdata.length, UInt((rdata.head.getWidth /
      splitNum).W))))\n245:     rdata.zipWithIndex.map{ case (r, i) =>\n246:     \
      \  r := Cat((0 until splitNum).map(x => rdataVec(x)(i)).reverse)\n247:     }\n\
      248:     val debugReadDataVec = OptionWrapper(debugReadData.nonEmpty, Wire(Vec(splitNum,
      Vec(debugReadData.get.length, UInt((debugReadData.get.head.getWidth / splitNum).W)))))\n\
      249:     if (debugReadData.nonEmpty) {\n250:       debugReadData.get.zipWithIndex.map
      { case (r, i) =>\n251:         r := Cat((0 until splitNum).map(x => debugReadDataVec.get(x)(i)).reverse)\n\
      252:       }\n253:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/Regfile.scala
    lines: 302-316
    context: "302:              withReset    : Boolean = false,\n303:            \
      \  bankNum      : Int,\n304:              isVlRegfile  : Boolean = false,\n\
      305:            )(implicit p: Parameters): Unit = {\n306:     require(Seq(1,
      2, 4, 8).contains(splitNum))\n307:     val rdataVec = Wire(Vec(splitNum, Vec(rdata.length,
      UInt((rdata.head.getWidth / splitNum).W))))\n308:     rdata.zipWithIndex.map{
      case (r, i) =>\n309:       r := Cat((0 until splitNum).map(x => rdataVec(x)(i)).reverse)\n\
      310:     }\n311:     val debugReadDataVec = OptionWrapper(debugReadData.nonEmpty,
      Wire(Vec(splitNum, Vec(debugReadData.get.length, UInt((debugReadData.get.head.getWidth
      / splitNum).W)))))\n312:     if (debugReadData.nonEmpty) {\n313:       debugReadData.get.zipWithIndex.map
      { case (r, i) =>\n314:         r := Cat((0 until splitNum).map(x => debugReadDataVec.get(x)(i)).reverse)\n\
      315:       }\n316:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/regfile/Regfile.scala
    lines: 344-359
    context: "344:   )(implicit p: Parameters): Unit = {\n345:     require(splitNum
      >= 1, \"splitNum should be no less than 1\")\n346:     require(splitNum == wen.length,
      \"splitNum should be equal to length of wen vec\")\n347:     if (splitNum ==
      1) {\n348:       Regfile(\n349:         name, numEntries, raddr, rdata, wen.head,
      waddr, wdata,\n350:         hasZero = false, withReset, bankNum = 1, debugReadAddr,
      debugReadData)\n351:     } else {\n352:       val dataWidth = wdata.head.getWidth
      / splitNum\n353:       val numReadPorts = raddr.length\n354:       require(splitNum
      > 1 && wdata.head.getWidth == dataWidth * splitNum)\n355:       val wdataVec
      = Wire(Vec(splitNum, Vec(wdata.length, UInt(dataWidth.W))))\n356:       val
      rdataVec = Wire(Vec(splitNum, Vec(raddr.length, UInt(dataWidth.W))))\n357: \
      \      val debugRDataVec: Option[Vec[Vec[UInt]]] = debugReadData.map(x => Wire(Vec(splitNum,
      Vec(x.length, UInt(dataWidth.W)))))\n358:       for (i <- 0 until splitNum)
      {\n359:         wdataVec(i) := wdata.map(_ ((i + 1) * dataWidth - 1, i * dataWidth))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/DataArray.scala
    lines: 15-39
    context: "15:   val en = Input(Bool())\n16:   val addr = Input(UInt(addrLen.W))\n\
      17:   val data = Input(gen)\n18: }\n19: \n20: class DataArrayIO[T <: Data](gen:
      T, numRead: Int, numWrite: Int, numEntries: Int) extends Bundle {\n21:   val
      read = Vec(numRead, new OHReadBundle(numEntries, gen))\n22:   val write = Vec(numWrite,
      new OHWriteBundle(numEntries, gen))\n23: }\n24: \n25: class DataArray[T <: Data](gen:
      T, numRead: Int, numWrite: Int, numEntries: Int)\n26:   (implicit p: Parameters)\n\
      27:   extends XSModule {\n28: \n29:   val io = IO(new DataArrayIO(gen, numRead,
      numWrite, numEntries))\n30: \n31:   private val dataModule = Module(new AsyncRawDataModuleTemplate(gen,
      numEntries, io.read.length, io.write.length))\n32: \n33:   dataModule.io.rvec\
      \  := VecInit(io.read.map(_.addr))\n34:   io.read.zip(dataModule.io.rdata).foreach
      { case (l, r) => l.data := r}\n35: \n36:   dataModule.io.wvec  := VecInit(io.write.map(_.addr))\n\
      37:   dataModule.io.wen   := VecInit(io.write.map(_.en))\n38:   dataModule.io.wdata
      := VecInit(io.write.map(_.data))\n39: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 44-54
    context: "44: \n45: class IssueQueueDeqRespBundle(implicit p:Parameters, params:
      IssueBlockParams) extends EntryDeqRespBundle\n46: \n47: class IssueQueueIO()(implicit
      p: Parameters, params: IssueBlockParams) extends XSBundle {\n48:   // Inputs\n\
      49:   val flush = Flipped(ValidIO(new Redirect))\n50:   val enq = Vec(params.numEnq,
      Flipped(DecoupledIO(new DynInst)))\n51: \n52:   val og0Resp = Vec(params.numDeq,
      Flipped(ValidIO(new IssueQueueDeqRespBundle)))\n53:   val og1Resp = Vec(params.numDeq,
      Flipped(ValidIO(new IssueQueueDeqRespBundle)))\n54:   val og2Resp = Option.when(params.needOg2Resp)(Vec(params.numDeq,
      Flipped(ValidIO(new IssueQueueDeqRespBundle))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 55-68
    context: "55:   val finalIssueResp = Option.when(params.LdExuCnt > 0 || params.VlduCnt
      > 0)(Vec(params.numDeq, Flipped(ValidIO(new IssueQueueDeqRespBundle))))\n56:\
      \   val memAddrIssueResp = Option.when(params.LdExuCnt > 0)(Vec(params.numDeq,
      Flipped(ValidIO(new IssueQueueDeqRespBundle))))\n57:   val vecLoadIssueResp
      = Option.when(params.VlduCnt > 0)(Vec(params.numDeq, Flipped(ValidIO(new IssueQueueDeqRespBundle))))\n\
      58:   val wbBusyTableRead = Input(params.genWbFuBusyTableReadBundle)\n59:  \
      \ val wbBusyTableWrite = Output(params.genWbFuBusyTableWriteBundle)\n60:   val
      wakeupFromWB: MixedVec[ValidIO[IssueQueueWBWakeUpBundle]] = Flipped(params.genWBWakeUpSinkValidBundle)\n\
      61:   val wakeupFromIQ: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]] = Flipped(params.genIQWakeUpSinkValidBundle)\n\
      62:   val wakeupFromWBDelayed: MixedVec[ValidIO[IssueQueueWBWakeUpBundle]] =
      Flipped(params.genWBWakeUpSinkValidBundle)\n63:   val wakeupFromIQDelayed: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]]
      = Flipped(params.genIQWakeUpSinkValidBundle)\n64:   val vlFromIntIsZero = Input(Bool())\n\
      65:   val vlFromIntIsVlmax = Input(Bool())\n66:   val vlFromVfIsZero = Input(Bool())\n\
      67:   val vlFromVfIsVlmax = Input(Bool())\n68:   val og0Cancel = Input(ExuVec())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 69-84
    context: "69:   val og1Cancel = Input(ExuVec())\n70:   val ldCancel = Vec(backendParams.LduCnt
      + backendParams.HyuCnt, Flipped(new LoadCancelIO))\n71:   val replaceRCIdx =
      Option.when(params.needWriteRegCache)(Vec(params.numDeq, Input(UInt(RegCacheIdxWidth.W))))\n\
      72: \n73:   // Outputs\n74:   val wakeupToIQ: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]]
      = params.genIQWakeUpSourceValidBundle\n75:   val status = Output(new IssueQueueStatusBundle(params.numEnq,
      params.numEntries))\n76:   val validCntDeqVec = Output(Vec(params.numDeq,UInt(params.numEntries.U.getWidth.W)))\n\
      77:   // val statusNext = Output(new IssueQueueStatusBundle(params.numEnq))\n\
      78: \n79:   val deqDelay: MixedVec[DecoupledIO[IssueQueueIssueBundle]] = params.genIssueDecoupledBundle//
      = deq.cloneType\n80:   def allWakeUp = wakeupFromWB ++ wakeupFromIQ\n81: }\n\
      82: \n83: class IssueQueueImp(override val wrapper: IssueQueue)(implicit p:
      Parameters, val params: IssueBlockParams)\n84:   extends LazyModuleImp(wrapper)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 112-122
    context: "112:       s\"exuSourcesEncodeMask: ${\"0\" * (p(XSCoreParamsKey).backendParams.numExu
      - exuSourcesEncodeString.length) + exuSourcesEncodeString}\")\n113:   }\n114:\
      \ \n115:   lazy val io = IO(new IssueQueueIO())\n116: \n117:   io.enq.zipWithIndex.foreach
      { case (enq, i) =>\n118:     PerfCCT.updateInstPos(enq.bits.debug_seqNum, PerfCCT.InstPos.AtIssueQue.id.U,
      enq.valid, clock, reset)\n119:   }\n120: \n121:   // Modules\n122:   val entries
      = Module(new Entries)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 132-142
    context: "132:   val v0WbBusyTableRead = params.exuBlockParams.map { case x =>
      Option.when(x.v0LatencyCertain)(Module(new FuBusyTableRead(x.v0FuLatencyMap)))
      }\n133:   val vlWbBusyTableWrite = params.exuBlockParams.map { case x => Option.when(x.vlLatencyCertain)(Module(new
      FuBusyTableWrite(x.vlFuLatencyMap))) }\n134:   val vlWbBusyTableRead = params.exuBlockParams.map
      { case x => Option.when(x.vlLatencyCertain)(Module(new FuBusyTableRead(x.vlFuLatencyMap)))
      }\n135: \n136:   class WakeupQueueFlush extends Bundle {\n137:     val redirect
      = ValidIO(new Redirect)\n138:     val ldCancel = Vec(backendParams.LduCnt +
      backendParams.HyuCnt, new LoadCancelIO)\n139:     val og0Fail = Output(Bool())\n\
      140:     val og1Fail = Output(Bool())\n141:   }\n142: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 138-156
    context: "138:     val ldCancel = Vec(backendParams.LduCnt + backendParams.HyuCnt,
      new LoadCancelIO)\n139:     val og0Fail = Output(Bool())\n140:     val og1Fail
      = Output(Bool())\n141:   }\n142: \n143:   private def flushFunc(exuInput: ExuInput,
      flush: WakeupQueueFlush, stage: Int): Bool = {\n144:     val redirectFlush =
      exuInput.robIdx.needFlush(flush.redirect)\n145:     val loadDependencyFlush
      = LoadShouldCancel(exuInput.loadDependency, flush.ldCancel)\n146:     val ogFailFlush
      = stage match {\n147:       case 1 => flush.og0Fail\n148:       case 2 => flush.og1Fail\n\
      149:       case _ => false.B\n150:     }\n151:     redirectFlush || loadDependencyFlush
      || ogFailFlush\n152:   }\n153: \n154:   private def modificationFunc(exuInput:
      ExuInput): ExuInput = {\n155:     val newExuInput = WireDefault(exuInput)\n\
      156:     newExuInput.loadDependency match {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 152-162
    context: "152:   }\n153: \n154:   private def modificationFunc(exuInput: ExuInput):
      ExuInput = {\n155:     val newExuInput = WireDefault(exuInput)\n156:     newExuInput.loadDependency
      match {\n157:       case Some(deps) => deps.zip(exuInput.loadDependency.get).foreach(x
      => x._1 := x._2 << 1)\n158:       case None =>\n159:     }\n160:     newExuInput\n\
      161:   }\n162: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 161-171
    context: "161:   }\n162: \n163:   private def lastConnectFunc(exuInput: ExuInput,
      newInput: ExuInput): ExuInput = {\n164:     val lastExuInput = WireDefault(exuInput)\n\
      165:     val newExuInput = WireDefault(newInput)\n166:     newExuInput.elements.foreach
      { case (name, data) =>\n167:       if (lastExuInput.elements.contains(name))
      {\n168:         data := lastExuInput.elements(name)\n169:       }\n170:    \
      \ }\n171:     if (newExuInput.pdestCopy.nonEmpty && !lastExuInput.pdestCopy.nonEmpty)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 167-195
    context: "167:       if (lastExuInput.elements.contains(name)) {\n168:       \
      \  data := lastExuInput.elements(name)\n169:       }\n170:     }\n171:     if
      (newExuInput.pdestCopy.nonEmpty && !lastExuInput.pdestCopy.nonEmpty) {\n172:\
      \       newExuInput.pdestCopy.get.foreach(_ := lastExuInput.pdest)\n173:   \
      \  }\n174:     if (newExuInput.rfWenCopy.nonEmpty && !lastExuInput.rfWenCopy.nonEmpty)
      {\n175:       newExuInput.rfWenCopy.get.foreach(_ := lastExuInput.rfWen.get)\n\
      176:     }\n177:     if (newExuInput.fpWenCopy.nonEmpty && !lastExuInput.fpWenCopy.nonEmpty)
      {\n178:       newExuInput.fpWenCopy.get.foreach(_ := lastExuInput.fpWen.get)\n\
      179:     }\n180:     if (newExuInput.vecWenCopy.nonEmpty && !lastExuInput.vecWenCopy.nonEmpty)
      {\n181:       newExuInput.vecWenCopy.get.foreach(_ := lastExuInput.vecWen.get)\n\
      182:     }\n183:     if (newExuInput.v0WenCopy.nonEmpty && !lastExuInput.v0WenCopy.nonEmpty)
      {\n184:       newExuInput.v0WenCopy.get.foreach(_ := lastExuInput.v0Wen.get)\n\
      185:     }\n186:     if (newExuInput.vlWenCopy.nonEmpty && !lastExuInput.vlWenCopy.nonEmpty)
      {\n187:       newExuInput.vlWenCopy.get.foreach(_ := lastExuInput.vlWen.get)\n\
      188:     }\n189:     if (newExuInput.loadDependencyCopy.nonEmpty && !lastExuInput.loadDependencyCopy.nonEmpty)
      {\n190:       newExuInput.loadDependencyCopy.get.foreach(_ := lastExuInput.loadDependency.get)\n\
      191:     }\n192:     newExuInput\n193:   }\n194: \n195:   val wakeUpQueues:
      Seq[Option[MultiWakeupQueue[ExuInput, WakeupQueueFlush]]] = params.exuBlockParams.map
      { x => Option.when(x.isIQWakeUpSource && !x.hasLoadExu)(Module("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 191-201
    context: "191:     }\n192:     newExuInput\n193:   }\n194: \n195:   val wakeUpQueues:
      Seq[Option[MultiWakeupQueue[ExuInput, WakeupQueueFlush]]] = params.exuBlockParams.map
      { x => Option.when(x.isIQWakeUpSource && !x.hasLoadExu)(Module(\n196:     new
      MultiWakeupQueue(new ExuInput(x), new ExuInput(x, x.copyWakeupOut, x.copyNum),
      new WakeupQueueFlush, x.wakeUpFuLatancySet, flushFunc, modificationFunc, lastConnectFunc)\n\
      197:   ))}\n198:   val deqBeforeDly = Wire(params.genIssueDecoupledBundle)\n\
      199: \n200:   val intWbBusyTableIn = io.wbBusyTableRead.map(_.intWbBusyTable)\n\
      201:   val fpWbBusyTableIn = io.wbBusyTableRead.map(_.fpWbBusyTable)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 222-234
    context: "222:   val v0WbBusyTableMask = Wire(Vec(params.numDeq, UInt(params.numEntries.W)))\n\
      223:   val vlWbBusyTableMask = Wire(Vec(params.numDeq, UInt(params.numEntries.W)))\n\
      224: \n225:   val s0_enqValidVec = io.enq.map(_.valid)\n226:   val s0_enqSelValidVec
      = Wire(Vec(params.numEnq, Bool()))\n227:   val s0_enqNotFlush = !io.flush.valid\n\
      228:   val s0_enqBits = WireInit(VecInit(io.enq.map(_.bits)))\n229:   val s0_doEnqSelValidVec
      = s0_enqSelValidVec.map(_ && s0_enqNotFlush) //enqValid && notFlush && enqReady\n\
      230: \n231: \n232:   val finalDeqSelValidVec = Wire(Vec(params.numDeq, Bool()))\n\
      233:   val finalDeqSelOHVec    = Wire(Vec(params.numDeq, UInt(params.numEntries.W)))\n\
      234: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 269-288
    context: "269:   //trans\n270:   val simpEntryEnqSelVec = Option.when(params.hasCompAndSimp)(Wire(Vec(params.numEnq,
      UInt(params.numSimp.W))))\n271:   val compEntryEnqSelVec = Option.when(params.hasCompAndSimp)(Wire(Vec(params.numEnq,
      UInt(params.numComp.W))))\n272:   val othersEntryEnqSelVec = Option.when(params.isAllComp
      || params.isAllSimp)(Wire(Vec(params.numEnq, UInt((params.numEntries - params.numEnq).W))))\n\
      273:   val simpAgeDetectRequest = Option.when(params.hasCompAndSimp)(Wire(Vec(params.numDeq
      + params.numEnq, UInt(params.numSimp.W))))\n274:   simpAgeDetectRequest.foreach(_
      := 0.U.asTypeOf(simpAgeDetectRequest.get))\n275: \n276:   // when vf exu (with
      og2) wake up int/mem iq (without og2), the wakeup signals should delay 1 cycle\n\
      277:   // as vf exu's min latency is 1, we do not need consider og0cancel\n\
      278:   val wakeupFromIQ = Wire(chiselTypeOf(io.wakeupFromIQ))\n279:   wakeupFromIQ.zip(io.wakeupFromIQ).foreach
      { case (w, w_src) =>\n280:     if (!params.inVfSchd && params.readVfRf && params.hasWakeupFromVf
      && w_src.bits.params.isVfExeUnit) {\n281:       val noCancel = !LoadShouldCancel(Some(w_src.bits.loadDependency),
      io.ldCancel)\n282:       w := RegNext(Mux(noCancel, w_src, 0.U.asTypeOf(w)))\n\
      283:       w.bits.loadDependency.zip(w_src.bits.loadDependency).foreach{ case
      (ld, ld_src) => ld := RegNext(Mux(noCancel, ld_src << 1, 0.U.asTypeOf(ld)))
      }\n284:     } else {\n285:       w := w_src\n286:     }\n287:   }\n288:   val
      wakeupFromIQDelayed = Wire(chiselTypeOf(io.wakeupFromIQDelayed))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 284-298
    context: "284:     } else {\n285:       w := w_src\n286:     }\n287:   }\n288:\
      \   val wakeupFromIQDelayed = Wire(chiselTypeOf(io.wakeupFromIQDelayed))\n289:\
      \   wakeupFromIQDelayed.zip(io.wakeupFromIQDelayed).foreach { case (w, w_src)
      =>\n290:     if (!params.inVfSchd && params.readVfRf && params.hasWakeupFromVf
      && w_src.bits.params.isVfExeUnit) {\n291:       val noCancel = !LoadShouldCancel(Some(w_src.bits.loadDependency),
      io.ldCancel)\n292:       w := RegNext(Mux(noCancel, w_src, 0.U.asTypeOf(w)))\n\
      293:       w.bits.loadDependency.zip(w_src.bits.loadDependency).foreach { case
      (ld, ld_src) => ld := RegNext(Mux(noCancel, ld_src << 1, 0.U.asTypeOf(ld)))
      }\n294:     } else {\n295:       w := w_src\n296:     }\n297:   }\n298: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 298-312
    context: "298: \n299:   /**\n300:     * Connection of [[entries]]\n301:     */\n\
      302:   entries.io match { case entriesIO: EntriesIO =>\n303:     entriesIO.flush\
      \                                             := io.flush\n304:     entriesIO.enq.zipWithIndex.foreach
      { case (enq, enqIdx) =>\n305:       enq.valid                              \
      \                   := s0_doEnqSelValidVec(enqIdx)\n306:       enq.bits.status.robIdx\
      \                                    := s0_enqBits(enqIdx).robIdx\n307:    \
      \   enq.bits.status.fuType                                    := IQFuType.readFuType(VecInit(s0_enqBits(enqIdx).fuType.asBools),
      params.getFuCfgs.map(_.fuType))\n308:       val numLsrc = s0_enqBits(enqIdx).srcType.size.min(enq.bits.status.srcStatus.map(_.srcType).size)\n\
      309:       for(j <- 0 until numLsrc) {\n310:         enq.bits.status.srcStatus(j).psrc\
      \                       := s0_enqBits(enqIdx).psrc(j)\n311:         enq.bits.status.srcStatus(j).srcType\
      \                    := s0_enqBits(enqIdx).srcType(j)\n312:         enq.bits.status.srcStatus(j).srcState\
      \                   := (if (j < 3) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 309-319
    context: "309:       for(j <- 0 until numLsrc) {\n310:         enq.bits.status.srcStatus(j).psrc\
      \                       := s0_enqBits(enqIdx).psrc(j)\n311:         enq.bits.status.srcStatus(j).srcType\
      \                    := s0_enqBits(enqIdx).srcType(j)\n312:         enq.bits.status.srcStatus(j).srcState\
      \                   := (if (j < 3) {\n313:                                 \
      \                                      Mux(SrcType.isVp(s0_enqBits(enqIdx).srcType(j))
      && (s0_enqBits(enqIdx).psrc(j) === 0.U),\n314:                             \
      \                                              SrcState.rdy,\n315:         \
      \                                                                  s0_enqBits(enqIdx).srcState(j))\n\
      316:                                                                     } else
      {\n317:                                                                    \
      \   s0_enqBits(enqIdx).srcState(j)\n318:                                   \
      \                                  })\n319:         enq.bits.status.srcStatus(j).dataSources.value\
      \          := (if (j < 3) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 326-338
    context: "326:                                                               \
      \        MuxCase(DataSource.reg, Seq(\n327:                                \
      \                                         SrcType.isNotReg(s0_enqBits(enqIdx).srcType(j))\
      \  -> DataSource.imm,\n328:                                                \
      \                       ))\n329:                                           \
      \                          })\n330:         enq.bits.status.srcStatus(j).srcLoadDependency\
      \          := VecInit(s0_enqBits(enqIdx).srcLoadDependency(j).map(x => x <<
      1))\n331:         enq.bits.status.srcStatus(j).exuSources.foreach(_       :=
      0.U.asTypeOf(ExuSource()))\n332:         enq.bits.status.srcStatus(j).useRegCache.foreach(_\
      \      := s0_enqBits(enqIdx).useRegCache(j))\n333:         enq.bits.status.srcStatus(j).regCacheIdx.foreach(_\
      \      := s0_enqBits(enqIdx).regCacheIdx(j))\n334:       }\n335:       enq.bits.status.blocked\
      \                                   := false.B\n336:       enq.bits.status.issued\
      \                                    := false.B\n337:       enq.bits.status.firstIssue\
      \                                := false.B\n338:       enq.bits.status.issueTimer\
      \                                := \"b11\".U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 335-384
    context: "335:       enq.bits.status.blocked                                 \
      \  := false.B\n336:       enq.bits.status.issued                           \
      \         := false.B\n337:       enq.bits.status.firstIssue                \
      \                := false.B\n338:       enq.bits.status.issueTimer         \
      \                       := \"b11\".U\n339:       enq.bits.status.deqPortIdx\
      \                                := 0.U\n340:       enq.bits.imm.foreach(_ \
      \                                   := s0_enqBits(enqIdx).imm)\n341:       enq.bits.payload\
      \                                          := s0_enqBits(enqIdx)\n342:     }\n\
      343:     entriesIO.og0Resp.zipWithIndex.foreach { case (og0Resp, i) =>\n344:\
      \       og0Resp                                                   := io.og0Resp(i)\n\
      345:     }\n346:     entriesIO.og1Resp.zipWithIndex.foreach { case (og1Resp,
      i) =>\n347:       og1Resp                                                  \
      \ := io.og1Resp(i)\n348:     }\n349:     if (params.needOg2Resp) {\n350:   \
      \    entriesIO.og2Resp.get.zipWithIndex.foreach { case (og2Resp, i) =>\n351:\
      \         og2Resp                                                 := io.og2Resp.get(i)\n\
      352:       }\n353:     }\n354:     if (params.isLdAddrIQ || params.isHyAddrIQ)
      {\n355:       entriesIO.fromLoad.get.finalIssueResp.zipWithIndex.foreach { case
      (finalIssueResp, i) =>\n356:         finalIssueResp                        \
      \                  := io.finalIssueResp.get(i)\n357:       }\n358:       entriesIO.fromLoad.get.memAddrIssueResp.zipWithIndex.foreach
      { case (memAddrIssueResp, i) =>\n359:         memAddrIssueResp             \
      \                           := io.memAddrIssueResp.get(i)\n360:       }\n361:\
      \     }\n362:     if (params.isVecLduIQ) {\n363:       entriesIO.vecLdIn.get.finalIssueResp.zipWithIndex.foreach
      { case (resp, i) =>\n364:         resp := io.finalIssueResp.get(i)\n365:   \
      \    }\n366:       entriesIO.vecLdIn.get.resp.zipWithIndex.foreach { case (resp,
      i) =>\n367:         resp                                                   \
      \ := io.vecLoadIssueResp.get(i)\n368:       }\n369:     }\n370:     for(deqIdx
      <- 0 until params.numDeq) {\n371:       entriesIO.deqReady(deqIdx)         \
      \                       := deqBeforeDly(deqIdx).ready\n372:       entriesIO.deqSelOH(deqIdx).valid\
      \                          := deqSelValidVec(deqIdx)\n373:       entriesIO.deqSelOH(deqIdx).bits\
      \                           := deqSelOHVec(deqIdx)\n374:       entriesIO.enqEntryOldestSel(deqIdx)\
      \                       := enqEntryOldestSel(deqIdx)\n375:       entriesIO.simpEntryOldestSel.foreach(_(deqIdx)\
      \            := simpEntryOldestSel.get(deqIdx))\n376:       entriesIO.compEntryOldestSel.foreach(_(deqIdx)\
      \            := compEntryOldestSel.get(deqIdx))\n377:       entriesIO.othersEntryOldestSel.foreach(_(deqIdx)\
      \          := othersEntryOldestSel(deqIdx))\n378:       entriesIO.subDeqRequest.foreach(_(deqIdx)\
      \                 := subDeqRequest.get)\n379:       entriesIO.subDeqSelOH.foreach(_(deqIdx)\
      \                   := subDeqSelOHVec.get(deqIdx))\n380:     }\n381:     entriesIO.wakeUpFromWB\
      \                                      := io.wakeupFromWB\n382:     entriesIO.wakeUpFromIQ\
      \                                      := wakeupFromIQ\n383:     entriesIO.wakeUpFromWBDelayed\
      \                               := io.wakeupFromWBDelayed\n384:     entriesIO.wakeUpFromIQDelayed\
      \                               := wakeupFromIQDelayed"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 387-408
    context: "387:     entriesIO.vlFromVfIsZero                                  \
      \  := io.vlFromVfIsZero\n388:     entriesIO.vlFromVfIsVlmax                \
      \                   := io.vlFromVfIsVlmax\n389:     entriesIO.og0Cancel    \
      \                                     := io.og0Cancel\n390:     entriesIO.og1Cancel\
      \                                         := io.og1Cancel\n391:     entriesIO.ldCancel\
      \                                          := io.ldCancel\n392:     entriesIO.simpEntryDeqSelVec.foreach(_\
      \                      := VecInit(simpEntryOldestSel.get.takeRight(params.numEnq).map(_.bits)))\n\
      393:     //output\n394:     fuTypeVec                                      \
      \             := entriesIO.fuType\n395:     deqEntryVec                    \
      \                             := entriesIO.deqEntry\n396:     cancelDeqVec \
      \                                               := entriesIO.cancelDeqVec\n\
      397:     simpEntryEnqSelVec.foreach(_                                := entriesIO.simpEntryEnqSelVec.get)\n\
      398:     compEntryEnqSelVec.foreach(_                                := entriesIO.compEntryEnqSelVec.get)\n\
      399:     othersEntryEnqSelVec.foreach(_                              := entriesIO.othersEntryEnqSelVec.get)\n\
      400:   }\n401: \n402: \n403:   s0_enqSelValidVec := s0_enqValidVec.zip(io.enq).map{
      case (enqValid, enq) => enqValid && enq.ready}\n404: \n405:   protected val
      commonAccept: UInt = Cat(fuTypeVec.map(fuType =>\n406:     FuType.FuTypeOrR(fuType,
      commonFuCfgs.map(_.fuType))\n407:   ).reverse)\n408: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 416-426
    context: "416:   protected val deqCanAcceptVec: Seq[IndexedSeq[Bool]] = deqFuCfgs.map
      { fuCfgs: Seq[FuConfig] =>\n417:     fuTypeVec.map(fuType =>\n418:       FuType.FuTypeOrR(fuType,
      fuCfgs.map(_.fuType)))\n419:   }\n420: \n421:   canIssueMergeAllBusy.zipWithIndex.foreach
      { case (merge, i) =>\n422:     val mergeFuBusy = {\n423:       if (fuBusyTableWrite(i).nonEmpty)
      canIssueVec.asUInt & (~fuBusyTableMask(i))\n424:       else canIssueVec.asUInt\n\
      425:     }\n426:     val mergeIntWbBusy = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 444-454
    context: "444:       else  mergeV0WbBusy\n445:     }\n446:     merge := mergeVlWbBusy\n\
      447:   }\n448: \n449:   deqCanIssue.zipWithIndex.foreach { case (req, i) =>\n\
      450:     req := canIssueMergeAllBusy(i) & VecInit(deqCanAcceptVec(i)).asUInt\n\
      451:   }\n452:   dontTouch(fuTypeVec)\n453:   dontTouch(canIssueMergeAllBusy)\n\
      454:   dontTouch(deqCanIssue)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 511-522
    context: "511:     deqSelOHVec(0) := Mux(othersEntryOldestSel(0).valid,\n512:\
      \                           Cat(othersEntryOldestSel(0).bits, 0.U((params.numEnq).W)),\n\
      513:                           subDeqSelOHVec.get(1)) & canIssueMergeAllBusy(0)\n\
      514:     deqSelOHVec(1) := subDeqSelOHVec.get(0) & canIssueMergeAllBusy(1)\n\
      515: \n516:     finalDeqSelValidVec.zip(finalDeqSelOHVec).zip(deqSelValidVec).zip(deqSelOHVec).zipWithIndex.foreach
      { case ((((selValid, selOH), deqValid), deqOH), i) =>\n517:       selValid :=
      deqValid && deqOH.orR\n518:       selOH := deqOH\n519:     }\n520:   }\n521:\
      \   else {\n522:     enqEntryOldestSel := NewAgeDetector(numEntries = params.numEnq,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 528-543
    context: "528:       othersEntryOldestSel := AgeDetector(numEntries = params.numEntries
      - params.numEnq,\n529:         enq = othersEntryEnqSelVec.get,\n530:       \
      \  canIssue = VecInit(deqCanIssue.map(_(params.numEntries - 1, params.numEnq)))\n\
      531:       )\n532: \n533:       deqSelValidVec.zip(deqSelOHVec).zipWithIndex.foreach
      { case ((selValid, selOH), i) =>\n534:         if (params.exuBlockParams(i).fuConfigs.contains(FuConfig.FakeHystaCfg))
      {\n535:           selValid := false.B\n536:           selOH := 0.U.asTypeOf(selOH)\n\
      537:         } else {\n538:           selValid := othersEntryOldestSel(i).valid
      || enqEntryOldestSel(i).valid\n539:           selOH := Cat(othersEntryOldestSel(i).bits,
      Fill(params.numEnq, !othersEntryOldestSel(i).valid) & enqEntryOldestSel(i).bits)\n\
      540:         }\n541:       }\n542:     }\n543:     else {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 541-551
    context: "541:       }\n542:     }\n543:     else {\n544:       othersEntryOldestSel
      := DontCare\n545: \n546:       deqCanIssue.zipWithIndex.foreach { case (req,
      i) =>\n547:         simpAgeDetectRequest.get(i) := req(params.numEnq + params.numSimp
      - 1, params.numEnq)\n548:       }\n549:       simpAgeDetectRequest.get(params.numDeq)
      := VecInit(requestForTrans.drop(params.numEnq).take(params.numSimp)).asUInt\n\
      550:       if (params.numEnq == 2) {\n551:         simpAgeDetectRequest.get(params.numDeq
      + 1) := VecInit(requestForTrans.drop(params.numEnq).take(params.numSimp)).asUInt
      & ~simpEntryOldestSel.get(params.numDeq).bits"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 559-574
    context: "559:       compEntryOldestSel.get := AgeDetector(numEntries = params.numComp,\n\
      560:         enq = compEntryEnqSelVec.get,\n561:         canIssue = VecInit(deqCanIssue.map(_(params.numEntries
      - 1, params.numEnq + params.numSimp)))\n562:       )\n563: \n564:       deqSelValidVec.zip(deqSelOHVec).zipWithIndex.foreach
      { case ((selValid, selOH), i) =>\n565:         if (params.exuBlockParams(i).fuConfigs.contains(FuConfig.FakeHystaCfg))
      {\n566:           selValid := false.B\n567:           selOH := 0.U.asTypeOf(selOH)\n\
      568:         } else {\n569:           selValid := compEntryOldestSel.get(i).valid
      || simpEntryOldestSel.get(i).valid || enqEntryOldestSel(i).valid\n570:     \
      \      selOH := Cat(\n571:             compEntryOldestSel.get(i).bits,\n572:\
      \             Fill(params.numSimp, !compEntryOldestSel.get(i).valid) & simpEntryOldestSel.get(i).bits,\n\
      573:             Fill(params.numEnq, !compEntryOldestSel.get(i).valid && !simpEntryOldestSel.get(i).valid)
      & enqEntryOldestSel(i).bits\n574:           )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 574-585
    context: "574:           )\n575:         }\n576:       }\n577:     }\n578: \n\
      579:     finalDeqSelValidVec.zip(finalDeqSelOHVec).zip(deqSelValidVec).zip(deqSelOHVec).zipWithIndex.foreach
      { case ((((selValid, selOH), deqValid), deqOH), i) =>\n580:       selValid :=
      deqValid\n581:       selOH := deqOH\n582:     }\n583:   }\n584: \n585:   val
      toBusyTableDeqResp = Wire(Vec(params.numDeq, ValidIO(new IssueQueueDeqRespBundle)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 582-603
    context: "582:     }\n583:   }\n584: \n585:   val toBusyTableDeqResp = Wire(Vec(params.numDeq,
      ValidIO(new IssueQueueDeqRespBundle)))\n586: \n587:   toBusyTableDeqResp.zipWithIndex.foreach
      { case (deqResp, i) =>\n588:     deqResp.valid := deqBeforeDly(i).valid\n589:\
      \     deqResp.bits.resp   := RespType.success\n590:     deqResp.bits.robIdx
      := DontCare\n591:     deqResp.bits.sqIdx.foreach(_ := DontCare)\n592:     deqResp.bits.lqIdx.foreach(_
      := DontCare)\n593:     deqResp.bits.fuType := deqBeforeDly(i).bits.common.fuType\n\
      594:     deqResp.bits.uopIdx.foreach(_ := DontCare)\n595:   }\n596: \n597: \
      \  //fuBusyTable\n598:   fuBusyTableWrite.zip(fuBusyTableRead).zipWithIndex.foreach
      { case ((busyTableWrite: Option[FuBusyTableWrite], busyTableRead: Option[FuBusyTableRead]),
      i) =>\n599:     if(busyTableWrite.nonEmpty) {\n600:       val btwr = busyTableWrite.get\n\
      601:       val btrd = busyTableRead.get\n602:       btwr.io.in.deqResp := toBusyTableDeqResp(i)\n\
      603:       btwr.io.in.og0Resp := io.og0Resp(i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 610-620
    context: "610:       fuBusyTableMask(i) := 0.U(params.numEntries.W)\n611:    \
      \ }\n612:   }\n613: \n614:   //wbfuBusyTable write\n615:   intWbBusyTableWrite.zip(intWbBusyTableOut).zip(intDeqRespSetOut).zipWithIndex.foreach
      { case (((busyTableWrite: Option[FuBusyTableWrite], busyTable: Option[UInt]),
      deqResp), i) =>\n616:     if(busyTableWrite.nonEmpty) {\n617:       val btwr
      = busyTableWrite.get\n618:       val bt = busyTable.get\n619:       val dq =
      deqResp.get\n620:       btwr.io.in.deqResp := toBusyTableDeqResp(i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 624-634
    context: "624:       bt := btwr.io.out.fuBusyTable\n625:       dq := btwr.io.out.deqRespSet\n\
      626:     }\n627:   }\n628: \n629:   fpWbBusyTableWrite.zip(fpWbBusyTableOut).zip(fpDeqRespSetOut).zipWithIndex.foreach
      { case (((busyTableWrite: Option[FuBusyTableWrite], busyTable: Option[UInt]),
      deqResp), i) =>\n630:     if (busyTableWrite.nonEmpty) {\n631:       val btwr
      = busyTableWrite.get\n632:       val bt = busyTable.get\n633:       val dq =
      deqResp.get\n634:       btwr.io.in.deqResp := toBusyTableDeqResp(i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 638-648
    context: "638:       bt := btwr.io.out.fuBusyTable\n639:       dq := btwr.io.out.deqRespSet\n\
      640:     }\n641:   }\n642: \n643:   vfWbBusyTableWrite.zip(vfWbBusyTableOut).zip(vfDeqRespSetOut).zipWithIndex.foreach
      { case (((busyTableWrite: Option[FuBusyTableWrite], busyTable: Option[UInt]),
      deqResp), i) =>\n644:     if (busyTableWrite.nonEmpty) {\n645:       val btwr
      = busyTableWrite.get\n646:       val bt = busyTable.get\n647:       val dq =
      deqResp.get\n648:       btwr.io.in.deqResp := toBusyTableDeqResp(i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 652-662
    context: "652:       bt := btwr.io.out.fuBusyTable\n653:       dq := btwr.io.out.deqRespSet\n\
      654:     }\n655:   }\n656: \n657:   v0WbBusyTableWrite.zip(v0WbBusyTableOut).zip(v0DeqRespSetOut).zipWithIndex.foreach
      { case (((busyTableWrite: Option[FuBusyTableWrite], busyTable: Option[UInt]),
      deqResp), i) =>\n658:     if (busyTableWrite.nonEmpty) {\n659:       val btwr
      = busyTableWrite.get\n660:       val bt = busyTable.get\n661:       val dq =
      deqResp.get\n662:       btwr.io.in.deqResp := toBusyTableDeqResp(i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 666-676
    context: "666:       bt := btwr.io.out.fuBusyTable\n667:       dq := btwr.io.out.deqRespSet\n\
      668:     }\n669:   }\n670: \n671:   vlWbBusyTableWrite.zip(vlWbBusyTableOut).zip(vlDeqRespSetOut).zipWithIndex.foreach
      { case (((busyTableWrite: Option[FuBusyTableWrite], busyTable: Option[UInt]),
      deqResp), i) =>\n672:     if (busyTableWrite.nonEmpty) {\n673:       val btwr
      = busyTableWrite.get\n674:       val bt = busyTable.get\n675:       val dq =
      deqResp.get\n676:       btwr.io.in.deqResp := toBusyTableDeqResp(i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 681-691
    context: "681:       dq := btwr.io.out.deqRespSet\n682:     }\n683:   }\n684:\
      \ \n685:   //wbfuBusyTable read\n686:   intWbBusyTableRead.zip(intWbBusyTableIn).zipWithIndex.foreach
      { case ((busyTableRead: Option[FuBusyTableRead], busyTable: Option[UInt]), i)
      =>\n687:     if(busyTableRead.nonEmpty) {\n688:       val btrd = busyTableRead.get\n\
      689:       val bt = busyTable.get\n690:       btrd.io.in.fuBusyTable := bt\n\
      691:       btrd.io.in.fuTypeRegVec := fuTypeVec"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 693-703
    context: "693:     }\n694:     else {\n695:       intWbBusyTableMask(i) := 0.U(params.numEntries.W)\n\
      696:     }\n697:   }\n698:   fpWbBusyTableRead.zip(fpWbBusyTableIn).zipWithIndex.foreach
      { case ((busyTableRead: Option[FuBusyTableRead], busyTable: Option[UInt]), i)
      =>\n699:     if (busyTableRead.nonEmpty) {\n700:       val btrd = busyTableRead.get\n\
      701:       val bt = busyTable.get\n702:       btrd.io.in.fuBusyTable := bt\n\
      703:       btrd.io.in.fuTypeRegVec := fuTypeVec"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 705-715
    context: "705:     }\n706:     else {\n707:       fpWbBusyTableMask(i) := 0.U(params.numEntries.W)\n\
      708:     }\n709:   }\n710:   vfWbBusyTableRead.zip(vfWbBusyTableIn).zipWithIndex.foreach
      { case ((busyTableRead: Option[FuBusyTableRead], busyTable: Option[UInt]), i)
      =>\n711:     if (busyTableRead.nonEmpty) {\n712:       val btrd = busyTableRead.get\n\
      713:       val bt = busyTable.get\n714:       btrd.io.in.fuBusyTable := bt\n\
      715:       btrd.io.in.fuTypeRegVec := fuTypeVec"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 717-727
    context: "717:     }\n718:     else {\n719:       vfWbBusyTableMask(i) := 0.U(params.numEntries.W)\n\
      720:     }\n721:   }\n722:   v0WbBusyTableRead.zip(v0WbBusyTableIn).zipWithIndex.foreach
      { case ((busyTableRead: Option[FuBusyTableRead], busyTable: Option[UInt]), i)
      =>\n723:     if (busyTableRead.nonEmpty) {\n724:       val btrd = busyTableRead.get\n\
      725:       val bt = busyTable.get\n726:       btrd.io.in.fuBusyTable := bt\n\
      727:       btrd.io.in.fuTypeRegVec := fuTypeVec"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 729-739
    context: "729:     }\n730:     else {\n731:       v0WbBusyTableMask(i) := 0.U(params.numEntries.W)\n\
      732:     }\n733:   }\n734:   vlWbBusyTableRead.zip(vlWbBusyTableIn).zipWithIndex.foreach
      { case ((busyTableRead: Option[FuBusyTableRead], busyTable: Option[UInt]), i)
      =>\n735:     if (busyTableRead.nonEmpty) {\n736:       val btrd = busyTableRead.get\n\
      737:       val bt = busyTable.get\n738:       btrd.io.in.fuBusyTable := bt\n\
      739:       btrd.io.in.fuTypeRegVec := fuTypeVec"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 742-803
    context: "742:     else {\n743:       vlWbBusyTableMask(i) := 0.U(params.numEntries.W)\n\
      744:     }\n745:   }\n746: \n747:   wakeUpQueues.zipWithIndex.foreach { case
      (wakeUpQueueOption, i) =>\n748:     wakeUpQueueOption.foreach {\n749:      \
      \ wakeUpQueue =>\n750:         val flush = Wire(new WakeupQueueFlush)\n751:\
      \         flush.redirect := io.flush\n752:         flush.ldCancel := io.ldCancel\n\
      753:         flush.og0Fail := io.og0Resp(i).valid && RespType.isBlocked(io.og0Resp(i).bits.resp)\n\
      754:         flush.og1Fail := io.og1Resp(i).valid && RespType.isBlocked(io.og1Resp(i).bits.resp)\n\
      755:         wakeUpQueue.io.flush := flush\n756:         wakeUpQueue.io.enq.valid
      := deqBeforeDly(i).valid\n757:         wakeUpQueue.io.enq.bits.uop :<= deqBeforeDly(i).bits.common\n\
      758:         wakeUpQueue.io.enq.bits.uop.pdestCopy.foreach(_ := 0.U)\n759: \
      \        wakeUpQueue.io.enq.bits.lat := getDeqLat(i, deqBeforeDly(i).bits.common.fuType)\n\
      760:     }\n761:   }\n762: \n763:   deqBeforeDly.zipWithIndex.foreach { case
      (deq, i) =>\n764:     deq.valid                := finalDeqSelValidVec(i) &&
      !cancelDeqVec(i)\n765:     deq.bits.addrOH          := finalDeqSelOHVec(i)\n\
      766:     deq.bits.common.isFirstIssue := deqFirstIssueVec(i)\n767:     deq.bits.common.iqIdx\
      \    := OHToUInt(finalDeqSelOHVec(i))\n768:     deq.bits.common.fuType   :=
      IQFuType.readFuType(deqEntryVec(i).bits.status.fuType, params.getFuCfgs.map(_.fuType)).asUInt\n\
      769:     deq.bits.common.fuOpType := deqEntryVec(i).bits.payload.fuOpType\n\
      770:     deq.bits.common.rfWen.foreach(_ := deqEntryVec(i).bits.payload.rfWen)\n\
      771:     deq.bits.common.fpWen.foreach(_ := deqEntryVec(i).bits.payload.fpWen)\n\
      772:     deq.bits.common.vecWen.foreach(_ := deqEntryVec(i).bits.payload.vecWen)\n\
      773:     deq.bits.common.v0Wen.foreach(_ := deqEntryVec(i).bits.payload.v0Wen)\n\
      774:     deq.bits.common.vlWen.foreach(_ := deqEntryVec(i).bits.payload.vlWen)\n\
      775:     deq.bits.common.flushPipe.foreach(_ := deqEntryVec(i).bits.payload.flushPipe)\n\
      776:     deq.bits.common.pdest := deqEntryVec(i).bits.payload.pdest\n777:  \
      \   deq.bits.common.robIdx := deqEntryVec(i).bits.status.robIdx\n778: \n779:\
      \     require(deq.bits.common.dataSources.size <= finalDataSources(i).size)\n\
      780:     deq.bits.common.dataSources.zip(finalDataSources(i)).foreach { case
      (sink, source) => sink := source}\n781:     deq.bits.common.exuSources.foreach(_.zip(finalExuSources.get(i)).foreach
      { case (sink, source) => sink := source})\n782:     deq.bits.common.srcTimer.foreach(_
      := DontCare)\n783:     deq.bits.common.loadDependency.foreach(_.zip(finalLoadDependency(i)).foreach
      { case (sink, source) => sink := source})\n784:     deq.bits.common.src := DontCare\n\
      785:     deq.bits.common.preDecode.foreach(_ := deqEntryVec(i).bits.payload.preDecodeInfo)\n\
      786: \n787:     deq.bits.rf.zip(deqEntryVec(i).bits.status.srcStatus.map(_.psrc)).zip(deqEntryVec(i).bits.status.srcStatus.map(_.srcType)).foreach
      { case ((rf, psrc), srcType) =>\n788:       // psrc in status array can be pregIdx
      of IntRegFile or VfRegFile\n789:       rf.foreach(_.addr := psrc)\n790:    \
      \   rf.foreach(_.srcType := srcType)\n791:     }\n792:     deq.bits.srcType.zip(deqEntryVec(i).bits.status.srcStatus.map(_.srcType)).foreach
      { case (sink, source) =>\n793:       sink := source\n794:     }\n795:     deq.bits.immType
      := deqEntryVec(i).bits.payload.selImm\n796:     deq.bits.common.imm := deqEntryVec(i).bits.imm.getOrElse(0.U)\n\
      797:     deq.bits.common.nextPcOffset.foreach(_ := 0.U)\n798:     deq.bits.rcIdx.foreach(_
      := deqEntryVec(i).bits.status.srcStatus.map(_.regCacheIdx.get))\n799: \n800:\
      \     deq.bits.common.perfDebugInfo := deqEntryVec(i).bits.payload.debugInfo\n\
      801:     deq.bits.common.perfDebugInfo.selectTime := GTimer()\n802:     deq.bits.common.perfDebugInfo.issueTime
      := GTimer() + 1.U\n803:     deq.bits.common.debug_seqNum := deqEntryVec(i).bits.payload.debug_seqNum"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 802-812
    context: "802:     deq.bits.common.perfDebugInfo.issueTime := GTimer() + 1.U\n\
      803:     deq.bits.common.debug_seqNum := deqEntryVec(i).bits.payload.debug_seqNum\n\
      804:   }\n805: \n806:   val deqDelay = Reg(params.genIssueValidBundle)\n807:\
      \   deqDelay.zip(deqBeforeDly).foreach { case (deqDly, deq) =>\n808:     deqDly.valid
      := deq.valid\n809:     when(validVec.asUInt.orR) {\n810:       deqDly.bits :=
      deq.bits\n811:     }\n812:     // deqBeforeDly.ready is always true"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 808-820
    context: "808:     deqDly.valid := deq.valid\n809:     when(validVec.asUInt.orR)
      {\n810:       deqDly.bits := deq.bits\n811:     }\n812:     // deqBeforeDly.ready
      is always true\n813:     deq.ready := true.B\n814:   }\n815:   io.deqDelay.zip(deqDelay).foreach
      { case (sink, source) =>\n816:     sink.valid := source.valid\n817:     sink.bits
      := source.bits\n818:   }\n819:   if(backendParams.debugEn) {\n820:     dontTouch(deqDelay)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 819-829
    context: "819:   if(backendParams.debugEn) {\n820:     dontTouch(deqDelay)\n821:\
      \     dontTouch(io.deqDelay)\n822:     dontTouch(deqBeforeDly)\n823:   }\n824:\
      \   io.wakeupToIQ.zipWithIndex.foreach { case (wakeup, i) =>\n825:     if (wakeUpQueues(i).nonEmpty)
      {\n826:       wakeup.valid := wakeUpQueues(i).get.io.deq.valid\n827:       wakeup.bits.fromExuInput(wakeUpQueues(i).get.io.deq.bits)\n\
      828:       wakeup.bits.loadDependency := wakeUpQueues(i).get.io.deq.bits.loadDependency.getOrElse(0.U.asTypeOf(wakeup.bits.loadDependency))\n\
      829:       wakeup.bits.is0Lat := getDeqLat(i, wakeUpQueues(i).get.io.deq.bits.fuType)
      === 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 825-835
    context: "825:     if (wakeUpQueues(i).nonEmpty) {\n826:       wakeup.valid :=
      wakeUpQueues(i).get.io.deq.valid\n827:       wakeup.bits.fromExuInput(wakeUpQueues(i).get.io.deq.bits)\n\
      828:       wakeup.bits.loadDependency := wakeUpQueues(i).get.io.deq.bits.loadDependency.getOrElse(0.U.asTypeOf(wakeup.bits.loadDependency))\n\
      829:       wakeup.bits.is0Lat := getDeqLat(i, wakeUpQueues(i).get.io.deq.bits.fuType)
      === 0.U\n830:       wakeup.bits.rcDest.foreach(_ := io.replaceRCIdx.get(i))\n\
      831:     } else {\n832:       wakeup.valid := false.B\n833:       wakeup.bits
      := 0.U.asTypeOf(wakeup.bits)\n834:     }\n835:     if (wakeUpQueues(i).nonEmpty)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 882-895
    context: "882:   )\n883:   protected val deqCanAcceptVecEnq: Seq[IndexedSeq[Bool]]
      = deqFuCfgs.map { fuCfgs: Seq[FuConfig] =>\n884:     io.enq.map(_.bits.fuType).map(fuType
      =>\n885:       FuType.FuTypeOrR(fuType, fuCfgs.map(_.fuType)))\n886:   }\n887:\
      \   protected val enqValidCntDeq0 = PopCount(io.enq.map(_.fire).zip(deqCanAcceptVecEnq(0)).map
      { case (a, b) => a && b })\n888:   protected val enqValidCntDeq1 = PopCount(io.enq.map(_.fire).zip(deqCanAcceptVecEnq.last).map
      { case (a, b) => a && b })\n889:   io.validCntDeqVec.head := RegNext(enqEntryValidCntDeq0
      +& othersValidCntDeq0 - io.deqDelay.head.fire) // validCntDeqVec(0)\n890:  \
      \ io.validCntDeqVec.last := RegNext(enqEntryValidCntDeq1 +& othersValidCntDeq1
      - io.deqDelay.last.fire) // validCntDeqVec(1)\n891:   io.status.leftVec(0) :=
      validVec.drop(params.numEnq).reduce(_ & _)\n892:   for (i <- 0 until params.numEnq)
      {\n893:     io.status.leftVec(i + 1) := othersValidCnt === (params.numEntries
      - params.numEnq - (i + 1)).U\n894:   }\n895:   private val othersLeftOneCaseVec
      = Wire(Vec(params.numEntries - params.numEnq, UInt((params.numEntries - params.numEnq).W)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 891-901
    context: "891:   io.status.leftVec(0) := validVec.drop(params.numEnq).reduce(_
      & _)\n892:   for (i <- 0 until params.numEnq) {\n893:     io.status.leftVec(i
      + 1) := othersValidCnt === (params.numEntries - params.numEnq - (i + 1)).U\n\
      894:   }\n895:   private val othersLeftOneCaseVec = Wire(Vec(params.numEntries
      - params.numEnq, UInt((params.numEntries - params.numEnq).W)))\n896:   othersLeftOneCaseVec.zipWithIndex.foreach
      { case (leftone, i) =>\n897:     leftone := ~(1.U((params.numEntries - params.numEnq).W)
      << i)\n898:   }\n899:   private val othersLeftOne = othersLeftOneCaseVec.map(_
      === VecInit(validVec.drop(params.numEnq)).asUInt).reduce(_ | _)\n900:   private
      val othersCanotIn = Wire(Bool())\n901:   othersCanotIn := othersLeftOne || validVec.drop(params.numEnq).reduce(_
      & _)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 900-910
    context: "900:   private val othersCanotIn = Wire(Bool())\n901:   othersCanotIn
      := othersLeftOne || validVec.drop(params.numEnq).reduce(_ & _)\n902:   // if
      has simp Entry, othersCanotIn will be simpCanotIn\n903:   if (params.numSimp
      > 0) {\n904:     val simpLeftOneCaseVec = Wire(Vec(params.numSimp, UInt((params.numSimp).W)))\n\
      905:     simpLeftOneCaseVec.zipWithIndex.foreach { case (leftone, i) =>\n906:\
      \       leftone := ~(1.U((params.numSimp).W) << i)\n907:     }\n908:     val
      simpLeftOne = simpLeftOneCaseVec.map(_ === VecInit(validVec.drop(params.numEnq).take(params.numSimp)).asUInt).reduce(_
      | _)\n909:     val simpCanotIn = simpLeftOne || validVec.drop(params.numEnq).take(params.numSimp).reduce(_
      & _)\n910:     othersCanotIn := simpCanotIn"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 907-917
    context: "907:     }\n908:     val simpLeftOne = simpLeftOneCaseVec.map(_ ===
      VecInit(validVec.drop(params.numEnq).take(params.numSimp)).asUInt).reduce(_
      | _)\n909:     val simpCanotIn = simpLeftOne || validVec.drop(params.numEnq).take(params.numSimp).reduce(_
      & _)\n910:     othersCanotIn := simpCanotIn\n911:   }\n912:   io.enq.foreach(_.ready
      := (!othersCanotIn || !enqHasValid) && !enqHasIssued)\n913:   io.status.empty
      := !Cat(validVec).orR\n914:   io.status.full := othersCanotIn\n915:   io.status.validCnt
      := PopCount(validVec)\n916: \n917:   protected def getDeqLat(deqPortIdx: Int,
      fuType: UInt) : UInt = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 918-933
    context: "918:     Mux1H(wakeupFuLatencyMaps(deqPortIdx) map { case (k, v) =>
      (fuType(k.id), v.U) })\n919:   }\n920: \n921:   // issue perf counter\n922:\
      \   // enq count\n923:   XSPerfAccumulate(\"enq_valid_cnt\", PopCount(io.enq.map(_.fire)))\n\
      924:   XSPerfAccumulate(\"enq_fire_cnt\", PopCount(io.enq.map(_.fire)))\n925:\
      \   XSPerfAccumulate(\"enq_alu_fire_cnt\", PopCount(io.enq.map { case enq =>
      enq.fire && FuType.isAlu(enq.bits.fuType) }))\n926:   XSPerfAccumulate(\"enq_brh_fire_cnt\"\
      , PopCount(io.enq.map { case enq => enq.fire && FuType.isBrh(enq.bits.fuType)
      }))\n927:   XSPerfAccumulate(\"deqDelay0_fire_cnt\", PopCount(io.deqDelay.head.fire))\n\
      928:   XSPerfAccumulate(\"deqDelay1_fire_cnt\", PopCount(io.deqDelay.last.fire))\n\
      929:   // valid count\n930:   XSPerfHistogram(\"enq_entry_valid_cnt\", enqEntryValidCnt,
      true.B, 0, params.numEnq + 1)\n931:   XSPerfHistogram(\"other_entry_valid_cnt\"\
      , othersValidCnt, true.B, 0, params.numEntries - params.numEnq + 1)\n932:  \
      \ XSPerfHistogram(\"valid_cnt\", PopCount(validVec), true.B, 0, params.numEntries
      + 1)\n933:   // only split when more than 1 func type"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 939-949
    context: "939:       }\n940:     }\n941:   }\n942:   // ready instr count\n943:\
      \   private val readyEntriesCnt = PopCount(validVec.zip(canIssueVec).map(x =>
      x._1 && x._2))\n944:   XSPerfHistogram(\"ready_cnt\", readyEntriesCnt, true.B,
      0, params.numEntries + 1)\n945:   // only split when more than 1 func type\n\
      946:   if (params.getFuCfgs.size > 0) {\n947:     for (t <- FuType.functionNameMap.keys)
      {\n948:       val fuName = FuType.functionNameMap(t)\n949:       if (params.getFuCfgs.map(_.fuType
      == t).reduce(_ | _)) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 964-974
    context: "964:   }.reduce(_ +& _))\n965:   XSPerfAccumulate(\"issue_datasource_bypass\"\
      , deqBeforeDly.map{ deq =>\n966:     PopCount(deq.bits.common.dataSources.zipWithIndex.map{
      case (ds, j) => deq.valid && ds.value === DataSource.bypass && !SrcType.isNotReg(deq.bits.srcType(j))
      })\n967:   }.reduce(_ +& _))\n968:   XSPerfAccumulate(\"issue_datasource_forward\"\
      , deqBeforeDly.map{ deq =>\n969:     PopCount(deq.bits.common.dataSources.zipWithIndex.map{
      case (ds, j) => deq.valid && ds.value === DataSource.forward && !SrcType.isNotReg(deq.bits.srcType(j))
      })\n970:   }.reduce(_ +& _))\n971:   XSPerfAccumulate(\"issue_datasource_noreg\"\
      , deqBeforeDly.map{ deq =>\n972:     PopCount(deq.bits.common.dataSources.zipWithIndex.map{
      case (ds, j) => deq.valid && SrcType.isNotReg(deq.bits.srcType(j)) })\n973:\
      \   }.reduce(_ +& _))\n974: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 977-987
    context: "977:   }.reduce(_ +& _), true.B, 0, params.numDeq * params.numRegSrc
      + 1, 1)\n978:   XSPerfHistogram(\"issue_datasource_bypass_hist\", deqBeforeDly.map{
      deq =>\n979:     PopCount(deq.bits.common.dataSources.zipWithIndex.map{ case
      (ds, j) => deq.valid && ds.value === DataSource.bypass && !SrcType.isNotReg(deq.bits.srcType(j))
      })\n980:   }.reduce(_ +& _), true.B, 0, params.numDeq * params.numRegSrc + 1,
      1)\n981:   XSPerfHistogram(\"issue_datasource_forward_hist\", deqBeforeDly.map{
      deq =>\n982:     PopCount(deq.bits.common.dataSources.zipWithIndex.map{ case
      (ds, j) => deq.valid && ds.value === DataSource.forward && !SrcType.isNotReg(deq.bits.srcType(j))
      })\n983:   }.reduce(_ +& _), true.B, 0, params.numDeq * params.numRegSrc + 1,
      1)\n984:   XSPerfHistogram(\"issue_datasource_noreg_hist\", deqBeforeDly.map{
      deq =>\n985:     PopCount(deq.bits.common.dataSources.zipWithIndex.map{ case
      (ds, j) => deq.valid && SrcType.isNotReg(deq.bits.srcType(j)) })\n986:   }.reduce(_
      +& _), true.B, 0, params.numDeq * params.numRegSrc + 1, 1)\n987: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 994-1004
    context: "994:       }.reduce(_ +& _))\n995:       XSPerfAccumulate(s\"issue_datasource_bypass_futype_${fuName}\"\
      , deqBeforeDly.map{ deq =>\n996:         PopCount(deq.bits.common.dataSources.zipWithIndex.map{
      case (ds, j) => deq.valid && ds.value === DataSource.bypass && !SrcType.isNotReg(deq.bits.srcType(j))
      && deq.bits.common.fuType === t.U })\n997:       }.reduce(_ +& _))\n998:   \
      \    XSPerfAccumulate(s\"issue_datasource_forward_futype_${fuName}\", deqBeforeDly.map{
      deq =>\n999:         PopCount(deq.bits.common.dataSources.zipWithIndex.map{
      case (ds, j) => deq.valid && ds.value === DataSource.forward && !SrcType.isNotReg(deq.bits.srcType(j))
      && deq.bits.common.fuType === t.U })\n1000:       }.reduce(_ +& _))\n1001: \
      \      XSPerfAccumulate(s\"issue_datasource_noreg_futype_${fuName}\", deqBeforeDly.map{
      deq =>\n1002:         PopCount(deq.bits.common.dataSources.zipWithIndex.map{
      case (ds, j) => deq.valid && SrcType.isNotReg(deq.bits.srcType(j)) && deq.bits.common.fuType
      === t.U })\n1003:       }.reduce(_ +& _))\n1004: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 1007-1017
    context: "1007:       }.reduce(_ +& _), true.B, 0, params.numDeq * params.numRegSrc
      + 1, 1)\n1008:       XSPerfHistogram(s\"issue_datasource_bypass_hist_futype_${fuName}\"\
      , deqBeforeDly.map{ deq =>\n1009:         PopCount(deq.bits.common.dataSources.zipWithIndex.map{
      case (ds, j) => deq.valid && ds.value === DataSource.bypass && !SrcType.isNotReg(deq.bits.srcType(j))
      && deq.bits.common.fuType === t.U })\n1010:       }.reduce(_ +& _), true.B,
      0, params.numDeq * params.numRegSrc + 1, 1)\n1011:       XSPerfHistogram(s\"\
      issue_datasource_forward_hist_futype_${fuName}\", deqBeforeDly.map{ deq =>\n\
      1012:         PopCount(deq.bits.common.dataSources.zipWithIndex.map{ case (ds,
      j) => deq.valid && ds.value === DataSource.forward && !SrcType.isNotReg(deq.bits.srcType(j))
      && deq.bits.common.fuType === t.U })\n1013:       }.reduce(_ +& _), true.B,
      0, params.numDeq * params.numRegSrc + 1, 1)\n1014:       XSPerfHistogram(s\"\
      issue_datasource_noreg_hist_futype_${fuName}\", deqBeforeDly.map{ deq =>\n1015:\
      \         PopCount(deq.bits.common.dataSources.zipWithIndex.map{ case (ds, j)
      => deq.valid && SrcType.isNotReg(deq.bits.srcType(j)) && deq.bits.common.fuType
      === t.U })\n1016:       }.reduce(_ +& _), true.B, 0, params.numDeq * params.numRegSrc
      + 1, 1)\n1017:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 1029-1051
    context: "1029:   extends IssueQueueImp(wrapper)\n1030: {\n1031:   io.suggestName(\"\
      none\")\n1032:   override lazy val io = IO(new IssueQueueIntIO).suggestName(\"\
      io\")\n1033: \n1034:   deqBeforeDly.zipWithIndex.foreach{ case (deq, i) => {\n\
      1035:     deq.bits.common.pc.foreach(_ := DontCare)\n1036:     deq.bits.common.preDecode.foreach(_
      := deqEntryVec(i).bits.payload.preDecodeInfo)\n1037:     deq.bits.common.ftqIdx.foreach(_
      := deqEntryVec(i).bits.payload.ftqPtr)\n1038:     deq.bits.common.ftqOffset.foreach(_
      := deqEntryVec(i).bits.payload.ftqOffset)\n1039:     deq.bits.common.predictInfo.foreach(x
      => {\n1040:       x.target := DontCare\n1041:       x.taken := deqEntryVec(i).bits.payload.pred_taken\n\
      1042:     })\n1043:     // for std\n1044:     deq.bits.common.sqIdx.foreach(_
      := deqEntryVec(i).bits.payload.sqIdx)\n1045:     // for i2f\n1046:     deq.bits.common.fpu.foreach(_
      := deqEntryVec(i).bits.payload.fpu)\n1047:   }}\n1048: }\n1049: \n1050: class
      IssueQueueVfImp(override val wrapper: IssueQueue)(implicit p: Parameters, iqParams:
      IssueBlockParams)\n1051:   extends IssueQueueImp(wrapper)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 1048-1062
    context: "1048: }\n1049: \n1050: class IssueQueueVfImp(override val wrapper: IssueQueue)(implicit
      p: Parameters, iqParams: IssueBlockParams)\n1051:   extends IssueQueueImp(wrapper)\n\
      1052: {\n1053:   deqBeforeDly.zipWithIndex.foreach{ case (deq, i) => {\n1054:\
      \     deq.bits.common.fpu.foreach(_ := deqEntryVec(i).bits.payload.fpu)\n1055:\
      \     deq.bits.common.vpu.foreach(_ := deqEntryVec(i).bits.payload.vpu)\n1056:\
      \     deq.bits.common.vpu.foreach(_.vuopIdx := deqEntryVec(i).bits.payload.uopIdx)\n\
      1057:     deq.bits.common.vpu.foreach(_.lastUop := deqEntryVec(i).bits.payload.lastUop)\n\
      1058:   }}\n1059: }\n1060: \n1061: class IssueQueueFpImp(override val wrapper:
      IssueQueue)(implicit p: Parameters, iqParams: IssueBlockParams)\n1062:   extends
      IssueQueueImp(wrapper)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 1059-1073
    context: "1059: }\n1060: \n1061: class IssueQueueFpImp(override val wrapper: IssueQueue)(implicit
      p: Parameters, iqParams: IssueBlockParams)\n1062:   extends IssueQueueImp(wrapper)\n\
      1063: {\n1064:   deqBeforeDly.zipWithIndex.foreach{ case (deq, i) => {\n1065:\
      \     deq.bits.common.fpu.foreach(_ := deqEntryVec(i).bits.payload.fpu)\n1066:\
      \     deq.bits.common.vpu.foreach(_ := deqEntryVec(i).bits.payload.vpu)\n1067:\
      \     deq.bits.common.vpu.foreach(_.vuopIdx := deqEntryVec(i).bits.payload.uopIdx)\n\
      1068:     deq.bits.common.vpu.foreach(_.lastUop := deqEntryVec(i).bits.payload.lastUop)\n\
      1069:   }}\n1070: }\n1071: \n1072: class IssueQueueMemBundle(implicit p: Parameters,
      params: IssueBlockParams) extends Bundle {\n1073:   val feedbackIO = Flipped(Vec(params.numDeq,
      new MemRSFeedbackIO(params.isVecMemIQ)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 1102-1125
    context: "1102:   override lazy val io = IO(new IssueQueueMemIO).suggestName(\"\
      io\")\n1103:   private val memIO = io.memIO.get\n1104: \n1105:   memIO.loadFastMatch
      := 0.U.asTypeOf(memIO.loadFastMatch) // TODO: is still needed?\n1106: \n1107:\
      \   entries.io.fromMem.get.slowResp.zipWithIndex.foreach { case (slowResp, i)
      =>\n1108:     slowResp.valid       := memIO.feedbackIO(i).feedbackSlow.valid\n\
      1109:     slowResp.bits.robIdx := memIO.feedbackIO(i).feedbackSlow.bits.robIdx\n\
      1110:     slowResp.bits.sqIdx.foreach( _ := memIO.feedbackIO(i).feedbackSlow.bits.sqIdx)\n\
      1111:     slowResp.bits.lqIdx.foreach( _ := memIO.feedbackIO(i).feedbackSlow.bits.lqIdx)\n\
      1112:     slowResp.bits.resp   := Mux(memIO.feedbackIO(i).feedbackSlow.bits.hit,
      RespType.success, RespType.block)\n1113:     slowResp.bits.fuType := DontCare\n\
      1114:   }\n1115: \n1116:   entries.io.fromMem.get.fastResp.zipWithIndex.foreach
      { case (fastResp, i) =>\n1117:     fastResp.valid       := memIO.feedbackIO(i).feedbackFast.valid\n\
      1118:     fastResp.bits.robIdx := memIO.feedbackIO(i).feedbackFast.bits.robIdx\n\
      1119:     fastResp.bits.sqIdx.foreach( _ := memIO.feedbackIO(i).feedbackFast.bits.sqIdx)\n\
      1120:     fastResp.bits.lqIdx.foreach( _ := memIO.feedbackIO(i).feedbackFast.bits.lqIdx)\n\
      1121:     fastResp.bits.resp   := Mux(memIO.feedbackIO(i).feedbackFast.bits.hit,
      RespType.success, RespType.block)\n1122:     fastResp.bits.fuType := DontCare\n\
      1123:   }\n1124: \n1125:   // load wakeup"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 1122-1153
    context: "1122:     fastResp.bits.fuType := DontCare\n1123:   }\n1124: \n1125:\
      \   // load wakeup\n1126:   val loadWakeUpIter = memIO.loadWakeUp.iterator\n\
      1127:   io.wakeupToIQ.zip(params.exuBlockParams).zipWithIndex.foreach { case
      ((wakeup, param), i) =>\n1128:     if (param.hasLoadExu) {\n1129:       require(wakeUpQueues(i).isEmpty)\n\
      1130:       val uop = loadWakeUpIter.next()\n1131: \n1132:       wakeup.valid
      := GatedValidRegNext(uop.fire)\n1133:       wakeup.bits.rfWen  := (if (params.writeIntRf)
      GatedValidRegNext(uop.bits.rfWen  && uop.fire) else false.B)\n1134:       wakeup.bits.fpWen\
      \  := (if (params.writeFpRf)  GatedValidRegNext(uop.bits.fpWen  && uop.fire)
      else false.B)\n1135:       wakeup.bits.vecWen := (if (params.writeVecRf) GatedValidRegNext(uop.bits.vecWen
      && uop.fire) else false.B)\n1136:       wakeup.bits.v0Wen  := (if (params.writeV0Rf)\
      \  GatedValidRegNext(uop.bits.v0Wen  && uop.fire) else false.B)\n1137:     \
      \  wakeup.bits.vlWen  := (if (params.writeVlRf)  GatedValidRegNext(uop.bits.vlWen\
      \  && uop.fire) else false.B)\n1138:       wakeup.bits.pdest  := RegEnable(uop.bits.pdest,
      uop.fire)\n1139:       wakeup.bits.rcDest.foreach(_ := io.replaceRCIdx.get(i))\n\
      1140:       wakeup.bits.loadDependency.foreach(_ := 0.U) // this is correct
      for load only\n1141: \n1142:       wakeup.bits.rfWenCopy .foreach(_.foreach(_
      := (if (params.writeIntRf) GatedValidRegNext(uop.bits.rfWen  && uop.fire) else
      false.B)))\n1143:       wakeup.bits.fpWenCopy .foreach(_.foreach(_ := (if (params.writeFpRf)\
      \  GatedValidRegNext(uop.bits.fpWen  && uop.fire) else false.B)))\n1144:   \
      \    wakeup.bits.vecWenCopy.foreach(_.foreach(_ := (if (params.writeVecRf) GatedValidRegNext(uop.bits.vecWen
      && uop.fire) else false.B)))\n1145:       wakeup.bits.v0WenCopy .foreach(_.foreach(_
      := (if (params.writeV0Rf)  GatedValidRegNext(uop.bits.v0Wen  && uop.fire) else
      false.B)))\n1146:       wakeup.bits.vlWenCopy .foreach(_.foreach(_ := (if (params.writeVlRf)\
      \  GatedValidRegNext(uop.bits.vlWen  && uop.fire) else false.B)))\n1147:   \
      \    wakeup.bits.pdestCopy .foreach(_.foreach(_ := RegEnable(uop.bits.pdest,
      uop.fire)))\n1148:       wakeup.bits.loadDependencyCopy.foreach(x => x := 0.U.asTypeOf(x))
      // this is correct for load only\n1149: \n1150:       wakeup.bits.is0Lat :=
      0.U\n1151:     }\n1152:   }\n1153:   require(!loadWakeUpIter.hasNext)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 1150-1170
    context: "1150:       wakeup.bits.is0Lat := 0.U\n1151:     }\n1152:   }\n1153:\
      \   require(!loadWakeUpIter.hasNext)\n1154: \n1155:   deqBeforeDly.zipWithIndex.foreach
      { case (deq, i) =>\n1156:     deq.bits.common.pc.foreach(_ := 0.U)\n1157:  \
      \   deq.bits.common.loadWaitBit.foreach(_ := deqEntryVec(i).bits.payload.loadWaitBit)\n\
      1158:     deq.bits.common.waitForRobIdx.foreach(_ := deqEntryVec(i).bits.payload.waitForRobIdx)\n\
      1159:     deq.bits.common.storeSetHit.foreach(_ := deqEntryVec(i).bits.payload.storeSetHit)\n\
      1160:     deq.bits.common.loadWaitStrict.foreach(_ := deqEntryVec(i).bits.payload.loadWaitStrict)\n\
      1161:     deq.bits.common.ssid.foreach(_ := deqEntryVec(i).bits.payload.ssid)\n\
      1162:     deq.bits.common.sqIdx.get := deqEntryVec(i).bits.payload.sqIdx\n1163:\
      \     deq.bits.common.lqIdx.get := deqEntryVec(i).bits.payload.lqIdx\n1164:\
      \     deq.bits.common.ftqIdx.foreach(_ := deqEntryVec(i).bits.payload.ftqPtr)\n\
      1165:     deq.bits.common.ftqOffset.foreach(_ := deqEntryVec(i).bits.payload.ftqOffset)\n\
      1166:   }\n1167: }\n1168: \n1169: class IssueQueueVecMemImp(override val wrapper:
      IssueQueue)(implicit p: Parameters, params: IssueBlockParams)\n1170:   extends
      IssueQueueImp(wrapper) with HasCircularQueuePtrHelper {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 1189-1199
    context: "1189:       val isVleff               = s0_enqBits(i).vpu.isVleff\n\
      1190:       enqData.blocked          := !isFirstLoad && isVleff\n1191:     }\n\
      1192:   }\n1193: \n1194:   entries.io.fromMem.get.slowResp.zipWithIndex.foreach
      { case (slowResp, i) =>\n1195:     slowResp.valid                 := memIO.feedbackIO(i).feedbackSlow.valid\n\
      1196:     slowResp.bits.robIdx           := memIO.feedbackIO(i).feedbackSlow.bits.robIdx\n\
      1197:     slowResp.bits.sqIdx.get        := memIO.feedbackIO(i).feedbackSlow.bits.sqIdx\n\
      1198:     slowResp.bits.lqIdx.get        := memIO.feedbackIO(i).feedbackSlow.bits.lqIdx\n\
      1199:     slowResp.bits.resp             := Mux(memIO.feedbackIO(i).feedbackSlow.bits.hit,
      RespType.success, RespType.block)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 1199-1209
    context: "1199:     slowResp.bits.resp             := Mux(memIO.feedbackIO(i).feedbackSlow.bits.hit,
      RespType.success, RespType.block)\n1200:     slowResp.bits.fuType          \
      \ := DontCare\n1201:     slowResp.bits.uopIdx.get       := DontCare\n1202: \
      \  }\n1203: \n1204:   entries.io.fromMem.get.fastResp.zipWithIndex.foreach {
      case (fastResp, i) =>\n1205:     fastResp.valid                 := memIO.feedbackIO(i).feedbackFast.valid\n\
      1206:     fastResp.bits.robIdx           := memIO.feedbackIO(i).feedbackFast.bits.robIdx\n\
      1207:     fastResp.bits.sqIdx.get        := memIO.feedbackIO(i).feedbackFast.bits.sqIdx\n\
      1208:     fastResp.bits.lqIdx.get        := memIO.feedbackIO(i).feedbackFast.bits.lqIdx\n\
      1209:     fastResp.bits.resp             := Mux(memIO.feedbackIO(i).feedbackFast.bits.hit,
      RespType.success, RespType.block)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 1212-1232
    context: "1212:   }\n1213: \n1214:   entries.io.vecMemIn.get.sqDeqPtr := memIO.sqDeqPtr.get\n\
      1215:   entries.io.vecMemIn.get.lqDeqPtr := memIO.lqDeqPtr.get\n1216: \n1217:\
      \   deqBeforeDly.zipWithIndex.foreach { case (deq, i) =>\n1218:     deq.bits.common.sqIdx.foreach(_
      := deqEntryVec(i).bits.status.vecMem.get.sqIdx)\n1219:     deq.bits.common.lqIdx.foreach(_
      := deqEntryVec(i).bits.status.vecMem.get.lqIdx)\n1220:     deq.bits.common.numLsElem.foreach(_
      := deqEntryVec(i).bits.status.vecMem.get.numLsElem)\n1221:     if (params.isVecLduIQ)
      {\n1222:       deq.bits.common.ftqIdx.get := deqEntryVec(i).bits.payload.ftqPtr\n\
      1223:       deq.bits.common.ftqOffset.get := deqEntryVec(i).bits.payload.ftqOffset\n\
      1224:     }\n1225:     deq.bits.common.fpu.foreach(_ := deqEntryVec(i).bits.payload.fpu)\n\
      1226:     deq.bits.common.vpu.foreach(_ := deqEntryVec(i).bits.payload.vpu)\n\
      1227:     deq.bits.common.vpu.foreach(_.vuopIdx := deqEntryVec(i).bits.payload.uopIdx)\n\
      1228:     deq.bits.common.vpu.foreach(_.lastUop := deqEntryVec(i).bits.payload.lastUop)\n\
      1229:   }\n1230: \n1231:   io.vecLoadIssueResp.foreach(dontTouch(_))\n1232:
      }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/DeqPolicy.scala
    lines: 16-25
    context: "16: \n17:   private val requestVec = VecInit(io.request.asBools)\n18:\
      \   // Todo: support more policies\n19:   private val selVec: Seq[(Bool, Vec[Bool])]
      = io.deqSelOHVec.indices.map(i => SelectOne(\"circ\", requestVec, iqP.numDeq).getNthOH(i
      + 1))\n20: \n21:   io.deqSelOHVec.zip(selVec).foreach { case (deqOH, (selValid,
      selOH)) =>\n22:     deqOH.valid := selValid\n23:     deqOH.bits := selOH.asUInt\n\
      24:   }\n25: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueBlockParams.scala
    lines: 90-100
    context: "90: \n91:   def readVecRf: Boolean = numVecSrc > 0\n92: \n93:   def
      readVfRf: Boolean = numVfSrc > 0\n94: \n95:   def readV0Rf: Boolean = numV0Src
      > 0\n96: \n97:   def readVlRf: Boolean = numVlSrc > 0\n98: \n99:   def writeIntRf:
      Boolean = exuBlockParams.map(_.writeIntRf).reduce(_ || _)\n100: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueBlockParams.scala
    lines: 108-118
    context: "108: \n109:   def exceptionOut: Seq[Int] = exuBlockParams.map(_.exceptionOut).reduce(_
      ++ _).distinct.sorted\n110: \n111:   def hasLoadError: Boolean = exuBlockParams.map(_.hasLoadError).reduce(_
      || _)\n112: \n113:   def flushPipe: Boolean = exuBlockParams.map(_.flushPipe).reduce(_
      || _)\n114: \n115:   def replayInst: Boolean = exuBlockParams.map(_.replayInst).reduce(_
      || _)\n116: \n117:   def trigger: Boolean = exuBlockParams.map(_.trigger).reduce(_
      || _)\n118: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueBlockParams.scala
    lines: 114-124
    context: "114: \n115:   def replayInst: Boolean = exuBlockParams.map(_.replayInst).reduce(_
      || _)\n116: \n117:   def trigger: Boolean = exuBlockParams.map(_.trigger).reduce(_
      || _)\n118: \n119:   def needExceptionGen: Boolean = exceptionOut.nonEmpty ||
      flushPipe || replayInst || trigger\n120: \n121:   def needPc: Boolean = JmpCnt
      + BrhCnt + FenceCnt > 0\n122: \n123:   def needSrcFrm: Boolean = exuBlockParams.map(_.needSrcFrm).reduce(_
      || _)\n124: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueBlockParams.scala
    lines: 196-206
    context: "196: \n197:   def VseglduCnt: Int = exuBlockParams.map(_.fuConfigs.count(_.fuType
      == FuType.vsegldu)).sum\n198: \n199:   def VsegstuCnt: Int = exuBlockParams.map(_.fuConfigs.count(_.fuType
      == FuType.vsegstu)).sum\n200: \n201:   def numRedirect: Int = exuBlockParams.count(_.hasRedirect)\n\
      202: \n203:   def numWriteRegCache: Int = exuBlockParams.map(x => if (x.needWriteRegCache)
      1 else 0).sum\n204: \n205:   def needWriteRegCache: Boolean = numWriteRegCache
      > 0\n206: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueBlockParams.scala
    lines: 278-288
    context: "278:     backendParam.allExuParams.filter(x => !wakeUpInExuSources.map(_.name).contains(x.name)
      && this.readFpRf).groupBy(x => x.getFpWBPort.getOrElse(FpWB(port = -1)).port).filter(_._1
      != -1)\n279:   }\n280: \n281:   def needWakeupFromVfWBPort = backendParam.allExuParams.filter(x
      => !wakeUpInExuSources.map(_.name).contains(x.name) && this.readVecRf).groupBy(x
      => x.getVfWBPort.getOrElse(VfWB(port = -1)).port).filter(_._1 != -1)\n282: \n\
      283:   def needWakeupFromV0WBPort = backendParam.allExuParams.filter(x => !wakeUpInExuSources.map(_.name).contains(x.name)
      && this.readV0Rf).groupBy(x => x.getV0WBPort.getOrElse(V0WB(port = -1)).port).filter(_._1
      != -1)\n284: \n285:   def needWakeupFromVlWBPort = backendParam.allExuParams.filter(x
      => !wakeUpInExuSources.map(_.name).contains(x.name) && this.readVlRf).groupBy(x
      => x.getVlWBPort.getOrElse(VlWB(port = -1)).port).filter(_._1 != -1)\n286: \n\
      287:   def hasWakeupFromMem: Boolean = backendParam.allExuParams.filter(x =>
      wakeUpInExuSources.map(_.name).contains(x.name)).map(_.isMemExeUnit).fold(false)(_
      | _)\n288: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueBlockParams.scala
    lines: 325-363
    context: "325: \n326:   def wakeUpSourceExuIdx: Seq[Int] = {\n327:     wakeUpInExuSources.map(x
      => backendParam.getExuIdx(x.name))\n328:   }\n329: \n330:   def genExuInputDecoupledBundle(implicit
      p: Parameters): MixedVec[DecoupledIO[ExuInput]] = {\n331:     MixedVec(this.exuBlockParams.map(x
      => DecoupledIO(x.genExuInputBundle)))\n332:   }\n333: \n334:   def genExuInputDecoupledCopySrcBundle(implicit
      p: Parameters): MixedVec[DecoupledIO[ExuInput]] = {\n335:     MixedVec(this.exuBlockParams.map(x
      => DecoupledIO(x.genExuInputCopySrcBundle)))\n336:   }\n337: \n338:   def genExuOutputDecoupledBundle(implicit
      p: Parameters): MixedVec[DecoupledIO[ExuOutput]] = {\n339:     MixedVec(this.exuParams.map(x
      => DecoupledIO(x.genExuOutputBundle)))\n340:   }\n341: \n342:   def genExuOutputValidBundle(implicit
      p: Parameters): MixedVec[ValidIO[ExuOutput]] = {\n343:     MixedVec(this.exuParams.map(x
      => ValidIO(x.genExuOutputBundle)))\n344:   }\n345: \n346:   def genExuBypassValidBundle(implicit
      p: Parameters): MixedVec[ValidIO[ExuBypassBundle]] = {\n347:     MixedVec(this.exuParams.filterNot(_.fakeUnit).map(x
      => ValidIO(x.genExuBypassBundle)))\n348:   }\n349: \n350:   def genIssueDecoupledBundle(implicit
      p: Parameters): MixedVec[DecoupledIO[IssueQueueIssueBundle]] = {\n351:     MixedVec(exuBlockParams.filterNot(_.fakeUnit).map(x
      => DecoupledIO(new IssueQueueIssueBundle(this, x))))\n352:   }\n353: \n354:\
      \   def genIssueValidBundle(implicit p: Parameters): MixedVec[ValidIO[IssueQueueIssueBundle]]
      = {\n355:     MixedVec(exuBlockParams.filterNot(_.fakeUnit).map(x => ValidIO(new
      IssueQueueIssueBundle(this, x))))\n356:   }\n357: \n358:   def genWBWakeUpSinkValidBundle(implicit
      p: Parameters): MixedVec[ValidIO[IssueQueueWBWakeUpBundle]] = {\n359:     val
      intBundle: Seq[ValidIO[IssueQueueWBWakeUpBundle]] = schdType match {\n360: \
      \      case IntScheduler() | MemScheduler() => needWakeupFromIntWBPort.map(x
      => ValidIO(new IssueQueueWBWakeUpBundle(x._2.map(_.exuIdx), backendParam))).toSeq\n\
      361:       case _ => Seq()\n362:     }\n363:     val fpBundle = schdType match
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueBlockParams.scala
    lines: 374-412
    context: "374:     }\n375:     val vlBundle = schdType match {\n376:       case
      VfScheduler() | MemScheduler() => needWakeupFromVlWBPort.map(x => ValidIO(new
      IssueQueueWBWakeUpBundle(x._2.map(_.exuIdx), backendParam))).toSeq\n377:   \
      \    case _ => Seq()\n378:     }\n379:     MixedVec(intBundle ++ fpBundle ++
      vfBundle ++ v0Bundle ++ vlBundle)\n380:   }\n381: \n382:   def genIQWakeUpSourceValidBundle(implicit
      p: Parameters): MixedVec[ValidIO[IssueQueueIQWakeUpBundle]] = {\n383:     MixedVec(exuBlockParams.map(x
      => ValidIO(new IssueQueueIQWakeUpBundle(x.exuIdx, backendParam, x.copyWakeupOut,
      x.copyNum))))\n384:   }\n385: \n386:   def genIQWakeUpSinkValidBundle(implicit
      p: Parameters): MixedVec[ValidIO[IssueQueueIQWakeUpBundle]] = {\n387:     MixedVec(this.wakeUpInExuSources.map(x
      => ValidIO(new IssueQueueIQWakeUpBundle(backendParam.getExuIdx(x.name), backendParam))))\n\
      388:   }\n389: \n390:   def genOGRespBundle(implicit p: Parameters) = {\n391:\
      \     implicit val issueBlockParams = this\n392:     MixedVec(exuBlockParams.map(_
      => new OGRespBundle))\n393:   }\n394: \n395:   def genOG2RespBundle(implicit
      p: Parameters) = {\n396:     implicit val issueBlockParams = this\n397:    \
      \ MixedVec(exuBlockParams.map(_ => new Valid(new EntryDeqRespBundle)))\n398:\
      \   }\n399: \n400:   def genWbFuBusyTableWriteBundle(implicit p: Parameters)
      = {\n401:     implicit val issueBlockParams = this\n402:     MixedVec(exuBlockParams.map(x
      => new WbFuBusyTableWriteBundle(x)))\n403:   }\n404: \n405:   def genWbFuBusyTableReadBundle(implicit
      p: Parameters) = {\n406:     implicit val issueBlockParams = this\n407:    \
      \ MixedVec(exuBlockParams.map{ x =>\n408:       new WbFuBusyTableReadBundle(x)\n\
      409:     })\n410:   }\n411: \n412:   def genWbConflictBundle()(implicit p: Parameters)
      = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueBlockParams.scala
    lines: 409-419
    context: "409:     })\n410:   }\n411: \n412:   def genWbConflictBundle()(implicit
      p: Parameters) = {\n413:     implicit val issueBlockParams = this\n414:    \
      \ MixedVec(exuBlockParams.map { x =>\n415:       new WbConflictBundle(x)\n416:\
      \     })\n417:   }\n418: \n419:   def getIQName = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 27-37
    context: "27: case class NoScheduler() extends SchedulerType\n28: \n29: class
      Scheduler(val params: SchdBlockParams)(implicit p: Parameters) extends LazyModule
      with HasXSParameter {\n30:   override def shouldBeInlined: Boolean = false\n\
      31: \n32:   val numIntStateWrite = backendParams.numPregWb(IntData())\n33: \
      \  val numFpStateWrite = backendParams.numPregWb(FpData())\n34:   val numVfStateWrite
      = backendParams.numPregWb(VecData())\n35:   val numV0StateWrite = backendParams.numPregWb(V0Data())\n\
      36:   val numVlStateWrite = backendParams.numPregWb(VlData())\n37: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 55-96
    context: "55:   val maxIQSize = allIssueParams.map(_.numEntries).max\n56:   val
      fromTop = new Bundle {\n57:     val hartId = Input(UInt(8.W))\n58:   }\n59:\
      \   val fromWbFuBusyTable = new Bundle{\n60:     val fuBusyTableRead = MixedVec(params.issueBlockParams.map(x
      => Input(x.genWbFuBusyTableReadBundle)))\n61:   }\n62:   val wbFuBusyTable =
      MixedVec(params.issueBlockParams.map(x => Output(x.genWbFuBusyTableWriteBundle)))\n\
      63:   val IQValidNumVec = Output(Vec(IssueQueueDeqSum, UInt((maxIQSize).U.getWidth.W)))\n\
      64: \n65:   val fromCtrlBlock = new Bundle {\n66:     val flush = Flipped(ValidIO(new
      Redirect))\n67:   }\n68:   val fromDispatch = new Bundle {\n69:     val uops
      =  Vec(fromDispatchUopNum, Flipped(DecoupledIO(new DynInst)))\n70:   }\n71:\
      \   val intWriteBack = MixedVec(Vec(backendParams.numPregWb(IntData()),\n72:\
      \     new RfWritePortWithConfig(backendParams.intPregParams.dataCfg, backendParams.intPregParams.addrWidth)))\n\
      73:   val fpWriteBack = MixedVec(Vec(backendParams.numPregWb(FpData()),\n74:\
      \     new RfWritePortWithConfig(backendParams.fpPregParams.dataCfg, backendParams.fpPregParams.addrWidth)))\n\
      75:   val vfWriteBack = MixedVec(Vec(backendParams.numPregWb(VecData()),\n76:\
      \     new RfWritePortWithConfig(backendParams.vfPregParams.dataCfg, backendParams.vfPregParams.addrWidth)))\n\
      77:   val v0WriteBack = MixedVec(Vec(backendParams.numPregWb(V0Data()),\n78:\
      \     new RfWritePortWithConfig(backendParams.v0PregParams.dataCfg, backendParams.v0PregParams.addrWidth)))\n\
      79:   val vlWriteBack = MixedVec(Vec(backendParams.numPregWb(VlData()),\n80:\
      \     new RfWritePortWithConfig(backendParams.vlPregParams.dataCfg, backendParams.vlPregParams.addrWidth)))\n\
      81:   val intWriteBackDelayed = MixedVec(Vec(backendParams.numPregWb(IntData()),\n\
      82:     new RfWritePortWithConfig(backendParams.intPregParams.dataCfg, backendParams.intPregParams.addrWidth)))\n\
      83:   val fpWriteBackDelayed = MixedVec(Vec(backendParams.numPregWb(FpData()),\n\
      84:     new RfWritePortWithConfig(backendParams.fpPregParams.dataCfg, backendParams.fpPregParams.addrWidth)))\n\
      85:   val vfWriteBackDelayed = MixedVec(Vec(backendParams.numPregWb(VecData()),\n\
      86:     new RfWritePortWithConfig(backendParams.vfPregParams.dataCfg, backendParams.vfPregParams.addrWidth)))\n\
      87:   val v0WriteBackDelayed = MixedVec(Vec(backendParams.numPregWb(V0Data()),\n\
      88:     new RfWritePortWithConfig(backendParams.v0PregParams.dataCfg, backendParams.v0PregParams.addrWidth)))\n\
      89:   val vlWriteBackDelayed = MixedVec(Vec(backendParams.numPregWb(VlData()),\n\
      90:     new RfWritePortWithConfig(backendParams.vlPregParams.dataCfg, backendParams.vlPregParams.addrWidth)))\n\
      91:   val toDataPathAfterDelay: MixedVec[MixedVec[DecoupledIO[IssueQueueIssueBundle]]]
      = MixedVec(params.issueBlockParams.map(_.genIssueDecoupledBundle))\n92: \n93:\
      \   val vlWriteBackInfo = new Bundle {\n94:     val vlFromIntIsZero  = Input(Bool())\n\
      95:     val vlFromIntIsVlmax = Input(Bool())\n96:     val vlFromVfIsZero   =
      Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 96-115
    context: "96:     val vlFromVfIsZero   = Input(Bool())\n97:     val vlFromVfIsVlmax\
      \  = Input(Bool())\n98:   }\n99: \n100:   val fromSchedulers = new Bundle {\n\
      101:     val wakeupVec: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]] = Flipped(params.genIQWakeUpInValidBundle)\n\
      102:     val wakeupVecDelayed: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]] =
      Flipped(params.genIQWakeUpInValidBundle)\n103:   }\n104: \n105:   val toSchedulers
      = new Bundle {\n106:     val wakeupVec: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]]
      = params.genIQWakeUpOutValidBundle\n107:   }\n108: \n109:   val fromDataPath
      = new Bundle {\n110:     val resp: MixedVec[MixedVec[OGRespBundle]] = MixedVec(params.issueBlockParams.map(x
      => Flipped(x.genOGRespBundle)))\n111:     val og0Cancel = Input(ExuVec())\n\
      112:     // Todo: remove this after no cancel signal from og1\n113:     val
      og1Cancel = Input(ExuVec())\n114:     // replace RCIdx to Wakeup Queue\n115:\
      \     val replaceRCIdx = OptionWrapper(params.needWriteRegCache, Vec(params.numWriteRegCache,
      Input(UInt(RegCacheIdxWidth.W))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 115-128
    context: "115:     val replaceRCIdx = OptionWrapper(params.needWriteRegCache,
      Vec(params.numWriteRegCache, Input(UInt(RegCacheIdxWidth.W))))\n116:     //
      just be compatible to old code\n117:     def apply(i: Int)(j: Int) = resp(i)(j)\n\
      118:   }\n119: \n120:   val loadFinalIssueResp = MixedVec(params.issueBlockParams.map(x
      => MixedVec(Vec(x.LdExuCnt, Flipped(ValidIO(new IssueQueueDeqRespBundle()(p,
      x)))))))\n121:   val vecLoadFinalIssueResp = MixedVec(params.issueBlockParams.map(x
      => MixedVec(Vec(x.VlduCnt, Flipped(ValidIO(new IssueQueueDeqRespBundle()(p,
      x)))))))\n122:   val memAddrIssueResp = MixedVec(params.issueBlockParams.map(x
      => MixedVec(Vec(x.LdExuCnt, Flipped(ValidIO(new IssueQueueDeqRespBundle()(p,
      x)))))))\n123:   val vecLoadIssueResp = MixedVec(params.issueBlockParams.map(x
      => MixedVec(Vec(x.VlduCnt, Flipped(ValidIO(new IssueQueueDeqRespBundle()(p,
      x)))))))\n124: \n125:   val ldCancel = Vec(backendParams.LduCnt + backendParams.HyuCnt,
      Flipped(new LoadCancelIO))\n126: \n127:   val fromMem = if (params.isMemSchd)
      Some(new Bundle {\n128:     val ldaFeedback = Flipped(Vec(params.LduCnt, new
      MemRSFeedbackIO))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 142-152
    context: "142:     val memWaitUpdateReq = Flipped(new MemWaitUpdateReqBundle)\n\
      143:   }) else None\n144:   val toMem = if (params.isMemSchd) Some(new Bundle
      {\n145:     val loadFastMatch = Output(Vec(params.LduCnt, new IssueQueueLoadBundle))\n\
      146:   }) else None\n147:   val fromOg2Resp = if(params.needOg2Resp) Some(MixedVec(params.issueBlockParams.filter(_.needOg2Resp).map(x
      => Flipped(x.genOG2RespBundle)))) else None\n148: }\n149: \n150: abstract class
      SchedulerImpBase(wrapper: Scheduler)(implicit params: SchdBlockParams, p: Parameters)\n\
      151:   extends LazyModuleImp(wrapper)\n152:     with HasXSParameter"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 201-212
    context: "201:       sink.bits.vlWen := source.vlWen\n202:       sink.bits.pdest
      := source.addr\n203:     }\n204:   }\n205:   // Connect bundles having the same
      wakeup source\n206:   issueQueues.zipWithIndex.foreach { case(iq, i) =>\n207:\
      \     iq.io.wakeupFromIQ.foreach { wakeUp =>\n208:       val wakeUpIn = iqWakeUpInMap(wakeUp.bits.exuIdx)\n\
      209:       val exuIdx = wakeUp.bits.exuIdx\n210:       println(s\"[Backend]
      Connect wakeup exuIdx ${exuIdx}\")\n211:       connectSamePort(wakeUp,wakeUpIn)\n\
      212:       backendParams.connectWakeup(exuIdx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 224-234
    context: "224:       if (iq.params.numFpSrc == 0)  wakeUp.bits.fpWen := false.B\n\
      225:       if (iq.params.numVfSrc == 0)  wakeUp.bits.vecWen := false.B\n226:\
      \       if (iq.params.numV0Src == 0)  wakeUp.bits.v0Wen := false.B\n227:   \
      \    if (iq.params.numVlSrc == 0)  wakeUp.bits.vlWen := false.B\n228:     }\n\
      229:     iq.io.wakeupFromIQDelayed.foreach { wakeUp =>\n230:       val wakeUpIn
      = iqWakeUpInMapDelayed(wakeUp.bits.exuIdx)\n231:       connectSamePort(wakeUp,
      wakeUpIn)\n232:       if (iq.params.numIntSrc == 0) wakeUp.bits.rfWen := false.B\n\
      233:       if (iq.params.numFpSrc == 0) wakeUp.bits.fpWen := false.B\n234: \
      \      if (iq.params.numVfSrc == 0) wakeUp.bits.vecWen := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 242-252
    context: "242:     else\n243:       iq.io.ldCancel := 0.U.asTypeOf(io.ldCancel)\n\
      244:   }\n245: \n246:   // connect the vl writeback informatino to the issue
      queues\n247:   issueQueues.zipWithIndex.foreach { case(iq, i) =>\n248:     iq.io.vlFromIntIsVlmax
      := io.vlWriteBackInfo.vlFromIntIsVlmax\n249:     iq.io.vlFromIntIsZero := io.vlWriteBackInfo.vlFromIntIsZero\n\
      250:     iq.io.vlFromVfIsVlmax := io.vlWriteBackInfo.vlFromVfIsVlmax\n251: \
      \    iq.io.vlFromVfIsZero := io.vlWriteBackInfo.vlFromVfIsZero\n252:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 255-281
    context: "255:     issueQueues.flatMap(_.io.wakeupToIQ)\n256:       .map(x =>
      (x.bits.exuIdx, x))\n257:       .toMap\n258: \n259:   // Connect bundles having
      the same wakeup source\n260:   io.toSchedulers.wakeupVec.foreach { wakeUp =>\n\
      261:     wakeUp := iqWakeUpOutMap(wakeUp.bits.exuIdx)\n262:   }\n263: \n264:\
      \   io.toDataPathAfterDelay.zipWithIndex.foreach { case (toDpDy, i) =>\n265:\
      \     toDpDy <> issueQueues(i).io.deqDelay\n266:   }\n267: \n268:   // Response\n\
      269:   issueQueues.zipWithIndex.foreach { case (iq, i) =>\n270:     iq.io.og0Resp.zipWithIndex.foreach
      { case (og0Resp, j) =>\n271:       og0Resp := io.fromDataPath(i)(j).og0resp\n\
      272:     }\n273:     iq.io.og1Resp.zipWithIndex.foreach { case (og1Resp, j)
      =>\n274:       og1Resp := io.fromDataPath(i)(j).og1resp\n275:     }\n276:  \
      \   iq.io.finalIssueResp.foreach(_.zipWithIndex.foreach { case (finalIssueResp,
      j) =>\n277:       if (io.loadFinalIssueResp(i).isDefinedAt(j) && iq.params.isLdAddrIQ)
      {\n278:         finalIssueResp := io.loadFinalIssueResp(i)(j)\n279:       }
      else if (io.vecLoadFinalIssueResp(i).isDefinedAt(j) && iq.params.isVecLduIQ)
      {\n280:         finalIssueResp := io.vecLoadFinalIssueResp(i)(j)\n281:     \
      \  }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 281-291
    context: "281:       }\n282:       else {\n283:         finalIssueResp := 0.U.asTypeOf(finalIssueResp)\n\
      284:       }\n285:     })\n286:     iq.io.memAddrIssueResp.foreach(_.zipWithIndex.foreach
      { case (memAddrIssueResp, j) =>\n287:       if (io.memAddrIssueResp(i).isDefinedAt(j))
      {\n288:         memAddrIssueResp := io.memAddrIssueResp(i)(j)\n289:       }
      else {\n290:         memAddrIssueResp := 0.U.asTypeOf(memAddrIssueResp)\n291:\
      \       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 288-307
    context: "288:         memAddrIssueResp := io.memAddrIssueResp(i)(j)\n289:   \
      \    } else {\n290:         memAddrIssueResp := 0.U.asTypeOf(memAddrIssueResp)\n\
      291:       }\n292:     })\n293:     iq.io.vecLoadIssueResp.foreach(_.zipWithIndex.foreach
      { case (resp, deqIdx) =>\n294:       resp := io.vecLoadIssueResp(i)(deqIdx)\n\
      295:     })\n296:     iq.io.wbBusyTableRead := io.fromWbFuBusyTable.fuBusyTableRead(i)\n\
      297:     io.wbFuBusyTable(i) := iq.io.wbBusyTableWrite\n298:     iq.io.replaceRCIdx.foreach(x
      => x := 0.U.asTypeOf(x))\n299:   }\n300:   if (params.needOg2Resp) {\n301: \
      \    issueQueues.filter(_.params.needOg2Resp).zip(io.fromOg2Resp.get).foreach{
      case (iq, og2RespVec) =>\n302:       iq.io.og2Resp.get.zip(og2RespVec).foreach{
      case (iqOg2Resp, og2Resp) =>\n303:         iqOg2Resp := og2Resp\n304:      \
      \ }\n305:     }\n306:   }\n307: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 308-318
    context: "308:   // Connect each replace RCIdx to IQ\n309:   if (params.needWriteRegCache)
      {\n310:     val iqReplaceRCIdxVec = issueQueues.filter(_.params.needWriteRegCache).flatMap{
      iq =>\n311:       iq.params.allExuParams.zip(iq.io.replaceRCIdx.get).filter(_._1.needWriteRegCache).map(_._2)\n\
      312:     }\n313:     iqReplaceRCIdxVec.zip(io.fromDataPath.replaceRCIdx.get).foreach{
      case (iq, in) =>\n314:       iq := in\n315:     }\n316: \n317:     println(s\"\
      [Scheduler] numWriteRegCache: ${params.numWriteRegCache}\")\n318:     println(s\"\
      [Scheduler] iqReplaceRCIdxVec: ${iqReplaceRCIdxVec.size}\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 317-328
    context: "317:     println(s\"[Scheduler] numWriteRegCache: ${params.numWriteRegCache}\"\
      )\n318:     println(s\"[Scheduler] iqReplaceRCIdxVec: ${iqReplaceRCIdxVec.size}\"\
      )\n319:   }\n320: \n321:   // perfEvent\n322:   val lastCycleIqEnqFireVec  \
      \  = RegNext(VecInit(issueQueues.map(_.io.enq.map(_.fire)).flatten))\n323: \
      \  val lastCycleIqFullVec       = RegNext(VecInit(issueQueues.map(_.io.enq.head.ready)))\n\
      324: \n325:   val issueQueueFullVecPerf = issueQueues.zip(lastCycleIqFullVec)map{
      case (iq, full) => (iq.params.getIQName + s\"_full\", full) }\n326:   val basePerfEvents
      = Seq(\n327:     (\"issueQueue_enq_fire_cnt\",  PopCount(lastCycleIqEnqFireVec)\
      \                    )\n328:   )  ++ issueQueueFullVecPerf"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 339-350
    context: "339:     with HasXSParameter\n340:     with HasPerfEvents\n341: {\n\
      342:   val issueQueuesUopIn = issueQueues.map(_.io.enq).flatten\n343:   issueQueuesUopIn.zip(io.fromDispatch.uops).map(x
      => x._1 <> x._2)\n344:   issueQueues.zipWithIndex.foreach { case (iq, i) =>\n\
      345:     iq.io.flush <> io.fromCtrlBlock.flush\n346:     if (!iq.params.needLoadDependency)
      {\n347:       iq.io.enq.map(x => x.bits.srcLoadDependency := 0.U.asTypeOf(x.bits.srcLoadDependency))\n\
      348:     }\n349:     val intWBIQ = params.schdType match {\n350:       case
      IntScheduler() => wakeupFromIntWBVec.zipWithIndex.filter(x => iq.params.needWakeupFromIntWBPort.keys.toSeq.contains(x._2)).map(_._1)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 360-371
    context: "360:       case VfScheduler() => (wakeupFromVfWBVecDelayed.zipWithIndex.filter(x
      => iq.params.needWakeupFromVfWBPort.keys.toSeq.contains(x._2)).map(_._1) ++\n\
      361:                              wakeupFromV0WBVecDelayed.zipWithIndex.filter(x
      => iq.params.needWakeupFromV0WBPort.keys.toSeq.contains(x._2)).map(_._1) ++\n\
      362:                              wakeupFromVlWBVecDelayed.zipWithIndex.filter(x
      => iq.params.needWakeupFromVlWBPort.keys.toSeq.contains(x._2)).map(_._1))\n\
      363:       case _ => null\n364:     }\n365:     iq.io.wakeupFromWB.zip(intWBIQ).foreach{
      case (sink, source) => sink := source}\n366:     iq.io.wakeupFromWBDelayed.zip(intWBIQDelayed).foreach{
      case (sink, source) => sink := source}\n367:   }\n368: \n369:   val perfEvents
      = basePerfEvents\n370:   generatePerfEvent()\n371: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 379-392
    context: "379: \n380:   val issueQueuesUopIn = issueQueues.filter(_.params.StdCnt
      == 0).map(_.io.enq).flatten\n381:   issueQueuesUopIn.zip(io.fromDispatch.uops).map(x
      => x._1 <> x._2)\n382:   val noStdExuParams = params.issueBlockParams.map(x
      => Seq.fill(x.numEnq)(x.exuBlockParams)).flatten.filter{x => x.map(!_.hasStdFu).reduce(_
      && _)}\n383:   val staIdx = noStdExuParams.zipWithIndex.filter{x => x._1.map(_.hasStoreAddrFu).reduce(_
      || _)}.map(_._2)\n384:   val staReady = issueQueues.filter(iq => iq.params.StaCnt
      > 0).map(_.io.enq.map(_.ready)).flatten\n385:   val stdReady = issueQueues.filter(iq
      => iq.params.StdCnt > 0).map(_.io.enq.map(_.ready)).flatten\n386:   staIdx.zipWithIndex.map{
      case (sta, i) => {\n387:     io.fromDispatch.uops(sta).ready := staReady(i)
      && stdReady(i)\n388:   }}\n389:   issueQueues.filter(iq => iq.params.StaCnt
      > 0).map(_.io.enq).flatten.zipWithIndex.map{ case (iq, idx) =>\n390:     iq.valid
      := io.fromDispatch.uops(staIdx(idx)).valid && !io.fromDispatch.uops(staIdx(idx)).bits.isDropAmocasSta\n\
      391:   }\n392:   val staValidFromDispatch = staIdx.map(idx => io.fromDispatch.uops(idx).valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 406-419
    context: "406: \n407:   io.toMem.get.loadFastMatch := 0.U.asTypeOf(io.toMem.get.loadFastMatch)
      // TODO: is still needed?\n408: \n409:   private val loadWakeUp = issueQueues.filter(_.params.LdExuCnt
      > 0).map(_.asInstanceOf[IssueQueueMemAddrImp].io.memIO.get.loadWakeUp).flatten\n\
      410:   require(loadWakeUp.length == io.fromMem.get.wakeup.length)\n411:   loadWakeUp.zip(io.fromMem.get.wakeup).foreach(x
      => x._1 := x._2)\n412: \n413:   memAddrIQs.zipWithIndex.foreach { case (iq,
      i) =>\n414:     iq.io.flush <> io.fromCtrlBlock.flush\n415:     if (!iq.params.needLoadDependency)
      {\n416:       iq.io.enq.map(x => x.bits.srcLoadDependency := 0.U.asTypeOf(x.bits.srcLoadDependency))\n\
      417:     }\n418:     iq.io.wakeupFromWB.zip(\n419:       wakeupFromIntWBVec.zipWithIndex.filter(x
      => iq.params.needWakeupFromIntWBPort.keys.toSeq.contains(x._2)).map(_._1) ++"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 419-429
    context: "419:       wakeupFromIntWBVec.zipWithIndex.filter(x => iq.params.needWakeupFromIntWBPort.keys.toSeq.contains(x._2)).map(_._1)
      ++\n420:       wakeupFromFpWBVec.zipWithIndex.filter(x => iq.params.needWakeupFromFpWBPort.keys.toSeq.contains(x._2)).map(_._1)
      ++\n421:       wakeupFromVfWBVec.zipWithIndex.filter(x => iq.params.needWakeupFromVfWBPort.keys.toSeq.contains(x._2)).map(_._1)
      ++\n422:       wakeupFromV0WBVec.zipWithIndex.filter(x => iq.params.needWakeupFromV0WBPort.keys.toSeq.contains(x._2)).map(_._1)
      ++\n423:       wakeupFromVlWBVec.zipWithIndex.filter(x => iq.params.needWakeupFromVlWBPort.keys.toSeq.contains(x._2)).map(_._1)\n\
      424:     ).foreach{ case (sink, source) => sink := source}\n425:     iq.io.wakeupFromWBDelayed.zip(\n\
      426:       wakeupFromIntWBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromIntWBPort.keys.toSeq.contains(x._2)).map(_._1)
      ++\n427:       wakeupFromFpWBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromFpWBPort.keys.toSeq.contains(x._2)).map(_._1)
      ++\n428:       wakeupFromVfWBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromVfWBPort.keys.toSeq.contains(x._2)).map(_._1)
      ++\n429:       wakeupFromV0WBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromV0WBPort.keys.toSeq.contains(x._2)).map(_._1)
      ++"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 426-441
    context: "426:       wakeupFromIntWBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromIntWBPort.keys.toSeq.contains(x._2)).map(_._1)
      ++\n427:       wakeupFromFpWBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromFpWBPort.keys.toSeq.contains(x._2)).map(_._1)
      ++\n428:       wakeupFromVfWBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromVfWBPort.keys.toSeq.contains(x._2)).map(_._1)
      ++\n429:       wakeupFromV0WBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromV0WBPort.keys.toSeq.contains(x._2)).map(_._1)
      ++\n430:       wakeupFromVlWBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromVlWBPort.keys.toSeq.contains(x._2)).map(_._1)\n\
      431:     ).foreach { case (sink, source) => sink := source }\n432:   }\n433:\
      \ \n434:   ldAddrIQs.zipWithIndex.foreach {\n435:     case (imp: IssueQueueMemAddrImp,
      i) =>\n436:       imp.io.memIO.get.feedbackIO.head := 0.U.asTypeOf(imp.io.memIO.get.feedbackIO.head)\n\
      437:       imp.io.memIO.get.checkWait.stIssuePtr := io.fromMem.get.stIssuePtr\n\
      438:       imp.io.memIO.get.checkWait.memWaitUpdateReq := io.fromMem.get.memWaitUpdateReq\n\
      439:     case _ =>\n440:   }\n441: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 437-449
    context: "437:       imp.io.memIO.get.checkWait.stIssuePtr := io.fromMem.get.stIssuePtr\n\
      438:       imp.io.memIO.get.checkWait.memWaitUpdateReq := io.fromMem.get.memWaitUpdateReq\n\
      439:     case _ =>\n440:   }\n441: \n442:   stAddrIQs.zipWithIndex.foreach {\n\
      443:     case (imp: IssueQueueMemAddrImp, i) =>\n444:       imp.io.memIO.get.feedbackIO.head
      := io.fromMem.get.staFeedback(i)\n445:       imp.io.memIO.get.checkWait.stIssuePtr
      := io.fromMem.get.stIssuePtr\n446:       imp.io.memIO.get.checkWait.memWaitUpdateReq
      := io.fromMem.get.memWaitUpdateReq\n447:     case _ =>\n448:   }\n449: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 445-462
    context: "445:       imp.io.memIO.get.checkWait.stIssuePtr := io.fromMem.get.stIssuePtr\n\
      446:       imp.io.memIO.get.checkWait.memWaitUpdateReq := io.fromMem.get.memWaitUpdateReq\n\
      447:     case _ =>\n448:   }\n449: \n450:   hyuIQs.zip(hyuIQIdxs).foreach {\n\
      451:     case (imp: IssueQueueMemAddrImp, idx) =>\n452:       imp.io.memIO.get.feedbackIO.head
      := io.fromMem.get.hyuFeedback.head\n453:       imp.io.memIO.get.feedbackIO(1)
      := 0.U.asTypeOf(imp.io.memIO.get.feedbackIO(1))\n454:       imp.io.memIO.get.checkWait.stIssuePtr
      := io.fromMem.get.stIssuePtr\n455:       imp.io.memIO.get.checkWait.memWaitUpdateReq
      := io.fromMem.get.memWaitUpdateReq\n456:       // TODO: refactor ditry code\n\
      457:       imp.io.deqDelay(1).ready := false.B\n458:       io.toDataPathAfterDelay(idx)(1).valid
      := false.B\n459:       io.toDataPathAfterDelay(idx)(1).bits := 0.U.asTypeOf(io.toDataPathAfterDelay(idx)(1).bits)\n\
      460:     case _ =>\n461:   }\n462: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 475-486
    context: "475:   s\"should be equal to number of enq ports of store data IQs(${stdEnqs.size})\"\
      )\n476: \n477:   require(hyaEnqs.size == hydEnqs.size, s\"number of enq ports
      of hybrid address IQs(${hyaEnqs.size}) \" +\n478:   s\"should be equal to number
      of enq ports of hybrid data IQs(${hydEnqs.size})\")\n479: \n480:   stDataIQs.zipWithIndex.foreach
      { case (iq, i) =>\n481:     iq.io.flush <> io.fromCtrlBlock.flush\n482:    \
      \ iq.io.wakeupFromWB.zip(\n483:       wakeupFromIntWBVec.zipWithIndex.filter(x
      => iq.params.needWakeupFromIntWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n484:       wakeupFromFpWBVec.zipWithIndex.filter(x => iq.params.needWakeupFromFpWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n485:       wakeupFromVfWBVec.zipWithIndex.filter(x => iq.params.needWakeupFromVfWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n486:       wakeupFromV0WBVec.zipWithIndex.filter(x => iq.params.needWakeupFromV0WBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 483-493
    context: "483:       wakeupFromIntWBVec.zipWithIndex.filter(x => iq.params.needWakeupFromIntWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n484:       wakeupFromFpWBVec.zipWithIndex.filter(x => iq.params.needWakeupFromFpWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n485:       wakeupFromVfWBVec.zipWithIndex.filter(x => iq.params.needWakeupFromVfWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n486:       wakeupFromV0WBVec.zipWithIndex.filter(x => iq.params.needWakeupFromV0WBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n487:       wakeupFromVlWBVec.zipWithIndex.filter(x => iq.params.needWakeupFromVlWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq\n\
      488:     ).foreach{ case (sink, source) => sink := source}\n489:     iq.io.wakeupFromWBDelayed.zip(\n\
      490:       wakeupFromIntWBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromIntWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n491:       wakeupFromFpWBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromFpWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n492:       wakeupFromVfWBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromVfWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n493:       wakeupFromV0WBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromV0WBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 490-505
    context: "490:       wakeupFromIntWBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromIntWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n491:       wakeupFromFpWBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromFpWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n492:       wakeupFromVfWBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromVfWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n493:       wakeupFromV0WBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromV0WBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n494:       wakeupFromVlWBVecDelayed.zipWithIndex.filter(x => iq.params.needWakeupFromVlWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq\n\
      495:     ).foreach { case (sink, source) => sink := source }\n496:     // here
      disable fp load fast wakeup to std, and no FEX wakeup to std\n497:     iq.io.wakeupFromIQ.map(_.bits.fpWen
      := false.B)\n498:   }\n499: \n500:   (stdEnqs ++ hydEnqs).zip(staEnqs ++ hyaEnqs).zipWithIndex.foreach
      { case ((stdIQEnq, staIQEnq), i) =>\n501:     stdIQEnq.valid := staValidFromDispatch(i)\n\
      502:     stdIQEnq.bits  := staIQEnq.bits\n503:     // Store data reuses store
      addr src(1) in dispatch2iq\n504:     // [dispatch2iq] --src*------src*(0)-->
      [staIQ|hyaIQ]\n505:     //                       \\"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 514-527
    context: "514:     stdIQEnq.bits.sqIdx := staIQEnq.bits.sqIdx\n515:     stdIQEnq.bits.useRegCache(0)
      := staIQEnq.bits.useRegCache(stdIdx)\n516:     stdIQEnq.bits.regCacheIdx(0)
      := staIQEnq.bits.regCacheIdx(stdIdx)\n517:   }\n518: \n519:   vecMemIQs.foreach
      {\n520:     case imp: IssueQueueVecMemImp =>\n521:       imp.io.memIO.get.sqDeqPtr.foreach(_
      := io.fromMem.get.sqDeqPtr)\n522:       imp.io.memIO.get.lqDeqPtr.foreach(_
      := io.fromMem.get.lqDeqPtr)\n523:       // not used\n524:       //imp.io.memIO.get.feedbackIO.head
      := io.fromMem.get.vstuFeedback.head // only vector store replay\n525:      \
      \ // maybe not used\n526:       imp.io.memIO.get.checkWait.stIssuePtr := io.fromMem.get.stIssuePtr\n\
      527:       imp.io.memIO.get.checkWait.memWaitUpdateReq := io.fromMem.get.memWaitUpdateReq"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 529-539
    context: "529:         wakeupFromIntWBVec.zipWithIndex.filter(x => imp.params.needWakeupFromIntWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n530:         wakeupFromFpWBVec.zipWithIndex.filter(x => imp.params.needWakeupFromFpWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n531:         wakeupFromVfWBVec.zipWithIndex.filter(x => imp.params.needWakeupFromVfWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n532:         wakeupFromV0WBVec.zipWithIndex.filter(x => imp.params.needWakeupFromV0WBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n533:         wakeupFromVlWBVec.zipWithIndex.filter(x => imp.params.needWakeupFromVlWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq\n\
      534:       ).foreach{ case (sink, source) => sink := source}\n535:       imp.io.wakeupFromWBDelayed.zip(\n\
      536:         wakeupFromIntWBVecDelayed.zipWithIndex.filter(x => imp.params.needWakeupFromIntWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n537:         wakeupFromFpWBVecDelayed.zipWithIndex.filter(x => imp.params.needWakeupFromFpWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n538:         wakeupFromVfWBVecDelayed.zipWithIndex.filter(x => imp.params.needWakeupFromVfWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n539:         wakeupFromV0WBVecDelayed.zipWithIndex.filter(x => imp.params.needWakeupFromV0WBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 536-546
    context: "536:         wakeupFromIntWBVecDelayed.zipWithIndex.filter(x => imp.params.needWakeupFromIntWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n537:         wakeupFromFpWBVecDelayed.zipWithIndex.filter(x => imp.params.needWakeupFromFpWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n538:         wakeupFromVfWBVecDelayed.zipWithIndex.filter(x => imp.params.needWakeupFromVfWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n539:         wakeupFromV0WBVecDelayed.zipWithIndex.filter(x => imp.params.needWakeupFromV0WBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq
      ++\n540:         wakeupFromVlWBVecDelayed.zipWithIndex.filter(x => imp.params.needWakeupFromVlWBPort.keys.toSeq.contains(x._2)).map(_._1).toSeq\n\
      541:       ).foreach { case (sink, source) => sink := source }\n542: \n543:\
      \     case _ =>\n544:   }\n545:   val vecMemFeedbackIO: Seq[MemRSFeedbackIO]
      = vecMemIQs.map {\n546:     case imp: IssueQueueVecMemImp =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 545-555
    context: "545:   val vecMemFeedbackIO: Seq[MemRSFeedbackIO] = vecMemIQs.map {\n\
      546:     case imp: IssueQueueVecMemImp =>\n547:       imp.io.memIO.get.feedbackIO\n\
      548:   }.flatten\n549:   assert(vecMemFeedbackIO.size == io.fromMem.get.vstuFeedback.size,
      \"vecMemFeedback size dont match!\")\n550:   vecMemFeedbackIO.zip(io.fromMem.get.vstuFeedback).foreach{\n\
      551:     case (sink, source) =>\n552:       sink := source\n553:   }\n554: \n\
      555:   val perfEvents = basePerfEvents"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/AgeDetector.scala
    lines: 93-103
    context: "93:     VecInit((0 until numEntries).map(i => {\n94:       (VecInit((0
      until numEntries).map(j => get(i, j))).asUInt | ~canIssue).andR & canIssue(i)\n\
      95:     })).asUInt\n96:   }\n97: \n98:   io.out.zip(io.canIssue).foreach { case
      (out, canIssue) =>\n99:     out := getOldestCanIssue(get_age, canIssue)\n100:\
      \   }\n101: \n102:   for (i <- 0 until numEnq) {\n103:     assert(PopCount(io.enq(i))
      <= 1.U, s\"enq port ($i) is not ont-hot\\n\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/AgeDetector.scala
    lines: 108-118
    context: "108:   def apply(numEntries: Int, enq: Vec[UInt], canIssue: Vec[UInt])(implicit
      p: Parameters): Vec[Valid[UInt]] = {\n109:     val age = Module(new AgeDetector(numEntries,
      enq.length, canIssue.length))\n110:     age.io.enq := enq\n111:     age.io.canIssue
      := canIssue\n112:     val outVec = Wire(Vec(canIssue.length, Valid(UInt(numEntries.W))))\n\
      113:     outVec.zipWithIndex.foreach { case (out, i) =>\n114:       out.valid
      := canIssue(i).orR\n115:       out.bits := age.io.out(i)\n116:       when (out.valid)
      {\n117:         assert(PopCount(out.bits) === 1.U, s\"out ($i) is not ont-hot
      when there is at least one entry can be issued\\n\")\n118:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/SchdBlockParams.scala
    lines: 93-103
    context: "93: \n94:   def writeVConfig: Boolean = issueBlockParams.map(_.writeVConfig).reduce(_
      || _)\n95:   \n96:   def writeVType: Boolean = issueBlockParams.map(_.writeVType).reduce(_
      || _)\n97: \n98:   def numRedirect: Int = issueBlockParams.map(_.numRedirect).sum\n\
      99: \n100:   def pregIdxWidth: Int = log2Up(numPregs)\n101: \n102:   def numWakeupFromWB:
      Int = schdType match {\n103:     case IntScheduler() | VfScheduler() => 8"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/SchdBlockParams.scala
    lines: 121-148
    context: "121: \n122:   def numWriteRegCache: Int = issueBlockParams.map(_.numWriteRegCache).sum\n\
      123: \n124:   def needWriteRegCache: Boolean = numWriteRegCache > 0\n125: \n\
      126:   def genExuInputBundle(implicit p: Parameters): MixedVec[MixedVec[DecoupledIO[ExuInput]]]
      = {\n127:     MixedVec(this.issueBlockParams.map(_.genExuInputDecoupledBundle))\n\
      128:   }\n129: \n130:   def genExuInputCopySrcBundle(implicit p: Parameters):
      MixedVec[MixedVec[DecoupledIO[ExuInput]]] = {\n131:     MixedVec(this.issueBlockParams.map(_.genExuInputDecoupledCopySrcBundle))\n\
      132:   }\n133: \n134:   def genExuOutputDecoupledBundle(implicit p: Parameters):
      MixedVec[MixedVec[DecoupledIO[ExuOutput]]] = {\n135:     MixedVec(this.issueBlockParams.map(_.genExuOutputDecoupledBundle))\n\
      136:   }\n137: \n138:   def genExuOutputValidBundle(implicit p: Parameters):
      MixedVec[MixedVec[ValidIO[ExuOutput]]] = {\n139:     MixedVec(this.issueBlockParams.map(_.genExuOutputValidBundle))\n\
      140:   }\n141: \n142:   def genExuBypassValidBundle(implicit p: Parameters):
      MixedVec[MixedVec[ValidIO[ExuBypassBundle]]] = {\n143:     MixedVec(this.issueBlockParams.map(_.genExuBypassValidBundle))\n\
      144:   }\n145: \n146:   def wakeUpInExuSources: Seq[WakeUpSource] = {\n147:\
      \     issueBlockParams\n148:       .flatMap(_.wakeUpInExuSources)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/SchdBlockParams.scala
    lines: 153-164
    context: "153:     issueBlockParams\n154:       .flatMap(_.wakeUpOutExuSources)\n\
      155:       .distinctBy(_.name)\n156:   }\n157: \n158:   def genIQWakeUpInValidBundle(implicit
      p: Parameters): MixedVec[ValidIO[IssueQueueIQWakeUpBundle]] = {\n159:     MixedVec(this.wakeUpInExuSources.map(x
      => {\n160:       val param = x.getExuParam(backendParam.allExuParams)\n161:\
      \       val isCopyPdest = param.copyWakeupOut\n162:       val copyNum = param.copyNum\n\
      163:       ValidIO(new IssueQueueIQWakeUpBundle(backendParam.getExuIdx(x.name),
      backendParam, isCopyPdest, copyNum))\n164:       })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/SchdBlockParams.scala
    lines: 163-174
    context: "163:       ValidIO(new IssueQueueIQWakeUpBundle(backendParam.getExuIdx(x.name),
      backendParam, isCopyPdest, copyNum))\n164:       })\n165:     )\n166:   }\n\
      167: \n168:   def genIQWakeUpOutValidBundle(implicit p: Parameters): MixedVec[ValidIO[IssueQueueIQWakeUpBundle]]
      = {\n169:     MixedVec(this.wakeUpOutExuSources.map(x => {\n170:       val param
      = x.getExuParam(backendParam.allExuParams)\n171:       val isCopyPdest = param.copyWakeupOut\n\
      172:       val copyNum = param.copyNum\n173:       ValidIO(new IssueQueueIQWakeUpBundle(backendParam.getExuIdx(x.name),
      backendParam, isCopyPdest, copyNum))\n174:       })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/SchdBlockParams.scala
    lines: 173-183
    context: "173:       ValidIO(new IssueQueueIQWakeUpBundle(backendParam.getExuIdx(x.name),
      backendParam, isCopyPdest, copyNum))\n174:       })\n175:     )\n176:   }\n\
      177: \n178:   def genWBWakeUpSinkValidBundle(implicit p: Parameters): MixedVec[ValidIO[IssueQueueWBWakeUpBundle]]
      = {\n179:     val intBundle: Seq[ValidIO[IssueQueueWBWakeUpBundle]] = schdType
      match {\n180:       case IntScheduler() | MemScheduler() => backendParam.getIntWBExeGroup.map(x
      => ValidIO(new IssueQueueWBWakeUpBundle(x._2.map(_.exuIdx), backendParam))).toSeq\n\
      181:       case _ => Seq()\n182:     }\n183:     val fpBundle: Seq[ValidIO[IssueQueueWBWakeUpBundle]]
      = schdType match {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/SchdBlockParams.scala
    lines: 194-224
    context: "194:     }\n195:     val vlBundle = schdType match {\n196:       case
      VfScheduler() | MemScheduler() => backendParam.getVlWBExeGroup.map(x => ValidIO(new
      IssueQueueWBWakeUpBundle(x._2.map(_.exuIdx), backendParam))).toSeq\n197:   \
      \    case _ => Seq()\n198:     }\n199:     MixedVec(intBundle ++ fpBundle ++
      vfBundle ++ v0Bundle ++ vlBundle)\n200:   }\n201: \n202:   def genIntWBWakeUpSinkValidBundle(implicit
      p: Parameters): MixedVec[ValidIO[IssueQueueWBWakeUpBundle]] = {\n203:     MixedVec(backendParam.getIntWBExeGroup.map(x
      => ValidIO(new IssueQueueWBWakeUpBundle(x._2.map(_.exuIdx), backendParam))).toSeq)\n\
      204:   }\n205: \n206:   def genFpWBWakeUpSinkValidBundle(implicit p: Parameters):
      MixedVec[ValidIO[IssueQueueWBWakeUpBundle]] = {\n207:     MixedVec(backendParam.getFpWBExeGroup.map(x
      => ValidIO(new IssueQueueWBWakeUpBundle(x._2.map(_.exuIdx), backendParam))).toSeq)\n\
      208:   }\n209: \n210:   def genVfWBWakeUpSinkValidBundle(implicit p: Parameters):
      MixedVec[ValidIO[IssueQueueWBWakeUpBundle]] = {\n211:     MixedVec(backendParam.getVfWBExeGroup.map(x
      => ValidIO(new IssueQueueWBWakeUpBundle(x._2.map(_.exuIdx), backendParam))).toSeq)\n\
      212:   }\n213: \n214:   def genV0WBWakeUpSinkValidBundle(implicit p: Parameters):
      MixedVec[ValidIO[IssueQueueWBWakeUpBundle]] = {\n215:     MixedVec(backendParam.getV0WBExeGroup.map(x
      => ValidIO(new IssueQueueWBWakeUpBundle(x._2.map(_.exuIdx), backendParam))).toSeq)\n\
      216:   }\n217: \n218:   def genVlWBWakeUpSinkValidBundle(implicit p: Parameters):
      MixedVec[ValidIO[IssueQueueWBWakeUpBundle]] = {\n219:     MixedVec(backendParam.getVlWBExeGroup.map(x
      => ValidIO(new IssueQueueWBWakeUpBundle(x._2.map(_.exuIdx), backendParam))).toSeq)\n\
      220:   }\n221: \n222:   // cfgs(issueIdx)(exuIdx)(set of exu's wb)\n223:   def
      getWbCfgs: Seq[Seq[Set[PregWB]]] = {\n224:     this.issueBlockParams.map(_.getWbCfgs)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EnqEntry.scala
    lines: 51-64
    context: "51: \n52:   //Wire\n53:   CommonWireConnect(common, hasWakeupIQ, validReg,
      currentStatus, io.commonIn, true)\n54: \n55:   when(io.commonIn.enq.valid) {\n\
      56:     assert(common.enqReady, s\"${params.getIQName}'s EnqEntry is not ready
      when enq is valid\\n\")\n57:   }\n58: \n59:   when(io.commonIn.enq.valid &&
      common.enqReady) {\n60:     entryRegNext := io.commonIn.enq.bits\n61:   }.otherwise
      {\n62:     entryRegNext := entryUpdate\n63:   }\n64: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EnqEntry.scala
    lines: 60-70
    context: "60:     entryRegNext := io.commonIn.enq.bits\n61:   }.otherwise {\n\
      62:     entryRegNext := entryUpdate\n63:   }\n64: \n65:   when(io.commonIn.enq.valid
      && common.enqReady) {\n66:     enqDelayValidRegNext := true.B\n67:   }.otherwise
      {\n68:     enqDelayValidRegNext := false.B\n69:   }\n70: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EnqEntry.scala
    lines: 132-152
    context: "132:   }\n133: \n134:   // current status\n135:   currentStatus    \
      \                         := entryReg.status\n136:   when (enqDelayValidReg)
      {\n137:     currentStatus.srcStatus.zipWithIndex.foreach { case (srcStatus,
      srcIdx) =>\n138:       srcStatus.srcState                    := enqDelaySrcState(srcIdx)\n\
      139:       srcStatus.dataSources                 := enqDelayDataSources(srcIdx)\n\
      140:       srcStatus.srcLoadDependency           := enqDelaySrcLoadDependency(srcIdx)\n\
      141:       srcStatus.useRegCache.foreach(_       := enqDelayUseRegCache.get(srcIdx))\n\
      142:       srcStatus.regCacheIdx.foreach(_       := enqDelayRegCacheIdx.get(srcIdx))\n\
      143:     }\n144:   }\n145: \n146:   if (params.hasIQWakeUp) {\n147:     currentStatus.srcStatus.map(_.exuSources.get).zip(entryReg.status.srcStatus.map(_.exuSources.get)).zip(enqDelayExuSources.get).foreach
      {\n148:       case ((currExu, regExu), enqDelayExu) =>\n149:         currExu
      := Mux(enqDelayValidReg, enqDelayExu, regExu)\n150:     }\n151:   }\n152: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 30-45
    context: "30:     val issueTimer            = UInt(2.W)\n31:     val deqPortIdx\
      \            = UInt(1.W)\n32:     //vector mem status\n33:     val vecMem  \
      \              = Option.when(params.isVecMemIQ)(new StatusVecMemPart)\n34: \n\
      35:     def srcReady: Bool        = {\n36:       VecInit(srcStatus.map(_.srcState).map(SrcState.isReady)).asUInt.andR\n\
      37:     }\n38: \n39:     def canIssue: Bool        = {\n40:       srcReady &&
      !issued && !blocked\n41:     }\n42: \n43:     def mergedLoadDependency: Vec[UInt]
      = {\n44:       srcStatus.map(_.srcLoadDependency).reduce({\n45:         case
      (l: Vec[UInt], r: Vec[UInt]) => VecInit(l.zip(r).map(x => x._1 | x._2))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 95-109
    context: "95:     val imm                   = Option.when(params.needImm)(UInt((params.deqImmTypesMaxLen).W))\n\
      96:     val payload               = new DynInst()\n97:   }\n98: \n99:   class
      CommonInBundle(implicit p: Parameters, params: IssueBlockParams) extends XSBundle
      {\n100:     val flush                 = Flipped(ValidIO(new Redirect))\n101:\
      \     val enq                   = Flipped(ValidIO(new EntryBundle))\n102:  \
      \   //wakeup\n103:     val wakeUpFromWB: MixedVec[ValidIO[IssueQueueWBWakeUpBundle]]
      = Flipped(params.genWBWakeUpSinkValidBundle)\n104:     val wakeUpFromIQ: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]]
      = Flipped(params.genIQWakeUpSinkValidBundle)\n105:     // vl\n106:     val vlFromIntIsZero\
      \       = Input(Bool())\n107:     val vlFromIntIsVlmax      = Input(Bool())\n\
      108:     val vlFromVfIsZero        = Input(Bool())\n109:     val vlFromVfIsVlmax\
      \       = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 140-150
    context: "140:     val entry                 = ValidIO(new EntryBundle)\n141:\
      \     val cancelBypass          = Output(Bool())\n142:     val deqPortIdxRead\
      \        = Output(UInt(1.W))\n143:     val issueTimerRead        = Output(UInt(2.W))\n\
      144:     //trans\n145:     val enqReady              = Output(Bool())\n146:\
      \     val transEntry            = ValidIO(new EntryBundle)\n147:     // debug\n\
      148:     val entryInValid          = Output(Bool())\n149:     val entryOutDeqValid\
      \      = Output(Bool())\n150:     val entryOutTransValid    = Output(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 154-167
    context: "154:     val perfWakeupByIQ        = Option.when(params.hasIQWakeUp)(Output(Vec(params.numRegSrc,
      Vec(params.numWakeupFromIQ, Bool()))))\n155:   }\n156: \n157:   class CommonWireBundle(implicit
      p: Parameters, params: IssueBlockParams) extends XSBundle {\n158:     val validRegNext\
      \          = Bool()\n159:     val flushed               = Bool()\n160:     val
      clear                 = Bool()\n161:     val canIssue              = Bool()\n\
      162:     val enqReady              = Bool()\n163:     val deqSuccess       \
      \     = Bool()\n164:     val srcWakeupByWB         = Vec(params.numRegSrc, Bool())\n\
      165:     val vlWakeupByIntWb       = Bool()\n166:     val vlWakeupByVfWb   \
      \     = Bool()\n167:     val srcCancelVec          = Vec(params.numRegSrc, Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 170-180
    context: "170:     val srcLoadDependencyNext = Vec(params.numRegSrc, Vec(LoadPipelineWidth,
      UInt(LoadDependencyWidth.W)))\n171:   }\n172: \n173:   def CommonWireConnect(common:
      CommonWireBundle, hasIQWakeup: Option[CommonIQWakeupBundle], validReg: Bool,
      status: Status, commonIn: CommonInBundle, isEnq: Boolean)(implicit p: Parameters,
      params: IssueBlockParams) = {\n174:     val hasIQWakeupGet        = hasIQWakeup.getOrElse(0.U.asTypeOf(new
      CommonIQWakeupBundle))\n175:     common.flushed            := status.robIdx.needFlush(commonIn.flush)\n\
      176:     common.deqSuccess         := (if (params.isVecMemIQ) status.issued
      else true.B) &&\n177:       commonIn.issueResp.valid && RespType.succeed(commonIn.issueResp.bits.resp)
      && !common.srcLoadCancelVec.asUInt.orR\n178:     common.srcWakeupByWB      :=
      commonIn.wakeUpFromWB.map{ bundle =>\n179:                                 \
      \    val psrcSrcTypeVec = status.srcStatus.map(_.psrc) zip status.srcStatus.map(_.srcType)\n\
      180:                                     if (params.numRegSrc == 5) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 184-205
    context: "184:                                     }\n185:                   \
      \                  else\n186:                                       bundle.bits.wakeUp(psrcSrcTypeVec,
      bundle.valid)\n187:                                  }.transpose.map(x => VecInit(x.toSeq).asUInt.orR).toSeq\n\
      188:     common.canIssue           := validReg && status.canIssue\n189:    \
      \ common.enqReady           := !validReg || commonIn.transSel\n190:     common.clear\
      \              := common.flushed || common.deqSuccess || commonIn.transSel\n\
      191:     common.srcCancelVec.zip(hasIQWakeupGet.srcWakeupByIQWithoutCancel).zipWithIndex.foreach
      { case ((srcCancel, wakeUpByIQVec), srcIdx) =>\n192:       common.srcLoadTransCancelVec(srcIdx)
      := (if(params.hasIQWakeUp) Mux1H(wakeUpByIQVec, hasIQWakeupGet.wakeupLoadDependencyByIQVec.map(dep
      => LoadShouldCancel(Some(dep), commonIn.ldCancel))) else false.B)\n193:    \
      \   common.srcLoadCancelVec(srcIdx) := LoadShouldCancel(Some(status.srcStatus(srcIdx).srcLoadDependency),
      commonIn.ldCancel)\n194:       srcCancel := common.srcLoadTransCancelVec(srcIdx)
      || common.srcLoadCancelVec(srcIdx)\n195:     }\n196:     common.srcLoadDependencyNext.zip(status.srcStatus.map(_.srcLoadDependency)).foreach
      { case (ldsNext, lds) =>\n197:       ldsNext.zip(lds).foreach{ case (ldNext,
      ld) => ldNext := ld << 1 }\n198:     }\n199:     if(isEnq) {\n200:       common.validRegNext\
      \     := Mux(commonIn.enq.valid && common.enqReady, true.B, Mux(common.clear,
      false.B, validReg))\n201:     } else {\n202:       common.validRegNext     :=
      Mux(commonIn.enq.valid, true.B, Mux(common.clear, false.B, validReg))\n203:\
      \     }\n204:     if (params.numRegSrc == 5) {\n205:       // only when numRegSrc
      == 5 need vl"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 246-257
    context: "246:     hasIQWakeupGet.srcWakeupByIQ                    := wakeupVec.map(x
      => VecInit(x.zip(cancelSel).map { case (wakeup, cancel) => wakeup && !cancel
      }))\n247:     hasIQWakeupGet.srcWakeupByIQButCancel           := wakeupVec.map(x
      => VecInit(x.zip(cancelSel).map { case (wakeup, cancel) => wakeup && cancel
      }))\n248:     hasIQWakeupGet.srcWakeupByIQWithoutCancel       := wakeupVec.map(x
      => VecInit(x))\n249:     hasIQWakeupGet.wakeupLoadDependencyByIQVec      :=
      commonIn.wakeUpFromIQ.map(_.bits.loadDependency).toSeq\n250:     hasIQWakeupGet.canIssueBypass\
      \                   := validReg && !status.issued && !status.blocked &&\n251:\
      \       VecInit(status.srcStatus.map(_.srcState).zip(hasIQWakeupGet.srcWakeupByIQWithoutCancel).zipWithIndex.map
      { case ((state, wakeupVec), srcIdx) =>\n252:         wakeupVec.asUInt.orR |
      state\n253:       }).asUInt.andR\n254:   }\n255: \n256: \n257:   def ShiftLoadDependency(hasIQWakeupGet:
      CommonIQWakeupBundle)(implicit p: Parameters, params: IssueBlockParams) = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 255-266
    context: "255: \n256: \n257:   def ShiftLoadDependency(hasIQWakeupGet: CommonIQWakeupBundle)(implicit
      p: Parameters, params: IssueBlockParams) = {\n258:     hasIQWakeupGet.shiftedWakeupLoadDependencyByIQVec\n\
      259:       .zip(hasIQWakeupGet.wakeupLoadDependencyByIQVec)\n260:       .zip(params.wakeUpInExuSources.map(_.name)).foreach
      {\n261:       case ((deps, originalDeps), name) => deps.zip(originalDeps).zipWithIndex.foreach
      {\n262:         case ((dep, originalDep), deqPortIdx) =>\n263:           if
      (params.backendParam.getLdExuIdx(params.backendParam.allExuParams.find(_.name
      == name).get) == deqPortIdx)\n264:             dep := 1.U\n265:           else\n\
      266:             dep := originalDep << 1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 279-290
    context: "279:     val hasIQWakeupGet                                 = hasIQWakeup.getOrElse(0.U.asTypeOf(new
      CommonIQWakeupBundle))\n280:     val cancelBypassVec                       \
      \         = Wire(Vec(params.numRegSrc, Bool()))\n281:     val srcCancelByLoad\
      \                                = common.srcLoadCancelVec.asUInt.orR\n282:\
      \     val respIssueFail                                  = commonIn.issueResp.valid
      && RespType.isBlocked(commonIn.issueResp.bits.resp)\n283:     entryUpdate.status.robIdx\
      \                         := status.robIdx\n284:     entryUpdate.status.fuType\
      \                         := IQFuType.readFuType(status.fuType, params.getFuCfgs.map(_.fuType))\n\
      285:     entryUpdate.status.srcStatus.zip(status.srcStatus).zipWithIndex.foreach
      { case ((srcStatusNext, srcStatus), srcIdx) =>\n286:       val srcLoadCancel
      = common.srcLoadCancelVec(srcIdx)\n287:       val loadTransCancel = common.srcLoadTransCancelVec(srcIdx)\n\
      288:       val wakeupByWB = common.srcWakeupByWB(srcIdx)\n289:       val wakeupByIQ
      = hasIQWakeupGet.srcWakeupByIQ(srcIdx).asUInt.orR && !loadTransCancel\n290:\
      \       val wakeupByIQOH = hasIQWakeupGet.srcWakeupByIQ(srcIdx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 328-339
    context: "328:                                                             //
      Vf / Mem -> Vf\n329:                                                       \
      \      MuxCase(srcStatus.dataSources.value, Seq(\n330:                     \
      \                                          ignoreOldVd                     \
      \  -> DataSource.imm,\n331:                                                \
      \               (wakeupByIQ && wakeupByMemIQ)     -> DataSource.bypass2,\n332:\
      \                                                               (wakeupByIQ
      && !wakeupByMemIQ)    -> DataSource.bypass,\n333:                          \
      \                                     srcStatus.dataSources.readBypass  -> DataSource.bypass2,\n\
      334:                                                               srcStatus.dataSources.readBypass2
      -> DataSource.reg,\n335:                                                   \
      \          ))\n336:                                                        \
      \   }\n337:                                                           else if
      (params.inMemSchd && params.readVfRf && params.hasIQWakeUp) {\n338:        \
      \                                                     // Vf / Int -> Mem\n339:\
      \                                                             MuxCase(srcStatus.dataSources.value,
      Seq("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 336-348
    context: "336:                                                           }\n337:\
      \                                                           else if (params.inMemSchd
      && params.readVfRf && params.hasIQWakeUp) {\n338:                          \
      \                                   // Vf / Int -> Mem\n339:               \
      \                                              MuxCase(srcStatus.dataSources.value,
      Seq(\n340:                                                               wakeupByIQ\
      \                                                               -> DataSource.bypass,\n\
      341:                                                               (srcStatus.dataSources.readBypass
      && wakeUpByVf(srcStatus.exuSources.get)) -> DataSource.bypass2,\n342:      \
      \                                                         (srcStatus.dataSources.readBypass
      && !wakeUpByVf(srcStatus.exuSources.get)) -> DataSource.reg,\n343:         \
      \                                                      srcStatus.dataSources.readBypass2\
      \                                        -> DataSource.reg,\n344:          \
      \                                                   ))\n345:               \
      \                                            }\n346:                       \
      \                                    else {\n347:                          \
      \                                   MuxCase(srcStatus.dataSources.value, Seq(\n\
      348:                                                               ignoreOldVd\
      \                        -> DataSource.imm,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 345-355
    context: "345:                                                           }\n346:\
      \                                                           else {\n347:   \
      \                                                          MuxCase(srcStatus.dataSources.value,
      Seq(\n348:                                                               ignoreOldVd\
      \                        -> DataSource.imm,\n349:                          \
      \                                     wakeupByIQ                         ->
      DataSource.bypass,\n350:                                                   \
      \            srcStatus.dataSources.readBypass   -> DataSource.reg,\n351:   \
      \                                                          ))\n352:        \
      \                                                   })\n353:       if(params.hasIQWakeUp)
      {\n354:         srcStatusNext.exuSources.get.value            := Mux(wakeupByIQOH.asUInt.orR,\n\
      355:                                                             ExuSource().fromExuOH(params,
      Mux1H(wakeupByIQOH, params.wakeUpSourceExuIdx.map(x => MathUtils.IntToOH(x).U(p(XSCoreParamsKey).backendParams.numExu.W)))),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 377-387
    context: "377:                                                           (srcCancelByLoad
      || respIssueFail)                -> false.B,\n378:                         \
      \                                 ))\n379:     entryUpdate.status.firstIssue\
      \                     := commonIn.deqSel || status.firstIssue\n380:     entryUpdate.status.issueTimer\
      \                     := Mux(commonIn.deqSel, 0.U, Mux(status.issued, Mux(status.issueTimer
      === \"b11\".U, status.issueTimer, status.issueTimer + 1.U), \"b11\".U))\n381:\
      \     entryUpdate.status.deqPortIdx                     := Mux(commonIn.deqSel,
      commonIn.deqPortIdxWrite, Mux(status.issued, status.deqPortIdx, 0.U))\n382:\
      \     entryUpdate.imm.foreach(_                         := entryReg.imm.get)\n\
      383:     entryUpdate.payload                               := entryReg.payload\n\
      384:     if (params.isVecMemIQ) {\n385:       entryUpdate.status.vecMem.get
      := entryReg.status.vecMem.get\n386:     }\n387:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 388-415
    context: "388: \n389:   def CommonOutConnect(commonOut: CommonOutBundle, common:
      CommonWireBundle, hasIQWakeup: Option[CommonIQWakeupBundle], validReg: Bool,
      entryUpdate: EntryBundle, entryReg: EntryBundle, status: Status, commonIn: CommonInBundle,
      isEnq: Boolean, isComp: Boolean)(implicit p: Parameters, params: IssueBlockParams)
      = {\n390:     val hasIQWakeupGet                                 = hasIQWakeup.getOrElse(0.U.asTypeOf(new
      CommonIQWakeupBundle))\n391:     commonOut.valid                           \
      \        := validReg\n392:     commonOut.issued                            \
      \      := entryReg.status.issued\n393:     commonOut.canIssue              \
      \                  := (if (isComp) (common.canIssue || hasIQWakeupGet.canIssueBypass)
      && !common.flushed\n394:                                                   \
      \        else common.canIssue && !common.flushed)\n395:     commonOut.fuType\
      \                                  := IQFuType.readFuType(status.fuType, params.getFuCfgs.map(_.fuType)).asUInt\n\
      396:     commonOut.robIdx                                  := status.robIdx\n\
      397:     commonOut.dataSources.zipWithIndex.foreach{ case (dataSourceOut, srcIdx)
      =>\n398:       val wakeupByIQWithoutCancel = hasIQWakeupGet.srcWakeupByIQWithoutCancel(srcIdx).asUInt.orR\n\
      399:       val wakeupByIQWithoutCancelOH = hasIQWakeupGet.srcWakeupByIQWithoutCancel(srcIdx)\n\
      400:       val isWakeupByMemIQ = wakeupByIQWithoutCancelOH.zip(commonIn.wakeUpFromIQ).filter(_._2.bits.params.isMemExeUnit).map(_._1).fold(false.B)(_
      || _)\n401:       val useRegCache = status.srcStatus(srcIdx).useRegCache.getOrElse(false.B)
      && status.srcStatus(srcIdx).dataSources.readReg\n402:       dataSourceOut.value\
      \                             := (if (isComp)\n403:                        \
      \                                     if (params.inVfSchd && params.readVfRf
      && params.hasWakeupFromMem) {\n404:                                        \
      \                       MuxCase(status.srcStatus(srcIdx).dataSources.value,
      Seq(\n405:                                                                 (wakeupByIQWithoutCancel
      && !isWakeupByMemIQ)  -> DataSource.forward,\n406:                         \
      \                                        (wakeupByIQWithoutCancel && isWakeupByMemIQ)\
      \   -> DataSource.bypass,\n407:                                            \
      \                   ))\n408:                                               \
      \              } else {\n409:                                              \
      \                 MuxCase(status.srcStatus(srcIdx).dataSources.value, Seq(\n\
      410:                                                                 wakeupByIQWithoutCancel\
      \                        -> DataSource.forward,\n411:                      \
      \                                           useRegCache                    \
      \                -> DataSource.regcache,\n412:                             \
      \                                  ))\n413:                                \
      \                             }\n414:                                      \
      \                     else {\n415:                                         \
      \                      MuxCase(status.srcStatus(srcIdx).dataSources.value, Seq("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 425-435
    context: "425:     }\n426:     commonOut.issueTimerRead                      \
      \    := status.issueTimer\n427:     commonOut.deqPortIdxRead               \
      \           := status.deqPortIdx\n428: \n429:     if(params.hasIQWakeUp) {\n\
      430:       commonOut.exuSources.get.zipWithIndex.foreach{ case (exuSourceOut,
      srcIdx) =>\n431:         val wakeupByIQWithoutCancelOH = hasIQWakeupGet.srcWakeupByIQWithoutCancel(srcIdx)\n\
      432:         if (isComp)\n433:           exuSourceOut.value := Mux(wakeupByIQWithoutCancelOH.asUInt.orR,\n\
      434:                                     ExuSource().fromExuOH(params, Mux1H(wakeupByIQWithoutCancelOH,
      params.wakeUpSourceExuIdx.map(x => MathUtils.IntToOH(x).U(p(XSCoreParamsKey).backendParams.numExu.W)))),\n\
      435:                                     status.srcStatus(srcIdx).exuSources.get.value)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 439-449
    context: "439:     }\n440: \n441:     val srcLoadDependencyOut               \
      \            = Wire(chiselTypeOf(common.srcLoadDependencyNext))\n442:     if(params.hasIQWakeUp)
      {\n443:       val wakeupSrcLoadDependencyNext                  = hasIQWakeupGet.srcWakeupByIQWithoutCancel.map(x
      => Mux1H(x, hasIQWakeupGet.shiftedWakeupLoadDependencyByIQVec))\n444:      \
      \ srcLoadDependencyOut.zipWithIndex.foreach { case (ldOut, srcIdx) =>\n445:\
      \         ldOut                                         := (if (isComp) Mux(hasIQWakeupGet.srcWakeupByIQWithoutCancel(srcIdx).asUInt.orR,\n\
      446:                                                                       wakeupSrcLoadDependencyNext(srcIdx),\n\
      447:                                                                       common.srcLoadDependencyNext(srcIdx))\n\
      448:                                                           else common.srcLoadDependencyNext(srcIdx))\n\
      449:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 452-472
    context: "452:     }\n453:     commonOut.cancelBypass                        \
      \    := VecInit(hasIQWakeupGet.srcWakeupByIQWithoutCancel.zipWithIndex.map{
      case (wakeupVec, srcIdx) =>\n454:                                          \
      \                   if (isComp) Mux(wakeupVec.asUInt.orR, common.srcLoadTransCancelVec(srcIdx),
      common.srcLoadCancelVec(srcIdx))\n455:                                     \
      \                        else common.srcLoadCancelVec(srcIdx)\n456:        \
      \                                                  }).asUInt.orR\n457:     commonOut.entry.bits.status.srcStatus.map(_.srcLoadDependency).zipWithIndex.foreach
      { case (ldOut, srcIdx) =>\n458:       ldOut                                \
      \           := srcLoadDependencyOut(srcIdx)\n459:     }\n460: \n461:     commonOut.enqReady\
      \                                := common.enqReady\n462:     commonOut.transEntry.valid\
      \                        := validReg && !common.flushed && !status.issued\n\
      463:     commonOut.transEntry.bits                         := entryUpdate\n\
      464:     // debug\n465:     commonOut.entryInValid                         \
      \   := commonIn.enq.valid\n466:     commonOut.entryOutDeqValid             \
      \           := validReg && (common.flushed || common.deqSuccess)\n467:     commonOut.entryOutTransValid\
      \                      := validReg && commonIn.transSel && !(common.flushed
      || common.deqSuccess)\n468:     commonOut.perfWakeupByWB                   \
      \       := common.srcWakeupByWB.zip(status.srcStatus).map{ case (w, s) => w
      && SrcState.isBusy(s.srcState) && validReg }\n469:     if (params.hasIQWakeUp)
      {\n470:       commonOut.perfLdCancel.get                      := common.srcCancelVec.map(_
      && validReg)\n471:       commonOut.perfOg0Cancel.get                     :=
      hasIQWakeupGet.srcWakeupByIQButCancel.map(_.asUInt.orR && validReg)\n472:  \
      \     commonOut.perfWakeupByIQ.get                    := hasIQWakeupGet.srcWakeupByIQ.map(x
      => VecInit(x.map(_ && validReg)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 493-505
    context: "493:   object IQFuType {\n494:     def num = FuType.num\n495: \n496:\
      \     def apply() = Vec(num, Bool())\n497: \n498:     def readFuType(fuType:
      Vec[Bool], fus: Seq[FuType.OHType]): Vec[Bool] = {\n499:       val res = WireDefault(0.U.asTypeOf(fuType))\n\
      500:       fus.foreach(x => res(x.id) := fuType(x.id))\n501:       res\n502:\
      \     }\n503:   }\n504: \n505:   class EnqDelayInBundle(implicit p: Parameters,
      params: IssueBlockParams) extends XSBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 502-513
    context: "502:     }\n503:   }\n504: \n505:   class EnqDelayInBundle(implicit
      p: Parameters, params: IssueBlockParams) extends XSBundle {\n506:     //wakeup\n\
      507:     val wakeUpFromWB: MixedVec[ValidIO[IssueQueueWBWakeUpBundle]] = Flipped(params.genWBWakeUpSinkValidBundle)\n\
      508:     val wakeUpFromIQ: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]] = Flipped(params.genIQWakeUpSinkValidBundle)\n\
      509:     //cancel\n510:     val srcLoadDependency     = Input(Vec(params.numRegSrc,
      Vec(LoadPipelineWidth, UInt(LoadDependencyWidth.W))))\n511:     val og0Cancel\
      \             = Input(ExuVec())\n512:     val ldCancel              = Vec(backendParams.LdExuCnt,
      Flipped(new LoadCancelIO))\n513:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 519-529
    context: "519:     val srcCancelByLoad: Vec[Bool]                          = Vec(params.numRegSrc,
      Bool())\n520:     val shiftedWakeupLoadDependencyByIQVec: Vec[Vec[UInt]]  =
      Vec(params.numWakeupFromIQ, Vec(LoadPipelineWidth, UInt(LoadDependencyWidth.W)))\n\
      521:   }\n522: \n523:   def EnqDelayWakeupConnect(enqDelayIn: EnqDelayInBundle,
      enqDelayOut: EnqDelayOutBundle, status: Status, delay: Int)(implicit p: Parameters,
      params: IssueBlockParams) = {\n524:     enqDelayOut.srcWakeUpByWB.zipWithIndex.foreach
      { case (wakeup, i) =>\n525:       wakeup := enqDelayIn.wakeUpFromWB.map{ x =>\n\
      526:         if (i == 3)\n527:           x.bits.wakeUpV0((status.srcStatus(i).psrc,
      status.srcStatus(i).srcType), x.valid)\n528:         else if (i == 4)\n529:\
      \           x.bits.wakeUpVl((status.srcStatus(i).psrc, status.srcStatus(i).srcType),
      x.valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 526-536
    context: "526:         if (i == 3)\n527:           x.bits.wakeUpV0((status.srcStatus(i).psrc,
      status.srcStatus(i).srcType), x.valid)\n528:         else if (i == 4)\n529:\
      \           x.bits.wakeUpVl((status.srcStatus(i).psrc, status.srcStatus(i).srcType),
      x.valid)\n530:         else\n531:           x.bits.wakeUp(Seq((status.srcStatus(i).psrc,
      status.srcStatus(i).srcType)), x.valid).head\n532:       }.reduce(_ || _)\n\
      533:     }\n534: \n535:     if (params.hasIQWakeUp) {\n536:       val wakeupVec:
      IndexedSeq[IndexedSeq[Bool]] = enqDelayIn.wakeUpFromIQ.map{ x =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 548-562
    context: "548:     } else {\n549:       enqDelayOut.srcWakeUpByIQVec := 0.U.asTypeOf(enqDelayOut.srcWakeUpByIQVec)\n\
      550:     }\n551: \n552:     if (params.hasIQWakeUp) {\n553:       enqDelayOut.srcWakeUpByIQ.zipWithIndex.foreach
      { case (wakeup, i) =>\n554:         val ldTransCancel = Mux1H(enqDelayOut.srcWakeUpByIQVec(i),
      enqDelayIn.wakeUpFromIQ.map(_.bits.loadDependency).map(dp => LoadShouldCancel(Some(dp),
      enqDelayIn.ldCancel)).toSeq)\n555:         wakeup := enqDelayOut.srcWakeUpByIQVec(i).asUInt.orR
      && !ldTransCancel\n556:       }\n557:       enqDelayOut.srcCancelByLoad.zipWithIndex.foreach
      { case (ldCancel, i) =>\n558:         ldCancel := LoadShouldCancel(Some(enqDelayIn.srcLoadDependency(i)),
      enqDelayIn.ldCancel)\n559:       }\n560:     } else {\n561:       enqDelayOut.srcWakeUpByIQ
      := 0.U.asTypeOf(enqDelayOut.srcWakeUpByIQ)\n562:       enqDelayOut.srcCancelByLoad
      := 0.U.asTypeOf(enqDelayOut.srcCancelByLoad)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 561-572
    context: "561:       enqDelayOut.srcWakeUpByIQ := 0.U.asTypeOf(enqDelayOut.srcWakeUpByIQ)\n\
      562:       enqDelayOut.srcCancelByLoad := 0.U.asTypeOf(enqDelayOut.srcCancelByLoad)\n\
      563:     }\n564: \n565:     enqDelayOut.shiftedWakeupLoadDependencyByIQVec.zip(enqDelayIn.wakeUpFromIQ.map(_.bits.loadDependency))\n\
      566:       .zip(params.wakeUpInExuSources.map(_.name)).foreach { case ((dps,
      ldps), name) =>\n567:       dps.zip(ldps).zipWithIndex.foreach { case ((dp,
      ldp), deqPortIdx) =>\n568:         if (params.backendParam.getLdExuIdx(params.backendParam.allExuParams.find(_.name
      == name).get) == deqPortIdx)\n569:           dp := 1.U << (delay - 1)\n570:\
      \         else\n571:           dp := ldp << delay\n572:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/NewAgeDetector.scala
    lines: 77-87
    context: "77:     VecInit((0 until numEntries).map(i => {\n78:       (VecInit((0
      until numEntries).map(j => get(i, j))).asUInt | ~canIssue).andR & canIssue(i)\n\
      79:     })).asUInt\n80:   }\n81: \n82:   io.out.zip(io.canIssue).foreach { case
      (out, canIssue) =>\n83:     out := getOldestCanIssue(get_age, canIssue)\n84:\
      \   }\n85: }\n86: \n87: object NewAgeDetector {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/NewAgeDetector.scala
    lines: 88-98
    context: "88:   def apply(numEntries: Int, enq: Vec[Bool], canIssue: Vec[UInt])(implicit
      p: Parameters): Vec[Valid[UInt]] = {\n89:     val age = Module(new NewAgeDetector(numEntries,
      enq.length, canIssue.length))\n90:     age.io.enq := enq\n91:     age.io.canIssue
      := canIssue\n92:     val outVec = Wire(Vec(canIssue.length, Valid(UInt(numEntries.W))))\n\
      93:     outVec.zipWithIndex.foreach { case (out, i) =>\n94:       out.valid
      := canIssue(i).orR\n95:       out.bits := age.io.out(i)\n96:       when (out.valid)
      {\n97:         assert(PopCount(out.bits) === 1.U, s\"out ($i) is not ont-hot
      when there is at least one entry can be issued\\n\")\n98:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EnqPolicy.scala
    lines: 16-25
    context: "16: \n17:   val canEnqVec = io.canEnq.asBools\n18:   // Todo: support
      more policies\n19:   val selVec: Seq[(Bool, Vec[Bool])] = io.enqSelOHVec.indices.map(i
      => SelectOne(\"circ\", canEnqVec, iqP.numEnq).getNthOH(i + 1))\n20: \n21:  \
      \ io.enqSelOHVec.zip(selVec).foreach { case (enqOH, (selValid, selOH)) =>\n\
      22:     enqOH.valid := selValid\n23:     enqOH.bits := selOH.asUInt\n24:   }\n\
      25: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/OthersEntry.scala
    lines: 43-53
    context: "43:     ShiftLoadDependency(hasWakeupIQ.get)\n44:     CommonIQWakeupConnect(common,
      hasWakeupIQ.get, validReg, entryReg.status, io.commonIn, false)\n45:   }\n46:\
      \ \n47:   when(io.commonIn.enq.valid) {\n48:     assert(common.enqReady, s\"\
      ${params.getIQName}'s OthersEntry is not ready when enq is valid\\n\")\n49:\
      \   }\n50: \n51:   when(io.commonIn.enq.valid) {\n52:     entryRegNext := io.commonIn.enq.bits\n\
      53:   }.otherwise {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/MultiWakeupQueue.scala
    lines: 4-17
    context: "4: import chisel3.util._\n5: import utils.PipeWithFlush\n6: import xiangshan.backend.Bundles.{ExuInput,
      connectSamePort}\n7: import xiangshan.backend.exu.ExeUnitParams\n8: \n9: class
      MultiWakeupQueueIO[T <: Bundle, TFlush <: Data](\n10:   gen       : ExuInput,\n\
      11:   lastGen   : ExuInput,\n12:   flushGen  : TFlush,\n13:   latWidth  : Int,\n\
      14: ) extends Bundle {\n15:   class EnqBundle extends Bundle {\n16:     val
      uop = Output(gen)\n17:     val lat = Output(UInt(latWidth.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/MultiWakeupQueue.scala
    lines: 15-35
    context: "15:   class EnqBundle extends Bundle {\n16:     val uop = Output(gen)\n\
      17:     val lat = Output(UInt(latWidth.W))\n18:   }\n19: \n20:   val flush =
      Input(flushGen)\n21:   val enq = Flipped(Valid(new EnqBundle))\n22:   val deq
      = Output(Valid(lastGen))\n23: }\n24: \n25: class MultiWakeupQueue[T <: Bundle,
      TFlush <: Data](\n26:   val gen       : ExuInput,\n27:   val lastGen   : ExuInput,\n\
      28:   val flushGen  : TFlush,\n29:   val latencySet: Set[Int],\n30:   flushFunc
      : (ExuInput, TFlush, Int) => Bool,\n31:   modificationFunc: ExuInput => ExuInput
      = { x: ExuInput => x },\n32:   lastConnectFunc: (ExuInput, ExuInput) => ExuInput,\n\
      33: ) extends Module {\n34:   require(latencySet.min >= 0)\n35: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/MultiWakeupQueue.scala
    lines: 31-50
    context: "31:   modificationFunc: ExuInput => ExuInput = { x: ExuInput => x },\n\
      32:   lastConnectFunc: (ExuInput, ExuInput) => ExuInput,\n33: ) extends Module
      {\n34:   require(latencySet.min >= 0)\n35: \n36:   val io = IO(new MultiWakeupQueueIO(gen,
      lastGen, flushGen, log2Up(latencySet.max) + 1))\n37: \n38:   val pipes = latencySet.map(x
      => Module(new PipeWithFlush[T, TFlush](gen, flushGen, x, flushFunc, modificationFunc))).toSeq\n\
      39: \n40:   val pipesOut = Wire(Valid(gen))\n41:   val lastConnect = Reg(Valid(lastGen))\n\
      42: \n43:   pipes.zip(latencySet).foreach {\n44:     case (pipe, lat) =>\n45:\
      \       pipe.io.flush := io.flush\n46:       pipe.io.enq.valid := io.enq.valid
      && io.enq.bits.lat === lat.U\n47:       pipe.io.enq.bits := io.enq.bits.uop\n\
      48:   }\n49: \n50:   private val pipesValidVec = VecInit(pipes.map(_.io.deq).zip(latencySet).map(_
      match {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/MultiWakeupQueue.scala
    lines: 47-57
    context: "47:       pipe.io.enq.bits := io.enq.bits.uop\n48:   }\n49: \n50:  \
      \ private val pipesValidVec = VecInit(pipes.map(_.io.deq).zip(latencySet).map(_
      match {\n51:     case (deq, 0) => deq.valid\n52:     case (deq, i) => deq.valid
      && !flushFunc(deq.bits, io.flush, i)\n53:   }))\n54:   private val pipesBitsVec
      = VecInit(pipes.map(_.io.deq.bits).zip(latencySet).map(_ match {\n55:     case
      (deq, 0) => deq\n56:     case (deq, i) => modificationFunc(deq)\n57:   }))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/MultiWakeupQueue.scala
    lines: 56-70
    context: "56:     case (deq, i) => modificationFunc(deq)\n57:   }))\n58: \n59:\
      \   pipesOut.valid := pipesValidVec.asUInt.orR\n60:   pipesOut.bits := Mux1H(pipesValidVec,
      pipesBitsVec)\n61:   pipesOut.bits.rfWen .foreach(_ := pipesValidVec.zip(pipesBitsVec.map(_.rfWen
      .get)).map{case(valid,wen) => valid && wen}.reduce(_||_))\n62:   pipesOut.bits.fpWen
      .foreach(_ := pipesValidVec.zip(pipesBitsVec.map(_.fpWen .get)).map{case(valid,wen)
      => valid && wen}.reduce(_||_))\n63:   pipesOut.bits.vecWen.foreach(_ := pipesValidVec.zip(pipesBitsVec.map(_.vecWen.get)).map{case(valid,wen)
      => valid && wen}.reduce(_||_))\n64:   pipesOut.bits.v0Wen .foreach(_ := pipesValidVec.zip(pipesBitsVec.map(_.v0Wen
      .get)).map{case(valid,wen) => valid && wen}.reduce(_||_))\n65:   pipesOut.bits.vlWen
      .foreach(_ := pipesValidVec.zip(pipesBitsVec.map(_.vlWen .get)).map{case(valid,wen)
      => valid && wen}.reduce(_||_))\n66: \n67:   lastConnect.valid := pipesOut.valid\n\
      68:   lastConnect.bits := lastConnectFunc(pipesOut.bits, lastConnect.bits)\n\
      69: \n70:   io.deq.valid := lastConnect.valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 129-139
    context: "129:   //cancel bypass\n130:   val cancelBypassVec        = Wire(Vec(params.numEntries,
      Bool()))\n131: \n132: \n133:   //enqEntries\n134:   enqEntries.zipWithIndex.foreach
      { case (enqEntry, entryIdx) =>\n135:     enqEntry.io.commonIn.enq          \
      \        := io.enq(entryIdx)\n136:     enqEntry.io.commonIn.transSel       \
      \      := (if (params.isAllComp || params.isAllSimp) enqCanTrans2Others.get
      && othersTransSelVec.get(entryIdx).valid\n137:                             \
      \                      else enqCanTrans2Simp.get && simpTransSelVec.get(entryIdx).valid
      || enqCanTrans2Comp.get && compTransSelVec.get(entryIdx).valid)\n138:     EntriesConnect(enqEntry.io.commonIn,
      enqEntry.io.commonOut, entryIdx)\n139:     enqEntry.io.enqDelayIn1.wakeUpFromWB
      := io.wakeUpFromWBDelayed"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 148-158
    context: "148:     enqEntry.io.enqDelayIn2.og0Cancel         := DelayN(io.og0Cancel,
      2)\n149:     enqEntry.io.enqDelayIn2.ldCancel          := DelayN(io.ldCancel,
      2)\n150:     enqEntryTransVec(entryIdx)                := enqEntry.io.commonOut.transEntry\n\
      151:   }\n152:   //othersEntries\n153:   othersEntries.zipWithIndex.foreach
      { case (othersEntry, entryIdx) =>\n154:     othersEntry.io.commonIn.enq    \
      \           := othersEntryEnqVec(entryIdx)\n155:     othersEntry.io.commonIn.transSel\
      \          := (if (params.hasCompAndSimp && (entryIdx < SimpEntryNum))\n156:\
      \                                                     io.simpEntryDeqSelVec.get.zip(simpCanTrans2Comp.get).map(x
      => x._1(entryIdx) && x._2).reduce(_ | _)\n157:                             \
      \                      else false.B)\n158:     EntriesConnect(othersEntry.io.commonIn,
      othersEntry.io.commonOut, entryIdx + EnqEntryNum)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 154-164
    context: "154:     othersEntry.io.commonIn.enq               := othersEntryEnqVec(entryIdx)\n\
      155:     othersEntry.io.commonIn.transSel          := (if (params.hasCompAndSimp
      && (entryIdx < SimpEntryNum))\n156:                                        \
      \             io.simpEntryDeqSelVec.get.zip(simpCanTrans2Comp.get).map(x =>
      x._1(entryIdx) && x._2).reduce(_ | _)\n157:                                \
      \                   else false.B)\n158:     EntriesConnect(othersEntry.io.commonIn,
      othersEntry.io.commonOut, entryIdx + EnqEntryNum)\n159:     othersEntryEnqReadyVec(entryIdx)\
      \          := othersEntry.io.commonOut.enqReady\n160:     if (params.hasCompAndSimp
      && (entryIdx < SimpEntryNum)) {\n161:       simpEntryTransVec.get(entryIdx)\
      \         := othersEntry.io.commonOut.transEntry\n162:     }\n163:   }\n164: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 161-172
    context: "161:       simpEntryTransVec.get(entryIdx)         := othersEntry.io.commonOut.transEntry\n\
      162:     }\n163:   }\n164: \n165: \n166:   deqSelVec.zip(deqPortIdxWriteVec).zipWithIndex.foreach
      { case ((deqSel, deqPortIdxWrite), i) =>\n167:     val deqVec = io.deqSelOH.zip(io.deqReady).map(x
      => x._1.valid && x._1.bits(i) && x._2)\n168:     deqPortIdxWrite := OHToUInt(deqVec)\n\
      169:     deqSel := deqVec.reduce(_ | _)\n170:   }\n171: \n172: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 185-203
    context: "185:     if (params.numEnq == 2) {\n186:       othersTransSelVec.get(1).valid
      := Mux(!validForTrans(0), othersTransPolicy.get.io.enqSelOHVec(0).valid, othersTransPolicy.get.io.enqSelOHVec(1).valid)
      && validForTrans(1)\n187:       othersTransSelVec.get(1).bits  := Mux(!validForTrans(0),
      othersTransPolicy.get.io.enqSelOHVec(0).bits,  othersTransPolicy.get.io.enqSelOHVec(1).bits)\n\
      188:     }\n189: \n190:     finalOthersTransSelVec.get.zip(othersTransSelVec.get).zipWithIndex.foreach
      { case ((finalOH, selOH), enqIdx) =>\n191:       finalOH := Fill(OthersEntryNum,
      enqCanTrans2Others.get && selOH.valid) & selOH.bits\n192:     }\n193: \n194:\
      \     //othersEntryEnq\n195:     othersEntryEnqVec.zipWithIndex.foreach { case
      (othersEntryEnq, othersIdx) =>\n196:       val othersEnqOH = finalOthersTransSelVec.get.map(_(othersIdx))\n\
      197:       if (othersEnqOH.size == 1)\n198:         othersEntryEnq := Mux(othersEnqOH.head,
      enqEntryTransVec.head, 0.U.asTypeOf(enqEntryTransVec.head))\n199:       else\n\
      200:         othersEntryEnq := Mux1H(othersEnqOH, enqEntryTransVec)\n201:  \
      \   }\n202:   }\n203:   else {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 208-218
    context: "208:     // we only allow all or none of the enq entries transfering
      to comp/simp entries.\n209:     // when all of simp entries are empty and comp
      entries are enough, transfer to comp entries.\n210:     // otherwise, transfer
      to simp entries.\n211:     enqCanTrans2Comp.get := PopCount(validVec.take(EnqEntryNum))
      <= PopCount(validVec.takeRight(CompEntryNum).map(!_)) && !validVec.drop(EnqEntryNum).take(SimpEntryNum).reduce(_
      || _)\n212:     enqCanTrans2Simp.get := !enqCanTrans2Comp.get && PopCount(validVec.take(EnqEntryNum))
      <= PopCount(simpEntryEnqReadyVec)\n213:     simpCanTrans2Comp.get.zipWithIndex.foreach
      { case (canTrans, idx) =>\n214:       canTrans := !enqCanTrans2Comp.get && PopCount(validVec.takeRight(CompEntryNum).map(!_))
      >= (idx + 1).U\n215:     }\n216: \n217:     // simp/compTransSelVec(i) is the
      target simp/comp entry for enq entry [i].\n218:     // note that dispatch does
      not guarantee the validity of enq entries with low index."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 227-240
    context: "227:       simpTransSelVec.get(1).bits  := Mux(!validForTrans(0), simpTransPolicy.get.io.enqSelOHVec(0).bits,\
      \  simpTransPolicy.get.io.enqSelOHVec(1).bits)\n228:       compTransSelVec.get(1).valid
      := Mux(!validForTrans(0), compTransPolicy.get.io.enqSelOHVec(0).valid, compTransPolicy.get.io.enqSelOHVec(1).valid)
      && validForTrans(1)\n229:       compTransSelVec.get(1).bits  := Mux(!validForTrans(0),
      compTransPolicy.get.io.enqSelOHVec(0).bits,  compTransPolicy.get.io.enqSelOHVec(1).bits)\n\
      230:     }\n231: \n232:     finalSimpTransSelVec.get.zip(simpTransSelVec.get).zipWithIndex.foreach
      { case ((finalOH, selOH), enqIdx) =>\n233:       finalOH := Fill(SimpEntryNum,
      enqCanTrans2Simp.get && selOH.valid) & selOH.bits\n234:     }\n235:     finalCompTransSelVec.get.zip(compTransSelVec.get).zip(compTransPolicy.get.io.enqSelOHVec).zipWithIndex.foreach
      {\n236:       case (((finalOH, selOH), origSelOH), enqIdx) =>\n237:        \
      \ finalOH := Mux(enqCanTrans2Comp.get, Fill(CompEntryNum, selOH.valid) & selOH.bits,
      Fill(CompEntryNum, origSelOH.valid) & origSelOH.bits)\n238:     }\n239: \n240:\
      \     //othersEntryEnq"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 236-262
    context: "236:       case (((finalOH, selOH), origSelOH), enqIdx) =>\n237:   \
      \      finalOH := Mux(enqCanTrans2Comp.get, Fill(CompEntryNum, selOH.valid)
      & selOH.bits, Fill(CompEntryNum, origSelOH.valid) & origSelOH.bits)\n238:  \
      \   }\n239: \n240:     //othersEntryEnq\n241:     simpEntryEnqVec.zipWithIndex.foreach
      { case (simpEntryEnq, simpIdx) =>\n242:       val simpEnqOH = finalSimpTransSelVec.get.map(_(simpIdx))\n\
      243:       // shit Mux1H directly returns in(0) if the seq has only 1 elements\n\
      244:       if (simpEnqOH.size == 1)\n245:         simpEntryEnq := Mux(simpEnqOH.head,
      enqEntryTransVec.head, 0.U.asTypeOf(enqEntryTransVec.head))\n246:       else\n\
      247:         simpEntryEnq := Mux1H(simpEnqOH, enqEntryTransVec)\n248:     }\n\
      249: \n250:     compEnqVec.get.zip(enqEntryTransVec).zip(io.simpEntryDeqSelVec.get).foreach
      { case ((compEnq, enqEntry), deqSel) =>\n251:       compEnq := Mux(enqCanTrans2Comp.get,
      enqEntry, Mux1H(deqSel, simpEntryTransVec.get))\n252:     }\n253:     compEntryEnqVec.zipWithIndex.foreach
      { case (compEntryEnq, compIdx) =>\n254:       val compEnqOH = finalCompTransSelVec.get.map(_(compIdx))\n\
      255:       // shit Mux1H directly returns in(0) if the seq has only 1 elements\n\
      256:       if (compEnqOH.size == 1)\n257:         compEntryEnq := Mux(compEnqOH.head,
      compEnqVec.get.head, 0.U.asTypeOf(compEnqVec.get.head))\n258:       else\n259:\
      \         compEntryEnq := Mux1H(compEnqOH, compEnqVec.get)\n260:     }\n261:\
      \ \n262:     assert(PopCount(simpEntryEnqVec.map(_.valid)) <= params.numEnq.U,
      \"the number of simpEntryEnq is more than numEnq\\n\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 267-277
    context: "267:     dontTouch(othersEntryEnqVec)\n268:   }\n269: \n270:   //issueRespVec\n\
      271:   if (params.needFeedBackSqIdx || params.needFeedBackLqIdx) {\n272:   \
      \  issueRespVec.lazyZip(sqIdxVec.get.zip(lqIdxVec.get)).lazyZip(issueTimerVec.lazyZip(deqPortIdxReadVec)).foreach
      { case (issueResp, (sqIdx, lqIdx), (issueTimer, deqPortIdx)) =>\n273:      \
      \ val respInDatapath = if (!params.isVecMemIQ) resps(issueTimer(0))(deqPortIdx)\n\
      274:                            else resps(issueTimer)(deqPortIdx)\n275:   \
      \    val respAfterDatapath = Wire(chiselTypeOf(respInDatapath))\n276:      \
      \ val hitRespsVec = VecInit(memEtyResps.map(x =>\n277:         x.valid &&"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 277-287
    context: "277:         x.valid &&\n278:         (if (params.needFeedBackSqIdx)
      x.bits.sqIdx.get === sqIdx else true.B) &&\n279:         (if (params.needFeedBackLqIdx)
      x.bits.lqIdx.get === lqIdx else true.B)\n280:       ).toSeq)\n281:       respAfterDatapath.valid
      := hitRespsVec.reduce(_ | _)\n282:       respAfterDatapath.bits  := (if (memEtyResps.size
      == 1) memEtyResps.head.bits\n283:                                   else Mux1H(hitRespsVec,
      memEtyResps.map(_.bits).toSeq))\n284:       issueResp := (if (!params.isVecMemIQ)
      Mux(issueTimer(1), respAfterDatapath, respInDatapath)\n285:                \
      \     else Mux(issueTimer === \"b11\".U, respAfterDatapath, respInDatapath))\n\
      286:     }\n287:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 284-294
    context: "284:       issueResp := (if (!params.isVecMemIQ) Mux(issueTimer(1),
      respAfterDatapath, respInDatapath)\n285:                     else Mux(issueTimer
      === \"b11\".U, respAfterDatapath, respInDatapath))\n286:     }\n287:   }\n288:\
      \   else {\n289:     issueRespVec.lazyZip(issueTimerVec.lazyZip(deqPortIdxReadVec)).foreach
      { case (issueResp, (issueTimer, deqPortIdx)) =>\n290:       val Resp = resps(issueTimer)(deqPortIdx)\n\
      291:       issueResp := Resp\n292:     }\n293:   }\n294: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 366-376
    context: "366:       assert(Mux1H(io.subDeqSelOH.get(1), entries).bits.status.robIdx
      === subDeqPolicyEntryVec(1).bits.status.robIdx, \"subDeqSelOH(1) is not the
      same\\n\")\n367:     }\n368:   }\n369:   else {\n370:     if (params.isAllComp
      || params.isAllSimp) {\n371:       io.othersEntryOldestSel.get.zipWithIndex.foreach
      { case (sel, i) =>\n372:         io.deqEntry(i)     := Mux(sel.valid, othersEntryOldest.get(i),
      enqEntryOldest(i))\n373:         io.cancelDeqVec(i) := Mux(sel.valid, othersEntryOldestCancel.get(i),
      enqEntryOldestCancel(i))\n374:       }\n375:     }\n376:     else {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 372-382
    context: "372:         io.deqEntry(i)     := Mux(sel.valid, othersEntryOldest.get(i),
      enqEntryOldest(i))\n373:         io.cancelDeqVec(i) := Mux(sel.valid, othersEntryOldestCancel.get(i),
      enqEntryOldestCancel(i))\n374:       }\n375:     }\n376:     else {\n377:  \
      \     io.compEntryOldestSel.get.zip(io.simpEntryOldestSel.get).zipWithIndex.foreach
      { case ((compSel, simpSel), i) =>\n378:         io.deqEntry(i)     := Mux(compSel.valid,\n\
      379:                                   compEntryOldest.get(i),\n380:       \
      \                            Mux(simpSel.valid, simpEntryOldest.get(i), enqEntryOldest(i)))\n\
      381:         io.cancelDeqVec(i) := Mux(compSel.valid,\n382:                \
      \                   compEntryOldestCancel.get(i),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 388-410
    context: "388:   io.valid                          := validVec.asUInt\n389:  \
      \ io.issued                         := issuedVec.asUInt\n390:   io.canIssue\
      \                       := canIssueVec.asUInt\n391:   io.fuType            \
      \             := fuTypeVec\n392:   io.dataSources                    := dataSourceVec\n\
      393:   io.exuSources.foreach(_           := exuSourceVec.get)\n394:   io.loadDependency\
      \                 := loadDependencyVec\n395:   io.isFirstIssue.zipWithIndex.foreach{
      case (isFirstIssue, deqIdx) =>\n396:     isFirstIssue                    :=
      io.deqSelOH(deqIdx).valid && Mux1H(io.deqSelOH(deqIdx).bits, isFirstIssueVec)\n\
      397:   }\n398:   io.simpEntryEnqSelVec.foreach(_   := finalSimpTransSelVec.get.zip(enqEntryTransVec).map(x
      => x._1 & Fill(SimpEntryNum, x._2.valid)))\n399:   io.compEntryEnqSelVec.foreach(_\
      \   := finalCompTransSelVec.get.zip(compEnqVec.get).map(x => x._1 & Fill(CompEntryNum,
      x._2.valid)))\n400:   io.othersEntryEnqSelVec.foreach(_ := finalOthersTransSelVec.get.zip(enqEntryTransVec).map(x
      => x._1 & Fill(OthersEntryNum, x._2.valid)))\n401:   io.robIdx.foreach(_   \
      \            := robIdxVec)\n402: \n403: \n404:   def EntriesConnect(in: CommonInBundle,
      out: CommonOutBundle, entryIdx: Int) = {\n405:     in.flush                \
      \    := io.flush\n406:     in.wakeUpFromWB             := io.wakeUpFromWB\n\
      407:     in.wakeUpFromIQ             := io.wakeUpFromIQ\n408:     in.vlFromIntIsZero\
      \          := io.vlFromIntIsZero\n409:     in.vlFromIntIsVlmax         := io.vlFromIntIsVlmax\n\
      410:     in.vlFromVfIsZero           := io.vlFromVfIsZero"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 429-439
    context: "429:     entries(entryIdx)           := out.entry\n430:     deqPortIdxReadVec(entryIdx)
      := out.deqPortIdxRead\n431:     issueTimerVec(entryIdx)     := out.issueTimerRead\n\
      432:     loadDependencyVec(entryIdx) := out.entry.bits.status.mergedLoadDependency\n\
      433:     cancelBypassVec(entryIdx)   := out.cancelBypass\n434:     exuSourceVec.foreach(_(entryIdx)
      := out.exuSources.get)\n435:     if (params.needFeedBackSqIdx || params.needFeedBackLqIdx)
      {\n436:       sqIdxVec.get(entryIdx) := out.entry.bits.payload.sqIdx\n437: \
      \      lqIdxVec.get(entryIdx) := out.entry.bits.payload.lqIdx\n438:     }\n\
      439:     entryInValidVec(entryIdx)       := out.entryInValid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 445-455
    context: "445:       perfOg0CancelVec.get(entryIdx)  := out.perfOg0Cancel.get\n\
      446:       perfWakeupByIQVec.get(entryIdx) := out.perfWakeupByIQ.get\n447: \
      \    }\n448:   }\n449: \n450:   io.vecLdIn.foreach(dontTouch(_))\n451: \n452:\
      \   // entries perf counter\n453:   // enq\n454:   for (i <- 0 until params.numEnq)
      {\n455:     XSPerfAccumulate(s\"enqEntry_${i}_in_cnt\", entryInValidVec(i))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 514-524
    context: "514:     }\n515:   }\n516: }\n517: \n518: class EntriesIO(implicit p:
      Parameters, params: IssueBlockParams) extends XSBundle {\n519:   val flush \
      \              = Flipped(ValidIO(new Redirect))\n520:   //enq\n521:   val enq\
      \                 = Vec(params.numEnq, Flipped(ValidIO(new EntryBundle)))\n\
      522:   val og0Resp             = Vec(params.numDeq, Flipped(ValidIO(new EntryDeqRespBundle)))\n\
      523:   val og1Resp             = Vec(params.numDeq, Flipped(ValidIO(new EntryDeqRespBundle)))\n\
      524:   val og2Resp             = OptionWrapper(params.needOg2Resp, Vec(params.numDeq,
      Flipped(ValidIO(new EntryDeqRespBundle))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 521-531
    context: "521:   val enq                 = Vec(params.numEnq, Flipped(ValidIO(new
      EntryBundle)))\n522:   val og0Resp             = Vec(params.numDeq, Flipped(ValidIO(new
      EntryDeqRespBundle)))\n523:   val og1Resp             = Vec(params.numDeq, Flipped(ValidIO(new
      EntryDeqRespBundle)))\n524:   val og2Resp             = OptionWrapper(params.needOg2Resp,
      Vec(params.numDeq, Flipped(ValidIO(new EntryDeqRespBundle))))\n525:   //deq
      sel\n526:   val deqReady            = Vec(params.numDeq, Input(Bool()))\n527:\
      \   val deqSelOH            = Vec(params.numDeq, Flipped(ValidIO(UInt(params.numEntries.W))))\n\
      528:   val enqEntryOldestSel   = Vec(params.numDeq, Flipped(ValidIO(UInt(params.numEnq.W))))\n\
      529:   val simpEntryOldestSel  = OptionWrapper(params.hasCompAndSimp, Vec(params.numDeq,
      Flipped(ValidIO(UInt(params.numSimp.W)))))\n530:   val compEntryOldestSel  =
      OptionWrapper(params.hasCompAndSimp, Vec(params.numDeq, Flipped(ValidIO(UInt(params.numComp.W)))))\n\
      531:   val othersEntryOldestSel= OptionWrapper(params.isAllComp || params.isAllSimp,
      Vec(params.numDeq, Flipped(ValidIO(UInt((params.numEntries - params.numEnq).W)))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 530-543
    context: "530:   val compEntryOldestSel  = OptionWrapper(params.hasCompAndSimp,
      Vec(params.numDeq, Flipped(ValidIO(UInt(params.numComp.W)))))\n531:   val othersEntryOldestSel=
      OptionWrapper(params.isAllComp || params.isAllSimp, Vec(params.numDeq, Flipped(ValidIO(UInt((params.numEntries
      - params.numEnq).W)))))\n532:   val subDeqRequest       = OptionWrapper(params.deqFuSame,
      Vec(params.numDeq, Input(UInt(params.numEntries.W))))\n533:   val subDeqSelOH\
      \         = OptionWrapper(params.deqFuSame, Vec(params.numDeq, Input(UInt(params.numEntries.W))))\n\
      534:   // wakeup\n535:   val wakeUpFromWB: MixedVec[ValidIO[IssueQueueWBWakeUpBundle]]
      = Flipped(params.genWBWakeUpSinkValidBundle)\n536:   val wakeUpFromIQ: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]]
      = Flipped(params.genIQWakeUpSinkValidBundle)\n537:   val wakeUpFromWBDelayed:
      MixedVec[ValidIO[IssueQueueWBWakeUpBundle]] = Flipped(params.genWBWakeUpSinkValidBundle)\n\
      538:   val wakeUpFromIQDelayed: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]]
      = Flipped(params.genIQWakeUpSinkValidBundle)\n539:   val vlFromIntIsZero   \
      \  = Input(Bool())\n540:   val vlFromIntIsVlmax    = Input(Bool())\n541:   val
      vlFromVfIsZero      = Input(Bool())\n542:   val vlFromVfIsVlmax     = Input(Bool())\n\
      543:   val og0Cancel           = Input(ExuVec())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/WakeupQueue.scala
    lines: 25-35
    context: "25: \n26: class WakeupQueue(number: Int)(implicit p: Parameters) extends
      XSModule {\n27:   val io = IO(new Bundle {\n28:     val in  = Flipped(ValidIO(new
      MicroOp))\n29:     val out = ValidIO(new MicroOp)\n30:     val redirect = Flipped(ValidIO(new
      Redirect))\n31:   })\n32:   if (number < 0) {\n33:     io.out.valid := false.B\n\
      34:     io.out.bits := DontCare\n35:   } else if(number == 0) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/WakeupQueue.scala
    lines: 39-53
    context: "39:   } else {\n40:     val queue = Seq.fill(number)(RegInit(0.U.asTypeOf(new
      Bundle{\n41:       val valid = Bool()\n42:       val bits = new MicroOp\n43:\
      \     })))\n44:     queue(0).valid := io.in.valid && !io.in.bits.robIdx.needFlush(io.redirect)\n\
      45:     queue(0).bits  := io.in.bits\n46:     (0 until (number-1)).map{i =>\n\
      47:       queue(i+1) := queue(i)\n48:       queue(i+1).valid := queue(i).valid
      && !queue(i).bits.robIdx.needFlush(io.redirect)\n49:     }\n50:     io.out.valid
      := queue(number-1).valid\n51:     io.out.bits := queue(number-1).bits\n52: \
      \    for (i <- 0 until number) {\n53:       XSDebug(queue(i).valid, p\"BPQue(${i.U}):
      pc:${Hexadecimal(queue(i).bits.cf.pc)} robIdx:${queue(i).bits.robIdx}\" +"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSDts.scala
    lines: 52-63
    context: "52:       val dtlb = Map(\n53:         \"d-tlb-size\" -> (ldtlbParams.NSets
      * ldtlbParams.NWays).asProperty,\n54:         \"d-tlb-sets\" -> 1.asProperty\n\
      55:       )\n56: \n57:       val itlb = Map(\n58:         \"i-tlb-size\" ->
      (itlbParams.NSets * itlbParams.NWays).asProperty,\n59:         \"i-tlb-sets\"\
      \ -> 1.asProperty\n60:       )\n61: \n62:       val mmu = Map(\n63:        \
      \ \"tlb-split\" -> Nil,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSDts.scala
    lines: 64-74
    context: "64:         \"mmu-type\" -> s\"riscv,sv$VAddrBits\".asProperty\n65:\
      \       )\n66: \n67:       val pmp = Nil\n68: \n69:       dcache ++ icache ++
      dtlb ++ itlb ++ mmu ++ pmp\n70:     }\n71: \n72:     def nextLevelCacheProperty:
      PropertyOption = {\n73:       if(coreParams.dcacheParametersOpt.nonEmpty){\n\
      74:         val outer = memBlock.inner.dcache.clientNode.edges.out.flatMap(_.manager.managers)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 63-73
    context: "63: \n64: object RSFeedbackType {\n65:   val lrqFull         = 0.U(4.W)\n\
      66:   val tlbMiss         = 1.U(4.W)\n67:   val mshrFull        = 2.U(4.W)\n\
      68:   val dataInvalid     = 3.U(4.W)\n69:   val bankConflict    = 4.U(4.W)\n\
      70:   val ldVioCheckRedo  = 5.U(4.W)\n71:   val feedbackInvalid = 7.U(4.W)\n\
      72:   val issueSuccess    = 8.U(4.W)\n73:   val rfArbitFail     = 9.U(4.W)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 124-134
    context: "124:   // raise exceptions from backend\n125:   val backendIGPF = Bool()
      // instruction guest page fault\n126:   val backendIPF = Bool() // instruction
      page fault\n127:   val backendIAF = Bool() // instruction access fault\n128:\
      \ \n129:   def fromFtqRedirectSram(entry: Ftq_Redirect_SRAMEntry) = {\n130:\
      \     // this.hist := entry.ghist\n131:     this.histPtr := entry.histPtr\n\
      132:     this.ssp := entry.ssp\n133:     this.sctr := entry.sctr\n134:     this.TOSW
      := entry.TOSW"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 186-202
    context: "186:   val fuOpType = FuOpType()\n187:   val rfWen = Bool()\n188:  \
      \ val fpWen = Bool()\n189:   val vecWen = Bool()\n190:   val isXSTrap = Bool()\n\
      191:   val noSpecExec = Bool() // wait forward\n192:   val blockBackward = Bool()
      // block backward\n193:   val flushPipe = Bool() // This inst will flush all
      the pipe when commit, like exception but can commit\n194:   val uopSplitType
      = UopSplitType()\n195:   val selImm = SelImm()\n196:   val imm = UInt(32.W)\n\
      197:   val commitType = CommitType()\n198:   val fpu = new FPUCtrlSignals\n\
      199:   val uopIdx = UopIdx()\n200:   val isMove = Bool()\n201:   val vm = Bool()\n\
      202:   val singleStep = Bool()"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 204-224
    context: "204:   // then replay from this inst itself\n205:   val replayInst =
      Bool()\n206:   val canRobCompress = Bool()\n207: \n208:   private def allSignals
      = srcType.take(3) ++ Seq(fuType, fuOpType, rfWen, fpWen, vecWen,\n209:     isXSTrap,
      noSpecExec, blockBackward, flushPipe, canRobCompress, uopSplitType, selImm)\n\
      210: \n211:   def decode(inst: UInt, table: Iterable[(BitPat, List[BitPat])]):
      CtrlSignals = {\n212:     val decoder = freechips.rocketchip.rocket.DecodeLogic(inst,
      XDecode.decodeDefault, table, EspressoMinimizer)\n213:     allSignals zip decoder
      foreach { case (s, d) => s := d }\n214:     commitType := DontCare\n215:   \
      \  this\n216:   }\n217: \n218:   def decode(bit: List[BitPat]): CtrlSignals
      = {\n219:     allSignals.zip(bit.map(bitPatToUInt(_))).foreach{ case (s, d)
      => s := d }\n220:     this\n221:   }\n222: \n223:   def isWFI: Bool = fuType
      === FuType.csr.U && fuOpType === CSROpType.wfi\n224:   def isSoftPrefetch: Bool
      = {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 266-294
    context: "266:   val lqIdx = new LqPtr\n267:   val sqIdx = new SqPtr\n268:   val
      eliminatedMove = Bool()\n269:   val snapshot = Bool()\n270:   val debugInfo
      = new PerfDebugInfo\n271:   def needRfRPort(index: Int, isFp: Boolean, ignoreState:
      Boolean = true) : Bool = {\n272:     val stateReady = srcState(index) === SrcState.rdy
      || ignoreState.B\n273:     val readReg = if (isFp) {\n274:       ctrl.srcType(index)
      === SrcType.fp\n275:     } else {\n276:       ctrl.srcType(index) === SrcType.reg
      && ctrl.lsrc(index) =/= 0.U\n277:     }\n278:     readReg && stateReady\n279:\
      \   }\n280:   def srcIsReady: Vec[Bool] = {\n281:     VecInit(ctrl.srcType.zip(srcState).map{
      case (t, s) => SrcType.isPcOrImm(t) || s === SrcState.rdy })\n282:   }\n283:\
      \   def clearExceptions(\n284:     exceptionBits: Seq[Int] = Seq(),\n285:  \
      \   flushPipe: Boolean = false,\n286:     replayInst: Boolean = false\n287:\
      \   ): MicroOp = {\n288:     cf.exceptionVec.zipWithIndex.filterNot(x => exceptionBits.contains(x._2)).foreach(_._1
      := false.B)\n289:     if (!flushPipe) { ctrl.flushPipe := false.B }\n290:  \
      \   if (!replayInst) { ctrl.replayInst := false.B }\n291:     this\n292:   }\n\
      293: }\n294: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 298-331
    context: "298: \n299: class MicroOpRbExt(implicit p: Parameters) extends XSBundleWithMicroOp
      {\n300:   val flag = UInt(1.W)\n301: }\n302: \n303: class Redirect(implicit
      p: Parameters) extends XSBundle {\n304:   val isRVC = Bool()\n305:   val robIdx
      = new RobPtr\n306:   val ftqIdx = new FtqPtr\n307:   val ftqOffset = UInt(log2Up(PredictWidth).W)\n\
      308:   val level = RedirectLevel()\n309:   val interrupt = Bool()\n310:   val
      cfiUpdate = new CfiUpdateInfo\n311:   val fullTarget = UInt(XLEN.W) // only
      used for tval storage in backend\n312: \n313:   val stFtqIdx = new FtqPtr //
      for load violation predict\n314:   val stFtqOffset = UInt(log2Up(PredictWidth).W)\n\
      315: \n316:   val debug_runahead_checkpoint_id = UInt(64.W)\n317:   val debugIsCtrl
      = Bool()\n318:   val debugIsMemVio = Bool()\n319: \n320:   def flushItself()
      = RedirectLevel.flushItself(level)\n321: }\n322: \n323: object Redirect extends
      HasCircularQueuePtrHelper {\n324: \n325:   def selectOldestRedirect(xs: Seq[Valid[Redirect]]):
      Vec[Bool] = {\n326:     val compareVec = (0 until xs.length).map(i => (0 until
      i).map(j => isAfter(xs(j).bits.robIdx, xs(i).bits.robIdx)))\n327:     val resultOnehot
      = VecInit((0 until xs.length).map(i => Cat((0 until xs.length).map(j =>\n328:\
      \       (if (j < i) !xs(j).valid || compareVec(i)(j)\n329:       else if (j
      == i) xs(i).valid\n330:       else !xs(j).valid || !compareVec(j)(i))\n331:\
      \     )).andR))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 342-352
    context: "342:   val isVl = Bool()\n343:   val preg = UInt(PhyRegIdxWidth.W)\n\
      344: }\n345: \n346: class DebugBundle(implicit p: Parameters) extends XSBundle
      {\n347:   val isMMIO = Bool()\n348:   val isNCIO = Bool()\n349:   val isPerfCnt
      = Bool()\n350:   val paddr = UInt(PAddrBits.W)\n351:   val vaddr = UInt(VAddrBits.W)\n\
      352: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 348-358
    context: "348:   val isNCIO = Bool()\n349:   val isPerfCnt = Bool()\n350:   val
      paddr = UInt(PAddrBits.W)\n351:   val vaddr = UInt(VAddrBits.W)\n352: \n353:\
      \   def isSkipDiff: Bool = isMMIO || isNCIO || isPerfCnt\n354:   /* add L/S
      inst info in EXU */\n355:   // val L1toL2TlbLatency = UInt(XLEN.W)\n356:   //
      val levelTlbHit = UInt(2.W)\n357: }\n358: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 383-393
    context: "383:   val externalInterrupt = new ExternalInterruptIO\n384:   val interrupt
      = Output(Bool())\n385: }\n386: \n387: class DiffCommitIO(implicit p: Parameters)
      extends XSBundle {\n388:   val isCommit = Bool()\n389:   val commitValid = Vec(CommitWidth
      * MaxUopSize, Bool())\n390: \n391:   val info = Vec(CommitWidth * MaxUopSize,
      new RabCommitInfo)\n392: }\n393: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 392-413
    context: "392: }\n393: \n394: class RobCommitInfo(implicit p: Parameters) extends
      RobCommitEntryBundle\n395: \n396: class RobCommitIO(implicit p: Parameters)
      extends XSBundle {\n397:   val isCommit = Bool()\n398:   val commitValid = Vec(CommitWidth,
      Bool())\n399: \n400:   val isWalk = Bool()\n401:   // valid bits optimized for
      walk\n402:   val walkValid = Vec(CommitWidth, Bool())\n403: \n404:   val info
      = Vec(CommitWidth, new RobCommitInfo)\n405:   val robIdx = Vec(CommitWidth,
      new RobPtr)\n406: \n407:   def hasWalkInstr: Bool = isWalk && walkValid.asUInt.orR\n\
      408:   def hasCommitInstr: Bool = isCommit && commitValid.asUInt.orR\n409: }\n\
      410: \n411: class RabCommitInfo(implicit p: Parameters) extends XSBundle {\n\
      412:   val ldest = UInt(LogicRegsWidth.W)\n413:   val pdest = UInt(PhyRegIdxWidth.W)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 418-439
    context: "418:   val vlWen = Bool()\n419:   val isMove = Bool()\n420: }\n421:\
      \ \n422: class RabCommitIO(implicit p: Parameters) extends XSBundle {\n423:\
      \   val isCommit = Bool()\n424:   val commitValid = Vec(RabCommitWidth, Bool())\n\
      425: \n426:   val isWalk = Bool()\n427:   // valid bits optimized for walk\n\
      428:   val walkValid = Vec(RabCommitWidth, Bool())\n429: \n430:   val info =
      Vec(RabCommitWidth, new RabCommitInfo)\n431:   val robIdx = OptionWrapper(!env.FPGAPlatform,
      Vec(RabCommitWidth, new RobPtr))\n432: \n433:   def hasWalkInstr: Bool = isWalk
      && walkValid.asUInt.orR\n434:   def hasCommitInstr: Bool = isCommit && commitValid.asUInt.orR\n\
      435: }\n436: \n437: class SnapshotPort(implicit p: Parameters) extends XSBundle
      {\n438:   val snptEnq = Bool()\n439:   val snptDeq = Bool()"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 437-447
    context: "437: class SnapshotPort(implicit p: Parameters) extends XSBundle {\n\
      438:   val snptEnq = Bool()\n439:   val snptDeq = Bool()\n440:   val useSnpt
      = Bool()\n441:   val snptSelect = UInt(log2Ceil(RenameSnapshotNum).W)\n442:\
      \   val flushVec = Vec(RenameSnapshotNum, Bool())\n443: }\n444: \n445: class
      RSFeedback(isVector: Boolean = false)(implicit p: Parameters) extends XSBundle
      {\n446:   val robIdx = new RobPtr\n447:   val hit = Bool()"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 443-453
    context: "443: }\n444: \n445: class RSFeedback(isVector: Boolean = false)(implicit
      p: Parameters) extends XSBundle {\n446:   val robIdx = new RobPtr\n447:   val
      hit = Bool()\n448:   val flushState = Bool()\n449:   val sourceType = RSFeedbackType()\n\
      450:   val dataInvalidSqIdx = new SqPtr\n451:   val sqIdx = new SqPtr\n452:\
      \   val lqIdx = new LqPtr\n453: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 496-506
    context: "496:     require(satp_value.getWidth == XLEN)\n497:     val sa = satp_value.asTypeOf(new
      SatpStruct)\n498:     mode := sa.mode\n499:     asid := sa.asid\n500:     ppn
      := sa.ppn\n501:     changed := DataChanged(sa.asid) // when ppn is changed,
      software need do the flush\n502:   }\n503: }\n504: \n505: class HgatpStruct(implicit
      p: Parameters) extends XSBundle {\n506:   val mode = UInt(4.W)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 516-526
    context: "516:     require(hgatp_value.getWidth == XLEN)\n517:     val sa = hgatp_value.asTypeOf(new
      HgatpStruct)\n518:     mode := sa.mode\n519:     vmid := sa.vmid\n520:     ppn
      := sa.ppn\n521:     changed := DataChanged(sa.vmid) // when ppn is changed,
      software need do the flush\n522:   }\n523: }\n524: \n525: // add mbmc csr\n\
      526: class MbmcStruct(implicit p: Parameters) extends XSBundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 578-588
    context: "578:   val bits = new Bundle {\n579:     val rs1 = Bool()\n580:    \
      \ val rs2 = Bool()\n581:     val addr = UInt(VAddrBits.W)\n582:     val id =
      UInt((AsidLength).W) // asid or vmid\n583:     val flushPipe = Bool()\n584:\
      \     val hv = Bool()\n585:     val hg = Bool()\n586:   }\n587: \n588:   override
      def toPrintable: Printable = {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 584-594
    context: "584:     val hv = Bool()\n585:     val hg = Bool()\n586:   }\n587: \n\
      588:   override def toPrintable: Printable = {\n589:     p\"valid:0x${Hexadecimal(valid)}
      rs1:${bits.rs1} rs2:${bits.rs2} addr:${Hexadecimal(bits.addr)}, flushPipe:${bits.flushPipe}\"\
      \n590:   }\n591: }\n592: \n593: // Bundle for load violation predictor updating\n\
      594: class MemPredUpdateReq(implicit p: Parameters) extends XSBundle  {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 804-814
    context: "804: }\n805: \n806: // custom l2 - l1 interface\n807: class L2ToL1Hint(implicit
      p: Parameters) extends XSBundle with HasDCacheParameters {\n808:   val sourceId
      = UInt(log2Up(cfg.nMissEntries).W)    // tilelink sourceID -> mshr id\n809:\
      \   val isKeyword = Bool()                             // miss entry keyword
      -> L1 load queue replay\n810: }\n811: \n812: class TopDownInfo(implicit p: Parameters)
      extends XSBundle {\n813:   val lqEmpty = Input(Bool())\n814:   val sqEmpty =
      Input(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSCore.scala
    lines: 87-98
    context: "87:     val msiInfo = Input(ValidIO(UInt(soc.IMSICParams.MSI_INFO_WIDTH.W)))\n\
      88:     val msiAck = Output(Bool())\n89:     val clintTime = Input(ValidIO(UInt(64.W)))\n\
      90:     val reset_vector = Input(UInt(PAddrBits.W))\n91:     val cpu_halt =
      Output(Bool())\n92:     val l2_flush_done = Input(Bool())\n93:     val l2_flush_en
      = Output(Bool())\n94:     val power_down_en = Output(Bool())\n95:     val cpu_critical_error
      = Output(Bool())\n96:     val resetInFrontend = Output(Bool())\n97:     val
      traceCoreInterface = new TraceCoreInterface\n98:     val l2PfCtrl = Output(new
      PrefetchCtrlFromCore)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSCore.scala
    lines: 101-111
    context: "101:     val l2_hint = Input(Valid(new L2ToL1Hint()))\n102:     val
      l2_tlb_req = Flipped(new TlbRequestIO(nRespDups = 2))\n103:     val l2_pmp_resp
      = new PMPRespBundle\n104:     val l2PfqBusy = Input(Bool())\n105:     val debugTopDown
      = new Bundle {\n106:       val robTrueCommit = Output(UInt(64.W))\n107:    \
      \   val robHeadPaddr = Valid(UInt(PAddrBits.W))\n108:       val l2MissMatch
      = Input(Bool())\n109:       val l3MissMatch = Input(Bool())\n110:     }\n111:\
      \     val topDownInfo = Input(new Bundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSCore.scala
    lines: 114-125
    context: "114:     })\n115:     val dft = Option.when(hasDFT)(Input(new SramBroadcastBundle))\n\
      116:     val dft_reset = Option.when(hasDFT)(Input(new DFTResetSignals()))\n\
      117:   })\n118: \n119:   dontTouch(io.l2_flush_done)\n120:   dontTouch(io.l2_flush_en)\n\
      121:   dontTouch(io.power_down_en)\n122: \n123:   println(s\"FPGAPlatform:${env.FPGAPlatform}
      EnableDebug:${env.EnableDebug}\")\n124: \n125:   val frontend = outer.frontend.module"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSCore.scala
    lines: 136-146
    context: "136:   frontend.io.fencei <> backend.io.fenceio.fencei\n137: \n138:\
      \   backend.io.fromTop := memBlock.io.mem_to_ooo.topToBackendBypass\n139: \n\
      140:   require(backend.io.mem.stIn.length == memBlock.io.mem_to_ooo.stIn.length)\n\
      141:   backend.io.mem.stIn.zip(memBlock.io.mem_to_ooo.stIn).foreach { case (sink,
      source) =>\n142:     sink.valid := source.valid\n143:     sink.bits := 0.U.asTypeOf(sink.bits)\n\
      144:     sink.bits.robIdx := source.bits.uop.robIdx\n145:     sink.bits.ssid
      := source.bits.uop.ssid\n146:     sink.bits.storeSetHit := source.bits.uop.storeSetHit"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSCore.scala
    lines: 167-177
    context: "167:   backend.io.mem.writebackSta <> memBlock.io.mem_to_ooo.writebackSta\n\
      168:   backend.io.mem.writebackHyuLda <> memBlock.io.mem_to_ooo.writebackHyuLda\n\
      169:   backend.io.mem.writebackHyuSta <> memBlock.io.mem_to_ooo.writebackHyuSta\n\
      170:   backend.io.mem.writebackStd <> memBlock.io.mem_to_ooo.writebackStd\n\
      171:   backend.io.mem.writebackVldu <> memBlock.io.mem_to_ooo.writebackVldu\n\
      172:   backend.io.mem.robLsqIO.mmio := memBlock.io.mem_to_ooo.lsqio.mmio\n173:\
      \   backend.io.mem.robLsqIO.uop := memBlock.io.mem_to_ooo.lsqio.uop\n174: \n\
      175:   // memblock error exception writeback, 1 cycle after normal writeback\n\
      176:   backend.io.mem.s3_delayed_load_error := memBlock.io.mem_to_ooo.s3_delayed_load_error\n\
      177: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSCore.scala
    lines: 197-207
    context: "197: \n198:   // top -> memBlock\n199:   memBlock.io.fromTopToBackend.clintTime
      := io.clintTime\n200:   memBlock.io.fromTopToBackend.msiInfo := io.msiInfo\n\
      201:   memBlock.io.hartId := io.hartId\n202:   memBlock.io.l2_flush_done :=
      io.l2_flush_done\n203:   memBlock.io.outer_reset_vector := io.reset_vector\n\
      204:   memBlock.io.outer_hc_perfEvents := io.perfEvents\n205:   // frontend
      -> memBlock\n206:   memBlock.io.inner_beu_errors_icache <> frontend.io.error.bits.toL1BusErrorUnitInfo(frontend.io.error.valid)\n\
      207:   memBlock.io.ooo_to_mem.backendToTopBypass := backend.io.toTop"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSCore.scala
    lines: 207-217
    context: "207:   memBlock.io.ooo_to_mem.backendToTopBypass := backend.io.toTop\n\
      208:   memBlock.io.ooo_to_mem.issueLda <> backend.io.mem.issueLda\n209:   memBlock.io.ooo_to_mem.issueSta
      <> backend.io.mem.issueSta\n210:   memBlock.io.ooo_to_mem.issueStd <> backend.io.mem.issueStd\n\
      211:   memBlock.io.ooo_to_mem.issueHya <> backend.io.mem.issueHylda\n212:  \
      \ backend.io.mem.issueHysta.foreach(_.ready := false.B) // this fake port should
      not be used\n213:   memBlock.io.ooo_to_mem.issueVldu <> backend.io.mem.issueVldu\n\
      214: \n215:   // By default, instructions do not have exceptions when they enter
      the function units.\n216:   memBlock.io.ooo_to_mem.issueUops.map(_.bits.uop.clearExceptions())\n\
      217:   memBlock.io.ooo_to_mem.storePc := backend.io.mem.storePcRead"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSCore.scala
    lines: 214-224
    context: "214: \n215:   // By default, instructions do not have exceptions when
      they enter the function units.\n216:   memBlock.io.ooo_to_mem.issueUops.map(_.bits.uop.clearExceptions())\n\
      217:   memBlock.io.ooo_to_mem.storePc := backend.io.mem.storePcRead\n218:  \
      \ memBlock.io.ooo_to_mem.hybridPc := backend.io.mem.hyuPcRead\n219:   memBlock.io.ooo_to_mem.flushSb
      := backend.io.fenceio.sbuffer.flushSb\n220:   memBlock.io.ooo_to_mem.loadFastMatch
      := 0.U.asTypeOf(memBlock.io.ooo_to_mem.loadFastMatch)\n221:   memBlock.io.ooo_to_mem.loadFastImm
      := 0.U.asTypeOf(memBlock.io.ooo_to_mem.loadFastImm)\n222:   memBlock.io.ooo_to_mem.loadFastFuOpType
      := 0.U.asTypeOf(memBlock.io.ooo_to_mem.loadFastFuOpType)\n223: \n224:   memBlock.io.ooo_to_mem.sfence
      <> backend.io.mem.sfence"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSCore.scala
    lines: 221-231
    context: "221:   memBlock.io.ooo_to_mem.loadFastImm := 0.U.asTypeOf(memBlock.io.ooo_to_mem.loadFastImm)\n\
      222:   memBlock.io.ooo_to_mem.loadFastFuOpType := 0.U.asTypeOf(memBlock.io.ooo_to_mem.loadFastFuOpType)\n\
      223: \n224:   memBlock.io.ooo_to_mem.sfence <> backend.io.mem.sfence\n225: \n\
      226:   memBlock.io.redirect := backend.io.mem.redirect\n227:   memBlock.io.ooo_to_mem.csrCtrl
      := backend.io.mem.csrCtrl\n228:   memBlock.io.ooo_to_mem.tlbCsr := backend.io.mem.tlbCsr\n\
      229:   memBlock.io.ooo_to_mem.lsqio.lcommit          := backend.io.mem.robLsqIO.lcommit\n\
      230:   memBlock.io.ooo_to_mem.lsqio.scommit          := backend.io.mem.robLsqIO.scommit\n\
      231:   memBlock.io.ooo_to_mem.lsqio.pendingMMIOld    := backend.io.mem.robLsqIO.pendingMMIOld"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSCore.scala
    lines: 230-240
    context: "230:   memBlock.io.ooo_to_mem.lsqio.scommit          := backend.io.mem.robLsqIO.scommit\n\
      231:   memBlock.io.ooo_to_mem.lsqio.pendingMMIOld    := backend.io.mem.robLsqIO.pendingMMIOld\n\
      232:   memBlock.io.ooo_to_mem.lsqio.pendingld        := backend.io.mem.robLsqIO.pendingld\n\
      233:   memBlock.io.ooo_to_mem.lsqio.pendingst        := backend.io.mem.robLsqIO.pendingst\n\
      234:   memBlock.io.ooo_to_mem.lsqio.pendingVst       := backend.io.mem.robLsqIO.pendingVst\n\
      235:   memBlock.io.ooo_to_mem.lsqio.commit           := backend.io.mem.robLsqIO.commit\n\
      236:   memBlock.io.ooo_to_mem.lsqio.pendingPtr       := backend.io.mem.robLsqIO.pendingPtr\n\
      237:   memBlock.io.ooo_to_mem.lsqio.pendingPtrNext   := backend.io.mem.robLsqIO.pendingPtrNext\n\
      238:   memBlock.io.ooo_to_mem.isStoreException       := backend.io.mem.isStoreException\n\
      239:   memBlock.io.ooo_to_mem.isVlsException         := backend.io.mem.isVlsException\n\
      240: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSCore.scala
    lines: 236-246
    context: "236:   memBlock.io.ooo_to_mem.lsqio.pendingPtr       := backend.io.mem.robLsqIO.pendingPtr\n\
      237:   memBlock.io.ooo_to_mem.lsqio.pendingPtrNext   := backend.io.mem.robLsqIO.pendingPtrNext\n\
      238:   memBlock.io.ooo_to_mem.isStoreException       := backend.io.mem.isStoreException\n\
      239:   memBlock.io.ooo_to_mem.isVlsException         := backend.io.mem.isVlsException\n\
      240: \n241:   memBlock.io.fetch_to_mem.itlb <> frontend.io.ptw\n242:   memBlock.io.l2_hint.valid
      := io.l2_hint.valid\n243:   memBlock.io.l2_hint.bits.sourceId := io.l2_hint.bits.sourceId\n\
      244:   memBlock.io.l2_tlb_req <> io.l2_tlb_req\n245:   memBlock.io.l2_pmp_resp
      <> io.l2_pmp_resp\n246:   memBlock.io.l2_hint.bits.isKeyword := io.l2_hint.bits.isKeyword"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSCore.scala
    lines: 250-260
    context: "250: \n251:   // top-down info\n252:   memBlock.io.debugTopDown.robHeadVaddr
      := backend.io.debugTopDown.fromRob.robHeadVaddr\n253:   frontend.io.debugTopDown.robHeadVaddr
      := backend.io.debugTopDown.fromRob.robHeadVaddr\n254:   io.debugTopDown.robHeadPaddr
      := backend.io.debugTopDown.fromRob.robHeadPaddr\n255:   io.debugTopDown.robTrueCommit
      := backend.io.debugRolling.robTrueCommit\n256:   backend.io.debugTopDown.fromCore.l2MissMatch
      := io.debugTopDown.l2MissMatch\n257:   backend.io.debugTopDown.fromCore.l3MissMatch
      := io.debugTopDown.l3MissMatch\n258:   backend.io.debugTopDown.fromCore.fromMem
      := memBlock.io.debugTopDown.toCore\n259:   memBlock.io.debugRolling := backend.io.debugRolling\n\
      260: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSCore.scala
    lines: 257-267
    context: "257:   backend.io.debugTopDown.fromCore.l3MissMatch := io.debugTopDown.l3MissMatch\n\
      258:   backend.io.debugTopDown.fromCore.fromMem := memBlock.io.debugTopDown.toCore\n\
      259:   memBlock.io.debugRolling := backend.io.debugRolling\n260: \n261:   io.cpu_halt
      := memBlock.io.outer_cpu_halt\n262:   io.l2_flush_en := memBlock.io.outer_l2_flush_en\n\
      263:   io.power_down_en := memBlock.io.outer_power_down_en\n264:   io.cpu_critical_error
      := memBlock.io.outer_cpu_critical_error\n265:   io.msiAck := memBlock.io.outer_msi_ack\n\
      266:   io.beu_errors.icache <> memBlock.io.outer_beu_errors_icache\n267:   io.beu_errors.dcache
      <> memBlock.io.dcacheError.bits.toL1BusErrorUnitInfo(memBlock.io.dcacheError.valid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSCore.scala
    lines: 287-298
    context: "287:   if (debugOpts.ResetGen) {\n288:     backend.reset := memBlock.io.reset_backend\n\
      289:     frontend.reset := backend.io.frontendReset\n290:   }\n291: \n292: \
      \  memBlock.io.dft.zip(io.dft).foreach({ case (a, b) => a := b })\n293:   memBlock.io.dft_reset.zip(io.dft_reset).foreach({
      case (a, b) => a := b })\n294:   frontend.io.dft.zip(memBlock.io.dft_frnt).foreach({
      case (a, b) => a := b })\n295:   frontend.io.dft_reset.zip(memBlock.io.dft_reset_frnt).foreach({
      case (a, b) => a := b })\n296:   backend.io.dft.zip(memBlock.io.dft_bcknd).foreach({
      case (a, b) => a := b })\n297:   backend.io.dft_reset.zip(memBlock.io.dft_reset_bcknd).foreach({
      case (a, b) => a := b })\n298: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 33-43
    context: "33:     def pc  = \"b0000\".U\n34:     def xp  = \"b0001\".U\n35:  \
      \   def fp  = \"b0010\".U\n36:     def vp  = \"b0100\".U\n37:     def v0  =
      \"b1000\".U\n38:     def no  = \"b0000\".U // this src read no reg but cannot
      be Any value\n39: \n40:     // alias\n41:     def reg = this.xp\n42:     def
      DC  = imm // Don't Care\n43:     def X   = BitPat(\"b0000\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 55-70
    context: "55:     def apply() = UInt(4.W)\n56:   }\n57: \n58:   object SrcState
      {\n59:     def busy    = \"b0\".U\n60:     def rdy     = \"b1\".U\n61:     //
      def specRdy = \"b10\".U // speculative ready, for future use\n62:     def apply()
      = UInt(1.W)\n63: \n64:     def isReady(state: UInt): Bool = state === this.rdy\n\
      65:     def isBusy(state: UInt): Bool = state === this.busy\n66:   }\n67: \n\
      68:   def FuOpTypeWidth = 9\n69:   object FuOpType {\n70:     def apply() =
      UInt(FuOpTypeWidth.W)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 160-170
    context: "160:     def FMX_D_X    = \"b0_01_11\".U\n161:     def FMX_W_X    =
      \"b0_01_10\".U\n162:     def FMX_H_X   =  \"b0_01_01\".U\n163:   }\n164: \n\
      165:   object CommitType {\n166:     def NORMAL = \"b000\".U  // int/fp\n167:\
      \     def BRANCH = \"b001\".U  // branch\n168:     def LOAD   = \"b010\".U \
      \ // load\n169:     def STORE  = \"b011\".U  // store\n170: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 167-186
    context: "167:     def BRANCH = \"b001\".U  // branch\n168:     def LOAD   = \"\
      b010\".U  // load\n169:     def STORE  = \"b011\".U  // store\n170: \n171: \
      \    def apply() = UInt(3.W)\n172:     def isFused(commitType: UInt): Bool =
      commitType(2)\n173:     def isLoadStore(commitType: UInt): Bool = !isFused(commitType)
      && commitType(1)\n174:     def lsInstIsStore(commitType: UInt): Bool = commitType(0)\n\
      175:     def isStore(commitType: UInt): Bool = isLoadStore(commitType) && lsInstIsStore(commitType)\n\
      176:     def isBranch(commitType: UInt): Bool = commitType(0) && !commitType(1)
      && !isFused(commitType)\n177:   }\n178: \n179:   object RedirectLevel {\n180:\
      \     def flushAfter = \"b0\".U\n181:     def flush      = \"b1\".U\n182: \n\
      183:     def apply() = UInt(1.W)\n184:     // def isUnconditional(level: UInt)
      = level(1)\n185:     def flushItself(level: UInt) = level(0)\n186:     // def
      isException(level: UInt) = level(1) && level(0)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 203-213
    context: "203:     def C = \"b1\".U << 7 //if it is cacheable is configable\n\
      204:     def Reserved = \"b0\".U\n205: \n206:     def apply() = UInt(7.W)\n\
      207: \n208:     def read(mode: UInt) = mode(0)\n209:     def write(mode: UInt)
      = mode(1)\n210:     def execute(mode: UInt) = mode(2)\n211:     def icache(mode:
      UInt) = mode(3)\n212:     def dcache(mode: UInt) = mode(4)\n213:     def speculate(mode:
      UInt) = mode(5)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 245-255
    context: "245:     def isSystemOp (op: UInt): Bool = op(4)\n246:     def isWfi\
      \      (op: UInt): Bool = op(5) && !op(1)\n247:     def isWrsNto   (op: UInt):
      Bool = op(5) && op(1, 0) === \"b10\".U\n248:     def isWrsSto   (op: UInt):
      Bool = op(5) && op(1, 0) === \"b11\".U\n249:     def isCsrAccess(op: UInt):
      Bool = op(3)\n250:     def isReadOnly (op: UInt): Bool = op(3) && op(2, 0) ===
      0.U\n251:     def notReadOnly(op: UInt): Bool = op(3) && op(2, 0) =/= 0.U\n\
      252:     def isCSRRW    (op: UInt): Bool = op(3) && op(1, 0) === \"b01\".U\n\
      253:     def isCSRRSorRC(op: UInt): Bool = op(3) && op(1)\n254: \n255:     def
      getCSROp(op: UInt) = op(1, 0)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 584-594
    context: "584:     def cbo_zero  = \"b0111\".U\n585: \n586:     // llc op\n587:\
      \     // bit encoding: | prefetch 11 | suboptype(2bit) |\n588:     def cbo_clean
      = \"b1100\".U\n589:     def cbo_flush = \"b1101\".U\n590:     def cbo_inval
      = \"b1110\".U\n591: \n592:     def isCbo(op: UInt): Bool = op(3, 2) === \"b11\"\
      .U && (op(6, 4) === \"b000\".U)\n593:     def isCboAll(op: UInt): Bool = isCbo(op)
      || op(3,0) === cbo_zero\n594:     def isCboClean(op: UInt): Bool = isCbo(op)
      && (op(3, 0) === cbo_clean)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 590-600
    context: "590:     def cbo_inval = \"b1110\".U\n591: \n592:     def isCbo(op:
      UInt): Bool = op(3, 2) === \"b11\".U && (op(6, 4) === \"b000\".U)\n593:    \
      \ def isCboAll(op: UInt): Bool = isCbo(op) || op(3,0) === cbo_zero\n594:   \
      \  def isCboClean(op: UInt): Bool = isCbo(op) && (op(3, 0) === cbo_clean)\n\
      595:     def isCboFlush(op: UInt): Bool = isCbo(op) && (op(3, 0) === cbo_flush)\n\
      596:     def isCboInval(op: UInt): Bool = isCbo(op) && (op(3, 0) === cbo_inval)\n\
      597: \n598:     // atomics\n599:     // bit(1, 0) are size\n600:     // since
      atomics use a different fu type"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 694-704
    context: "694:   }\n695: \n696:   object BTBtype {\n697:     def B = \"b00\".U\
      \  // branch\n698:     def J = \"b01\".U  // jump\n699:     def I = \"b10\"\
      .U  // indirect\n700:     def R = \"b11\".U  // return\n701: \n702:     def
      apply() = UInt(2.W)\n703:   }\n704: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 921-938
    context: "921:       virtualInstr,\n922:       breakPoint\n923:     )\n924:  \
      \   def partialSelect(vec: Vec[Bool], select: Seq[Int]): Vec[Bool] = {\n925:\
      \       val new_vec = Wire(ExceptionVec())\n926:       new_vec.foreach(_ :=
      false.B)\n927:       select.foreach(i => new_vec(i) := vec(i))\n928:       new_vec\n\
      929:     }\n930:     def partialSelect(vec: Vec[Bool], select: Seq[Int], unSelect:
      Seq[Int]): Vec[Bool] = {\n931:       val new_vec = Wire(ExceptionVec())\n932:\
      \       new_vec.foreach(_ := false.B)\n933:       select.diff(unSelect).foreach(i
      => new_vec(i) := vec(i))\n934:       new_vec\n935:     }\n936:     def selectFrontend(vec:
      Vec[Bool]): Vec[Bool] = partialSelect(vec, frontendSet)\n937:     def selectAll(vec:
      Vec[Bool]): Vec[Bool] = partialSelect(vec, ExceptionNO.all)\n938:     def selectByFu(vec:Vec[Bool],
      fuConfig: FuConfig): Vec[Bool] ="
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 951-961
    context: "951:     // val ControlRedirectBubble = Value(\"ControlRedirectBubble\"\
      )\n952:     val TAGEMissBubble = Value(\"TAGEMissBubble\")\n953:     val SCMissBubble
      = Value(\"SCMissBubble\")\n954:     val ITTAGEMissBubble = Value(\"ITTAGEMissBubble\"\
      )\n955:     val RASMissBubble = Value(\"RASMissBubble\")\n956:     val MemVioRedirectBubble
      = Value(\"MemVioRedirectBubble\")\n957:     val OtherRedirectBubble = Value(\"\
      OtherRedirectBubble\")\n958:     val FtqFullStall = Value(\"FtqFullStall\")\n\
      959: \n960:     val ICacheMissBubble = Value(\"ICacheMissBubble\")\n961:   \
      \  val ITLBMissBubble = Value(\"ITLBMissBubble\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 963-981
    context: "963:     val FetchFragBubble = Value(\"FetchFragBubble\")\n964: \n965:\
      \     // backend\n966:     // long inst stall at rob head\n967:     val DivStall
      = Value(\"DivStall\") // int div, float div/sqrt\n968:     val IntNotReadyStall
      = Value(\"IntNotReadyStall\") // int-inst at rob head not issue\n969:     val
      FPNotReadyStall = Value(\"FPNotReadyStall\") // fp-inst at rob head not issue\n\
      970:     val MemNotReadyStall = Value(\"MemNotReadyStall\") // mem-inst at rob
      head not issue\n971:     // freelist full\n972:     val IntFlStall = Value(\"\
      IntFlStall\")\n973:     val FpFlStall = Value(\"FpFlStall\")\n974:     val VecFlStall
      = Value(\"VecFlStall\")\n975:     val V0FlStall = Value(\"V0FlStall\")\n976:\
      \     val VlFlStall = Value(\"VlFlStall\")\n977:     val MultiFlStall = Value(\"\
      MultiFlStall\")\n978: \n979:     // memblock\n980:     val LoadTLBStall = Value(\"\
      LoadTLBStall\")\n981:     val LoadL1Stall = Value(\"LoadL1Stall\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 992-1002
    context: "992:     // bad speculation\n993:     val ControlRecoveryStall = Value(\"\
      ControlRecoveryStall\")\n994:     val MemVioRecoveryStall = Value(\"MemVioRecoveryStall\"\
      )\n995:     val OtherRecoveryStall = Value(\"OtherRecoveryStall\")\n996: \n\
      997:     val FlushedInsts = Value(\"FlushedInsts\") // control flushed, memvio
      flushed, others\n998: \n999:     val OtherCoreStall = Value(\"OtherCoreStall\"\
      )\n1000: \n1001:     val NumStallReasons = Value(\"NumStallReasons\")\n1002:\
      \   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/FakeSbuffer.scala
    lines: 30-40
    context: "30: // used as extended dcache miss queue for store\n31: class FakeSbuffer(implicit
      p: Parameters) extends XSModule {\n32:   val io = IO(new Bundle() {\n33:   \
      \  val in = Vec(StorePipelineWidth, Flipped(Decoupled(new DCacheWordReqWithVaddr)))\n\
      34:     val dcache = new DCacheLineIO\n35:     val forward = Vec(LoadPipelineWidth,
      Flipped(new LoadForwardQueryIO))\n36:   })\n37: \n38:   assert(!(io.in(1).valid
      && !io.in(0).valid))\n39: \n40:   // assign default values to signals"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/FakeSbuffer.scala
    lines: 36-60
    context: "36:   })\n37: \n38:   assert(!(io.in(1).valid && !io.in(0).valid))\n\
      39: \n40:   // assign default values to signals\n41:   io.in(1).ready := false.B\n\
      42: \n43:   io.dcache.req.valid := false.B\n44:   io.dcache.req.bits := DontCare\n\
      45:   io.dcache.resp.ready := false.B\n46: \n47:   val s_invalid :: s_req ::
      s_resp :: Nil = Enum(3)\n48: \n49:   val state = RegInit(s_invalid)\n50: \n\
      51:   val req = Reg(new DCacheWordReqWithVaddr)\n52: \n53:   XSDebug(\"state:
      %d\\n\", state)\n54: \n55:   io.in(0).ready := state === s_invalid\n56: \n57:\
      \   def word_addr(addr: UInt) = (addr >> 3) << 3\n58:   def block_addr(addr:
      UInt) = (addr >> 6) << 6\n59: \n60:   // --------------------------------------------"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/FakeSbuffer.scala
    lines: 57-70
    context: "57:   def word_addr(addr: UInt) = (addr >> 3) << 3\n58:   def block_addr(addr:
      UInt) = (addr >> 6) << 6\n59: \n60:   // --------------------------------------------\n\
      61:   // s_invalid: receive requests\n62:   when (state === s_invalid) {\n63:\
      \     when (io.in(0).fire) {\n64:       req   := io.in(0).bits\n65:       state
      := s_req\n66:     }\n67:   }\n68: \n69:   val wdataVec = WireInit(VecInit(Seq.fill(8)(0.U(64.W))))\n\
      70:   val wmaskVec = WireInit(VecInit(Seq.fill(8)(0.U(8.W))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/FakeSbuffer.scala
    lines: 69-79
    context: "69:   val wdataVec = WireInit(VecInit(Seq.fill(8)(0.U(64.W))))\n70:\
      \   val wmaskVec = WireInit(VecInit(Seq.fill(8)(0.U(8.W))))\n71:   wdataVec(req.addr(5,3))
      := req.data\n72:   wmaskVec(req.addr(5,3)) := req.mask\n73: \n74:   when (state
      === s_req) {\n75:     val dcache_req = io.dcache.req\n76:     dcache_req.valid
      := true.B\n77:     dcache_req.bits.cmd  := MemoryOpConstants.M_XWR\n78:    \
      \ dcache_req.bits.addr := block_addr(req.addr)\n79:     dcache_req.bits.data
      := wdataVec.asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/FakeSbuffer.scala
    lines: 78-96
    context: "78:     dcache_req.bits.addr := block_addr(req.addr)\n79:     dcache_req.bits.data
      := wdataVec.asUInt\n80:     dcache_req.bits.mask := wmaskVec.asUInt\n81:   \
      \  dcache_req.bits.id   := DontCare\n82: \n83:     when (dcache_req.fire) {\n\
      84:       state := s_resp\n85:     }\n86:   }\n87: \n88:   when (state === s_resp)
      {\n89:     io.dcache.resp.ready := true.B\n90:     when (io.dcache.resp.fire)
      {\n91:       state := s_invalid\n92:     }\n93:   }\n94: \n95:   // do forwarding
      here\n96:   for (i <- 0 until LoadPipelineWidth) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/FakeSbuffer.scala
    lines: 92-110
    context: "92:     }\n93:   }\n94: \n95:   // do forwarding here\n96:   for (i
      <- 0 until LoadPipelineWidth) {\n97:     val addr_match = word_addr(io.forward(i).paddr)
      === word_addr(req.addr)\n98:     val mask = io.forward(i).mask & req.mask(7,
      0)\n99:     val mask_match = mask =/= 0.U\n100:     val need_forward = state
      =/= s_invalid && addr_match && mask_match\n101: \n102:     io.forward(i).forwardMask
      := Mux(need_forward, VecInit(mask.asBools),\n103:       VecInit(0.U(8.W).asBools))\n\
      104:     io.forward(i).forwardData := VecInit((0 until 8) map {i => req.data((i
      + 1) * 8 - 1, i * 8)})\n105:   }\n106: \n107:   XSInfo(io.in(0).fire, \"ensbuffer
      addr 0x%x wdata 0x%x mask %b\\n\", io.in(0).bits.addr, io.in(0).bits.data, io.in(0).bits.mask)\n\
      108:   XSInfo(io.in(1).fire, \"ensbuffer addr 0x%x wdata 0x%x mask %b\\n\",
      io.in(1).bits.addr, io.in(1).bits.data, io.in(0).bits.mask)\n109:   XSInfo(io.dcache.req.fire,
      \"desbuffer addr 0x%x wdata 0x%x mask %b\\n\", io.dcache.req.bits.addr, io.dcache.req.bits.data,
      io.dcache.req.bits.mask)\n110: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/DatamoduleResultBuffer.scala
    lines: 47-86
    context: "47: \n48:   val io = IO(new DatamoduleResultBufferIO[T](gen))\n49: \n\
      50:   val data = Reg(Vec(EnsbufferWidth, genType))\n51:   val valids = RegInit(VecInit(Seq.fill(EnsbufferWidth)(false.B)))\n\
      52:   val enq_flag = RegInit(0.U(log2Up(EnsbufferWidth).W)) // head is entry
      0\n53:   val deq_flag = RegInit(0.U(log2Up(EnsbufferWidth).W)) // tail is entry
      0\n54: \n55:   val entry_allowin = Wire(Vec(EnsbufferWidth, Bool()))\n56: \n\
      57:   (0 until EnsbufferWidth).foreach(index => {\n58:     io.deq(index).valid
      := valids(deq_flag + index.U) && (if (index == 0) 1.B else io.deq(index - 1).valid)\n\
      59:     io.deq(index).bits := data(deq_flag + index.U)\n60:   })\n61: \n62:\
      \   (1 until EnsbufferWidth).foreach(i => {\n63:     assert(!(io.deq(i).valid
      && !io.deq(i - 1).valid))\n64:     assert(!(io.deq(i).ready && !io.deq(i - 1).ready))\n\
      65:   })\n66: \n67:   (0 until EnsbufferWidth).foreach(\n68:     index => entry_allowin(index)
      := !valids(index) || (0 until EnsbufferWidth).map(i => io.deq(i).fire && deq_flag
      + i.U === index.U).reduce(_ || _)\n69:   )\n70: \n71:   (0 until EnsbufferWidth).foreach(\n\
      72:     index => io.enq(index).ready := entry_allowin(enq_flag + index.U) &&
      (if (index == 0) 1.B else io.enq(index - 1).ready)\n73:   )\n74: \n75:   (1
      until EnsbufferWidth).foreach(i => {\n76:     assert(!(io.enq(i).ready && !io.enq(i
      - 1).ready))\n77:     assert(!(io.enq(i).valid && !io.enq(i - 1).valid))\n78:\
      \   })\n79: \n80:   (0 until EnsbufferWidth).foreach(index =>\n81:     when(io.deq(index).fire)
      {\n82:       valids(deq_flag + index.U) := 0.B\n83:       if (EnsbufferWidth
      > 1) deq_flag := deq_flag + index.U + 1.U\n84:     }\n85:   )\n86: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/DatamoduleResultBuffer.scala
    lines: 82-93
    context: "82:       valids(deq_flag + index.U) := 0.B\n83:       if (EnsbufferWidth
      > 1) deq_flag := deq_flag + index.U + 1.U\n84:     }\n85:   )\n86: \n87:   (0
      until EnsbufferWidth).foreach(index =>\n88:     when(io.enq(index).fire) {\n\
      89:       valids(enq_flag + index.U) := 1.B\n90:       data(enq_flag + index.U)
      := io.enq(index).bits\n91:       if (EnsbufferWidth > 1) enq_flag := enq_flag
      + index.U + 1.U\n92:     }\n93:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 62-81
    context: "62:   val VWordWidth: Int = log2Up(VDataBytes)\n63:   val VWordOffsetWidth:
      Int = PAddrBits - VWordWidth\n64: }\n65: \n66: class SbufferEntryState (implicit
      p: Parameters) extends SbufferBundle {\n67:   val state_valid    = Bool() //
      this entry is active\n68:   val state_inflight = Bool() // sbuffer is trying
      to write this entry to dcache\n69:   val w_timeout = Bool() // with timeout
      resp, waiting for resend store pipeline req timeout\n70:   val w_sameblock_inflight
      = Bool() // same cache block dcache req is inflight\n71: \n72:   def isInvalid():
      Bool = !state_valid\n73:   def isValid(): Bool = state_valid\n74:   def isActive():
      Bool = state_valid && !state_inflight\n75:   def isInflight(): Bool = state_inflight\n\
      76:   def isDcacheReqCandidate(): Bool = state_valid && !state_inflight && !w_sameblock_inflight\n\
      77: }\n78: \n79: class SbufferBundle(implicit p: Parameters) extends XSBundle
      with HasSbufferConst\n80: \n81: class DataWriteReq(implicit p: Parameters) extends
      SbufferBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 193-206
    context: "193:     with HasPerfEvents {\n194:   val io = IO(new Bundle() {\n195:\
      \     val hartId = Input(UInt(hartIdLen.W))\n196:     val in = Vec(EnsbufferWidth,
      Flipped(Decoupled(new DCacheWordReqWithVaddrAndPfFlag)))  //Todo: store logic
      only support Width == 2 now\n197:     val dcache = Flipped(new DCacheToSbufferIO)\n\
      198:     val forward = Vec(LoadPipelineWidth, Flipped(new LoadForwardQueryIO))\n\
      199:     val sqempty = Input(Bool())\n200:     val sbempty = Output(Bool())\n\
      201:     val flush = Flipped(new SbufferFlushBundle)\n202:     val csrCtrl =
      Flipped(new CustomCSRCtrlIO)\n203:     val store_prefetch = Vec(StorePipelineWidth,
      DecoupledIO(new StorePrefetchReq)) // to dcache\n204:     val memSetPattenDetected
      = Input(Bool())\n205:     val force_write = Input(Bool())\n206:     val diffStore
      = Input(new DiffStoreIO)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 222-232
    context: "222:   val missqReplayCount = RegInit(VecInit(Seq.fill(StoreBufferSize)(0.U(MissqReplayCountBits.W))))\n\
      223: \n224:   val sbuffer_out_s0_fire = Wire(Bool())\n225: \n226:   /*\n227:\
      \        idle --[flush]   --> drain   --[buf empty]--> idle\n228:          \
      \   --[buf full]--> replace --[dcache resp]--> idle\n229:   */\n230:   // x_drain_all:
      drain store queue and sbuffer\n231:   // x_drain_sbuffer: drain sbuffer only,
      block store queue to sbuffer write\n232:   val x_idle :: x_replace :: x_drain_all
      :: x_drain_sbuffer :: Nil = Enum(4)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 228-239
    context: "228:             --[buf full]--> replace --[dcache resp]--> idle\n229:\
      \   */\n230:   // x_drain_all: drain store queue and sbuffer\n231:   // x_drain_sbuffer:
      drain sbuffer only, block store queue to sbuffer write\n232:   val x_idle ::
      x_replace :: x_drain_all :: x_drain_sbuffer :: Nil = Enum(4)\n233:   def needDrain(state:
      UInt): Bool =\n234:     state(1)\n235:   val sbuffer_state = RegInit(x_idle)\n\
      236: \n237:   // ---------------------- Store Enq Sbuffer ---------------------\n\
      238: \n239:   def getPTag(pa: UInt): UInt ="
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 329-339
    context: "329: \n330:   for(i <- 0 until EnsbufferWidth){\n331:     mergeMask(i)
      := widthMap(j =>\n332:       inptags(i) === ptag(j) && activeMask(j)\n333: \
      \    )\n334:     assert(!(PopCount(mergeMask(i).asUInt) > 1.U && io.in(i).fire
      && io.in(i).bits.vecValid))\n335:   }\n336: \n337:   // insert condition\n338:\
      \   // firstInsert: the first invalid entry\n339:   // if first entry canMerge
      or second entry has the same ptag with the first entry,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 383-399
    context: "383:   val forward_need_uarch_drain = WireInit(false.B)\n384:   val
      merge_need_uarch_drain = WireInit(false.B)\n385:   val do_uarch_drain = GatedValidRegNext(forward_need_uarch_drain)
      || GatedValidRegNext(GatedValidRegNext(merge_need_uarch_drain))\n386:   XSPerfAccumulate(\"\
      do_uarch_drain\", do_uarch_drain)\n387: \n388:   io.in(0).ready := firstCanInsert\n\
      389:   io.in(1).ready := secondCanInsert && io.in(0).ready\n390: \n391:   for
      (i <- 0 until EnsbufferWidth) {\n392:     // train\n393:     if (EnableStorePrefetchSPB)
      {\n394:       prefetcher.io.sbuffer_enq(i).valid := io.in(i).fire && io.in(i).bits.vecValid\n\
      395:       prefetcher.io.sbuffer_enq(i).bits := DontCare\n396:       prefetcher.io.sbuffer_enq(i).bits.vaddr
      := io.in(i).bits.vaddr\n397:     } else {\n398:       prefetcher.io.sbuffer_enq(i).valid
      := false.B\n399:       prefetcher.io.sbuffer_enq(i).bits := DontCare"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 400-420
    context: "400:     }\n401: \n402:     // prefetch req\n403:     if (EnableStorePrefetchAtCommit)
      {\n404:       if (EnableAtCommitMissTrigger) {\n405:         io.store_prefetch(i).valid
      := prefetcher.io.prefetch_req(i).valid || (io.in(i).fire && io.in(i).bits.vecValid
      && io.in(i).bits.prefetch)\n406:       } else {\n407:         io.store_prefetch(i).valid
      := prefetcher.io.prefetch_req(i).valid || (io.in(i).fire && io.in(i).bits.vecValid)\n\
      408:       }\n409:       io.store_prefetch(i).bits.paddr := DontCare\n410: \
      \      io.store_prefetch(i).bits.vaddr := Mux(prefetcher.io.prefetch_req(i).valid,
      prefetcher.io.prefetch_req(i).bits.vaddr, io.in(i).bits.vaddr)\n411:       prefetcher.io.prefetch_req(i).ready
      := io.store_prefetch(i).ready\n412:     } else {\n413:       io.store_prefetch(i)
      <> prefetcher.io.prefetch_req(i)\n414:     }\n415:     io.store_prefetch zip
      prefetcher.io.prefetch_req drop 2 foreach (x => x._1 <> x._2)\n416:   }\n417:\
      \   prefetcher.io.memSetPattenDetected := io.memSetPattenDetected\n418: \n419:\
      \   def wordReqToBufLine( // allocate a new line in sbuffer\n420:     req: DCacheWordReq,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 426-436
    context: "426:   ): Unit = {\n427:     assert(UIntToOH(insertIdx) === insertVec)\n\
      428:     val sameBlockInflightMask = genSameBlockInflightMask(reqptag)\n429:\
      \     (0 until StoreBufferSize).map(entryIdx => {\n430:       when(insertVec(entryIdx)){\n\
      431:         stateVec(entryIdx).state_valid := true.B\n432:         stateVec(entryIdx).w_sameblock_inflight
      := sameBlockInflightMask.orR // set w_sameblock_inflight when a line is first
      allocated\n433:         when(sameBlockInflightMask.orR){\n434:           waitInflightMask(entryIdx)
      := sameBlockInflightMask\n435:         }\n436:         cohCount(entryIdx) :=
      0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 461-471
    context: "461:       }\n462:     })\n463:   }\n464: \n465:   for(((in, vwordOffset),
      i) <- io.in.zip(Seq(firstWord, secondWord)).zipWithIndex){\n466:     writeReq(i).valid
      := in.fire && in.bits.vecValid\n467:     writeReq(i).bits.vwordOffset := vwordOffset\n\
      468:     writeReq(i).bits.mask := in.bits.mask\n469:     writeReq(i).bits.data
      := in.bits.data\n470:     writeReq(i).bits.wline := in.bits.wline\n471:    \
      \ val debug_insertIdx = if(i == 0) firstInsertIdx else secondInsertIdx"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 468-480
    context: "468:     writeReq(i).bits.mask := in.bits.mask\n469:     writeReq(i).bits.data
      := in.bits.data\n470:     writeReq(i).bits.wline := in.bits.wline\n471:    \
      \ val debug_insertIdx = if(i == 0) firstInsertIdx else secondInsertIdx\n472:\
      \     val insertVec = if(i == 0) firstInsertVec else secondInsertVec\n473: \
      \    assert(!((PopCount(insertVec) > 1.U) && in.fire && in.bits.vecValid))\n\
      474:     val insertIdx = OHToUInt(insertVec)\n475:     val accessValid = in.fire
      && in.bits.vecValid\n476:     accessIdx(i).valid := RegNext(accessValid)\n477:\
      \     accessIdx(i).bits := RegEnable(Mux(canMerge(i), mergeIdx(i), insertIdx),
      accessValid)\n478: \n479:     XSDebug(accessValid && canMerge(i), p\"merge req
      $i to line [${mergeIdx(i)}]\\n\")\n480:     XSDebug(accessValid && !canMerge(i),
      p\"insert req $i to line[$insertIdx]\\n\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 503-518
    context: "503:   }\n504: \n505: \n506:   for(i <- 0 until StoreBufferSize){\n\
      507:     XSDebug(stateVec(i).isValid(),\n508:       p\"[$i] timeout:${cohCount(i)(EvictCountBits-1)}
      state:${stateVec(i)}\\n\"\n509:     )\n510:   }\n511: \n512:   for((req, i)
      <- io.in.zipWithIndex){\n513:     XSDebug(req.fire && req.bits.vecValid,\n514:\
      \       p\"accept req [$i]: \" +\n515:         p\"addr:${Hexadecimal(req.bits.addr)}
      \" +\n516:         p\"mask:${Binary(shiftMaskToLow(req.bits.addr,req.bits.mask))}
      \" +\n517:         p\"data:${Hexadecimal(shiftDataToLow(req.bits.addr,req.bits.data))}\\\
      n\"\n518:     )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 514-524
    context: "514:       p\"accept req [$i]: \" +\n515:         p\"addr:${Hexadecimal(req.bits.addr)}
      \" +\n516:         p\"mask:${Binary(shiftMaskToLow(req.bits.addr,req.bits.mask))}
      \" +\n517:         p\"data:${Hexadecimal(shiftDataToLow(req.bits.addr,req.bits.data))}\\\
      n\"\n518:     )\n519:     XSDebug(req.valid && !req.ready,\n520:       p\"req
      [$i] blocked by sbuffer\\n\"\n521:     )\n522:   }\n523: \n524:   // for now,
      when enq, trigger a prefetch (if EnableAtCommitMissTrigger)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 540-554
    context: "540:   require((StoreBufferThreshold + 1) <= StoreBufferSize)\n541:\
      \ \n542:   XSDebug(p\"ActiveCount[$ActiveCount]\\n\")\n543: \n544:   io.sbempty
      := GatedValidRegNext(empty)\n545:   io.flush.empty := GatedValidRegNext(empty
      && io.sqempty)\n546:   // lru.io.flush := sbuffer_state === x_drain_all && empty\n\
      547:   switch(sbuffer_state){\n548:     is(x_idle){\n549:       when(io.flush.valid){\n\
      550:         sbuffer_state := x_drain_all\n551:       }.elsewhen(do_uarch_drain){\n\
      552:         sbuffer_state := x_drain_sbuffer\n553:       }.elsewhen(do_eviction){\n\
      554:         sbuffer_state := x_replace"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 558-568
    context: "558:       when(empty){\n559:         sbuffer_state := x_idle\n560:\
      \       }\n561:     }\n562:     is(x_drain_sbuffer){\n563:       when(io.flush.valid){\n\
      564:         sbuffer_state := x_drain_all\n565:       }.elsewhen(sbuffer_empty){\n\
      566:         sbuffer_state := x_idle\n567:       }\n568:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 565-575
    context: "565:       }.elsewhen(sbuffer_empty){\n566:         sbuffer_state :=
      x_idle\n567:       }\n568:     }\n569:     is(x_replace){\n570:       when(io.flush.valid){\n\
      571:         sbuffer_state := x_drain_all\n572:       }.elsewhen(do_uarch_drain){\n\
      573:         sbuffer_state := x_drain_sbuffer\n574:       }.elsewhen(!do_eviction){\n\
      575:         sbuffer_state := x_idle"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 574-584
    context: "574:       }.elsewhen(!do_eviction){\n575:         sbuffer_state :=
      x_idle\n576:       }\n577:     }\n578:   }\n579:   XSDebug(p\"sbuffer state:${sbuffer_state}
      do eviction:${do_eviction} empty:${empty}\\n\")\n580: \n581:   def noSameBlockInflight(idx:
      UInt): Bool = {\n582:     // stateVec(idx) itself must not be s_inflight\n583:\
      \     !Cat(widthMap(i => inflightMask(i) && ptag(idx) === ptag(i))).orR\n584:\
      \   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 650-661
    context: "650:   }).asUInt.orR)\n651:   // block dcache write if read / write
      hazard\n652:   val blockDcacheWrite = shouldWaitWriteFinish\n653: \n654:   val
      sbuffer_out_s1_valid = RegInit(false.B)\n655:   sbuffer_out_s1_ready := io.dcache.req.ready
      && !blockDcacheWrite || !sbuffer_out_s1_valid\n656:   val sbuffer_out_s1_fire
      = io.dcache.req.fire\n657: \n658:   // when sbuffer_out_s1_fire, send dcache
      req stored in pipeline reg to dcache\n659:   when(sbuffer_out_s1_fire){\n660:\
      \     sbuffer_out_s1_valid := false.B\n661:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 671-681
    context: "671:   XSDebug(sbuffer_out_s0_fire, p\"$sbuffer_out_s0_evictionIdx will
      be sent to Dcache\\n\")\n672: \n673:   XSDebug(p\"need drain:$need_drain cohHasTimeOut:
      $cohHasTimeOut need replace:$need_replace\\n\")\n674:   XSDebug(p\"drainIdx:$drainIdx
      tIdx:$cohTimeOutIdx replIdx:$replaceIdx \" +\n675:     p\"blocked:${!noSameBlockInflight(sbuffer_out_s0_evictionIdx)}
      v:${activeMask(sbuffer_out_s0_evictionIdx)}\\n\")\n676:   XSDebug(p\"sbuffer_out_s0_valid:$sbuffer_out_s0_valid
      evictIdx:$sbuffer_out_s0_evictionIdx dcache ready:${io.dcache.req.ready}\\n\"\
      )\n677:   // Note: if other dcache req in the same block are inflight,\n678:\
      \   // the lru update may not accurate\n679:   accessIdx(EnsbufferWidth).valid
      := invalidMask(replaceIdx) || (\n680:     need_replace && !need_drain && !cohHasTimeOut
      && !missqReplayHasTimeOut && sbuffer_out_s0_cango && activeMask(replaceIdx))\n\
      681:   accessIdx(EnsbufferWidth).bits := replaceIdx"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 691-701
    context: "691:   io.dcache.req.bits.data  := data(sbuffer_out_s1_evictionIdx).asUInt\n\
      692:   io.dcache.req.bits.mask  := mask(sbuffer_out_s1_evictionIdx).asUInt\n\
      693:   io.dcache.req.bits.id := sbuffer_out_s1_evictionIdx\n694: \n695:   XSDebug(sbuffer_out_s1_fire,\n\
      696:     p\"send buf [$sbuffer_out_s1_evictionIdx] to Dcache, req fire\\n\"\n\
      697:   )\n698: \n699:   // update sbuffer status according to dcache resp source\n\
      700: \n701:   def id_to_sbuffer_id(id: UInt): UInt = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 704-717
    context: "704:   }\n705: \n706:   // hit resp\n707:   io.dcache.hit_resps.map(resp
      => {\n708:     val dcache_resp_id = resp.bits.id\n709:     when (resp.fire)
      {\n710:       stateVec(dcache_resp_id).state_inflight := false.B\n711:     \
      \  stateVec(dcache_resp_id).state_valid := false.B\n712:       assert(!resp.bits.replay)\n\
      713:       assert(!resp.bits.miss) // not need to resp if miss, to be opted\n\
      714:       assert(stateVec(dcache_resp_id).state_inflight === true.B)\n715:\
      \     }\n716: \n717:     // Update w_sameblock_inflight flag is delayed for
      1 cycle"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 720-732
    context: "720:     // current dcache.hit_resps. Then, in the next cycle, we have
      plenty of time to check\n721:     // if the same block is still inflight\n722:\
      \     (0 until StoreBufferSize).map(i => {\n723:       when(\n724:         stateVec(i).w_sameblock_inflight
      &&\n725:         stateVec(i).state_valid &&\n726:         GatedValidRegNext(resp.fire)
      &&\n727:         waitInflightMask(i) === UIntToOH(RegEnable(id_to_sbuffer_id(dcache_resp_id),
      resp.fire))\n728:       ){\n729:         stateVec(i).w_sameblock_inflight :=
      false.B\n730:       }\n731:     })\n732:   })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 729-750
    context: "729:         stateVec(i).w_sameblock_inflight := false.B\n730:     \
      \  }\n731:     })\n732:   })\n733: \n734:   io.dcache.hit_resps.zip(dataModule.io.maskFlushReq).map{case
      (resp, maskFlush) => {\n735:     maskFlush.valid := resp.fire\n736:     maskFlush.bits.wvec
      := UIntToOH(resp.bits.id)\n737:   }}\n738: \n739:   // replay resp\n740:   val
      replay_resp_id = io.dcache.replay_resp.bits.id\n741:   when (io.dcache.replay_resp.fire)
      {\n742:     missqReplayCount(replay_resp_id) := 0.U\n743:     stateVec(replay_resp_id).w_timeout
      := true.B\n744:     // waiting for timeout\n745:     assert(io.dcache.replay_resp.bits.replay)\n\
      746:     assert(stateVec(replay_resp_id).state_inflight === true.B)\n747:  \
      \ }\n748: \n749:   // TODO: reuse cohCount\n750:   (0 until StoreBufferSize).map(i
      => {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 761-771
    context: "761:     io.dcache.hit_resps.zipWithIndex.map{case (resp, index) =>
      {\n762:       val difftest = DifftestModule(new DiffSbufferEvent, delay = 1)\n\
      763:       val dcache_resp_id = resp.bits.id\n764:       difftest.coreid :=
      io.hartId\n765:       difftest.index  := index.U\n766:       difftest.valid\
      \  := resp.fire\n767:       difftest.addr   := getAddr(ptag(dcache_resp_id))\n\
      768:       difftest.data   := data(dcache_resp_id).asTypeOf(Vec(CacheLineBytes,
      UInt(8.W)))\n769:       difftest.mask   := mask(dcache_resp_id).asUInt\n770:\
      \     }}\n771:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 771-786
    context: "771:   }\n772: \n773:   // ---------------------- Load Data Forward
      ---------------------\n774:   val mismatch = Wire(Vec(LoadPipelineWidth, Bool()))\n\
      775:   XSPerfAccumulate(\"vaddr_match_failed\", mismatch(0) || mismatch(1))\n\
      776:   for ((forward, i) <- io.forward.zipWithIndex) {\n777:     val vtag_matches
      = VecInit(widthMap(w => vtag(w) === getVTag(forward.vaddr)))\n778:     // ptag_matches
      uses paddr from dtlb, which is far from sbuffer\n779:     val ptag_matches =
      VecInit(widthMap(w => RegEnable(ptag(w), forward.valid) === RegEnable(getPTag(forward.paddr),
      forward.valid)))\n780:     val tag_matches = vtag_matches\n781:     val tag_mismatch
      = GatedValidRegNext(forward.valid) && VecInit(widthMap(w =>\n782:       GatedValidRegNext(vtag_matches(w))
      =/= ptag_matches(w) && GatedValidRegNext((activeMask(w) || inflightMask(w)))\n\
      783:     )).asUInt.orR\n784:     mismatch(i) := tag_mismatch\n785:     when
      (tag_mismatch) {\n786:       forward_need_uarch_drain := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 785-813
    context: "785:     when (tag_mismatch) {\n786:       forward_need_uarch_drain
      := true.B\n787:     }\n788:     XSDebug(\n789:       tag_mismatch,\n790:   \
      \    \"forward tag mismatch: pmatch %x vmatch %x vaddr %x paddr %x\\n\",\n791:\
      \       RegNext(ptag_matches.asUInt),\n792:       RegNext(vtag_matches.asUInt),\n\
      793:       RegNext(forward.vaddr),\n794:       RegNext(forward.paddr)\n795:\
      \     )\n796:     val valid_tag_matches = widthMap(w => tag_matches(w) && activeMask(w))\n\
      797:     val inflight_tag_matches = widthMap(w => tag_matches(w) && inflightMask(w))\n\
      798:     val line_offset_mask = UIntToOH(getVWordOffset(forward.paddr))\n799:\
      \ \n800:     val valid_tag_match_reg = valid_tag_matches.map(RegEnable(_, forward.valid))\n\
      801:     val inflight_tag_match_reg = inflight_tag_matches.map(RegEnable(_,
      forward.valid))\n802:     val forward_mask_candidate_reg = RegEnable(\n803:\
      \       VecInit(mask.map(entry => entry(getVWordOffset(forward.paddr)))),\n\
      804:       forward.valid\n805:     )\n806:     val forward_data_candidate_reg
      = RegEnable(\n807:       VecInit(data.map(entry => entry(getVWordOffset(forward.paddr)))),\n\
      808:       forward.valid\n809:     )\n810: \n811:     val selectedValidMask
      = Mux1H(valid_tag_match_reg, forward_mask_candidate_reg)\n812:     val selectedValidData
      = Mux1H(valid_tag_match_reg, forward_data_candidate_reg)\n813:     selectedValidMask.suggestName(\"\
      selectedValidMask_\"+i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 820-848
    context: "820: \n821:     // currently not being used\n822:     val selectedInflightMaskFast
      = Mux1H(line_offset_mask, Mux1H(inflight_tag_matches, mask).asTypeOf(Vec(CacheLineVWords,
      Vec(VDataBytes, Bool()))))\n823:     val selectedValidMaskFast = Mux1H(line_offset_mask,
      Mux1H(valid_tag_matches, mask).asTypeOf(Vec(CacheLineVWords, Vec(VDataBytes,
      Bool()))))\n824: \n825:     forward.dataInvalid := false.B // data in store
      line merge buffer is always ready\n826:     forward.matchInvalid := tag_mismatch
      // paddr / vaddr cam result does not match\n827:     for (j <- 0 until VDataBytes)
      {\n828:       forward.forwardMask(j) := false.B\n829:       forward.forwardData(j)
      := DontCare\n830: \n831:       // valid entries have higher priority than inflight
      entries\n832:       when(selectedInflightMask(j)) {\n833:         forward.forwardMask(j)
      := true.B\n834:         forward.forwardData(j) := selectedInflightData(j)\n\
      835:       }\n836:       when(selectedValidMask(j)) {\n837:         forward.forwardMask(j)
      := true.B\n838:         forward.forwardData(j) := selectedValidData(j)\n839:\
      \       }\n840: \n841:       forward.forwardMaskFast(j) := selectedInflightMaskFast(j)
      || selectedValidMaskFast(j)\n842:     }\n843:     forward.addrInvalid := DontCare\n\
      844:   }\n845: \n846:   for (i <- 0 until StoreBufferSize) {\n847:     XSDebug(\"\
      sbf entry \" + i + \" : ptag %x vtag %x valid %x active %x inflight %x w_timeout
      %x\\n\",\n848:       ptag(i) << OffsetWidth,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 945-955
    context: "945:         val upperBits         = Mux(unaligned_start === 0.U &&
      unaligned_offset =/= 0.U,\n946:                                    (unaligned_offset
      << 3.U).asUInt - 1.U,\n947:                                    ((EEB + unaligned_offset)
      << 3.U).asUInt - 1.U)// unit-stride second write request\n948:         val splitMask\
      \         = UIntSlice(rawMask, upper, unaligned_start)(7,0)  // Byte\n949: \
      \        val splitData         = UIntSlice(rawData, upperBits, unaligned_start_bits)(63,0)
      // Double word\n950:         val storeCommit       = io.diffStore.pmaStore(i).fire
      && splitMask.orR && io.diffStore.pmaStore(i).bits.vecValid\n951:         //
      align with ref\n952:         val waddr             = Mux(unaligned_offset =/=
      0.U && rawAddr(3), ZeroExt(Cat(rawAddr(PAddrBits - 1, 3), 0.U(3.W)), 64), rawAddr)\n\
      953:         val wmask             = Mux(unaligned_offset =/= 0.U && rawAddr(3),
      0.U, splitMask << unaligned_offset)\n954:         val wdata             = Mux(unaligned_offset
      =/= 0.U && rawAddr(3), 0.U, (splitData & MaskExpand(splitMask)) << unaligned_offset_bits)\n\
      955: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 953-963
    context: "953:         val wmask             = Mux(unaligned_offset =/= 0.U &&
      rawAddr(3), 0.U, splitMask << unaligned_offset)\n954:         val wdata    \
      \         = Mux(unaligned_offset =/= 0.U && rawAddr(3), 0.U, (splitData & MaskExpand(splitMask))
      << unaligned_offset_bits)\n955: \n956:         difftestCommon.coreid := io.hartId\n\
      957:         difftestCommon.index  := (i*VecMemFLOWMaxNumber).U\n958:      \
      \   difftestCommon.valid  := storeCommit\n959:         difftestCommon.addr \
      \  := waddr\n960:         difftestCommon.data   := wdata\n961:         difftestCommon.mask\
      \   := wmask\n962:         difftestCommon.robidx := io.diffStore.diffInfo(i).uop.robIdx.value\n\
      963:         difftestCommon.pc     := io.diffStore.diffInfo(i).uop.pc"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 961-971
    context: "961:         difftestCommon.mask   := wmask\n962:         difftestCommon.robidx
      := io.diffStore.diffInfo(i).uop.robIdx.value\n963:         difftestCommon.pc\
      \     := io.diffStore.diffInfo(i).uop.pc\n964: \n965:       } .elsewhen (!isWline)
      {\n966:         val storeCommit       = io.diffStore.pmaStore(i).fire\n967:\
      \         val waddr             = ZeroExt(Cat(io.diffStore.pmaStore(i).bits.addr(PAddrBits
      - 1, 3), 0.U(3.W)), 64)\n968:         val sbufferMask       = shiftMaskToLow(io.diffStore.pmaStore(i).bits.addr,
      io.diffStore.pmaStore(i).bits.mask)\n969:         val sbufferData       = shiftDataToLow(io.diffStore.pmaStore(i).bits.addr,
      io.diffStore.pmaStore(i).bits.data)\n970:         val wmask             = sbufferMask\n\
      971:         val wdata             = sbufferData & MaskExpand(sbufferMask)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 970-980
    context: "970:         val wmask             = sbufferMask\n971:         val wdata\
      \             = sbufferData & MaskExpand(sbufferMask)\n972: \n973:         difftestCommon.coreid
      := io.hartId\n974:         difftestCommon.index  := (i*VecMemFLOWMaxNumber).U\n\
      975:         difftestCommon.valid  := storeCommit && io.diffStore.pmaStore(i).bits.vecValid\n\
      976:         difftestCommon.addr   := waddr\n977:         difftestCommon.data\
      \   := wdata\n978:         difftestCommon.mask   := wmask\n979:         difftestCommon.robidx
      := io.diffStore.diffInfo(i).uop.robIdx.value\n980:         difftestCommon.pc\
      \     := io.diffStore.diffInfo(i).uop.pc"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 982-992
    context: "982: \n983:       for (index <- 0 until WlineMaxNumber) {\n984:    \
      \     val difftest = DifftestModule(new DiffStoreEvent, delay = 2, dontCare
      = true)\n985:         diffStoreEventCount += 1\n986: \n987:         val storeCommit
      = io.diffStore.pmaStore(i).fire && io.diffStore.pmaStore(i).bits.vecValid\n\
      988:         val blockAddr = get_block_addr(io.diffStore.pmaStore(i).bits.addr)\n\
      989: \n990:         when (isWline) {\n991:           difftest.coreid := io.hartId\n\
      992:           difftest.index  := (i*VecMemFLOWMaxNumber + index).U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 988-998
    context: "988:         val blockAddr = get_block_addr(io.diffStore.pmaStore(i).bits.addr)\n\
      989: \n990:         when (isWline) {\n991:           difftest.coreid := io.hartId\n\
      992:           difftest.index  := (i*VecMemFLOWMaxNumber + index).U\n993:  \
      \         difftest.valid  := storeCommit\n994:           difftest.addr   :=
      blockAddr + (index.U << wordOffBits)\n995:           difftest.data   := io.diffStore.pmaStore(i).bits.data\n\
      996:           difftest.mask   := ((1 << wordBytes) - 1).U\n997:           difftest.robidx
      := io.diffStore.diffInfo(i).uop.robIdx.value\n998:           difftest.pc   \
      \  := io.diffStore.diffInfo(i).uop.pc"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 995-1005
    context: "995:           difftest.data   := io.diffStore.pmaStore(i).bits.data\n\
      996:           difftest.mask   := ((1 << wordBytes) - 1).U\n997:           difftest.robidx
      := io.diffStore.diffInfo(i).uop.robIdx.value\n998:           difftest.pc   \
      \  := io.diffStore.diffInfo(i).uop.pc\n999: \n1000:           assert(!storeCommit
      || (io.diffStore.pmaStore(i).bits.data === 0.U), \"wline only supports whole
      zero write now\")\n1001:         }\n1002:       }\n1003: \n1004:       // Only
      the interface used by the 'unit-store' and 'whole' vector store instr\n1005:\
      \       for (index <- 1 until VecMemFLOWMaxNumber) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 1016-1026
    context: "1016:           val shiftFlag   = shiftIndex(2,0).orR // Double word
      Flag\n1017:           val shiftBytes  = Mux(shiftFlag, shiftIndex(2,0), 0.U)\n\
      1018:           val shiftBits   = shiftBytes << 3.U\n1019:           val splitMask\
      \   = UIntSlice(rawMask, (EEB*(index+1).U - 1.U) + unaligned_offset, EEB*index.U
      + unaligned_offset)(7,0)  // Byte\n1020:           val splitData   = UIntSlice(rawData,
      (EEWBits*(index+1).U - 1.U) + unaligned_offset_bits, EEWBits*index.U + unaligned_offset_bits)(63,0)
      // Double word\n1021:           val storeCommit = io.diffStore.pmaStore(i).fire
      && splitMask.orR  && io.diffStore.pmaStore(i).bits.vecValid\n1022:         \
      \  val waddr       = Mux(unaligned_offset =/= 0.U && shiftIndex(3), Cat(rawAddr(PAddrBits
      - 1, 4),  0.U(4.W)),Cat(rawAddr(PAddrBits - 1, 4), Cat(shiftIndex(3), 0.U(3.W))))\n\
      1023:           val wmask       = Mux(unaligned_offset =/= 0.U && shiftIndex(3),
      0.U,splitMask << (shiftBytes + unaligned_offset))\n1024:           val wdata\
      \       = Mux(unaligned_offset =/= 0.U && shiftIndex(3), 0.U,(splitData & MaskExpand(splitMask))
      << (shiftBits.asUInt + unaligned_offset_bits))\n1025: \n1026:           difftest.coreid
      := io.hartId"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 1023-1033
    context: "1023:           val wmask       = Mux(unaligned_offset =/= 0.U && shiftIndex(3),
      0.U,splitMask << (shiftBytes + unaligned_offset))\n1024:           val wdata\
      \       = Mux(unaligned_offset =/= 0.U && shiftIndex(3), 0.U,(splitData & MaskExpand(splitMask))
      << (shiftBits.asUInt + unaligned_offset_bits))\n1025: \n1026:           difftest.coreid
      := io.hartId\n1027:           difftest.index  := (i*VecMemFLOWMaxNumber+index).U\n\
      1028:           difftest.valid  := storeCommit\n1029:           difftest.addr\
      \   := waddr\n1030:           difftest.data   := wdata\n1031:           difftest.mask\
      \   := wmask\n1032:           difftest.robidx := io.diffStore.diffInfo(i).uop.robIdx.value\n\
      1033:           difftest.pc     := io.diffStore.diffInfo(i).uop.pc"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 1051-1074
    context: "1051: \n1052: \n1053:   val perf_valid_entry_count = RegNext(PopCount(VecInit(stateVec.map(s
      => !s.isInvalid())).asUInt))\n1054:   XSPerfHistogram(\"util\", perf_valid_entry_count,
      true.B, 0, StoreBufferSize, 1)\n1055:   XSPerfAccumulate(\"sbuffer_req_valid\"\
      , PopCount(VecInit(io.in.map(_.valid)).asUInt))\n1056:   XSPerfAccumulate(\"\
      sbuffer_req_fire\", PopCount(VecInit(io.in.map(_.fire)).asUInt))\n1057:   XSPerfAccumulate(\"\
      sbuffer_req_fire_vecinvalid\", PopCount(VecInit(io.in.map(data => data.fire
      && !data.bits.vecValid)).asUInt))\n1058:   XSPerfAccumulate(\"sbuffer_merge\"\
      , PopCount(VecInit(io.in.zipWithIndex.map({case (in, i) => in.fire && canMerge(i)})).asUInt))\n\
      1059:   XSPerfAccumulate(\"sbuffer_newline\", PopCount(VecInit(io.in.zipWithIndex.map({case
      (in, i) => in.fire && !canMerge(i)})).asUInt))\n1060:   XSPerfAccumulate(\"\
      dcache_req_valid\", io.dcache.req.valid)\n1061:   XSPerfAccumulate(\"dcache_req_fire\"\
      , io.dcache.req.fire)\n1062:   XSPerfAccumulate(\"sbuffer_idle\", sbuffer_state
      === x_idle)\n1063:   XSPerfAccumulate(\"sbuffer_flush\", sbuffer_state === x_drain_sbuffer)\n\
      1064:   XSPerfAccumulate(\"sbuffer_replace\", sbuffer_state === x_replace)\n\
      1065:   XSPerfAccumulate(\"evenCanInsert\", evenCanInsert)\n1066:   XSPerfAccumulate(\"\
      oddCanInsert\", oddCanInsert)\n1067:   XSPerfAccumulate(\"mainpipe_resp_valid\"\
      , io.dcache.main_pipe_hit_resp.fire)\n1068:   //XSPerfAccumulate(\"refill_resp_valid\"\
      , io.dcache.refill_hit_resp.fire)\n1069:   XSPerfAccumulate(\"replay_resp_valid\"\
      , io.dcache.replay_resp.fire)\n1070:   XSPerfAccumulate(\"coh_timeout\", cohHasTimeOut)\n\
      1071: \n1072:   // val (store_latency_sample, store_latency) = TransactionLatencyCounter(io.lsu.req.fire,
      io.lsu.resp.fire)\n1073:   // XSPerfHistogram(\"store_latency\", store_latency,
      store_latency_sample, 0, 100, 10)\n1074:   // XSPerfAccumulate(\"store_req\"\
      , io.lsu.req.fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 1073-1093
    context: "1073:   // XSPerfHistogram(\"store_latency\", store_latency, store_latency_sample,
      0, 100, 10)\n1074:   // XSPerfAccumulate(\"store_req\", io.lsu.req.fire)\n1075:\
      \ \n1076:   val perfEvents = Seq(\n1077:     (\"sbuffer_req_valid \", PopCount(VecInit(io.in.map(_.valid)).asUInt)\
      \                                                                ),\n1078: \
      \    (\"sbuffer_req_fire  \", PopCount(VecInit(io.in.map(_.fire)).asUInt)  \
      \                                                             ),\n1079:    \
      \ (\"sbuffer_merge     \", PopCount(VecInit(io.in.zipWithIndex.map({case (in,
      i) => in.fire && canMerge(i)})).asUInt)                ),\n1080:     (\"sbuffer_newline\
      \   \", PopCount(VecInit(io.in.zipWithIndex.map({case (in, i) => in.fire &&
      !canMerge(i)})).asUInt)               ),\n1081:     (\"dcache_req_valid  \"\
      , io.dcache.req.valid                                                      \
      \                                   ),\n1082:     (\"dcache_req_fire   \", io.dcache.req.fire\
      \                                                                          \
      \              ),\n1083:     (\"sbuffer_idle      \", sbuffer_state === x_idle\
      \                                                                          \
      \          ),\n1084:     (\"sbuffer_flush     \", sbuffer_state === x_drain_sbuffer\
      \                                                                          \
      \ ),\n1085:     (\"sbuffer_replace   \", sbuffer_state === x_replace       \
      \                                                                          ),\n\
      1086:     (\"mpipe_resp_valid  \", io.dcache.main_pipe_hit_resp.fire       \
      \                                                                  ),\n1087:\
      \     //(\"refill_resp_valid \", io.dcache.refill_hit_resp.fire            \
      \                                                                ),\n1088: \
      \    (\"replay_resp_valid \", io.dcache.replay_resp.fire                   \
      \                                                             ),\n1089:    \
      \ (\"coh_timeout       \", cohHasTimeOut                                   \
      \                                                            ),\n1090:     (\"\
      sbuffer_1_4_valid \", (perf_valid_entry_count < (StoreBufferSize.U/4.U))   \
      \                                                       ),\n1091:     (\"sbuffer_2_4_valid
      \", (perf_valid_entry_count > (StoreBufferSize.U/4.U)) & (perf_valid_entry_count
      <= (StoreBufferSize.U/2.U))    ),\n1092:     (\"sbuffer_3_4_valid \", (perf_valid_entry_count
      > (StoreBufferSize.U/2.U)) & (perf_valid_entry_count <= (StoreBufferSize.U*3.U/4.U))),\n\
      1093:     (\"sbuffer_full_valid\", (perf_valid_entry_count > (StoreBufferSize.U*3.U/4.U)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/StorePrefetchBursts.scala
    lines: 54-65
    context: "54:       case(v, e_vaddr) => v && same_page_addr(e_vaddr, incoming_vaddr)\n\
      55:     }\n56:     VecInit(match_vec).asUInt.orR\n57:   }\n58: \n59:   def cache_block_addr_difference(req_addr:
      UInt, last_addr: UInt): UInt = {\n60:     (block_addr(req_addr).asSInt - block_addr(last_addr).asSInt)(SATURATE_COUNTER_BITS
      - 1, 0)\n61:   }\n62: \n63:   def get_store_count_divided_by_8(st_count: UInt):
      UInt = {\n64:     st_count(st_count.getWidth - 1, 3)\n65:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/StorePrefetchBursts.scala
    lines: 121-139
    context: "121:   // deq\n122:   // val deq_valids = (valids zip datas zip pagebits).map{case
      (v, vaddr, pgbit) => v && vaddr(PAGEOFFSET) === pagebits}\n123:   val deq_valids
      = valids\n124:   val deq_decoupled = Wire(Vec(SIZE, Vec(StorePipelineWidth,
      Decoupled(new StorePrefetchReq))))\n125: \n126:   (deq_valids zip deq_decoupled
      zip datas zip datas_next zip datas_next_next zip pagebits zip valids).foreach{case
      ((((((deq_valid, out_decouple), data), data_next), data_next_next), pg_bit),
      v) => {\n127:     out_decouple(0).valid := deq_valid\n128:     out_decouple(0).bits
      := DontCare\n129:     out_decouple(0).bits.vaddr := data\n130:     out_decouple(1).valid
      := deq_valid && data_next(PAGEOFFSET) === pg_bit && out_decouple(0).fire\n131:\
      \     out_decouple(1).bits := DontCare\n132:     out_decouple(1).bits.vaddr
      := data_next\n133:     out_decouple.drop(2).foreach { out => out.valid := false.B;
      out.bits := DontCare }\n134:     when(out_decouple(1).fire) {\n135:       //
      fired 2 prefetch reqs\n136:       data := data_next_next\n137:       when(data_next_next(PAGEOFFSET)
      =/= pg_bit) {\n138:         // cross page, invalid this entry\n139:        \
      \ v := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/StorePrefetchBursts.scala
    lines: 136-146
    context: "136:       data := data_next_next\n137:       when(data_next_next(PAGEOFFSET)
      =/= pg_bit) {\n138:         // cross page, invalid this entry\n139:        \
      \ v := false.B\n140:       }\n141:     }.elsewhen(out_decouple(0).fire) {\n\
      142:       // fired 1 prefetch req\n143:       data := data_next\n144:     \
      \  when(data_next(PAGEOFFSET) =/= pg_bit) {\n145:         // cross page, invalid
      this entry\n146:         v := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/StorePrefetchBursts.scala
    lines: 150-160
    context: "150:   for (i <- 0 until StorePipelineWidth) {\n151:     arbiter(deq_decoupled.map(_(i)),
      io.prefetch_req(i), Some(s\"spb_deq_arb${i}\"))\n152:   }\n153: \n154:   XSPerfAccumulate(\"\
      burst_valid_num\", PopCount(valids))\n155:   XSPerfAccumulate(\"prefetch_req_fire_by_generator\"\
      , PopCount(VecInit(io.prefetch_req.map(_.fire))))\n156: }\n157: \n158: class
      StorePrefetchBursts(implicit p: Parameters) extends DCacheModule with HasStorePrefetchHelper
      {\n159:   val io = IO(new DCacheBundle {\n160:     val enable = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/StorePrefetchBursts.scala
    lines: 232-242
    context: "232: \n233:   // deq\n234:   io.prefetch_train.valid := reqs(deqPtr).valid\n\
      235:   io.prefetch_train.bits  := reqs(deqPtr).bits\n236: \n237:   when(io.prefetch_train.fire)
      {\n238:     deqPtrExt := deqPtrExt + 1.U\n239:     reqs(deqPtr).valid := false.B\n\
      240:   }\n241: \n242:   // enq"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/StorePrefetchBursts.scala
    lines: 251-261
    context: "251:     }\n252:     enqPtrExt.map(ptr => ptr := ptr + count_vsreq)\n\
      253:   }\n254: \n255:   XSPerfAccumulate(\"canNotEnqueue\", !canEnqueue)\n256:\
      \   XSPerfAccumulate(\"prefetch_train_fire\", io.prefetch_train.fire)\n257:\
      \   XSPerfAccumulate(\"full\", PopCount(reqs.map(_.valid)) === QueueSize.U)\n\
      258: }\n259: \n260: class StorePfWrapper()(implicit p: Parameters) extends DCacheModule
      with HasStorePrefetchHelper {\n261:   val io = IO(new DCacheBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/StorePrefetchBursts.scala
    lines: 278-287
    context: "278:   spb.io.enable := ENABLE_SPB.B\n279:   spb.io.memSetPattenDetected
      := io.memSetPattenDetected\n280:   spb.io.sbuffer_enq.valid := serializer.io.prefetch_train.valid\n\
      281:   spb.io.sbuffer_enq.bits  := serializer.io.prefetch_train.bits\n282: \
      \  // spb will always recieve train req\n283:   serializer.io.prefetch_train.ready
      := true.B\n284: \n285:   // fire a prefetch req\n286:   io.prefetch_req <> spb.io.prefetch_req\n\
      287: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemTrace.scala
    lines: 18-28
    context: "18: \n19: import org.chipsalliance.cde.config.Parameters\n20: import
      chisel3._\n21: import chisel3.util._\n22: \n23: class L1MissTrace extends Bundle
      {\n24:   val vaddr = UInt(39.W)\n25:   val paddr = UInt(36.W)\n26:   val source
      = UInt(4.W)\n27:   val pc = UInt(39.W)\n28: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/Bundles.scala
    lines: 64-74
    context: "64:     val miss = Bool()\n65:     val tlbMiss = Bool()\n66:     val
      ptwBack = Bool()\n67:     val af = Bool()\n68:     val nc = Bool()\n69:    \
      \ val mmio = Bool()\n70:     val memBackTypeMM = Bool() // 1: main memory, 0:
      IO\n71:     val hasException = Bool()\n72:     val isHyper = Bool()\n73:   \
      \  val isForVSnonLeafPTE = Bool()\n74:     val isPrefetch = Bool()"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/Bundles.scala
    lines: 183-193
    context: "183: \n184:   class LoadForwardQueryIO(implicit p: Parameters) extends
      XSBundle {\n185:     val vaddr = Output(UInt(VAddrBits.W))\n186:     val paddr
      = Output(UInt(PAddrBits.W))\n187:     val mask = Output(UInt((VLEN/8).W))\n\
      188:     val uop = Output(new DynInst) // for replay\n189:     val pc = Output(UInt(VAddrBits.W))
      //for debug\n190:     val valid = Output(Bool())\n191: \n192:     val forwardMaskFast
      = Input(Vec((VLEN/8), Bool())) // resp to load_s1\n193:     val forwardMask
      = Input(Vec((VLEN/8), Bool())) // resp to load_s2"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/Bundles.scala
    lines: 197-212
    context: "197:     val sqIdx = Output(new SqPtr)\n198: \n199:     // dataInvalid
      suggests store to load forward found forward should happen,\n200:     // but
      data is not available for now. If dataInvalid, load inst should\n201:     //
      be replayed from RS. Feedback type should be RSFeedbackType.dataInvalid\n202:\
      \     val dataInvalid = Input(Bool()) // Addr match, but data is not valid for
      now\n203: \n204:     // matchInvalid suggests in store to load forward logic,
      paddr cam result does\n205:     // to equal to vaddr cam result. If matchInvalid,
      a microarchitectural exception\n206:     // should be raised to flush SQ and
      committed sbuffer.\n207:     val matchInvalid = Input(Bool()) // resp to load_s2\n\
      208: \n209:     // addrInvalid suggests store to load forward found forward
      should happen,\n210:     // but address (SSID) is not available for now. If
      addrInvalid, load inst should\n211:     // be replayed from RS. Feedback type
      should be RSFeedbackType.addrInvalid\n212:     val addrInvalid = Input(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/Bundles.scala
    lines: 241-251
    context: "241:     val mask = UInt((VLEN/8).W)\n242: \n243:     // paddr: load's
      paddr.\n244:     val paddr      = UInt(PAddrBits.W)\n245:     // dataInvalid:
      load data is invalid.\n246:     val data_valid = Bool()\n247:     // nc: is
      NC access\n248:     val is_nc = Bool()\n249:   }\n250: \n251:   class LoadNukeQueryRespBundle(implicit
      p: Parameters) extends XSBundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/Bundles.scala
    lines: 293-303
    context: "293:     })\n294:   }\n295: \n296:   class StoreMaBufToVecStoreMergeBufferIO(implicit
      p: Parameters)  extends VLSUBundle{\n297:     val mbIndex = Output(UInt(vsmBindexBits.W))\n\
      298:     val flush   = Output(Bool())\n299:   }\n300: \n301:   // Store byte
      valid mask write bundle\n302:   //\n303:   // Store byte valid mask write to
      SQ takes 2 cycles"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/MaskedDataModule.scala
    lines: 24-34
    context: "24: import xiangshan.cache._\n25: \n26: class MaskedSyncDataModuleTemplate[T
      <: Data](\n27:   gen: T,\n28:   numEntries: Int,\n29:   numRead: Int,\n30: \
      \  numWrite: Int,\n31:   numMRead: Int = 0,\n32:   numMWrite: Int = 0\n33: )
      extends Module {\n34:   val io = IO(new Bundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/MaskedDataModule.scala
    lines: 31-42
    context: "31:   numMRead: Int = 0,\n32:   numMWrite: Int = 0\n33: ) extends Module
      {\n34:   val io = IO(new Bundle {\n35:     // address indexed sync read\n36:\
      \     val raddr = Input(Vec(numRead, UInt(log2Up(numEntries).W)))\n37:     val
      rdata = Output(Vec(numRead, gen))\n38:     // masked sync read (1H)\n39:   \
      \  val mrmask = Input(Vec(numMRead, Vec(numEntries, Bool())))\n40:     val mrdata
      = Output(Vec(numMRead, gen))\n41:     // address indexed write\n42:     val
      wen   = Input(Vec(numWrite, Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/MaskedDataModule.scala
    lines: 48-58
    context: "48:   })\n49: \n50:   val data = Reg(Vec(numEntries, gen))\n51: \n52:\
      \   // read ports\n53:   for (i <- 0 until numRead) {\n54:     io.rdata(i) :=
      data(RegNext(io.raddr(i)))\n55:   }\n56: \n57:   // masked read ports\n58: \
      \  for (i <- 0 until numMRead) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/MaskedDataModule.scala
    lines: 85-95
    context: "85: }\n86: \n87: class MaskedBankedSyncDataModuleTemplate[T <: Data](\n\
      88:   gen: T,\n89:   numEntries: Int,\n90:   numRead: Int,\n91:   numWrite:
      Int,\n92:   numMRead: Int = 0,\n93:   numMWrite: Int = 0,\n94:   numWBanks:
      Int = 2\n95: ) extends Module {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/MaskedDataModule.scala
    lines: 93-104
    context: "93:   numMWrite: Int = 0,\n94:   numWBanks: Int = 2\n95: ) extends Module
      {\n96:   val io = IO(new Bundle {\n97:     // address indexed sync read\n98:\
      \     val raddr = Input(Vec(numRead, UInt(log2Up(numEntries).W)))\n99:     val
      rdata = Output(Vec(numRead, gen))\n100:     // masked sync read (1H)\n101: \
      \    val mrmask = Input(Vec(numMRead, Vec(numEntries, Bool())))\n102:     val
      mrdata = Output(Vec(numMRead, gen))\n103:     // address indexed write\n104:\
      \     val wen   = Input(Vec(numWrite, Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/MaskedDataModule.scala
    lines: 115-125
    context: "115:   val numEntryPerBank = numEntries / numWBanks\n116: \n117:   val
      data = Reg(Vec(numEntries, gen))\n118: \n119:   // read ports\n120:   for (i
      <- 0 until numRead) {\n121:     val raddr_dec = RegNext(UIntToOH(io.raddr(i)))\n\
      122:     io.rdata(i) := Mux1H(raddr_dec, data)\n123:   }\n124: \n125:   // masked
      read ports"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemCommon.scala
    lines: 99-124
    context: "99: object AddPipelineReg {\n100:   class PipelineRegModule[T <: Data](gen:
      T) extends Module {\n101:     val io = IO(new Bundle() {\n102:       val in
      = Flipped(DecoupledIO(gen.cloneType))\n103:       val out = DecoupledIO(gen.cloneType)\n\
      104:       val isFlush = Input(Bool())\n105:     })\n106: \n107:     val valid
      = RegInit(false.B)\n108:     valid.suggestName(\"pipeline_reg_valid\")\n109:\
      \     when (io.out.fire) { valid := false.B }\n110:     when (io.in.fire) {
      valid := true.B }\n111:     when (io.isFlush) { valid := false.B }\n112: \n\
      113:     io.in.ready := !valid || io.out.ready\n114:     io.out.bits := RegEnable(io.in.bits,
      io.in.fire)\n115:     io.out.valid := valid //&& !isFlush\n116:   }\n117: \n\
      118:   def apply[T <: Data]\n119:   (left: DecoupledIO[T], right: DecoupledIO[T],
      isFlush: Bool,\n120:    moduleName: Option[String] = None\n121:   ): Unit =
      {\n122:     val pipelineReg = Module(new PipelineRegModule[T](left.bits.cloneType))\n\
      123:     if(moduleName.nonEmpty) pipelineReg.suggestName(moduleName.get)\n124:\
      \     pipelineReg.io.in <> left"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemCommon.scala
    lines: 121-128
    context: "121:   ): Unit = {\n122:     val pipelineReg = Module(new PipelineRegModule[T](left.bits.cloneType))\n\
      123:     if(moduleName.nonEmpty) pipelineReg.suggestName(moduleName.get)\n124:\
      \     pipelineReg.io.in <> left\n125:     right <> pipelineReg.io.out\n126:\
      \     pipelineReg.io.isFlush := isFlush\n127:   }\n128: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 35-45
    context: "35:   with HasLoadHelper\n36:   with HasPerfEvents\n37: {\n38:   val
      io = IO(new Bundle() {\n39:     // control\n40:     val redirect = Flipped(ValidIO(new
      Redirect))\n41: \n42:     // violation query\n43:     val query = Vec(LoadPipelineWidth,
      Flipped(new LoadNukeQueryIO))\n44: \n45:     // from store unit s1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 44-54
    context: "44: \n45:     // from store unit s1\n46:     val storeIn = Vec(StorePipelineWidth,
      Flipped(Valid(new LsPipelineBundle)))\n47: \n48:     // global rollback flush\n\
      49:     val rollback = Vec(StorePipelineWidth,Output(Valid(new Redirect)))\n\
      50: \n51:     // to LoadQueueReplay\n52:     val stAddrReadySqPtr = Input(new
      SqPtr)\n53:     val stIssuePtr       = Input(new SqPtr)\n54:     val lqFull\
      \           = Output(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 76-86
    context: "76:   val allocated = RegInit(VecInit(List.fill(LoadQueueRAWSize)(false.B)))
      // The control signals need to explicitly indicate the initial value\n77:  \
      \ val uop = Reg(Vec(LoadQueueRAWSize, new DynInst))\n78:   val paddrModule =
      Module(new LqPAddrModule(\n79:     gen = UInt(PartialPAddrWidth.W),\n80:   \
      \  numEntries = LoadQueueRAWSize,\n81:     numRead = LoadPipelineWidth,\n82:\
      \     numWrite = LoadPipelineWidth,\n83:     numWBank = LoadQueueNWriteBanks,\n\
      84:     numWDelay = 2,\n85:     numCamPort = StorePipelineWidth,\n86:     enableCacheLineCheck
      = true,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 88-98
    context: "88:   ))\n89:   paddrModule.io := DontCare\n90:   val maskModule = Module(new
      LqMaskModule(\n91:     gen = UInt((VLEN/8).W),\n92:     numEntries = LoadQueueRAWSize,\n\
      93:     numRead = LoadPipelineWidth,\n94:     numWrite = LoadPipelineWidth,\n\
      95:     numWBank = LoadQueueNWriteBanks,\n96:     numWDelay = 2,\n97:     numCamPort
      = StorePipelineWidth\n98:   ))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 95-105
    context: "95:     numWBank = LoadQueueNWriteBanks,\n96:     numWDelay = 2,\n97:\
      \     numCamPort = StorePipelineWidth\n98:   ))\n99:   maskModule.io := DontCare\n\
      100:   val datavalid = RegInit(VecInit(List.fill(LoadQueueRAWSize)(false.B)))\n\
      101: \n102:   // freeliset: store valid entries index.\n103:   // +---+---+--------------+-----+-----+\n\
      104:   // | 0 | 1 |      ......  | n-2 | n-1 |\n105:   // +---+---+--------------+-----+-----+"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 112-122
    context: "112:   ))\n113:   freeList.io := DontCare\n114: \n115:   //  LoadQueueRAW
      enqueue\n116:   val canEnqueue = io.query.map(_.req.valid)\n117:   val cancelEnqueue
      = io.query.map(_.req.bits.uop.robIdx.needFlush(io.redirect))\n118:   val allAddrCheck
      = io.stIssuePtr === io.stAddrReadySqPtr\n119:   val hasAddrInvalidStore = io.query.map(_.req.bits.uop.sqIdx).map(sqIdx
      => {\n120:     Mux(!allAddrCheck, isBefore(io.stAddrReadySqPtr, sqIdx), false.B)\n\
      121:   })\n122:   val needEnqueue = canEnqueue.zip(hasAddrInvalidStore).zip(cancelEnqueue).map
      { case ((v, r), c) => v && r && !c }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 136-149
    context: "136: \n137:     //  Allocate ready\n138:     val offset = PopCount(needEnqueue.take(w))\n\
      139:     val canAccept = freeList.io.canAllocate(offset)\n140:     val enqIndex
      = freeList.io.allocateSlot(offset)\n141:     enq.ready := Mux(needEnqueue(w),
      canAccept, true.B)\n142: \n143:     enqIndexVec(w) := enqIndex\n144:     when
      (needEnqueue(w) && enq.ready) {\n145:       acceptedVec(w) := true.B\n146: \n\
      147:       freeList.io.doAllocate(w) := true.B\n148: \n149:       //  Allocate
      new entry"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 159-172
    context: "159:       maskModule.io.waddr(w) := enqIndex\n160:       maskModule.io.wdata(w)
      := enq.bits.mask\n161: \n162:       //  Fill info\n163:       uop(enqIndex)
      := enq.bits.uop\n164:       datavalid(enqIndex) := enq.bits.data_valid\n165:\
      \     }\n166:     val debug_robIdx = enq.bits.uop.robIdx.asUInt\n167:     XSError(needEnqueue(w)
      && enq.ready && allocated(enqIndex), p\"LoadQueueRAW: You can not write an valid
      entry! check: ldu $w, robIdx $debug_robIdx\")\n168:   }\n169: \n170:   for ((query,
      w) <- io.query.map(_.resp).zipWithIndex) {\n171:     query.valid := RegNext(io.query(w).req.valid)\n\
      172:     query.bits.rep_frm_fetch := RegNext(false.B)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 180-190
    context: "180: \n181:   // when the stores that \"older than\" current load address
      were ready.\n182:   // current load will be released.\n183:   for (i <- 0 until
      LoadQueueRAWSize) {\n184:     val deqNotBlock = Mux(!allAddrCheck, !isBefore(io.stAddrReadySqPtr,
      uop(i).sqIdx), true.B)\n185:     val needCancel = uop(i).robIdx.needFlush(io.redirect)\n\
      186: \n187:     when (allocated(i) && (deqNotBlock || needCancel)) {\n188: \
      \      allocated(i) := false.B\n189:       freeMaskVec(i) := true.B\n190:  \
      \   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 190-204
    context: "190:     }\n191:   }\n192: \n193:   // if need replay deallocate entry\n\
      194:   val lastCanAccept = GatedValidRegNext(acceptedVec)\n195:   val lastAllocIndex
      = GatedRegNext(enqIndexVec)\n196: \n197:   for ((revoke, w) <- io.query.map(_.revoke).zipWithIndex)
      {\n198:     val revokeValid = revoke && lastCanAccept(w)\n199:     val revokeIndex
      = lastAllocIndex(w)\n200: \n201:     when (allocated(revokeIndex) && revokeValid)
      {\n202:       allocated(revokeIndex) := false.B\n203:       freeMaskVec(revokeIndex)
      := true.B\n204:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 201-211
    context: "201:     when (allocated(revokeIndex) && revokeValid) {\n202:      \
      \ allocated(revokeIndex) := false.B\n203:       freeMaskVec(revokeIndex) :=
      true.B\n204:     }\n205:   }\n206:   freeList.io.free := freeMaskVec.asUInt\n\
      207: \n208:   io.lqFull := freeList.io.empty\n209: \n210:   /**\n211:     *
      Store-Load Memory violation detection"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 251-261
    context: "251:       val res = Seq.fill(2)(Wire(ValidIO(chiselTypeOf(bits(0)))))\n\
      252:       for (i <- res.indices) {\n253:         res(i).valid := valid(i)\n\
      254:         res(i).bits := bits(i)\n255:       }\n256:       val oldest = Mux(valid(0)
      && valid(1), Mux(isAfter(bits(0).uop.robIdx, bits(1).uop.robIdx), res(1), res(0)),
      Mux(valid(0) && !valid(1), res(0), res(1)))\n257:       (Seq(oldest.valid),
      Seq(oldest.bits))\n258:     } else {\n259:       val left = selectPartialOldest(valid.take(valid.length
      / 2), bits.take(bits.length / 2))\n260:       val right = selectPartialOldest(valid.takeRight(valid.length
      - (valid.length / 2)), bits.takeRight(bits.length - (bits.length / 2)))\n261:\
      \       selectPartialOldest(left._1 ++ right._1, left._2 ++ right._2)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 269-288
    context: "269:     // group info\n270:     val selectValidGroups = valid.grouped(SelectGroupSize).toList\n\
      271:     val selectBitsGroups = bits.grouped(SelectGroupSize).toList\n272: \
      \    // select logic\n273:     if (valid.length <= SelectGroupSize) {\n274:\
      \       val (selValid, selBits) = selectPartialOldest(valid, bits)\n275:   \
      \    val selValidNext = GatedValidRegNext(selValid(0))\n276:       val selBitsNext
      = RegEnable(selBits(0), selValid(0))\n277:       (Seq(selValidNext && !selBitsNext.uop.robIdx.needFlush(RegNext(io.redirect))),
      Seq(selBitsNext))\n278:     } else {\n279:       val select = (0 until numSelectGroups).map(g
      => {\n280:         val (selValid, selBits) = selectPartialOldest(selectValidGroups(g),
      selectBitsGroups(g))\n281:         val selValidNext = RegNext(selValid(0))\n\
      282:         val selBitsNext = RegEnable(selBits(0), selValid(0))\n283:    \
      \     (selValidNext && !selBitsNext.uop.robIdx.needFlush(io.redirect) && !selBitsNext.uop.robIdx.needFlush(RegNext(io.redirect)),
      selBitsNext)\n284:       })\n285:       selectOldest(select.map(_._1), select.map(_._2))\n\
      286:     }\n287:   }\n288: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 293-303
    context: "293:     paddrModule.io.violationCheckLine.get(i) := storeIn(i).bits.wlineflag\n\
      294:     maskModule.io.violationMdata(i) := RegEnable(storeIn(i).bits.mask,
      storeIn(i).valid)\n295: \n296:     val addrMaskMatch = paddrModule.io.violationMmask(i).asUInt
      & maskModule.io.violationMmask(i).asUInt\n297:     val entryNeedCheck = GatedValidRegNext(VecInit((0
      until LoadQueueRAWSize).map(j => {\n298:       allocated(j) && storeIn(i).valid
      && isAfter(uop(j).robIdx, storeIn(i).bits.uop.robIdx) && datavalid(j) && !uop(j).robIdx.needFlush(io.redirect)\n\
      299:     })))\n300:     val lqViolationSelVec = VecInit((0 until LoadQueueRAWSize).map(j
      => {\n301:       addrMaskMatch(j) && entryNeedCheck(j)\n302:     }))\n303: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 331-342
    context: "331:   val stFtqOffset = Wire(Vec(StorePipelineWidth, UInt(log2Up(PredictWidth).W)))\n\
      332:   for (w <- 0 until StorePipelineWidth) {\n333:     val detectedRollback
      = detectRollback(w)\n334:     rollbackLqWb(w).valid := detectedRollback._1 &&
      DelayN(storeIn(w).valid && !storeIn(w).bits.miss, TotalSelectCycles)\n335: \
      \    rollbackLqWb(w).bits  := detectedRollback._2\n336:     stFtqIdx(w) := DelayNWithValid(storeIn(w).bits.uop.ftqPtr,
      storeIn(w).valid, TotalSelectCycles)._2\n337:     stFtqOffset(w) := DelayNWithValid(storeIn(w).bits.uop.ftqOffset,
      storeIn(w).valid, TotalSelectCycles)._2\n338:   }\n339: \n340:   // select rollback
      (part2), generate rollback request, then fire rollback request\n341:   // Note
      that we use robIdx - 1.U to flush the load instruction itself.\n342:   // Thus,
      here if last cycle's robIdx equals to this cycle's robIdx, it still triggers
      the redirect."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 341-369
    context: "341:   // Note that we use robIdx - 1.U to flush the load instruction
      itself.\n342:   // Thus, here if last cycle's robIdx equals to this cycle's
      robIdx, it still triggers the redirect.\n343: \n344:   // select uop in parallel\n\
      345: \n346:   val allRedirect = (0 until StorePipelineWidth).map(i => {\n347:\
      \     val redirect = Wire(Valid(new Redirect))\n348:     redirect.valid := rollbackLqWb(i).valid\n\
      349:     redirect.bits             := DontCare\n350:     redirect.bits.isRVC\
      \       := rollbackLqWb(i).bits.preDecodeInfo.isRVC\n351:     redirect.bits.robIdx\
      \      := rollbackLqWb(i).bits.robIdx\n352:     redirect.bits.ftqIdx      :=
      rollbackLqWb(i).bits.ftqPtr\n353:     redirect.bits.ftqOffset   := rollbackLqWb(i).bits.ftqOffset\n\
      354:     redirect.bits.stFtqIdx    := stFtqIdx(i)\n355:     redirect.bits.stFtqOffset
      := stFtqOffset(i)\n356:     redirect.bits.level       := RedirectLevel.flush\n\
      357:     redirect.bits.cfiUpdate.target := rollbackLqWb(i).bits.pc\n358:   \
      \  redirect.bits.debug_runahead_checkpoint_id := rollbackLqWb(i).bits.debugInfo.runahead_checkpoint_id\n\
      359:     redirect\n360:   })\n361:   io.rollback := allRedirect\n362: \n363:\
      \   // perf cnt\n364:   val canEnqCount = PopCount(io.query.map(_.req.fire))\n\
      365:   val validCount = freeList.io.validCount\n366:   val allowEnqueue = validCount
      <= (LoadQueueRAWSize - LoadPipelineWidth).U\n367:   val rollbaclValid = io.rollback.map(_.valid).reduce(_
      || _).asUInt\n368: \n369:   QueuePerf(LoadQueueRAWSize, validCount, !allowEnqueue)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 34-50
    context: "34:   with HasCircularQueuePtrHelper\n35:   with HasLoadHelper\n36:
      {\n37:   val io = IO(new Bundle() {\n38:     /* control */\n39:     val redirect
      = Flipped(Valid(new Redirect))\n40:     // redirect flush\n41:     val flush
      = Output(Bool())\n42:     // mmio commit\n43:     val rob = Flipped(new RobLsqIO)\n\
      44:     // mmio select\n45:     val mmioSelect = Output(Bool())\n46:     //
      slaveId\n47:     val slaveId = ValidIO(UInt(UncacheBufferIndexWidth.W))\n48:\
      \ \n49:     /* transaction */\n50:     // from ldu"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 48-59
    context: "48: \n49:     /* transaction */\n50:     // from ldu\n51:     val req
      = Flipped(Valid(new LqWriteBundle))\n52:     // to ldu: mmio, data\n53:    \
      \ val mmioOut = DecoupledIO(new MemExuOutput)\n54:     val mmioRawData = Output(new
      LoadDataFromLQBundle)\n55:     // to ldu: nc with data\n56:     val ncOut =
      DecoupledIO(new LsPipelineBundle)\n57:     // <=> uncache\n58:     val uncache
      = new UncacheWordIO\n59:     // exception generated by outer bus"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 68-78
    context: "68:   val s_idle :: s_req :: s_resp :: s_wait :: Nil = Enum(4)\n69:\
      \   val uncacheState = RegInit(s_idle)\n70:   val uncacheData = Reg(io.uncache.resp.bits.data.cloneType)\n\
      71:   val nderr = RegInit(false.B)\n72: \n73:   val writeback = Mux(req.nc,
      io.ncOut.fire, io.mmioOut.fire)\n74:   val slaveAck = req_valid && io.uncache.idResp.valid
      && io.uncache.idResp.bits.mid === entryIndex.U\n75: \n76:   /**\n77:     * Flush\n\
      78:     *"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 78-97
    context: "78:     *\n79:     * 1. direct flush during idle\n80:     * 2. otherwise
      delayed flush until receiving uncache resp\n81:     */\n82:   val needFlushReg
      = RegInit(false.B)\n83:   val needFlush = req_valid && req.uop.robIdx.needFlush(io.redirect)\n\
      84:   val flush = WireInit(false.B)\n85:   when(flush){\n86:     needFlushReg
      := false.B\n87:   }.elsewhen(needFlush){\n88:     needFlushReg := true.B\n89:\
      \   }\n90: \n91:   /* enter req */\n92:   when (flush) {\n93:     req_valid
      := false.B\n94:     slaveAccept := false.B\n95:   } .elsewhen (io.req.valid)
      {\n96:     req_valid := true.B\n97:     slaveAccept := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 102-112
    context: "102:     slaveId := io.uncache.idResp.bits.sid\n103:   } .elsewhen (writeback)
      {\n104:     req_valid := false.B\n105:     slaveAccept := false.B\n106:   }\n\
      107:   XSError(!flush && io.req.valid && req_valid, p\"LoadQueueUncache: You
      can not write an valid entry: $entryIndex\")\n108: \n109:   /**\n110:     *
      Memory mapped IO / NC operations\n111:     *\n112:     * States:"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 115-125
    context: "115:     * (3) s_resp: wait for response from uncache channel\n116:\
      \     * (4) s_wait: wait for loadunit to receive writeback req\n117:     */\n\
      118:   val pendingld = GatedValidRegNext(io.rob.pendingMMIOld)\n119:   val pendingPtr
      = GatedRegNext(io.rob.pendingPtr)\n120:   val canSendReq = req_valid && !needFlush
      && Mux(\n121:     req.nc, true.B,\n122:     pendingld && req.uop.robIdx ===
      pendingPtr\n123:   )\n124:   switch (uncacheState) {\n125:     is (s_idle) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 121-133
    context: "121:     req.nc, true.B,\n122:     pendingld && req.uop.robIdx === pendingPtr\n\
      123:   )\n124:   switch (uncacheState) {\n125:     is (s_idle) {\n126:     \
      \  when (needFlush) {\n127:         uncacheState := s_idle\n128:         flush
      := true.B\n129:       }.elsewhen (canSendReq) {\n130:         uncacheState :=
      s_req\n131:       }\n132:     }\n133:     is (s_req) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 129-150
    context: "129:       }.elsewhen (canSendReq) {\n130:         uncacheState := s_req\n\
      131:       }\n132:     }\n133:     is (s_req) {\n134:       when(needFlush){\n\
      135:         uncacheState := s_idle\n136:         flush := true.B\n137:    \
      \   }.elsewhen(io.uncache.req.fire) {\n138:         uncacheState := s_resp\n\
      139:       }\n140:     }\n141:     is (s_resp) {\n142:       when (io.uncache.resp.fire)
      {\n143:         when (needFlush || needFlushReg) {\n144:           uncacheState
      := s_idle\n145:           flush := true.B\n146:         }.otherwise{\n147: \
      \          uncacheState := s_wait\n148:         }\n149:       }\n150:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 147-159
    context: "147:           uncacheState := s_wait\n148:         }\n149:       }\n\
      150:     }\n151:     is (s_wait) {\n152:       when (needFlush || writeback)
      {\n153:         uncacheState := s_idle\n154:         flush := true.B\n155: \
      \      }\n156:     }\n157:   }\n158: \n159:   /* control */"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 155-173
    context: "155:       }\n156:     }\n157:   }\n158: \n159:   /* control */\n160:\
      \   io.flush := flush\n161:   io.rob.mmio := DontCare\n162:   io.rob.uop :=
      DontCare\n163:   io.mmioSelect := (uncacheState =/= s_idle) && req.mmio\n164:\
      \   io.slaveId.valid := slaveAccept\n165:   io.slaveId.bits := slaveId\n166:\
      \ \n167:   /* uncahce req */\n168:   io.uncache.req.valid     := uncacheState
      === s_req && !needFlush\n169:   io.uncache.req.bits      := DontCare\n170: \
      \  io.uncache.req.bits.cmd  := MemoryOpConstants.M_XRD\n171:   io.uncache.req.bits.data
      := DontCare\n172:   io.uncache.req.bits.addr := req.paddr\n173:   io.uncache.req.bits.vaddr:=
      req.vaddr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 177-190
    context: "177:   io.uncache.req.bits.replayCarry := DontCare\n178:   io.uncache.req.bits.robIdx
      := req.uop.robIdx\n179:   io.uncache.req.bits.nc := req.nc\n180:   io.uncache.req.bits.memBackTypeMM
      := req.memBackTypeMM\n181: \n182:   io.uncache.resp.ready := true.B\n183: \n\
      184:   /* uncahce resp */\n185:   when (io.uncache.resp.fire) {\n186:     uncacheData
      := io.uncache.resp.bits.data\n187:     nderr := io.uncache.resp.bits.nderr\n\
      188:   }\n189: \n190:   /* uncahce writeback */"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 186-203
    context: "186:     uncacheData := io.uncache.resp.bits.data\n187:     nderr :=
      io.uncache.resp.bits.nderr\n188:   }\n189: \n190:   /* uncahce writeback */\n\
      191:   io.mmioOut.valid := false.B\n192:   io.mmioOut.bits := DontCare\n193:\
      \   io.mmioRawData := DontCare\n194:   io.ncOut.valid := false.B\n195:   io.ncOut.bits
      := DontCare\n196: \n197:   when(req.nc){\n198:     io.ncOut.valid := (uncacheState
      === s_wait) && !needFlush\n199:     io.ncOut.bits := DontCare\n200:     io.ncOut.bits.uop
      := req.uop\n201:     io.ncOut.bits.uop.lqIdx := req.uop.lqIdx\n202:     io.ncOut.bits.uop.exceptionVec(hardwareError)
      := nderr\n203:     io.ncOut.bits.data := uncacheData"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 208-230
    context: "208:     io.ncOut.bits.schedIndex := req.schedIndex\n209:     io.ncOut.bits.isvec
      := req.isvec\n210:     io.ncOut.bits.is128bit := req.is128bit\n211:     io.ncOut.bits.vecActive
      := req.vecActive\n212:   }.otherwise{\n213:     io.mmioOut.valid := (uncacheState
      === s_wait) && !needFlush\n214:     io.mmioOut.bits := DontCare\n215:     io.mmioOut.bits.uop
      := req.uop\n216:     io.mmioOut.bits.uop.lqIdx := req.uop.lqIdx\n217:     io.mmioOut.bits.uop.exceptionVec(hardwareError)
      := nderr\n218:     io.mmioOut.bits.data := uncacheData\n219:     io.mmioOut.bits.debug.isMMIO
      := true.B\n220:     io.mmioOut.bits.debug.isNCIO := false.B\n221:     io.mmioOut.bits.debug.paddr
      := req.paddr\n222:     io.mmioOut.bits.debug.vaddr := req.vaddr\n223:     io.mmioRawData.lqData
      := uncacheData\n224:     io.mmioRawData.uop := req.uop\n225:     io.mmioRawData.addrOffset
      := req.paddr\n226:   }\n227: \n228:   io.exception.valid := writeback\n229:\
      \   io.exception.bits := req\n230:   io.exception.bits.uop.exceptionVec(hardwareError)
      := nderr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 228-238
    context: "228:   io.exception.valid := writeback\n229:   io.exception.bits :=
      req\n230:   io.exception.bits.uop.exceptionVec(hardwareError) := nderr\n231:\
      \ \n232:   /* debug log */\n233:   XSDebug(io.uncache.req.fire,\n234:     \"\
      uncache req: pc %x addr %x data %x op %x mask %x\\n\",\n235:     req.uop.pc,\n\
      236:     io.uncache.req.bits.addr,\n237:     io.uncache.req.bits.data,\n238:\
      \     io.uncache.req.bits.cmd,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 236-247
    context: "236:     io.uncache.req.bits.addr,\n237:     io.uncache.req.bits.data,\n\
      238:     io.uncache.req.bits.cmd,\n239:     io.uncache.req.bits.mask\n240: \
      \  )\n241:   XSInfo(io.ncOut.fire,\n242:     \"int load miss write to cbd robidx
      %d lqidx %d pc 0x%x mmio %x\\n\",\n243:     io.ncOut.bits.uop.robIdx.asUInt,\n\
      244:     io.ncOut.bits.uop.lqIdx.asUInt,\n245:     io.ncOut.bits.uop.pc,\n246:\
      \     true.B\n247:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 243-257
    context: "243:     io.ncOut.bits.uop.robIdx.asUInt,\n244:     io.ncOut.bits.uop.lqIdx.asUInt,\n\
      245:     io.ncOut.bits.uop.pc,\n246:     true.B\n247:   )\n248:   XSInfo(io.mmioOut.fire,\n\
      249:     \"int load miss write to cbd robidx %d lqidx %d pc 0x%x mmio %x\\n\"\
      ,\n250:     io.mmioOut.bits.uop.robIdx.asUInt,\n251:     io.mmioOut.bits.uop.lqIdx.asUInt,\n\
      252:     io.mmioOut.bits.uop.pc,\n253:     true.B\n254:   )\n255: \n256: }\n\
      257: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 259-269
    context: "259:   with HasCircularQueuePtrHelper\n260:   with HasMemBlockParameters\n\
      261: {\n262:   val io = IO(new Bundle() {\n263:     /* control */\n264:    \
      \ val redirect = Flipped(Valid(new Redirect))\n265:     // mmio commit\n266:\
      \     val rob = Flipped(new RobLsqIO)\n267: \n268:     /* transaction */\n269:\
      \     // enqueue: from ldu s3"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 267-278
    context: "267: \n268:     /* transaction */\n269:     // enqueue: from ldu s3\n\
      270:     val req = Vec(LoadPipelineWidth, Flipped(Decoupled(new LqWriteBundle)))\n\
      271:     // writeback: mmio to ldu s0, s3\n272:     val mmioOut = Vec(LoadPipelineWidth,
      DecoupledIO(new MemExuOutput))\n273:     val mmioRawData = Vec(LoadPipelineWidth,
      Output(new LoadDataFromLQBundle))\n274:     // writeback: nc to ldu s0--s3\n\
      275:     val ncOut = Vec(LoadPipelineWidth, Decoupled(new LsPipelineBundle))\n\
      276:     // <=>uncache\n277:     val uncache = new UncacheWordIO\n278: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 276-286
    context: "276:     // <=>uncache\n277:     val uncache = new UncacheWordIO\n278:\
      \ \n279:     /* except */\n280:     // rollback from frontend when buffer is
      full\n281:     val rollback = Output(Valid(new Redirect))\n282:     // exception
      generated by outer bus\n283:     val exception = Valid(new LqWriteBundle)\n\
      284:   })\n285: \n286:   /******************************************************************"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 296-324
    context: "296:     moduleName = \"LoadQueueUncache freelist\"\n297:   ))\n298:\
      \   freeList.io := DontCare\n299: \n300:   // set default IO\n301:   entries.foreach
      {\n302:     case (e) =>\n303:       e.io.req.valid := false.B\n304:       e.io.req.bits
      := DontCare\n305:       e.io.uncache.req.ready := false.B\n306:       e.io.uncache.idResp.valid
      := false.B\n307:       e.io.uncache.idResp.bits := DontCare\n308:       e.io.uncache.resp.valid
      := false.B\n309:       e.io.uncache.resp.bits := DontCare\n310:       e.io.ncOut.ready
      := false.B\n311:       e.io.mmioOut.ready := false.B\n312:   }\n313:   io.uncache.req.valid
      := false.B\n314:   io.uncache.req.bits := DontCare\n315:   io.uncache.resp.ready
      := false.B\n316:   for (w <- 0 until LoadPipelineWidth) {\n317:     io.mmioOut(w).valid
      := false.B\n318:     io.mmioOut(w).bits := DontCare\n319:     io.mmioRawData(w)
      := DontCare\n320:     io.ncOut(w).valid := false.B\n321:     io.ncOut(w).bits
      := DontCare\n322:   }\n323: \n324: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 331-352
    context: "331:    *    ready: freelist can allocate\n332:    ******************************************************************/\n\
      333: \n334:   val s1_sortedVec = HwSort(VecInit(io.req.map { case x => DataWithPtr(x.valid,
      x.bits, x.bits.uop.robIdx) }))\n335:   val s1_req = VecInit(s1_sortedVec.map(_.bits))\n\
      336:   val s1_valid = VecInit(s1_sortedVec.map(_.valid))\n337:   val s2_enqueue
      = Wire(Vec(LoadPipelineWidth, Bool()))\n338:   io.req.zipWithIndex.foreach{
      case (r, i) =>\n339:     r.ready := true.B\n340:   }\n341: \n342:   // s2: enqueue\n\
      343:   val s2_req = (0 until LoadPipelineWidth).map(i => {RegEnable(s1_req(i),
      s1_valid(i))})\n344:   val s2_valid = (0 until LoadPipelineWidth).map(i => {\n\
      345:     RegNext(s1_valid(i)) &&\n346:     !s2_req(i).uop.robIdx.needFlush(RegNext(io.redirect))
      &&\n347:     !s2_req(i).uop.robIdx.needFlush(io.redirect)\n348:   })\n349: \
      \  val s2_has_exception = s2_req.map(x => ExceptionNO.selectByFu(x.uop.exceptionVec,
      LduCfg).asUInt.orR)\n350:   val s2_need_replay = s2_req.map(_.rep_info.need_rep)\n\
      351: \n352:   for (w <- 0 until LoadPipelineWidth) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 348-358
    context: "348:   })\n349:   val s2_has_exception = s2_req.map(x => ExceptionNO.selectByFu(x.uop.exceptionVec,
      LduCfg).asUInt.orR)\n350:   val s2_need_replay = s2_req.map(_.rep_info.need_rep)\n\
      351: \n352:   for (w <- 0 until LoadPipelineWidth) {\n353:     s2_enqueue(w)
      := s2_valid(w) && !s2_has_exception(w) && !s2_need_replay(w) && (s2_req(w).mmio
      || s2_req(w).nc)\n354:   }\n355: \n356:   val s2_enqValidVec = Wire(Vec(LoadPipelineWidth,
      Bool()))\n357:   val s2_enqIndexVec = Wire(Vec(LoadPipelineWidth, UInt()))\n\
      358: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 380-396
    context: "380:    * 3. writeback\n381:    ******************************************************************/\n\
      382:   private val NC_WB_MOD = NCWBPorts.length\n383: \n384:   val uncacheReq
      = Wire(DecoupledIO(io.uncache.req.bits.cloneType))\n385:   val mmioSelect =
      entries.map(e => e.io.mmioSelect).reduce(_ || _)\n386:   val mmioReq = Wire(DecoupledIO(io.uncache.req.bits.cloneType))\n\
      387:   // TODO lyq: It's best to choose in robIdx order / the order in which
      they enter\n388:   val ncReqArb = Module(new RRArbiterInit(io.uncache.req.bits.cloneType,
      LoadUncacheBufferSize))\n389: \n390:   val mmioOut = Wire(DecoupledIO(io.mmioOut(0).bits.cloneType))\n\
      391:   val mmioRawData = Wire(io.mmioRawData(0).cloneType)\n392:   val ncOut
      = Wire(chiselTypeOf(io.ncOut))\n393:   val ncOutValidVec = VecInit(entries.map(e
      => e.io.ncOut.valid))\n394:   val ncOutValidVecRem = SubVec.getMaskRem(ncOutValidVec,
      NC_WB_MOD)\n395: \n396:   // init"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 394-408
    context: "394:   val ncOutValidVecRem = SubVec.getMaskRem(ncOutValidVec, NC_WB_MOD)\n\
      395: \n396:   // init\n397:   uncacheReq.valid := false.B\n398:   uncacheReq.bits\
      \  := DontCare\n399:   mmioReq.valid := false.B\n400:   mmioReq.bits := DontCare\n\
      401:   mmioOut.valid := false.B\n402:   mmioOut.bits := DontCare\n403:   mmioRawData
      := DontCare\n404:   for (i <- 0 until LoadUncacheBufferSize) {\n405:     ncReqArb.io.in(i).valid
      := false.B\n406:     ncReqArb.io.in(i).bits := DontCare\n407:   }\n408:   for
      (i <- 0 until LoadPipelineWidth) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 408-418
    context: "408:   for (i <- 0 until LoadPipelineWidth) {\n409:     ncOut(i).valid
      := false.B\n410:     ncOut(i).bits := DontCare\n411:   }\n412: \n413:   entries.zipWithIndex.foreach
      {\n414:     case (e, i) =>\n415:       // enqueue\n416:       for (w <- 0 until
      LoadPipelineWidth) {\n417:         when (s2_enqValidVec(w) && (i.U === s2_enqIndexVec(w)))
      {\n418:           e.io.req.valid := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 419-446
    context: "419:           e.io.req.bits := s2_req(w)\n420:         }\n421:    \
      \   }\n422: \n423:       // control\n424:       e.io.redirect <> io.redirect\n\
      425:       e.io.rob <> io.rob\n426: \n427:       // uncache req, writeback\n\
      428:       when (e.io.mmioSelect) {\n429:         mmioReq.valid := e.io.uncache.req.valid\n\
      430:         mmioReq.bits := e.io.uncache.req.bits\n431:         e.io.uncache.req.ready
      := mmioReq.ready\n432: \n433:         e.io.mmioOut.ready := mmioOut.ready\n\
      434:         mmioOut.valid := e.io.mmioOut.valid\n435:         mmioOut.bits
      := e.io.mmioOut.bits\n436:         mmioRawData := e.io.mmioRawData\n437: \n\
      438:       }.otherwise{\n439:         ncReqArb.io.in(i).valid := e.io.uncache.req.valid\n\
      440:         ncReqArb.io.in(i).bits := e.io.uncache.req.bits\n441:         e.io.uncache.req.ready
      := ncReqArb.io.in(i).ready\n442: \n443:         (0 until NC_WB_MOD).map { w
      =>\n444:           val (idx, ncOutValid) = PriorityEncoderWithFlag(ncOutValidVecRem(w))\n\
      445:           val port = NCWBPorts(w)\n446:           when((i.U === idx) &&
      ncOutValid) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 444-454
    context: "444:           val (idx, ncOutValid) = PriorityEncoderWithFlag(ncOutValidVecRem(w))\n\
      445:           val port = NCWBPorts(w)\n446:           when((i.U === idx) &&
      ncOutValid) {\n447:             ncOut(port).valid := ncOutValid\n448:      \
      \       ncOut(port).bits := e.io.ncOut.bits\n449:             e.io.ncOut.ready
      := ncOut(port).ready\n450:           }\n451:         }\n452: \n453:       }\n\
      454: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 462-475
    context: "462:         e.io.uncache.resp <> io.uncache.resp\n463:       }\n464:\
      \ \n465:   }\n466: \n467:   mmioReq.ready := false.B\n468:   ncReqArb.io.out.ready
      := false.B\n469:   when(mmioSelect){\n470:     uncacheReq <> mmioReq\n471: \
      \  }.otherwise{\n472:     uncacheReq <> ncReqArb.io.out\n473:   }\n474: \n475:\
      \   // uncache Request"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 474-487
    context: "474: \n475:   // uncache Request\n476:   AddPipelineReg(uncacheReq,
      io.uncache.req, false.B)\n477: \n478:   // uncache Writeback\n479:   AddPipelineReg(mmioOut,
      io.mmioOut(UncacheWBPort), false.B)\n480:   io.mmioRawData(UncacheWBPort) :=
      RegEnable(mmioRawData, mmioOut.fire)\n481: \n482:   (0 until LoadPipelineWidth).foreach
      { i => AddPipelineReg(ncOut(i), io.ncOut(i), false.B) }\n483: \n484:   // uncache
      exception\n485:   io.exception.valid := Cat(entries.map(_.io.exception.valid)).orR\n\
      486:   io.exception.bits := ParallelPriorityMux(entries.map(e =>\n487:     (e.io.exception.valid,
      e.io.exception.bits)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 487-498
    context: "487:     (e.io.exception.valid, e.io.exception.bits)\n488:   ))\n489:\
      \ \n490:   // rob\n491:   for (i <- 0 until LoadPipelineWidth) {\n492:     io.rob.mmio(i)
      := RegNext(s1_valid(i) && s1_req(i).mmio)\n493:     io.rob.uop(i) := RegEnable(s1_req(i).uop,
      s1_valid(i))\n494:   }\n495: \n496: \n497:   /******************************************************************\n\
      498:    * Deallocate"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 502-519
    context: "502: \n503:   // init\n504:   freeMaskVec.map(e => e := false.B)\n505:\
      \ \n506:   // dealloc logic\n507:   entries.zipWithIndex.foreach {\n508:   \
      \  case (e, i) =>\n509:       when ((e.io.mmioSelect && e.io.mmioOut.fire) ||
      e.io.ncOut.fire || e.io.flush) {\n510:         freeMaskVec(i) := true.B\n511:\
      \       }\n512:   }\n513: \n514:   freeList.io.free := freeMaskVec.asUInt\n\
      515: \n516: \n517:   /******************************************************************\n\
      518:    * Uncache rollback detection\n519:    *"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 536-547
    context: "536:    * stage 2:               lq\n537:    *                     \
      \   |\n538:    *                     rollback req\n539:    *\n540:    ******************************************************************/\n\
      541:   def selectOldestRedirect(xs: Seq[Valid[Redirect]]): Vec[Bool] = {\n542:\
      \     val compareVec = (0 until xs.length).map(i => (0 until i).map(j => isAfter(xs(j).bits.robIdx,
      xs(i).bits.robIdx)))\n543:     val resultOnehot = VecInit((0 until xs.length).map(i
      => Cat((0 until xs.length).map(j =>\n544:       (if (j < i) !xs(j).valid ||
      compareVec(i)(j)\n545:       else if (j == i) xs(i).valid\n546:       else !xs(j).valid
      || !compareVec(j)(i))\n547:     )).andR))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 549-584
    context: "549:   }\n550:   val reqNeedCheck = VecInit((0 until LoadPipelineWidth).map(w
      =>\n551:     s2_enqueue(w) && !s2_enqValidVec(w)\n552:   ))\n553:   val reqSelUops
      = VecInit(s2_req.map(_.uop))\n554:   val allRedirect = (0 until LoadPipelineWidth).map(i
      => {\n555:     val redirect = Wire(Valid(new Redirect))\n556:     redirect.valid
      := reqNeedCheck(i)\n557:     redirect.bits             := DontCare\n558:   \
      \  redirect.bits.isRVC       := reqSelUops(i).preDecodeInfo.isRVC\n559:    \
      \ redirect.bits.robIdx      := reqSelUops(i).robIdx\n560:     redirect.bits.ftqIdx\
      \      := reqSelUops(i).ftqPtr\n561:     redirect.bits.ftqOffset   := reqSelUops(i).ftqOffset\n\
      562:     redirect.bits.level       := RedirectLevel.flush\n563:     redirect.bits.cfiUpdate.target
      := reqSelUops(i).pc // TODO: check if need pc\n564:     redirect.bits.debug_runahead_checkpoint_id
      := reqSelUops(i).debugInfo.runahead_checkpoint_id\n565:     redirect\n566: \
      \  })\n567:   val oldestOneHot = selectOldestRedirect(allRedirect)\n568:   val
      oldestRedirect = Mux1H(oldestOneHot, allRedirect)\n569:   val lastCycleRedirect
      = Wire(Valid(new Redirect))\n570:   lastCycleRedirect.valid := RegNext(io.redirect.valid)\n\
      571:   lastCycleRedirect.bits := RegEnable(io.redirect.bits, io.redirect.valid)\n\
      572:   val lastLastCycleRedirect = Wire(Valid(new Redirect))\n573:   lastLastCycleRedirect.valid
      := RegNext(lastCycleRedirect.valid)\n574:   lastLastCycleRedirect.bits := RegEnable(lastCycleRedirect.bits,
      lastCycleRedirect.valid)\n575:   io.rollback.valid := GatedValidRegNext(oldestRedirect.valid
      &&\n576:                       !oldestRedirect.bits.robIdx.needFlush(io.redirect)
      &&\n577:                       !oldestRedirect.bits.robIdx.needFlush(lastCycleRedirect)
      &&\n578:                       !oldestRedirect.bits.robIdx.needFlush(lastLastCycleRedirect))\n\
      579:   io.rollback.bits := RegEnable(oldestRedirect.bits, oldestRedirect.valid)\n\
      580: \n581: \n582:   /******************************************************************\n\
      583:    * Perf Counter\n584:    ******************************************************************/"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 584-607
    context: "584:    ******************************************************************/\n\
      585:   val validCount = freeList.io.validCount\n586:   val allowEnqueue = !freeList.io.empty\n\
      587:   QueuePerf(LoadUncacheBufferSize, validCount, !allowEnqueue)\n588: \n\
      589:   XSPerfAccumulate(\"mmio_uncache_req\", io.uncache.req.fire && !io.uncache.req.bits.nc)\n\
      590:   XSPerfAccumulate(\"mmio_writeback_success\", io.mmioOut(0).fire)\n591:\
      \   XSPerfAccumulate(\"mmio_writeback_blocked\", io.mmioOut(0).valid && !io.mmioOut(0).ready)\n\
      592:   XSPerfAccumulate(\"nc_uncache_req\", io.uncache.req.fire && io.uncache.req.bits.nc)\n\
      593:   XSPerfAccumulate(\"nc_writeback_success\", io.ncOut(0).fire)\n594:  \
      \ XSPerfAccumulate(\"nc_writeback_blocked\", io.ncOut(0).valid && !io.ncOut(0).ready)\n\
      595:   XSPerfAccumulate(\"uncache_full_rollback\", io.rollback.valid)\n596:\
      \ \n597:   val perfEvents: Seq[(String, UInt)] = Seq(\n598:     (\"mmio_uncache_req\"\
      , io.uncache.req.fire && !io.uncache.req.bits.nc),\n599:     (\"mmio_writeback_success\"\
      , io.mmioOut(0).fire),\n600:     (\"mmio_writeback_blocked\", io.mmioOut(0).valid
      && !io.mmioOut(0).ready),\n601:     (\"nc_uncache_req\", io.uncache.req.fire
      && io.uncache.req.bits.nc),\n602:     (\"nc_writeback_success\", io.ncOut(0).fire),\n\
      603:     (\"nc_writeback_blocked\", io.ncOut(0).valid && !io.ncOut(0).ready),\n\
      604:     (\"uncache_full_rollback\", io.rollback.valid)\n605:   )\n606:   //
      end\n607: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 65-75
    context: "65: \n66: // Load / Store Queue Wrapper for XiangShan Out of Order LSU\n\
      67: class LsqWrapper(implicit p: Parameters) extends XSModule with HasDCacheParameters
      with HasPerfEvents {\n68:   val io = IO(new Bundle() {\n69:     val hartId =
      Input(UInt(hartIdLen.W))\n70:     val brqRedirect = Flipped(ValidIO(new Redirect))\n\
      71:     val stvecFeedback = Vec(VecStorePipelineWidth, Flipped(ValidIO(new FeedbackToLsqIO)))\n\
      72:     val ldvecFeedback = Vec(VecLoadPipelineWidth, Flipped(ValidIO(new FeedbackToLsqIO)))\n\
      73:     val enq = new LsqEnqIO\n74:     val ldu = new Bundle() {\n75:      \
      \   val stld_nuke_query = Vec(LoadPipelineWidth, Flipped(new LoadNukeQueryIO))
      // from load_s2"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 85-100
    context: "85:       val storeDataIn = Vec(StorePipelineWidth, Flipped(Valid(new
      MemExuOutput(isVector = true)))) // from store_s0, store data, send to sq from
      rs\n86:     }\n87:     val ldout = Vec(LoadPipelineWidth, DecoupledIO(new MemExuOutput))\n\
      88:     val ld_raw_data = Vec(LoadPipelineWidth, Output(new LoadDataFromLQBundle))\n\
      89:     val ncOut = Vec(LoadPipelineWidth, DecoupledIO(new LsPipelineBundle))\n\
      90:     val replay = Vec(LoadPipelineWidth, Decoupled(new LsPipelineBundle))\n\
      91:     val sbuffer = Vec(EnsbufferWidth, Decoupled(new DCacheWordReqWithVaddrAndPfFlag))\n\
      92:     val forward = Vec(LoadPipelineWidth, Flipped(new PipeLoadForwardQueryIO))\n\
      93:     val rob = Flipped(new RobLsqIO)\n94:     val nuke_rollback = Vec(StorePipelineWidth,
      Output(Valid(new Redirect)))\n95:     val nack_rollback = Vec(1, Output(Valid(new
      Redirect))) // uncahce\n96:     val release = Flipped(Valid(new Release))\n\
      97:    // val refill = Flipped(Valid(new Refill))\n98:     val tl_d_channel\
      \  = Input(new DcacheToLduForwardIO)\n99:     val maControl     = Flipped(new
      StoreMaBufToSqControlIO)\n100:     val uncacheOutstanding = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 97-110
    context: "97:    // val refill = Flipped(Valid(new Refill))\n98:     val tl_d_channel\
      \  = Input(new DcacheToLduForwardIO)\n99:     val maControl     = Flipped(new
      StoreMaBufToSqControlIO)\n100:     val uncacheOutstanding = Input(Bool())\n\
      101:     val uncache = new UncacheWordIO\n102:     val mmioStout = DecoupledIO(new
      MemExuOutput) // writeback uncached store\n103:     val cboZeroStout = DecoupledIO(new
      MemExuOutput)\n104:     // TODO: implement vector store\n105:     val vecmmioStout
      = DecoupledIO(new MemExuOutput(isVector = true)) // vec writeback uncached store\n\
      106:     val sqEmpty = Output(Bool())\n107:     val lq_rep_full = Output(Bool())\n\
      108:     val sqFull = Output(Bool())\n109:     val lqFull = Output(Bool())\n\
      110:     val sqCancelCnt = Output(UInt(log2Up(StoreQueueSize+1).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 173-183
    context: "173:     io.enq.resp(i).lqIdx := loadQueue.io.enq.resp(i)\n174:    \
      \ io.enq.resp(i).sqIdx := storeQueue.io.enq.resp(i)\n175:   }\n176: \n177: \
      \  // store queue wiring\n178:   storeQueue.io.brqRedirect <> io.brqRedirect\n\
      179:   storeQueue.io.vecFeedback   <> io.stvecFeedback\n180:   storeQueue.io.storeAddrIn
      <> io.sta.storeAddrIn // from store_s1\n181:   storeQueue.io.storeAddrInRe <>
      io.sta.storeAddrInRe // from store_s2\n182:   storeQueue.io.storeDataIn <> io.std.storeDataIn
      // from store_s0\n183:   storeQueue.io.storeMaskIn <> io.sta.storeMaskIn //
      from store_s0"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 180-192
    context: "180:   storeQueue.io.storeAddrIn <> io.sta.storeAddrIn // from store_s1\n\
      181:   storeQueue.io.storeAddrInRe <> io.sta.storeAddrInRe // from store_s2\n\
      182:   storeQueue.io.storeDataIn <> io.std.storeDataIn // from store_s0\n183:\
      \   storeQueue.io.storeMaskIn <> io.sta.storeMaskIn // from store_s0\n184: \
      \  storeQueue.io.sbuffer     <> io.sbuffer\n185:   storeQueue.io.mmioStout \
      \  <> io.mmioStout\n186:   storeQueue.io.cboZeroStout <> io.cboZeroStout\n187:\
      \   storeQueue.io.vecmmioStout <> io.vecmmioStout\n188:   storeQueue.io.rob\
      \         <> io.rob\n189:   storeQueue.io.exceptionAddr.isStore := DontCare\n\
      190:   storeQueue.io.sqCancelCnt  <> io.sqCancelCnt\n191:   storeQueue.io.sqDeq\
      \        <> io.sqDeq\n192:   storeQueue.io.sqEmpty      <> io.sqEmpty"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 189-199
    context: "189:   storeQueue.io.exceptionAddr.isStore := DontCare\n190:   storeQueue.io.sqCancelCnt\
      \  <> io.sqCancelCnt\n191:   storeQueue.io.sqDeq        <> io.sqDeq\n192:  \
      \ storeQueue.io.sqEmpty      <> io.sqEmpty\n193:   storeQueue.io.sqFull    \
      \   <> io.sqFull\n194:   storeQueue.io.forward      <> io.forward // overlap
      forwardMask & forwardData, DO NOT CHANGE SEQUENCE\n195:   storeQueue.io.force_write\
      \  <> io.force_write\n196:   storeQueue.io.cmoOpReq     <> io.cmoOpReq\n197:\
      \   storeQueue.io.cmoOpResp    <> io.cmoOpResp\n198:   storeQueue.io.flushSbuffer
      <> io.flushSbuffer\n199:   storeQueue.io.maControl    <> io.maControl"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 200-210
    context: "200:   io.diffStore := storeQueue.io.diffStore\n201: \n202:   /* <-------
      DANGEROUS: Don't change sequence here ! -------> */\n203: \n204:   //  load
      queue wiring\n205:   loadQueue.io.redirect            <> io.brqRedirect\n206:\
      \   loadQueue.io.vecFeedback           <> io.ldvecFeedback\n207:   loadQueue.io.ldu\
      \                 <> io.ldu\n208:   loadQueue.io.ldout               <> io.ldout\n\
      209:   loadQueue.io.ld_raw_data         <> io.ld_raw_data\n210:   loadQueue.io.ncOut\
      \               <> io.ncOut"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 209-219
    context: "209:   loadQueue.io.ld_raw_data         <> io.ld_raw_data\n210:   loadQueue.io.ncOut\
      \               <> io.ncOut\n211:   loadQueue.io.rob                 <> io.rob\n\
      212:   loadQueue.io.nuke_rollback       <> io.nuke_rollback\n213:   loadQueue.io.nack_rollback\
      \       <> io.nack_rollback\n214:   loadQueue.io.replay              <> io.replay\n\
      215:  // loadQueue.io.refill              <> io.refill\n216:   loadQueue.io.tl_d_channel\
      \        <> io.tl_d_channel\n217:   loadQueue.io.release             <> io.release\n\
      218:   loadQueue.io.exceptionAddr.isStore := DontCare\n219:   loadQueue.io.loadMisalignFull\
      \    := io.loadMisalignFull"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 257-267
    context: "257:     loadQueue.io.uncache.req.bits.robIdx < storeQueue.io.uncache.req.bits.robIdx\n\
      258:   )\n259: \n260:   switch(pendingstate){\n261:     is(s_idle){\n262:  \
      \     when(io.uncache.req.fire){\n263:         pendingstate :=\n264:       \
      \    Mux(io.uncacheOutstanding && io.uncache.req.bits.nc, s_idle,\n265:    \
      \       Mux(selectLq, s_load,\n266:           s_store))\n267:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 265-280
    context: "265:           Mux(selectLq, s_load,\n266:           s_store))\n267:\
      \       }\n268:     }\n269:     is(s_load){\n270:       when(io.uncache.resp.fire){\n\
      271:         pendingstate := s_idle\n272:       }\n273:     }\n274:     is(s_store){\n\
      275:       when(io.uncache.resp.fire){\n276:         pendingstate := s_idle\n\
      277:       }\n278:     }\n279:   }\n280: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 278-289
    context: "278:     }\n279:   }\n280: \n281:   loadQueue.io.uncache := DontCare\n\
      282:   storeQueue.io.uncache := DontCare\n283:   loadQueue.io.uncache.req.ready
      := false.B\n284:   storeQueue.io.uncache.req.ready := false.B\n285:   loadQueue.io.uncache.resp.valid
      := false.B\n286:   loadQueue.io.uncache.idResp.valid := false.B\n287:   storeQueue.io.uncache.resp.valid
      := false.B\n288:   storeQueue.io.uncache.idResp.valid := false.B\n289:   when(pendingstate
      === s_idle){"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 322-332
    context: "322: }\n323: \n324: class LsqEnqCtrl(implicit p: Parameters) extends
      XSModule\n325:   with HasVLSUParameters  {\n326:   val io = IO(new Bundle {\n\
      327:     val redirect = Flipped(ValidIO(new Redirect))\n328:     // to dispatch\n\
      329:     val enq = new LsqEnqIO\n330:     // from `memBlock.io.lqDeq\n331: \
      \    val lcommit = Input(UInt(log2Up(CommitWidth + 1).W))\n332:     // from
      `memBlock.io.sqDeq`"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 363-375
    context: "363:   io.lqFreeCount  := lqCounter\n364:   io.sqFreeCount  := sqCounter\n\
      365:   // How to update ptr and counter:\n366:   // (1) by default, updated
      according to enq/commit\n367:   // (2) when redirect and dispatch queue is empty,
      update according to lsq\n368:   val t1_redirect = RegNext(io.redirect.valid)\n\
      369:   val t2_redirect = RegNext(t1_redirect)\n370:   val t2_update = t2_redirect
      && !VecInit(io.enq.needAlloc.map(_.orR)).asUInt.orR\n371:   val t3_update =
      RegNext(t2_update)\n372:   val t3_lqCancelCnt = GatedRegNext(io.lqCancelCnt)\n\
      373:   val t3_sqCancelCnt = GatedRegNext(io.sqCancelCnt)\n374:   when (t3_update)
      {\n375:     lqPtr := lqPtr - t3_lqCancelCnt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 374-384
    context: "374:   when (t3_update) {\n375:     lqPtr := lqPtr - t3_lqCancelCnt\n\
      376:     lqCounter := lqCounter + io.lcommit + t3_lqCancelCnt\n377:     sqPtr
      := sqPtr - t3_sqCancelCnt\n378:     sqCounter := sqCounter + io.scommit + t3_sqCancelCnt\n\
      379:   }.elsewhen (!io.redirect.valid && io.enq.canAccept) {\n380:     lqPtr
      := lqPtr + lqAllocNumber\n381:     lqCounter := lqCounter + io.lcommit - lqAllocNumber\n\
      382:     sqPtr := sqPtr + sqAllocNumber\n383:     sqCounter := sqCounter + io.scommit
      - sqAllocNumber\n384:   }.otherwise {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 407-418
    context: "407:     resp.sqIdx := sqPtr + sqOffset(i)\n408:   }\n409: \n410:  \
      \ io.enqLsq.needAlloc := RegNext(io.enq.needAlloc)\n411:   io.enqLsq.iqAccept
      := RegNext(io.enq.iqAccept)\n412:   io.enqLsq.req.zip(io.enq.req).zip(io.enq.resp).foreach{
      case ((toLsq, enq), resp) =>\n413:     val do_enq = enq.valid && !io.redirect.valid
      && io.enq.canAccept\n414:     toLsq.valid := RegNext(do_enq)\n415:     toLsq.bits
      := RegEnable(enq.bits, do_enq)\n416:     toLsq.bits.lqIdx := RegEnable(resp.lqIdx,
      do_enq)\n417:     toLsq.bits.sqIdx := RegEnable(resp.sqIdx, do_enq)\n418:  \
      \ }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 37-48
    context: "37:   with HasLoadHelper\n38:   with HasPerfEvents\n39:   with HasVLSUParameters
      {\n40:   val io = IO(new Bundle() {\n41:     // control\n42:     val redirect\
      \    = Flipped(Valid(new Redirect))\n43:     val vecCommit   = Vec(VecLoadPipelineWidth,
      Flipped(ValidIO(new FeedbackToLsqIO)))\n44:     // from dispatch\n45:     val
      enq         = new LqEnqIO\n46:     // from ldu s3\n47:     val ldin        =
      Vec(LoadPipelineWidth, Flipped(DecoupledIO(new LqWriteBundle)))\n48:     //
      to LoadQueueReplay and LoadQueueRAR"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 67-83
    context: "67:   //  Flags       : load flags\n68:   val allocated = RegInit(VecInit(List.fill(VirtualLoadQueueSize)(false.B)))
      // The control signals need to explicitly indicate the initial value\n69:  \
      \ val robIdx = Reg(Vec(VirtualLoadQueueSize, new RobPtr))\n70:   val uopIdx
      = Reg(Vec(VirtualLoadQueueSize, UopIdx()))\n71:   val isvec = RegInit(VecInit(List.fill(VirtualLoadQueueSize)(false.B)))
      // vector load flow\n72:   val committed = Reg(Vec(VirtualLoadQueueSize, Bool()))\n\
      73: \n74:   /**\n75:    * used for debug\n76:    */\n77:   val debug_mmio =
      Reg(Vec(VirtualLoadQueueSize, Bool())) // mmio: inst is an mmio inst\n78:  \
      \ val debug_paddr = Reg(Vec(VirtualLoadQueueSize, UInt(PAddrBits.W))) // mmio:
      inst's paddr\n79: \n80:   //  maintain pointers\n81:   val enqPtrExt = RegInit(VecInit((0
      until io.enq.req.length).map(_.U.asTypeOf(new LqPtr))))\n82:   val enqPtr =
      enqPtrExt(0).value\n83:   val deqPtr = Wire(new LqPtr)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 84-94
    context: "84:   val deqPtrNext = Wire(new LqPtr)\n85: \n86:   /**\n87:    * update
      pointer\n88:    */\n89:   val lastCycleRedirect = RegNext(io.redirect)\n90:\
      \   val lastLastCycleRedirect = RegNext(lastCycleRedirect)\n91: \n92:   val
      validCount = distanceBetween(enqPtrExt(0), deqPtr)\n93:   val allowEnqueue =
      validCount <= (VirtualLoadQueueSize - LSQLdEnqWidth).U\n94:   val canEnqueue
      = io.enq.req.map(_.valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 92-106
    context: "92:   val validCount = distanceBetween(enqPtrExt(0), deqPtr)\n93:  \
      \ val allowEnqueue = validCount <= (VirtualLoadQueueSize - LSQLdEnqWidth).U\n\
      94:   val canEnqueue = io.enq.req.map(_.valid)\n95:   val vLoadFlow = io.enq.req.map(_.bits.numLsElem.asTypeOf(UInt(elemIdxBits.W)))\n\
      96:   val needCancel = WireInit(VecInit((0 until VirtualLoadQueueSize).map(i
      => {\n97:     robIdx(i).needFlush(io.redirect) && allocated(i)\n98:   })))\n\
      99:   val lastNeedCancel = GatedValidRegNext(needCancel)\n100:   val enqCancel
      = canEnqueue.zip(io.enq.req).map{case (v , x) =>\n101:     v && x.bits.robIdx.needFlush(io.redirect)\n\
      102:   }\n103:   val enqCancelNum = enqCancel.zip(vLoadFlow).map{case (v, flow)
      =>\n104:     Mux(v, flow, 0.U)\n105:   }\n106:   val lastEnqCancel = GatedRegNext(enqCancelNum.reduce(_
      + _))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 121-131
    context: "121:   } .otherwise {\n122:     enqPtrExtNextVec := VecInit(enqPtrExt.map(_
      + enqNumber))\n123:   }\n124:   assert(!(lastCycleRedirect.valid && enqNumber
      =/= 0.U))\n125: \n126:   when (isAfter(enqPtrExtNextVec(0), deqPtrNext)) {\n\
      127:     enqPtrExtNext := enqPtrExtNextVec\n128:   } .otherwise {\n129:    \
      \ enqPtrExtNext := VecInit((0 until io.enq.req.length).map(i => deqPtrNext +
      i.U))\n130:   }\n131:   enqPtrExt := enqPtrExtNext"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 132-142
    context: "132: \n133:   // update dequeue pointer\n134:   val DeqPtrMoveStride
      = CommitWidth\n135:   require(DeqPtrMoveStride == CommitWidth, \"DeqPtrMoveStride
      must be equal to CommitWidth!\")\n136:   val deqLookupVec = VecInit((0 until
      DeqPtrMoveStride).map(deqPtr + _.U))\n137:   val deqLookup = VecInit(deqLookupVec.map(ptr
      => allocated(ptr.value) && committed(ptr.value) && ptr =/= enqPtrExt(0)))\n\
      138:   val deqInSameRedirectCycle = VecInit(deqLookupVec.map(ptr => needCancel(ptr.value)))\n\
      139:   // make chisel happy\n140:   val deqCountMask = Wire(UInt(DeqPtrMoveStride.W))\n\
      141:   deqCountMask := deqLookup.asUInt & (~deqInSameRedirectCycle.asUInt).asUInt\n\
      142:   val commitCount = PopCount(PriorityEncoderOH(~deqCountMask) - 1.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 179-189
    context: "179:     when (entryCanEnq) {\n180:       allocated(i) := true.B\n181:\
      \       robIdx(i) := selectBits.robIdx\n182:       uopIdx(i) := selectBits.uopIdx\n\
      183:       isvec(i) :=  FuType.isVLoad(selectBits.fuType)\n184:       committed(i)
      := false.B\n185: \n186:       debug_mmio(i) := false.B\n187:       debug_paddr(i)
      := 0.U\n188:     }\n189:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 203-213
    context: "203:     */\n204:   (0 until DeqPtrMoveStride).map(i => {\n205:    \
      \ when (commitCount > i.U) {\n206:       allocated((deqPtr+i.U).value) := false.B\n\
      207:     }\n208:     XSError(commitCount > i.U && !allocated((deqPtr+i.U).value),
      s\"why commit invalid entry $i?\\n\")\n209:   })\n210: \n211:   // vector commit
      or replay\n212:   val vecLdCommittmp = Wire(Vec(VirtualLoadQueueSize, Vec(VecLoadPipelineWidth,
      Bool())))\n213:   val vecLdCommit = Wire(Vec(VirtualLoadQueueSize, Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 210-220
    context: "210: \n211:   // vector commit or replay\n212:   val vecLdCommittmp
      = Wire(Vec(VirtualLoadQueueSize, Vec(VecLoadPipelineWidth, Bool())))\n213: \
      \  val vecLdCommit = Wire(Vec(VirtualLoadQueueSize, Bool()))\n214:   for (i
      <- 0 until VirtualLoadQueueSize) {\n215:     val cmt = io.vecCommit\n216:  \
      \   for (j <- 0 until VecLoadPipelineWidth) {\n217:       vecLdCommittmp(i)(j)
      := allocated(i) && cmt(j).valid && robIdx(i) === cmt(j).bits.robidx && uopIdx(i)
      === cmt(j).bits.uopidx\n218:     }\n219:     vecLdCommit(i) := vecLdCommittmp(i).reduce(_
      || _)\n220: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 217-227
    context: "217:       vecLdCommittmp(i)(j) := allocated(i) && cmt(j).valid && robIdx(i)
      === cmt(j).bits.robidx && uopIdx(i) === cmt(j).bits.uopidx\n218:     }\n219:\
      \     vecLdCommit(i) := vecLdCommittmp(i).reduce(_ || _)\n220: \n221:     when
      (vecLdCommit(i) && isvec(i)) {\n222:       committed(i) := true.B\n223:    \
      \ }\n224:   }\n225: \n226:   // misprediction recovery / exception redirect\n\
      227:   // invalidate lq term using robIdx"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 229-239
    context: "229:     when (needCancel(i)) {\n230:       allocated(i) := false.B\n\
      231:     }\n232:   }\n233: \n234:   XSDebug(p\"(ready, valid): ${io.enq.canAccept},
      ${Binary(Cat(io.enq.req.map(_.valid)))}\\n\")\n235: \n236:   /**\n237:     *
      Writeback load from load units\n238:     *\n239:     * Most load instructions
      writeback to regfile at the same time."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 241-251
    context: "241:     *   (1) For ready load instruction (no need replay), it writes
      back to ROB immediately.\n242:     */\n243:   for(i <- 0 until LoadPipelineWidth)
      {\n244:     //   most lq status need to be updated immediately after load writeback
      to lq\n245:     //   flag bits in lq needs to be updated accurately\n246:  \
      \   io.ldin(i).ready := true.B\n247:     val loadWbIndex = io.ldin(i).bits.uop.lqIdx.value\n\
      248: \n249:     val need_rep = io.ldin(i).bits.rep_info.need_rep\n250:     val
      need_valid = io.ldin(i).bits.updateAddrValid\n251:     when (io.ldin(i).valid)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 249-266
    context: "249:     val need_rep = io.ldin(i).bits.rep_info.need_rep\n250:    \
      \ val need_valid = io.ldin(i).bits.updateAddrValid\n251:     when (io.ldin(i).valid)
      {\n252:       val hasExceptions = ExceptionNO.selectByFu(io.ldin(i).bits.uop.exceptionVec,
      LduCfg).asUInt.orR\n253:       when (!need_rep && need_valid && !io.ldin(i).bits.isvec)
      {\n254:         committed(loadWbIndex) := true.B\n255:         //  Debug info\n\
      256:         debug_mmio(loadWbIndex) := io.ldin(i).bits.mmio\n257:         debug_paddr(loadWbIndex)
      := io.ldin(i).bits.paddr\n258:       }\n259:     }\n260:     XSInfo(io.ldin(i).valid
      && !need_rep && need_valid,\n261:       \"load hit write to lq idx %d pc 0x%x
      vaddr %x paddr %x mask %x forwardData %x forwardMask: %x mmio %x isvec %x\\\
      n\",\n262:       io.ldin(i).bits.uop.lqIdx.asUInt,\n263:       io.ldin(i).bits.uop.pc,\n\
      264:       io.ldin(i).bits.vaddr,\n265:       io.ldin(i).bits.paddr,\n266: \
      \      io.ldin(i).bits.mask,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 264-274
    context: "264:       io.ldin(i).bits.vaddr,\n265:       io.ldin(i).bits.paddr,\n\
      266:       io.ldin(i).bits.mask,\n267:       io.ldin(i).bits.forwardData.asUInt,\n\
      268:       io.ldin(i).bits.forwardMask.asUInt,\n269:       io.ldin(i).bits.mmio,\n\
      270:       io.ldin(i).bits.isvec\n271:     )\n272:   }\n273: \n274:   //  perf
      counter"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 298-308
    context: "298:     XSDebug(false, !flag, \" \") // otherwise\n299:   }\n300: \n\
      301:   for (i <- 0 until VirtualLoadQueueSize) {\n302:     PrintFlag(allocated(i),
      \"a\")\n303:     PrintFlag(allocated(i) && committed(i), \"c\")\n304:     PrintFlag(allocated(i)
      && isvec(i), \"v\")\n305:     XSDebug(false, true.B, \"\\n\")\n306:   }\n307:\
      \   // end\n308: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadExceptionBuffer.scala
    lines: 31-44
    context: "31: import xiangshan.mem.Bundles._\n32: import xiangshan.cache._\n33:
      import xiangshan.cache.wpu.ReplayCarry\n34: \n35: class LqExceptionBuffer(implicit
      p: Parameters) extends XSModule with HasCircularQueuePtrHelper {\n36:   val
      enqPortNum = LoadPipelineWidth + VecLoadPipelineWidth + 1 // 1 for mmio bus
      non-data error\n37: \n38:   val io = IO(new Bundle() {\n39:     val redirect\
      \      = Flipped(Valid(new Redirect))\n40:     val req           = Vec(enqPortNum,
      Flipped(Valid(new LqWriteBundle)))\n41:     val exceptionAddr = new ExceptionAddrIO\n\
      42:   })\n43: \n44:   val req_valid = RegInit(false.B)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadExceptionBuffer.scala
    lines: 45-63
    context: "45:   val req = Reg(new LqWriteBundle)\n46: \n47:   // enqueue\n48:\
      \   // s1:\n49:   val s1_req = VecInit(io.req.map(_.bits))\n50:   val s1_valid
      = VecInit(io.req.map(x => x.valid))\n51: \n52:   // s2: delay 1 cycle\n53: \
      \  val s2_req = (0 until enqPortNum).map(i => {\n54:     RegEnable(s1_req(i),
      s1_valid(i))})\n55:   val s2_valid = (0 until enqPortNum).map(i =>\n56:    \
      \ RegNext(s1_valid(i)) &&\n57:     !s2_req(i).uop.robIdx.needFlush(RegNext(io.redirect))
      &&\n58:     !s2_req(i).uop.robIdx.needFlush(io.redirect)\n59:   )\n60:   val
      s2_has_exception = s2_req.map(x => ExceptionNO.selectByFu(x.uop.exceptionVec,
      LduCfg).asUInt.orR)\n61: \n62:   val s2_enqueue = Wire(Vec(enqPortNum, Bool()))\n\
      63:   for (w <- 0 until enqPortNum) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadExceptionBuffer.scala
    lines: 59-72
    context: "59:   )\n60:   val s2_has_exception = s2_req.map(x => ExceptionNO.selectByFu(x.uop.exceptionVec,
      LduCfg).asUInt.orR)\n61: \n62:   val s2_enqueue = Wire(Vec(enqPortNum, Bool()))\n\
      63:   for (w <- 0 until enqPortNum) {\n64:     s2_enqueue(w) := s2_valid(w)
      && s2_has_exception(w)\n65:   }\n66: \n67:   when (req_valid && req.uop.robIdx.needFlush(io.redirect))
      {\n68:     req_valid := s2_enqueue.asUInt.orR\n69:   } .elsewhen (s2_enqueue.asUInt.orR)
      {\n70:     req_valid := true.B\n71:   }\n72: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadExceptionBuffer.scala
    lines: 79-89
    context: "79:       for (i <- res.indices) {\n80:         res(i).valid := valid(i)\n\
      81:         res(i).bits := bits(i)\n82:       }\n83:       val oldest = Mux(valid(0)
      && valid(1),\n84:         Mux(isAfter(bits(0).uop.robIdx, bits(1).uop.robIdx)
      ||\n85:           (bits(0).uop.robIdx === bits(1).uop.robIdx && bits(0).uop.uopIdx
      > bits(1).uop.uopIdx), res(1), res(0)),\n86:         Mux(valid(0) && !valid(1),
      res(0), res(1)))\n87:       (Seq(oldest.valid), Seq(oldest.bits))\n88:     }
      else {\n89:       val left = selectOldest(valid.take(valid.length / 2), bits.take(bits.length
      / 2))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadExceptionBuffer.scala
    lines: 94-104
    context: "94: \n95:   val reqSel = selectOldest(s2_enqueue, s2_req)\n96: \n97:\
      \   when (req_valid) {\n98:     req := Mux(\n99:       reqSel._1(0) && (isAfter(req.uop.robIdx,
      reqSel._2(0).uop.robIdx) || (req.uop.robIdx === reqSel._2(0).uop.robIdx && req.uop.uopIdx
      > reqSel._2(0).uop.uopIdx)),\n100:       reqSel._2(0),\n101:       req)\n102:\
      \   } .elsewhen (s2_enqueue.asUInt.orR) {\n103:     req := reqSel._2(0)\n104:\
      \   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 76-86
    context: "76:   // The following VecStorePipelineWidth ports: vector st exception\n\
      77:   // The last port: non-data error generated in SoC\n78:   val enqPortNum
      = StorePipelineWidth * 2 + VecStorePipelineWidth + 1\n79: \n80:   val io = IO(new
      Bundle() {\n81:     val redirect = Flipped(ValidIO(new Redirect))\n82:     val
      storeAddrIn = Vec(enqPortNum, Flipped(ValidIO(new LsPipelineBundle())))\n83:\
      \     val exceptionAddr = new ExceptionAddrIO\n84:   })\n85: \n86:   val req_valid
      = RegInit(false.B)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 87-113
    context: "87:   val req = Reg(new LsPipelineBundle())\n88: \n89:   // enqueue\n\
      90:   // S1:\n91:   val s1_req = VecInit(io.storeAddrIn.map(_.bits))\n92:  \
      \ val s1_valid = VecInit(io.storeAddrIn.map(x =>\n93:       x.valid && !x.bits.uop.robIdx.needFlush(io.redirect)
      && ExceptionNO.selectByFu(x.bits.uop.exceptionVec, StaCfg).asUInt.orR\n94: \
      \  ))\n95: \n96:   // S2: delay 1 cycle\n97:   val s2_req = (0 until enqPortNum).map(i
      =>\n98:     RegEnable(s1_req(i), s1_valid(i)))\n99:   val s2_valid = (0 until
      enqPortNum).map(i =>\n100:     RegNext(s1_valid(i)) && !s2_req(i).uop.robIdx.needFlush(io.redirect)\n\
      101:   )\n102: \n103:   val s2_enqueue = Wire(Vec(enqPortNum, Bool()))\n104:\
      \   for (w <- 0 until enqPortNum) {\n105:     s2_enqueue(w) := s2_valid(w)\n\
      106:   }\n107: \n108:   when (req_valid && req.uop.robIdx.needFlush(io.redirect))
      {\n109:     req_valid := s2_enqueue.asUInt.orR\n110:   }.elsewhen (s2_enqueue.asUInt.orR)
      {\n111:     req_valid := true.B\n112:   }\n113: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 120-130
    context: "120:       for (i <- res.indices) {\n121:         res(i).valid := valid(i)\n\
      122:         res(i).bits := bits(i)\n123:       }\n124:       val oldest = Mux(valid(0)
      && valid(1),\n125:         Mux(isAfter(bits(0).uop.robIdx, bits(1).uop.robIdx)
      ||\n126:           (bits(0).uop.robIdx === bits(1).uop.robIdx && bits(0).uop.uopIdx
      > bits(1).uop.uopIdx), res(1), res(0)),\n127:         Mux(valid(0) && !valid(1),
      res(0), res(1)))\n128:       (Seq(oldest.valid), Seq(oldest.bits))\n129:   \
      \  } else {\n130:       val left = selectOldest(valid.take(valid.length / 2),
      bits.take(bits.length / 2))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 135-145
    context: "135: \n136:   val reqSel = selectOldest(s2_enqueue, s2_req)\n137: \n\
      138:   when (req_valid) {\n139:     req := Mux(\n140:       reqSel._1(0) &&
      (isAfter(req.uop.robIdx, reqSel._2(0).uop.robIdx) || (isNotBefore(req.uop.robIdx,
      reqSel._2(0).uop.robIdx) && req.uop.uopIdx > reqSel._2(0).uop.uopIdx)),\n141:\
      \       reqSel._2(0),\n142:       req)\n143:   } .elsewhen (s2_enqueue.asUInt.orR)
      {\n144:     req := reqSel._2(0)\n145:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 165-188
    context: "165:   with HasPerfEvents\n166:   with HasVLSUParameters {\n167:   val
      io = IO(new Bundle() {\n168:     val hartId = Input(UInt(hartIdLen.W))\n169:\
      \     val enq = new SqEnqIO\n170:     val brqRedirect = Flipped(ValidIO(new
      Redirect))\n171:     val vecFeedback = Vec(VecLoadPipelineWidth, Flipped(ValidIO(new
      FeedbackToLsqIO)))\n172:     val storeAddrIn = Vec(StorePipelineWidth, Flipped(Valid(new
      LsPipelineBundle))) // store addr, data is not included\n173:     val storeAddrInRe
      = Vec(StorePipelineWidth, Input(new LsPipelineBundle())) // store more mmio
      and exception\n174:     val storeDataIn = Vec(StorePipelineWidth, Flipped(Valid(new
      MemExuOutput(isVector = true)))) // store data, send to sq from rs\n175:   \
      \  val storeMaskIn = Vec(StorePipelineWidth, Flipped(Valid(new StoreMaskBundle)))
      // store mask, send to sq from rs\n176:     val sbuffer = Vec(EnsbufferWidth,
      Decoupled(new DCacheWordReqWithVaddrAndPfFlag)) // write committed store to
      sbuffer\n177:     val uncacheOutstanding = Input(Bool())\n178:     val cmoOpReq\
      \  = DecoupledIO(new CMOReq)\n179:     val cmoOpResp = Flipped(DecoupledIO(new
      CMOResp))\n180:     val cboZeroStout = DecoupledIO(new MemExuOutput)\n181: \
      \    val mmioStout = DecoupledIO(new MemExuOutput) // writeback uncached store\n\
      182:     val vecmmioStout = DecoupledIO(new MemExuOutput(isVector = true))\n\
      183:     val forward = Vec(LoadPipelineWidth, Flipped(new PipeLoadForwardQueryIO))\n\
      184:     // TODO: scommit is only for scalar store\n185:     val rob = Flipped(new
      RobLsqIO)\n186:     val uncache = new UncacheWordIO\n187:     // val refill
      = Flipped(Valid(new DCacheLineReq ))\n188:     val exceptionAddr = new ExceptionAddrIO"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 208-218
    context: "208:   // data modules\n209:   val uop = Reg(Vec(StoreQueueSize, new
      DynInst))\n210:   // val data = Reg(Vec(StoreQueueSize, new LsqEntry))\n211:\
      \   val dataModule = Module(new SQDataModule(\n212:     numEntries = StoreQueueSize,\n\
      213:     numRead = EnsbufferWidth,\n214:     numWrite = StorePipelineWidth,\n\
      215:     numForward = LoadPipelineWidth\n216:   ))\n217:   dataModule.io :=
      DontCare\n218:   val paddrModule = Module(new SQAddrModule("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 216-226
    context: "216:   ))\n217:   dataModule.io := DontCare\n218:   val paddrModule
      = Module(new SQAddrModule(\n219:     dataWidth = PAddrBits,\n220:     numEntries
      = StoreQueueSize,\n221:     numRead = EnsbufferWidth,\n222:     numWrite = StorePipelineWidth,\n\
      223:     numForward = LoadPipelineWidth\n224:   ))\n225:   paddrModule.io :=
      DontCare\n226:   val vaddrModule = Module(new SQAddrModule("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 224-234
    context: "224:   ))\n225:   paddrModule.io := DontCare\n226:   val vaddrModule
      = Module(new SQAddrModule(\n227:     dataWidth = VAddrBits,\n228:     numEntries
      = StoreQueueSize,\n229:     numRead = EnsbufferWidth, // sbuffer; badvaddr will
      be sent from exceptionBuffer\n230:     numWrite = StorePipelineWidth,\n231:\
      \     numForward = LoadPipelineWidth\n232:   ))\n233:   vaddrModule.io := DontCare\n\
      234:   val dataBuffer = Module(new DatamoduleResultBuffer(new DataBufferEntry))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 231-245
    context: "231:     numForward = LoadPipelineWidth\n232:   ))\n233:   vaddrModule.io
      := DontCare\n234:   val dataBuffer = Module(new DatamoduleResultBuffer(new DataBufferEntry))\n\
      235:   val exceptionBuffer = Module(new StoreExceptionBuffer)\n236:   exceptionBuffer.io.redirect
      := io.brqRedirect\n237:   exceptionBuffer.io.exceptionAddr.isStore := DontCare\n\
      238:   // vlsu exception!\n239:   for (i <- 0 until VecStorePipelineWidth) {\n\
      240:     exceptionBuffer.io.storeAddrIn(StorePipelineWidth * 2 + i).valid  \
      \             := io.vecFeedback(i).valid && io.vecFeedback(i).bits.feedback(VecFeedbacks.FLUSH)
      // have exception\n241:     exceptionBuffer.io.storeAddrIn(StorePipelineWidth
      * 2 + i).bits                := DontCare\n242:     exceptionBuffer.io.storeAddrIn(StorePipelineWidth
      * 2 + i).bits.fullva         := io.vecFeedback(i).bits.vaddr\n243:     exceptionBuffer.io.storeAddrIn(StorePipelineWidth
      * 2 + i).bits.vaNeedExt      := io.vecFeedback(i).bits.vaNeedExt\n244:     exceptionBuffer.io.storeAddrIn(StorePipelineWidth
      * 2 + i).bits.gpaddr         := io.vecFeedback(i).bits.gpaddr\n245:     exceptionBuffer.io.storeAddrIn(StorePipelineWidth
      * 2 + i).bits.uop.uopIdx     := io.vecFeedback(i).bits.uopidx"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 259-283
    context: "259: \n260:   // state & misc\n261:   val allocated = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // sq entry has been allocated\n262:   val completed = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))\n\
      263:   val addrvalid = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))\n\
      264:   val datavalid = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))\n\
      265:   val allvalid  = VecInit((0 until StoreQueueSize).map(i => addrvalid(i)
      && datavalid(i)))\n266:   val committed = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // inst has been committed by rob\n267:   val unaligned = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // unaligned store\n268:   val cross16Byte = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // unaligned cross 16Byte boundary\n269:   val pending = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // mmio pending: inst is an mmio inst, it will not be executed until it reachs
      the end of rob\n270:   val nc = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // nc: inst is a nc inst\n271:   val mmio = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // mmio: inst is an mmio inst\n272:   val memBackTypeMM = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))\n\
      273:   val prefetch = RegInit(VecInit(List.fill(StoreQueueSize)(false.B))) //
      need prefetch when committing this store to sbuffer?\n274:   val isVec = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // vector store instruction\n275:   val vecLastFlow = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // last uop the last flow of vector store instruction\n276:   val vecMbCommit
      = RegInit(VecInit(List.fill(StoreQueueSize)(false.B))) // vector store committed
      from merge buffer to rob\n277:   val hasException = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // store has exception, should deq but not write sbuffer\n278:   val waitStoreS2
      = RegInit(VecInit(List.fill(StoreQueueSize)(false.B))) // wait for mmio and
      exception result until store_s2\n279:   // val vec_robCommit = Reg(Vec(StoreQueueSize,
      Bool())) // vector store committed by rob\n280:   // val vec_secondInv = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // Vector unit-stride, second entry is invalid\n281:   val vecExceptionFlag
      = RegInit(0.U.asTypeOf(Valid(new DynInst)))\n282:   val noPending = RegInit(true.B)\n\
      283: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 300-310
    context: "300:   val deqMask = UIntToMask(deqPtr, StoreQueueSize)\n301:   val
      enqMask = UIntToMask(enqPtr, StoreQueueSize)\n302: \n303:   val commitCount
      = WireInit(0.U(log2Ceil(CommitWidth + 1).W))\n304:   val scommit = GatedRegNext(io.rob.scommit)\n\
      305:   val mmioReq = Wire(chiselTypeOf(io.uncache.req))\n306:   val ncWaitRespPtrReg
      = RegInit(0.U(uncacheIdxBits.W)) // it's valid only in non-outstanding situation\n\
      307:   val ncReq = Wire(chiselTypeOf(io.uncache.req))\n308:   val ncResp = Wire(chiselTypeOf(io.uncache.resp))\n\
      309:   val ncDoReq = Wire(Bool())\n310:   val ncSlaveAck = Wire(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 313-323
    context: "313:   val ncReadNextTrigger = Mux(io.uncacheOutstanding, ncSlaveAck,
      ncDoResp)\n314:   val ncDeqTrigger = Mux(io.uncacheOutstanding, ncSlaveAck,
      ncDoResp)\n315:   val ncPtr = Mux(io.uncacheOutstanding, ncSlaveAckMid, ncWaitRespPtrReg)\n\
      316: \n317:   // store can be committed by ROB\n318:   io.rob.mmio := DontCare\n\
      319:   io.rob.uop := DontCare\n320: \n321:   // Read dataModule\n322:   assert(EnsbufferWidth
      <= 2)\n323:   // rdataPtrExtNext and rdataPtrExtNext+1 entry will be read from
      dataModule"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 323-337
    context: "323:   // rdataPtrExtNext and rdataPtrExtNext+1 entry will be read from
      dataModule\n324:   val rdataPtrExtNext = Wire(Vec(EnsbufferWidth, new SqPtr))\n\
      325:   val sqReadCnt = WireInit(0.U(log2Ceil(EnsbufferWidth + 1).W))\n326: \
      \  val readyReadGoVec = WireInit(VecInit((0 until EnsbufferWidth).map(i =>\n\
      327:     if(i == 0) {\n328:       dataBuffer.io.enq(i).fire && dataBuffer.io.enq(i).bits.sqNeedDeq
      ||\n329:       allocated(rdataPtrExt(i).value) && completed(rdataPtrExt(i).value)
      && nc(rdataPtrExt(i).value) ||\n330:       io.mmioStout.fire || io.vecmmioStout.fire\n\
      331:     } else {\n332:       dataBuffer.io.enq(i).fire && dataBuffer.io.enq(i).bits.sqNeedDeq
      ||\n333:       allocated(rdataPtrExt(i).value) && completed(rdataPtrExt(i).value)
      && nc(rdataPtrExt(i).value)\n334:     }\n335:   )))\n336:   for (i <- 0 until
      EnsbufferWidth) {\n337:     when(readyReadGoVec.take(i + 1).reduce(_ && _))
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 355-365
    context: "355:     }\n356:   }\n357:   deqPtrExtNext := deqPtrExt.map(_ + sqDeqCnt)\n\
      358:   io.sqDeq := RegNext(sqDeqCnt)\n359: \n360:   assert(!RegNext(RegNext(io.sbuffer(0).fire)
      && (io.mmioStout.fire || io.vecmmioStout.fire)))\n361: \n362:   for (i <- 0
      until EnsbufferWidth) {\n363:     dataModule.io.raddr(i) := rdataPtrExtNext(i).value\n\
      364:     paddrModule.io.raddr(i) := rdataPtrExtNext(i).value\n365:     vaddrModule.io.raddr(i)
      := rdataPtrExtNext(i).value"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 371-383
    context: "371:     * Currently, StoreQueue only allows enqueue when #emptyEntries
      > EnqWidth\n372:     * Dynamic enq based on numLsElem number\n373:     */\n\
      374:   io.enq.canAccept := allowEnqueue\n375:   val canEnqueue = io.enq.req.map(_.valid)\n\
      376:   val enqCancel = io.enq.req.map(_.bits.robIdx.needFlush(io.brqRedirect))\n\
      377:   val vStoreFlow = io.enq.req.map(_.bits.numLsElem.asTypeOf(UInt(elemIdxBits.W)))\n\
      378:   val validVStoreFlow = vStoreFlow.zipWithIndex.map{case (vStoreFlowNumItem,
      index) => Mux(!RegNext(io.brqRedirect.valid) && canEnqueue(index), vStoreFlowNumItem,
      0.U)}\n379:   val validVStoreOffset = vStoreFlow.zip(io.enq.needAlloc).map{case
      (flow, needAllocItem) => Mux(needAllocItem, flow, 0.U)}\n380:   val validVStoreOffsetRShift
      = 0.U +: validVStoreOffset.take(vStoreFlow.length - 1)\n381: \n382:   val enqLowBound
      = io.enq.req.map(_.bits.sqIdx)\n383:   val enqUpBound  = io.enq.req.map(x =>
      x.bits.sqIdx + x.bits.numLsElem)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 401-419
    context: "401:       if (i + 1 == StoreQueueSize)\n402:         vecLastFlow(i)
      := Mux(0.U === selectUpBound.value, selectBits.lastUop, false.B) else\n403:\
      \         vecLastFlow(i) := Mux((i + 1).U === selectUpBound.value, selectBits.lastUop,
      false.B)\n404:       allocated(i) := true.B\n405:       completed(i) := false.B\n\
      406:       datavalid(i) := false.B\n407:       addrvalid(i) := false.B\n408:\
      \       unaligned(i) := false.B\n409:       cross16Byte(i) := false.B\n410:\
      \       committed(i) := false.B\n411:       pending(i) := false.B\n412:    \
      \   prefetch(i) := false.B\n413:       nc(i) := false.B\n414:       mmio(i)
      := false.B\n415:       isVec(i) :=  FuType.isVStore(selectBits.fuType)\n416:\
      \       vecMbCommit(i) := false.B\n417:       hasException(i) := false.B\n418:\
      \       waitStoreS2(i) := true.B\n419:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 424-434
    context: "424:     val index = io.enq.req(i).bits.sqIdx\n425:     XSError(canEnqueue(i)
      && !enqCancel(i) && (!io.enq.canAccept || !io.enq.lqCanAccept), s\"must accept
      $i\\n\")\n426:     XSError(canEnqueue(i) && !enqCancel(i) && index.value =/=
      sqIdx.value, s\"must be the same entry $i\\n\")\n427:     io.enq.resp(i) :=
      sqIdx\n428:   }\n429:   XSDebug(p\"(ready, valid): ${io.enq.canAccept}, ${Binary(Cat(io.enq.req.map(_.valid)))}\\\
      n\")\n430: \n431:   /**\n432:     * Update addr/dataReadyPtr when issue from
      rs\n433:     */\n434:   // update issuePtr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 435-445
    context: "435:   val IssuePtrMoveStride = 4\n436:   require(IssuePtrMoveStride
      >= 2)\n437: \n438:   val addrReadyLookupVec = (0 until IssuePtrMoveStride).map(addrReadyPtrExt
      + _.U)\n439:   val addrReadyLookup = addrReadyLookupVec.map(ptr => allocated(ptr.value)
      &&\n440:    (mmio(ptr.value) || addrvalid(ptr.value) || vecMbCommit(ptr.value))\n\
      441:     && ptr =/= enqPtrExt(0))\n442:   val nextAddrReadyPtr = addrReadyPtrExt
      + PriorityEncoder(VecInit(addrReadyLookup.map(!_) :+ true.B))\n443:   addrReadyPtrExt
      := nextAddrReadyPtr\n444: \n445:   val stAddrReadyVecReg = Wire(Vec(StoreQueueSize,
      Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 442-460
    context: "442:   val nextAddrReadyPtr = addrReadyPtrExt + PriorityEncoder(VecInit(addrReadyLookup.map(!_)
      :+ true.B))\n443:   addrReadyPtrExt := nextAddrReadyPtr\n444: \n445:   val stAddrReadyVecReg
      = Wire(Vec(StoreQueueSize, Bool()))\n446:   (0 until StoreQueueSize).map(i =>
      {\n447:     stAddrReadyVecReg(i) := allocated(i) && (mmio(i) || addrvalid(i)
      || (isVec(i) && vecMbCommit(i)))\n448:   })\n449:   io.stAddrReadyVec := GatedValidRegNext(stAddrReadyVecReg)\n\
      450: \n451:   when (io.brqRedirect.valid) {\n452:     addrReadyPtrExt := Mux(\n\
      453:       isAfter(cmtPtrExt(0), deqPtrExt(0)),\n454:       cmtPtrExt(0),\n\
      455:       deqPtrExtNext(0) // for mmio insts, deqPtr may be ahead of cmtPtr\n\
      456:     )\n457:   }\n458: \n459:   io.stAddrReadySqPtr := addrReadyPtrExt\n\
      460: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 460-470
    context: "460: \n461:   // update\n462:   val dataReadyLookupVec = (0 until IssuePtrMoveStride).map(dataReadyPtrExt
      + _.U)\n463:   val dataReadyLookup = dataReadyLookupVec.map(ptr =>\n464:   \
      \  allocated(ptr.value) &&\n465:     (addrvalid(ptr.value) && (mmio(ptr.value)
      || datavalid(ptr.value)) || vecMbCommit(ptr.value)) &&\n466:     !unaligned(ptr.value)
      &&\n467:     ptr =/= enqPtrExt(0)\n468:   )\n469:   val nextDataReadyPtr = dataReadyPtrExt
      + PriorityEncoder(VecInit(dataReadyLookup.map(!_) :+ true.B))\n470:   dataReadyPtrExt
      := nextDataReadyPtr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 481-499
    context: "481:   }\n482: \n483:   val stDataReadyVecReg = Wire(Vec(StoreQueueSize,
      Bool()))\n484:   (0 until StoreQueueSize).map(i => {\n485:     stDataReadyVecReg(i)
      := allocated(i) &&\n486:       (addrvalid(i) && (mmio(i) || datavalid(i)) ||
      (isVec(i) && vecMbCommit(i))) && !unaligned(i)\n487:   })\n488:   io.stDataReadyVec
      := GatedValidRegNext(stDataReadyVecReg)\n489: \n490:   when (io.brqRedirect.valid)
      {\n491:     dataReadyPtrExt := Mux(\n492:       isAfter(cmtPtrExt(0), deqPtrExt(0)),\n\
      493:       cmtPtrExt(0),\n494:       deqPtrExtNext(0) // for mmio insts, deqPtr
      may be ahead of cmtPtr\n495:     )\n496:   }\n497: \n498:   io.stDataReadySqPtr
      := dataReadyPtrExt\n499:   io.stIssuePtr := enqPtrExt(0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 517-527
    context: "517:   for (i <- 0 until StorePipelineWidth) {\n518:     paddrModule.io.wen(i)
      := false.B\n519:     vaddrModule.io.wen(i) := false.B\n520:     dataModule.io.mask.wen(i)
      := false.B\n521:     val stWbIndex = io.storeAddrIn(i).bits.uop.sqIdx.value\n\
      522:     exceptionBuffer.io.storeAddrIn(i).valid := io.storeAddrIn(i).fire &&
      !io.storeAddrIn(i).bits.miss && !io.storeAddrIn(i).bits.isvec\n523:     exceptionBuffer.io.storeAddrIn(i).bits
      := io.storeAddrIn(i).bits\n524:     // will re-enter exceptionbuffer at store_s2\n\
      525:     exceptionBuffer.io.storeAddrIn(StorePipelineWidth + i).valid := false.B\n\
      526:     exceptionBuffer.io.storeAddrIn(StorePipelineWidth + i).bits := 0.U.asTypeOf(new
      LsPipelineBundle)\n527: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 523-539
    context: "523:     exceptionBuffer.io.storeAddrIn(i).bits := io.storeAddrIn(i).bits\n\
      524:     // will re-enter exceptionbuffer at store_s2\n525:     exceptionBuffer.io.storeAddrIn(StorePipelineWidth
      + i).valid := false.B\n526:     exceptionBuffer.io.storeAddrIn(StorePipelineWidth
      + i).bits := 0.U.asTypeOf(new LsPipelineBundle)\n527: \n528:     when (io.storeAddrIn(i).fire
      && io.storeAddrIn(i).bits.updateAddrValid) {\n529:       val addr_valid = !io.storeAddrIn(i).bits.miss\n\
      530:       addrvalid(stWbIndex) := addr_valid //!io.storeAddrIn(i).bits.mmio\n\
      531:       nc(stWbIndex) := io.storeAddrIn(i).bits.nc\n532: \n533:     }\n534:\
      \     when (io.storeAddrIn(i).fire && !io.storeAddrIn(i).bits.isFrmMisAlignBuf)
      {\n535:       // pending(stWbIndex) := io.storeAddrIn(i).bits.mmio\n536:   \
      \    unaligned(stWbIndex) := io.storeAddrIn(i).bits.isMisalign\n537:       cross16Byte(stWbIndex)
      := io.storeAddrIn(i).bits.isMisalign && !io.storeAddrIn(i).bits.misalignWith16Byte\n\
      538: \n539:       paddrModule.io.waddr(i) := stWbIndex"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 550-566
    context: "550: \n551:       debug_paddr(paddrModule.io.waddr(i)) := paddrModule.io.wdata(i)\n\
      552: \n553:       // mmio(stWbIndex) := io.storeAddrIn(i).bits.mmio\n554:  \
      \   }\n555:     when (io.storeAddrIn(i).fire) {\n556:       uop(stWbIndex) :=
      io.storeAddrIn(i).bits.uop\n557:       uop(stWbIndex).debugInfo := io.storeAddrIn(i).bits.uop.debugInfo\n\
      558:       uop(stWbIndex).debug_seqNum := io.storeAddrIn(i).bits.uop.debug_seqNum\n\
      559:     }\n560:     XSInfo(io.storeAddrIn(i).fire && !io.storeAddrIn(i).bits.isFrmMisAlignBuf,\n\
      561:       \"store addr write to sq idx %d pc 0x%x miss:%d vaddr %x paddr %x
      mmio %x isvec %x\\n\",\n562:       io.storeAddrIn(i).bits.uop.sqIdx.value,\n\
      563:       io.storeAddrIn(i).bits.uop.pc,\n564:       io.storeAddrIn(i).bits.miss,\n\
      565:       io.storeAddrIn(i).bits.vaddr,\n566:       io.storeAddrIn(i).bits.paddr,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 562-582
    context: "562:       io.storeAddrIn(i).bits.uop.sqIdx.value,\n563:       io.storeAddrIn(i).bits.uop.pc,\n\
      564:       io.storeAddrIn(i).bits.miss,\n565:       io.storeAddrIn(i).bits.vaddr,\n\
      566:       io.storeAddrIn(i).bits.paddr,\n567:       io.storeAddrIn(i).bits.mmio,\n\
      568:       io.storeAddrIn(i).bits.isvec\n569:     )\n570: \n571:     // re-replinish
      mmio, for pma/pmp will get mmio one cycle later\n572:     val storeAddrInFireReg
      = RegNext(io.storeAddrIn(i).fire && !io.storeAddrIn(i).bits.miss) && io.storeAddrInRe(i).updateAddrValid\n\
      573:     //val stWbIndexReg = RegNext(stWbIndex)\n574:     val stWbIndexReg
      = RegEnable(stWbIndex, io.storeAddrIn(i).fire)\n575:     when (storeAddrInFireReg)
      {\n576:       pending(stWbIndexReg) := io.storeAddrInRe(i).mmio\n577:      \
      \ mmio(stWbIndexReg) := io.storeAddrInRe(i).mmio\n578:       memBackTypeMM(stWbIndexReg)
      := io.storeAddrInRe(i).memBackTypeMM\n579:       hasException(stWbIndexReg)
      := io.storeAddrInRe(i).hasException\n580:       addrvalid(stWbIndexReg) := addrvalid(stWbIndexReg)
      || io.storeAddrInRe(i).hasException\n581:       waitStoreS2(stWbIndexReg) :=
      false.B\n582:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 580-594
    context: "580:       addrvalid(stWbIndexReg) := addrvalid(stWbIndexReg) || io.storeAddrInRe(i).hasException\n\
      581:       waitStoreS2(stWbIndexReg) := false.B\n582:     }\n583:     // dcache
      miss info (one cycle later than storeIn)\n584:     // if dcache report a miss
      in sta pipeline, this store will trigger a prefetch when committing to sbuffer
      (if EnableAtCommitMissTrigger)\n585:     when (storeAddrInFireReg) {\n586: \
      \      prefetch(stWbIndexReg) := io.storeAddrInRe(i).miss\n587:     }\n588:\
      \     // enter exceptionbuffer again\n589:     when (storeAddrInFireReg) {\n\
      590:       exceptionBuffer.io.storeAddrIn(StorePipelineWidth + i).valid := io.storeAddrInRe(i).hasException
      && !io.storeAddrInRe(i).isvec\n591:       exceptionBuffer.io.storeAddrIn(StorePipelineWidth
      + i).bits := io.storeAddrInRe(i)\n592:       exceptionBuffer.io.storeAddrIn(StorePipelineWidth
      + i).bits.uop.exceptionVec(storeAccessFault) := io.storeAddrInRe(i).af\n593:\
      \     }\n594: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 603-613
    context: "603:     dataModule.io.data.wen(i) := false.B\n604:     val stWbIndex
      = io.storeDataIn(i).bits.uop.sqIdx.value\n605:     val isVec     = FuType.isVStore(io.storeDataIn(i).bits.uop.fuType)\n\
      606:     // sq data write takes 2 cycles:\n607:     // sq data write s0\n608:\
      \     when (io.storeDataIn(i).fire) {\n609:       // send data write req to
      data module\n610:       dataModule.io.data.waddr(i) := stWbIndex\n611:     \
      \  dataModule.io.data.wdata(i) := Mux(io.storeDataIn(i).bits.uop.fuOpType ===
      LSUOpType.cbo_zero,\n612:         0.U,\n613:         Mux(isVec,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 618-628
    context: "618: \n619:       debug_data(dataModule.io.data.waddr(i)) := dataModule.io.data.wdata(i)\n\
      620:       debug_vec_unaligned_start(dataModule.io.data.waddr(i)) := io.storeDataIn(i).bits.vecDebug.get.start\n\
      621:       debug_vec_unaligned_offset(dataModule.io.data.waddr(i)) := io.storeDataIn(i).bits.vecDebug.get.offset\n\
      622:     }\n623:     XSInfo(io.storeDataIn(i).fire,\n624:       \"store data
      write to sq idx %d pc 0x%x data %x -> %x\\n\",\n625:       io.storeDataIn(i).bits.uop.sqIdx.value,\n\
      626:       io.storeDataIn(i).bits.uop.pc,\n627:       io.storeDataIn(i).bits.data,\n\
      628:       dataModule.io.data.wdata(i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 626-641
    context: "626:       io.storeDataIn(i).bits.uop.pc,\n627:       io.storeDataIn(i).bits.data,\n\
      628:       dataModule.io.data.wdata(i)\n629:     )\n630:     // sq data write
      s1\n631:     val lastStWbIndex = RegEnable(stWbIndex, io.storeDataIn(i).fire)\n\
      632:     when (\n633:       RegNext(io.storeDataIn(i).fire) && allocated(lastStWbIndex)\n\
      634:       // && !RegNext(io.storeDataIn(i).bits.uop).robIdx.needFlush(io.brqRedirect)\n\
      635:     ) {\n636:       datavalid(lastStWbIndex) := true.B\n637:     }\n638:\
      \   }\n639: \n640:   // Write mask to sq\n641:   for (i <- 0 until StorePipelineWidth)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 638-648
    context: "638:   }\n639: \n640:   // Write mask to sq\n641:   for (i <- 0 until
      StorePipelineWidth) {\n642:     // sq mask write s0\n643:     when (io.storeMaskIn(i).fire)
      {\n644:       // send data write req to data module\n645:       dataModule.io.mask.waddr(i)
      := io.storeMaskIn(i).bits.sqIdx.value\n646:       dataModule.io.mask.wdata(i)
      := io.storeMaskIn(i).bits.mask\n647:       dataModule.io.mask.wen(i) := true.B\n\
      648:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 660-671
    context: "660:     // (1) if they have the same flag, we need to check range(tail,
      sqIdx)\n661:     // (2) if they have different flags, we need to check range(tail,
      VirtualLoadQueueSize) and range(0, sqIdx)\n662:     // Forward1: Mux(same_flag,
      range(tail, sqIdx), range(tail, VirtualLoadQueueSize))\n663:     // Forward2:
      Mux(same_flag, 0.U,                   range(0, sqIdx)    )\n664:     // i.e.
      forward1 is the target entries with the same flag bits and forward2 otherwise\n\
      665:     val differentFlag = deqPtrExt(0).flag =/= io.forward(i).sqIdx.flag\n\
      666:     val forwardMask = io.forward(i).sqIdxMask\n667:     // all addrvalid
      terms need to be checked\n668:     // Real Vaild: all scalar stores, and vector
      store with (!inactive && !secondInvalid)\n669:     val addrRealValidVec = WireInit(VecInit((0
      until StoreQueueSize).map(j => addrvalid(j) && allocated(j))))\n670:     //
      vector store will consider all inactive || secondInvalid flows as valid\n671:\
      \     val addrValidVec = WireInit(VecInit((0 until StoreQueueSize).map(j =>
      addrvalid(j) && allocated(j))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 667-683
    context: "667:     // all addrvalid terms need to be checked\n668:     // Real
      Vaild: all scalar stores, and vector store with (!inactive && !secondInvalid)\n\
      669:     val addrRealValidVec = WireInit(VecInit((0 until StoreQueueSize).map(j
      => addrvalid(j) && allocated(j))))\n670:     // vector store will consider all
      inactive || secondInvalid flows as valid\n671:     val addrValidVec = WireInit(VecInit((0
      until StoreQueueSize).map(j => addrvalid(j) && allocated(j))))\n672:     val
      dataValidVec = WireInit(VecInit((0 until StoreQueueSize).map(j => datavalid(j))))\n\
      673:     val allValidVec  = WireInit(VecInit((0 until StoreQueueSize).map(j
      => addrvalid(j) && datavalid(j) && allocated(j))))\n674: \n675:     val lfstEnable
      = Constantin.createRecord(\"LFSTEnable\", LFSTEnable)\n676:     val storeSetHitVec
      = Mux(lfstEnable,\n677:       WireInit(VecInit((0 until StoreQueueSize).map(j
      => io.forward(i).uop.loadWaitBit && uop(j).robIdx === io.forward(i).uop.waitForRobIdx))),\n\
      678:       WireInit(VecInit((0 until StoreQueueSize).map(j => uop(j).storeSetHit
      && uop(j).ssid === io.forward(i).uop.ssid)))\n679:     )\n680: \n681:     val
      forwardMask1 = Mux(differentFlag, ~deqMask, deqMask ^ forwardMask)\n682:   \
      \  val forwardMask2 = Mux(differentFlag, forwardMask, 0.U(StoreQueueSize.W))\n\
      683:     val canForward1 = forwardMask1 & allValidVec.asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 683-693
    context: "683:     val canForward1 = forwardMask1 & allValidVec.asUInt\n684: \
      \    val canForward2 = forwardMask2 & allValidVec.asUInt\n685:     val needForward
      = Mux(differentFlag, ~deqMask | forwardMask, deqMask ^ forwardMask)\n686: \n\
      687:     XSDebug(p\"$i f1 ${Binary(canForward1)} f2 ${Binary(canForward2)} \"\
      \ +\n688:       p\"sqIdx ${io.forward(i).sqIdx} pa ${Hexadecimal(io.forward(i).paddr)}\\\
      n\"\n689:     )\n690: \n691:     // do real fwd query (cam lookup in load_s1)\n\
      692:     dataModule.io.needForward(i)(0) := canForward1 & vaddrModule.io.forwardMmask(i).asUInt\n\
      693:     dataModule.io.needForward(i)(1) := canForward2 & vaddrModule.io.forwardMmask(i).asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 690-703
    context: "690: \n691:     // do real fwd query (cam lookup in load_s1)\n692: \
      \    dataModule.io.needForward(i)(0) := canForward1 & vaddrModule.io.forwardMmask(i).asUInt\n\
      693:     dataModule.io.needForward(i)(1) := canForward2 & vaddrModule.io.forwardMmask(i).asUInt\n\
      694: \n695:     vaddrModule.io.forwardMdata(i) := io.forward(i).vaddr\n696:\
      \     vaddrModule.io.forwardDataMask(i) := io.forward(i).mask\n697:     paddrModule.io.forwardMdata(i)
      := io.forward(i).paddr\n698:     paddrModule.io.forwardDataMask(i) := io.forward(i).mask\n\
      699: \n700:     // vaddr cam result does not equal to paddr cam result\n701:\
      \     // replay needed\n702:     // val vpmaskNotEqual = ((paddrModule.io.forwardMmask(i).asUInt
      ^ vaddrModule.io.forwardMmask(i).asUInt) & needForward) =/= 0.U\n703:     //
      val vaddrMatchFailed = vpmaskNotEqual && io.forward(i).valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 700-719
    context: "700:     // vaddr cam result does not equal to paddr cam result\n701:\
      \     // replay needed\n702:     // val vpmaskNotEqual = ((paddrModule.io.forwardMmask(i).asUInt
      ^ vaddrModule.io.forwardMmask(i).asUInt) & needForward) =/= 0.U\n703:     //
      val vaddrMatchFailed = vpmaskNotEqual && io.forward(i).valid\n704:     val vpmaskNotEqual
      = (\n705:       (RegEnable(paddrModule.io.forwardMmask(i).asUInt, io.forward(i).valid)
      ^ RegEnable(vaddrModule.io.forwardMmask(i).asUInt, io.forward(i).valid)) &\n\
      706:       RegNext(needForward) &\n707:       GatedRegNext(addrRealValidVec.asUInt)\n\
      708:     ) =/= 0.U\n709:     val vaddrMatchFailed = vpmaskNotEqual && RegNext(io.forward(i).valid)\n\
      710:     XSInfo(vaddrMatchFailed,\n711:       \"vaddrMatchFailed: pc %x pmask
      %x vmask %x\\n\",\n712:       RegEnable(io.forward(i).uop.pc, io.forward(i).valid),\n\
      713:       RegEnable(needForward & paddrModule.io.forwardMmask(i).asUInt, io.forward(i).valid),\n\
      714:       RegEnable(needForward & vaddrModule.io.forwardMmask(i).asUInt, io.forward(i).valid)\n\
      715:     );\n716:     XSPerfAccumulate(\"vaddr_match_failed\", vpmaskNotEqual)\n\
      717:     XSPerfAccumulate(\"vaddr_match_really_failed\", vaddrMatchFailed)\n\
      718: \n719:     // Fast forward mask will be generated immediately (load_s1)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 715-729
    context: "715:     );\n716:     XSPerfAccumulate(\"vaddr_match_failed\", vpmaskNotEqual)\n\
      717:     XSPerfAccumulate(\"vaddr_match_really_failed\", vaddrMatchFailed)\n\
      718: \n719:     // Fast forward mask will be generated immediately (load_s1)\n\
      720:     io.forward(i).forwardMaskFast := dataModule.io.forwardMaskFast(i)\n\
      721: \n722:     // Forward result will be generated 1 cycle later (load_s2)\n\
      723:     io.forward(i).forwardMask := dataModule.io.forwardMask(i)\n724:   \
      \  io.forward(i).forwardData := dataModule.io.forwardData(i)\n725: \n726:  \
      \   //TODO If the previous store appears out of alignment, then simply FF, this
      is a very unreasonable way to do it.\n727:     //TODO But for the time being,
      this is the way to ensure correctness. Such a suitable opportunity to support
      unaligned forward.\n728:     // If addr match, data not ready, mark it as dataInvalid\n\
      729:     // load_s1: generate dataInvalid in load_s1 to set fastUop"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 725-738
    context: "725: \n726:     //TODO If the previous store appears out of alignment,
      then simply FF, this is a very unreasonable way to do it.\n727:     //TODO But
      for the time being, this is the way to ensure correctness. Such a suitable opportunity
      to support unaligned forward.\n728:     // If addr match, data not ready, mark
      it as dataInvalid\n729:     // load_s1: generate dataInvalid in load_s1 to set
      fastUop\n730:     val dataInvalidMask1 = ((addrValidVec.asUInt & ~dataValidVec.asUInt
      & vaddrModule.io.forwardMmask(i).asUInt) | unaligned.asUInt & allocated.asUInt)
      & forwardMask1.asUInt\n731:     val dataInvalidMask2 = ((addrValidVec.asUInt
      & ~dataValidVec.asUInt & vaddrModule.io.forwardMmask(i).asUInt) | unaligned.asUInt
      & allocated.asUInt) & forwardMask2.asUInt\n732:     val dataInvalidMask = dataInvalidMask1
      | dataInvalidMask2\n733:     io.forward(i).dataInvalidFast := dataInvalidMask.orR\n\
      734: \n735:     // make chisel happy\n736:     val dataInvalidMask1Reg = Wire(UInt(StoreQueueSize.W))\n\
      737:     dataInvalidMask1Reg := RegNext(dataInvalidMask1)\n738:     // make
      chisel happy"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 751-763
    context: "751:     val addrInvalidMask2Reg = Wire(UInt(StoreQueueSize.W))\n752:\
      \     addrInvalidMask2Reg := RegNext(addrInvalidMask2)\n753:     val addrInvalidMaskReg
      = addrInvalidMask1Reg | addrInvalidMask2Reg\n754: \n755:     // load_s2\n756:\
      \     io.forward(i).dataInvalid := RegNext(io.forward(i).dataInvalidFast)\n\
      757:     // check if vaddr forward mismatched\n758:     io.forward(i).matchInvalid
      := vaddrMatchFailed\n759: \n760:     // data invalid sq index\n761:     // check
      whether false fail\n762:     // check flag\n763:     val s2_differentFlag =
      RegNext(differentFlag)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 795-814
    context: "795:     //  |   stores operations    |   | older store operations \
      \      |\n796:     //  +------------------------+   +------------------------------+\n\
      797: \n798: \n799: \n800:     when (RegEnable(io.forward(i).uop.loadWaitStrict,
      io.forward(i).valid)) {\n801:       io.forward(i).addrInvalidSqIdx := RegEnable((io.forward(i).uop.sqIdx
      - 1.U), io.forward(i).valid)\n802:     } .elsewhen (addrInvalidFlag) {\n803:\
      \       io.forward(i).addrInvalidSqIdx.flag := Mux(!s2_differentFlag || addrInvalidSqIdx
      >= s2_deqPtrExt.value, s2_deqPtrExt.flag, s2_enqPtrExt.flag)\n804:       io.forward(i).addrInvalidSqIdx.value
      := addrInvalidSqIdx\n805:     } .otherwise {\n806:       // may be store inst
      has been written to sbuffer already.\n807:       io.forward(i).addrInvalidSqIdx
      := RegEnable(io.forward(i).uop.sqIdx, io.forward(i).valid)\n808:     }\n809:\
      \     io.forward(i).addrInvalid := Mux(RegEnable(io.forward(i).uop.loadWaitStrict,
      io.forward(i).valid), RegNext(hasInvalidAddr), addrInvalidFlag)\n810: \n811:\
      \     // data invalid sq index\n812:     // make chisel happy\n813:     val
      dataInvalidMaskRegWire = Wire(UInt(StoreQueueSize.W))\n814:     dataInvalidMaskRegWire
      := dataInvalidMaskReg"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 817-831
    context: "817:     val dataInvalidSqIdx1 = OHToUInt(Reverse(PriorityEncoderOH(Reverse(dataInvalidMask1Reg))))\n\
      818:     val dataInvalidSqIdx2 = OHToUInt(Reverse(PriorityEncoderOH(Reverse(dataInvalidMask2Reg))))\n\
      819:     val dataInvalidSqIdx = Mux(dataInvalidMask2Reg.orR, dataInvalidSqIdx2,
      dataInvalidSqIdx1)\n820: \n821:     when (dataInvalidFlag) {\n822:       io.forward(i).dataInvalidSqIdx.flag
      := Mux(!s2_differentFlag || dataInvalidSqIdx >= s2_deqPtrExt.value, s2_deqPtrExt.flag,
      s2_enqPtrExt.flag)\n823:       io.forward(i).dataInvalidSqIdx.value := dataInvalidSqIdx\n\
      824:     } .otherwise {\n825:       // may be store inst has been written to
      sbuffer already.\n826:       io.forward(i).dataInvalidSqIdx := RegEnable(io.forward(i).uop.sqIdx,
      io.forward(i).valid)\n827:     }\n828:   }\n829: \n830:   /**\n831:     * Memory
      mapped IO / other uncached operations / CMO"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 838-874
    context: "838:     * (5) ROB commits the instruction: same as normal instructions\n\
      839:     */\n840:   //(2) when they reach ROB's head, they can be sent to uncache
      channel\n841:   // TODO: CAN NOT deal with vector mmio now!\n842:   val s_idle
      :: s_req :: s_resp :: s_wb :: s_wait :: Nil = Enum(5)\n843:   val mmioState
      = RegInit(s_idle)\n844:   val uncacheUop = Reg(new DynInst)\n845:   val cboFlushedSb
      = RegInit(false.B)\n846:   val cmoOpCode = uncacheUop.fuOpType(1, 0)\n847: \
      \  val mmioDoReq = io.uncache.req.fire && !io.uncache.req.bits.nc\n848:   val
      cboMmioPAddr = Reg(UInt(PAddrBits.W))\n849:   switch(mmioState) {\n850:    \
      \ is(s_idle) {\n851:       when(RegNext(io.rob.pendingst && uop(deqPtr).robIdx
      === io.rob.pendingPtr && pending(deqPtr) && allocated(deqPtr) && datavalid(deqPtr)
      && addrvalid(deqPtr) && !hasException(deqPtr))) {\n852:         mmioState :=
      s_req\n853:         uncacheUop := uop(deqPtr)\n854:         uncacheUop.exceptionVec
      := 0.U.asTypeOf(ExceptionVec())\n855:         uncacheUop.trigger := 0.U.asTypeOf(TriggerAction())\n\
      856:         cboFlushedSb := false.B\n857:         cboMmioPAddr := paddrModule.io.rdata(0)\n\
      858:       }\n859:     }\n860:     is(s_req) {\n861:       when (mmioDoReq)
      {\n862:         noPending := false.B\n863:         mmioState := s_resp\n864:\
      \       }\n865:     }\n866:     is(s_resp) {\n867:       when(io.uncache.resp.fire
      && !io.uncache.resp.bits.nc) {\n868:         noPending := true.B\n869:     \
      \    mmioState := s_wb\n870: \n871:         when (io.uncache.resp.bits.nderr
      || io.cmoOpResp.bits.nderr) {\n872:           uncacheUop.exceptionVec(hardwareError)
      := true.B\n873:         }\n874:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 872-886
    context: "872:           uncacheUop.exceptionVec(hardwareError) := true.B\n873:\
      \         }\n874:       }\n875:     }\n876:     is(s_wb) {\n877:       when
      (io.mmioStout.fire || io.vecmmioStout.fire) {\n878:         when (uncacheUop.exceptionVec(hardwareError))
      {\n879:           mmioState := s_idle\n880:         }.otherwise {\n881:    \
      \       mmioState := s_wait\n882:         }\n883:       }\n884:     }\n885:\
      \     is(s_wait) {\n886:       // A MMIO store can always move cmtPtrExt as
      it must be ROB head"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 883-908
    context: "883:       }\n884:     }\n885:     is(s_wait) {\n886:       // A MMIO
      store can always move cmtPtrExt as it must be ROB head\n887:       when(scommit
      > 0.U) {\n888:         mmioState := s_idle // ready for next mmio\n889:    \
      \   }\n890:     }\n891:   }\n892: \n893:   mmioReq.valid := mmioState === s_req
      && !LSUOpType.isCbo(uop(deqPtr).fuOpType) && !io.wfi.wfiReq\n894:   mmioReq.bits
      := DontCare\n895:   mmioReq.bits.cmd  := MemoryOpConstants.M_XWR\n896:   mmioReq.bits.addr
      := paddrModule.io.rdata(0) // data(deqPtr) -> rdata(0)\n897:   mmioReq.bits.vaddr:=
      vaddrModule.io.rdata(0)\n898:   mmioReq.bits.data := shiftDataToLow(paddrModule.io.rdata(0),
      dataModule.io.rdata(0).data)\n899:   mmioReq.bits.mask := shiftMaskToLow(paddrModule.io.rdata(0),
      dataModule.io.rdata(0).mask)\n900:   mmioReq.bits.robIdx := uop(GatedRegNext(rdataPtrExtNext(0)).value).robIdx\n\
      901:   mmioReq.bits.memBackTypeMM := memBackTypeMM(GatedRegNext(rdataPtrExtNext(0)).value)\n\
      902:   mmioReq.bits.nc := false.B\n903:   mmioReq.bits.id := rdataPtrExt(0).value\n\
      904: \n905:   /**\n906:     * NC Store\n907:     * (1) req: when it has been
      commited, it can be sent to lower level.\n908:     * (2) resp: because SQ data
      forward is required, it can only be deq when ncResp is received"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 910-928
    context: "910:     * NOTE: nc_req_ack is used to make sure that the request is
      written by the ubuffer and\n911:     * the ubuffer can forward the required
      data\n912:     */\n913:   // TODO: CAN NOT deal with vector nc now!\n914:  \
      \ val nc_idle :: nc_req :: nc_req_ack :: nc_resp :: Nil = Enum(4)\n915:   val
      ncState = RegInit(nc_idle)\n916:   val rptr0 = rdataPtrExt(0).value\n917:  \
      \ switch(ncState){\n918:     is(nc_idle) {\n919:       when(\n920:         nc(rptr0)
      && allocated(rptr0) && !completed(rptr0) && committed(rptr0) &&\n921:      \
      \   allvalid(rptr0) && !isVec(rptr0) && !hasException(rptr0) && !mmio(rptr0)\n\
      922:       ) {\n923:         ncState := nc_req\n924:         ncWaitRespPtrReg
      := rptr0\n925:       }\n926:     }\n927:     is(nc_req) {\n928:       when(ncDoReq)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 924-934
    context: "924:         ncWaitRespPtrReg := rptr0\n925:       }\n926:     }\n927:\
      \     is(nc_req) {\n928:       when(ncDoReq) {\n929:         ncState := nc_req_ack\n\
      930:       }\n931:     }\n932:     is(nc_req_ack) {\n933:       when(ncSlaveAck)
      {\n934:         when(io.uncacheOutstanding) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 930-958
    context: "930:       }\n931:     }\n932:     is(nc_req_ack) {\n933:       when(ncSlaveAck)
      {\n934:         when(io.uncacheOutstanding) {\n935:           ncState := nc_idle\n\
      936:         }.otherwise{\n937:           ncState := nc_resp\n938:         }\n\
      939:       }\n940:     }\n941:     is(nc_resp) {\n942:       when(ncResp.fire)
      {\n943:         ncState := nc_idle\n944:       }\n945:     }\n946:   }\n947:\
      \ \n948:   ncDoReq := io.uncache.req.fire && io.uncache.req.bits.nc\n949:  \
      \ ncDoResp := ncResp.fire\n950:   ncSlaveAck := io.uncache.idResp.valid && io.uncache.idResp.bits.nc\n\
      951:   ncSlaveAckMid := io.uncache.idResp.bits.mid\n952: \n953:   ncReq.valid
      := ncState === nc_req && !io.wfi.wfiReq\n954:   ncReq.bits := DontCare\n955:\
      \   ncReq.bits.cmd  := MemoryOpConstants.M_XWR\n956:   ncReq.bits.addr := paddrModule.io.rdata(0)\n\
      957:   ncReq.bits.vaddr:= vaddrModule.io.rdata(0)\n958:   ncReq.bits.data :=
      shiftDataToLow(paddrModule.io.rdata(0), dataModule.io.rdata(0).data)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 960-981
    context: "960:   ncReq.bits.robIdx := uop(GatedRegNext(rdataPtrExtNext(0)).value).robIdx\n\
      961:   ncReq.bits.memBackTypeMM := memBackTypeMM(GatedRegNext(rdataPtrExtNext(0)).value)\n\
      962:   ncReq.bits.nc := true.B\n963:   ncReq.bits.id := rptr0\n964: \n965: \
      \  ncResp.ready := io.uncache.resp.ready\n966:   ncResp.valid := io.uncache.resp.fire
      && io.uncache.resp.bits.nc\n967:   ncResp.bits <> io.uncache.resp.bits\n968:\
      \   when (ncDeqTrigger) {\n969:     completed(ncPtr) := true.B\n970:   }\n971:\
      \   XSDebug(ncDeqTrigger,\"nc fire: ptr %d\\n\", ncPtr)\n972: \n973:   mmioReq.ready
      := io.uncache.req.ready\n974:   ncReq.ready := io.uncache.req.ready && !mmioReq.valid\n\
      975:   io.uncache.req.valid := mmioReq.valid || ncReq.valid\n976:   io.uncache.req.bits
      := Mux(mmioReq.valid, mmioReq.bits, ncReq.bits)\n977: \n978:   // CBO op type
      check can be delayed for 1 cycle,\n979:   // as uncache op will not start in
      s_idle\n980:   val cboMmioAddr = get_block_addr(cboMmioPAddr)\n981:   val deqCanDoCbo
      = GatedRegNext(LSUOpType.isCbo(uop(deqPtr).fuOpType) && allocated(deqPtr) &&
      addrvalid(deqPtr) && !hasException(deqPtr))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 979-989
    context: "979:   // as uncache op will not start in s_idle\n980:   val cboMmioAddr
      = get_block_addr(cboMmioPAddr)\n981:   val deqCanDoCbo = GatedRegNext(LSUOpType.isCbo(uop(deqPtr).fuOpType)
      && allocated(deqPtr) && addrvalid(deqPtr) && !hasException(deqPtr))\n982: \n\
      983:   val isCboZeroToSbVec = (0 until EnsbufferWidth).map{ i =>\n984:     io.sbuffer(i).fire
      && io.sbuffer(i).bits.vecValid && io.sbuffer(i).bits.wline && allocated(dataBuffer.io.deq(i).bits.sqPtr.value)\n\
      985:   }\n986:   val cboZeroToSb        = isCboZeroToSbVec.reduce(_ || _)\n\
      987:   val cboZeroFlushSb     = GatedRegNext(cboZeroToSb)\n988: \n989:   val
      cboZeroUop         = RegEnable(PriorityMux(isCboZeroToSbVec, dataBuffer.io.deq.map(x=>uop(x.bits.sqPtr.value))),
      cboZeroToSb)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1000-1042
    context: "1000: \n1001:   when (deqCanDoCbo) {\n1002:     // disable uncache channel\n\
      1003:     io.uncache.req.valid := false.B\n1004: \n1005:     when (io.cmoOpReq.fire)
      {\n1006:       noPending := false.B\n1007:       mmioState := s_resp\n1008:\
      \     }\n1009: \n1010:     when (mmioState === s_resp) {\n1011:       when (io.cmoOpResp.fire)
      {\n1012:         noPending := true.B\n1013:         mmioState := s_wb\n1014:\
      \       }\n1015:     }\n1016:   }\n1017: \n1018:   io.cmoOpReq.valid := deqCanDoCbo
      && cboFlushedSb && (mmioState === s_req) && !io.wfi.wfiReq\n1019:   io.cmoOpReq.bits.opcode\
      \  := cmoOpCode\n1020:   io.cmoOpReq.bits.address := cboMmioAddr\n1021: \n1022:\
      \   io.cmoOpResp.ready := deqCanDoCbo && (mmioState === s_resp)\n1023: \n1024:\
      \   io.wfi.wfiSafe := GatedValidRegNext(noPending && io.wfi.wfiReq)\n1025: \n\
      1026:   io.flushSbuffer.valid := deqCanDoCbo && !cboFlushedSb && (mmioState
      === s_req) && !io.flushSbuffer.empty || cboZeroFlushSb\n1027: \n1028:   when(deqCanDoCbo
      && !cboFlushedSb && (mmioState === s_req) && io.flushSbuffer.empty) {\n1029:\
      \     cboFlushedSb := true.B\n1030:   }\n1031: \n1032:   when(mmioDoReq){\n\
      1033:     // mmio store should not be committed until uncache req is sent\n\
      1034:     pending(deqPtr) := false.B\n1035:   }\n1036:   XSDebug(\n1037:   \
      \  mmioDoReq,\n1038:     p\"uncache req: pc ${Hexadecimal(uop(deqPtr).pc)} \"\
      \ +\n1039:     p\"addr ${Hexadecimal(io.uncache.req.bits.addr)} \" +\n1040:\
      \     p\"data ${Hexadecimal(io.uncache.req.bits.data)} \" +\n1041:     p\"op
      ${Hexadecimal(io.uncache.req.bits.cmd)} \" +\n1042:     p\"mask ${Hexadecimal(io.uncache.req.bits.mask)}\\\
      n\""
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1041-1068
    context: "1041:     p\"op ${Hexadecimal(io.uncache.req.bits.cmd)} \" +\n1042:\
      \     p\"mask ${Hexadecimal(io.uncache.req.bits.mask)}\\n\"\n1043:   )\n1044:\
      \ \n1045:   // (3) response from uncache channel: mark as datavalid\n1046: \
      \  io.uncache.resp.ready := true.B\n1047: \n1048:   // (4) scalar store: writeback
      to ROB (and other units): mark as writebacked\n1049:   io.mmioStout.valid :=
      mmioState === s_wb && !isVec(deqPtr)\n1050:   io.mmioStout.bits.uop := uncacheUop\n\
      1051:   io.mmioStout.bits.uop.exceptionVec := ExceptionNO.selectByFu(uncacheUop.exceptionVec,
      StaCfg)\n1052:   io.mmioStout.bits.uop.sqIdx := deqPtrExt(0)\n1053:   io.mmioStout.bits.uop.flushPipe
      := deqCanDoCbo // flush Pipeline to keep order in CMO\n1054:   io.mmioStout.bits.data
      := shiftDataToLow(paddrModule.io.rdata(0), dataModule.io.rdata(0).data) // dataModule.io.rdata.read(deqPtr)\n\
      1055:   io.mmioStout.bits.isFromLoadUnit := DontCare\n1056:   io.mmioStout.bits.debug.isMMIO
      := true.B\n1057:   io.mmioStout.bits.debug.isNCIO := false.B\n1058:   io.mmioStout.bits.debug.paddr
      := DontCare\n1059:   io.mmioStout.bits.debug.isPerfCnt := false.B\n1060:   io.mmioStout.bits.debug.vaddr
      := DontCare\n1061:   // Remove MMIO inst from store queue after MMIO request
      is being sent\n1062:   // That inst will be traced by uncache state machine\n\
      1063:   when (io.mmioStout.fire) {\n1064:     completed(deqPtr) := true.B\n\
      1065:   }\n1066: \n1067:   // cbo Zero writeback to ROB\n1068:   io.cboZeroStout.valid\
      \                := cboZeroValid && !cboZeroWaitFlushSb"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1068-1078
    context: "1068:   io.cboZeroStout.valid                := cboZeroValid && !cboZeroWaitFlushSb\n\
      1069:   io.cboZeroStout.bits.uop             := cboZeroUop\n1070:   io.cboZeroStout.bits.uop.sqIdx\
      \       := cboZeroSqIdx\n1071:   io.cboZeroStout.bits.data            := DontCare\n\
      1072:   io.cboZeroStout.bits.isFromLoadUnit  := DontCare\n1073:   io.cboZeroStout.bits.debug.isMMIO\
      \    := false.B\n1074:   io.cboZeroStout.bits.debug.isNCIO      := false.B\n\
      1075:   io.cboZeroStout.bits.debug.paddr     := DontCare\n1076:   io.cboZeroStout.bits.debug.isPerfCnt
      := false.B\n1077:   io.cboZeroStout.bits.debug.vaddr     := DontCare\n1078: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1077-1094
    context: "1077:   io.cboZeroStout.bits.debug.vaddr     := DontCare\n1078: \n1079:\
      \   when (cboZeroWaitFlushSb && io.flushSbuffer.empty) {\n1080:     cboZeroWaitFlushSb\
      \    := false.B\n1081:   }\n1082:   when (io.cboZeroStout.fire) {\n1083:   \
      \  completed(cboZeroSqIdx.value) := true.B\n1084:     cboZeroValid := false.B\n\
      1085:   }\n1086: \n1087:   exceptionBuffer.io.storeAddrIn.last.valid := io.mmioStout.fire\n\
      1088:   exceptionBuffer.io.storeAddrIn.last.bits := DontCare\n1089:   exceptionBuffer.io.storeAddrIn.last.bits.fullva
      := vaddrModule.io.rdata.head\n1090:   exceptionBuffer.io.storeAddrIn.last.bits.vaNeedExt
      := true.B\n1091:   exceptionBuffer.io.storeAddrIn.last.bits.uop := uncacheUop\n\
      1092: \n1093:   // (4) or vector store:\n1094:   // TODO: implement it!"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1090-1112
    context: "1090:   exceptionBuffer.io.storeAddrIn.last.bits.vaNeedExt := true.B\n\
      1091:   exceptionBuffer.io.storeAddrIn.last.bits.uop := uncacheUop\n1092: \n\
      1093:   // (4) or vector store:\n1094:   // TODO: implement it!\n1095:   io.vecmmioStout
      := DontCare\n1096:   io.vecmmioStout.valid := false.B //mmioState === s_wb &&
      isVec(deqPtr)\n1097:   io.vecmmioStout.bits.uop := uop(deqPtr)\n1098:   io.vecmmioStout.bits.uop.sqIdx
      := deqPtrExt(0)\n1099:   io.vecmmioStout.bits.data := shiftDataToLow(paddrModule.io.rdata(0),
      dataModule.io.rdata(0).data) // dataModule.io.rdata.read(deqPtr)\n1100:   io.vecmmioStout.bits.debug.isMMIO
      := true.B\n1101:   io.vecmmioStout.bits.debug.isNCIO   := false.B\n1102:   io.vecmmioStout.bits.debug.paddr
      := DontCare\n1103:   io.vecmmioStout.bits.debug.isPerfCnt := false.B\n1104:\
      \   io.vecmmioStout.bits.debug.vaddr := DontCare\n1105:   // Remove MMIO inst
      from store queue after MMIO request is being sent\n1106:   // That inst will
      be traced by uncache state machine\n1107:   when (io.vecmmioStout.fire) {\n\
      1108:     completed(deqPtr) := true.B\n1109:   }\n1110: \n1111:   /**\n1112:\
      \     * ROB commits store instructions (mark them as committed)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1112-1123
    context: "1112:     * ROB commits store instructions (mark them as committed)\n\
      1113:     *\n1114:     * (1) When store commits, mark it as committed.\n1115:\
      \     * (2) They will not be cancelled and can be sent to lower level.\n1116:\
      \     */\n1117:   XSError(mmioState =/= s_idle && mmioState =/= s_wait && commitCount
      > 0.U,\n1118:    \"should not commit instruction when MMIO has not been finished\\\
      n\")\n1119: \n1120:   val commitVec = WireInit(VecInit(Seq.fill(CommitWidth)(false.B)))\n\
      1121:   val needCancel = Wire(Vec(StoreQueueSize, Bool())) // Will be assigned
      later\n1122: \n1123:   if (backendParams.debugEn){ dontTouch(commitVec) }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1124-1145
    context: "1124: \n1125:   // TODO: Deal with vector store mmio\n1126:   for (i
      <- 0 until CommitWidth) {\n1127:     // don't mark misalign store as committed\n\
      1128:     val ptr = cmtPtrExt(i).value\n1129:     val isCommit = WireInit(false.B)\n\
      1130:     when (\n1131:       allocated(ptr) &&\n1132:       isNotAfter(uop(ptr).robIdx,
      GatedRegNext(io.rob.pendingPtr)) &&\n1133:       !needCancel(ptr) &&\n1134:\
      \       (!waitStoreS2(ptr) || isVec(ptr))) {\n1135:       if (i == 0){\n1136:\
      \         // TODO: fixme for vector mmio\n1137:         when ((mmioState ===
      s_idle) || (mmioState === s_wait && scommit > 0.U)){\n1138:           when ((isVec(ptr)
      && vecMbCommit(ptr)) || !isVec(ptr)) {\n1139:             isCommit := true.B\n\
      1140:             committed(ptr) := true.B\n1141:             commitVec(0) :=
      true.B\n1142:           }\n1143:         }\n1144:       } else {\n1145:    \
      \     when ((isVec(ptr) && vecMbCommit(ptr)) || !isVec(ptr)) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1141-1157
    context: "1141:             commitVec(0) := true.B\n1142:           }\n1143: \
      \        }\n1144:       } else {\n1145:         when ((isVec(ptr) && vecMbCommit(ptr))
      || !isVec(ptr)) {\n1146:           isCommit := commitVec(i - 1) || committed(ptr)\n\
      1147:           committed(ptr) := commitVec(i - 1) || committed(ptr)\n1148:\
      \           commitVec(i) := commitVec(i - 1)\n1149:         }\n1150:       }\n\
      1151:     }\n1152:     when(isCommit && nc(ptr) && hasException(ptr)) {\n1153:\
      \       completed(ptr) := true.B\n1154:     }\n1155:   }\n1156: \n1157:   commitCount
      := PopCount(commitVec)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1169-1179
    context: "1169:    *    module keeps growing higher. Now we give data read a whole
      cycle.\n1170:    */\n1171: \n1172:   //TODO An unaligned command can only be
      sent out if the databuffer can enter more than two.\n1173:   //TODO For now,
      hardcode the number of ENQs for the databuffer.\n1174:   val canDeqMisaligned
      = dataBuffer.io.enq(0).ready && dataBuffer.io.enq(1).ready\n1175:   val firstWithMisalign
      = unaligned(rdataPtrExt(0).value)\n1176:   val firstWithCross16Byte = cross16Byte(rdataPtrExt(0).value)\n\
      1177: \n1178:   val isCross4KPage = io.maControl.toStoreQueue.crossPageWithHit\n\
      1179:   val isCross4KPageCanDeq = io.maControl.toStoreQueue.crossPageCanDeq"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1177-1191
    context: "1177: \n1178:   val isCross4KPage = io.maControl.toStoreQueue.crossPageWithHit\n\
      1179:   val isCross4KPageCanDeq = io.maControl.toStoreQueue.crossPageCanDeq\n\
      1180:   // When encountering a cross page store, a request needs to be sent
      to storeMisalignBuffer for the high page table's paddr.\n1181:   io.maControl.toStoreMisalignBuffer.sqPtr
      := rdataPtrExt(0)\n1182:   io.maControl.toStoreMisalignBuffer.doDeq := isCross4KPage
      && isCross4KPageCanDeq && dataBuffer.io.enq(0).fire\n1183:   io.maControl.toStoreMisalignBuffer.uop
      := uop(rdataPtrExt(0).value)\n1184:   for (i <- 0 until EnsbufferWidth) {\n\
      1185:     val ptr = rdataPtrExt(i).value\n1186:     val mmioStall = if(i ==
      0) mmio(rdataPtrExt(0).value) else (mmio(rdataPtrExt(i).value) || mmio(rdataPtrExt(i-1).value))\n\
      1187:     val ncStall = if(i == 0) nc(rdataPtrExt(0).value) else (nc(rdataPtrExt(i).value)
      || nc(rdataPtrExt(i-1).value))\n1188:     val exceptionValid = if(i == 0) hasException(rdataPtrExt(0).value)
      else {\n1189:       hasException(rdataPtrExt(i).value) || (hasException(rdataPtrExt(i-1).value)
      && uop(rdataPtrExt(i).value).robIdx === uop(rdataPtrExt(i-1).value).robIdx)\n\
      1190:     }\n1191:     val vecNotAllMask = dataModule.io.rdata(i).mask.orR"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1190-1201
    context: "1190:     }\n1191:     val vecNotAllMask = dataModule.io.rdata(i).mask.orR\n\
      1192:     // Vector instructions that prevent triggered exceptions from being
      written to the 'databuffer'.\n1193:     val vecHasExceptionFlagValid = vecExceptionFlag.valid
      && isVec(ptr) && vecExceptionFlag.bits.robIdx === uop(ptr).robIdx\n1194: \n\
      1195:     val misalignToDataBufferValid = allocated(rdataPtrExt(0).value) &&
      committed(rdataPtrExt(0).value) &&\n1196:                                  \
      \   (!isVec(rdataPtrExt(0).value) && allvalid(rdataPtrExt(0).value) || vecMbCommit(rdataPtrExt(0).value))
      &&\n1197:                                     canDeqMisaligned && (!isCross4KPage
      || isCross4KPageCanDeq || hasException(rdataPtrExt(0).value))\n1198:     //
      Only the first interface can write unaligned directives.\n1199:     // Simplified
      design, even if the two ports have exceptions, but still only one unaligned
      dequeue.\n1200:     val assert_flag = WireInit(false.B)\n1201:     when(firstWithMisalign
      && firstWithCross16Byte) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1201-1214
    context: "1201:     when(firstWithMisalign && firstWithCross16Byte) {\n1202: \
      \      dataBuffer.io.enq(i).valid := misalignToDataBufferValid\n1203:      \
      \ assert_flag := dataBuffer.io.enq(1).valid\n1204:     }.otherwise {\n1205:\
      \       dataBuffer.io.enq(i).valid := (\n1206:         allocated(ptr) && committed(ptr)\n\
      1207:           && ((!isVec(ptr) && (allvalid(ptr) || hasException(ptr))) ||
      vecMbCommit(ptr))\n1208:           && !mmioStall && !ncStall\n1209:        \
      \   && (!unaligned(ptr) || !cross16Byte(ptr) && (allvalid(ptr) || hasException(ptr)))\n\
      1210:         )\n1211:     }\n1212: \n1213:     val misalignAddrLow = vaddrModule.io.rdata(0)(2,
      0)\n1214:     val cross16ByteAddrLow4bit = vaddrModule.io.rdata(0)(3, 0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1230-1240
    context: "1230:     val maskHigh  = Cross16ByteMask(31, 16)\n1231: \n1232:   \
      \  val dataLow   = Cross16ByteData(127, 0)\n1233:     val dataHigh  = Cross16ByteData(255,
      128)\n1234: \n1235:     val toSbufferVecValid = (!isVec(ptr) || (vecMbCommit(ptr)
      && allvalid(ptr) && vecNotAllMask)) && !exceptionValid && !vecHasExceptionFlagValid\n\
      1236:     when(canDeqMisaligned && firstWithMisalign && firstWithCross16Byte)
      {\n1237:       when(isCross4KPage && isCross4KPageCanDeq) {\n1238:         if
      (i == 0) {\n1239:           dataBuffer.io.enq(i).bits.addr      := paddrLow\n\
      1240:           dataBuffer.io.enq(i).bits.vaddr     := vaddrLow"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1307-1317
    context: "1307:       dataBuffer.io.enq(i).bits.vecValid := toSbufferVecValid\n\
      1308: \n1309:     }\n1310: \n1311:     // Note that store data/addr should both
      be valid after store's commit\n1312:     assert(!dataBuffer.io.enq(i).valid
      || allvalid(ptr) || hasException(ptr) || (allocated(ptr) && vecMbCommit(ptr))
      || assert_flag)\n1313:   }\n1314: \n1315:   // Send data stored in sbufferReqBitsReg
      to sbuffer\n1316:   for (i <- 0 until EnsbufferWidth) {\n1317:     io.sbuffer(i).valid
      := dataBuffer.io.deq(i).valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1313-1323
    context: "1313:   }\n1314: \n1315:   // Send data stored in sbufferReqBitsReg
      to sbuffer\n1316:   for (i <- 0 until EnsbufferWidth) {\n1317:     io.sbuffer(i).valid
      := dataBuffer.io.deq(i).valid\n1318:     dataBuffer.io.deq(i).ready := io.sbuffer(i).ready\n\
      1319:     io.sbuffer(i).bits.fromDataBufferEntry(dataBuffer.io.deq(i).bits,
      MemoryOpConstants.M_XWR)\n1320:     // io.sbuffer(i).fire is RegNexted, as sbuffer
      data write takes 2 cycles.\n1321:     // Before data write finish, sbuffer is
      unable to provide store to load\n1322:     // forward data. As an workaround,
      deqPtrExt and allocated flag update\n1323:     // is delayed so that load can
      get the right data from store queue."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1325-1339
    context: "1325:     // Only sqNeedDeq can move the ptr.\n1326:     // ---\n1327:\
      \     // however, `completed` is register, when it turn true, the data has already
      been written to sbuffer\n1328:     // Besides, we should not have cbozero completed.
      (wline is currently only for cbozero)\n1329:     val ptr = dataBuffer.io.deq(i).bits.sqPtr.value\n\
      1330:     when (io.sbuffer(i).fire && io.sbuffer(i).bits.sqNeedDeq && !io.sbuffer(i).bits.wline)
      {\n1331: \n1332:       completed(ptr) := true.B\n1333:     }\n1334:     XSDebug(RegNext(io.sbuffer(i).fire
      && io.sbuffer(i).bits.sqNeedDeq), \"sbuffer \"+i+\" fire: ptr %d\\n\", ptr)\n\
      1335:   }\n1336: \n1337:   // All vector instruction uop normally dequeue, but
      the Uop after the exception is raised does not write to the 'sbuffer'.\n1338:\
      \   // Flags are used to record whether there are any exceptions when the queue
      is displayed.\n1339:   // This is determined each time a write is made to the
      'databuffer', prevent subsequent uop of the same instruction from writing to
      the 'dataBuffer'."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1337-1349
    context: "1337:   // All vector instruction uop normally dequeue, but the Uop
      after the exception is raised does not write to the 'sbuffer'.\n1338:   // Flags
      are used to record whether there are any exceptions when the queue is displayed.\n\
      1339:   // This is determined each time a write is made to the 'databuffer',
      prevent subsequent uop of the same instruction from writing to the 'dataBuffer'.\n\
      1340:   val vecCommitHasException = (0 until EnsbufferWidth).map{ i =>\n1341:\
      \     val ptr = rdataPtrExt(i).value\n1342:     val mmioStall = if(i == 0) mmio(rdataPtrExt(0).value)
      else (mmio(rdataPtrExt(i).value) || mmio(rdataPtrExt(i-1).value))\n1343:   \
      \  val ncStall = if(i == 0) nc(rdataPtrExt(0).value) else (nc(rdataPtrExt(i).value)
      || nc(rdataPtrExt(i-1).value))\n1344:     val exceptionVliad      = isVec(ptr)
      && hasException(ptr) && dataBuffer.io.enq(i).fire && dataBuffer.io.enq(i).bits.sqNeedDeq\n\
      1345:     (exceptionVliad, uop(ptr), vecLastFlow(ptr))\n1346:   }\n1347: \n\
      1348:   val vecCommitHasExceptionValid      = vecCommitHasException.map(_._1)\n\
      1349:   val vecCommitHasExceptionUop        = vecCommitHasException.map(_._2)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1352-1367
    context: "1352:   // Just select the last Uop tah has an exception.\n1353:   val
      vecCommitHasExceptionSelectUop  = ParallelPosteriorityMux(vecCommitHasExceptionValid,
      vecCommitHasExceptionUop)\n1354:   // If the last flow with an exception is
      the LastFlow of this instruction, the flag is not set.\n1355:   // compare robidx
      to select the last flow\n1356:   require(EnsbufferWidth == 2, \"The vector store
      exception handle process only support EnsbufferWidth == 2 yet.\")\n1357:   val
      robidxEQ = dataBuffer.io.enq(0).fire && dataBuffer.io.enq(1).fire &&\n1358:\
      \     uop(rdataPtrExt(0).value).robIdx === uop(rdataPtrExt(1).value).robIdx\n\
      1359:   val robidxNE = dataBuffer.io.enq(0).fire && dataBuffer.io.enq(1).fire
      && (\n1360:     uop(rdataPtrExt(0).value).robIdx =/= uop(rdataPtrExt(1).value).robIdx\n\
      1361:   )\n1362:   val onlyCommit0 = dataBuffer.io.enq(0).fire && !dataBuffer.io.enq(1).fire\n\
      1363: \n1364:   /**\n1365:    * If rdataPtr(0) is misaligned and Cross16Byte,
      this store request will fill two ports of rdataBuffer,\n1366:    * Therefore,
      the judgement of vecCommitLastFlow should't to use rdataPtr(1)\n1367:    * */"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1375-1385
    context: "1375: \n1376: \n1377:   val vecExceptionFlagCancel  = (0 until EnsbufferWidth).map{
      i =>\n1378:     val ptr = rdataPtrExt(i).value\n1379:     val vecLastFlowCommit
      = vecLastFlow(ptr) && (uop(ptr).robIdx === vecExceptionFlag.bits.robIdx) &&\n\
      1380:                             dataBuffer.io.enq(i).fire && !firstSplit\n\
      1381:     vecLastFlowCommit\n1382:   }.reduce(_ || _)\n1383: \n1384:   // When
      a LastFlow with an exception instruction is commited, clear the flag.\n1385:\
      \   when(!vecExceptionFlag.valid && vecCommitHasExceptionValidOR && !vecCommitLastFlow)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1402-1417
    context: "1402:   // Only the vector store difftest required signal is separated
      from the rtl code.\n1403:   if (env.EnableDifftest) {\n1404:     // commit cbo.inval
      to difftest\n1405:     val cmoInvalEvent = DifftestModule(new DiffCMOInvalEvent)\n\
      1406:     cmoInvalEvent.coreid := io.hartId\n1407:     cmoInvalEvent.valid :=
      io.mmioStout.fire && deqCanDoCbo && LSUOpType.isCboInval(uop(deqPtr).fuOpType)\n\
      1408:     cmoInvalEvent.addr := cboMmioAddr\n1409: \n1410:     // DiffStoreEvent
      happens when rdataPtr moves.\n1411:     // That is, pmsStore enter dataBuffer
      or ncStore enter Ubuffer\n1412:     (0 until EnsbufferWidth).foreach { i =>\n\
      1413:       // when i = 0, the sqPtr is rdataPtr(0), which is rdataPtrExt(0),
      so it applies to NC as well.\n1414:       val ptr = dataBuffer.io.enq(i).bits.sqPtr.value\n\
      1415:       io.diffStore.diffInfo(i).uop := uop(ptr)\n1416:       io.diffStore.diffInfo(i).start
      := debug_vec_unaligned_start(ptr)\n1417:       io.diffStore.diffInfo(i).offset
      := debug_vec_unaligned_offset(ptr)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1413-1436
    context: "1413:       // when i = 0, the sqPtr is rdataPtr(0), which is rdataPtrExt(0),
      so it applies to NC as well.\n1414:       val ptr = dataBuffer.io.enq(i).bits.sqPtr.value\n\
      1415:       io.diffStore.diffInfo(i).uop := uop(ptr)\n1416:       io.diffStore.diffInfo(i).start
      := debug_vec_unaligned_start(ptr)\n1417:       io.diffStore.diffInfo(i).offset
      := debug_vec_unaligned_offset(ptr)\n1418:       io.diffStore.pmaStore(i).valid
      := dataBuffer.io.enq(i).fire\n1419:       io.diffStore.pmaStore(i).bits.fromDataBufferEntry(dataBuffer.io.enq(i).bits,
      MemoryOpConstants.M_XWR)\n1420:     }\n1421:     io.diffStore.ncStore.valid
      := ncReq.fire && ncReq.bits.memBackTypeMM\n1422:     io.diffStore.ncStore.bits
      := ncReq.bits\n1423:   }\n1424: \n1425: \n1426:   (1 until EnsbufferWidth).foreach(i
      => when(io.sbuffer(i).fire) { assert(io.sbuffer(i - 1).fire) })\n1427:   if
      (coreParams.dcacheParametersOpt.isEmpty) {\n1428:     for (i <- 0 until EnsbufferWidth)
      {\n1429:       val ptr = deqPtrExt(i).value\n1430:       val ram = DifftestMem(64L
      * 1024 * 1024 * 1024, 8)\n1431:       val wen = allocated(ptr) && committed(ptr)
      && !mmio(ptr)\n1432:       val waddr = ((paddrModule.io.rdata(i) - \"h80000000\"\
      .U) >> 3).asUInt\n1433:       val wdata = Mux(paddrModule.io.rdata(i)(3), dataModule.io.rdata(i).data(127,
      64), dataModule.io.rdata(i).data(63, 0))\n1434:       val wmask = Mux(paddrModule.io.rdata(i)(3),
      dataModule.io.rdata(i).mask(15, 8), dataModule.io.rdata(i).mask(7, 0))\n1435:\
      \       when (wen) {\n1436:         ram.write(waddr, wdata.asTypeOf(Vec(8, UInt(8.W))),
      wmask.asBools)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1447-1466
    context: "1447:   io.exceptionAddr.vl        := exceptionBuffer.io.exceptionAddr.vl\n\
      1448:   io.exceptionAddr.isForVSnonLeafPTE := exceptionBuffer.io.exceptionAddr.isForVSnonLeafPTE\n\
      1449: \n1450:   // vector commit or replay from\n1451:   val vecCommittmp =
      Wire(Vec(StoreQueueSize, Vec(VecStorePipelineWidth, Bool())))\n1452:   val vecCommit
      = Wire(Vec(StoreQueueSize, Bool()))\n1453:   for (i <- 0 until StoreQueueSize)
      {\n1454:     val fbk = io.vecFeedback\n1455:     for (j <- 0 until VecStorePipelineWidth)
      {\n1456:       vecCommittmp(i)(j) := fbk(j).valid && (fbk(j).bits.isCommit ||
      fbk(j).bits.isFlush) &&\n1457:         uop(i).robIdx === fbk(j).bits.robidx
      && uop(i).uopIdx === fbk(j).bits.uopidx && allocated(i)\n1458:     }\n1459:\
      \     vecCommit(i) := vecCommittmp(i).reduce(_ || _)\n1460: \n1461:     when
      (vecCommit(i)) {\n1462:       vecMbCommit(i) := true.B\n1463:     }\n1464: \
      \  }\n1465: \n1466:   // For vector, when there is a store across pages with
      the same uop in storeMisalignBuffer, storequeue needs to mark this item as committed."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1463-1473
    context: "1463:     }\n1464:   }\n1465: \n1466:   // For vector, when there is
      a store across pages with the same uop in storeMisalignBuffer, storequeue needs
      to mark this item as committed.\n1467:   // TODO FIXME Can vecMbCommit be removed?\n\
      1468:   when(io.maControl.toStoreQueue.withSameUop && allvalid(rdataPtrExt(0).value))
      {\n1469:     vecMbCommit(rdataPtrExt(0).value) := true.B\n1470:   }\n1471: \n\
      1472:   // misprediction recovery / exception redirect\n1473:   // invalidate
      sq term using robIdx"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1470-1483
    context: "1470:   }\n1471: \n1472:   // misprediction recovery / exception redirect\n\
      1473:   // invalidate sq term using robIdx\n1474:   for (i <- 0 until StoreQueueSize)
      {\n1475:     needCancel(i) := allocated(i) && !committed(i) && Mux(\n1476: \
      \        vecExceptionFlag.valid,\n1477:         isAfter(uop(i).robIdx, io.brqRedirect.bits.robIdx)
      && io.brqRedirect.valid,\n1478:         uop(i).robIdx.needFlush(io.brqRedirect)\n\
      1479:       )\n1480:     when (needCancel(i)) {\n1481:       allocated(i) :=
      false.B\n1482:       completed(i) := false.B\n1483:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1485-1507
    context: "1485: \n1486:  /**\n1487: * update pointers\n1488: **/\n1489:   val
      enqCancelValid = canEnqueue.zip(io.enq.req).map{case (v , x) =>\n1490:     v
      && x.bits.robIdx.needFlush(io.brqRedirect)\n1491:   }\n1492:   val enqCancelNum
      = enqCancelValid.zip(vStoreFlow).map{case (v, flow) =>\n1493:     Mux(v, flow,
      0.U)\n1494:   }\n1495:   val lastEnqCancel = RegEnable(enqCancelNum.reduce(_
      + _), io.brqRedirect.valid) // 1 cycle after redirect\n1496: \n1497:   val lastCycleCancelCount
      = PopCount(RegEnable(needCancel, io.brqRedirect.valid)) // 1 cycle after redirect\n\
      1498:   val lastCycleRedirect = RegNext(io.brqRedirect.valid) // 1 cycle after
      redirect\n1499:   val enqNumber = validVStoreFlow.reduce(_ + _)\n1500: \n1501:\
      \   val lastlastCycleRedirect=RegNext(lastCycleRedirect)// 2 cycle after redirect\n\
      1502:   val redirectCancelCount = RegEnable(lastCycleCancelCount + lastEnqCancel,
      0.U, lastCycleRedirect) // 2 cycle after redirect\n1503: \n1504:   when (lastlastCycleRedirect)
      {\n1505:     // we recover the pointers in 2 cycle after redirect for better
      timing\n1506:     enqPtrExt := VecInit(enqPtrExt.map(_ - redirectCancelCount))\n\
      1507:   }.otherwise {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1537-1550
    context: "1537:   // perf counter\n1538:   QueuePerf(StoreQueueSize, validCount,
      !allowEnqueue)\n1539:   val vecValidVec = WireInit(VecInit((0 until StoreQueueSize).map(i
      => allocated(i) && isVec(i))))\n1540:   QueuePerf(StoreQueueSize, PopCount(vecValidVec),
      !allowEnqueue)\n1541:   io.sqFull := !allowEnqueue\n1542:   XSPerfAccumulate(\"\
      mmioCycle\", mmioState =/= s_idle) // lq is busy dealing with uncache req\n\
      1543:   XSPerfAccumulate(\"mmioCnt\", mmioDoReq)\n1544:   XSPerfAccumulate(\"\
      mmio_wb_success\", io.mmioStout.fire || io.vecmmioStout.fire)\n1545:   XSPerfAccumulate(\"\
      mmio_wb_blocked\", (io.mmioStout.valid && !io.mmioStout.ready) || (io.vecmmioStout.valid
      && !io.vecmmioStout.ready))\n1546:   XSPerfAccumulate(\"validEntryCnt\", distanceBetween(enqPtrExt(0),
      deqPtrExt(0)))\n1547:   XSPerfAccumulate(\"cmtEntryCnt\", distanceBetween(cmtPtrExt(0),
      deqPtrExt(0)))\n1548:   XSPerfAccumulate(\"nCmtEntryCnt\", distanceBetween(enqPtrExt(0),
      cmtPtrExt(0)))\n1549: \n1550:   val perfValidCount = distanceBetween(enqPtrExt(0),
      deqPtrExt(0))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1547-1564
    context: "1547:   XSPerfAccumulate(\"cmtEntryCnt\", distanceBetween(cmtPtrExt(0),
      deqPtrExt(0)))\n1548:   XSPerfAccumulate(\"nCmtEntryCnt\", distanceBetween(enqPtrExt(0),
      cmtPtrExt(0)))\n1549: \n1550:   val perfValidCount = distanceBetween(enqPtrExt(0),
      deqPtrExt(0))\n1551:   val perfEvents = Seq(\n1552:     (\"mmioCycle      \"\
      , mmioState =/= s_idle),\n1553:     (\"mmioCnt        \", mmioDoReq),\n1554:\
      \     (\"mmio_wb_success\", io.mmioStout.fire || io.vecmmioStout.fire),\n1555:\
      \     (\"mmio_wb_blocked\", (io.mmioStout.valid && !io.mmioStout.ready) || (io.vecmmioStout.valid
      && !io.vecmmioStout.ready)),\n1556:     (\"stq_1_4_valid  \", (perfValidCount
      < (StoreQueueSize.U/4.U))),\n1557:     (\"stq_2_4_valid  \", (perfValidCount
      > (StoreQueueSize.U/4.U)) & (perfValidCount <= (StoreQueueSize.U/2.U))),\n1558:\
      \     (\"stq_3_4_valid  \", (perfValidCount > (StoreQueueSize.U/2.U)) & (perfValidCount
      <= (StoreQueueSize.U*3.U/4.U))),\n1559:     (\"stq_4_4_valid  \", (perfValidCount
      > (StoreQueueSize.U*3.U/4.U))),\n1560:   )\n1561:   generatePerfEvent()\n1562:\
      \ \n1563:   // debug info\n1564:   XSDebug(\"enqPtrExt %d:%d deqPtrExt %d:%d\\\
      n\", enqPtrExt(0).flag, enqPtr, deqPtrExt(0).flag, deqPtr)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1575-1587
    context: "1575:       debug_paddr(i),\n1576:       debug_data(i)\n1577:     )\n\
      1578:     PrintFlag(allocated(i), \"a\")\n1579:     PrintFlag(allocated(i) &&
      addrvalid(i), \"a\")\n1580:     PrintFlag(allocated(i) && datavalid(i), \"d\"\
      )\n1581:     PrintFlag(allocated(i) && committed(i), \"c\")\n1582:     PrintFlag(allocated(i)
      && pending(i), \"p\")\n1583:     PrintFlag(allocated(i) && mmio(i), \"m\")\n\
      1584:     XSDebug(false, true.B, \"\\n\")\n1585:   }\n1586: \n1587: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/FreeList.scala
    lines: 30-40
    context: "30:     val allocateReq = Input(Vec(allocWidth, Bool()))\n31:     val
      allocateSlot = Output(Vec(allocWidth, UInt()))\n32:     val canAllocate = Output(Vec(allocWidth,
      Bool()))\n33:     val doAllocate = Input(Vec(allocWidth, Bool()))\n34: \n35:\
      \     val free = Input(UInt(size.W))\n36: \n37:     val validCount = Output(UInt())\n\
      38:     val empty = Output(Bool())\n39:   })\n40: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/FreeList.scala
    lines: 71-81
    context: "71:   val freeSelMaskVec = Wire(Vec(freeWidth, UInt(size.W)))\n72: \n\
      73:   // update freeMask\n74:   require((size % freeWidth) == 0)\n75:   freeSelMask
      := freeSelMaskVec.reduce(_|_)\n76:   freeMask := (io.free | freeMask) & ~freeSelMask\n\
      77: \n78:   val remFreeSelMaskVec = VecInit(Seq.tabulate(freeWidth)(rem => getRemBits((freeMask
      & ~freeSelMask))(rem)))\n79:   val remFreeSelIndexOHVec = VecInit(Seq.tabulate(freeWidth)(fport
      => {\n80:     val highIndexOH = PriorityEncoderOH(remFreeSelMaskVec(fport))\n\
      81:     val freeIndexOHVec = Wire(Vec(size, Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/FreeList.scala
    lines: 77-87
    context: "77: \n78:   val remFreeSelMaskVec = VecInit(Seq.tabulate(freeWidth)(rem
      => getRemBits((freeMask & ~freeSelMask))(rem)))\n79:   val remFreeSelIndexOHVec
      = VecInit(Seq.tabulate(freeWidth)(fport => {\n80:     val highIndexOH = PriorityEncoderOH(remFreeSelMaskVec(fport))\n\
      81:     val freeIndexOHVec = Wire(Vec(size, Bool()))\n82:     freeIndexOHVec.foreach(e
      => e := false.B)\n83:     for (i <- 0 until size / freeWidth) {\n84:       freeIndexOHVec(i
      * freeWidth + fport) := highIndexOH(i)\n85:     }\n86:     freeIndexOHVec.asUInt\n\
      87:   }))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/FreeList.scala
    lines: 147-157
    context: "147:     val validMask2 = Mux(differentFlag, headMask, 0.U(size.W))\n\
      148:     val validMask = ~(validMask1 | validMask2)\n149:     for (i <- 0 until
      size) {\n150:       for (j <- i+1 until size) {\n151:         if (i != j) {\n\
      152:           XSError(validMask(i) && validMask(j) && freeList(i) === freeList(j),s\"\
      Found same entry in free list! (i=$i j=$j)\\n\")\n153:         }\n154:     \
      \  }\n155:     }\n156:   }\n157: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 32-42
    context: "32:   with HasLoadHelper\n33:   with HasPerfEvents\n34: {\n35:   val
      io = IO(new Bundle() {\n36:     // control\n37:     val redirect = Flipped(Valid(new
      Redirect))\n38: \n39:     // violation query\n40:     val query = Vec(LoadPipelineWidth,
      Flipped(new LoadNukeQueryIO))\n41: \n42:     // release cacheline"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 68-78
    context: "68:       boundary(i + PartialPAddrStride + 33, PAddrBits)\n69:    \
      \ )\n70:   )\n71:   private def genPartialPAddr(paddr: UInt) = {\n72:     val
      ppaddr_low = Wire(Vec(PartialPAddrLowBits, Bool()))\n73:     ppaddr_low.zip(lowMapping).foreach
      {\n74:       case (bit, mapping) =>\n75:         bit := mapping.filter(_.isDefined).map(x
      => paddr(x.get)).reduce(_^_)\n76:     }\n77: \n78:     val ppaddr_high = Wire(Vec(PartialPAddrHighBits,
      Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 74-84
    context: "74:       case (bit, mapping) =>\n75:         bit := mapping.filter(_.isDefined).map(x
      => paddr(x.get)).reduce(_^_)\n76:     }\n77: \n78:     val ppaddr_high = Wire(Vec(PartialPAddrHighBits,
      Bool()))\n79:     ppaddr_high.zip(highMapping).foreach {\n80:       case (bit,
      mapping) =>\n81:         bit := mapping.filter(_.isDefined).map(x => paddr(x.get)).reduce(_^_)\n\
      82:     }\n83:     Cat(ppaddr_high.asUInt, ppaddr_low.asUInt)\n84:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 97-107
    context: "97:   val allocated = RegInit(VecInit(List.fill(LoadQueueRARSize)(false.B)))
      // The control signals need to explicitly indicate the initial value\n98:  \
      \ val uop = Reg(Vec(LoadQueueRARSize, new DynInst))\n99:   val paddrModule =
      Module(new LqPAddrModule(\n100:     gen = UInt(PartialPAddrBits.W),\n101:  \
      \   numEntries = LoadQueueRARSize,\n102:     numRead = LoadPipelineWidth,\n\
      103:     numWrite = LoadPipelineWidth,\n104:     numWBank = LoadQueueNWriteBanks,\n\
      105:     numWDelay = 1,\n106:     numCamPort = LoadPipelineWidth,\n107:    \
      \ enableCacheLineCheck = false, // Now `RARQueue` has no need to check cacheline."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 135-146
    context: "135: \n136:   // LoadQueueRAR enqueue condition:\n137:   // There are
      still not completed load instructions before the current load instruction.\n\
      138:   // (e.g. \"not completed\" means that load instruction get the data or
      exception).\n139:   val canEnqueue = io.query.map(_.req.valid)\n140:   val cancelEnqueue
      = io.query.map(_.req.bits.uop.robIdx.needFlush(io.redirect))\n141:   val hasNotWritebackedLoad
      = io.query.map(_.req.bits.uop.lqIdx).map(lqIdx => isAfter(lqIdx, io.ldWbPtr))\n\
      142:   val needEnqueue = canEnqueue.zip(hasNotWritebackedLoad).zip(cancelEnqueue).map
      { case ((v, r), c) => v && r && !c }\n143: \n144:   // Allocate logic\n145:\
      \   val acceptedVec = Wire(Vec(LoadPipelineWidth, Bool()))\n146:   val enqIndexVec
      = Wire(Vec(LoadPipelineWidth, UInt(log2Up(LoadQueueRARSize).W)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 154-167
    context: "154: \n155:     //  Allocate ready\n156:     val offset = PopCount(needEnqueue.take(w))\n\
      157:     val canAccept = freeList.io.canAllocate(offset)\n158:     val enqIndex
      = freeList.io.allocateSlot(offset)\n159:     enq.ready := Mux(needEnqueue(w),
      canAccept, true.B)\n160: \n161:     enqIndexVec(w) := enqIndex\n162:     when
      (needEnqueue(w) && enq.ready) {\n163:       acceptedVec(w) := true.B\n164: \n\
      165:       freeList.io.doAllocate(w) := true.B\n166:       //  Allocate new
      entry\n167:       allocated(enqIndex) := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 174-184
    context: "174:       //  Fill info\n175:       uop(enqIndex) := enq.bits.uop\n\
      176:       //  NC is uncachable and will not be explicitly released.\n177: \
      \      //  So NC requests are not allowed to have RAR\n178:       released(enqIndex)
      := enq.bits.is_nc || (\n179:         enq.bits.data_valid &&\n180:         (release2Cycle.valid
      &&\n181:         enq.bits.paddr(PAddrBits-1, DCacheLineOffset) === release2Cycle.bits.paddr(PAddrBits-1,
      DCacheLineOffset) ||\n182:         release1Cycle.valid &&\n183:         enq.bits.paddr(PAddrBits-1,
      DCacheLineOffset) === release1Cycle.bits.paddr(PAddrBits-1, DCacheLineOffset))\n\
      184:       )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 183-193
    context: "183:         enq.bits.paddr(PAddrBits-1, DCacheLineOffset) === release1Cycle.bits.paddr(PAddrBits-1,
      DCacheLineOffset))\n184:       )\n185:     }\n186:     val debug_robIdx = enq.bits.uop.robIdx.asUInt\n\
      187:     XSError(\n188:       needEnqueue(w) && enq.ready && allocated(enqIndex),\n\
      189:       p\"LoadQueueRAR: You can not write an valid entry! check: ldu $w,
      robIdx $debug_robIdx\")\n190:   }\n191: \n192:   //  LoadQueueRAR deallocate\n\
      193:   val freeMaskVec = Wire(Vec(LoadQueueRARSize, Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 197-209
    context: "197: \n198:   // when the loads that \"older than\" current load were
      writebacked,\n199:   // current load will be released.\n200:   for (i <- 0 until
      LoadQueueRARSize) {\n201:     val deqNotBlock = !isBefore(io.ldWbPtr, uop(i).lqIdx)\n\
      202:     val needFlush = uop(i).robIdx.needFlush(io.redirect)\n203: \n204: \
      \    when (allocated(i) && (deqNotBlock || needFlush)) {\n205:       allocated(i)
      := false.B\n206:       freeMaskVec(i) := true.B\n207:     }\n208:   }\n209: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 207-221
    context: "207:     }\n208:   }\n209: \n210:   // if need replay revoke entry\n\
      211:   val lastCanAccept = GatedRegNext(acceptedVec)\n212:   val lastAllocIndex
      = GatedRegNext(enqIndexVec)\n213: \n214:   for ((revoke, w) <- io.query.map(_.revoke).zipWithIndex)
      {\n215:     val revokeValid = revoke && lastCanAccept(w)\n216:     val revokeIndex
      = lastAllocIndex(w)\n217: \n218:     when (allocated(revokeIndex) && revokeValid)
      {\n219:       allocated(revokeIndex) := false.B\n220:       freeMaskVec(revokeIndex)
      := true.B\n221:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 219-229
    context: "219:       allocated(revokeIndex) := false.B\n220:       freeMaskVec(revokeIndex)
      := true.B\n221:     }\n222:   }\n223: \n224:   freeList.io.free := freeMaskVec.asUInt\n\
      225: \n226:   // LoadQueueRAR Query\n227:   // Load-to-Load violation check
      condition:\n228:   // 1. Physical address match by CAM port.\n229:   // 2. release
      or nc_with_data is set."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 234-244
    context: "234:     ldLdViolation(w) := false.B\n235:     paddrModule.io.releaseViolationMdata(w)
      := genPartialPAddr(query.req.bits.paddr)\n236: \n237:     query.resp.valid :=
      RegNext(query.req.valid)\n238:     // Generate real violation mask\n239:   \
      \  val robIdxMask = VecInit(uop.map(_.robIdx).map(isAfter(_, query.req.bits.uop.robIdx)))\n\
      240:     val matchMaskReg = Wire(Vec(LoadQueueRARSize, Bool()))\n241:     for(i
      <- 0 until LoadQueueRARSize) {\n242:       matchMaskReg(i) := (allocated(i)
      &\n243:                          paddrModule.io.releaseViolationMmask(w)(i)
      &\n244:                          robIdxMask(i) &&"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 269-279
    context: "269: \n270:   io.lqFull := freeList.io.empty\n271:   io.validCount :=
      freeList.io.validCount\n272: \n273:   // perf cnt\n274:   val canEnqCount =
      PopCount(io.query.map(_.req.fire))\n275:   val validCount = freeList.io.validCount\n\
      276:   val allowEnqueue = validCount <= (LoadQueueRARSize - LoadPipelineWidth).U\n\
      277:   val ldLdViolationCount = PopCount(io.query.map(_.resp).map(resp => resp.valid
      && resp.bits.rep_frm_fetch))\n278: \n279:   QueuePerf(LoadQueueRARSize, validCount,
      !allowEnqueue)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 156-166
    context: "156:   with HasCircularQueuePtrHelper\n157:   with HasLoadHelper\n158:\
      \   with HasPerfEvents\n159: {\n160:   val io = IO(new Bundle() {\n161:    \
      \ val redirect = Flipped(Valid(new Redirect))\n162:     val vecFeedback = Vec(VecLoadPipelineWidth,
      Flipped(ValidIO(new FeedbackToLsqIO)))\n163:     val enq = new LqEnqIO\n164:\
      \     val ldu = new Bundle() {\n165:         val stld_nuke_query = Vec(LoadPipelineWidth,
      Flipped(new LoadNukeQueryIO)) // from load_s2\n166:         val ldld_nuke_query
      = Vec(LoadPipelineWidth, Flipped(new LoadNukeQueryIO)) // from load_s2"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 181-196
    context: "181:       val sqEmpty          = Input(Bool())\n182:     }\n183:  \
      \   val ldout = Vec(LoadPipelineWidth, DecoupledIO(new MemExuOutput))\n184:\
      \     val ld_raw_data = Vec(LoadPipelineWidth, Output(new LoadDataFromLQBundle))\n\
      185:     val ncOut = Vec(LoadPipelineWidth, DecoupledIO(new LsPipelineBundle))\n\
      186:     val replay = Vec(LoadPipelineWidth, Decoupled(new LsPipelineBundle))\n\
      187:   //  val refill = Flipped(ValidIO(new Refill))\n188:     val tl_d_channel\
      \  = Input(new DcacheToLduForwardIO)\n189:     val release = Flipped(Valid(new
      Release))\n190:     val nuke_rollback = Vec(StorePipelineWidth, Output(Valid(new
      Redirect)))\n191:     val nack_rollback = Vec(1, Output(Valid(new Redirect)))
      // uncachebuffer\n192:     val rob = Flipped(new RobLsqIO)\n193:     val uncache
      = new UncacheWordIO\n194:     val exceptionAddr = new ExceptionAddrIO\n195:\
      \     val loadMisalignFull = Input(Bool())\n196:     val misalignAllowSpec =
      Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 209-222
    context: "209: \n210:     val debugTopDown = new LoadQueueTopDownIO\n211:    \
      \ val noUopsIssed = Input(Bool())\n212:   })\n213: \n214:   val loadQueueRAR
      = Module(new LoadQueueRAR)  //  read-after-read violation\n215:   val loadQueueRAW
      = Module(new LoadQueueRAW)  //  read-after-write violation\n216:   val loadQueueReplay
      = Module(new LoadQueueReplay)  //  enqueue if need replay\n217:   val virtualLoadQueue
      = Module(new VirtualLoadQueue)  //  control state\n218:   val exceptionBuffer
      = Module(new LqExceptionBuffer) // exception buffer\n219:   val uncacheBuffer
      = Module(new LoadQueueUncache) // uncache\n220:   /**\n221:    * LoadQueueRAR\n\
      222:    */"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 218-228
    context: "218:   val exceptionBuffer = Module(new LqExceptionBuffer) // exception
      buffer\n219:   val uncacheBuffer = Module(new LoadQueueUncache) // uncache\n\
      220:   /**\n221:    * LoadQueueRAR\n222:    */\n223:   loadQueueRAR.io.redirect\
      \  <> io.redirect\n224:   loadQueueRAR.io.release   <> io.release\n225:   loadQueueRAR.io.ldWbPtr\
      \   <> virtualLoadQueue.io.ldWbPtr\n226:   loadQueueRAR.io.validCount<> io.rarValidCount\n\
      227:   for (w <- 0 until LoadPipelineWidth) {\n228:     loadQueueRAR.io.query(w).req\
      \    <> io.ldu.ldld_nuke_query(w).req // from load_s1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 231-241
    context: "231:   }\n232: \n233:   /**\n234:    * LoadQueueRAW\n235:    */\n236:\
      \   loadQueueRAW.io.redirect         <> io.redirect\n237:   loadQueueRAW.io.storeIn\
      \          <> io.sta.storeAddrIn\n238:   loadQueueRAW.io.stAddrReadySqPtr <>
      io.sq.stAddrReadySqPtr\n239:   loadQueueRAW.io.stIssuePtr       <> io.sq.stIssuePtr\n\
      240:   for (w <- 0 until LoadPipelineWidth) {\n241:     loadQueueRAW.io.query(w).req\
      \    <> io.ldu.stld_nuke_query(w).req // from load_s1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 244-255
    context: "244:   }\n245: \n246:   /**\n247:    * VirtualLoadQueue\n248:    */\n\
      249:   virtualLoadQueue.io.redirect      <> io.redirect\n250:   virtualLoadQueue.io.vecCommit\
      \     <> io.vecFeedback\n251:   virtualLoadQueue.io.enq           <> io.enq\n\
      252:   virtualLoadQueue.io.ldin          <> io.ldu.ldin // from load_s3\n253:\
      \   virtualLoadQueue.io.lqFull        <> io.lqFull\n254:   virtualLoadQueue.io.lqDeq\
      \         <> io.lqDeq\n255:   virtualLoadQueue.io.lqCancelCnt   <> io.lqCancelCnt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 257-267
    context: "257:   virtualLoadQueue.io.ldWbPtr       <> io.lqDeqPtr\n258: \n259:\
      \   /**\n260:    * Load queue exception buffer\n261:    */\n262:   exceptionBuffer.io.redirect
      <> io.redirect\n263:   for (i <- 0 until LoadPipelineWidth) {\n264:     exceptionBuffer.io.req(i).valid
      := io.ldu.ldin(i).valid && !io.ldu.ldin(i).bits.isvec // from load_s3\n265:\
      \     exceptionBuffer.io.req(i).bits := io.ldu.ldin(i).bits\n266:   }\n267:\
      \   // vlsu exception!"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 264-274
    context: "264:     exceptionBuffer.io.req(i).valid := io.ldu.ldin(i).valid &&
      !io.ldu.ldin(i).bits.isvec // from load_s3\n265:     exceptionBuffer.io.req(i).bits
      := io.ldu.ldin(i).bits\n266:   }\n267:   // vlsu exception!\n268:   for (i <-
      0 until VecLoadPipelineWidth) {\n269:     exceptionBuffer.io.req(LoadPipelineWidth
      + i).valid                 := io.vecFeedback(i).valid && io.vecFeedback(i).bits.feedback(VecFeedbacks.FLUSH)
      // have exception\n270:     exceptionBuffer.io.req(LoadPipelineWidth + i).bits\
      \                  := DontCare\n271:     exceptionBuffer.io.req(LoadPipelineWidth
      + i).bits.vaddr            := io.vecFeedback(i).bits.vaddr\n272:     exceptionBuffer.io.req(LoadPipelineWidth
      + i).bits.fullva           := io.vecFeedback(i).bits.vaddr\n273:     exceptionBuffer.io.req(LoadPipelineWidth
      + i).bits.vaNeedExt        := io.vecFeedback(i).bits.vaNeedExt\n274:     exceptionBuffer.io.req(LoadPipelineWidth
      + i).bits.gpaddr           := io.vecFeedback(i).bits.gpaddr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 288-301
    context: "288:   io.exceptionAddr <> exceptionBuffer.io.exceptionAddr\n289: \n\
      290:   /**\n291:    * Load uncache buffer\n292:    */\n293:   uncacheBuffer.io.redirect
      <> io.redirect\n294:   uncacheBuffer.io.mmioOut <> io.ldout\n295:   uncacheBuffer.io.ncOut
      <> io.ncOut\n296:   uncacheBuffer.io.mmioRawData <> io.ld_raw_data\n297:   uncacheBuffer.io.rob
      <> io.rob\n298:   uncacheBuffer.io.uncache <> io.uncache\n299: \n300:   for
      ((buff, w) <- uncacheBuffer.io.req.zipWithIndex) {\n301:     // from load_s3"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 302-312
    context: "302:     val ldinBits = io.ldu.ldin(w).bits\n303:     buff.valid :=
      io.ldu.ldin(w).valid && !ldinBits.nc_with_data\n304:     buff.bits := ldinBits\n\
      305:   }\n306: \n307:   io.uncache.resp.ready := true.B\n308: \n309:   io.nuke_rollback
      := loadQueueRAW.io.rollback\n310:   io.nack_rollback(0) := uncacheBuffer.io.rollback\n\
      311: \n312:   /* <------- DANGEROUS: Don't change sequence here ! -------> */"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 312-326
    context: "312:   /* <------- DANGEROUS: Don't change sequence here ! ------->
      */\n313: \n314:   /**\n315:    * LoadQueueReplay\n316:    */\n317:   loadQueueReplay.io.redirect\
      \         <> io.redirect\n318:   loadQueueReplay.io.enq              <> io.ldu.ldin
      // from load_s3\n319:   loadQueueReplay.io.storeAddrIn      <> io.sta.storeAddrIn
      // from store_s1\n320:   loadQueueReplay.io.storeDataIn      <> io.std.storeDataIn
      // from store_s0\n321:   loadQueueReplay.io.replay           <> io.replay\n\
      322:   //loadQueueReplay.io.refill           <> io.refill\n323:   loadQueueReplay.io.tl_d_channel\
      \     <> io.tl_d_channel\n324:   loadQueueReplay.io.stAddrReadySqPtr <> io.sq.stAddrReadySqPtr\n\
      325:   loadQueueReplay.io.stAddrReadyVec   <> io.sq.stAddrReadyVec\n326:   loadQueueReplay.io.stDataReadySqPtr
      <> io.sq.stDataReadySqPtr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 76-91
    context: "76:         res(i).valid := valid(i)\n77:         res(i).bits := bits(i)\n\
      78:         resIndex(i) := index(i)\n79:       }\n80:       val oldest = Mux(valid(0)
      && valid(1),\n81:         Mux(isAfter(bits(0).uop.robIdx, bits(1).uop.robIdx)
      ||\n82:           (isNotBefore(bits(0).uop.robIdx, bits(1).uop.robIdx) && bits(0).uop.uopIdx
      > bits(1).uop.uopIdx), res(1), res(0)),\n83:         Mux(valid(0) && !valid(1),
      res(0), res(1)))\n84: \n85:       val oldestIndex = Mux(valid(0) && valid(1),\n\
      86:         Mux(isAfter(bits(0).uop.robIdx, bits(1).uop.robIdx) ||\n87:    \
      \       (bits(0).uop.robIdx === bits(1).uop.robIdx && bits(0).uop.uopIdx > bits(1).uop.uopIdx),
      resIndex(1), resIndex(0)),\n88:         Mux(valid(0) && !valid(1), resIndex(0),
      resIndex(1)))\n89:       (Seq(oldest.valid), Seq(oldest.bits), Seq(oldestIndex))\n\
      90:     } else {\n91:       val left = selectOldest(valid.take(valid.length
      / 2), bits.take(bits.length / 2), index.take(index.length / 2))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 93-103
    context: "93:       selectOldest(left._1 ++ right._1, left._2 ++ right._2, left._3
      ++ right._3)\n94:     }\n95:   }\n96: \n97:   val io = IO(new Bundle() {\n98:\
      \     val redirect        = Flipped(Valid(new Redirect))\n99:     val enq  \
      \           = Vec(enqPortNum, Flipped(new MisalignBufferEnqIO))\n100:     val
      rob             = Flipped(new RobLsqIO)\n101:     val splitStoreReq   = Decoupled(new
      LsPipelineBundle)\n102:     val splitStoreResp  = Flipped(Valid(new SqWriteBundle))\n\
      103:     val writeBack       = Decoupled(new MemExuOutput)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 115-125
    context: "115: \n116:     val toVecStoreMergeBuffer = Vec(VecStorePipelineWidth,
      new StoreMaBufToVecStoreMergeBufferIO)\n117:     val full = Bool()\n118:   })\n\
      119: \n120:   io.rob.mmio := 0.U.asTypeOf(Vec(LoadPipelineWidth, Bool()))\n\
      121:   io.rob.uop  := 0.U.asTypeOf(Vec(LoadPipelineWidth, new DynInst))\n122:\
      \ \n123:   class StoreMisalignBufferEntry(implicit p: Parameters) extends LsPipelineBundle
      {\n124:     val portIndex = UInt(log2Up(enqPortNum).W)\n125:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 140-153
    context: "140:   val bufferState    = RegInit(s_idle)\n141: \n142:   // enqueue\n\
      143:   // s1:\n144:   val s1_req = VecInit(io.enq.map(_.req.bits))\n145:   val
      s1_valid = VecInit(io.enq.map(x => x.req.valid))\n146: \n147:   val s1_index
      = (0 until io.enq.length).map(_.asUInt)\n148:   val reqSel = selectOldest(s1_valid,
      s1_req, s1_index)\n149: \n150:   val reqSelValid = reqSel._1(0)\n151:   val
      reqSelBits  = reqSel._2(0)\n152:   val reqSelPort  = reqSel._3(0)\n153: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 149-162
    context: "149: \n150:   val reqSelValid = reqSel._1(0)\n151:   val reqSelBits\
      \  = reqSel._2(0)\n152:   val reqSelPort  = reqSel._3(0)\n153: \n154:   val
      reqRedirect = reqSelBits.uop.robIdx.needFlush(io.redirect)\n155: \n156:   val
      canEnq = WireInit(false.B)\n157:   canEnq := !req_valid && !reqRedirect && reqSelValid\n\
      158:   val robMatch = req_valid && io.rob.pendingst && (io.rob.pendingPtr ===
      req.uop.robIdx)\n159: \n160:   val s2_canEnq = GatedRegNext(canEnq)\n161:  \
      \ val s2_reqSelPort = GatedRegNext(reqSelPort)\n162:   val s2_needRevoke = s2_canEnq
      && (0 until enqPortNum).map {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 167-180
    context: "167:     connectSamePort(req, reqSelBits)\n168:     req.portIndex :=
      reqSelPort\n169:     req_valid := true.B\n170:   }\n171:   val cross4KBPageEnq
      = WireInit(false.B)\n172:   when (cross4KBPageBoundary && !reqRedirect) {\n\
      173:     when(\n174:       reqSelValid &&\n175:       (isAfter(req.uop.robIdx,
      reqSelBits.uop.robIdx) || (isNotBefore(req.uop.robIdx, reqSelBits.uop.robIdx)
      && req.uop.uopIdx > reqSelBits.uop.uopIdx)) &&\n176:       bufferState === s_idle\n\
      177:     ) {\n178:       connectSamePort(req, reqSelBits)\n179:       req.portIndex
      := reqSelPort\n180:       cross4KBPageEnq := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 187-202
    context: "187:   }\n188: \n189:   val reqSelCanEnq = UIntToOH(reqSelPort)\n190:\
      \ \n191:   io.enq.zipWithIndex.map{\n192:     case (reqPort, index) => reqPort.req.ready
      := reqSelCanEnq(index) && (!req_valid || cross4KBPageBoundary && cross4KBPageEnq)\n\
      193:   }\n194: \n195:   io.toVecStoreMergeBuffer.zipWithIndex.map{\n196:   \
      \  case (toStMB, index) => {\n197:       toStMB.flush   := req_valid && cross4KBPageBoundary
      && cross4KBPageEnq && UIntToOH(req.portIndex)(index)\n198:       toStMB.mbIndex
      := req.mbIndex\n199:     }\n200:   }\n201:   io.full := req_valid\n202: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 218-228
    context: "218:   val globalNC   = RegInit(false.B)\n219:   val globalMemBackTypeMM
      = RegInit(false.B)\n220: \n221:   val hasException = io.splitStoreResp.bits.vecActive
      && !io.splitStoreResp.bits.need_rep &&\n222:     ExceptionNO.selectByFu(io.splitStoreResp.bits.uop.exceptionVec,
      StaCfg).asUInt.orR || TriggerAction.isDmode(io.splitStoreResp.bits.uop.trigger)\n\
      223:   val isUncache = (io.splitStoreResp.bits.mmio || io.splitStoreResp.bits.nc)
      && !io.splitStoreResp.bits.need_rep\n224: \n225:   io.sqControl.toStoreQueue.crossPageWithHit
      := io.sqControl.toStoreMisalignBuffer.sqPtr === req.uop.sqIdx && isCrossPage\n\
      226:   io.sqControl.toStoreQueue.crossPageCanDeq := !isCrossPage || bufferState
      === s_block\n227:   io.sqControl.toStoreQueue.paddr := Cat(splitStoreResp(1).paddr(splitStoreResp(1).paddr.getWidth
      - 1, 3), 0.U(3.W))\n228: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 247-257
    context: "247:     is (s_split) {\n248:       bufferState := s_req\n249:     }\n\
      250: \n251:     is (s_req) {\n252:       when (io.splitStoreReq.fire) {\n253:\
      \         bufferState := s_resp\n254:       }\n255:     }\n256: \n257:     is
      (s_resp) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 263-273
    context: "263:           // commit directly when exception ocurs\n264:       \
      \    // if any split store reaches mmio space, delegate to software storeAddrMisaligned
      exception\n265:           bufferState := s_wb\n266:           globalException
      := hasException\n267:           globalUncache := isUncache\n268:           globalMMIO
      := io.splitStoreResp.bits.mmio\n269:           globalNC   := io.splitStoreResp.bits.nc\n\
      270:           globalMemBackTypeMM := io.splitStoreResp.bits.memBackTypeMM\n\
      271:         } .elsewhen(io.splitStoreResp.bits.need_rep || (unSentStores &
      (~clearOh).asUInt).orR) {\n272:           // need replay or still has unsent
      requests\n273:           bufferState := s_req"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 284-294
    context: "284:       }\n285:     }\n286: \n287:     is (s_wb) {\n288:       when
      (req.isvec) {\n289:         when (io.vecWriteBack.map(x => x.fire).reduce( _
      || _)) {\n290:           bufferState := s_idle\n291:           req_valid :=
      false.B\n292:           curPtr := 0.U\n293:           unSentStores := 0.U\n\
      294:           unWriteStores := 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 301-311
    context: "301:           globalNC   := false.B\n302:           globalMemBackTypeMM
      := false.B\n303:         }\n304: \n305:       }.otherwise {\n306:         when
      (io.writeBack.fire && (!isCrossPage || globalUncache || globalException)) {\n\
      307:           bufferState := s_idle\n308:           req_valid := false.B\n\
      309:           curPtr := 0.U\n310:           unSentStores := 0.U\n311:     \
      \      unWriteStores := 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 315-325
    context: "315:           needFlushPipe := false.B\n316: \n317:           globalMMIO
      := false.B\n318:           globalNC   := false.B\n319:           globalMemBackTypeMM
      := false.B\n320:         } .elsewhen(io.writeBack.fire && isCrossPage) {\n321:\
      \           bufferState := s_block\n322:         } .otherwise {\n323:      \
      \     bufferState := s_wb\n324:         }\n325: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 602-616
    context: "602: \n603:   io.writeBack.valid := req_valid && (bufferState === s_wb)
      && !io.storeOutValid && !req.isvec\n604:   io.writeBack.bits.uop := req.uop\n\
      605:   io.writeBack.bits.uop.exceptionVec := DontCare\n606:   StaCfg.exceptionOut.map(no
      => io.writeBack.bits.uop.exceptionVec(no) := (globalUncache || globalException)
      && exceptionVec(no))\n607:   io.writeBack.bits.uop.flushPipe := needFlushPipe\n\
      608:   io.writeBack.bits.uop.replayInst := false.B\n609:   io.writeBack.bits.data
      := DontCare\n610:   io.writeBack.bits.isFromLoadUnit := DontCare\n611:   io.writeBack.bits.debug.isMMIO
      := globalMMIO\n612:   io.writeBack.bits.debug.isNCIO := globalNC && !globalMemBackTypeMM\n\
      613:   io.writeBack.bits.debug.isPerfCnt := false.B\n614:   io.writeBack.bits.debug.paddr
      := req.paddr\n615:   io.writeBack.bits.debug.vaddr := req.vaddr\n616: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 620-632
    context: "620: \n621:       wb.bits.mBIndex           := req.mbIndex\n622:   \
      \    wb.bits.hit               := true.B\n623:       wb.bits.isvec         \
      \    := true.B\n624:       wb.bits.sourceType        := RSFeedbackType.tlbMiss\n\
      625:       wb.bits.flushState        := DontCare\n626:       wb.bits.trigger\
      \           := TriggerAction.None\n627:       wb.bits.mmio              := globalMMIO\n\
      628:       wb.bits.exceptionVec      := ExceptionNO.selectByFu(exceptionVec,
      VstuCfg)\n629:       wb.bits.hasException      := globalException\n630:    \
      \   wb.bits.usSecondInv       := req.usSecondInv\n631:       wb.bits.vecFeedback\
      \       := true.B\n632:       wb.bits.elemIdx           := req.elemIdx"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 640-655
    context: "640:       wb.bits.vecTriggerMask    := 0.U\n641:       wb.bits.nc \
      \               := globalNC\n642:     }\n643:   }\n644: \n645:   val flush =
      req_valid && req.uop.robIdx.needFlush(io.redirect)\n646: \n647:   when (flush
      || s2_needRevoke) {\n648:     bufferState := s_idle\n649:     req_valid := Mux(\n\
      650:       cross4KBPageEnq && cross4KBPageBoundary && !reqRedirect && !s2_needRevoke,\n\
      651:       req_valid, // when s2_needRevoke is true, previous request is valid,
      so req_valid = true\n652:       false.B\n653:     )\n654:     curPtr := 0.U\n\
      655:     unSentStores := 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 680-688
    context: "680:   io.overwriteExpBuf.isHyper := overwriteIsHyper\n681:   io.overwriteExpBuf.gpaddr
      := overwriteGpaddr\n682:   io.overwriteExpBuf.isForVSnonLeafPTE := overwriteIsForVSnonLeafPTE\n\
      683: \n684:   XSPerfAccumulate(\"alloc\",                  RegNext(!req_valid)
      && req_valid)\n685:   XSPerfAccumulate(\"flush\",                  flush)\n\
      686:   XSPerfAccumulate(\"flush_idle\",             flush && (bufferState ===
      s_idle))\n687:   XSPerfAccumulate(\"flush_non_idle\",         flush && (bufferState
      =/= s_idle))\n688: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueData.scala
    lines: 30-40
    context: "30: // Data module define\n31: // These raw data modules are like SyncDataModuleTemplate,
      but support cam-like ops\n32: abstract class LqRawDataModule[T <: Data] (\n\
      33:   gen: T,\n34:   numEntries: Int,\n35:   numRead: Int,\n36:   numWrite:
      Int,\n37:   numWBank: Int,\n38:   numWDelay: Int,\n39:   numCamPort: Int = 0,\n\
      40:   enableCacheLineCheck: Boolean = false"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueData.scala
    lines: 38-50
    context: "38:   numWDelay: Int,\n39:   numCamPort: Int = 0,\n40:   enableCacheLineCheck:
      Boolean = false\n41: )(implicit p: Parameters) extends XSModule {\n42:   val
      io = IO(new Bundle() {\n43:     val ren   = Input(Vec(numRead, Bool()))\n44:\
      \     val raddr = Input(Vec(numRead, UInt(log2Up(numEntries).W)))\n45:     val
      rdata = Output(Vec(numRead, gen))\n46:     val wen   = Input(Vec(numWrite, Bool()))\n\
      47:     val waddr = Input(Vec(numWrite, UInt(log2Up(numEntries).W)))\n48:  \
      \   val wdata = Input(Vec(numWrite, gen))\n49:     // violation cam: hit if
      addr is in the same cacheline\n50:     val violationMdata = Input(Vec(numCamPort,
      gen)) // addr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueData.scala
    lines: 68-78
    context: "68:   val numEntryPerBank = numEntries / numWBank\n69:   val dataWidth
      = gen.getWidth\n70: \n71:   val data = Reg(Vec(numEntries, gen))\n72:   // read
      ports\n73:   for (i <- 0 until numRead) {\n74:     io.rdata(i) := RegEnable(data(io.raddr(i)),
      io.ren(i))\n75:   }\n76: \n77:   // write ports\n78:   val writeAddrDec = io.waddr.map(a
      => UIntToOH(a))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueData.scala
    lines: 89-102
    context: "89:     )\n90:     s0_bankWriteEn.zipWithIndex.map(a =>\n91:       a._1.suggestName(\"\
      s0_bankWriteEn\" + bank + \"_\" + a._2)\n92:     )\n93:     // sx: write data
      to entries\n94:     val sx_bankWriteAddrDec_resp = (0 until numWrite).map(w
      => DelayNWithValid(s0_bankWriteAddrDec(w), io.wen(w), numWDelay - 1))\n95: \
      \    val sx_bankWriteAddrDec = (0 until numWrite).map(w => sx_bankWriteAddrDec_resp(w)._2)\n\
      96:     val sx_bankWriteEn = s0_bankWriteEn.map(w => DelayN(w, numWDelay - 1))\n\
      97:      val sx_writeData_resp = (0 until numWrite).map(w => DelayNWithValid(io.wdata(w),
      io.wen(w), numWDelay - 1))\n98:      val sx_writeData =  (0 until numWrite).map(w
      => sx_writeData_resp(w)._2)\n99: \n100:     sx_bankWriteAddrDec.zipWithIndex.map(a
      =>\n101:       a._1.suggestName(\"sx_bankWriteAddrDec\" + bank + \"_\" + a._2)\n\
      102:     )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueData.scala
    lines: 134-144
    context: "134: \n135: // Load queue physical address module\n136: class LqPAddrModule[T
      <: UInt](\n137:   gen: T,\n138:   numEntries: Int,\n139:   numRead: Int,\n140:\
      \   numWrite: Int,\n141:   numWBank: Int,\n142:   numWDelay: Int = 1,\n143:\
      \   numCamPort: Int = 1,\n144:   enableCacheLineCheck: Boolean = false, // Check
      the entire cacheline. when enabled, set `paddrOffset` correctly."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueData.scala
    lines: 141-151
    context: "141:   numWBank: Int,\n142:   numWDelay: Int = 1,\n143:   numCamPort:
      Int = 1,\n144:   enableCacheLineCheck: Boolean = false, // Check the entire
      cacheline. when enabled, set `paddrOffset` correctly.\n145:   paddrOffset: Int
      // The least significant `paddrOffset` bits of paddr are neglected.\n146: )(implicit
      p: Parameters) extends LqRawDataModule(gen, numEntries, numRead, numWrite, numWBank,
      numWDelay, numCamPort, enableCacheLineCheck)\n147:   with HasDCacheParameters\n\
      148: {\n149:   // content addressed match\n150:   // 128-bits aligned\n151:\
      \   val needCacheLineCheck = enableCacheLineCheck && DCacheLineOffset > paddrOffset"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueData.scala
    lines: 182-196
    context: "182: \n183: // Load queue data module\n184: class LqVAddrModule[T <:
      UInt](\n185:   gen: T,\n186:   numEntries: Int,\n187:   numRead: Int,\n188:\
      \   numWrite: Int,\n189:   numWBank: Int,\n190:   numWDelay: Int = 1,\n191:\
      \   numCamPort: Int = 1)(implicit p: Parameters) extends LqRawDataModule(gen,
      numEntries, numRead, numWrite, numWBank, numWDelay, numCamPort)\n192:   with
      HasDCacheParameters\n193: {\n194:   // content addressed match\n195:   for (i
      <- 0 until numCamPort) {\n196:     for (j <- 0 until numEntries) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueData.scala
    lines: 208-222
    context: "208: \n209: // Load queue mask module\n210: class LqMaskModule[T <:
      UInt](\n211:   gen: T,\n212:   numEntries: Int,\n213:   numRead: Int,\n214:\
      \   numWrite: Int,\n215:   numWBank: Int,\n216:   numWDelay: Int = 1,\n217:\
      \   numCamPort: Int = 1)(implicit p: Parameters) extends LqRawDataModule(gen,
      numEntries, numRead, numWrite, numWBank, numWDelay, numCamPort)\n218:   with
      HasDCacheParameters\n219: {\n220:   // content addressed match\n221:   for (i
      <- 0 until numCamPort) {\n222:     for (j <- 0 until numEntries) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueueData.scala
    lines: 28-43
    context: "28: import xiangshan.backend.rob.RobPtr\n29: \n30: \n31: // Data module
      define\n32: // These data modules are like SyncDataModuleTemplate, but support
      cam-like ops\n33: class SQAddrModule(dataWidth: Int, numEntries: Int, numRead:
      Int, numWrite: Int, numForward: Int)(implicit p: Parameters) extends XSModule
      with HasDCacheParameters {\n34:   val io = IO(new Bundle {\n35:     // sync
      read\n36:     val raddr = Input(Vec(numRead, UInt(log2Up(numEntries).W)))\n\
      37:     val rdata = Output(Vec(numRead, UInt(dataWidth.W))) // rdata: store
      addr\n38:     val rlineflag = Output(Vec(numRead, Bool())) // rdata: line op
      flag\n39:     // write\n40:     val wen   = Input(Vec(numWrite, Bool()))\n41:\
      \     val waddr = Input(Vec(numWrite, UInt(log2Up(numEntries).W)))\n42:    \
      \ val wdata = Input(Vec(numWrite, UInt(dataWidth.W))) // wdata: store addr\n\
      43:     val wmask = Input(Vec(numWrite, UInt((VLEN/8).W)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueueData.scala
    lines: 42-52
    context: "42:     val wdata = Input(Vec(numWrite, UInt(dataWidth.W))) // wdata:
      store addr\n43:     val wmask = Input(Vec(numWrite, UInt((VLEN/8).W)))\n44:\
      \     val wlineflag = Input(Vec(numWrite, Bool())) // wdata: line op flag\n\
      45:     // forward addr cam\n46:     val forwardMdata = Input(Vec(numForward,
      UInt(dataWidth.W))) // addr\n47:     val forwardDataMask = Input(Vec(numForward,
      UInt((VLEN/8).W))) // forward mask\n48:     val forwardMmask = Output(Vec(numForward,
      Vec(numEntries, Bool()))) // cam result mask\n49:     // debug\n50:     val
      debug_data = Output(Vec(numEntries, UInt(dataWidth.W)))\n51:   })\n52: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueueData.scala
    lines: 55-65
    context: "55:   val lineflag = Reg(Vec(numEntries, Bool())) // cache line match
      flag\n56:   // if lineflag == true, this address points to a whole cacheline\n\
      57:   io.debug_data := data\n58: \n59:   // read ports\n60:   for (i <- 0 until
      numRead) {\n61:     io.rdata(i) := data(GatedRegNext(io.raddr(i)))\n62:    \
      \ io.rlineflag(i) := lineflag(GatedRegNext(io.raddr(i)))\n63:   }\n64: \n65:\
      \   // below is the write ports (with priorities)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueueData.scala
    lines: 93-103
    context: "93: class SQData8Entry(implicit p: Parameters) extends XSBundle {\n\
      94:   val valid = Bool() // this byte is valid\n95:   val data = UInt((XLEN/8).W)\n\
      96: }\n97: \n98: class SQData8Module(numEntries: Int, numRead: Int, numWrite:
      Int, numForward: Int)(implicit p: Parameters) extends XSModule\n99:   with HasDCacheParameters\n\
      100:   with HasCircularQueuePtrHelper\n101: {\n102:   val io = IO(new Bundle()
      {\n103:     // sync read port"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueueData.scala
    lines: 99-110
    context: "99:   with HasDCacheParameters\n100:   with HasCircularQueuePtrHelper\n\
      101: {\n102:   val io = IO(new Bundle() {\n103:     // sync read port\n104:\
      \     val raddr = Vec(numRead, Input(UInt(log2Up(numEntries).W)))\n105:    \
      \ val rdata = Vec(numRead, Output(new SQData8Entry))\n106:     // data write
      port\n107:     val data = new Bundle() {\n108:       val wen   = Vec(numWrite,
      Input(Bool()))\n109:       val waddr = Vec(numWrite, Input(UInt(log2Up(numEntries).W)))\n\
      110:       val wdata = Vec(numWrite, Input(UInt((XLEN/8).W)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueueData.scala
    lines: 199-209
    context: "199:       s1_waddr.suggestName(\"mask_s1_waddr_\" + i +\"_bank_\" +
      bank)\n200:     })\n201:   })\n202: \n203:   // destorequeue read data\n204:\
      \   (0 until numRead).map(i => {\n205:       io.rdata(i) := data(GatedRegNext(io.raddr(i)))\n\
      206:   })\n207: \n208:   // DataModuleTemplate should not be used when there're
      any write conflicts\n209:   for (i <- 0 until numWrite) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueueData.scala
    lines: 273-287
    context: "273:   val mask = UInt((VLEN/8).W)\n274:   val data = UInt(VLEN.W)\n\
      275: }\n276: \n277: // SQDataModule is a wrapper of SQData8Modules\n278: class
      SQDataModule(numEntries: Int, numRead: Int, numWrite: Int, numForward: Int)(implicit
      p: Parameters) extends XSModule with HasDCacheParameters with HasCircularQueuePtrHelper
      {\n279:   val io = IO(new Bundle() {\n280:     // sync read port\n281:     val
      raddr = Vec(numRead,  Input(UInt(log2Up(numEntries).W)))\n282:     val rdata
      = Vec(numRead,  Output(new SQDataEntry))\n283:     // data write port\n284:\
      \     val data = new Bundle() {\n285:       val wen   = Vec(numWrite, Input(Bool()))\n\
      286:       val waddr = Vec(numWrite, Input(UInt(log2Up(numEntries).W)))\n287:\
      \       val wdata = Vec(numWrite, Input(UInt(VLEN.W)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueueData.scala
    lines: 300-310
    context: "300:     // forward result generated in the next cycle\n301:     val
      forwardMask = Vec(numForward, Output(Vec((VLEN/8), Bool()))) // forwardMask
      = RegNext(forwardMaskFast)\n302:     val forwardData = Vec(numForward, Output(Vec((VLEN/8),
      UInt(8.W))))\n303:   })\n304: \n305:   val data16 = Seq.fill(16)(Module(new
      SQData8Module(numEntries, numRead, numWrite, numForward)))\n306: \n307:   //
      writeback to lq/sq\n308:   for (i <- 0 until numWrite) {\n309:     // write
      to data16\n310:     for (j <- 0 until 16) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueueData.scala
    lines: 316-326
    context: "316:       data16(j).io.data.wen(i)   := io.data.wen(i)\n317:     }\n\
      318:   }\n319: \n320:   // destorequeue read data\n321:   for (i <- 0 until
      numRead) {\n322:     for (j <- 0 until 16) {\n323:       data16(j).io.raddr(i)
      := io.raddr(i)\n324:     }\n325:     io.rdata(i).mask := VecInit((0 until 16).map(j
      => data16(j).io.rdata(i).valid)).asUInt\n326:     io.rdata(i).data := VecInit((0
      until 16).map(j => data16(j).io.rdata(i).data)).asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 101-111
    context: "101:       for (i <- res.indices) {\n102:         res(i).valid := valid(i)\n\
      103:         res(i).bits := bits(i)\n104:       }\n105:       val oldest = Mux(valid(0)
      && valid(1),\n106:         Mux(isAfter(bits(0).uop.robIdx, bits(1).uop.robIdx)
      ||\n107:           (bits(0).uop.robIdx === bits(1).uop.robIdx && bits(0).uop.uopIdx
      > bits(1).uop.uopIdx), res(1), res(0)),\n108:         Mux(valid(0) && !valid(1),
      res(0), res(1)))\n109:       (Seq(oldest.valid), Seq(oldest.bits))\n110:   \
      \  } else {\n111:       val left = selectOldest(valid.take(valid.length / 2),
      bits.take(bits.length / 2))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 113-123
    context: "113:       selectOldest(left._1 ++ right._1, left._2 ++ right._2)\n\
      114:     }\n115:   }\n116: \n117:   val io = IO(new Bundle() {\n118:     val
      redirect        = Flipped(Valid(new Redirect))\n119:     val enq           \
      \  = Vec(enqPortNum, Flipped(new MisalignBufferEnqIO))\n120:     val rob   \
      \          = Flipped(new RobLsqIO)\n121:     val splitLoadReq    = Decoupled(new
      LsPipelineBundle)\n122:     val splitLoadResp   = Flipped(Valid(new LqWriteBundle))\n\
      123:     val writeBack       = Decoupled(new MemExuOutput)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 120-130
    context: "120:     val rob             = Flipped(new RobLsqIO)\n121:     val splitLoadReq\
      \    = Decoupled(new LsPipelineBundle)\n122:     val splitLoadResp   = Flipped(Valid(new
      LqWriteBundle))\n123:     val writeBack       = Decoupled(new MemExuOutput)\n\
      124:     val vecWriteBack    = Decoupled(new VecPipelineFeedbackIO(isVStore
      = false))\n125:     val loadOutValid    = Input(Bool())\n126:     val loadVecOutValid
      = Input(Bool())\n127:     val overwriteExpBuf = Output(new XSBundle {\n128:\
      \       val valid  = Bool()\n129:       val vaddr  = UInt(XLEN.W)\n130:    \
      \   val isHyper = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 133-143
    context: "133:     })\n134:     val flushLdExpBuff  = Output(Bool())\n135:   \
      \  val loadMisalignFull = Output(Bool())\n136:   })\n137: \n138:   io.rob.mmio
      := 0.U.asTypeOf(Vec(LoadPipelineWidth, Bool()))\n139:   io.rob.uop  := 0.U.asTypeOf(Vec(LoadPipelineWidth,
      new DynInst))\n140: \n141:   val req_valid = RegInit(false.B)\n142:   val req
      = Reg(new LqWriteBundle)\n143: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 143-156
    context: "143: \n144:   io.loadMisalignFull := req_valid\n145: \n146:   (0 until
      io.enq.length).map{i =>\n147:     if (i == 0) {\n148:       io.enq(0).req.ready
      := !req_valid && io.enq(0).req.valid\n149:     }\n150:     else {\n151:    \
      \   io.enq(i).req.ready := !io.enq.take(i).map(_.req.ready).reduce(_ || _) &&
      !req_valid && io.enq(i).req.valid\n152:     }\n153:   }\n154: \n155:   val select_req_bit\
      \   = ParallelPriorityMux(io.enq.map(_.req.valid), io.enq.map(_.req.bits))\n\
      156:   val select_req_valid = io.enq.map(_.req.valid).reduce(_ || _)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 152-162
    context: "152:     }\n153:   }\n154: \n155:   val select_req_bit   = ParallelPriorityMux(io.enq.map(_.req.valid),
      io.enq.map(_.req.bits))\n156:   val select_req_valid = io.enq.map(_.req.valid).reduce(_
      || _)\n157:   val canEnqValid = !req_valid && !select_req_bit.uop.robIdx.needFlush(io.redirect)
      && select_req_valid\n158:   when(canEnqValid) {\n159:     req := select_req_bit\n\
      160:     req_valid := true.B\n161:   }\n162: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 187-197
    context: "187:   val globalNC   = RegInit(false.B)\n188:   val globalMemBackTypeMM
      = RegInit(false.B)\n189: \n190:   val hasException = io.splitLoadResp.bits.vecActive
      &&\n191:     ExceptionNO.selectByFu(io.splitLoadResp.bits.uop.exceptionVec,
      LduCfg).asUInt.orR || TriggerAction.isDmode(io.splitLoadResp.bits.uop.trigger)\n\
      192:   val isUncache = io.splitLoadResp.bits.mmio || io.splitLoadResp.bits.nc\n\
      193:   needWakeUpReqsWire := false.B\n194:   switch(bufferState) {\n195:   \
      \  is (s_idle) {\n196:       when (req_valid) {\n197:         bufferState :=
      s_split"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 201-211
    context: "201:     is (s_split) {\n202:       bufferState := s_req\n203:     }\n\
      204: \n205:     is (s_req) {\n206:       when (io.splitLoadReq.fire) {\n207:\
      \         bufferState := s_resp\n208:       }\n209:     }\n210: \n211:     is
      (s_resp) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 215-225
    context: "215:           // commit directly when exception ocurs\n216:       \
      \    // if any split load reaches uncache space, delegate to software loadAddrMisaligned
      exception\n217:           bufferState := s_wb\n218:           globalException
      := hasException\n219:           globalUncache := isUncache\n220:           globalMMIO
      := io.splitLoadResp.bits.mmio\n221:           globalNC   := io.splitLoadResp.bits.nc\n\
      222:           globalMemBackTypeMM := io.splitLoadResp.bits.memBackTypeMM\n\
      223:         } .elsewhen(io.splitLoadResp.bits.rep_info.need_rep || (unSentLoads
      & ~clearOh).orR) {\n224:           // need replay or still has unsent requests\n\
      225:           bufferState := s_req"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 231-241
    context: "231:       }\n232:     }\n233: \n234:     is (s_comb_wakeup_rep) {\n\
      235:       when(!req.isvec) {\n236:         when(io.splitLoadReq.fire) {\n237:\
      \           bufferState := s_wb\n238:         }.otherwise {\n239:          \
      \ bufferState := s_comb_wakeup_rep\n240:         }\n241:         needWakeUpReqsWire
      := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 245-255
    context: "245: \n246:     }\n247: \n248:     is (s_wb) {\n249:       when(req.isvec)
      {\n250:         when(io.vecWriteBack.fire) {\n251:           bufferState :=
      s_idle\n252:           req_valid := false.B\n253:           curPtr := 0.U\n\
      254:           unSentLoads := 0.U\n255:           globalException := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 260-270
    context: "260:           globalNC   := false.B\n261:           globalMemBackTypeMM
      := false.B\n262:         }\n263: \n264:       } .otherwise {\n265:         when(io.writeBack.fire)
      {\n266:           bufferState := s_idle\n267:           req_valid := false.B\n\
      268:           curPtr := 0.U\n269:           unSentLoads := 0.U\n270:      \
      \     globalException := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 547-557
    context: "547:     }\n548:     combinedData := Mux(req.isvec, rdataVecHelper(req.alignedType,
      (catResult.asUInt)(XLEN - 1, 0)), rdataHelper(req.uop, (catResult.asUInt)(XLEN
      - 1, 0)))\n549: \n550:   }\n551: \n552:   io.writeBack.valid := req_valid &&
      (bufferState === s_wb) && (io.splitLoadResp.valid && io.splitLoadResp.bits.misalignNeedWakeUp
      || globalUncache || globalException) && !io.loadOutValid && !req.isvec\n553:\
      \   io.writeBack.bits.uop := req.uop\n554:   io.writeBack.bits.uop.exceptionVec
      := DontCare\n555:   LduCfg.exceptionOut.map(no => io.writeBack.bits.uop.exceptionVec(no)
      := (globalUncache || globalException) && exceptionVec(no))\n556:   io.writeBack.bits.uop.rfWen
      := !globalException && !globalUncache && req.uop.rfWen\n557:   io.writeBack.bits.uop.fuType
      := FuType.ldu.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 553-563
    context: "553:   io.writeBack.bits.uop := req.uop\n554:   io.writeBack.bits.uop.exceptionVec
      := DontCare\n555:   LduCfg.exceptionOut.map(no => io.writeBack.bits.uop.exceptionVec(no)
      := (globalUncache || globalException) && exceptionVec(no))\n556:   io.writeBack.bits.uop.rfWen
      := !globalException && !globalUncache && req.uop.rfWen\n557:   io.writeBack.bits.uop.fuType
      := FuType.ldu.U\n558:   io.writeBack.bits.uop.flushPipe := false.B\n559:   io.writeBack.bits.uop.replayInst
      := false.B\n560:   io.writeBack.bits.data := newRdataHelper(data_select, combinedData)\n\
      561:   io.writeBack.bits.isFromLoadUnit := needWakeUpWB\n562:   // Misaligned
      accesses to uncache space trigger exceptions, so theoretically these signals
      won't do anything practical.\n563:   // But let's get them assigned correctly."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 559-569
    context: "559:   io.writeBack.bits.uop.replayInst := false.B\n560:   io.writeBack.bits.data
      := newRdataHelper(data_select, combinedData)\n561:   io.writeBack.bits.isFromLoadUnit
      := needWakeUpWB\n562:   // Misaligned accesses to uncache space trigger exceptions,
      so theoretically these signals won't do anything practical.\n563:   // But let's
      get them assigned correctly.\n564:   io.writeBack.bits.debug.isMMIO := globalMMIO\n\
      565:   io.writeBack.bits.debug.isNCIO := globalNC && !globalMemBackTypeMM\n\
      566:   io.writeBack.bits.debug.isPerfCnt := false.B\n567:   io.writeBack.bits.debug.paddr
      := req.paddr\n568:   io.writeBack.bits.debug.vaddr := req.vaddr\n569: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 582-592
    context: "582:   io.vecWriteBack.bits.usSecondInv          := req.usSecondInv\n\
      583:   io.vecWriteBack.bits.mBIndex              := req.mbIndex\n584:   io.vecWriteBack.bits.hit\
      \                  := true.B\n585:   io.vecWriteBack.bits.sourceType       \
      \    := RSFeedbackType.lrqFull\n586:   io.vecWriteBack.bits.trigger        \
      \      := TriggerAction.None\n587:   io.vecWriteBack.bits.flushState       \
      \    := DontCare\n588:   io.vecWriteBack.bits.exceptionVec         := ExceptionNO.selectByFu(exceptionVec,
      VlduCfg)\n589:   io.vecWriteBack.bits.hasException         := globalException\n\
      590:   io.vecWriteBack.bits.vaddr                := req.fullva\n591:   io.vecWriteBack.bits.vaNeedExt\
      \            := req.vaNeedExt\n592:   io.vecWriteBack.bits.gpaddr          \
      \     := req.gpaddr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 589-599
    context: "589:   io.vecWriteBack.bits.hasException         := globalException\n\
      590:   io.vecWriteBack.bits.vaddr                := req.fullva\n591:   io.vecWriteBack.bits.vaNeedExt\
      \            := req.vaNeedExt\n592:   io.vecWriteBack.bits.gpaddr          \
      \     := req.gpaddr\n593:   io.vecWriteBack.bits.isForVSnonLeafPTE    := req.isForVSnonLeafPTE\n\
      594:   io.vecWriteBack.bits.mmio                 := globalMMIO\n595:   io.vecWriteBack.bits.vstart\
      \               := req.uop.vpu.vstart\n596:   io.vecWriteBack.bits.vecTriggerMask\
      \       := req.vecTriggerMask\n597:   io.vecWriteBack.bits.nc              \
      \     := globalNC\n598: \n599: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 595-607
    context: "595:   io.vecWriteBack.bits.vstart               := req.uop.vpu.vstart\n\
      596:   io.vecWriteBack.bits.vecTriggerMask       := req.vecTriggerMask\n597:\
      \   io.vecWriteBack.bits.nc                   := globalNC\n598: \n599: \n600:\
      \   val flush = req_valid && req.uop.robIdx.needFlush(io.redirect)\n601: \n\
      602:   when (flush) {\n603:     bufferState := s_idle\n604:     req_valid :=
      false.B\n605:     curPtr := 0.U\n606:     unSentLoads := 0.U\n607:     globalException
      := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 637-645
    context: "637:   // when no exception or uncache, flush loadExceptionBuffer at
      s_wb\n638:   val flushLdExpBuff = GatedValidRegNext(req_valid && (bufferState
      === s_wb) && !(globalUncache || globalException))\n639:   io.flushLdExpBuff
      := flushLdExpBuff\n640: \n641:   XSPerfAccumulate(\"alloc\",               \
      \   RegNext(!req_valid) && req_valid)\n642:   XSPerfAccumulate(\"flush\",  \
      \                flush)\n643:   XSPerfAccumulate(\"flush_idle\",           \
      \  flush && (bufferState === s_idle))\n644:   XSPerfAccumulate(\"flush_non_idle\"\
      ,         flush && (bufferState =/= s_idle))\n645: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 93-103
    context: "93: class AgeDetector(numEntries: Int, numEnq: Int, regOut: Boolean
      = true)(implicit p: Parameters) extends XSModule {\n94:   val io = IO(new Bundle
      {\n95:     // NOTE: deq and enq may come at the same cycle.\n96:     val enq
      = Vec(numEnq, Input(UInt(numEntries.W)))\n97:     val deq = Input(UInt(numEntries.W))\n\
      98:     val ready = Input(UInt(numEntries.W))\n99:     val out = Output(UInt(numEntries.W))\n\
      100:   })\n101: \n102:   // age(i)(j): entry i enters queue before entry j\n\
      103:   val age = Seq.fill(numEntries)(Seq.fill(numEntries)(RegInit(false.B)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 104-132
    context: "104:   val nextAge = Seq.fill(numEntries)(Seq.fill(numEntries)(Wire(Bool())))\n\
      105: \n106:   // to reduce reg usage, only use upper matrix\n107:   def get_age(row:
      Int, col: Int): Bool = if (row <= col) age(row)(col) else !age(col)(row)\n108:\
      \   def get_next_age(row: Int, col: Int): Bool = if (row <= col) nextAge(row)(col)
      else !nextAge(col)(row)\n109:   def isFlushed(i: Int): Bool = io.deq(i)\n110:\
      \   def isEnqueued(i: Int, numPorts: Int = -1): Bool = {\n111:     val takePorts
      = if (numPorts == -1) io.enq.length else numPorts\n112:     takePorts match
      {\n113:       case 0 => false.B\n114:       case 1 => io.enq.head(i) && !isFlushed(i)\n\
      115:       case n => VecInit(io.enq.take(n).map(_(i))).asUInt.orR && !isFlushed(i)\n\
      116:     }\n117:   }\n118: \n119:   for ((row, i) <- nextAge.zipWithIndex) {\n\
      120:     val thisValid = get_age(i, i) || isEnqueued(i)\n121:     for ((elem,
      j) <- row.zipWithIndex) {\n122:       when (isFlushed(i)) {\n123:         //
      (1) when entry i is flushed or dequeues, set row(i) to false.B\n124:       \
      \  elem := false.B\n125:       }.elsewhen (isFlushed(j)) {\n126:         //
      (2) when entry j is flushed or dequeues, set column(j) to validVec\n127:   \
      \      elem := thisValid\n128:       }.elsewhen (isEnqueued(i)) {\n129:    \
      \     // (3) when entry i enqueues from port k,\n130:         // (3.1) if entry
      j enqueues from previous ports, set to false\n131:         // (3.2) otherwise,
      set to true if and only of entry j is invalid\n132:         // overall: !jEnqFromPreviousPorts
      && !jIsValid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 142-152
    context: "142:     }\n143:   }\n144: \n145:   def getOldest(get: (Int, Int) =>
      Bool): UInt = {\n146:     VecInit((0 until numEntries).map(i => {\n147:    \
      \   io.ready(i) & VecInit((0 until numEntries).map(j => if (i != j) !io.ready(j)
      || get(i, j) else true.B)).asUInt.andR\n148:     })).asUInt\n149:   }\n150:\
      \   val best = getOldest(get_age)\n151:   val nextBest = getOldest(get_next_age)\n\
      152: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 152-166
    context: "152: \n153:   io.out := (if (regOut) best else nextBest)\n154: }\n155:\
      \ \n156: object AgeDetector {\n157:   def apply(numEntries: Int, enq: Vec[UInt],
      deq: UInt, ready: UInt)(implicit p: Parameters): Valid[UInt] = {\n158:     val
      age = Module(new AgeDetector(numEntries, enq.length, regOut = true))\n159: \
      \    age.io.enq := enq\n160:     age.io.deq := deq\n161:     age.io.ready:=
      ready\n162:     val out = Wire(Valid(UInt(deq.getWidth.W)))\n163:     out.valid
      := age.io.out.orR\n164:     out.bits := age.io.out\n165:     out\n166:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 174-184
    context: "174:   with HasTlbConst\n175:   with HasPerfEvents\n176: {\n177:   val
      io = IO(new Bundle() {\n178:     // control\n179:     val redirect = Flipped(ValidIO(new
      Redirect))\n180:     val vecFeedback = Vec(VecLoadPipelineWidth, Flipped(ValidIO(new
      FeedbackToLsqIO)))\n181: \n182:     // from load unit s3\n183:     val enq =
      Vec(LoadPipelineWidth, Flipped(Decoupled(new LqWriteBundle)))\n184: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 187-197
    context: "187: \n188:     // from std s1\n189:     val storeDataIn = Vec(StorePipelineWidth,
      Flipped(Valid(new MemExuOutput(isVector = true))))\n190: \n191:     // queue-based
      replay\n192:     val replay = Vec(LoadPipelineWidth, Decoupled(new LsPipelineBundle))\n\
      193:    // val refill = Flipped(ValidIO(new Refill))\n194:     val tl_d_channel
      = Input(new DcacheToLduForwardIO)\n195: \n196:     // from StoreQueue\n197:\
      \     val stAddrReadySqPtr = Input(new SqPtr)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 229-239
    context: "229:   val uop = Reg(Vec(LoadQueueReplaySize, new DynInst))\n230:  \
      \ val vecReplay = Reg(Vec(LoadQueueReplaySize, new VecReplayInfo))\n231:   val
      vaddrModule = Module(new LqVAddrModule(\n232:     gen = UInt(VAddrBits.W),\n\
      233:     numEntries = LoadQueueReplaySize,\n234:     numRead = LoadPipelineWidth,\n\
      235:     numWrite = LoadPipelineWidth,\n236:     numWBank = LoadQueueNWriteBanks,\n\
      237:     numWDelay = 2,\n238:     numCamPort = 0))\n239:   vaddrModule.io :=
      DontCare"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 272-282
    context: "272: \n273:   /**\n274:    * Enqueue\n275:    */\n276:   val canEnqueue
      = io.enq.map(_.valid)\n277:   val cancelEnq = io.enq.map(enq => enq.bits.uop.robIdx.needFlush(io.redirect))\n\
      278:   val needReplay = io.enq.map(enq => enq.bits.rep_info.need_rep)\n279:\
      \   val hasExceptions = io.enq.map(enq => ExceptionNO.selectByFu(enq.bits.uop.exceptionVec,
      LduCfg).asUInt.orR && !enq.bits.tlbMiss)\n280:   val loadReplay = io.enq.map(enq
      => enq.bits.isLoadReplay)\n281:   val needEnqueue = VecInit((0 until LoadPipelineWidth).map(w
      => {\n282:     canEnqueue(w) && !cancelEnq(w) && needReplay(w) && !hasExceptions(w)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 304-315
    context: "304:   val stDataReadyVec = io.stDataReadyVec\n305: \n306:   for (i
      <- 0 until LoadQueueReplaySize) {\n307:     // dequeue\n308:     //  FIXME:
      store*Ptr is not accurate\n309:     dataNotBlockVec(i) := isAfter(io.stDataReadySqPtr,
      blockSqIdx(i)) || stDataReadyVec(blockSqIdx(i).value) || io.sqEmpty // for better
      timing\n310:     addrNotBlockVec(i) := isAfter(io.stAddrReadySqPtr, blockSqIdx(i))
      || !strict(i) && stAddrReadyVec(blockSqIdx(i).value) || io.sqEmpty // for better
      timing\n311:     // store address execute\n312:     storeAddrInSameCycleVec(i)
      := VecInit((0 until StorePipelineWidth).map(w => {\n313:       io.storeAddrIn(w).valid
      &&\n314:       !io.storeAddrIn(w).bits.miss &&\n315:       blockSqIdx(i) ===
      io.storeAddrIn(w).bits.uop.sqIdx"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 355-373
    context: "355:     when (cause(i)(LoadReplayCauses.C_DM)) {\n356:       blocking(i)
      := Mux(io.tl_d_channel.valid && io.tl_d_channel.mshrid === missMSHRId(i), false.B,
      blocking(i))\n357:     }\n358:     // case C_RAR\n359:     when (cause(i)(LoadReplayCauses.C_RAR))
      {\n360:       blocking(i) := Mux((!io.rarFull || !isAfter(uop(i).lqIdx, io.ldWbPtr)),
      false.B, blocking(i))\n361:     }\n362:     // case C_RAW\n363:     when (cause(i)(LoadReplayCauses.C_RAW))
      {\n364:       blocking(i) := Mux((!io.rawFull || !isAfter(uop(i).sqIdx, io.stAddrReadySqPtr)),
      false.B, blocking(i))\n365:     }\n366:     // case C_MF\n367:     when (cause(i)(LoadReplayCauses.C_MF))
      {\n368:       blocking(i) := Mux(!io.loadMisalignFull && (io.misalignAllowSpec
      || !isAfter(uop(i).lqIdx, io.ldWbPtr)), false.B, blocking(i))\n369:     }\n\
      370:   })\n371: \n372:   //  Replay is splitted into 3 stages\n373:   require((LoadQueueReplaySize
      % LoadPipelineWidth) == 0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 413-423
    context: "413:   val s0_remLoadHintSelMask = VecInit((0 until LoadPipelineWidth).map(rem
      => getRemBits(s0_loadHintSelMask)(rem)))\n414:   val s0_remHintSelValidVec =
      VecInit((0 until LoadPipelineWidth).map(rem => ParallelORR(s0_remLoadHintSelMask(rem))))\n\
      415:   val s0_hintSelValid = ParallelORR(s0_loadHintSelMask)\n416: \n417:  \
      \ // wake up cache missed load\n418:   (0 until LoadQueueReplaySize).foreach(i
      => {\n419:     when(s0_loadHintWakeMask(i)) {\n420:       blocking(i) := false.B\n\
      421:     }\n422:   })\n423: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 476-486
    context: "476:     val oldest = Wire(Valid(UInt()))\n477:     val oldestSel =
      Mux(issOldestValid, issOldestIndexOH, ageOldestIndexOH)\n478:     val oldestBitsVec
      = Wire(Vec(LoadQueueReplaySize, Bool()))\n479: \n480:     require((LoadQueueReplaySize
      % LoadPipelineWidth) == 0)\n481:     oldestBitsVec.foreach(e => e := false.B)\n\
      482:     for (i <- 0 until LoadQueueReplaySize / LoadPipelineWidth) {\n483:\
      \       oldestBitsVec(i * LoadPipelineWidth + rport) := oldestSel(i)\n484: \
      \    }\n485: \n486:     oldest.valid := ageOldest.valid || issOldestValid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 501-512
    context: "501: \n502:   val replay_req = Wire(Vec(LoadPipelineWidth, DecoupledIO(new
      LsPipelineBundle)))\n503: \n504:   for (i <- 0 until LoadPipelineWidth) {\n\
      505:     val s0_can_go = s1_can_go(i) ||\n506:                     uop(s1_oldestSel(i).bits).robIdx.needFlush(io.redirect)
      ||\n507:                     uop(s1_oldestSel(i).bits).robIdx.needFlush(RegNext(io.redirect))\n\
      508:     val s0_oldestSelIndexOH = s0_oldestSel(i).bits // one-hot\n509:   \
      \  s1_oldestSel(i).valid := RegEnable(s0_oldestSel(i).valid, false.B, s0_can_go)\n\
      510:     s1_oldestSel(i).bits := RegEnable(OHToUInt(s0_oldestSel(i).bits), s0_can_go)\n\
      511: \n512:     for (j <- 0 until LoadQueueReplaySize) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 515-529
    context: "515:       }\n516:     }\n517:   }\n518:   val s2_cancelReplay = Wire(Vec(LoadPipelineWidth,
      Bool()))\n519:   for (i <- 0 until LoadPipelineWidth) {\n520:     val s1_cancel
      = uop(s1_oldestSel(i).bits).robIdx.needFlush(io.redirect) ||\n521:         \
      \            uop(s1_oldestSel(i).bits).robIdx.needFlush(RegNext(io.redirect))\n\
      522:     val s1_oldestSelV = s1_oldestSel(i).valid && !s1_cancel\n523:     s1_can_go(i)\
      \          := replayCanFire(i) && (!s2_oldestSel(i).valid || replay_req(i).fire)
      || s2_cancelReplay(i)\n524:     s2_oldestSel(i).valid := RegEnable(Mux(s1_can_go(i),
      s1_oldestSelV, false.B), false.B, (s1_can_go(i) || replay_req(i).fire))\n525:\
      \     s2_oldestSel(i).bits  := RegEnable(s1_oldestSel(i).bits, s1_can_go(i))\n\
      526: \n527:     vaddrModule.io.ren(i) := s1_oldestSel(i).valid && s1_can_go(i)\n\
      528:     vaddrModule.io.raddr(i) := s1_oldestSel(i).bits\n529:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 536-546
    context: "536:     val s2_replacementUpdated = RegEnable(replacementUpdated(s1_replayIdx),
      s1_can_go(i))\n537:     val s2_missDbUpdated = RegEnable(missDbUpdated(s1_replayIdx),
      s1_can_go(i))\n538:     val s2_replayCauses = RegEnable(cause(s1_replayIdx),
      s1_can_go(i))\n539:     val s2_replayCarry = RegEnable(replayCarryReg(s1_replayIdx),
      s1_can_go(i))\n540:     val s2_replayCacheMissReplay = RegEnable(trueCacheMissReplay(s1_replayIdx),
      s1_can_go(i))\n541:     s2_cancelReplay(i) := s2_replayUop.robIdx.needFlush(io.redirect)\n\
      542: \n543:     s2_can_go(i) := DontCare\n544:     replay_req(i).valid     \
      \        := s2_oldestSel(i).valid\n545:     replay_req(i).bits             \
      \ := DontCare\n546:     replay_req(i).bits.uop          := s2_replayUop"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 567-577
    context: "567:     replay_req(i).bits.missDbUpdated := s2_missDbUpdated\n568:\
      \     replay_req(i).bits.forward_tlDchannel := s2_replayCauses(LoadReplayCauses.C_DM)\n\
      569:     replay_req(i).bits.schedIndex   := s2_oldestSel(i).bits\n570:     replay_req(i).bits.uop.loadWaitStrict
      := false.B\n571: \n572:     XSError(replay_req(i).fire && !allocated(s2_oldestSel(i).bits),
      p\"LoadQueueReplay: why replay an invalid entry ${s2_oldestSel(i).bits} ?\"\
      )\n573:   }\n574: \n575:   val EnableHybridUnitReplay = Constantin.createRecord(\"\
      EnableHybridUnitReplay\", true)\n576:   when(EnableHybridUnitReplay) {\n577:\
      \     for (i <- 0 until LoadPipelineWidth)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 573-597
    context: "573:   }\n574: \n575:   val EnableHybridUnitReplay = Constantin.createRecord(\"\
      EnableHybridUnitReplay\", true)\n576:   when(EnableHybridUnitReplay) {\n577:\
      \     for (i <- 0 until LoadPipelineWidth)\n578:       io.replay(i) <> replay_req(i)\n\
      579:   }.otherwise {\n580:     io.replay(0) <> replay_req(0)\n581:     io.replay(2).valid
      := false.B\n582:     io.replay(2).bits := DontCare\n583: \n584:     val arbiter
      = Module(new RRArbiter(new LsPipelineBundle, 2))\n585:     arbiter.io.in(0)
      <> replay_req(1)\n586:     arbiter.io.in(1) <> replay_req(2)\n587:     io.replay(1)
      <> arbiter.io.out\n588:   }\n589:   // update cold counter\n590:   val lastReplay
      = RegNext(VecInit(io.replay.map(_.fire)))\n591:   for (i <- 0 until LoadPipelineWidth)
      {\n592:     when (lastReplay(i) && io.replay(i).fire) {\n593:       coldCounter(i)
      := coldCounter(i) + 1.U\n594:     } .elsewhen (coldDownNow(i)) {\n595:     \
      \  coldCounter(i) := coldCounter(i) + 1.U\n596:     } .otherwise {\n597:   \
      \    coldCounter(i) := 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 622-643
    context: "622: \n623:     //  Allocated ready\n624:     val offset = PopCount(newEnqueue.take(w))\n\
      625:     val enqIndex = Mux(enq.bits.isLoadReplay, enq.bits.schedIndex, freeList.io.allocateSlot(offset))\n\
      626:     enqIndexOH(w) := UIntToOH(enqIndex)\n627:     enq.ready := true.B\n\
      628: \n629:     val debug_robIdx = enq.bits.uop.robIdx.asUInt\n630:     XSError(\n\
      631:       needEnqueue(w) && enq.ready &&\n632:       allocated(enqIndex) &&
      !enq.bits.isLoadReplay,\n633:       p\"LoadQueueReplay: can not accept more
      load, check: ldu $w, robIdx $debug_robIdx!\")\n634:     XSError(\n635:     \
      \  needEnqueue(w) && enq.ready &&\n636:       hasExceptions(w),\n637:      \
      \ p\"LoadQueueReplay: The instruction has exception, it can not be replay, check:
      ldu $w, robIdx $debug_robIdx!\")\n638:     when (needEnqueue(w) && enq.ready)
      {\n639:       freeList.io.doAllocate(w) := !enq.bits.isLoadReplay\n640: \n641:\
      \       //  Allocate new entry\n642:       allocated(enqIndex) := true.B\n643:\
      \       scheduled(enqIndex) := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 738-758
    context: "738:   val vecLdCommittmp = Wire(Vec(LoadQueueReplaySize, Vec(VecLoadPipelineWidth,
      Bool())))\n739:   val vecLdCommit = Wire(Vec(LoadQueueReplaySize, Bool()))\n\
      740:   for (i <- 0 until LoadQueueReplaySize) {\n741:     val fbk = io.vecFeedback\n\
      742:     for (j <- 0 until VecLoadPipelineWidth) {\n743:       vecLdCanceltmp(i)(j)
      := allocated(i) && fbk(j).valid && fbk(j).bits.isFlush && uop(i).robIdx ===
      fbk(j).bits.robidx && uop(i).uopIdx === fbk(j).bits.uopidx\n744:       vecLdCommittmp(i)(j)
      := allocated(i) && fbk(j).valid && fbk(j).bits.isCommit && uop(i).robIdx ===
      fbk(j).bits.robidx && uop(i).uopIdx === fbk(j).bits.uopidx\n745:     }\n746:\
      \     vecLdCancel(i) := vecLdCanceltmp(i).reduce(_ || _)\n747:     vecLdCommit(i)
      := vecLdCommittmp(i).reduce(_ || _)\n748:     XSError(((vecLdCancel(i) || vecLdCommit(i))
      && allocated(i)), s\"vector load, should not have replay entry $i when commit
      or flush.\\n\")\n749:   }\n750: \n751:   // misprediction recovery / exception
      redirect\n752:   for (i <- 0 until LoadQueueReplaySize) {\n753:     needCancel(i)
      := uop(i).robIdx.needFlush(io.redirect) && allocated(i)\n754:     when (needCancel(i))
      {\n755:       allocated(i) := false.B\n756:       freeMaskVec(i) := true.B\n\
      757:     }\n758:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 755-765
    context: "755:       allocated(i) := false.B\n756:       freeMaskVec(i) := true.B\n\
      757:     }\n758:   }\n759: \n760:   freeList.io.free := freeMaskVec.asUInt\n\
      761: \n762:   io.lqFull := lqFull\n763: \n764:   // Topdown\n765:   val robHeadVaddr
      = io.debugTopDown.robHeadVaddr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 763-773
    context: "763: \n764:   // Topdown\n765:   val robHeadVaddr = io.debugTopDown.robHeadVaddr\n\
      766: \n767:   val uop_wrapper = Wire(Vec(LoadQueueReplaySize, new XSBundleWithMicroOp))\n\
      768:   (uop_wrapper.zipWithIndex).foreach {\n769:     case (u, i) => {\n770:\
      \       u.uop := uop(i)\n771:     }\n772:   }\n773:   val lq_match_vec = (debug_vaddr.zip(allocated)).map{case(va,
      alloc) => alloc && (va === robHeadVaddr.bits)}"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 773-783
    context: "773:   val lq_match_vec = (debug_vaddr.zip(allocated)).map{case(va,
      alloc) => alloc && (va === robHeadVaddr.bits)}\n774:   val rob_head_lq_match
      = ParallelOperation(lq_match_vec.zip(uop_wrapper), (a: Tuple2[Bool, XSBundleWithMicroOp],
      b: Tuple2[Bool, XSBundleWithMicroOp]) => {\n775:     val (a_v, a_uop) = (a._1,
      a._2)\n776:     val (b_v, b_uop) = (b._1, b._2)\n777: \n778:     val res = Mux(a_v
      && b_v, Mux(isAfter(a_uop.uop.robIdx, b_uop.uop.robIdx), b_uop, a_uop),\n779:\
      \                   Mux(a_v, a_uop,\n780:                       Mux(b_v, b_uop,\n\
      781:                                 a_uop)))\n782:     (a_v || b_v, res)\n\
      783:   })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 806-827
    context: "806:   io.debugTopDown.robHeadLoadMSHR := rob_head_mshrfull_replay\n\
      807:   io.debugTopDown.robHeadOtherReplay := rob_head_other_replay\n808:   val
      perfValidCount = RegNext(PopCount(allocated))\n809: \n810:   //  perf cnt\n\
      811:   val enqNumber               = PopCount(io.enq.map(enq => enq.fire &&
      !enq.bits.isLoadReplay))\n812:   val deqNumber               = PopCount(io.replay.map(_.fire))\n\
      813:   val deqBlockCount           = PopCount(io.replay.map(r => r.valid &&
      !r.ready))\n814:   val replayTlbMissCount      = PopCount(io.enq.map(enq =>
      enq.fire && !enq.bits.isLoadReplay && enq.bits.rep_info.cause(LoadReplayCauses.C_TM)))\n\
      815:   val replayMemAmbCount       = PopCount(io.enq.map(enq => enq.fire &&
      !enq.bits.isLoadReplay && enq.bits.rep_info.cause(LoadReplayCauses.C_MA)))\n\
      816:   val replayNukeCount         = PopCount(io.enq.map(enq => enq.fire &&
      !enq.bits.isLoadReplay && enq.bits.rep_info.cause(LoadReplayCauses.C_NK)))\n\
      817:   val replayRARRejectCount    = PopCount(io.enq.map(enq => enq.fire &&
      !enq.bits.isLoadReplay && enq.bits.rep_info.cause(LoadReplayCauses.C_RAR)))\n\
      818:   val replayRAWRejectCount    = PopCount(io.enq.map(enq => enq.fire &&
      !enq.bits.isLoadReplay && enq.bits.rep_info.cause(LoadReplayCauses.C_RAW)))\n\
      819:   val replayBankConflictCount = PopCount(io.enq.map(enq => enq.fire &&
      !enq.bits.isLoadReplay && enq.bits.rep_info.cause(LoadReplayCauses.C_BC)))\n\
      820:   val replayDCacheReplayCount = PopCount(io.enq.map(enq => enq.fire &&
      !enq.bits.isLoadReplay && enq.bits.rep_info.cause(LoadReplayCauses.C_DR)))\n\
      821:   val replayForwardFailCount  = PopCount(io.enq.map(enq => enq.fire &&
      !enq.bits.isLoadReplay && enq.bits.rep_info.cause(LoadReplayCauses.C_FF)))\n\
      822:   val replayDCacheMissCount   = PopCount(io.enq.map(enq => enq.fire &&
      !enq.bits.isLoadReplay && enq.bits.rep_info.cause(LoadReplayCauses.C_DM)))\n\
      823:   XSPerfAccumulate(\"enq\", enqNumber)\n824:   XSPerfAccumulate(\"deq\"\
      , deqNumber)\n825:   XSPerfAccumulate(\"deq_block\", deqBlockCount)\n826:  \
      \ XSPerfAccumulate(\"replay_full\", io.lqFull)\n827:   XSPerfAccumulate(\"replay_rar_nack\"\
      , replayRARRejectCount)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 85-95
    context: "85:   val uncache         = Flipped(DecoupledIO(new MemExuOutput))\n\
      86:   val ld_raw_data     = Input(new LoadDataFromLQBundle)\n87:   // uncache-nc
      -> ldu\n88:   val nc_ldin = Flipped(DecoupledIO(new LsPipelineBundle))\n89:\
      \   // storequeue -> ldu\n90:   val forward         = new PipeLoadForwardQueryIO\n\
      91:   // ldu -> lsq LQRAW\n92:   val stld_nuke_query = new LoadNukeQueryIO\n\
      93:   // ldu -> lsq LQRAR\n94:   val ldld_nuke_query = new LoadNukeQueryIO\n\
      95:   // lq -> ldu for misalign"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 117-127
    context: "117:   with HasVLSUParameters\n118:   with SdtrigExt\n119: {\n120: \
      \  val io = IO(new Bundle() {\n121:     // control\n122:     val redirect  \
      \    = Flipped(ValidIO(new Redirect))\n123:     val csrCtrl       = Flipped(new
      CustomCSRCtrlIO)\n124: \n125:     // int issue path\n126:     val ldin     \
      \     = Flipped(Decoupled(new MemExuInput))\n127:     val ldout         = Decoupled(new
      MemExuOutput)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 186-196
    context: "186: \n187:     // schedule error query\n188:     val stld_nuke_query
      = Flipped(Vec(StorePipelineWidth, Valid(new StoreNukeQueryBundle)))\n189: \n\
      190:     // queue-based replay\n191:     val replay       = Flipped(Decoupled(new
      LsPipelineBundle))\n192:     val lq_rep_full  = Input(Bool())\n193: \n194: \
      \    // misc\n195:     val s2_ptr_chasing = Output(Bool()) // provide right
      pc for hw prefetch\n196: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 201-211
    context: "201:     // to misalign buffer\n202:     val misalign_enq = new MisalignBufferEnqIO\n\
      203:     val misalign_allow_spec = Input(Bool())\n204: \n205:     // Load RAR
      rollback\n206:     val rollback = Valid(new Redirect)\n207: \n208:     // perf\n\
      209:     val debug_ls         = Output(new DebugLsInfoBundle)\n210:     val
      lsTopdownInfo    = Output(new LsTopdownInfo)\n211:     val correctMissTrain
      = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 212-222
    context: "212:   })\n213: \n214: \n215:   PerfCCT.updateInstPos(io.ldin.bits.uop.debug_seqNum,
      PerfCCT.InstPos.AtFU.id.U, io.ldin.valid, clock, reset)\n216: \n217:   val s1_ready,
      s2_ready, s3_ready = WireInit(false.B)\n218: \n219:   // Pipeline\n220:   //
      --------------------------------------------------------------------------------\n\
      221:   // stage 0\n222:   // --------------------------------------------------------------------------------"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 219-239
    context: "219:   // Pipeline\n220:   // --------------------------------------------------------------------------------\n\
      221:   // stage 0\n222:   // --------------------------------------------------------------------------------\n\
      223:   // generate addr, use addr to query DCache and DTLB\n224:   val s0_valid\
      \         = Wire(Bool())\n225:   val s0_mmio_select   = Wire(Bool())\n226: \
      \  val s0_nc_select     = Wire(Bool())\n227:   val s0_misalign_select= Wire(Bool())\n\
      228:   val s0_kill          = Wire(Bool())\n229:   val s0_can_go        = s1_ready\n\
      230:   val s0_fire          = s0_valid && s0_can_go\n231:   val s0_mmio_fire\
      \     = s0_mmio_select && s0_can_go\n232:   val s0_nc_fire       = s0_nc_select
      && s0_can_go\n233:   val s0_out           = Wire(new LqWriteBundle)\n234:  \
      \ val s0_tlb_valid     = Wire(Bool())\n235:   val s0_tlb_hlv       = Wire(Bool())\n\
      236:   val s0_tlb_hlvx      = Wire(Bool())\n237:   val s0_tlb_vaddr     = Wire(UInt(VAddrBits.W))\n\
      238:   val s0_tlb_fullva    = Wire(UInt(XLEN.W))\n239:   val s0_dcache_vaddr\
      \  = Wire(UInt(VAddrBits.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 237-247
    context: "237:   val s0_tlb_vaddr     = Wire(UInt(VAddrBits.W))\n238:   val s0_tlb_fullva\
      \    = Wire(UInt(XLEN.W))\n239:   val s0_dcache_vaddr  = Wire(UInt(VAddrBits.W))\n\
      240:   val s0_is128bit      = Wire(Bool())\n241:   val s0_misalign_wakeup_fire
      = s0_misalign_select && s0_can_go &&\n242:     io.dcache.req.ready &&\n243:\
      \     io.misalign_ldin.bits.misalignNeedWakeUp\n244: \n245:   // flow source
      bundle\n246:   class FlowSource extends Bundle {\n247:     val vaddr       \
      \  = UInt(VAddrBits.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 299-310
    context: "299:   // src 7: vec read from RS (io.vecldin)\n300:   // src 8: int
      read / software prefetch first issue from RS (io.in)\n301:   // src 9: load
      try pointchaising when no issued or replayed load (io.fastpath)\n302:   // src10:
      hardware prefetch from prefetchor (high confidence) (io.prefetch)\n303:   //
      priority: high to low\n304:   val s0_rep_stall           = io.ldin.valid &&
      isAfter(io.replay.bits.uop.lqIdx, io.ldin.bits.uop.lqIdx) ||\n305:         \
      \                       io.vecldin.valid && isAfter(io.replay.bits.uop.lqIdx,
      io.vecldin.bits.uop.lqIdx)\n306:   private val SRC_NUM = 11\n307:   private
      val Seq(\n308:     mab_idx, super_rep_idx, fast_rep_idx, mmio_idx, nc_idx, lsq_rep_idx,\n\
      309:     high_pf_idx, vec_iss_idx, int_iss_idx, l2l_fwd_idx, low_pf_idx\n310:\
      \   ) = (0 until SRC_NUM).toSeq"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 309-323
    context: "309:     high_pf_idx, vec_iss_idx, int_iss_idx, l2l_fwd_idx, low_pf_idx\n\
      310:   ) = (0 until SRC_NUM).toSeq\n311:   // load flow source valid\n312: \
      \  val s0_src_valid_vec = WireInit(VecInit(Seq(\n313:     io.misalign_ldin.valid,\n\
      314:     io.replay.valid && io.replay.bits.forward_tlDchannel,\n315:     io.fast_rep_in.valid,\n\
      316:     io.lsq.uncache.valid,\n317:     io.lsq.nc_ldin.valid,\n318:     io.replay.valid
      && !io.replay.bits.forward_tlDchannel && !s0_rep_stall,\n319:     io.prefetch_req.valid
      && io.prefetch_req.bits.confidence > 0.U,\n320:     io.vecldin.valid,\n321:\
      \     io.ldin.valid, // int flow first issue or software prefetch\n322:    \
      \ io.l2l_fwd_in.valid,\n323:     io.prefetch_req.valid && io.prefetch_req.bits.confidence
      === 0.U,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 333-343
    context: "333:   val s0_hw_prf_select = s0_src_select_vec(high_pf_idx) || s0_src_select_vec(low_pf_idx)\n\
      334: \n335:   val s0_tlb_no_query = s0_hw_prf_select || s0_sel_src.prf_i ||\n\
      336:     s0_src_select_vec(fast_rep_idx) || s0_src_select_vec(mmio_idx) ||\n\
      337:     s0_src_select_vec(nc_idx)\n338:   s0_valid := !s0_kill && (s0_src_select_vec(nc_idx)
      || ((\n339:     s0_src_valid_vec(mab_idx) ||\n340:     s0_src_valid_vec(super_rep_idx)
      ||\n341:     s0_src_valid_vec(fast_rep_idx) ||\n342:     s0_src_valid_vec(lsq_rep_idx)
      ||\n343:     s0_src_valid_vec(high_pf_idx) ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 343-357
    context: "343:     s0_src_valid_vec(high_pf_idx) ||\n344:     s0_src_valid_vec(vec_iss_idx)
      ||\n345:     s0_src_valid_vec(int_iss_idx) ||\n346:     s0_src_valid_vec(l2l_fwd_idx)
      ||\n347:     s0_src_valid_vec(low_pf_idx)\n348:   ) && !s0_src_select_vec(mmio_idx)
      && io.dcache.req.ready &&\n349:     !(io.misalign_ldin.fire && io.misalign_ldin.bits.misalignNeedWakeUp)
      // Currently, misalign is the highest priority\n350:   ))\n351: \n352:   s0_mmio_select
      := s0_src_select_vec(mmio_idx) && !s0_kill\n353:   s0_nc_select := s0_src_select_vec(nc_idx)
      && !s0_kill\n354:   //judgment: is NC with data or not.\n355:   //If true, it's
      from `io.lsq.nc_ldin` or `io.fast_rep_in`\n356:   val s0_nc_with_data = s0_sel_src.isnc
      && !s0_kill\n357:   s0_misalign_select := s0_src_select_vec(mab_idx) && !s0_kill"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 355-365
    context: "355:   //If true, it's from `io.lsq.nc_ldin` or `io.fast_rep_in`\n356:\
      \   val s0_nc_with_data = s0_sel_src.isnc && !s0_kill\n357:   s0_misalign_select
      := s0_src_select_vec(mab_idx) && !s0_kill\n358: \n359:    // if is hardware
      prefetch or fast replay, don't send valid to tlb\n360:   s0_tlb_valid := (\n\
      361:     s0_src_valid_vec(mab_idx) ||\n362:     s0_src_valid_vec(super_rep_idx)
      ||\n363:     s0_src_valid_vec(lsq_rep_idx) ||\n364:     s0_src_valid_vec(vec_iss_idx)
      ||\n365:     s0_src_valid_vec(int_iss_idx) ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 362-376
    context: "362:     s0_src_valid_vec(super_rep_idx) ||\n363:     s0_src_valid_vec(lsq_rep_idx)
      ||\n364:     s0_src_valid_vec(vec_iss_idx) ||\n365:     s0_src_valid_vec(int_iss_idx)
      ||\n366:     s0_src_valid_vec(l2l_fwd_idx)\n367:   ) && io.dcache.req.ready\n\
      368: \n369:   // which is S0's out is ready and dcache is ready\n370:   val
      s0_try_ptr_chasing      = s0_src_select_vec(l2l_fwd_idx)\n371:   val s0_do_try_ptr_chasing\
      \   = s0_try_ptr_chasing && s0_can_go && io.dcache.req.ready\n372:   val s0_ptr_chasing_vaddr\
      \    = io.l2l_fwd_in.data(5, 0) +& io.ld_fast_imm(5, 0)\n373:   val s0_ptr_chasing_canceled
      = WireInit(false.B)\n374:   s0_kill := s0_ptr_chasing_canceled\n375: \n376:\
      \   // prefetch related ctrl signal"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 372-389
    context: "372:   val s0_ptr_chasing_vaddr    = io.l2l_fwd_in.data(5, 0) +& io.ld_fast_imm(5,
      0)\n373:   val s0_ptr_chasing_canceled = WireInit(false.B)\n374:   s0_kill :=
      s0_ptr_chasing_canceled\n375: \n376:   // prefetch related ctrl signal\n377:\
      \   io.canAcceptLowConfPrefetch  := s0_src_ready_vec(low_pf_idx) && io.dcache.req.ready\n\
      378:   io.canAcceptHighConfPrefetch := s0_src_ready_vec(high_pf_idx) && io.dcache.req.ready\n\
      379: \n380:   // query DTLB\n381:   io.tlb.req.valid                   := s0_tlb_valid\n\
      382:   io.tlb.req.bits.cmd                := Mux(s0_sel_src.prf,\n383:     \
      \                                     Mux(s0_sel_src.prf_wr, TlbCmd.write, TlbCmd.read),\n\
      384:                                          TlbCmd.read\n385:            \
      \                            )\n386:   io.tlb.req.bits.isPrefetch         :=
      s0_sel_src.prf\n387:   io.tlb.req.bits.vaddr              := s0_tlb_vaddr\n\
      388:   io.tlb.req.bits.fullva             := s0_tlb_fullva\n389:   io.tlb.req.bits.checkfullva\
      \        := s0_src_select_vec(vec_iss_idx) || s0_src_select_vec(int_iss_idx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 393-408
    context: "393:   io.tlb.req.bits.kill               := s0_kill || s0_tlb_no_query
      // if does not need to be translated, kill it\n394:   io.tlb.req.bits.memidx.is_ld\
      \       := true.B\n395:   io.tlb.req.bits.memidx.is_st       := false.B\n396:\
      \   io.tlb.req.bits.memidx.idx         := s0_sel_src.uop.lqIdx.value\n397: \
      \  io.tlb.req.bits.debug.robIdx       := s0_sel_src.uop.robIdx\n398:   io.tlb.req.bits.no_translate\
      \       := s0_tlb_no_query  // hardware prefetch and fast replay does not need
      to be translated, need this signal for pmp check\n399:   io.tlb.req.bits.debug.pc\
      \           := s0_sel_src.uop.pc\n400:   io.tlb.req.bits.debug.isFirstIssue
      := s0_sel_src.isFirstIssue\n401: \n402:   // query DCache\n403:   io.dcache.req.valid\
      \             := s0_valid && !s0_sel_src.prf_i && !s0_nc_with_data\n404:   io.dcache.req.bits.cmd\
      \          := Mux(s0_sel_src.prf_rd,\n405:                                 \
      \      MemoryOpConstants.M_PFR,\n406:                                      \
      \ Mux(s0_sel_src.prf_wr, MemoryOpConstants.M_PFW, MemoryOpConstants.M_XRD)\n\
      407:                                     )\n408:   io.dcache.req.bits.vaddr\
      \        := s0_dcache_vaddr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 671-685
    context: "671:   // set default\n672:   val s0_src_selector = WireInit(s0_src_valid_vec)\n\
      673:   if (!EnableLoadToLoadForward) { s0_src_selector(l2l_fwd_idx) := false.B
      }\n674:   val s0_src_format = Seq(\n675:     fromMisAlignBufferSource(io.misalign_ldin.bits),\n\
      676:     fromNormalReplaySource(io.replay.bits),\n677:     fromFastReplaySource(io.fast_rep_in.bits),\n\
      678:     fromMmioSource(io.lsq.uncache.bits),\n679:     fromNcSource(io.lsq.nc_ldin.bits),\n\
      680:     fromNormalReplaySource(io.replay.bits),\n681:     fromPrefetchSource(io.prefetch_req.bits),\n\
      682:     fromVecIssueSource(io.vecldin.bits),\n683:     fromIntIssueSource(io.ldin.bits),\n\
      684:     (if (EnableLoadToLoadForward) fromLoadToLoadSource(io.l2l_fwd_in) else
      fromNullSource()),\n685:     fromPrefetchSource(io.prefetch_req.bits)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 692-702
    context: "692:   s0_tlb_vaddr := Mux(\n693:     s0_src_valid_vec(mab_idx),\n694:\
      \     io.misalign_ldin.bits.vaddr,\n695:     Mux(\n696:       s0_src_valid_vec(super_rep_idx)
      || s0_src_valid_vec(lsq_rep_idx),\n697:       io.replay.bits.vaddr,\n698:  \
      \     int_vec_vaddr\n699:     )\n700:   )\n701:   s0_dcache_vaddr := Mux(\n\
      702:     s0_src_select_vec(fast_rep_idx), io.fast_rep_in.bits.vaddr,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 746-756
    context: "746:   s0_tlb_hlv := Mux(\n747:     s0_src_valid_vec(mab_idx),\n748:\
      \     LSUOpType.isHlv(io.misalign_ldin.bits.uop.fuOpType),\n749:     Mux(\n\
      750:       s0_src_valid_vec(super_rep_idx) || s0_src_valid_vec(lsq_rep_idx),\n\
      751:       LSUOpType.isHlv(io.replay.bits.uop.fuOpType),\n752:       Mux(\n\
      753:         s0_src_valid_vec(int_iss_idx),\n754:         LSUOpType.isHlv(io.ldin.bits.uop.fuOpType),\n\
      755:         false.B\n756:       )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 759-769
    context: "759:   s0_tlb_hlvx := Mux(\n760:     s0_src_valid_vec(mab_idx),\n761:\
      \     LSUOpType.isHlvx(io.misalign_ldin.bits.uop.fuOpType),\n762:     Mux(\n\
      763:       s0_src_valid_vec(super_rep_idx) || s0_src_valid_vec(lsq_rep_idx),\n\
      764:       LSUOpType.isHlvx(io.replay.bits.uop.fuOpType),\n765:       Mux(\n\
      766:         s0_src_valid_vec(int_iss_idx),\n767:         LSUOpType.isHlvx(io.ldin.bits.uop.fuOpType),\n\
      768:         false.B\n769:       )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 824-843
    context: "824:   s0_out.misalignWith16Byte    := s0_misalignWith16Byte\n825: \
      \  s0_out.misalignNeedWakeUp := s0_misalignNeedWakeUp\n826:   s0_out.isFinalSplit
      := s0_finalSplit\n827: \n828:   // load fast replay\n829:   io.fast_rep_in.ready
      := (s0_can_go && io.dcache.req.ready && s0_src_ready_vec(fast_rep_idx))\n830:\
      \ \n831:   // mmio\n832:   io.lsq.uncache.ready := s0_mmio_fire\n833:   io.lsq.nc_ldin.ready
      := s0_src_ready_vec(nc_idx) && s0_can_go\n834: \n835:   // load flow source
      ready\n836:   // cache missed load has highest priority\n837:   // always accept
      cache missed load flow from load replay queue\n838:   io.replay.ready := (s0_can_go
      && io.dcache.req.ready && (s0_src_ready_vec(lsq_rep_idx) && !s0_rep_stall ||
      s0_src_select_vec(super_rep_idx)))\n839: \n840:   // accept load flow from rs
      when:\n841:   // 1) there is no lsq-replayed load\n842:   // 2) there is no
      fast replayed load\n843:   // 3) there is no high confidence prefetch request"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 839-851
    context: "839: \n840:   // accept load flow from rs when:\n841:   // 1) there
      is no lsq-replayed load\n842:   // 2) there is no fast replayed load\n843: \
      \  // 3) there is no high confidence prefetch request\n844:   io.vecldin.ready
      := s0_can_go && io.dcache.req.ready && s0_src_ready_vec(vec_iss_idx)\n845: \
      \  io.ldin.ready := s0_can_go && io.dcache.req.ready && s0_src_ready_vec(int_iss_idx)\n\
      846:   io.misalign_ldin.ready := s0_can_go && io.dcache.req.ready && s0_src_ready_vec(mab_idx)\n\
      847: \n848:   // for hw prefetch load flow feedback, to be added later\n849:\
      \   // io.prefetch_in.ready := s0_hw_prf_select\n850: \n851:   // dcache replacement
      extra info"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 848-858
    context: "848:   // for hw prefetch load flow feedback, to be added later\n849:\
      \   // io.prefetch_in.ready := s0_hw_prf_select\n850: \n851:   // dcache replacement
      extra info\n852:   // TODO: should prefetch load update replacement?\n853: \
      \  io.dcache.replacementUpdated := Mux(s0_src_select_vec(lsq_rep_idx) || s0_src_select_vec(super_rep_idx),
      io.replay.bits.replacementUpdated, false.B)\n854: \n855:   // load wakeup\n\
      856:   // TODO: vector load wakeup? frm_mabuf wakeup?\n857:   val s0_wakeup_selector
      = Seq(\n858:     s0_misalign_wakeup_fire,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 856-866
    context: "856:   // TODO: vector load wakeup? frm_mabuf wakeup?\n857:   val s0_wakeup_selector
      = Seq(\n858:     s0_misalign_wakeup_fire,\n859:     s0_src_valid_vec(super_rep_idx),\n\
      860:     s0_src_valid_vec(fast_rep_idx),\n861:     s0_mmio_fire,\n862:     s0_nc_fire,\n\
      863:     s0_src_valid_vec(lsq_rep_idx),\n864:     s0_src_valid_vec(int_iss_idx)\n\
      865:   )\n866:   val s0_wakeup_format = Seq("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 863-877
    context: "863:     s0_src_valid_vec(lsq_rep_idx),\n864:     s0_src_valid_vec(int_iss_idx)\n\
      865:   )\n866:   val s0_wakeup_format = Seq(\n867:     io.misalign_ldin.bits.uop,\n\
      868:     io.replay.bits.uop,\n869:     io.fast_rep_in.bits.uop,\n870:     io.lsq.uncache.bits.uop,\n\
      871:     io.lsq.nc_ldin.bits.uop,\n872:     io.replay.bits.uop,\n873:     io.ldin.bits.uop,\n\
      874:   )\n875:   val s0_wakeup_uop = ParallelPriorityMux(s0_wakeup_selector,
      s0_wakeup_format)\n876:   io.wakeup.valid := s0_fire && !s0_sel_src.isvec &&
      !s0_sel_src.frm_mabuf && (\n877:     s0_src_valid_vec(super_rep_idx) ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 877-887
    context: "877:     s0_src_valid_vec(super_rep_idx) ||\n878:     s0_src_valid_vec(fast_rep_idx)
      ||\n879:     s0_src_valid_vec(lsq_rep_idx) ||\n880:     (s0_src_valid_vec(int_iss_idx)
      && !s0_sel_src.prf &&\n881:     !s0_src_valid_vec(vec_iss_idx) && !s0_src_valid_vec(high_pf_idx))\n\
      882:   ) || s0_mmio_fire || s0_nc_fire || s0_misalign_wakeup_fire\n883:   io.wakeup.bits
      := s0_wakeup_uop\n884: \n885:   // prefetch.i(Zicbop)\n886:   io.ifetchPrefetch.valid
      := RegNext(s0_src_select_vec(int_iss_idx) && s0_sel_src.prf_i)\n887:   io.ifetchPrefetch.bits.vaddr
      := RegEnable(s0_out.vaddr, 0.U, s0_src_select_vec(int_iss_idx) && s0_sel_src.prf_i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 884-897
    context: "884: \n885:   // prefetch.i(Zicbop)\n886:   io.ifetchPrefetch.valid
      := RegNext(s0_src_select_vec(int_iss_idx) && s0_sel_src.prf_i)\n887:   io.ifetchPrefetch.bits.vaddr
      := RegEnable(s0_out.vaddr, 0.U, s0_src_select_vec(int_iss_idx) && s0_sel_src.prf_i)\n\
      888: \n889:   XSDebug(io.dcache.req.fire,\n890:     p\"[DCACHE LOAD REQ] pc
      ${Hexadecimal(s0_sel_src.uop.pc)}, vaddr ${Hexadecimal(s0_dcache_vaddr)}\\n\"\
      \n891:   )\n892:   XSDebug(s0_valid,\n893:     p\"S0: pc ${Hexadecimal(s0_out.uop.pc)},
      lId ${Hexadecimal(s0_out.uop.lqIdx.asUInt)}, \" +\n894:     p\"vaddr ${Hexadecimal(s0_out.vaddr)},
      mask ${Hexadecimal(s0_out.mask)}\\n\")\n895: \n896:   // Pipeline\n897:   //
      --------------------------------------------------------------------------------"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 896-918
    context: "896:   // Pipeline\n897:   // --------------------------------------------------------------------------------\n\
      898:   // stage 1\n899:   // --------------------------------------------------------------------------------\n\
      900:   // TLB resp (send paddr to dcache)\n901:   val s1_valid      = RegInit(false.B)\n\
      902:   val s1_in         = Wire(new LqWriteBundle)\n903:   val s1_out      \
      \  = Wire(new LqWriteBundle)\n904:   val s1_kill       = Wire(Bool())\n905:\
      \   val s1_can_go     = s2_ready\n906:   val s1_fire       = s1_valid && !s1_kill
      && s1_can_go\n907:   val s1_vecActive        = RegEnable(s0_out.vecActive, true.B,
      s0_fire)\n908:   val s1_nc_with_data = RegNext(s0_nc_with_data)\n909: \n910:\
      \   s1_ready := !s1_valid || s1_kill || s2_ready\n911:   when (s0_fire) { s1_valid
      := true.B }\n912:   .elsewhen (s1_fire) { s1_valid := false.B }\n913:   .elsewhen
      (s1_kill) { s1_valid := false.B }\n914:   s1_in   := RegEnable(s0_out, s0_fire)\n\
      915: \n916:   val s1_fast_rep_dly_kill = RegEnable(io.fast_rep_in.bits.lateKill,
      io.fast_rep_in.valid) && s1_in.isFastReplay\n917:   val s1_fast_rep_dly_err
      =  RegEnable(io.fast_rep_in.bits.delayedLoadError, io.fast_rep_in.valid) &&
      s1_in.isFastReplay\n918:   val s1_l2l_fwd_dly_err  = RegEnable(io.l2l_fwd_in.dly_ld_err,
      io.l2l_fwd_in.valid) && s1_in.isFastPath"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 922-935
    context: "922:   val s1_vaddr            = Wire(UInt())\n923:   val s1_paddr_dup_lsu\
      \    = Wire(UInt())\n924:   val s1_gpaddr_dup_lsu   = Wire(UInt())\n925:   val
      s1_paddr_dup_dcache = Wire(UInt())\n926:   val s1_exception        = ExceptionNO.selectByFu(s1_out.uop.exceptionVec,
      LduCfg).asUInt.orR   // af & pf exception were modified below.\n927:   val s1_tlb_miss\
      \         = io.tlb.resp.bits.miss && io.tlb.resp.valid && s1_valid\n928:   val
      s1_tlb_fast_miss    = io.tlb.resp.bits.fastMiss && io.tlb.resp.valid && s1_valid\n\
      929:   val s1_tlb_hit          = !io.tlb.resp.bits.miss && io.tlb.resp.valid
      && s1_valid\n930:   val s1_pbmt             = Mux(s1_tlb_hit, io.tlb.resp.bits.pbmt.head,
      0.U(Pbmt.width.W))\n931:   val s1_nc               = s1_in.nc\n932:   val s1_prf\
      \              = s1_in.isPrefetch\n933:   val s1_hw_prf           = s1_in.isHWPrefetch\n\
      934:   val s1_sw_prf           = s1_prf && !s1_hw_prf\n935:   val s1_tlb_memidx\
      \       = io.tlb.resp.bits.memidx"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 946-956
    context: "946:     s1_out.uop.debugInfo.tlbRespTime := GTimer()\n947:   }\n948:\
      \ \n949:   io.tlb.req_kill   := s1_kill || s1_dly_err\n950:   io.tlb.req.bits.pmp_addr
      := s1_in.paddr\n951:   io.tlb.resp.ready := true.B\n952: \n953:   io.dcache.s1_paddr_dup_lsu\
      \    <> s1_paddr_dup_lsu\n954:   io.dcache.s1_paddr_dup_dcache <> s1_paddr_dup_dcache\n\
      955:   io.dcache.s1_kill             := s1_kill || s1_dly_err || s1_tlb_miss
      || s1_exception\n956:   io.dcache.s1_kill_data_read   := s1_kill || s1_dly_err
      || s1_tlb_fast_miss"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 954-964
    context: "954:   io.dcache.s1_paddr_dup_dcache <> s1_paddr_dup_dcache\n955:  \
      \ io.dcache.s1_kill             := s1_kill || s1_dly_err || s1_tlb_miss || s1_exception\n\
      956:   io.dcache.s1_kill_data_read   := s1_kill || s1_dly_err || s1_tlb_fast_miss\n\
      957: \n958:   // store to load forwarding\n959:   io.sbuffer.valid := s1_valid
      && !(s1_exception || s1_tlb_miss || s1_kill || s1_dly_err || s1_prf)\n960: \
      \  io.sbuffer.vaddr := s1_vaddr\n961:   io.sbuffer.paddr := s1_paddr_dup_lsu\n\
      962:   io.sbuffer.uop   := s1_in.uop\n963:   io.sbuffer.sqIdx := s1_in.uop.sqIdx\n\
      964:   io.sbuffer.mask  := s1_in.mask"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 962-972
    context: "962:   io.sbuffer.uop   := s1_in.uop\n963:   io.sbuffer.sqIdx := s1_in.uop.sqIdx\n\
      964:   io.sbuffer.mask  := s1_in.mask\n965:   io.sbuffer.pc    := s1_in.uop.pc
      // FIXME: remove it\n966: \n967:   io.ubuffer.valid := s1_valid && s1_nc_with_data
      && !(s1_exception || s1_tlb_miss || s1_kill || s1_dly_err || s1_prf)\n968: \
      \  io.ubuffer.vaddr := s1_vaddr\n969:   io.ubuffer.paddr := s1_paddr_dup_lsu\n\
      970:   io.ubuffer.uop   := s1_in.uop\n971:   io.ubuffer.sqIdx := s1_in.uop.sqIdx\n\
      972:   io.ubuffer.mask  := s1_in.mask"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 970-987
    context: "970:   io.ubuffer.uop   := s1_in.uop\n971:   io.ubuffer.sqIdx := s1_in.uop.sqIdx\n\
      972:   io.ubuffer.mask  := s1_in.mask\n973:   io.ubuffer.pc    := s1_in.uop.pc
      // FIXME: remove it\n974: \n975:   io.lsq.forward.valid     := s1_valid && !(s1_exception
      || s1_tlb_miss || s1_kill || s1_dly_err || s1_prf)\n976:   io.lsq.forward.vaddr\
      \     := s1_vaddr\n977:   io.lsq.forward.paddr     := s1_paddr_dup_lsu\n978:\
      \   io.lsq.forward.uop       := s1_in.uop\n979:   io.lsq.forward.sqIdx     :=
      s1_in.uop.sqIdx\n980:   io.lsq.forward.sqIdxMask := 0.U\n981:   io.lsq.forward.mask\
      \      := s1_in.mask\n982:   io.lsq.forward.pc        := s1_in.uop.pc // FIXME:
      remove it\n983: \n984:   // st-ld violation query\n985:     // if store unit
      is 128-bits memory access, need match 128-bit\n986:   val s1_nuke_paddr_match
      = VecInit((0 until StorePipelineWidth).map{\n987:     case index => {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 995-1005
    context: "995:       )\n996:     }\n997:   })\n998:   val s1_nuke = VecInit((0
      until StorePipelineWidth).map(w => {\n999:                        io.stld_nuke_query(w).valid
      && // query valid\n1000:                        isAfter(s1_in.uop.robIdx, io.stld_nuke_query(w).bits.robIdx)
      && // older store\n1001:                        s1_nuke_paddr_match(w) && //
      paddr match\n1002:                        (s1_in.mask & io.stld_nuke_query(w).bits.mask).orR
      // data mask contain\n1003:                       })).asUInt.orR && !s1_tlb_miss\n\
      1004: \n1005:   s1_out                   := s1_in"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1013-1024
    context: "1013:   s1_out.tlbMiss           := s1_tlb_miss\n1014:   s1_out.ptwBack\
      \           := io.tlb.resp.bits.ptwBack\n1015:   s1_out.rep_info.debug    :=
      s1_in.uop.debugInfo\n1016:   s1_out.rep_info.nuke     := s1_nuke && !s1_sw_prf\n\
      1017:   s1_out.delayedLoadError  := s1_dly_err\n1018:   s1_out.nc := (s1_nc
      || Pbmt.isNC(s1_pbmt)) && !s1_prf\n1019:   s1_out.mmio := Pbmt.isIO(s1_pbmt)\n\
      1020: \n1021:   when (!s1_dly_err) {\n1022:     // current ori test will cause
      the case of ldest == 0, below will be modifeid in the future.\n1023:     //
      af & pf exception were modified\n1024:     // if is tlbNoQuery request, don't
      trigger exception from tlb resp"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1050-1069
    context: "1050:   val s1_addr_misaligned       = WireInit(false.B)\n1051:   val
      s1_fast_mismatch         = WireInit(false.B)\n1052:   val s1_ptr_chasing_canceled\
      \  = WireInit(false.B)\n1053:   val s1_cancel_ptr_chasing    = WireInit(false.B)\n\
      1054: \n1055:   val s1_redirect_reg = Wire(Valid(new Redirect))\n1056:   s1_redirect_reg.bits
      := RegEnable(io.redirect.bits, io.redirect.valid)\n1057:   s1_redirect_reg.valid
      := GatedValidRegNext(io.redirect.valid)\n1058: \n1059:   s1_kill := s1_fast_rep_dly_kill
      ||\n1060:     s1_cancel_ptr_chasing ||\n1061:     s1_in.uop.robIdx.needFlush(io.redirect)
      ||\n1062:     (s1_in.uop.robIdx.needFlush(s1_redirect_reg) && !GatedValidRegNext(s0_try_ptr_chasing))
      ||\n1063:     RegEnable(s0_kill, false.B, io.ldin.valid ||\n1064:       io.vecldin.valid
      || io.replay.valid ||\n1065:       io.l2l_fwd_in.valid || io.fast_rep_in.valid
      ||\n1066:       io.misalign_ldin.valid || io.lsq.nc_ldin.valid\n1067:     )\n\
      1068: \n1069:   if (EnableLoadToLoadForward) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1097-1112
    context: "1097:       s1_in.uop.debugInfo.tlbFirstReqTime := GTimer()\n1098: \
      \      s1_in.uop.debugInfo.tlbRespTime     := GTimer()\n1099:     }\n1100: \
      \    when (!s1_cancel_ptr_chasing) {\n1101:       s0_ptr_chasing_canceled :=
      s1_try_ptr_chasing &&\n1102:         !io.replay.fire && !io.fast_rep_in.fire
      &&\n1103:         !(s0_src_valid_vec(high_pf_idx) && io.canAcceptHighConfPrefetch)
      &&\n1104:         !io.misalign_ldin.fire &&\n1105:         !io.lsq.nc_ldin.valid\n\
      1106:       when (s1_try_ptr_chasing) {\n1107:         io.ldin.ready := true.B\n\
      1108:       }\n1109:     }\n1110:   }\n1111: \n1112:   // pre-calcuate sqIdx
      mask in s0, then send it to lsq in s1 for forwarding"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1112-1129
    context: "1112:   // pre-calcuate sqIdx mask in s0, then send it to lsq in s1
      for forwarding\n1113:   val s1_sqIdx_mask = RegEnable(UIntToMask(s0_out.uop.sqIdx.value,
      StoreQueueSize), s0_fire)\n1114:   // to enable load-load, sqIdxMask must be
      calculated based on ldin.uop\n1115:   // If the timing here is not OK, load-load
      forwarding has to be disabled.\n1116:   // Or we calculate sqIdxMask at RS??\n\
      1117:   io.lsq.forward.sqIdxMask := s1_sqIdx_mask\n1118:   if (EnableLoadToLoadForward)
      {\n1119:     when (s1_try_ptr_chasing) {\n1120:       io.lsq.forward.sqIdxMask
      := UIntToMask(io.ldin.bits.uop.sqIdx.value, StoreQueueSize)\n1121:     }\n1122:\
      \   }\n1123: \n1124:   io.forward_mshr.valid  := s1_valid && s1_out.forward_tlDchannel\n\
      1125:   io.forward_mshr.mshrid := s1_out.mshrid\n1126:   io.forward_mshr.paddr\
      \  := s1_out.paddr\n1127: \n1128:   val loadTrigger = Module(new MemTrigger(MemType.LOAD))\n\
      1129:   loadTrigger.io.fromCsrTrigger.tdataVec             := io.fromCsrTrigger.tdataVec"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1144-1156
    context: "1144:     loadTrigger.io.toLoadStore.triggerVaddr - s1_in.vecBaseVaddr,\n\
      1145:     s1_in.vaddr + genVFirstUnmask(s1_in.mask).asUInt - s1_in.vecBaseVaddr\n\
      1146:   )\n1147:   s1_out.vecTriggerMask := Mux(s1_trigger_debug_mode || s1_trigger_breakpoint,
      loadTrigger.io.toLoadStore.triggerMask, 0.U)\n1148: \n1149:   XSDebug(s1_valid,\n\
      1150:     p\"S1: pc ${Hexadecimal(s1_out.uop.pc)}, lId ${Hexadecimal(s1_out.uop.lqIdx.asUInt)},
      tlb_miss ${io.tlb.resp.bits.miss}, \" +\n1151:     p\"paddr ${Hexadecimal(s1_out.paddr)},
      mmio ${s1_out.mmio}\\n\")\n1152: \n1153:   // Pipeline\n1154:   // --------------------------------------------------------------------------------\n\
      1155:   // stage 2\n1156:   // --------------------------------------------------------------------------------"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1153-1168
    context: "1153:   // Pipeline\n1154:   // --------------------------------------------------------------------------------\n\
      1155:   // stage 2\n1156:   // --------------------------------------------------------------------------------\n\
      1157:   // s2: DCache resp\n1158:   val s2_valid  = RegInit(false.B)\n1159:\
      \   val s2_in     = Wire(new LqWriteBundle)\n1160:   val s2_out    = Wire(new
      LqWriteBundle)\n1161:   val s2_kill   = Wire(Bool())\n1162:   val s2_can_go
      = s3_ready\n1163:   val s2_fire   = s2_valid && !s2_kill && s2_can_go\n1164:\
      \   val s2_vecActive = RegEnable(s1_out.vecActive, true.B, s1_fire)\n1165: \
      \  val s2_isvec  = RegEnable(s1_out.isvec, false.B, s1_fire)\n1166:   val s2_data_select\
      \  = genRdataOH(s2_out.uop)\n1167:   val s2_data_select_by_offset = genDataSelectByOffset(s2_out.paddr(3,
      0))\n1168:   val s2_frm_mabuf = s2_in.isFrmMisAlignBuf"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1167-1191
    context: "1167:   val s2_data_select_by_offset = genDataSelectByOffset(s2_out.paddr(3,
      0))\n1168:   val s2_frm_mabuf = s2_in.isFrmMisAlignBuf\n1169:   val s2_pbmt
      = RegEnable(s1_pbmt, s1_fire)\n1170:   val s2_trigger_debug_mode = RegEnable(s1_trigger_debug_mode,
      false.B, s1_fire)\n1171:   val s2_nc_with_data = RegNext(s1_nc_with_data)\n\
      1172:   val s2_mmio_req = Wire(Valid(new MemExuOutput))\n1173:   s2_mmio_req.valid
      := RegNextN(io.lsq.uncache.fire, 2, Some(false.B))\n1174:   s2_mmio_req.bits\
      \  := RegNextN(io.lsq.uncache.bits, 2)\n1175: \n1176:   val s3_misalign_wakeup_req
      = Wire(Valid(new LqWriteBundle))\n1177:   val s3_misalign_wakeup_req_bits =
      WireInit(0.U.asTypeOf(new LqWriteBundle))\n1178:   connectSamePort(s3_misalign_wakeup_req_bits,
      io.misalign_ldin.bits)\n1179:   s3_misalign_wakeup_req.valid := RegNextN(io.misalign_ldin.bits.misalignNeedWakeUp
      && io.misalign_ldin.fire, 3, Some(false.B))\n1180:   s3_misalign_wakeup_req.bits\
      \  := RegNextN(s3_misalign_wakeup_req_bits, 3)\n1181: \n1182:   s2_kill := s2_in.uop.robIdx.needFlush(io.redirect)\n\
      1183:   s2_ready := !s2_valid || s2_kill || s3_ready\n1184:   when (s1_fire)
      { s2_valid := true.B }\n1185:   .elsewhen (s2_fire) { s2_valid := false.B }\n\
      1186:   .elsewhen (s2_kill) { s2_valid := false.B }\n1187:   s2_in := RegEnable(s1_out,
      s1_fire)\n1188: \n1189:   val s2_pmp = WireInit(io.pmp)\n1190:   val s2_isMisalign
      = WireInit(s2_in.isMisalign)\n1191: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1203-1215
    context: "1203:     s2_in.uop.exceptionVec(loadAccessFault) ||\n1204:     s2_in.uop.exceptionVec(loadPageFault)\
      \   ||\n1205:     s2_in.uop.exceptionVec(loadGuestPageFault)\n1206:   )\n1207:\
      \   // This real physical address is located in uncache space.\n1208:   val
      s2_actually_uncache = !s2_in.tlbMiss && !s2_un_access_exception && Pbmt.isPMA(s2_pbmt)
      && s2_pmp.mmio || s2_in.nc || s2_in.mmio\n1209:   val s2_uncache = !s2_prf &&
      s2_actually_uncache\n1210:   val s2_memBackTypeMM = !s2_pmp.mmio\n1211:   when
      (!s2_in.delayedLoadError) {\n1212:     s2_exception_vec(loadAccessFault) :=
      s2_vecActive && (\n1213:       s2_in.uop.exceptionVec(loadAccessFault) ||\n\
      1214:       s2_pmp.ld ||\n1215:       s2_isvec && s2_uncache ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1224-1238
    context: "1224:     s2_exception_vec := 0.U.asTypeOf(s2_exception_vec.cloneType)\n\
      1225:     s2_isMisalign := false.B\n1226:   }\n1227:   val s2_exception = s2_vecActive
      &&\n1228:                     (s2_trigger_debug_mode || ExceptionNO.selectByFu(s2_exception_vec,
      LduCfg).asUInt.orR)\n1229:   val s2_mis_align = s2_valid && GatedValidRegNext(io.csrCtrl.hd_misalign_ld_enable)
      &&\n1230:                      s2_out.isMisalign && !s2_in.misalignWith16Byte
      && !s2_exception_vec(breakPoint) && !s2_trigger_debug_mode && !s2_uncache\n\
      1231:   val (s2_fwd_frm_d_chan, s2_fwd_data_frm_d_chan, s2_d_corrupt) = io.tl_d_channel.forward(s1_valid
      && s1_out.forward_tlDchannel, s1_out.mshrid, s1_out.paddr)\n1232:   val (s2_fwd_data_valid,
      s2_fwd_frm_mshr, s2_fwd_data_frm_mshr, s2_mshr_corrupt) = io.forward_mshr.forward()\n\
      1233:   val s2_fwd_frm_d_chan_or_mshr = s2_fwd_data_valid && (s2_fwd_frm_d_chan
      || s2_fwd_frm_mshr)\n1234: \n1235:   // writeback access fault caused by ecc
      error / bus error\n1236:   // * ecc data error is slow to generate, so we will
      not use it until load stage 3\n1237:   // * in load stage 3, an extra signal
      io.load_error will be used to\n1238:   // * if pbmt =/= 0, mmio is up to pbmt;
      otherwise, it's up to pmp"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1235-1254
    context: "1235:   // writeback access fault caused by ecc error / bus error\n\
      1236:   // * ecc data error is slow to generate, so we will not use it until
      load stage 3\n1237:   // * in load stage 3, an extra signal io.load_error will
      be used to\n1238:   // * if pbmt =/= 0, mmio is up to pbmt; otherwise, it's
      up to pmp\n1239:   val s2_tlb_hit = RegNext(s1_tlb_hit)\n1240:   val s2_mmio
      = !s2_prf &&\n1241:     !s2_exception && !s2_in.tlbMiss &&\n1242:     Mux(Pbmt.isUncache(s2_pbmt),
      s2_in.mmio, s2_tlb_hit && s2_pmp.mmio)\n1243: \n1244:   val s2_full_fwd    \
      \  = Wire(Bool())\n1245:   val s2_mem_amb       = s2_in.uop.storeSetHit &&\n\
      1246:                          io.lsq.forward.addrInvalid && RegNext(io.lsq.forward.valid)\n\
      1247: \n1248:   val s2_tlb_miss      = s2_in.tlbMiss\n1249:   val s2_fwd_fail\
      \      = io.lsq.forward.dataInvalid && RegNext(io.lsq.forward.valid)\n1250:\
      \   val s2_dcache_miss   = io.dcache.resp.bits.miss &&\n1251:              \
      \            !s2_fwd_frm_d_chan_or_mshr &&\n1252:                          !s2_full_fwd
      && !s2_in.nc\n1253: \n1254:   val s2_mq_nack       = io.dcache.s2_mq_nack &&"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1262-1275
    context: "1262:   val s2_wpu_pred_fail = io.dcache.s2_wpu_pred_fail &&\n1263:\
      \                         !s2_fwd_frm_d_chan_or_mshr &&\n1264:             \
      \            !s2_full_fwd && !s2_in.nc\n1265: \n1266:   val s2_rar_nack    \
      \  = io.lsq.ldld_nuke_query.req.valid &&\n1267:                          !io.lsq.ldld_nuke_query.req.ready\n\
      1268: \n1269:   val s2_raw_nack      = io.lsq.stld_nuke_query.req.valid &&\n\
      1270:                          !io.lsq.stld_nuke_query.req.ready\n1271:   //
      st-ld violation query\n1272:   //  NeedFastRecovery Valid when\n1273:   // \
      \ 1. Fast recovery query request Valid.\n1274:   //  2. Load instruction is
      younger than requestors(store instructions).\n1275:   //  3. Physical address
      match."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1286-1296
    context: "1286:       )\n1287:     }\n1288:   })\n1289:   val s2_nuke        \
      \  = VecInit((0 until StorePipelineWidth).map(w => {\n1290:                \
      \           io.stld_nuke_query(w).valid && // query valid\n1291:           \
      \                isAfter(s2_in.uop.robIdx, io.stld_nuke_query(w).bits.robIdx)
      && // older store\n1292:                           s2_nuke_paddr_match(w) &&
      // paddr match\n1293:                           (s2_in.mask & io.stld_nuke_query(w).bits.mask).orR
      // data mask contain\n1294:                         })).asUInt.orR && !s2_tlb_miss
      || s2_in.rep_info.nuke\n1295: \n1296:   val s2_cache_handled   = io.dcache.resp.bits.handled"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1300-1312
    context: "1300:   val s2_troublem        = !s2_exception &&\n1301:           \
      \                 (!s2_uncache || s2_nc_with_data) &&\n1302:               \
      \             !s2_prf &&\n1303:                            !s2_in.delayedLoadError\n\
      1304: \n1305:   io.dcache.resp.ready  := true.B\n1306:   val s2_dcache_should_resp
      = !(s2_in.tlbMiss || s2_exception || s2_in.delayedLoadError || s2_uncache ||
      s2_prf)\n1307:   assert(!(s2_valid && (s2_dcache_should_resp && !io.dcache.resp.valid)),
      \"DCache response got lost\")\n1308: \n1309:   // fast replay require\n1310:\
      \   val s2_dcache_fast_rep = (s2_mq_nack || !s2_dcache_miss && (s2_bank_conflict
      || s2_wpu_pred_fail))\n1311:   val s2_nuke_fast_rep   = !s2_mq_nack &&\n1312:\
      \                            !s2_dcache_miss &&"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1331-1347
    context: "1331:   // We will generate misaligned exceptions at mmio.\n1332:  \
      \ val s2_real_exceptionVec = WireInit(s2_exception_vec)\n1333:   s2_real_exceptionVec(loadAddrMisaligned)
      := (s2_out.isMisalign || s2_out.isFrmMisAlignBuf) && s2_uncache && !s2_isvec\n\
      1334:   s2_real_exceptionVec(loadAccessFault) := s2_exception_vec(loadAccessFault)
      ||\n1335:     s2_fwd_frm_d_chan && s2_d_corrupt ||\n1336:     s2_fwd_data_valid
      && s2_fwd_frm_mshr && s2_mshr_corrupt\n1337:   val s2_real_exception = s2_vecActive
      &&\n1338:     (s2_trigger_debug_mode || ExceptionNO.selectByFu(s2_real_exceptionVec,
      LduCfg).asUInt.orR)\n1339: \n1340:   val s2_fwd_vp_match_invalid = io.lsq.forward.matchInvalid
      || io.sbuffer.matchInvalid || io.ubuffer.matchInvalid\n1341:   val s2_vp_match_fail
      = s2_fwd_vp_match_invalid && s2_troublem\n1342:   val s2_safe_wakeup = !s2_out.rep_info.need_rep
      && !s2_mmio && (!s2_in.nc || s2_nc_with_data) && !s2_mis_align && !s2_real_exception
      // don't need to replay and is not a mmio\\misalign no data\n1343:   val s2_safe_writeback
      = s2_real_exception || s2_safe_wakeup || s2_vp_match_fail\n1344: \n1345:   //
      ld-ld violation require\n1346:   /**\n1347:     * In order to ensure timing,
      the RAR enqueue conditions need to be compromised, worst source of timing from
      pmp and missQueue."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1347-1372
    context: "1347:     * In order to ensure timing, the RAR enqueue conditions need
      to be compromised, worst source of timing from pmp and missQueue.\n1348:   \
      \  *   * if LoadQueueRARSize == VirtualLoadQueueSize, just need to exclude prefetching.\n\
      1349:     *   * if LoadQueueRARSize < VirtualLoadQueueSize, need to consider
      the situation of s2_can_query\n1350:     */\n1351:   if (LoadQueueRARSize ==
      VirtualLoadQueueSize) {\n1352:     io.lsq.ldld_nuke_query.req.valid        \
      \   := s2_valid && !s2_prf\n1353:   } else {\n1354:     io.lsq.ldld_nuke_query.req.valid\
      \           := s2_valid && s2_can_query\n1355:   }\n1356:   io.lsq.ldld_nuke_query.req.bits.uop\
      \        := s2_in.uop\n1357:   io.lsq.ldld_nuke_query.req.bits.mask       :=
      s2_in.mask\n1358:   io.lsq.ldld_nuke_query.req.bits.paddr      := s2_in.paddr\n\
      1359:   io.lsq.ldld_nuke_query.req.bits.data_valid := Mux(s2_full_fwd || s2_fwd_data_valid
      || s2_nc_with_data, true.B, !s2_dcache_miss)\n1360:   io.lsq.ldld_nuke_query.req.bits.is_nc
      := s2_nc_with_data\n1361: \n1362:   // st-ld violation require\n1363:   io.lsq.stld_nuke_query.req.valid\
      \           := s2_valid && s2_can_query\n1364:   io.lsq.stld_nuke_query.req.bits.uop\
      \        := s2_in.uop\n1365:   io.lsq.stld_nuke_query.req.bits.mask       :=
      s2_in.mask\n1366:   io.lsq.stld_nuke_query.req.bits.paddr      := s2_in.paddr\n\
      1367:   io.lsq.stld_nuke_query.req.bits.data_valid := Mux(s2_full_fwd || s2_fwd_data_valid
      || s2_nc_with_data, true.B, !s2_dcache_miss)\n1368:   io.lsq.stld_nuke_query.req.bits.is_nc
      := s2_nc_with_data\n1369: \n1370:   // merge forward result\n1371:   // lsq
      has higher priority than sbuffer\n1372:   val s2_fwd_mask = Wire(Vec((VLEN/8),
      Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1369-1384
    context: "1369: \n1370:   // merge forward result\n1371:   // lsq has higher priority
      than sbuffer\n1372:   val s2_fwd_mask = Wire(Vec((VLEN/8), Bool()))\n1373: \
      \  val s2_fwd_data = Wire(Vec((VLEN/8), UInt(8.W)))\n1374:   s2_full_fwd :=
      ((~s2_fwd_mask.asUInt).asUInt & s2_in.mask) === 0.U && !io.lsq.forward.dataInvalid\n\
      1375:   // generate XLEN/8 Muxs\n1376:   for (i <- 0 until VLEN / 8) {\n1377:\
      \     s2_fwd_mask(i) := io.lsq.forward.forwardMask(i) || io.sbuffer.forwardMask(i)
      || io.ubuffer.forwardMask(i)\n1378:     s2_fwd_data(i) :=\n1379:       Mux(io.lsq.forward.forwardMask(i),
      io.lsq.forward.forwardData(i),\n1380:       Mux(s2_nc_with_data, io.ubuffer.forwardData(i),\n\
      1381:       io.sbuffer.forwardData(i)))\n1382:   }\n1383: \n1384:   XSDebug(s2_fire,
      \"[FWD LOAD RESP] pc %x fwd %x(%b) + %x(%b)\\n\","
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1381-1391
    context: "1381:       io.sbuffer.forwardData(i)))\n1382:   }\n1383: \n1384:  \
      \ XSDebug(s2_fire, \"[FWD LOAD RESP] pc %x fwd %x(%b) + %x(%b)\\n\",\n1385:\
      \     s2_in.uop.pc,\n1386:     io.lsq.forward.forwardData.asUInt, io.lsq.forward.forwardMask.asUInt,\n\
      1387:     s2_in.forwardData.asUInt, s2_in.forwardMask.asUInt\n1388:   )\n1389:\
      \ \n1390:   //\n1391:   s2_out                     := s2_in"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1389-1402
    context: "1389: \n1390:   //\n1391:   s2_out                     := s2_in\n1392:\
      \   s2_out.uop.fpWen           := s2_in.uop.fpWen\n1393:   s2_out.nc       \
      \           := s2_in.nc\n1394:   s2_out.mmio                := s2_mmio\n1395:\
      \   s2_out.memBackTypeMM       := s2_memBackTypeMM\n1396:   s2_out.isMisalign\
      \          := s2_isMisalign\n1397:   s2_out.uop.flushPipe       := false.B\n\
      1398:   s2_out.uop.exceptionVec    := s2_real_exceptionVec\n1399:   s2_out.forwardMask\
      \         := s2_fwd_mask\n1400:   s2_out.forwardData         := s2_fwd_data\n\
      1401:   s2_out.handledByMSHR       := s2_cache_handled\n1402:   s2_out.miss\
      \                := s2_dcache_miss && s2_troublem"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1418-1429
    context: "1418:   s2_out.rep_info.wpu_fail        := s2_wpu_pred_fail && s2_troublem\n\
      1419:   s2_out.rep_info.rar_nack        := s2_rar_nack && s2_troublem\n1420:\
      \   s2_out.rep_info.raw_nack        := s2_raw_nack && s2_troublem\n1421:   s2_out.rep_info.nuke\
      \            := s2_nuke && s2_troublem\n1422:   s2_out.rep_info.full_fwd   \
      \     := s2_data_fwded\n1423:   s2_out.rep_info.data_inv_sq_idx := io.lsq.forward.dataInvalidSqIdx\n\
      1424:   s2_out.rep_info.addr_inv_sq_idx := io.lsq.forward.addrInvalidSqIdx\n\
      1425:   s2_out.rep_info.rep_carry       := io.dcache.resp.bits.replayCarry\n\
      1426:   s2_out.rep_info.mshr_id         := io.dcache.resp.bits.mshr_id\n1427:\
      \   s2_out.rep_info.last_beat       := s2_in.paddr(log2Up(refillBytes))\n1428:\
      \   s2_out.rep_info.debug           := s2_in.uop.debugInfo\n1429:   s2_out.rep_info.tlb_id\
      \          := io.tlb_hint.id"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1430-1445
    context: "1430:   s2_out.rep_info.tlb_full        := io.tlb_hint.full\n1431: \n\
      1432:   // if forward fail, replay this inst from fetch\n1433:   val debug_fwd_fail_rep
      = s2_fwd_fail && !s2_troublem && !s2_in.tlbMiss\n1434:   // if ld-ld violation
      is detected, replay from this inst from fetch\n1435:   val debug_ldld_nuke_rep
      = false.B // s2_ldld_violation && !s2_mmio && !s2_is_prefetch && !s2_in.tlbMiss\n\
      1436: \n1437:   // to be removed\n1438:   io.feedback_fast.valid           \
      \      := false.B\n1439:   io.feedback_fast.bits.hit              := false.B\n\
      1440:   io.feedback_fast.bits.flushState       := s2_in.ptwBack\n1441:   io.feedback_fast.bits.robIdx\
      \           := s2_in.uop.robIdx\n1442:   io.feedback_fast.bits.sqIdx       \
      \     := s2_in.uop.sqIdx\n1443:   io.feedback_fast.bits.lqIdx            :=
      s2_in.uop.lqIdx\n1444:   io.feedback_fast.bits.sourceType       := RSFeedbackType.lrqFull\n\
      1445:   io.feedback_fast.bits.dataInvalidSqIdx := DontCare"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1445-1463
    context: "1445:   io.feedback_fast.bits.dataInvalidSqIdx := DontCare\n1446: \n\
      1447:   io.ldCancel.ld1Cancel := false.B\n1448: \n1449:   // fast wakeup\n1450:\
      \   val s1_fast_uop_valid = WireInit(false.B)\n1451:   s1_fast_uop_valid :=\n\
      1452:     !io.dcache.s1_disable_fast_wakeup &&\n1453:     s1_valid &&\n1454:\
      \     !s1_kill &&\n1455:     !io.tlb.resp.bits.miss &&\n1456:     !io.lsq.forward.dataInvalidFast\n\
      1457:   io.fast_uop.valid := GatedValidRegNext(s1_fast_uop_valid) && (s2_valid
      && !s2_out.rep_info.need_rep && !s2_uncache && !(s2_prf && !s2_hw_prf)) && !s2_isvec
      && !s2_frm_mabuf\n1458:   io.fast_uop.bits := RegEnable(s1_out.uop, s1_fast_uop_valid)\n\
      1459: \n1460:   //\n1461:   io.s2_ptr_chasing                    := RegEnable(s1_try_ptr_chasing
      && !s1_cancel_ptr_chasing, false.B, s1_fire)\n1462: \n1463:   // RegNext prefetch
      train for better timing"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1461-1471
    context: "1461:   io.s2_ptr_chasing                    := RegEnable(s1_try_ptr_chasing
      && !s1_cancel_ptr_chasing, false.B, s1_fire)\n1462: \n1463:   // RegNext prefetch
      train for better timing\n1464:   // ** Now, prefetch train is valid at load
      s3 **\n1465:   val s2_prefetch_train_valid = WireInit(false.B)\n1466:   s2_prefetch_train_valid\
      \              := s2_valid && !s2_actually_uncache && (!s2_in.tlbMiss || s2_hw_prf)\n\
      1467:   io.prefetch_train.valid              := GatedValidRegNext(s2_prefetch_train_valid)\n\
      1468:   io.prefetch_train.bits.fromLsPipelineBundle(s2_in, latch = true, enable
      = s2_prefetch_train_valid)\n1469:   io.prefetch_train.bits.miss          :=
      RegEnable(io.dcache.resp.bits.miss, s2_prefetch_train_valid) // TODO: use trace
      with bank conflict?\n1470:   io.prefetch_train.bits.meta_prefetch := RegEnable(io.dcache.resp.bits.meta_prefetch,
      s2_prefetch_train_valid)\n1471:   io.prefetch_train.bits.meta_access   := RegEnable(io.dcache.resp.bits.meta_access,
      s2_prefetch_train_valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1477-1487
    context: "1477:   io.prefetch_train.bits.hasException := false.B\n1478:   io.s1_prefetch_spec
      := s1_fire\n1479:   io.s2_prefetch_spec := s2_prefetch_train_valid\n1480: \n\
      1481:   val s2_prefetch_train_l1_valid = WireInit(false.B)\n1482:   s2_prefetch_train_l1_valid\
      \              := s2_valid && !s2_actually_uncache\n1483:   io.prefetch_train_l1.valid\
      \              := GatedValidRegNext(s2_prefetch_train_l1_valid)\n1484:   io.prefetch_train_l1.bits.fromLsPipelineBundle(s2_in,
      latch = true, enable = s2_prefetch_train_l1_valid)\n1485:   io.prefetch_train_l1.bits.miss\
      \          := RegEnable(io.dcache.resp.bits.miss, s2_prefetch_train_l1_valid)\n\
      1486:   io.prefetch_train_l1.bits.meta_prefetch := RegEnable(io.dcache.resp.bits.meta_prefetch,
      s2_prefetch_train_l1_valid)\n1487:   io.prefetch_train_l1.bits.meta_access \
      \  := RegEnable(io.dcache.resp.bits.meta_access, s2_prefetch_train_l1_valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1500-1515
    context: "1500:     io.dcache.s1_pc := s1_out.uop.pc\n1501:     io.dcache.s2_pc
      := s2_out.uop.pc\n1502:   }\n1503:   io.dcache.s2_kill := s2_pmp.ld || s2_pmp.st
      || s2_actually_uncache || s2_kill\n1504: \n1505:   val s1_ld_left_fire = s1_valid
      && !s1_kill && s2_ready\n1506:   val s2_ld_valid_dup = RegInit(0.U(6.W))\n1507:\
      \   s2_ld_valid_dup := 0x0.U(6.W)\n1508:   when (s1_ld_left_fire && !s1_out.isHWPrefetch)
      { s2_ld_valid_dup := 0x3f.U(6.W) }\n1509:   when (s1_kill || s1_out.isHWPrefetch)
      { s2_ld_valid_dup := 0x0.U(6.W) }\n1510:   assert(RegNext((s2_valid === s2_ld_valid_dup(0))
      || RegNext(s1_out.isHWPrefetch)))\n1511: \n1512:   // Pipeline\n1513:   // --------------------------------------------------------------------------------\n\
      1514:   // stage 3\n1515:   // --------------------------------------------------------------------------------"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1512-1522
    context: "1512:   // Pipeline\n1513:   // --------------------------------------------------------------------------------\n\
      1514:   // stage 3\n1515:   // --------------------------------------------------------------------------------\n\
      1516:   // writeback and update load queue\n1517:   val s3_valid        = GatedValidRegNext(s2_valid
      && !s2_out.isHWPrefetch && !s2_out.uop.robIdx.needFlush(io.redirect))\n1518:\
      \   val s3_in           = RegEnable(s2_out, s2_fire)\n1519:   val s3_out   \
      \       = Wire(Valid(new MemExuOutput))\n1520:   val s3_dcache_rep   = RegEnable(s2_dcache_fast_rep
      && s2_troublem, false.B, s2_fire)\n1521:   val s3_ld_valid_dup = RegEnable(s2_ld_valid_dup,
      s2_fire)\n1522:   val s3_fast_rep     = Wire(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1520-1530
    context: "1520:   val s3_dcache_rep   = RegEnable(s2_dcache_fast_rep && s2_troublem,
      false.B, s2_fire)\n1521:   val s3_ld_valid_dup = RegEnable(s2_ld_valid_dup,
      s2_fire)\n1522:   val s3_fast_rep     = Wire(Bool())\n1523:   val s3_nc_with_data
      = RegNext(s2_nc_with_data)\n1524:   val s3_troublem     = GatedValidRegNext(s2_troublem)\n\
      1525:   val s3_kill         = s3_in.uop.robIdx.needFlush(io.redirect)\n1526:\
      \   val s3_vecout       = Wire(new OnlyVecExuOutput)\n1527:   val s3_vecActive\
      \    = RegEnable(s2_out.vecActive, true.B, s2_fire)\n1528:   val s3_isvec  \
      \      = RegEnable(s2_out.isvec, false.B, s2_fire)\n1529:   val s3_vec_alignedType
      = RegEnable(s2_out.alignedType, s2_fire)\n1530:   val s3_vec_mBIndex     = RegEnable(s2_out.mbIndex,
      s2_fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1527-1540
    context: "1527:   val s3_vecActive    = RegEnable(s2_out.vecActive, true.B, s2_fire)\n\
      1528:   val s3_isvec        = RegEnable(s2_out.isvec, false.B, s2_fire)\n1529:\
      \   val s3_vec_alignedType = RegEnable(s2_out.alignedType, s2_fire)\n1530: \
      \  val s3_vec_mBIndex     = RegEnable(s2_out.mbIndex, s2_fire)\n1531:   val
      s3_frm_mabuf       = s3_in.isFrmMisAlignBuf\n1532:   val s3_mmio_req     = RegNext(s2_mmio_req)\n\
      1533:   val s3_pdest        = RegNext(Mux(s2_valid, s2_out.uop.pdest, s2_mmio_req.bits.uop.pdest))\n\
      1534:   val s3_rfWen        = RegEnable(Mux(s2_valid, s2_out.uop.rfWen, s2_mmio_req.bits.uop.rfWen),
      s2_valid || s2_mmio_req.valid)\n1535:   val s3_fpWen        = RegEnable(Mux(s2_valid,
      s2_out.uop.fpWen, s2_mmio_req.bits.uop.fpWen), s2_valid || s2_mmio_req.valid)\n\
      1536:   val s3_data_select  = RegEnable(s2_data_select, 0.U(s2_data_select.getWidth.W),
      s2_fire)\n1537:   val s3_data_select_by_offset = RegEnable(s2_data_select_by_offset,
      0.U.asTypeOf(s2_data_select_by_offset), s2_fire)\n1538:   val s3_hw_err   =\n\
      1539:       if (EnableAccurateLoadError) {\n1540:         io.dcache.resp.bits.error_delayed
      && GatedValidRegNext(io.csrCtrl.cache_error_enable) && s3_troublem"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1543-1553
    context: "1543:       }\n1544:   val s3_safe_wakeup  = RegEnable(s2_safe_wakeup,
      s2_fire)\n1545:   val s3_safe_writeback = RegEnable(s2_safe_writeback, s2_fire)
      || s3_hw_err\n1546:   val s3_exception = RegEnable(s2_real_exception, s2_fire)\n\
      1547:   val s3_mis_align = RegEnable(s2_mis_align, s2_fire) && !s3_exception\n\
      1548:   val s3_misalign_can_go = RegEnable(!isAfter(s2_out.uop.lqIdx, io.lsq.lqDeqPtr)
      || io.misalign_allow_spec, s2_fire)\n1549:   val s3_trigger_debug_mode = RegEnable(s2_trigger_debug_mode,
      false.B, s2_fire)\n1550: \n1551:   // TODO: Fix vector load merge buffer nack\n\
      1552:   val s3_vec_mb_nack  = Wire(Bool())\n1553:   s3_vec_mb_nack     := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1549-1567
    context: "1549:   val s3_trigger_debug_mode = RegEnable(s2_trigger_debug_mode,
      false.B, s2_fire)\n1550: \n1551:   // TODO: Fix vector load merge buffer nack\n\
      1552:   val s3_vec_mb_nack  = Wire(Bool())\n1553:   s3_vec_mb_nack     := false.B\n\
      1554:   XSError(s3_valid && s3_vec_mb_nack, \"Merge buffer should always accept
      vector loads!\")\n1555: \n1556:   s3_ready := !s3_valid || s3_kill || io.ldout.ready\n\
      1557: \n1558: \n1559:   // forwrad last beat\n1560:   val s3_fast_rep_canceled
      = io.replay.valid && io.replay.bits.forward_tlDchannel || io.misalign_ldin.valid
      || !io.dcache.req.ready\n1561: \n1562:   val s3_can_enter_lsq_valid = s3_valid
      && (!s3_fast_rep || s3_fast_rep_canceled) && !s3_in.feedbacked\n1563:   io.lsq.ldin.valid
      := s3_can_enter_lsq_valid\n1564:   // TODO: check this --by hx\n1565:   // io.lsq.ldin.valid
      := s3_valid && (!s3_fast_rep || !io.fast_rep_out.ready) && !s3_in.feedbacked
      && !s3_in.lateKill\n1566:   io.lsq.ldin.bits := s3_in\n1567:   io.lsq.ldin.bits.miss
      := s3_in.miss"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1578-1588
    context: "1578:   io.lsq.ldin.bits.replacementUpdated := io.dcache.resp.bits.replacementUpdated\n\
      1579:   io.lsq.ldin.bits.missDbUpdated := GatedValidRegNext(s2_fire && s2_in.hasROBEntry
      && !s2_in.tlbMiss && !s2_in.missDbUpdated)\n1580:   io.lsq.ldin.bits.updateAddrValid
      := !s3_mis_align && (!s3_frm_mabuf || s3_in.isFinalSplit) || s3_exception\n\
      1581:   io.lsq.ldin.bits.hasException := false.B\n1582: \n1583:   io.s3_dly_ld_err
      := false.B // s3_dly_ld_err && s3_valid\n1584:   io.lsq.ldin.bits.dcacheRequireReplay\
      \  := s3_dcache_rep\n1585: \n1586:   val s3_vp_match_fail = GatedValidRegNext(s2_fwd_vp_match_invalid)
      && s3_troublem\n1587:   val s3_rep_frm_fetch = s3_vp_match_fail\n1588:   val
      s3_ldld_rep_inst ="
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1587-1600
    context: "1587:   val s3_rep_frm_fetch = s3_vp_match_fail\n1588:   val s3_ldld_rep_inst
      =\n1589:       io.lsq.ldld_nuke_query.resp.valid &&\n1590:       io.lsq.ldld_nuke_query.resp.bits.rep_frm_fetch
      &&\n1591:       GatedValidRegNext(io.csrCtrl.ldld_vio_check_enable)\n1592: \
      \  val s3_flushPipe = s3_ldld_rep_inst\n1593: \n1594:   val s3_lrq_rep_info
      = WireInit(s3_in.rep_info)\n1595:   s3_lrq_rep_info.misalign_nack := toMisalignBufferValid
      && !(io.misalign_enq.req.ready && s3_misalign_can_go)\n1596:   val s3_lrq_sel_rep_cause
      = PriorityEncoderOH(s3_lrq_rep_info.cause.asUInt)\n1597:   val s3_replayqueue_rep_cause
      = WireInit(0.U.asTypeOf(s3_in.rep_info.cause))\n1598: \n1599:   val s3_mab_rep_info
      = WireInit(s3_in.rep_info)\n1600:   val s3_mab_sel_rep_cause = PriorityEncoderOH(s3_mab_rep_info.cause.asUInt)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1610-1629
    context: "1610:   }\n1611:   io.lsq.ldin.bits.rep_info.cause := s3_replayqueue_rep_cause\n\
      1612: \n1613: \n1614:   // Int load, if hit, will be writebacked at s3\n1615:\
      \   s3_out.valid                := s3_valid && s3_safe_writeback && !toMisalignBufferValid\n\
      1616:   s3_out.bits.uop             := s3_in.uop\n1617:   s3_out.bits.uop.fpWen\
      \       := s3_in.uop.fpWen\n1618:   s3_out.bits.uop.exceptionVec(loadAccessFault)
      := s3_in.uop.exceptionVec(loadAccessFault) && s3_vecActive\n1619:   s3_out.bits.uop.exceptionVec(hardwareError)
      := (s3_in.uop.exceptionVec(hardwareError) || s3_hw_err) && s3_vecActive\n1620:\
      \   s3_out.bits.uop.flushPipe   := false.B\n1621:   s3_out.bits.uop.replayInst\
      \  := false.B\n1622:   s3_out.bits.data            := s3_in.data\n1623:   s3_out.bits.isFromLoadUnit\
      \  := true.B\n1624:   s3_out.bits.debug.isMMIO    := s3_in.mmio\n1625:   s3_out.bits.debug.isNCIO\
      \    := s3_in.nc && !s3_in.memBackTypeMM\n1626:   s3_out.bits.debug.isPerfCnt
      := false.B\n1627:   s3_out.bits.debug.paddr     := s3_in.paddr\n1628:   s3_out.bits.debug.vaddr\
      \     := s3_in.vaddr\n1629: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1639-1649
    context: "1639:   s3_vecout.reg_offset        := s3_in.reg_offset\n1640:   s3_vecout.vecActive\
      \         := s3_vecActive\n1641:   s3_vecout.is_first_ele      := s3_in.is_first_ele\n\
      1642:   // s3_vecout.uopQueuePtr       := DontCare // uopQueuePtr is already
      saved in flow queue\n1643:   // s3_vecout.flowPtr           := s3_in.flowPtr\n\
      1644:   s3_vecout.elemIdx           := s3_in.elemIdx // elemIdx is already saved
      in flow queue // TODO:\n1645:   s3_vecout.elemIdxInsideVd   := s3_in.elemIdxInsideVd\n\
      1646:   s3_vecout.trigger           := s3_in.uop.trigger\n1647:   s3_vecout.vstart\
      \            := s3_in.uop.vpu.vstart\n1648:   s3_vecout.vecTriggerMask    :=
      s3_in.vecTriggerMask\n1649:   val s3_usSecondInv          = s3_in.usSecondInv"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1646-1660
    context: "1646:   s3_vecout.trigger           := s3_in.uop.trigger\n1647:   s3_vecout.vstart\
      \            := s3_in.uop.vpu.vstart\n1648:   s3_vecout.vecTriggerMask    :=
      s3_in.vecTriggerMask\n1649:   val s3_usSecondInv          = s3_in.usSecondInv\n\
      1650: \n1651:   val s3_frm_mis_flush     = s3_frm_mabuf &&\n1652:     (io.misalign_ldout.bits.rep_info.fwd_fail
      || io.misalign_ldout.bits.rep_info.mem_amb || io.misalign_ldout.bits.rep_info.nuke\n\
      1653:       || io.misalign_ldout.bits.rep_info.rar_nack || io.misalign_ldout.bits.rep_info.raw_nack)\n\
      1654: \n1655:   io.rollback.valid := s3_valid && (s3_rep_frm_fetch || s3_flushPipe
      || s3_frm_mis_flush) && !s3_exception\n1656:   io.rollback.bits            \
      \ := DontCare\n1657:   io.rollback.bits.isRVC       := s3_out.bits.uop.preDecodeInfo.isRVC\n\
      1658:   io.rollback.bits.robIdx      := s3_out.bits.uop.robIdx\n1659:   io.rollback.bits.ftqIdx\
      \      := s3_out.bits.uop.ftqPtr\n1660:   io.rollback.bits.ftqOffset   := s3_out.bits.uop.ftqOffset"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1656-1666
    context: "1656:   io.rollback.bits             := DontCare\n1657:   io.rollback.bits.isRVC\
      \       := s3_out.bits.uop.preDecodeInfo.isRVC\n1658:   io.rollback.bits.robIdx\
      \      := s3_out.bits.uop.robIdx\n1659:   io.rollback.bits.ftqIdx      := s3_out.bits.uop.ftqPtr\n\
      1660:   io.rollback.bits.ftqOffset   := s3_out.bits.uop.ftqOffset\n1661:   io.rollback.bits.level\
      \       := Mux(s3_rep_frm_fetch || s3_frm_mis_flush, RedirectLevel.flush, RedirectLevel.flushAfter)\n\
      1662:   io.rollback.bits.cfiUpdate.target := s3_out.bits.uop.pc\n1663:   io.rollback.bits.debug_runahead_checkpoint_id
      := s3_out.bits.uop.debugInfo.runahead_checkpoint_id\n1664:   /* <------- DANGEROUS:
      Don't change sequence here ! -------> */\n1665: \n1666:   io.lsq.ldin.bits.uop
      := s3_out.bits.uop"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1677-1689
    context: "1677:                         (!(s3_fast_rep && !s3_fast_rep_canceled))
      &&\n1678:                         !s3_in.feedbacked\n1679: \n1680:   // feedback:
      scalar load will send feedback to RS\n1681:   //           vector load will
      send signal to VL Merge Buffer, then send feedback at granularity of uops\n\
      1682:   io.feedback_slow.valid                 := s3_valid && s3_fb_no_waiting
      && !s3_isvec && !s3_frm_mabuf\n1683:   io.feedback_slow.bits.hit           \
      \   := !s3_lrq_rep_info.need_rep || io.lsq.ldin.ready\n1684:   io.feedback_slow.bits.flushState\
      \       := s3_in.ptwBack\n1685:   io.feedback_slow.bits.robIdx           :=
      s3_in.uop.robIdx\n1686:   io.feedback_slow.bits.sqIdx            := s3_in.uop.sqIdx\n\
      1687:   io.feedback_slow.bits.lqIdx            := s3_in.uop.lqIdx\n1688:   io.feedback_slow.bits.sourceType\
      \       := RSFeedbackType.lrqFull\n1689:   io.feedback_slow.bits.dataInvalidSqIdx
      := DontCare"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1687-1699
    context: "1687:   io.feedback_slow.bits.lqIdx            := s3_in.uop.lqIdx\n\
      1688:   io.feedback_slow.bits.sourceType       := RSFeedbackType.lrqFull\n1689:\
      \   io.feedback_slow.bits.dataInvalidSqIdx := DontCare\n1690: \n1691:   // TODO:
      vector wakeup?\n1692:   io.ldCancel.ld2Cancel := s3_valid && !s3_safe_wakeup
      && !s3_isvec\n1693: \n1694:   val s3_ld_wb_meta = Mux(s3_valid, s3_out.bits,
      s3_mmio_req.bits)\n1695: \n1696:   // data from load queue refill\n1697:   val
      s3_ld_raw_data_frm_mmio = RegNextN(io.lsq.ld_raw_data, 3)\n1698:   val s3_merged_data_frm_mmio
      = s3_ld_raw_data_frm_mmio.mergedData()\n1699:   val s3_picked_data_frm_mmio
      = LookupTree(s3_ld_raw_data_frm_mmio.addrOffset, List("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1718-1728
    context: "1718:   s2_ld_raw_data_frm_pipe.respDcacheData       := Mux(s2_nc_with_data,
      s2_ld_data_frm_nc, io.dcache.resp.bits.data)\n1719:   s2_ld_raw_data_frm_pipe.forward_D\
      \            := s2_fwd_frm_d_chan && !s2_nc_with_data\n1720:   s2_ld_raw_data_frm_pipe.forwardData_D\
      \        := s2_fwd_data_frm_d_chan\n1721:   s2_ld_raw_data_frm_pipe.forward_mshr\
      \         := s2_fwd_frm_mshr && !s2_nc_with_data\n1722:   s2_ld_raw_data_frm_pipe.forwardData_mshr\
      \     := s2_fwd_data_frm_mshr\n1723:   s2_ld_raw_data_frm_pipe.forward_result_valid
      := s2_fwd_data_valid\n1724: \n1725:   s2_ld_raw_data_frm_pipe.forwardMask  \
      \        := s2_fwd_mask\n1726:   s2_ld_raw_data_frm_pipe.forwardData       \
      \   := s2_fwd_data\n1727:   s2_ld_raw_data_frm_pipe.uop                  :=
      s2_out.uop\n1728:   s2_ld_raw_data_frm_pipe.addrOffset           := s2_out.paddr(3,
      0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1762-1777
    context: "1762:     newRdataHelper(s3_data_select, s3_picked_data_frm_pipe(i))\n\
      1763:   }))\n1764: \n1765:   // FIXME: add 1 cycle delay ?\n1766:   // io.lsq.uncache.ready
      := !s3_valid\n1767:   val s3_ldout_valid  = s3_mmio_req.valid ||\n1768:    \
      \                     s3_out.valid && RegNext(!s2_out.isvec && !s2_out.isFrmMisAlignBuf)\n\
      1769:   val s3_outexception = ExceptionNO.selectByFu(s3_out.bits.uop.exceptionVec,
      LduCfg).asUInt.orR && s3_vecActive\n1770:   io.ldout.valid       := s3_ldout_valid\n\
      1771:   io.ldout.bits        := s3_ld_wb_meta\n1772:   io.ldout.bits.data  \
      \ := Mux(s3_valid, s3_ld_data_frm_pipe(0), s3_ld_data_frm_mmio)\n1773:   io.ldout.bits.uop.rfWen
      := s3_rfWen\n1774:   io.ldout.bits.uop.fpWen := s3_fpWen\n1775:   io.ldout.bits.uop.pdest
      := s3_pdest\n1776:   io.ldout.bits.uop.exceptionVec := ExceptionNO.selectByFu(s3_ld_wb_meta.uop.exceptionVec,
      LduCfg)\n1777:   io.ldout.bits.isFromLoadUnit := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1774-1789
    context: "1774:   io.ldout.bits.uop.fpWen := s3_fpWen\n1775:   io.ldout.bits.uop.pdest
      := s3_pdest\n1776:   io.ldout.bits.uop.exceptionVec := ExceptionNO.selectByFu(s3_ld_wb_meta.uop.exceptionVec,
      LduCfg)\n1777:   io.ldout.bits.isFromLoadUnit := true.B\n1778:   io.ldout.bits.uop.fuType
      := Mux(\n1779:                                   s3_valid && s3_isvec,\n1780:\
      \                                   FuType.vldu.U,\n1781:                  \
      \                 FuType.ldu.U\n1782:   )\n1783: \n1784:   XSError(s3_valid
      && s3_vecout.isvec && s3_in.vecActive && !s3_vecout.mask.orR, \"In vecActive,
      mask complement should not be 0\")\n1785:   // TODO: check this --hx\n1786:\
      \   // io.ldout.valid       := s3_out.valid && !s3_out.bits.uop.robIdx.needFlush(io.redirect)
      && !s3_vecout.isvec ||\n1787:   //   io.lsq.uncache.valid && !io.lsq.uncache.bits.uop.robIdx.needFlush(io.redirect)
      && !s3_out.valid && !io.lsq.uncache.bits.isVls\n1788:   //  io.ldout.bits.data\
      \   := Mux(s3_out.valid, s3_ld_data_frm_pipe, s3_ld_data_frm_mmio)\n1789:  \
      \ //  io.ldout.valid       := s3_out.valid && !s3_out.bits.uop.robIdx.needFlush(io.redirect)
      ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1788-1803
    context: "1788:   //  io.ldout.bits.data   := Mux(s3_out.valid, s3_ld_data_frm_pipe,
      s3_ld_data_frm_mmio)\n1789:   //  io.ldout.valid       := s3_out.valid && !s3_out.bits.uop.robIdx.needFlush(io.redirect)
      ||\n1790:   //                         s3_mmio_req.valid && !s3_mmio_req.bits.uop.robIdx.needFlush(io.redirect)
      && !s3_out.valid\n1791: \n1792:   // s3 load fast replay\n1793:   io.fast_rep_out.valid
      := s3_valid && s3_fast_rep\n1794:   io.fast_rep_out.bits := s3_in\n1795:   io.fast_rep_out.bits.lateKill
      := s3_rep_frm_fetch\n1796:   io.fast_rep_out.bits.delayedLoadError := s3_hw_err\n\
      1797: \n1798:   val vecFeedback = s3_valid && s3_fb_no_waiting && s3_lrq_rep_info.need_rep
      && !io.lsq.ldin.ready && s3_isvec\n1799: \n1800:   // vector output\n1801: \
      \  io.vecldout.bits.alignedType := s3_vec_alignedType\n1802:   // vec feedback\n\
      1803:   io.vecldout.bits.vecFeedback := vecFeedback"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1818-1831
    context: "1818:   io.vecldout.bits.mask := s3_vecout.mask\n1819:   io.vecldout.bits.hasException
      := s3_exception\n1820:   io.vecldout.bits.reg_offset.get := s3_vecout.reg_offset\n\
      1821:   io.vecldout.bits.usSecondInv := s3_usSecondInv\n1822:   io.vecldout.bits.mBIndex
      := s3_vec_mBIndex\n1823:   io.vecldout.bits.hit := !s3_lrq_rep_info.need_rep
      || io.lsq.ldin.ready\n1824:   io.vecldout.bits.sourceType := RSFeedbackType.lrqFull\n\
      1825:   io.vecldout.bits.trigger := s3_vecout.trigger\n1826:   io.vecldout.bits.flushState
      := DontCare\n1827:   io.vecldout.bits.exceptionVec := ExceptionNO.selectByFu(s3_out.bits.uop.exceptionVec,
      VlduCfg)\n1828:   io.vecldout.bits.vaddr := s3_in.fullva\n1829:   io.vecldout.bits.vaNeedExt
      := s3_in.vaNeedExt\n1830:   io.vecldout.bits.gpaddr := s3_in.gpaddr\n1831: \
      \  io.vecldout.bits.isForVSnonLeafPTE := s3_in.isForVSnonLeafPTE"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1827-1842
    context: "1827:   io.vecldout.bits.exceptionVec := ExceptionNO.selectByFu(s3_out.bits.uop.exceptionVec,
      VlduCfg)\n1828:   io.vecldout.bits.vaddr := s3_in.fullva\n1829:   io.vecldout.bits.vaNeedExt
      := s3_in.vaNeedExt\n1830:   io.vecldout.bits.gpaddr := s3_in.gpaddr\n1831: \
      \  io.vecldout.bits.isForVSnonLeafPTE := s3_in.isForVSnonLeafPTE\n1832:   io.vecldout.bits.mmio
      := DontCare\n1833:   io.vecldout.bits.vstart := s3_vecout.vstart\n1834:   io.vecldout.bits.vecTriggerMask
      := s3_vecout.vecTriggerMask\n1835:   io.vecldout.bits.nc := DontCare\n1836:\
      \ \n1837:   io.vecldout.valid := s3_out.valid && !s3_out.bits.uop.robIdx.needFlush(io.redirect)
      && s3_vecout.isvec && !s3_mis_align && !s3_frm_mabuf //||\n1838:   // TODO:
      check this, why !io.lsq.uncache.bits.isVls before?\n1839:   // Now vector instruction
      don't support mmio.\n1840:     // io.lsq.uncache.valid && !io.lsq.uncache.bits.uop.robIdx.needFlush(io.redirect)
      && !s3_out.valid && io.lsq.uncache.bits.isVls\n1841:     //io.lsq.uncache.valid
      && !io.lsq.uncache.bits.uop.robIdx.needFlush(io.redirect) && !s3_out.valid &&
      !io.lsq.uncache.bits.isVls\n1842: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1838-1848
    context: "1838:   // TODO: check this, why !io.lsq.uncache.bits.isVls before?\n\
      1839:   // Now vector instruction don't support mmio.\n1840:     // io.lsq.uncache.valid
      && !io.lsq.uncache.bits.uop.robIdx.needFlush(io.redirect) && !s3_out.valid &&
      io.lsq.uncache.bits.isVls\n1841:     //io.lsq.uncache.valid && !io.lsq.uncache.bits.uop.robIdx.needFlush(io.redirect)
      && !s3_out.valid && !io.lsq.uncache.bits.isVls\n1842: \n1843:   io.misalign_ldout.valid\
      \     := s3_valid && (!s3_fast_rep || s3_fast_rep_canceled) && s3_frm_mabuf
      || s3_misalign_wakeup_req.valid\n1844:   io.misalign_ldout.bits      := Mux(s3_misalign_wakeup_req.valid,
      s3_misalign_wakeup_req.bits, io.lsq.ldin.bits)\n1845:   io.misalign_ldout.bits.data
      := s3_picked_data_frm_pipe(2)\n1846:   io.misalign_ldout.bits.rep_info.cause
      := Mux(s3_misalign_wakeup_req.valid, 0.U.asTypeOf(s3_in.rep_info.cause), s3_misalign_rep_cause)\n\
      1847: \n1848:   // fast load to load forward"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1845-1855
    context: "1845:   io.misalign_ldout.bits.data := s3_picked_data_frm_pipe(2)\n\
      1846:   io.misalign_ldout.bits.rep_info.cause := Mux(s3_misalign_wakeup_req.valid,
      0.U.asTypeOf(s3_in.rep_info.cause), s3_misalign_rep_cause)\n1847: \n1848:  \
      \ // fast load to load forward\n1849:   if (EnableLoadToLoadForward) {\n1850:\
      \     io.l2l_fwd_out.valid      := s3_valid && !s3_in.mmio && !s3_in.nc && !s3_lrq_rep_info.need_rep\n\
      1851:     io.l2l_fwd_out.data       := Mux(s3_in.vaddr(3), s3_merged_data_frm_pipe(127,
      64), s3_merged_data_frm_pipe(63, 0))\n1852:     io.l2l_fwd_out.dly_ld_err :=
      s3_hw_err || // ecc delayed error\n1853:                                  s3_ldld_rep_inst
      ||\n1854:                                  s3_rep_frm_fetch\n1855:   } else
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1867-1880
    context: "1867:   io.debug_ls.s2_isBankConflict := s2_fire && (!s2_kill && s2_bank_conflict)\n\
      1868:   io.debug_ls.s2_isDcacheFirstMiss := s2_fire && io.dcache.resp.bits.miss
      && s2_in.isFirstIssue\n1869:   io.debug_ls.s2_isForwardFail := s2_fire && s2_fwd_fail\n\
      1870:   // s3\n1871:   io.debug_ls.s3_robIdx := s3_in.uop.robIdx.value\n1872:\
      \   io.debug_ls.s3_isReplayFast := s3_valid && s3_fast_rep && !s3_fast_rep_canceled\n\
      1873:   io.debug_ls.s3_isReplayRS :=  RegNext(io.feedback_fast.valid && !io.feedback_fast.bits.hit)
      || (io.feedback_slow.valid && !io.feedback_slow.bits.hit)\n1874:   io.debug_ls.s3_isReplaySlow
      := io.lsq.ldin.valid && io.lsq.ldin.bits.rep_info.need_rep\n1875:   io.debug_ls.s3_isReplay
      := s3_valid && s3_lrq_rep_info.need_rep // include fast+slow+rs replay\n1876:\
      \   io.debug_ls.replayCause := s3_lrq_rep_info.cause\n1877:   io.debug_ls.replayCnt
      := 1.U\n1878: \n1879:   // Topdown\n1880:   io.lsTopdownInfo.s1.robIdx     \
      \     := s1_in.uop.robIdx.value"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1876-1886
    context: "1876:   io.debug_ls.replayCause := s3_lrq_rep_info.cause\n1877:   io.debug_ls.replayCnt
      := 1.U\n1878: \n1879:   // Topdown\n1880:   io.lsTopdownInfo.s1.robIdx     \
      \     := s1_in.uop.robIdx.value\n1881:   io.lsTopdownInfo.s1.vaddr_valid   \
      \  := s1_valid && s1_in.hasROBEntry\n1882:   io.lsTopdownInfo.s1.vaddr_bits\
      \      := s1_vaddr\n1883:   io.lsTopdownInfo.s2.robIdx          := s2_in.uop.robIdx.value\n\
      1884:   io.lsTopdownInfo.s2.paddr_valid     := s2_fire && s2_in.hasROBEntry
      && !s2_in.tlbMiss\n1885:   io.lsTopdownInfo.s2.paddr_bits      := s2_in.paddr\n\
      1886:   io.lsTopdownInfo.s2.first_real_miss := io.dcache.resp.bits.real_miss"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1886-1906
    context: "1886:   io.lsTopdownInfo.s2.first_real_miss := io.dcache.resp.bits.real_miss\n\
      1887:   io.lsTopdownInfo.s2.cache_miss_en   := s2_fire && s2_in.hasROBEntry
      && !s2_in.tlbMiss && !s2_in.missDbUpdated\n1888: \n1889:   // perf cnt\n1890:\
      \   XSPerfAccumulate(\"s0_in_valid\",                  io.ldin.valid)\n1891:\
      \   XSPerfAccumulate(\"s0_in_block\",                  io.ldin.valid && !io.ldin.fire)\n\
      1892:   XSPerfAccumulate(\"s0_vecin_valid\",               io.vecldin.valid)\n\
      1893:   XSPerfAccumulate(\"s0_vecin_block\",               io.vecldin.valid
      && !io.vecldin.fire)\n1894:   XSPerfAccumulate(\"s0_in_fire_first_issue\", \
      \      s0_valid && s0_sel_src.isFirstIssue)\n1895:   XSPerfAccumulate(\"s0_lsq_replay_issue\"\
      ,          io.replay.fire)\n1896:   XSPerfAccumulate(\"s0_lsq_replay_vecissue\"\
      ,       io.replay.fire && io.replay.bits.isvec)\n1897:   XSPerfAccumulate(\"\
      s0_ldu_fire_first_issue\",      io.ldin.fire && s0_sel_src.isFirstIssue)\n1898:\
      \   XSPerfAccumulate(\"s0_fast_replay_issue\",         io.fast_rep_in.fire)\n\
      1899:   XSPerfAccumulate(\"s0_fast_replay_vecissue\",      io.fast_rep_in.fire
      && io.fast_rep_in.bits.isvec)\n1900:   XSPerfAccumulate(\"s0_stall_out\",  \
      \               s0_valid && !s0_can_go)\n1901:   XSPerfAccumulate(\"s0_stall_dcache\"\
      ,              s0_valid && !io.dcache.req.ready)\n1902:   XSPerfAccumulate(\"\
      s0_addr_spec_success\",         s0_fire && s0_dcache_vaddr(VAddrBits-1, 12)
      === io.ldin.bits.src(0)(VAddrBits-1, 12))\n1903:   XSPerfAccumulate(\"s0_addr_spec_failed\"\
      ,          s0_fire && s0_dcache_vaddr(VAddrBits-1, 12) =/= io.ldin.bits.src(0)(VAddrBits-1,
      12))\n1904:   XSPerfAccumulate(\"s0_addr_spec_success_once\",    s0_fire &&
      s0_dcache_vaddr(VAddrBits-1, 12) === io.ldin.bits.src(0)(VAddrBits-1, 12) &&
      s0_sel_src.isFirstIssue)\n1905:   XSPerfAccumulate(\"s0_addr_spec_failed_once\"\
      ,     s0_fire && s0_dcache_vaddr(VAddrBits-1, 12) =/= io.ldin.bits.src(0)(VAddrBits-1,
      12) && s0_sel_src.isFirstIssue)\n1906:   XSPerfAccumulate(\"s0_vec_addr_vlen_aligned\"\
      ,     s0_fire && s0_sel_src.isvec && s0_dcache_vaddr(3, 0) === 0.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1911-1932
    context: "1911:   XSPerfAccumulate(\"s0_hardware_prefetch_blocked\", io.prefetch_req.valid
      && !s0_hw_prf_select)\n1912:   XSPerfAccumulate(\"s0_hardware_prefetch_total\"\
      ,   io.prefetch_req.valid)\n1913: \n1914:   XSPerfAccumulate(\"s3_rollback_total\"\
      ,             io.rollback.valid)\n1915:   XSPerfAccumulate(\"s3_rep_frm_fetch_rollback\"\
      ,     io.rollback.valid && s3_rep_frm_fetch)\n1916:   XSPerfAccumulate(\"s3_flushPipe_rollback\"\
      ,         io.rollback.valid && s3_flushPipe)\n1917:   XSPerfAccumulate(\"s3_frm_mis_flush_rollback\"\
      ,     io.rollback.valid && s3_frm_mis_flush)\n1918: \n1919:   XSPerfAccumulate(\"\
      s1_in_valid\",                  s1_valid)\n1920:   XSPerfAccumulate(\"s1_in_fire\"\
      ,                   s1_fire)\n1921:   XSPerfAccumulate(\"s1_in_fire_first_issue\"\
      ,       s1_fire && s1_in.isFirstIssue)\n1922:   XSPerfAccumulate(\"s1_tlb_miss\"\
      ,                  s1_fire && s1_tlb_miss)\n1923:   XSPerfAccumulate(\"s1_tlb_miss_first_issue\"\
      ,      s1_fire && s1_tlb_miss && s1_in.isFirstIssue)\n1924:   XSPerfAccumulate(\"\
      s1_stall_out\",                 s1_valid && !s1_can_go)\n1925:   XSPerfAccumulate(\"\
      s1_dly_err\",                   s1_valid && s1_fast_rep_dly_err)\n1926: \n1927:\
      \   XSPerfAccumulate(\"s2_in_valid\",                  s2_valid)\n1928:   XSPerfAccumulate(\"\
      s2_in_fire\",                   s2_fire)\n1929:   XSPerfAccumulate(\"s2_in_fire_first_issue\"\
      ,       s2_fire && s2_in.isFirstIssue)\n1930:   XSPerfAccumulate(\"s2_dcache_miss\"\
      ,               s2_fire && io.dcache.resp.bits.miss)\n1931:   XSPerfAccumulate(\"\
      s2_dcache_miss_first_issue\",   s2_fire && io.dcache.resp.bits.miss && s2_in.isFirstIssue)\n\
      1932:   XSPerfAccumulate(\"s2_dcache_real_miss_first_issue\",   s2_fire && io.dcache.resp.bits.miss
      && s2_in.isFirstIssue)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1930-1941
    context: "1930:   XSPerfAccumulate(\"s2_dcache_miss\",               s2_fire &&
      io.dcache.resp.bits.miss)\n1931:   XSPerfAccumulate(\"s2_dcache_miss_first_issue\"\
      ,   s2_fire && io.dcache.resp.bits.miss && s2_in.isFirstIssue)\n1932:   XSPerfAccumulate(\"\
      s2_dcache_real_miss_first_issue\",   s2_fire && io.dcache.resp.bits.miss &&
      s2_in.isFirstIssue)\n1933:   XSPerfAccumulate(\"s2_full_forward\",         \
      \     s2_fire && s2_full_fwd)\n1934:   XSPerfAccumulate(\"s2_dcache_miss_full_forward\"\
      ,  s2_fire && s2_dcache_miss)\n1935:   XSPerfAccumulate(\"s2_fwd_frm_d_can\"\
      ,             s2_valid && s2_fwd_frm_d_chan)\n1936:   XSPerfAccumulate(\"s2_fwd_frm_d_chan_or_mshr\"\
      ,    s2_valid && s2_fwd_frm_d_chan_or_mshr)\n1937:   XSPerfAccumulate(\"s2_stall_out\"\
      ,                 s2_fire && !s2_can_go)\n1938:   XSPerfAccumulate(\"s2_prefetch\"\
      ,                  s2_fire && s2_prf)\n1939:   XSPerfAccumulate(\"s2_prefetch_ignored\"\
      ,          s2_fire && s2_prf && io.dcache.s2_mq_nack) // ignore prefetch for
      mshr full / miss req port conflict\n1940:   XSPerfAccumulate(\"s2_prefetch_miss\"\
      ,             s2_fire && s2_prf && io.dcache.resp.bits.miss) // prefetch req
      miss in l1\n1941:   XSPerfAccumulate(\"s2_prefetch_hit\",              s2_fire
      && s2_prf && !io.dcache.resp.bits.miss) // prefetch req hit in l1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1939-1950
    context: "1939:   XSPerfAccumulate(\"s2_prefetch_ignored\",          s2_fire &&
      s2_prf && io.dcache.s2_mq_nack) // ignore prefetch for mshr full / miss req
      port conflict\n1940:   XSPerfAccumulate(\"s2_prefetch_miss\",             s2_fire
      && s2_prf && io.dcache.resp.bits.miss) // prefetch req miss in l1\n1941:   XSPerfAccumulate(\"\
      s2_prefetch_hit\",              s2_fire && s2_prf && !io.dcache.resp.bits.miss)
      // prefetch req hit in l1\n1942:   XSPerfAccumulate(\"s2_prefetch_accept\",\
      \           s2_fire && s2_prf && io.dcache.resp.bits.miss && !io.dcache.s2_mq_nack)
      // prefetch a missed line in l1, and l1 accepted it\n1943:   XSPerfAccumulate(\"\
      s2_forward_req\",               s2_fire && s2_in.forward_tlDchannel)\n1944:\
      \   XSPerfAccumulate(\"s2_successfully_forward_channel_D\", s2_fire && s2_fwd_frm_d_chan
      && s2_fwd_data_valid)\n1945:   XSPerfAccumulate(\"s2_successfully_forward_mshr\"\
      ,      s2_fire && s2_fwd_frm_mshr && s2_fwd_data_valid)\n1946: \n1947:   XSPerfAccumulate(\"\
      load_to_load_forward\",                      s1_try_ptr_chasing && !s1_ptr_chasing_canceled)\n\
      1948:   XSPerfAccumulate(\"load_to_load_forward_try\",                  s1_try_ptr_chasing)\n\
      1949:   XSPerfAccumulate(\"load_to_load_forward_fail\",                 s1_cancel_ptr_chasing)\n\
      1950:   XSPerfAccumulate(\"load_to_load_forward_fail_cancelled\",       s1_cancel_ptr_chasing
      && s1_ptr_chasing_canceled)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1952-1969
    context: "1952:   XSPerfAccumulate(\"load_to_load_forward_fail_op_not_ld\",  \
      \     s1_cancel_ptr_chasing && !s1_ptr_chasing_canceled && !s1_not_fast_match
      && s1_fu_op_type_not_ld)\n1953:   XSPerfAccumulate(\"load_to_load_forward_fail_addr_align\"\
      ,      s1_cancel_ptr_chasing && !s1_ptr_chasing_canceled && !s1_not_fast_match
      && !s1_fu_op_type_not_ld && s1_addr_misaligned)\n1954:   XSPerfAccumulate(\"\
      load_to_load_forward_fail_set_mismatch\",    s1_cancel_ptr_chasing && !s1_ptr_chasing_canceled
      && !s1_not_fast_match && !s1_fu_op_type_not_ld && !s1_addr_misaligned && s1_addr_mismatch)\n\
      1955: \n1956:   XSPerfAccumulate(\"nc_ld_writeback\", io.ldout.valid && s3_nc_with_data)\n\
      1957:   XSPerfAccumulate(\"nc_ld_exception\", s3_valid && s3_nc_with_data &&
      s3_in.uop.exceptionVec.reduce(_ || _))\n1958:   XSPerfAccumulate(\"nc_ldld_vio\"\
      , s3_valid && s3_nc_with_data && s3_ldld_rep_inst)\n1959:   XSPerfAccumulate(\"\
      nc_stld_vio\", s3_valid && s3_nc_with_data && s3_in.rep_info.nuke)\n1960:  \
      \ XSPerfAccumulate(\"nc_ldld_vioNack\", s3_valid && s3_nc_with_data && s3_in.rep_info.rar_nack)\n\
      1961:   XSPerfAccumulate(\"nc_stld_vioNack\", s3_valid && s3_nc_with_data &&
      s3_in.rep_info.raw_nack)\n1962:   XSPerfAccumulate(\"nc_stld_fwd\", s3_valid
      && s3_nc_with_data && RegNext(s2_full_fwd))\n1963:   XSPerfAccumulate(\"nc_stld_fwdNotReady\"\
      , s3_valid && s3_nc_with_data && RegNext(s2_mem_amb || s2_fwd_fail))\n1964:\
      \   XSPerfAccumulate(\"nc_stld_fwdAddrMismatch\", s3_valid && s3_nc_with_data
      && s3_vp_match_fail)\n1965: \n1966:   // bug lyq: some signals in perfEvents
      are no longer suitable for the current MemBlock design\n1967:   // hardware
      performance counter\n1968:   val perfEvents = Seq(\n1969:     (\"load_s0_in_fire\
      \         \", s0_fire                                                      \
      \  ),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1966-1976
    context: "1966:   // bug lyq: some signals in perfEvents are no longer suitable
      for the current MemBlock design\n1967:   // hardware performance counter\n1968:\
      \   val perfEvents = Seq(\n1969:     (\"load_s0_in_fire         \", s0_fire\
      \                                                        ),\n1970:     (\"load_to_load_forward\
      \    \", s1_fire && s1_try_ptr_chasing && !s1_ptr_chasing_canceled      ),\n\
      1971:     (\"stall_dcache            \", s0_valid && s0_can_go && !io.dcache.req.ready\
      \                  ),\n1972:     (\"load_s1_in_fire         \", s0_fire    \
      \                                                    ),\n1973:     (\"load_s1_tlb_miss\
      \        \", s1_fire && io.tlb.resp.bits.miss                              \
      \ ),\n1974:     (\"load_s2_in_fire         \", s1_fire                     \
      \                                   ),\n1975:     (\"load_s2_dcache_miss   \
      \  \", s2_fire && io.dcache.resp.bits.miss                            ),\n1976:\
      \   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1984-1991
    context: "1984:     s3_data_select_by_offset.map(x=> dontTouch(x))\n1985:    \
      \ s3_data_frm_pipe.map(x=> dontTouch(x))\n1986:     s3_picked_data_frm_pipe.map(x=>
      dontTouch(x))\n1987:   }\n1988: \n1989:   XSDebug(io.ldout.fire, \"ldout %x\\\
      n\", io.ldout.bits.uop.pc)\n1990:   // end\n1991: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 28-38
    context: "28: import xiangshan.backend.fu.FuConfig._\n29: import xiangshan.backend.fu.FuType._\n\
      30: import xiangshan.backend.ctrlblock.DebugLsInfoBundle\n31: import xiangshan.backend.fu.NewCSR._\n\
      32: import xiangshan.mem.Bundles._\n33: import xiangshan.cache.mmu.{Pbmt, TlbCmd,
      TlbReq, TlbRequestIO, TlbResp}\n34: import xiangshan.cache.{DCacheStoreIO, DcacheStoreRequestIO,
      HasDCacheParameters, MemoryOpConstants, StorePrefetchReq}\n35: \n36: class StoreUnit(implicit
      p: Parameters) extends XSModule\n37:   with HasDCacheParameters\n38:   with
      HasVLSUParameters"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 36-46
    context: "36: class StoreUnit(implicit p: Parameters) extends XSModule\n37:  \
      \ with HasDCacheParameters\n38:   with HasVLSUParameters\n39:   {\n40:   val
      io = IO(new Bundle() {\n41:     val redirect        = Flipped(ValidIO(new Redirect))\n\
      42:     val csrCtrl         = Flipped(new CustomCSRCtrlIO)\n43:     val stin\
      \            = Flipped(Decoupled(new MemExuInput))\n44:     val issue      \
      \     = Valid(new MemExuInput)\n45:     // misalignBuffer issue path\n46:  \
      \   val misalign_stin   = Flipped(Decoupled(new LsPipelineBundle))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 74-84
    context: "74:     val s0_s1_valid = Output(Bool())\n75:   })\n76: \n77:   PerfCCT.updateInstPos(io.stin.bits.uop.debug_seqNum,
      PerfCCT.InstPos.AtFU.id.U, io.stin.valid, clock, reset)\n78: \n79:   val s1_ready,
      s2_ready, s3_ready = WireInit(false.B)\n80: \n81:   // Pipeline\n82:   // --------------------------------------------------------------------------------\n\
      83:   // stage 0\n84:   // --------------------------------------------------------------------------------"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 82-99
    context: "82:   // --------------------------------------------------------------------------------\n\
      83:   // stage 0\n84:   // --------------------------------------------------------------------------------\n\
      85:   // generate addr, use addr to query DCache and DTLB\n86:   val s0_iss_valid\
      \        = io.stin.valid\n87:   val s0_prf_valid        = io.prefetch_req.valid
      && io.dcache.req.ready\n88:   val s0_vec_valid        = io.vecstin.valid\n89:\
      \   val s0_ma_st_valid      = io.misalign_stin.valid\n90:   val s0_valid   \
      \         = s0_iss_valid || s0_prf_valid || s0_vec_valid || s0_ma_st_valid\n\
      91:   val s0_use_flow_ma      = s0_ma_st_valid\n92:   val s0_use_flow_vec  \
      \   = s0_vec_valid && !s0_ma_st_valid\n93:   val s0_use_flow_rs      = s0_iss_valid
      && !s0_vec_valid && !s0_ma_st_valid\n94:   val s0_use_flow_prf     = s0_prf_valid
      && !s0_iss_valid && !s0_vec_valid && !s0_ma_st_valid\n95:   val s0_use_non_prf_flow
      = s0_use_flow_rs || s0_use_flow_vec || s0_use_flow_ma\n96:   val s0_stin   \
      \          = Mux(s0_use_flow_rs, io.stin.bits, 0.U.asTypeOf(io.stin.bits))\n\
      97:   val s0_vecstin          = Mux(s0_use_flow_vec, io.vecstin.bits, 0.U.asTypeOf(io.vecstin.bits))\n\
      98:   val s0_uop              = Mux(\n99:     s0_use_flow_ma,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 114-126
    context: "114:   val s0_rob_idx      = Mux(s0_use_non_prf_flow, s0_uop.robIdx,
      0.U.asTypeOf(s0_uop.robIdx))\n115:   val s0_pc           = Mux(s0_use_non_prf_flow,
      s0_uop.pc, 0.U)\n116:   val s0_instr_type   = Mux(s0_use_non_prf_flow, STORE_SOURCE.U,
      DCACHE_PREFETCH_SOURCE.U)\n117:   val s0_wlineflag    = Mux(s0_use_flow_rs,
      LSUOpType.isCboAll(s0_uop.fuOpType), false.B)\n118:   val s0_out          =
      Wire(new LsPipelineBundle)\n119:   val s0_kill         = s0_uop.robIdx.needFlush(io.redirect)\n\
      120:   val s0_can_go       = s1_ready\n121:   val s0_fire         = s0_valid
      && !s0_kill && s0_can_go\n122:   val s0_is128bit     = Wire(Bool())\n123:  \
      \ // vector\n124:   val s0_vecActive    = !s0_use_flow_vec || s0_vecstin.vecActive\n\
      125:   // val s0_flowPtr      = s0_vecstin.flowPtr\n126:   // val s0_isLastElem\
      \   = s0_vecstin.isLastElem"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 151-161
    context: "151: \n152:   val s0_isCbo = s0_use_flow_rs && LSUOpType.isCboAll(s0_stin.uop.fuOpType)\n\
      153:   val s0_isCbo_noZero = s0_use_flow_rs && LSUOpType.isCbo(s0_stin.uop.fuOpType)\n\
      154:   // only simulation\n155:   val cbo_assert_flag = LSUOpType.isCboAll(s0_out.uop.fuOpType)\n\
      156:   XSError(!s0_use_flow_rs && cbo_assert_flag && s0_valid, \"cbo instruction
      selection error.\")\n157: \n158:   val s0_alignType = Mux(s0_use_flow_vec, s0_vecstin.alignedType(1,0),
      s0_uop.fuOpType(1, 0))\n159:   // exception check\n160:   val s0_addr_aligned
      = LookupTree(s0_alignType, List(\n161:     \"b00\".U   -> true.B,          \
      \    //b"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 201-215
    context: "201:         Fill(VLEN/8, 1.U(1.W))\n202:       )\n203:     )\n204:\
      \   )\n205: \n206:   io.tlb.req.valid                   := s0_valid\n207:  \
      \ io.tlb.req.bits.vaddr              := s0_vaddr\n208:   io.tlb.req.bits.fullva\
      \             := s0_fullva\n209:   io.tlb.req.bits.checkfullva        := s0_use_flow_rs
      || s0_use_flow_vec\n210:   io.tlb.req.bits.cmd                := Mux(s0_isCbo_noZero,
      TlbCmd.read, TlbCmd.write)\n211:   io.tlb.req.bits.isPrefetch         := s0_use_flow_prf\n\
      212:   io.tlb.req.bits.size               := s0_size\n213:   io.tlb.req.bits.kill\
      \               := false.B\n214:   io.tlb.req.bits.memidx.is_ld       := false.B\n\
      215:   io.tlb.req.bits.memidx.is_st       := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 254-264
    context: "254:   s0_out.alignedType  := s0_alignedType\n255:   s0_out.mbIndex\
      \      := s0_mBIndex\n256:   s0_out.misalignWith16Byte      := s0_misalignWith16Byte\n\
      257:   s0_out.isMisalign      := s0_isMisalign\n258:   s0_out.vecBaseVaddr :=
      s0_vecBaseVaddr\n259:   when(s0_valid && s0_isFirstIssue) {\n260:     s0_out.uop.debugInfo.tlbFirstReqTime
      := GTimer()\n261:   }\n262:   s0_out.isFrmMisAlignBuf := s0_use_flow_ma\n263:\
      \   s0_out.isFinalSplit := s0_isFinalSplit\n264: //  s0_out.uop.exceptionVec(storeAddrMisaligned)
      := Mux(s0_use_non_prf_flow, (!s0_addr_aligned || s0_vecstin.uop.exceptionVec(storeAddrMisaligned)
      && s0_vecActive), false.B) && !s0_misalignWith16Byte"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 265-278
    context: "265: \n266:   io.st_mask_out.valid       := s0_use_flow_rs || s0_use_flow_vec\n\
      267:   io.st_mask_out.bits.mask   := s0_out.mask\n268:   io.st_mask_out.bits.sqIdx\
      \  := s0_out.uop.sqIdx\n269: \n270:   io.stin.ready := s1_ready && s0_use_flow_rs\n\
      271:   io.vecstin.ready := s1_ready && s0_use_flow_vec\n272:   io.prefetch_req.ready
      := s1_ready && io.dcache.req.ready && !s0_iss_valid && !s0_vec_valid && !s0_ma_st_valid\n\
      273:   io.misalign_stin.ready := s1_ready && s0_use_flow_ma\n274: \n275:   //
      Pipeline\n276:   // --------------------------------------------------------------------------------\n\
      277:   // stage 1\n278:   // --------------------------------------------------------------------------------"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 275-290
    context: "275:   // Pipeline\n276:   // --------------------------------------------------------------------------------\n\
      277:   // stage 1\n278:   // --------------------------------------------------------------------------------\n\
      279:   // TLB resp (send paddr to dcache)\n280:   val s1_valid  = RegInit(false.B)\n\
      281:   val s1_in     = RegEnable(s0_out, s0_fire)\n282:   val s1_out    = Wire(new
      LsPipelineBundle)\n283:   val s1_kill   = Wire(Bool())\n284:   val s1_can_go
      = s2_ready\n285:   val s1_fire   = s1_valid && !s1_kill && s1_can_go\n286: \
      \  val s1_vecActive    = RegEnable(s0_out.vecActive, true.B, s0_fire)\n287:\
      \   val s1_frm_mabuf    = s1_in.isFrmMisAlignBuf\n288:   val s1_is128bit   \
      \  = s1_in.is128bit\n289: \n290:   // mmio cbo decoder"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 293-305
    context: "293:   val s1_isHyper   = io.tlb.resp.bits.excp(0).isHyper\n294:   val
      s1_paddr     = io.tlb.resp.bits.paddr(0)\n295:   val s1_gpaddr    = io.tlb.resp.bits.gpaddr(0)\n\
      296:   val s1_fullva    = Mux(s1_frm_mabuf, s1_out.vaddr, io.tlb.resp.bits.fullva)\n\
      297:   val s1_isForVSnonLeafPTE   = io.tlb.resp.bits.isForVSnonLeafPTE\n298:\
      \   val s1_tlb_miss  = io.tlb.resp.bits.miss && io.tlb.resp.valid && s1_valid\n\
      299:   val s1_tlb_hit   = !io.tlb.resp.bits.miss && io.tlb.resp.valid && s1_valid\n\
      300:   val s1_pbmt      = Mux(s1_tlb_hit, io.tlb.resp.bits.pbmt.head, 0.U(Pbmt.width.W))\n\
      301:   val s1_exception = ExceptionNO.selectByFu(s1_out.uop.exceptionVec, StaCfg).asUInt.orR\n\
      302:   val s1_isvec     = RegEnable(s0_out.isvec, false.B, s0_fire)\n303:  \
      \ //We don't want `StoreUnit` to have an additional effect on the Store of vector
      from a `misalignBuffer,`\n304:   //But there are places where a marker bit is
      needed to enable additional processing of vector instructions.\n305:   //For
      example: `StoreQueue` is exceptionBuffer"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 303-322
    context: "303:   //We don't want `StoreUnit` to have an additional effect on the
      Store of vector from a `misalignBuffer,`\n304:   //But there are places where
      a marker bit is needed to enable additional processing of vector instructions.\n\
      305:   //For example: `StoreQueue` is exceptionBuffer\n306:   val s1_frm_mab_vec
      = RegEnable(s0_use_flow_ma && io.misalign_stin.bits.isvec, false.B, s0_fire)\n\
      307:   // val s1_isLastElem = RegEnable(s0_isLastElem, false.B, s0_fire)\n308:\
      \   s1_kill := s1_in.uop.robIdx.needFlush(io.redirect) || (s1_tlb_miss && !s1_isvec
      && !s1_frm_mabuf)\n309: \n310:   s1_ready := !s1_valid || s1_kill || s2_ready\n\
      311:   io.tlb.resp.ready := true.B // TODO: why dtlbResp needs a ready?\n312:\
      \   when (s0_fire) { s1_valid := true.B }\n313:   .elsewhen (s1_fire) { s1_valid
      := false.B }\n314:   .elsewhen (s1_kill) { s1_valid := false.B }\n315: \n316:\
      \   // st-ld violation dectect request.\n317:   io.stld_nuke_query.valid   \
      \    := s1_valid && !s1_tlb_miss && !s1_in.isHWPrefetch\n318:   io.stld_nuke_query.bits.robIdx
      := s1_in.uop.robIdx\n319:   io.stld_nuke_query.bits.paddr  := s1_paddr\n320:\
      \   io.stld_nuke_query.bits.mask   := s1_in.mask\n321:   io.stld_nuke_query.bits.matchType
      := Mux(\n322:                                           s1_isCbo,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 323-334
    context: "323:                                           StLdNukeMatchType.CacheLine,\n\
      324:                                           Mux(s1_in.is128bit, StLdNukeMatchType.QuadWord,
      StLdNukeMatchType.Normal)\n325:                                         )\n\
      326: \n327:   // issue\n328:   io.issue.valid := s1_valid && !s1_tlb_miss &&
      !s1_in.isHWPrefetch && !s1_isvec && !s1_frm_mabuf\n329:   io.issue.bits  :=
      RegEnable(s0_stin, s0_valid)\n330: \n331:   // trigger\n332:   val storeTrigger
      = Module(new MemTrigger(MemType.STORE))\n333:   storeTrigger.io.fromCsrTrigger.tdataVec\
      \             := io.fromCsrTrigger.tdataVec\n334:   storeTrigger.io.fromCsrTrigger.tEnableVec\
      \           := io.fromCsrTrigger.tEnableVec"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 342-359
    context: "342:   val s1_trigger_action = storeTrigger.io.toLoadStore.triggerAction\n\
      343:   val s1_trigger_debug_mode = TriggerAction.isDmode(s1_trigger_action)\n\
      344:   val s1_trigger_breakpoint = TriggerAction.isExp(s1_trigger_action)\n\
      345: \n346:   // for misalign in vsMergeBuffer\n347:   io.s0_s1_valid := s0_valid
      || s1_valid\n348: \n349:   // Send TLB feedback to store issue queue\n350: \
      \  // Store feedback is generated in store_s1, sent to RS in store_s2\n351:\
      \   val s1_feedback = Wire(Valid(new RSFeedback))\n352:   s1_feedback.valid\
      \                 := s1_valid & !s1_in.isHWPrefetch\n353:   s1_feedback.bits.hit\
      \              := !s1_tlb_miss\n354:   s1_feedback.bits.flushState       :=
      io.tlb.resp.bits.ptwBack\n355:   s1_feedback.bits.robIdx           := s1_out.uop.robIdx\n\
      356:   s1_feedback.bits.sourceType       := RSFeedbackType.tlbMiss\n357:   s1_feedback.bits.dataInvalidSqIdx
      := DontCare\n358:   s1_feedback.bits.sqIdx            := s1_out.uop.sqIdx\n\
      359:   s1_feedback.bits.lqIdx            := s1_out.uop.lqIdx"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 373-384
    context: "373:   s1_out.gpaddr    := s1_gpaddr\n374:   s1_out.fullva    := s1_fullva\n\
      375:   s1_out.vaNeedExt := s1_vaNeedExt\n376:   s1_out.isHyper   := s1_isHyper\n\
      377:   s1_out.miss      := false.B\n378:   s1_out.nc        := Pbmt.isNC(s1_pbmt)\n\
      379:   s1_out.mmio      := Pbmt.isIO(s1_pbmt)\n380:   s1_out.tlbMiss   := s1_tlb_miss\n\
      381:   s1_out.isForVSnonLeafPTE := s1_isForVSnonLeafPTE\n382:   when (RegNext(io.tlb.req.bits.checkfullva)
      &&\n383:     (s1_out.uop.exceptionVec(storePageFault) ||\n384:       s1_out.uop.exceptionVec(storeAccessFault)
      ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 387-400
    context: "387:   }\n388:   s1_out.uop.exceptionVec(storePageFault)      := (io.tlb.resp.bits.excp(0).pf.st\
      \  || io.tlb.resp.bits.excp(0).pf.ld ) && s1_vecActive\n389:   s1_out.uop.exceptionVec(storeAccessFault)\
      \    := (io.tlb.resp.bits.excp(0).af.st  || io.tlb.resp.bits.excp(0).af.ld )
      && s1_vecActive\n390:   s1_out.uop.exceptionVec(storeGuestPageFault) := (io.tlb.resp.bits.excp(0).gpf.st
      || io.tlb.resp.bits.excp(0).gpf.ld) && s1_vecActive\n391: \n392:   s1_out.uop.flushPipe\
      \                := false.B\n393:   s1_out.uop.trigger                  := s1_trigger_action\n\
      394:   s1_out.uop.exceptionVec(breakPoint) := s1_trigger_breakpoint\n395:  \
      \ s1_out.uop.exceptionVec(storeAddrMisaligned) := s1_out.mmio && s1_in.isMisalign\n\
      396:   s1_out.vecVaddrOffset := Mux(\n397:     s1_trigger_debug_mode || s1_trigger_breakpoint,\n\
      398:     storeTrigger.io.toLoadStore.triggerVaddr - s1_in.vecBaseVaddr,\n399:\
      \     s1_in.vaddr + genVFirstUnmask(s1_in.mask).asUInt - s1_in.vecBaseVaddr
      ,\n400:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 400-410
    context: "400:   )\n401:   s1_out.vecTriggerMask := Mux(s1_trigger_debug_mode
      || s1_trigger_breakpoint, storeTrigger.io.toLoadStore.triggerMask, 0.U)\n402:\
      \ \n403:   // scalar store and scalar load nuke check, and also other purposes\n\
      404:   //A 128-bit aligned unaligned memory access requires changing the unaligned
      flag bit in sq\n405:   io.lsq.valid     := s1_valid && !s1_in.isHWPrefetch\n\
      406:   io.lsq.bits      := s1_out\n407:   io.lsq.bits.miss := s1_tlb_miss\n\
      408:   io.lsq.bits.isvec := s1_out.isvec || s1_frm_mab_vec\n409:   io.lsq.bits.updateAddrValid
      := (!s1_in.isMisalign || s1_in.misalignWith16Byte) && (!s1_frm_mabuf || s1_in.isFinalSplit)
      || s1_exception\n410:   // kill dcache write intent request when tlb miss or
      exception"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 406-416
    context: "406:   io.lsq.bits      := s1_out\n407:   io.lsq.bits.miss := s1_tlb_miss\n\
      408:   io.lsq.bits.isvec := s1_out.isvec || s1_frm_mab_vec\n409:   io.lsq.bits.updateAddrValid
      := (!s1_in.isMisalign || s1_in.misalignWith16Byte) && (!s1_frm_mabuf || s1_in.isFinalSplit)
      || s1_exception\n410:   // kill dcache write intent request when tlb miss or
      exception\n411:   io.dcache.s1_kill  := (s1_tlb_miss || s1_exception || s1_out.mmio
      || s1_out.nc || s1_in.uop.robIdx.needFlush(io.redirect))\n412:   io.dcache.s1_paddr
      := s1_paddr\n413: \n414:   // write below io.out.bits assign sentence to prevent
      overwriting values\n415:   val s1_tlb_memidx = io.tlb.resp.bits.memidx\n416:\
      \   when(s1_tlb_memidx.is_st && io.tlb.resp.valid && !s1_tlb_miss && s1_tlb_memidx.idx
      === s1_out.uop.sqIdx.value) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 415-428
    context: "415:   val s1_tlb_memidx = io.tlb.resp.bits.memidx\n416:   when(s1_tlb_memidx.is_st
      && io.tlb.resp.valid && !s1_tlb_miss && s1_tlb_memidx.idx === s1_out.uop.sqIdx.value)
      {\n417:     // printf(\"Store idx = %d\\n\", s1_tlb_memidx.idx)\n418:     s1_out.uop.debugInfo.tlbRespTime
      := GTimer()\n419:   }\n420:   val s1_mis_align = s1_valid && !s1_tlb_miss &&
      !s1_in.isHWPrefetch && !s1_isCbo && !s1_out.nc && !s1_out.mmio &&\n421:    \
      \                   GatedValidRegNext(io.csrCtrl.hd_misalign_st_enable) && s1_in.isMisalign
      && !s1_in.misalignWith16Byte &&\n422:                       !s1_trigger_breakpoint
      && !s1_trigger_debug_mode\n423:   val s1_toMisalignBufferValid = s1_valid &&
      !s1_tlb_miss && !s1_in.isHWPrefetch &&\n424:     !s1_frm_mabuf && !s1_isCbo
      && s1_in.isMisalign && !s1_in.misalignWith16Byte &&\n425:     GatedValidRegNext(io.csrCtrl.hd_misalign_st_enable)\n\
      426:   io.misalign_enq.req.valid := s1_toMisalignBufferValid\n427:   io.misalign_enq.req.bits.fromLsPipelineBundle(s1_in)\n\
      428: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 429-444
    context: "429:   // Pipeline\n430:   // --------------------------------------------------------------------------------\n\
      431:   // stage 2\n432:   // --------------------------------------------------------------------------------\n\
      433:   // mmio check\n434:   val s2_valid  = RegInit(false.B)\n435:   val s2_in\
      \     = RegEnable(s1_out, s1_fire)\n436:   val s2_out    = Wire(new LsPipelineBundle)\n\
      437:   val s2_kill   = Wire(Bool())\n438:   val s2_can_go = s3_ready\n439: \
      \  val s2_fire   = s2_valid && !s2_kill && s2_can_go\n440:   val s2_vecActive\
      \    = RegEnable(s1_out.vecActive, true.B, s1_fire)\n441:   val s2_frm_mabuf\
      \    = s2_in.isFrmMisAlignBuf\n442:   val s2_frm_mab_vec  = RegEnable(s1_frm_mab_vec,
      true.B, s1_fire)\n443:   val s2_pbmt   = RegEnable(s1_pbmt, s1_fire)\n444: \
      \  val s2_trigger_debug_mode = RegEnable(s1_trigger_debug_mode, false.B, s1_fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 442-455
    context: "442:   val s2_frm_mab_vec  = RegEnable(s1_frm_mab_vec, true.B, s1_fire)\n\
      443:   val s2_pbmt   = RegEnable(s1_pbmt, s1_fire)\n444:   val s2_trigger_debug_mode
      = RegEnable(s1_trigger_debug_mode, false.B, s1_fire)\n445:   val s2_tlb_hit
      = RegEnable(s1_tlb_hit, s1_fire)\n446: \n447:   s2_ready := !s2_valid || s2_kill
      || s3_ready\n448:   when (s1_fire) { s2_valid := true.B }\n449:   .elsewhen
      (s2_fire) { s2_valid := false.B }\n450:   .elsewhen (s2_kill) { s2_valid :=
      false.B }\n451: \n452:   val s2_pmp = WireInit(io.pmp)\n453: \n454:   val s2_exception
      = RegNext(s1_feedback.bits.hit) &&\n455:                     (s2_trigger_debug_mode
      || ExceptionNO.selectByFu(s2_out.uop.exceptionVec, StaCfg).asUInt.orR) && s2_vecActive"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 454-465
    context: "454:   val s2_exception = RegNext(s1_feedback.bits.hit) &&\n455:   \
      \                  (s2_trigger_debug_mode || ExceptionNO.selectByFu(s2_out.uop.exceptionVec,
      StaCfg).asUInt.orR) && s2_vecActive\n456:   val s2_un_misalign_exception = \
      \ RegNext(s1_feedback.bits.hit) &&\n457:                     (s2_trigger_debug_mode
      || ExceptionNO.selectByFuAndUnSelect(s2_out.uop.exceptionVec, StaCfg, Seq(storeAddrMisaligned)).asUInt.orR)\n\
      458: \n459:   val s2_mmio = (s2_in.mmio || (Pbmt.isPMA(s2_pbmt) && s2_pmp.mmio))
      && RegNext(s1_feedback.bits.hit)\n460:   val s2_memBackTypeMM = !s2_pmp.mmio\n\
      461:   // The response signal of `pmp/pma` is credible only after the physical
      address is actually generated.\n462:   // Therefore, the response signals of
      pmp/pma generated after an address translation has produced an `access fault`
      or a `page fault` are completely unreliable.\n463:   val s2_un_access_exception
      =  s2_vecActive && (\n464:     s2_in.uop.exceptionVec(storeAccessFault) ||\n\
      465:     s2_in.uop.exceptionVec(storePageFault)   ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 464-486
    context: "464:     s2_in.uop.exceptionVec(storeAccessFault) ||\n465:     s2_in.uop.exceptionVec(storePageFault)\
      \   ||\n466:     s2_in.uop.exceptionVec(storeGuestPageFault)\n467:   )\n468:\
      \   // This real physical address is located in uncache space.\n469:   val s2_actually_uncache
      = s2_tlb_hit && !s2_un_access_exception && (Pbmt.isPMA(s2_pbmt) && s2_pmp.mmio
      || s2_in.nc || s2_in.mmio) && RegNext(s1_feedback.bits.hit)\n470:   val s2_isCbo\
      \  = RegEnable(s1_isCbo, s1_fire) // all cbo instr\n471:   val s2_isCbo_noZero
      = LSUOpType.isCbo(s2_in.uop.fuOpType)\n472: \n473:   s2_kill := ((s2_mmio &&
      !s2_exception) && !s2_in.isvec && !s2_frm_mabuf) || s2_in.uop.robIdx.needFlush(io.redirect)\n\
      474: \n475:   s2_out        := s2_in\n476:   s2_out.af     := s2_out.uop.exceptionVec(storeAccessFault)\n\
      477:   s2_out.mmio   := s2_mmio && !s2_exception\n478:   s2_out.memBackTypeMM
      := s2_memBackTypeMM\n479:   s2_out.uop.exceptionVec(storeAccessFault) := (s2_in.uop.exceptionVec(storeAccessFault)
      ||\n480:                                                 s2_pmp.st ||\n481:\
      \                                                 s2_pmp.ld && s2_isCbo_noZero
      || // cmo need read permission but produce store exception\n482:           \
      \                                      ((s2_in.isvec || s2_isCbo) && s2_actually_uncache
      && RegNext(s1_feedback.bits.hit))\n483:                                    \
      \             ) && s2_vecActive\n484:   s2_out.uop.exceptionVec(storeAddrMisaligned)
      := s2_actually_uncache && !s2_in.isvec && (s2_in.isMisalign || s2_in.isFrmMisAlignBuf)
      && !s2_un_misalign_exception\n485:   s2_out.uop.vpu.vstart     := s2_in.vecVaddrOffset
      >> s2_in.uop.vpu.veew\n486: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 483-516
    context: "483:                                                 ) && s2_vecActive\n\
      484:   s2_out.uop.exceptionVec(storeAddrMisaligned) := s2_actually_uncache &&
      !s2_in.isvec && (s2_in.isMisalign || s2_in.isFrmMisAlignBuf) && !s2_un_misalign_exception\n\
      485:   s2_out.uop.vpu.vstart     := s2_in.vecVaddrOffset >> s2_in.uop.vpu.veew\n\
      486: \n487:   // kill dcache write intent request when mmio or exception\n488:\
      \   io.dcache.s2_kill := (s2_actually_uncache || s2_exception || s2_in.uop.robIdx.needFlush(io.redirect))\n\
      489:   io.dcache.s2_pc   := s2_out.uop.pc\n490:   // TODO: dcache resp\n491:\
      \   io.dcache.resp.ready := true.B\n492: \n493:   val s2_mis_align = s2_valid
      && RegEnable(s1_mis_align, s1_fire) && !s2_exception\n494:   // goto misalignBuffer\n\
      495:   io.misalign_enq.revoke := s2_exception\n496:   val s2_misalignBufferNack
      = !io.misalign_enq.revoke &&\n497:     RegEnable(s1_toMisalignBufferValid &&
      !io.misalign_enq.req.ready, false.B, s1_fire)\n498: \n499:   // feedback tlb
      miss to RS in store_s2\n500:   val feedback_slow_valid = WireInit(false.B)\n\
      501: \n502:   feedback_slow_valid := s1_feedback.valid && !s1_out.uop.robIdx.needFlush(io.redirect)
      && !s1_out.isvec && !s1_frm_mabuf\n503:   io.feedback_slow.valid := GatedValidRegNext(feedback_slow_valid)\n\
      504:   io.feedback_slow.bits  := RegEnable(s1_feedback.bits, feedback_slow_valid)\n\
      505:   io.feedback_slow.bits.hit  := RegEnable(s1_feedback.bits.hit, feedback_slow_valid)
      && !s2_misalignBufferNack\n506: \n507:   val s2_vecFeedback = RegNext(!s1_out.uop.robIdx.needFlush(io.redirect)
      && s1_feedback.bits.hit && s1_feedback.valid) &&\n508:                     \
      \   !s2_misalignBufferNack && s2_in.isvec && !s2_frm_mabuf\n509: \n510:   val
      s2_misalign_stout = WireInit(0.U.asTypeOf(io.misalign_stout))\n511:   s2_misalign_stout.valid
      := s2_valid && s2_can_go && s2_frm_mabuf\n512:   connectSamePort(s2_misalign_stout.bits,
      s2_out)\n513:   s2_misalign_stout.bits.need_rep := RegEnable(s1_tlb_miss, s1_fire)\n\
      514:   io.misalign_stout := s2_misalign_stout\n515: \n516:   val s2_misalign_cango
      = !s2_mis_align || s2_in.isvec && s2_misalignBufferNack"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 515-534
    context: "515: \n516:   val s2_misalign_cango = !s2_mis_align || s2_in.isvec &&
      s2_misalignBufferNack\n517: \n518:   // mmio and exception\n519:   io.lsq_replenish
      := s2_out\n520:   io.lsq_replenish.af := s2_out.af && s2_valid && !s2_kill\n\
      521:   io.lsq_replenish.mmio := (s2_mmio || s2_isCbo_noZero) && !s2_exception
      // reuse `mmiostall` logic in sq\n522: \n523:   // prefetch related\n524:  \
      \ io.lsq_replenish.miss := io.dcache.resp.fire && io.dcache.resp.bits.miss //
      miss info\n525:   io.lsq_replenish.updateAddrValid := !s2_mis_align && (!s2_frm_mabuf
      || s2_out.isFinalSplit) || s2_exception\n526:   io.lsq_replenish.isvec := s2_out.isvec
      || s2_frm_mab_vec\n527: \n528:   io.lsq_replenish.hasException := (ExceptionNO.selectByFu(s2_out.uop.exceptionVec,
      StaCfg).asUInt.orR ||\n529:     TriggerAction.isDmode(s2_out.uop.trigger) ||
      s2_out.af) && s2_valid && !s2_kill\n530: \n531: \n532:   // RegNext prefetch
      train for better timing\n533:   // ** Now, prefetch train is valid at store
      s3 **\n534:   val s2_prefetch_train_valid = WireInit(false.B)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 530-540
    context: "530: \n531: \n532:   // RegNext prefetch train for better timing\n533:\
      \   // ** Now, prefetch train is valid at store s3 **\n534:   val s2_prefetch_train_valid
      = WireInit(false.B)\n535:   s2_prefetch_train_valid := s2_valid && io.dcache.resp.fire
      && !s2_out.mmio && !s2_out.nc && !s2_in.tlbMiss && !s2_in.isHWPrefetch\n536:\
      \   if(EnableStorePrefetchSMS) {\n537:     io.s1_prefetch_spec := s1_fire\n\
      538:     io.s2_prefetch_spec := s2_prefetch_train_valid\n539:     io.prefetch_train.valid
      := RegNext(s2_prefetch_train_valid)\n540:     io.prefetch_train.bits.fromLsPipelineBundle(s2_in,
      latch = true, enable = s2_prefetch_train_valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 559-581
    context: "559:   // Pipeline\n560:   // --------------------------------------------------------------------------------\n\
      561:   // stage 3\n562:   // --------------------------------------------------------------------------------\n\
      563:   // store write back\n564:   val s3_valid  = RegInit(false.B)\n565:  \
      \ val s3_in     = RegEnable(s2_out, s2_fire)\n566:   val s3_out    = Wire(new
      MemExuOutput(isVector = true))\n567:   val s3_kill   = s3_in.uop.robIdx.needFlush(io.redirect)\n\
      568:   val s3_can_go = s3_ready\n569:   val s3_fire   = s3_valid && !s3_kill
      && s3_can_go\n570:   val s3_vecFeedback = RegEnable(s2_vecFeedback, s2_fire)\n\
      571:   val s3_exception     = RegEnable(s2_exception, s2_fire)\n572: \n573:\
      \   // store misalign will not writeback to rob now\n574:   when (s2_fire) {
      s3_valid := (!s2_mmio && !s2_isCbo || s2_exception) && !s2_out.isHWPrefetch
      && s2_misalign_cango && !s2_frm_mabuf }\n575:   .elsewhen (s3_fire) { s3_valid
      := false.B }\n576:   .elsewhen (s3_kill) { s3_valid := false.B }\n577: \n578:\
      \   // wb: writeback\n579: \n580:   s3_out                 := DontCare\n581:\
      \   s3_out.uop             := s3_in.uop"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 578-588
    context: "578:   // wb: writeback\n579: \n580:   s3_out                 := DontCare\n\
      581:   s3_out.uop             := s3_in.uop\n582:   s3_out.data            :=
      DontCare\n583:   s3_out.debug.isMMIO    := s3_in.mmio\n584:   s3_out.debug.isNCIO\
      \    := s3_in.nc && !s3_in.memBackTypeMM\n585:   s3_out.debug.paddr     := s3_in.paddr\n\
      586:   s3_out.debug.vaddr     := s3_in.vaddr\n587:   s3_out.debug.isPerfCnt
      := false.B\n588: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 584-594
    context: "584:   s3_out.debug.isNCIO    := s3_in.nc && !s3_in.memBackTypeMM\n\
      585:   s3_out.debug.paddr     := s3_in.paddr\n586:   s3_out.debug.vaddr    \
      \ := s3_in.vaddr\n587:   s3_out.debug.isPerfCnt := false.B\n588: \n589:   XSError(s3_valid
      && s3_in.isvec && s3_in.vecActive && !s3_in.mask.orR, \"In vecActive, mask complement
      should not be 0\")\n590:   // Pipeline\n591:   // --------------------------------------------------------------------------------\n\
      592:   // stage x\n593:   // --------------------------------------------------------------------------------\n\
      594:   val sx_valid = Wire(Vec(RAWTotalDelayCycles + 1, Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 590-612
    context: "590:   // Pipeline\n591:   // --------------------------------------------------------------------------------\n\
      592:   // stage x\n593:   // --------------------------------------------------------------------------------\n\
      594:   val sx_valid = Wire(Vec(RAWTotalDelayCycles + 1, Bool()))\n595:   val
      sx_ready = Wire(Vec(RAWTotalDelayCycles + 1, Bool()))\n596:   val sx_in    =
      Wire(Vec(RAWTotalDelayCycles + 1, new VecMemExuOutput(isVector = true)))\n597:\
      \   val sx_in_vec = Wire(Vec(RAWTotalDelayCycles +1, Bool()))\n598: \n599: \
      \  // backward ready signal\n600:   s3_ready := sx_ready.head\n601:   for (i
      <- 0 until RAWTotalDelayCycles + 1) {\n602:     if (i == 0) {\n603:       sx_valid(i)\
      \          := s3_valid\n604:       sx_in(i).output      := s3_out\n605:    \
      \   sx_in(i).vecFeedback := s3_vecFeedback\n606:       sx_in(i).nc         \
      \ := s3_in.nc\n607:       sx_in(i).mmio        := s3_in.mmio\n608:       sx_in(i).usSecondInv
      := s3_in.usSecondInv\n609:       sx_in(i).elemIdx     := s3_in.elemIdx\n610:\
      \       sx_in(i).alignedType := s3_in.alignedType\n611:       sx_in(i).mbIndex\
      \     := s3_in.mbIndex\n612:       sx_in(i).mask        := s3_in.mask"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 615-632
    context: "615:       sx_in(i).gpaddr      := s3_in.gpaddr\n616:       sx_in(i).isForVSnonLeafPTE\
      \     := s3_in.isForVSnonLeafPTE\n617:       sx_in(i).vecTriggerMask := s3_in.vecTriggerMask\n\
      618:       sx_in(i).hasException := s3_exception\n619:       sx_in_vec(i)  \
      \       := s3_in.isvec\n620:       sx_ready(i) := !s3_valid(i) || sx_in(i).output.uop.robIdx.needFlush(io.redirect)
      || (if (RAWTotalDelayCycles == 0) io.stout.ready else sx_ready(i+1))\n621: \
      \    } else {\n622:       val cur_kill   = sx_in(i).output.uop.robIdx.needFlush(io.redirect)\n\
      623:       val cur_can_go = (if (i == RAWTotalDelayCycles) io.stout.ready else
      sx_ready(i+1))\n624:       val cur_fire   = sx_valid(i) && !cur_kill && cur_can_go\n\
      625:       val prev_fire  = sx_valid(i-1) && !sx_in(i-1).output.uop.robIdx.needFlush(io.redirect)
      && sx_ready(i)\n626: \n627:       sx_ready(i) := !sx_valid(i) || cur_kill ||
      (if (i == RAWTotalDelayCycles) io.stout.ready else sx_ready(i+1))\n628:    \
      \   val sx_valid_can_go = prev_fire || cur_fire || cur_kill\n629:       sx_valid(i)
      := RegEnable(Mux(prev_fire, true.B, false.B), false.B, sx_valid_can_go)\n630:\
      \       sx_in(i) := RegEnable(sx_in(i-1), prev_fire)\n631:       sx_in_vec(i)
      := RegEnable(sx_in_vec(i-1), prev_fire)\n632:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 629-650
    context: "629:       sx_valid(i) := RegEnable(Mux(prev_fire, true.B, false.B),
      false.B, sx_valid_can_go)\n630:       sx_in(i) := RegEnable(sx_in(i-1), prev_fire)\n\
      631:       sx_in_vec(i) := RegEnable(sx_in_vec(i-1), prev_fire)\n632:     }\n\
      633:   }\n634:   val sx_last_valid = sx_valid.takeRight(1).head\n635:   val
      sx_last_ready = sx_ready.takeRight(1).head\n636:   val sx_last_in    = sx_in.takeRight(1).head\n\
      637:   val sx_last_in_vec = sx_in_vec.takeRight(1).head\n638:   sx_last_ready
      := !sx_last_valid || sx_last_in.output.uop.robIdx.needFlush(io.redirect) ||
      io.stout.ready\n639: \n640:   // write back: normal store, nc store\n641:  \
      \ io.stout.valid := sx_last_valid && !sx_last_in_vec //isStore(sx_last_in.output.uop.fuType)\n\
      642:   io.stout.bits := sx_last_in.output\n643:   io.stout.bits.uop.exceptionVec
      := ExceptionNO.selectByFu(sx_last_in.output.uop.exceptionVec, StaCfg)\n644:\
      \ \n645:   io.vecstout.valid := sx_last_valid && sx_last_in_vec //isVStore(sx_last_in.output.uop.fuType)\n\
      646:   // TODO: implement it!\n647:   io.vecstout.bits.mBIndex := sx_last_in.mbIndex\n\
      648:   io.vecstout.bits.hit := sx_last_in.vecFeedback\n649:   io.vecstout.bits.isvec
      := true.B\n650:   io.vecstout.bits.sourceType := RSFeedbackType.tlbMiss"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 646-659
    context: "646:   // TODO: implement it!\n647:   io.vecstout.bits.mBIndex := sx_last_in.mbIndex\n\
      648:   io.vecstout.bits.hit := sx_last_in.vecFeedback\n649:   io.vecstout.bits.isvec
      := true.B\n650:   io.vecstout.bits.sourceType := RSFeedbackType.tlbMiss\n651:\
      \   io.vecstout.bits.flushState := DontCare\n652:   io.vecstout.bits.trigger\
      \    := sx_last_in.output.uop.trigger\n653:   io.vecstout.bits.nc := sx_last_in.nc\n\
      654:   io.vecstout.bits.mmio := sx_last_in.mmio\n655:   io.vecstout.bits.exceptionVec
      := ExceptionNO.selectByFu(sx_last_in.output.uop.exceptionVec, VstuCfg)\n656:\
      \   io.vecstout.bits.hasException := sx_last_in.hasException\n657:   io.vecstout.bits.usSecondInv
      := sx_last_in.usSecondInv\n658:   io.vecstout.bits.vecFeedback := sx_last_in.vecFeedback\n\
      659:   io.vecstout.bits.elemIdx     := sx_last_in.elemIdx"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 684-698
    context: "684:         p\"data ${Hexadecimal(pipeline.data)} \" +\n685:      \
      \   p\"mask ${Hexadecimal(pipeline.mask)}\\n\"\n686:     )\n687:   }\n688: \n\
      689:   printPipeLine(s0_out, s0_valid, \"S0\")\n690:   printPipeLine(s1_out,
      s1_valid, \"S1\")\n691: \n692:   // perf cnt\n693:   XSPerfAccumulate(\"s0_in_valid\"\
      ,                s0_valid)\n694:   XSPerfAccumulate(\"s0_in_fire\",        \
      \         s0_fire)\n695:   XSPerfAccumulate(\"s0_vecin_fire\",             \
      \ s0_fire && s0_use_flow_vec)\n696:   XSPerfAccumulate(\"s0_in_fire_first_issue\"\
      ,     s0_fire && s0_isFirstIssue)\n697:   XSPerfAccumulate(\"s0_addr_spec_success\"\
      ,       s0_fire && !s0_use_flow_vec && s0_saddr(VAddrBits-1, 12) === s0_stin.src(0)(VAddrBits-1,
      12))\n698:   XSPerfAccumulate(\"s0_addr_spec_failed\",        s0_fire && !s0_use_flow_vec
      && s0_saddr(VAddrBits-1, 12) =/= s0_stin.src(0)(VAddrBits-1, 12))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 697-707
    context: "697:   XSPerfAccumulate(\"s0_addr_spec_success\",       s0_fire && !s0_use_flow_vec
      && s0_saddr(VAddrBits-1, 12) === s0_stin.src(0)(VAddrBits-1, 12))\n698:   XSPerfAccumulate(\"\
      s0_addr_spec_failed\",        s0_fire && !s0_use_flow_vec && s0_saddr(VAddrBits-1,
      12) =/= s0_stin.src(0)(VAddrBits-1, 12))\n699:   XSPerfAccumulate(\"s0_addr_spec_success_once\"\
      ,  s0_fire && !s0_use_flow_vec && s0_saddr(VAddrBits-1, 12) === s0_stin.src(0)(VAddrBits-1,
      12) && s0_isFirstIssue)\n700:   XSPerfAccumulate(\"s0_addr_spec_failed_once\"\
      ,   s0_fire && !s0_use_flow_vec && s0_saddr(VAddrBits-1, 12) =/= s0_stin.src(0)(VAddrBits-1,
      12) && s0_isFirstIssue)\n701: \n702:   XSPerfAccumulate(\"s1_in_valid\",   \
      \             s1_valid)\n703:   XSPerfAccumulate(\"s1_in_fire\",           \
      \      s1_fire)\n704:   XSPerfAccumulate(\"s1_in_fire_first_issue\",     s1_fire
      && s1_in.isFirstIssue)\n705:   XSPerfAccumulate(\"s1_tlb_miss\",           \
      \     s1_fire && s1_tlb_miss)\n706:   XSPerfAccumulate(\"s1_tlb_miss_first_issue\"\
      ,    s1_fire && s1_tlb_miss && s1_in.isFirstIssue)\n707:   // end"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 45-55
    context: "45:   with HasVLSUParameters\n46:   with SdtrigExt\n47: {\n48:   val
      io = IO(new Bundle() {\n49:     // control\n50:     val redirect      = Flipped(ValidIO(new
      Redirect))\n51:     val csrCtrl       = Flipped(new CustomCSRCtrlIO)\n52: \n\
      53:     // flow in\n54:     val lsin          = Flipped(Decoupled(new MemExuInput))\n\
      55: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 99-109
    context: "99: \n100:       // schedule error query\n101:       val stld_nuke_query
      = Flipped(Vec(StorePipelineWidth, Valid(new StoreNukeQueryBundle)))\n102: \n\
      103:       // queue-based replay\n104:       val replay       = Flipped(Decoupled(new
      LsPipelineBundle))\n105:       val lq_rep_full  = Input(Bool())\n106: \n107:\
      \       // misc\n108:       val s2_ptr_chasing = Output(Bool()) // provide right
      pc for hw prefetch\n109: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 110-120
    context: "110:       // Load fast replay path\n111:       val fast_rep_in  = Flipped(Decoupled(new
      LqWriteBundle))\n112:       val fast_rep_out = Decoupled(new LqWriteBundle)\n\
      113: \n114:       // Load RAR rollback\n115:       val rollback = Valid(new
      Redirect)\n116: \n117:       // perf\n118:       val debug_ls         = Output(new
      DebugLsInfoBundle)\n119:       val lsTopdownInfo    = Output(new LsTopdownInfo)\n\
      120:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 160-170
    context: "160:   })\n161: \n162:   PerfCCT.updateInstPos(io.lsin.bits.uop.debug_seqNum,
      PerfCCT.InstPos.AtFU.id.U, io.lsin.valid, clock, reset)\n163: \n164:   val StorePrefetchL1Enabled
      = EnableStorePrefetchAtCommit || EnableStorePrefetchAtIssue || EnableStorePrefetchSPB\n\
      165:   val s1_ready, s2_ready, s3_ready, sx_can_go = WireInit(false.B)\n166:\
      \ \n167:   // Pipeline\n168:   // --------------------------------------------------------------------------------\n\
      169:   // stage 0\n170:   // --------------------------------------------------------------------------------"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 167-177
    context: "167:   // Pipeline\n168:   // --------------------------------------------------------------------------------\n\
      169:   // stage 0\n170:   // --------------------------------------------------------------------------------\n\
      171:   // generate addr, use addr to query DCache and DTLB\n172:   val s0_valid\
      \         = Wire(Bool())\n173:   val s0_dcache_ready  = Wire(Bool())\n174: \
      \  val s0_kill          = Wire(Bool())\n175:   val s0_vaddr         = Wire(UInt(VAddrBits.W))\n\
      176:   val s0_mask          = Wire(UInt((VLEN/8).W))\n177:   val s0_uop    \
      \       = Wire(new DynInst)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 182-193
    context: "182:   val s0_isFirstIssue  = Wire(Bool())\n183:   val s0_fast_rep \
      \     = Wire(Bool())\n184:   val s0_ld_rep        = Wire(Bool())\n185:   val
      s0_l2l_fwd       = Wire(Bool())\n186:   val s0_sched_idx     = Wire(UInt())\n\
      187:   val s0_can_go        = s1_ready\n188:   val s0_fire          = s0_valid
      && s0_dcache_ready && s0_can_go\n189:   val s0_out           = Wire(new LqWriteBundle)\n\
      190:   // vector\n191:   val s0_isvec = WireInit(false.B)\n192:   val s0_vecActive
      = WireInit(true.B)\n193:   // val s0_flowPtr = WireInit(0.U.asTypeOf(new VsFlowPtr))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 202-212
    context: "202:   // src5: vec read first issue from RS (TODO)\n203:   // src6:
      load try pointchaising when no issued or replayed load (io.fastpath)\n204: \
      \  // src7: hardware prefetch from prefetchor (high confidence) (io.prefetch)\n\
      205:   // priority: high to low\n206:   val s0_ld_flow             = FuType.isLoad(s0_uop.fuType)
      || FuType.isVLoad(s0_uop.fuType)\n207:   val s0_rep_stall           = io.lsin.valid
      && isAfter(io.ldu_io.replay.bits.uop.robIdx, io.lsin.bits.uop.robIdx)\n208:\
      \   private val SRC_NUM = 8\n209:   private val Seq(\n210:     super_rep_idx,
      fast_rep_idx, lsq_rep_idx, high_pf_idx,\n211:     int_iss_idx, vec_iss_idx,
      l2l_fwd_idx, low_pf_idx\n212:   ) = (0 until SRC_NUM).toSeq"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 210-222
    context: "210:     super_rep_idx, fast_rep_idx, lsq_rep_idx, high_pf_idx,\n211:\
      \     int_iss_idx, vec_iss_idx, l2l_fwd_idx, low_pf_idx\n212:   ) = (0 until
      SRC_NUM).toSeq\n213:   // load flow source valid\n214:   val s0_src_valid_vec
      = WireInit(VecInit(Seq(\n215:     io.ldu_io.replay.valid && io.ldu_io.replay.bits.forward_tlDchannel,\n\
      216:     io.ldu_io.fast_rep_in.valid,\n217:     io.ldu_io.replay.valid && !io.ldu_io.replay.bits.forward_tlDchannel
      && !s0_rep_stall,\n218:     io.ldu_io.prefetch_req.valid && io.ldu_io.prefetch_req.bits.confidence
      > 0.U,\n219:     io.lsin.valid, // int flow first issue or software prefetch\n\
      220:     io.vec_stu_io.in.valid,\n221:     io.ldu_io.l2l_fwd_in.valid && io.ldu_io.ld_fast_match,\n\
      222:     io.ldu_io.prefetch_req.valid && io.ldu_io.prefetch_req.bits.confidence
      === 0.U,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 235-252
    context: "235:     dontTouch(s0_src_valid_vec)\n236:     dontTouch(s0_src_ready_vec)\n\
      237:     dontTouch(s0_src_select_vec)\n238:   }\n239: \n240:   s0_valid := s0_src_valid_vec.reduce(_
      || _) && !s0_kill\n241: \n242:   // which is S0's out is ready and dcache is
      ready\n243:   val s0_try_ptr_chasing      = s0_src_select_vec(l2l_fwd_idx)\n\
      244:   val s0_do_try_ptr_chasing   = s0_try_ptr_chasing && s0_can_go && io.ldu_io.dcache.req.ready\n\
      245:   val s0_ptr_chasing_vaddr    = io.ldu_io.l2l_fwd_in.data(5, 0) +& io.ldu_io.ld_fast_imm(5,
      0)\n246:   val s0_ptr_chasing_canceled = WireInit(false.B)\n247:   s0_kill :=
      s0_ptr_chasing_canceled || (s0_out.uop.robIdx.needFlush(io.redirect) && !s0_try_ptr_chasing)\n\
      248: \n249:   // prefetch related ctrl signal\n250:   val s0_prf    = Wire(Bool())\n\
      251:   val s0_prf_rd = Wire(Bool())\n252:   val s0_prf_wr = Wire(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 250-273
    context: "250:   val s0_prf    = Wire(Bool())\n251:   val s0_prf_rd = Wire(Bool())\n\
      252:   val s0_prf_wr = Wire(Bool())\n253:   val s0_hw_prf = s0_hw_prf_select\n\
      254: \n255:   io.canAcceptLowConfPrefetch  := s0_src_ready_vec(low_pf_idx) &&
      io.ldu_io.dcache.req.ready\n256:   io.canAcceptHighConfPrefetch := s0_src_ready_vec(high_pf_idx)
      && io.ldu_io.dcache.req.ready\n257: \n258:   if (StorePrefetchL1Enabled) {\n\
      259:     s0_dcache_ready := Mux(s0_ld_flow, io.ldu_io.dcache.req.ready, io.stu_io.dcache.req.ready)\n\
      260:   } else {\n261:     s0_dcache_ready := Mux(s0_ld_flow, io.ldu_io.dcache.req.ready,
      true.B)\n262:   }\n263: \n264:   // query DTLB\n265:   io.tlb.req.valid    \
      \               := s0_valid && s0_dcache_ready\n266:   io.tlb.req.bits.cmd \
      \               := Mux(s0_prf,\n267:                                       \
      \   Mux(s0_prf_wr, TlbCmd.write, TlbCmd.read),\n268:                       \
      \                   Mux(s0_ld_flow, TlbCmd.read, TlbCmd.write)\n269:       \
      \                                 )\n270:   io.tlb.req.bits.vaddr          \
      \    := Mux(s0_hw_prf_select, io.ldu_io.prefetch_req.bits.paddr, s0_vaddr)\n\
      271:   io.tlb.req.bits.size               := Mux(s0_isvec, io.vec_stu_io.in.bits.alignedType(1,
      0), LSUOpType.size(s0_uop.fuOpType)) // may broken if use it in feature\n272:\
      \   io.tlb.req.bits.kill               := s0_kill\n273:   io.tlb.req.bits.memidx.is_ld\
      \       := s0_ld_flow"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 278-288
    context: "278:   io.tlb.req.bits.debug.pc           := s0_uop.pc\n279:   io.tlb.req.bits.debug.isFirstIssue
      := s0_isFirstIssue\n280: \n281:   // query DCache\n282:   // for load\n283:\
      \   io.ldu_io.dcache.req.valid             := s0_valid && s0_dcache_ready &&
      s0_ld_flow\n284:   io.ldu_io.dcache.req.bits.cmd          :=  Mux(s0_prf_rd,
      MemoryOpConstants.M_PFR,\n285:                                             \
      \  Mux(s0_prf_wr, MemoryOpConstants.M_PFW, MemoryOpConstants.M_XRD))\n286: \
      \  io.ldu_io.dcache.req.bits.vaddr        := s0_vaddr\n287:   io.ldu_io.dcache.req.bits.mask\
      \         := s0_mask\n288:   io.ldu_io.dcache.req.bits.data         := DontCare"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 293-303
    context: "293:   io.ldu_io.dcache.req.bits.id           := DontCare // TODO: update
      cache meta\n294:   io.ldu_io.dcache.pf_source             := Mux(s0_hw_prf_select,
      io.ldu_io.prefetch_req.bits.pf_source.value, L1_HW_PREFETCH_NULL)\n295:   io.ldu_io.dcache.is128Req\
      \              := is128Bit(io.vec_stu_io.in.bits.alignedType) && io.vec_stu_io.in.valid
      && s0_src_select_vec(vec_iss_idx)\n296: \n297:   // for store\n298:   io.stu_io.dcache.req.valid\
      \             := s0_valid && s0_dcache_ready && !s0_ld_flow && !s0_prf\n299:\
      \   io.stu_io.dcache.req.bits.cmd          := MemoryOpConstants.M_PFW\n300:\
      \   io.stu_io.dcache.req.bits.vaddr        := s0_vaddr\n301:   io.stu_io.dcache.req.bits.instrtype\
      \    := Mux(s0_prf, DCACHE_PREFETCH_SOURCE.U, STORE_SOURCE.U)\n302: \n303: \
      \  // load flow priority mux"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 437-449
    context: "437:     s0_sched_idx          := 0.U\n438:   }\n439: \n440:   // set
      default\n441:   s0_uop := DontCare\n442:   when (s0_src_select_vec(super_rep_idx))
      { fromNormalReplaySource(io.ldu_io.replay.bits)     }\n443:   .elsewhen (s0_src_select_vec(fast_rep_idx))
      { fromFastReplaySource(io.ldu_io.fast_rep_in.bits)  }\n444:   .elsewhen (s0_src_select_vec(lsq_rep_idx))
      { fromNormalReplaySource(io.ldu_io.replay.bits)     }\n445:   .elsewhen (s0_hw_prf_select)
      { fromPrefetchSource(io.ldu_io.prefetch_req.bits)   }\n446:   .elsewhen (s0_src_select_vec(int_iss_idx))
      { fromIntIssueSource(io.lsin.bits)                  }\n447:   .elsewhen (s0_src_select_vec(vec_iss_idx))
      { fromVecIssueSource(io.vec_stu_io.in.bits)         }\n448:   .otherwise {\n\
      449:     if (EnableLoadToLoadForward) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 488-503
    context: "488:     s0_out.uop.debugInfo.tlbFirstReqTime := s0_uop.debugInfo.tlbFirstReqTime\n\
      489:   }\n490:   s0_out.schedIndex     := s0_sched_idx\n491: \n492:   // load
      fast replay\n493:   io.ldu_io.fast_rep_in.ready := (s0_can_go && io.ldu_io.dcache.req.ready
      && s0_src_ready_vec(fast_rep_idx))\n494: \n495:   // load flow source ready\n\
      496:   // cache missed load has highest priority\n497:   // always accept cache
      missed load flow from load replay queue\n498:   io.ldu_io.replay.ready := (s0_can_go
      && io.ldu_io.dcache.req.ready && (s0_src_ready_vec(lsq_rep_idx) && !s0_rep_stall
      || s0_src_select_vec(super_rep_idx)))\n499: \n500:   // accept load flow from
      rs when:\n501:   // 1) there is no lsq-replayed load\n502:   // 2) there is
      no fast replayed load\n503:   // 3) there is no high confidence prefetch request"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 499-512
    context: "499: \n500:   // accept load flow from rs when:\n501:   // 1) there
      is no lsq-replayed load\n502:   // 2) there is no fast replayed load\n503: \
      \  // 3) there is no high confidence prefetch request\n504:   io.lsin.ready
      := (s0_can_go &&\n505:                     Mux(FuType.isLoad(io.lsin.bits.uop.fuType),
      io.ldu_io.dcache.req.ready,\n506:                     (if (StorePrefetchL1Enabled)
      io.stu_io.dcache.req.ready else true.B)) && s0_src_ready_vec(int_iss_idx))\n\
      507:   io.vec_stu_io.in.ready := s0_can_go && io.ldu_io.dcache.req.ready &&
      s0_src_ready_vec(vec_iss_idx)\n508: \n509: \n510:   // for hw prefetch load
      flow feedback, to be added later\n511:   // io.prefetch_in.ready := s0_hw_prf_select\n\
      512: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 510-536
    context: "510:   // for hw prefetch load flow feedback, to be added later\n511:\
      \   // io.prefetch_in.ready := s0_hw_prf_select\n512: \n513:   // dcache replacement
      extra info\n514:   // TODO: should prefetch load update replacement?\n515: \
      \  io.ldu_io.dcache.replacementUpdated := Mux(s0_src_select_vec(lsq_rep_idx)
      || s0_src_select_vec(super_rep_idx), io.ldu_io.replay.bits.replacementUpdated,
      false.B)\n516: \n517:   io.stu_io.prefetch_req.ready := s1_ready && io.stu_io.dcache.req.ready
      && !io.lsin.valid\n518: \n519:   // load debug\n520:   XSDebug(io.ldu_io.dcache.req.fire
      && s0_ld_flow,\n521:     p\"[DCACHE LOAD REQ] pc ${Hexadecimal(s0_uop.pc)},
      vaddr ${Hexadecimal(s0_vaddr)}\\n\"\n522:   )\n523:   XSDebug(s0_valid && s0_ld_flow,\n\
      524:     p\"S0: pc ${Hexadecimal(s0_out.uop.pc)}, lqIdx ${Hexadecimal(s0_out.uop.lqIdx.asUInt)},
      \" +\n525:     p\"vaddr ${Hexadecimal(s0_out.vaddr)}, mask ${Hexadecimal(s0_out.mask)}\\\
      n\")\n526: \n527:   // store debug\n528:   XSDebug(io.stu_io.dcache.req.fire
      && !s0_ld_flow,\n529:     p\"[DCACHE STORE REQ] pc ${Hexadecimal(s0_uop.pc)},
      vaddr ${Hexadecimal(s0_vaddr)}\\n\"\n530:   )\n531:   XSDebug(s0_valid && !s0_ld_flow,\n\
      532:     p\"S0: pc ${Hexadecimal(s0_out.uop.pc)}, sqIdx ${Hexadecimal(s0_out.uop.sqIdx.asUInt)},
      \" +\n533:     p\"vaddr ${Hexadecimal(s0_out.vaddr)}, mask ${Hexadecimal(s0_out.mask)}\\\
      n\")\n534: \n535: \n536:   // Pipeline"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 536-559
    context: "536:   // Pipeline\n537:   // --------------------------------------------------------------------------------\n\
      538:   // stage 1\n539:   // --------------------------------------------------------------------------------\n\
      540:   // TLB resp (send paddr to dcache)\n541:   val s1_valid      = RegInit(false.B)\n\
      542:   val s1_in         = Wire(new LqWriteBundle)\n543:   val s1_out      \
      \  = Wire(new LqWriteBundle)\n544:   val s1_kill       = Wire(Bool())\n545:\
      \   val s1_can_go     = s2_ready\n546:   val s1_fire       = s1_valid && !s1_kill
      && s1_can_go\n547:   val s1_ld_flow    = RegNext(s0_ld_flow)\n548:   val s1_isvec\
      \      = RegEnable(s0_out.isvec, false.B, s0_fire)\n549:   val s1_isLastElem
      = RegEnable(s0_out.isLastElem, false.B, s0_fire)\n550: \n551:   s1_ready :=
      !s1_valid || s1_kill || s2_ready\n552:   when (s0_fire) { s1_valid := true.B
      }\n553:   .elsewhen (s1_fire) { s1_valid := false.B }\n554:   .elsewhen (s1_kill)
      { s1_valid := false.B }\n555:   s1_in   := RegEnable(s0_out, s0_fire)\n556:\
      \ \n557:   val s1_fast_rep_dly_err = RegNext(io.ldu_io.fast_rep_in.bits.delayedLoadError)\n\
      558:   val s1_fast_rep_kill    = s1_fast_rep_dly_err && s1_in.isFastReplay\n\
      559:   val s1_l2l_fwd_dly_err  = RegNext(io.ldu_io.l2l_fwd_in.dly_ld_err)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 573-585
    context: "573:   val s1_sw_prf           = s1_prf && !s1_hw_prf\n574:   val s1_tlb_memidx\
      \       = io.tlb.resp.bits.memidx\n575: \n576:   // mmio cbo decoder\n577: \
      \  val s1_mmio_cbo  = (s1_in.uop.fuOpType === LSUOpType.cbo_clean ||\n578: \
      \                      s1_in.uop.fuOpType === LSUOpType.cbo_flush ||\n579: \
      \                      s1_in.uop.fuOpType === LSUOpType.cbo_inval) && !s1_ld_flow
      && !s1_prf\n580:   val s1_mmio = s1_mmio_cbo\n581: \n582:   s1_vaddr_hi    \
      \     := s1_in.vaddr(VAddrBits - 1, 6)\n583:   s1_vaddr_lo         := s1_in.vaddr(5,
      0)\n584:   s1_vaddr            := Cat(s1_vaddr_hi, s1_vaddr_lo)\n585:   s1_paddr_dup_lsu\
      \    := io.tlb.resp.bits.paddr(0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 594-604
    context: "594:     // printf(\"Store idx = %d\\n\", s1_tlb_memidx.idx)\n595: \
      \    s1_out.uop.debugInfo.tlbRespTime := GTimer()\n596:   }\n597: \n598:   io.tlb.req_kill\
      \   := s1_kill\n599:   io.tlb.resp.ready := true.B\n600: \n601:   io.ldu_io.dcache.s1_paddr_dup_lsu\
      \    <> s1_paddr_dup_lsu\n602:   io.ldu_io.dcache.s1_paddr_dup_dcache <> s1_paddr_dup_dcache\n\
      603:   io.ldu_io.dcache.s1_kill             := s1_kill || s1_tlb_miss || s1_exception\n\
      604:   io.ldu_io.dcache.s1_kill_data_read   := s1_kill || s1_tlb_miss"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 602-612
    context: "602:   io.ldu_io.dcache.s1_paddr_dup_dcache <> s1_paddr_dup_dcache\n\
      603:   io.ldu_io.dcache.s1_kill             := s1_kill || s1_tlb_miss || s1_exception\n\
      604:   io.ldu_io.dcache.s1_kill_data_read   := s1_kill || s1_tlb_miss\n605:\
      \ \n606:   // store to load forwarding\n607:   io.ldu_io.sbuffer.valid := s1_valid
      && !(s1_exception || s1_tlb_miss || s1_kill || s1_fast_rep_kill || s1_prf ||
      !s1_ld_flow)\n608:   io.ldu_io.sbuffer.vaddr := s1_vaddr\n609:   io.ldu_io.sbuffer.paddr
      := s1_paddr_dup_lsu\n610:   io.ldu_io.sbuffer.uop   := s1_in.uop\n611:   io.ldu_io.sbuffer.sqIdx
      := s1_in.uop.sqIdx\n612:   io.ldu_io.sbuffer.mask  := s1_in.mask"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 610-620
    context: "610:   io.ldu_io.sbuffer.uop   := s1_in.uop\n611:   io.ldu_io.sbuffer.sqIdx
      := s1_in.uop.sqIdx\n612:   io.ldu_io.sbuffer.mask  := s1_in.mask\n613:   io.ldu_io.sbuffer.pc\
      \    := s1_in.uop.pc // FIXME: remove it\n614: \n615:   io.ldu_io.ubuffer.valid
      := s1_valid && !(s1_exception || s1_tlb_miss || s1_kill || s1_fast_rep_kill
      || s1_prf || !s1_ld_flow)\n616:   io.ldu_io.ubuffer.vaddr := s1_vaddr\n617:\
      \   io.ldu_io.ubuffer.paddr := s1_paddr_dup_lsu\n618:   io.ldu_io.ubuffer.uop\
      \   := s1_in.uop\n619:   io.ldu_io.ubuffer.sqIdx := s1_in.uop.sqIdx\n620:  \
      \ io.ldu_io.ubuffer.mask  := s1_in.mask"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 618-628
    context: "618:   io.ldu_io.ubuffer.uop   := s1_in.uop\n619:   io.ldu_io.ubuffer.sqIdx
      := s1_in.uop.sqIdx\n620:   io.ldu_io.ubuffer.mask  := s1_in.mask\n621:   io.ldu_io.ubuffer.pc\
      \    := s1_in.uop.pc // FIXME: remove it\n622: \n623:   io.ldu_io.vec_forward.valid
      := s1_valid && !(s1_exception || s1_tlb_miss || s1_kill || s1_fast_rep_kill
      || s1_prf || !s1_ld_flow)\n624:   io.ldu_io.vec_forward.vaddr := s1_vaddr\n\
      625:   io.ldu_io.vec_forward.paddr := s1_paddr_dup_lsu\n626:   io.ldu_io.vec_forward.uop\
      \   := s1_in.uop\n627:   io.ldu_io.vec_forward.sqIdx := s1_in.uop.sqIdx\n628:\
      \   io.ldu_io.vec_forward.mask  := s1_in.mask"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 626-648
    context: "626:   io.ldu_io.vec_forward.uop   := s1_in.uop\n627:   io.ldu_io.vec_forward.sqIdx
      := s1_in.uop.sqIdx\n628:   io.ldu_io.vec_forward.mask  := s1_in.mask\n629: \
      \  io.ldu_io.vec_forward.pc    := s1_in.uop.pc // FIXME: remove it\n630: \n\
      631:   io.ldu_io.lsq.forward.valid     := s1_valid && !(s1_exception || s1_tlb_miss
      || s1_kill || s1_fast_rep_kill || s1_prf || !s1_ld_flow)\n632:   io.ldu_io.lsq.forward.vaddr\
      \     := s1_vaddr\n633:   io.ldu_io.lsq.forward.paddr     := s1_paddr_dup_lsu\n\
      634:   io.ldu_io.lsq.forward.uop       := s1_in.uop\n635:   io.ldu_io.lsq.forward.sqIdx\
      \     := s1_in.uop.sqIdx\n636:   io.ldu_io.lsq.forward.sqIdxMask := 0.U\n637:\
      \   io.ldu_io.lsq.forward.mask      := s1_in.mask\n638:   io.ldu_io.lsq.forward.pc\
      \        := s1_in.uop.pc // FIXME: remove it\n639: \n640:   // st-ld violation
      query\n641:   val s1_nuke = VecInit((0 until StorePipelineWidth).map(w => {\n\
      642:                        io.ldu_io.stld_nuke_query(w).valid && // query valid\n\
      643:                        isAfter(s1_in.uop.robIdx, io.ldu_io.stld_nuke_query(w).bits.robIdx)
      && // older store\n644:                        // TODO: Fix me when vector instruction\n\
      645:                        (s1_paddr_dup_lsu(PAddrBits-1, 3) === io.ldu_io.stld_nuke_query(w).bits.paddr(PAddrBits-1,
      3)) && // paddr match\n646:                        (s1_in.mask & io.ldu_io.stld_nuke_query(w).bits.mask).orR
      // data mask contain\n647:                       })).asUInt.orR && !s1_tlb_miss
      && s1_ld_flow\n648: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 709-720
    context: "709:   val s1_ptr_chasing_canceled  = WireInit(false.B)\n710:   val
      s1_cancel_ptr_chasing    = WireInit(false.B)\n711: \n712:   s1_kill := s1_late_kill
      ||\n713:              s1_cancel_ptr_chasing ||\n714:              s1_in.uop.robIdx.needFlush(io.redirect)
      ||\n715:              RegEnable(s0_kill, false.B, io.lsin.valid || io.ldu_io.replay.valid
      || io.ldu_io.l2l_fwd_in.valid || io.ldu_io.fast_rep_in.valid || io.vec_stu_io.in.valid)\n\
      716: \n717:   if (EnableLoadToLoadForward) {\n718:     // Sometimes, we need
      to cancel the load-load forwarding.\n719:     // These can be put at S0 if timing
      is bad at S1.\n720:     // Case 0: CACHE_SET(base + offset) != CACHE_SET(base)
      (lowest 6-bit addition has an overflow)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 741-753
    context: "741:       // recored tlb time when get the data to ensure the correctness
      of the latency calculation (although it should not record in here, because it
      does not use tlb)\n742:       s1_in.uop.debugInfo.tlbFirstReqTime := GTimer()\n\
      743:       s1_in.uop.debugInfo.tlbRespTime     := GTimer()\n744:     }\n745:\
      \     when (!s1_cancel_ptr_chasing) {\n746:       s0_ptr_chasing_canceled :=
      s1_try_ptr_chasing && !io.ldu_io.replay.fire && !io.ldu_io.fast_rep_in.fire
      && !(s0_src_valid_vec(high_pf_idx) && io.canAcceptHighConfPrefetch)\n747:  \
      \     when (s1_try_ptr_chasing) {\n748:         io.lsin.ready := true.B\n749:\
      \       }\n750:     }\n751:   }\n752: \n753:   // pre-calcuate sqIdx mask in
      s0, then send it to lsq in s1 for forwarding"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 753-770
    context: "753:   // pre-calcuate sqIdx mask in s0, then send it to lsq in s1 for
      forwarding\n754:   val s1_sqIdx_mask = RegNext(UIntToMask(s0_out.uop.sqIdx.value,
      StoreQueueSize))\n755:   // to enable load-load, sqIdxMask must be calculated
      based on lsin.uop\n756:   // If the timing here is not OK, load-load forwarding
      has to be disabled.\n757:   // Or we calculate sqIdxMask at RS??\n758:   io.ldu_io.lsq.forward.sqIdxMask
      := s1_sqIdx_mask\n759:   if (EnableLoadToLoadForward) {\n760:     when (s1_try_ptr_chasing)
      {\n761:       io.ldu_io.lsq.forward.sqIdxMask := UIntToMask(io.lsin.bits.uop.sqIdx.value,
      StoreQueueSize)\n762:     }\n763:   }\n764: \n765:   io.ldu_io.forward_mshr.valid\
      \  := s1_valid && s1_out.forward_tlDchannel && s1_ld_flow\n766:   io.ldu_io.forward_mshr.mshrid
      := s1_out.mshrid\n767:   io.ldu_io.forward_mshr.paddr  := s1_out.paddr\n768:\
      \ \n769:   io.ldu_io.wakeup.valid := s0_fire && s0_ld_flow && (s0_src_select_vec(super_rep_idx)
      || s0_src_select_vec(fast_rep_idx) || s0_src_select_vec(lsq_rep_idx) || s0_src_select_vec(int_iss_idx))\n\
      770:   io.ldu_io.wakeup.bits := s0_uop"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 767-809
    context: "767:   io.ldu_io.forward_mshr.paddr  := s1_out.paddr\n768: \n769:  \
      \ io.ldu_io.wakeup.valid := s0_fire && s0_ld_flow && (s0_src_select_vec(super_rep_idx)
      || s0_src_select_vec(fast_rep_idx) || s0_src_select_vec(lsq_rep_idx) || s0_src_select_vec(int_iss_idx))\n\
      770:   io.ldu_io.wakeup.bits := s0_uop\n771: \n772:   io.stu_io.dcache.s1_kill
      := s1_tlb_miss || s1_exception || s1_mmio || s1_in.uop.robIdx.needFlush(io.redirect)\n\
      773:   io.stu_io.dcache.s1_paddr := s1_paddr_dup_dcache\n774: \n775: \n776:\
      \   // load debug\n777:   XSDebug(s1_valid && s1_ld_flow,\n778:     p\"S1: pc
      ${Hexadecimal(s1_out.uop.pc)}, lId ${Hexadecimal(s1_out.uop.lqIdx.asUInt)},
      tlb_miss ${io.tlb.resp.bits.miss}, \" +\n779:     p\"paddr ${Hexadecimal(s1_out.paddr)},
      mmio ${s1_out.mmio}\\n\")\n780: \n781:   // store debug\n782:   XSDebug(s1_valid
      && !s1_ld_flow,\n783:     p\"S1: pc ${Hexadecimal(s1_out.uop.pc)}, lId ${Hexadecimal(s1_out.uop.sqIdx.asUInt)},
      tlb_miss ${io.tlb.resp.bits.miss}, \" +\n784:     p\"paddr ${Hexadecimal(s1_out.paddr)},
      mmio ${s1_out.mmio}\\n\")\n785: \n786:   // store out\n787:   io.stu_io.lsq.valid\
      \         := s1_valid && !s1_ld_flow && !s1_prf && !s1_isvec\n788:   io.stu_io.lsq.bits\
      \          := s1_out\n789:   io.stu_io.lsq.bits.miss     := s1_tlb_miss\n790:\
      \ \n791:   io.vec_stu_io.lsq.valid     := s1_valid && !s1_ld_flow && !s1_prf
      && s1_isvec\n792:   io.vec_stu_io.lsq.bits          := s1_out\n793:   io.vec_stu_io.lsq.bits.miss\
      \     := s1_tlb_miss\n794:   io.vec_stu_io.lsq.bits.isLastElem := s1_isLastElem\n\
      795: \n796:   io.stu_io.st_mask_out.valid       := s1_valid && !s1_ld_flow &&
      !s1_prf\n797:   io.stu_io.st_mask_out.bits.mask   := s1_out.mask\n798:   io.stu_io.st_mask_out.bits.sqIdx\
      \  := s1_out.uop.sqIdx\n799: \n800:   io.stu_io.issue.valid       := s1_valid
      && !s1_tlb_miss && !s1_ld_flow && !s1_prf && !s1_isvec\n801:   io.stu_io.issue.bits\
      \        := RegEnable(io.lsin.bits, io.lsin.fire)\n802: \n803:   // st-ld violation
      dectect request\n804:   io.stu_io.stld_nuke_query.valid       := s1_valid &&
      !s1_tlb_miss && !s1_ld_flow && !s1_prf\n805:   io.stu_io.stld_nuke_query.bits.robIdx
      := s1_in.uop.robIdx\n806:   io.stu_io.stld_nuke_query.bits.paddr  := s1_paddr_dup_lsu\n\
      807:   io.stu_io.stld_nuke_query.bits.mask   := s1_in.mask\n808: \n809:   //
      Pipeline"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 809-833
    context: "809:   // Pipeline\n810:   // --------------------------------------------------------------------------------\n\
      811:   // stage 2\n812:   // --------------------------------------------------------------------------------\n\
      813:   // s2: DCache resp\n814:   val s2_valid  = RegInit(false.B)\n815:   val
      s2_in     = Wire(new LqWriteBundle)\n816:   val s2_out    = Wire(new LqWriteBundle)\n\
      817:   val s2_kill   = Wire(Bool())\n818:   val s2_can_go = s3_ready\n819: \
      \  val s2_fire   = s2_valid && !s2_kill && s2_can_go\n820:   val s2_isvec  =
      RegEnable(s1_isvec, false.B, s1_fire)\n821:   val s2_vecActive    = RegEnable(s1_out.vecActive,
      true.B, s1_fire)\n822:   val s2_paddr  = RegEnable(s1_paddr_dup_lsu, s1_fire)\n\
      823: \n824:   s2_kill := s2_in.uop.robIdx.needFlush(io.redirect)\n825:   s2_ready
      := !s2_valid || s2_kill || s3_ready\n826:   when (s1_fire) { s2_valid := true.B
      }\n827:   .elsewhen (s2_fire) { s2_valid := false.B }\n828:   .elsewhen (s2_kill)
      { s2_valid := false.B }\n829:   s2_in := RegEnable(s1_out, s1_fire)\n830: \n\
      831:   val s2_pmp = WireInit(io.pmp)\n832: \n833:   val s2_prf    = s2_in.isPrefetch"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 858-875
    context: "858:   }\n859:   val s2_ld_exception = ExceptionNO.selectByFu(s2_exception_vec,
      LduCfg).asUInt.orR && s2_ld_flow\n860:   val s2_st_exception = ExceptionNO.selectByFu(s2_exception_vec,
      StaCfg).asUInt.orR && !s2_ld_flow\n861:   val s2_exception    = s2_ld_exception
      || s2_st_exception\n862: \n863:   val (s2_fwd_frm_d_chan, s2_fwd_data_frm_d_chan,
      s2_d_corrupt) = io.ldu_io.tl_d_channel.forward(s1_valid && s1_out.forward_tlDchannel,
      s1_out.mshrid, s1_out.paddr)\n864:   val (s2_fwd_data_valid, s2_fwd_frm_mshr,
      s2_fwd_data_frm_mshr, s2_mshr_corrupt) = io.ldu_io.forward_mshr.forward()\n\
      865:   val s2_fwd_frm_d_chan_or_mshr = s2_fwd_data_valid && (s2_fwd_frm_d_chan
      || s2_fwd_frm_mshr)\n866: \n867:   // writeback access fault caused by ecc error
      / bus error\n868:   // * ecc data error is slow to generate, so we will not
      use it until load stage 3\n869:   // * in load stage 3, an extra signal io.load_error
      will be used to\n870:   val s2_actually_mmio = s2_pmp.mmio\n871:   val s2_ld_mmio\
      \       = !s2_prf &&\n872:                           s2_actually_mmio &&\n873:\
      \                          !s2_exception &&\n874:                          !s2_in.tlbMiss
      &&\n875:                          s2_ld_flow"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 872-882
    context: "872:                           s2_actually_mmio &&\n873:           \
      \               !s2_exception &&\n874:                          !s2_in.tlbMiss
      &&\n875:                          s2_ld_flow\n876:   val s2_st_mmio       =
      !s2_prf &&\n877:                           (RegNext(s1_mmio) || s2_pmp.mmio)
      &&\n878:                          !s2_exception &&\n879:                   \
      \       !s2_in.tlbMiss &&\n880:                          !s2_ld_flow\n881: \
      \  val s2_full_fwd      = Wire(Bool())\n882:   val s2_mem_amb       = s2_in.uop.storeSetHit
      &&"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 878-891
    context: "878:                          !s2_exception &&\n879:               \
      \           !s2_in.tlbMiss &&\n880:                          !s2_ld_flow\n881:\
      \   val s2_full_fwd      = Wire(Bool())\n882:   val s2_mem_amb       = s2_in.uop.storeSetHit
      &&\n883:                          io.ldu_io.lsq.forward.addrInvalid\n884: \n\
      885:   val s2_tlb_miss      = s2_in.tlbMiss\n886:   val s2_fwd_fail      = io.ldu_io.lsq.forward.dataInvalid
      || io.ldu_io.vec_forward.dataInvalid\n887:   val s2_dcache_miss   = io.ldu_io.dcache.resp.bits.miss
      &&\n888:                          !s2_fwd_frm_d_chan_or_mshr &&\n889:      \
      \                    !s2_full_fwd\n890: \n891:   val s2_mq_nack       = io.ldu_io.dcache.s2_mq_nack
      &&"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 899-912
    context: "899:   val s2_wpu_pred_fail = io.ldu_io.dcache.s2_wpu_pred_fail &&\n\
      900:                         !s2_fwd_frm_d_chan_or_mshr &&\n901:           \
      \              !s2_full_fwd\n902: \n903:   val s2_rar_nack      = io.ldu_io.lsq.ldld_nuke_query.req.valid
      &&\n904:                          !io.ldu_io.lsq.ldld_nuke_query.req.ready\n\
      905: \n906:   val s2_raw_nack      = io.ldu_io.lsq.stld_nuke_query.req.valid
      &&\n907:                          !io.ldu_io.lsq.stld_nuke_query.req.ready\n\
      908: \n909:   // st-ld violation query\n910:   //  NeedFastRecovery Valid when\n\
      911:   //  1. Fast recovery query request Valid.\n912:   //  2. Load instruction
      is younger than requestors(store instructions)."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 912-922
    context: "912:   //  2. Load instruction is younger than requestors(store instructions).\n\
      913:   //  3. Physical address match.\n914:   //  4. Data contains.\n915:  \
      \ val s2_nuke = VecInit((0 until StorePipelineWidth).map(w => {\n916:      \
      \                   io.ldu_io.stld_nuke_query(w).valid && // query valid\n917:\
      \                         isAfter(s2_in.uop.robIdx, io.ldu_io.stld_nuke_query(w).bits.robIdx)
      && // older store\n918:                         // TODO: Fix me when vector
      instruction\n919:                         (s2_in.paddr(PAddrBits-1, 3) === io.ldu_io.stld_nuke_query(w).bits.paddr(PAddrBits-1,
      3)) && // paddr match\n920:                         (s2_in.mask & io.ldu_io.stld_nuke_query(w).bits.mask).orR
      // data mask contain\n921:                       })).asUInt.orR && s2_ld_flow
      || s2_in.rep_info.nuke\n922: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 928-941
    context: "928:                            !s2_ld_mmio &&\n929:               \
      \             !s2_prf &&\n930:                            !s2_in.lateKill &&\n\
      931:                            s2_ld_flow\n932: \n933:   io.ldu_io.dcache.resp.ready
      := true.B\n934:   io.stu_io.dcache.resp.ready := true.B\n935:   val s2_dcache_should_resp
      = !(s2_in.tlbMiss || s2_exception || s2_ld_mmio || s2_prf || s2_in.lateKill)
      && s2_ld_flow\n936:   assert(!(s2_valid && (s2_dcache_should_resp && !io.ldu_io.dcache.resp.valid)),
      \"DCache response got lost\")\n937: \n938:   // fast replay require\n939:  \
      \ val s2_dcache_fast_rep = (s2_mq_nack || !s2_dcache_miss && (s2_bank_conflict
      || s2_wpu_pred_fail))\n940:   val s2_nuke_fast_rep   = !s2_mq_nack &&\n941:\
      \                            !s2_dcache_miss &&"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 959-980
    context: "959:                      s2_troublem\n960: \n961:   val s2_data_fwded
      = s2_dcache_miss && (s2_full_fwd || s2_cache_tag_error)\n962: \n963:   // ld-ld
      violation require\n964:   io.ldu_io.lsq.ldld_nuke_query.req.valid          \
      \ := s2_valid && s2_can_query\n965:   io.ldu_io.lsq.ldld_nuke_query.req.bits.uop\
      \        := s2_in.uop\n966:   io.ldu_io.lsq.ldld_nuke_query.req.bits.mask  \
      \     := s2_in.mask\n967:   io.ldu_io.lsq.ldld_nuke_query.req.bits.paddr   \
      \   := s2_in.paddr\n968:   io.ldu_io.lsq.ldld_nuke_query.req.bits.data_valid
      := Mux(s2_full_fwd || s2_fwd_data_valid, true.B, !s2_dcache_miss)\n969: \n970:\
      \   // st-ld violation require\n971:   io.ldu_io.lsq.stld_nuke_query.req.valid\
      \           := s2_valid && s2_can_query\n972:   io.ldu_io.lsq.stld_nuke_query.req.bits.uop\
      \        := s2_in.uop\n973:   io.ldu_io.lsq.stld_nuke_query.req.bits.mask  \
      \     := s2_in.mask\n974:   io.ldu_io.lsq.stld_nuke_query.req.bits.paddr   \
      \   := s2_in.paddr\n975:   io.ldu_io.lsq.stld_nuke_query.req.bits.data_valid
      := Mux(s2_full_fwd || s2_fwd_data_valid, true.B, !s2_dcache_miss)\n976: \n977:\
      \   // merge forward result\n978:   // lsq has higher priority than sbuffer\n\
      979:   val s2_fwd_mask = Wire(Vec((VLEN/8), Bool()))\n980:   val s2_fwd_data
      = Wire(Vec((VLEN/8), UInt(8.W)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 976-991
    context: "976: \n977:   // merge forward result\n978:   // lsq has higher priority
      than sbuffer\n979:   val s2_fwd_mask = Wire(Vec((VLEN/8), Bool()))\n980:   val
      s2_fwd_data = Wire(Vec((VLEN/8), UInt(8.W)))\n981:   s2_full_fwd := ((~s2_fwd_mask.asUInt).asUInt
      & s2_in.mask) === 0.U && !io.ldu_io.lsq.forward.dataInvalid && !io.ldu_io.vec_forward.dataInvalid\n\
      982:   // generate XLEN/8 Muxs\n983:   for (i <- 0 until VLEN / 8) {\n984: \
      \    s2_fwd_mask(i) := io.ldu_io.lsq.forward.forwardMask(i) || io.ldu_io.sbuffer.forwardMask(i)
      || io.ldu_io.vec_forward.forwardMask(i) || io.ldu_io.ubuffer.forwardMask(i)\n\
      985:     s2_fwd_data(i) :=\n986:       Mux(io.ldu_io.lsq.forward.forwardMask(i),
      io.ldu_io.lsq.forward.forwardData(i),\n987:       Mux(io.ldu_io.vec_forward.forwardMask(i),
      io.ldu_io.vec_forward.forwardData(i),\n988:       Mux(io.ldu_io.ubuffer.forwardMask(i),
      io.ldu_io.ubuffer.forwardData(i),\n989:       io.ldu_io.sbuffer.forwardData(i))))\n\
      990:   }\n991: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 989-999
    context: "989:       io.ldu_io.sbuffer.forwardData(i))))\n990:   }\n991: \n992:\
      \   XSDebug(s2_fire && s2_ld_flow, \"[FWD LOAD RESP] pc %x fwd %x(%b) + %x(%b)\\\
      n\",\n993:     s2_in.uop.pc,\n994:     io.ldu_io.lsq.forward.forwardData.asUInt,
      io.ldu_io.lsq.forward.forwardMask.asUInt,\n995:     s2_in.forwardData.asUInt,
      s2_in.forwardMask.asUInt\n996:   )\n997: \n998:   //\n999:   s2_out        \
      \          := s2_in"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 997-1008
    context: "997: \n998:   //\n999:   s2_out                  := s2_in\n1000:   s2_out.data\
      \             := 0.U // data will be generated in load s3\n1001:   s2_out.uop.fpWen\
      \        := s2_in.uop.fpWen && !s2_exception && s2_ld_flow\n1002:   s2_out.mmio\
      \             := s2_ld_mmio || s2_st_mmio\n1003:   s2_out.uop.flushPipe    :=
      false.B\n1004:   s2_out.uop.exceptionVec := s2_exception_vec\n1005:   s2_out.forwardMask\
      \      := s2_fwd_mask\n1006:   s2_out.forwardData      := s2_fwd_data\n1007:\
      \   s2_out.handledByMSHR    := s2_cache_handled\n1008:   s2_out.miss       \
      \      := s2_dcache_miss && s2_troublem"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1023-1034
    context: "1023:   s2_out.rep_info.wpu_fail        := s2_wpu_pred_fail && s2_troublem\n\
      1024:   s2_out.rep_info.rar_nack        := s2_rar_nack && s2_troublem\n1025:\
      \   s2_out.rep_info.raw_nack        := s2_raw_nack && s2_troublem\n1026:   s2_out.rep_info.nuke\
      \            := s2_nuke && s2_troublem\n1027:   s2_out.rep_info.full_fwd   \
      \     := s2_data_fwded\n1028:   s2_out.rep_info.data_inv_sq_idx := Mux(io.ldu_io.vec_forward.dataInvalid,
      s2_out.uop.sqIdx, io.ldu_io.lsq.forward.dataInvalidSqIdx)\n1029:   s2_out.rep_info.addr_inv_sq_idx
      := Mux(io.ldu_io.vec_forward.addrInvalid, s2_out.uop.sqIdx, io.ldu_io.lsq.forward.addrInvalidSqIdx)\n\
      1030:   s2_out.rep_info.rep_carry       := io.ldu_io.dcache.resp.bits.replayCarry\n\
      1031:   s2_out.rep_info.mshr_id         := io.ldu_io.dcache.resp.bits.mshr_id\n\
      1032:   s2_out.rep_info.last_beat       := s2_in.paddr(log2Up(refillBytes))\n\
      1033:   s2_out.rep_info.debug           := s2_in.uop.debugInfo\n1034:   s2_out.rep_info.tlb_id\
      \          := io.ldu_io.tlb_hint.id"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1039-1058
    context: "1039:   // if ld-ld violation is detected, replay from this inst from
      fetch\n1040:   val debug_ldld_nuke_rep = false.B // s2_ldld_violation && !s2_ld_mmio
      && !s2_is_prefetch && !s2_in.tlbMiss\n1041:   // io.out.bits.uop.replayInst
      := false.B\n1042: \n1043:   // to be removed\n1044:   val s2_ld_need_fb = !s2_in.isLoadReplay
      &&      // already feedbacked\n1045:                       io.ldu_io.lq_rep_full
      &&           // LoadQueueReplay is full\n1046:                       s2_out.rep_info.need_rep
      && // need replay\n1047:                       !s2_exception &&            //
      no exception is triggered\n1048:                       !s2_hw_prf &&       \
      \        // not hardware prefetch\n1049:                       !s2_isvec\n1050:\
      \   val s2_st_need_fb = !s2_ld_flow && !s2_hw_prf && !s2_isvec\n1051:   io.feedback_fast.valid\
      \                 := s2_valid && (s2_ld_need_fb || s2_st_need_fb)\n1052:   io.feedback_fast.bits.hit\
      \              := Mux(s2_ld_flow, false.B, !s2_tlb_miss)\n1053:   io.feedback_fast.bits.flushState\
      \       := s2_in.ptwBack\n1054:   io.feedback_fast.bits.robIdx           :=
      s2_in.uop.robIdx\n1055:   io.feedback_fast.bits.sourceType       := Mux(s2_ld_flow,
      RSFeedbackType.lrqFull, RSFeedbackType.tlbMiss)\n1056:   io.feedback_fast.bits.dataInvalidSqIdx
      := DontCare\n1057: \n1058:   val s2_vec_feedback = Wire(Valid(new VSFQFeedback))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1054-1073
    context: "1054:   io.feedback_fast.bits.robIdx           := s2_in.uop.robIdx\n\
      1055:   io.feedback_fast.bits.sourceType       := Mux(s2_ld_flow, RSFeedbackType.lrqFull,
      RSFeedbackType.tlbMiss)\n1056:   io.feedback_fast.bits.dataInvalidSqIdx := DontCare\n\
      1057: \n1058:   val s2_vec_feedback = Wire(Valid(new VSFQFeedback))\n1059: \
      \  s2_vec_feedback.valid := s2_valid && !s2_ld_flow && !s2_hw_prf && s2_isvec\n\
      1060:   // s2_vec_feedback.bits.flowPtr := s2_out.sflowPtr\n1061:   s2_vec_feedback.bits.hit
      := !s2_tlb_miss\n1062:   s2_vec_feedback.bits.sourceType := RSFeedbackType.tlbMiss\n\
      1063:   s2_vec_feedback.bits.paddr := s2_paddr\n1064:   s2_vec_feedback.bits.mmio
      := s2_st_mmio\n1065:   s2_vec_feedback.bits.exceptionVec := s2_exception_vec\n\
      1066: \n1067:   io.stu_io.lsq_replenish := s2_out\n1068:   io.stu_io.lsq_replenish.miss
      := io.ldu_io.dcache.resp.fire && io.ldu_io.dcache.resp.bits.miss\n1069: \n1070:\
      \   io.ldu_io.ldCancel.ld1Cancel := false.B\n1071: \n1072:   // fast wakeup\n\
      1073:   io.ldu_io.fast_uop.valid := RegNext("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1070-1084
    context: "1070:   io.ldu_io.ldCancel.ld1Cancel := false.B\n1071: \n1072:   //
      fast wakeup\n1073:   io.ldu_io.fast_uop.valid := RegNext(\n1074:     !io.ldu_io.dcache.s1_disable_fast_wakeup
      &&\n1075:     s1_valid &&\n1076:     !s1_kill &&\n1077:     !io.tlb.resp.bits.miss
      &&\n1078:     !io.ldu_io.lsq.forward.dataInvalidFast\n1079:   ) && (s2_valid
      && !s2_out.rep_info.need_rep && !s2_ld_mmio && s2_ld_flow) && !s2_isvec\n1080:\
      \   io.ldu_io.fast_uop.bits := RegNext(s1_out.uop)\n1081: \n1082:   //\n1083:\
      \   io.ldu_io.s2_ptr_chasing                    := RegEnable(s1_try_ptr_chasing
      && !s1_cancel_ptr_chasing, false.B, s1_fire)\n1084: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1083-1093
    context: "1083:   io.ldu_io.s2_ptr_chasing                    := RegEnable(s1_try_ptr_chasing
      && !s1_cancel_ptr_chasing, false.B, s1_fire)\n1084: \n1085:   // prefetch train\n\
      1086:   io.s0_prefetch_spec := s0_fire\n1087:   io.s1_prefetch_spec := s1_fire\n\
      1088:   io.prefetch_train.valid              := s2_valid && !s2_actually_mmio
      && !s2_in.tlbMiss\n1089:   io.prefetch_train.bits.fromLsPipelineBundle(s2_in)\n\
      1090:   io.prefetch_train.bits.miss          := Mux(s2_ld_flow, io.ldu_io.dcache.resp.bits.miss,
      io.stu_io.dcache.resp.bits.miss) // TODO: use trace with bank conflict?\n1091:\
      \   io.prefetch_train.bits.meta_prefetch := Mux(s2_ld_flow, io.ldu_io.dcache.resp.bits.meta_prefetch,
      false.B)\n1092:   io.prefetch_train.bits.meta_access   := Mux(s2_ld_flow, io.ldu_io.dcache.resp.bits.meta_access,
      false.B)\n1093: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1089-1099
    context: "1089:   io.prefetch_train.bits.fromLsPipelineBundle(s2_in)\n1090:  \
      \ io.prefetch_train.bits.miss          := Mux(s2_ld_flow, io.ldu_io.dcache.resp.bits.miss,
      io.stu_io.dcache.resp.bits.miss) // TODO: use trace with bank conflict?\n1091:\
      \   io.prefetch_train.bits.meta_prefetch := Mux(s2_ld_flow, io.ldu_io.dcache.resp.bits.meta_prefetch,
      false.B)\n1092:   io.prefetch_train.bits.meta_access   := Mux(s2_ld_flow, io.ldu_io.dcache.resp.bits.meta_access,
      false.B)\n1093: \n1094:   io.prefetch_train_l1.valid              := s2_valid
      && !s2_actually_mmio && s2_ld_flow\n1095:   io.prefetch_train_l1.bits.fromLsPipelineBundle(s2_in)\n\
      1096:   io.prefetch_train_l1.bits.miss          := io.ldu_io.dcache.resp.bits.miss\n\
      1097:   io.prefetch_train_l1.bits.meta_prefetch := io.ldu_io.dcache.resp.bits.meta_prefetch\n\
      1098:   io.prefetch_train_l1.bits.meta_access   := io.ldu_io.dcache.resp.bits.meta_access\n\
      1099:   if (env.FPGAPlatform){"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1107-1122
    context: "1107:   }\n1108:   io.ldu_io.dcache.s2_kill := s2_pmp.ld  || s2_actually_mmio
      || s2_kill\n1109:   io.stu_io.dcache.s2_kill := s2_pmp.st || s2_actually_mmio
      || s2_kill\n1110:   io.stu_io.dcache.s2_pc := s2_out.uop.pc\n1111: \n1112: \
      \  val s1_ld_left_fire = s1_valid && !s1_kill && s2_ready && s1_ld_flow\n1113:\
      \   val s2_ld_valid_dup = RegInit(0.U(6.W))\n1114:   s2_ld_valid_dup := 0x0.U(6.W)\n\
      1115:   when (s1_ld_left_fire && !s1_out.isHWPrefetch && s1_ld_flow) { s2_ld_valid_dup
      := 0x3f.U(6.W) }\n1116:   when (s1_kill || s1_out.isHWPrefetch || !s1_ld_flow)
      { s2_ld_valid_dup := 0x0.U(6.W) }\n1117:   assert(RegNext((s2_valid === s2_ld_valid_dup(0))
      || RegNext(s1_out.isHWPrefetch) || RegNext(!s1_ld_flow)))\n1118: \n1119:   //
      Pipeline\n1120:   // --------------------------------------------------------------------------------\n\
      1121:   // stage 3\n1122:   // --------------------------------------------------------------------------------"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1119-1129
    context: "1119:   // Pipeline\n1120:   // --------------------------------------------------------------------------------\n\
      1121:   // stage 3\n1122:   // --------------------------------------------------------------------------------\n\
      1123:   // writeback and update load queue\n1124:   val s3_valid        = RegNext(s2_valid
      && !s2_out.isHWPrefetch && !s2_out.uop.robIdx.needFlush(io.redirect))\n1125:\
      \   val s3_in           = RegEnable(s2_out, s2_fire)\n1126:   val s3_out   \
      \       = Wire(Valid(new MemExuOutput))\n1127:   val s3_dcache_rep   = RegEnable(s2_dcache_fast_rep
      && s2_troublem, false.B, s2_fire)\n1128:   val s3_ld_valid_dup = RegEnable(s2_ld_valid_dup,
      s2_fire)\n1129:   val s3_fast_rep     = Wire(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1127-1150
    context: "1127:   val s3_dcache_rep   = RegEnable(s2_dcache_fast_rep && s2_troublem,
      false.B, s2_fire)\n1128:   val s3_ld_valid_dup = RegEnable(s2_ld_valid_dup,
      s2_fire)\n1129:   val s3_fast_rep     = Wire(Bool())\n1130:   val s3_ld_flow\
      \      = RegNext(s2_ld_flow)\n1131:   val s3_troublem     = RegNext(s2_troublem)\n\
      1132:   val s3_kill         = s3_in.uop.robIdx.needFlush(io.redirect)\n1133:\
      \   val s3_isvec        = RegNext(s2_isvec)\n1134:   s3_ready := !s3_valid ||
      s3_kill || sx_can_go\n1135: \n1136:   // s3 load fast replay\n1137:   io.ldu_io.fast_rep_out.valid
      := s3_valid &&\n1138:                                   s3_fast_rep &&\n1139:\
      \                                   !s3_in.uop.robIdx.needFlush(io.redirect)
      &&\n1140:                                   s3_ld_flow &&\n1141:           \
      \                        !s3_isvec\n1142:   io.ldu_io.fast_rep_out.bits := s3_in\n\
      1143: \n1144:   io.ldu_io.lsq.ldin.valid := s3_valid &&\n1145:             \
      \                  (!s3_fast_rep || !io.ldu_io.fast_rep_out.ready) &&\n1146:\
      \                               !s3_in.feedbacked &&\n1147:                \
      \               !s3_in.lateKill &&\n1148:                               s3_ld_flow\n\
      1149:   io.ldu_io.lsq.ldin.bits := s3_in\n1150:   io.ldu_io.lsq.ldin.bits.miss
      := s3_in.miss"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1158-1172
    context: "1158:     if (EnableAccurateLoadError) {\n1159:       (s3_in.lateKill
      || io.ldu_io.dcache.resp.bits.error_delayed) && RegNext(io.csrCtrl.cache_error_enable)\n\
      1160:     } else {\n1161:       WireInit(false.B)\n1162:     }\n1163:   io.ldu_io.s3_dly_ld_err
      := false.B // s3_dly_ld_err && s3_valid\n1164:   io.ldu_io.fast_rep_out.bits.delayedLoadError
      := s3_dly_ld_err\n1165:   io.ldu_io.lsq.ldin.bits.dcacheRequireReplay  := s3_dcache_rep\n\
      1166: \n1167:   val s3_vp_match_fail = RegNext(io.ldu_io.lsq.forward.matchInvalid
      || io.ldu_io.sbuffer.matchInvalid || io.ldu_io.ubuffer.matchInvalid) && s3_troublem\n\
      1168:   val s3_ldld_rep_inst =\n1169:       io.ldu_io.lsq.ldld_nuke_query.resp.valid
      &&\n1170:       io.ldu_io.lsq.ldld_nuke_query.resp.bits.rep_frm_fetch &&\n1171:\
      \       RegNext(io.csrCtrl.ldld_vio_check_enable)\n1172: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1171-1181
    context: "1171:       RegNext(io.csrCtrl.ldld_vio_check_enable)\n1172: \n1173:\
      \   val s3_rep_info = WireInit(s3_in.rep_info)\n1174:   s3_rep_info.dcache_miss\
      \   := s3_in.rep_info.dcache_miss && s3_troublem\n1175:   val s3_rep_frm_fetch
      = s3_vp_match_fail\n1176:   val s3_flushPipe = s3_ldld_rep_inst\n1177:   val
      s3_sel_rep_cause = PriorityEncoderOH(s3_rep_info.cause.asUInt)\n1178:   val
      s3_force_rep     = s3_sel_rep_cause(LoadReplayCauses.C_TM) &&\n1179:       \
      \                   !s3_in.uop.exceptionVec(loadAddrMisaligned) &&\n1180:  \
      \                        s3_troublem\n1181: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1187-1203
    context: "1187:   } .otherwise {\n1188:     io.ldu_io.lsq.ldin.bits.rep_info.cause
      := VecInit(s3_sel_rep_cause.asBools)\n1189:   }\n1190: \n1191:   // Int flow,
      if hit, will be writebacked at s3\n1192:   s3_out.valid                := s3_valid
      &&\n1193:                                 (!s3_ld_flow && !s3_in.feedbacked
      || !io.ldu_io.lsq.ldin.bits.rep_info.need_rep) && !s3_in.mmio\n1194:   s3_out.bits.uop\
      \             := s3_in.uop\n1195:   s3_out.bits.uop.exceptionVec(loadAccessFault)
      := (s3_dly_ld_err  || s3_in.uop.exceptionVec(loadAccessFault)) && s3_ld_flow\n\
      1196:   s3_out.bits.uop.replayInst := s3_rep_frm_fetch\n1197:   s3_out.bits.data\
      \            := s3_in.data\n1198:   s3_out.bits.debug.isMMIO    := s3_in.mmio\n\
      1199:   s3_out.bits.debug.isNCIO    := s3_in.nc && !s3_in.memBackTypeMM\n1200:\
      \   s3_out.bits.debug.isPerfCnt := false.B\n1201:   s3_out.bits.debug.paddr\
      \     := s3_in.paddr\n1202:   s3_out.bits.debug.vaddr     := s3_in.vaddr\n1203: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1203-1213
    context: "1203: \n1204:   when (s3_force_rep) {\n1205:     s3_out.bits.uop.exceptionVec
      := 0.U.asTypeOf(s3_in.uop.exceptionVec.cloneType)\n1206:   }\n1207: \n1208:\
      \   io.ldu_io.rollback.valid := s3_valid && (s3_rep_frm_fetch || s3_flushPipe)
      && !s3_exception && s3_ld_flow\n1209:   io.ldu_io.rollback.bits            \
      \ := DontCare\n1210:   io.ldu_io.rollback.bits.isRVC       := s3_out.bits.uop.preDecodeInfo.isRVC\n\
      1211:   io.ldu_io.rollback.bits.robIdx      := s3_out.bits.uop.robIdx\n1212:\
      \   io.ldu_io.rollback.bits.ftqIdx      := s3_out.bits.uop.ftqPtr\n1213:   io.ldu_io.rollback.bits.ftqOffset\
      \   := s3_out.bits.uop.ftqOffset"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1209-1219
    context: "1209:   io.ldu_io.rollback.bits             := DontCare\n1210:   io.ldu_io.rollback.bits.isRVC\
      \       := s3_out.bits.uop.preDecodeInfo.isRVC\n1211:   io.ldu_io.rollback.bits.robIdx\
      \      := s3_out.bits.uop.robIdx\n1212:   io.ldu_io.rollback.bits.ftqIdx   \
      \   := s3_out.bits.uop.ftqPtr\n1213:   io.ldu_io.rollback.bits.ftqOffset   :=
      s3_out.bits.uop.ftqOffset\n1214:   io.ldu_io.rollback.bits.level       := Mux(s3_rep_frm_fetch,
      RedirectLevel.flush, RedirectLevel.flushAfter)\n1215:   io.ldu_io.rollback.bits.cfiUpdate.target
      := s3_out.bits.uop.pc\n1216:   io.ldu_io.rollback.bits.debug_runahead_checkpoint_id
      := s3_out.bits.uop.debugInfo.runahead_checkpoint_id\n1217:   /* <------- DANGEROUS:
      Don't change sequence here ! -------> */\n1218:   io.ldu_io.lsq.ldin.bits.uop
      := s3_out.bits.uop\n1219: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1226-1250
    context: "1226:                  !s3_in.feedbacked &&\n1227:                 \
      \ !s3_in.lateKill &&\n1228:                  !s3_rep_frm_fetch &&\n1229:   \
      \               !s3_exception\n1230: \n1231:   val s3_fb_no_waiting = !s3_in.isLoadReplay
      && !(s3_fast_rep && io.ldu_io.fast_rep_out.ready) && !s3_in.feedbacked\n1232:\
      \ \n1233:   //\n1234:   io.feedback_slow.valid                 := s3_valid &&
      !s3_in.uop.robIdx.needFlush(io.redirect) && s3_fb_no_waiting && s3_ld_flow\n\
      1235:   io.feedback_slow.bits.hit              := !io.ldu_io.lsq.ldin.bits.rep_info.need_rep
      || io.ldu_io.lsq.ldin.ready\n1236:   io.feedback_slow.bits.flushState      \
      \ := s3_in.ptwBack\n1237:   io.feedback_slow.bits.robIdx           := s3_in.uop.robIdx\n\
      1238:   io.feedback_slow.bits.sourceType       := RSFeedbackType.lrqFull\n1239:\
      \   io.feedback_slow.bits.dataInvalidSqIdx := DontCare\n1240: \n1241:   io.vec_stu_io.feedbackSlow.valid
      := RegNext(s2_vec_feedback.valid && !s2_out.uop.robIdx.needFlush(io.redirect))\n\
      1242:   io.vec_stu_io.feedbackSlow.bits := RegNext(s2_vec_feedback.bits)\n1243:\
      \ \n1244:   io.ldu_io.ldCancel.ld2Cancel := s3_valid && s3_ld_flow && (    \
      \                      // is load\n1245:     io.ldu_io.lsq.ldin.bits.rep_info.need_rep
      || s3_in.mmio                            // exe fail or is mmio\n1246:   )\n\
      1247: \n1248:   // data from dcache hit\n1249:   val s3_ld_raw_data_frm_cache
      = Wire(new LoadDataFromDcacheBundle)\n1250:   s3_ld_raw_data_frm_cache.respDcacheData\
      \       := io.ldu_io.dcache.resp.bits.data"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1250-1267
    context: "1250:   s3_ld_raw_data_frm_cache.respDcacheData       := io.ldu_io.dcache.resp.bits.data\n\
      1251:   s3_ld_raw_data_frm_cache.forward_D            := s2_fwd_frm_d_chan\n\
      1252:   s3_ld_raw_data_frm_cache.forwardData_D        := s2_fwd_data_frm_d_chan\n\
      1253:   s3_ld_raw_data_frm_cache.forward_mshr         := s2_fwd_frm_mshr\n1254:\
      \   s3_ld_raw_data_frm_cache.forwardData_mshr     := s2_fwd_data_frm_mshr\n\
      1255:   s3_ld_raw_data_frm_cache.forward_result_valid := s2_fwd_data_valid\n\
      1256: \n1257:   s3_ld_raw_data_frm_cache.forwardMask          := RegEnable(s2_fwd_mask,
      s2_valid)\n1258:   s3_ld_raw_data_frm_cache.forwardData          := RegEnable(s2_fwd_data,
      s2_valid)\n1259:   s3_ld_raw_data_frm_cache.uop                  := RegEnable(s2_out.uop,
      s2_valid)\n1260:   s3_ld_raw_data_frm_cache.addrOffset           := RegEnable(s2_out.paddr(3,
      0), s2_valid)\n1261: \n1262:   val s3_merged_data_frm_tlD   = RegEnable(s3_ld_raw_data_frm_cache.mergeTLData(),
      s2_valid)\n1263:   val s3_merged_data_frm_cache = s3_ld_raw_data_frm_cache.mergeLsqFwdData(s3_merged_data_frm_tlD)\n\
      1264:   val s3_picked_data_frm_cache = LookupTree(s3_ld_raw_data_frm_cache.addrOffset,
      List(\n1265:     \"b0000\".U -> s3_merged_data_frm_cache(63,    0),\n1266: \
      \    \"b0001\".U -> s3_merged_data_frm_cache(63,    8),\n1267:     \"b0010\"\
      .U -> s3_merged_data_frm_cache(63,   16),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1282-1295
    context: "1282:   val s3_ld_data_frm_cache = rdataHelper(s3_ld_raw_data_frm_cache.uop,
      s3_picked_data_frm_cache)\n1283: \n1284:   // FIXME: add 1 cycle delay ?\n1285:\
      \   io.ldout.bits      := s3_out.bits\n1286:   io.ldout.bits.data := s3_ld_data_frm_cache\n\
      1287:   io.ldout.valid     := s3_out.valid && !s3_out.bits.uop.robIdx.needFlush(io.redirect)
      && s3_ld_flow && !s3_isvec\n1288: \n1289:   // for uncache\n1290:   io.ldu_io.lsq.uncache.ready
      := true.B\n1291: \n1292:   // fast load to load forward\n1293:   if (EnableLoadToLoadForward)
      {\n1294:     io.ldu_io.l2l_fwd_out.valid      := s3_out.valid && !s3_in.lateKill
      && s3_ld_flow\n1295:     io.ldu_io.l2l_fwd_out.data       := s3_ld_data_frm_cache"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1307-1335
    context: "1307:   val TotalSelectCycles = scala.math.ceil(log2Ceil(LoadQueueRAWSize).toFloat
      / lgSelectGroupSize).toInt + 1\n1308:   val TotalDelayCycles  = TotalSelectCycles
      - 2\n1309: \n1310:   // writeback\n1311:   val sx_valid = Wire(Vec(TotalDelayCycles
      + 1, Bool()))\n1312:   val sx_ready = Wire(Vec(TotalDelayCycles + 1, Bool()))\n\
      1313:   val sx_in    = Wire(Vec(TotalDelayCycles + 1, new MemExuOutput))\n1314:\
      \ \n1315:   sx_can_go := sx_ready.head\n1316:   for (i <- 0 until TotalDelayCycles
      + 1) {\n1317:     if (i == 0) {\n1318:       sx_valid(i) := s3_valid &&\n1319:\
      \                     !s3_ld_flow &&\n1320:                     !s3_in.feedbacked
      &&\n1321:                     !s3_in.mmio\n1322:       sx_in(i)    := s3_out.bits\n\
      1323:       sx_ready(i) := !s3_valid(i) || sx_in(i).uop.robIdx.needFlush(io.redirect)
      || (if (TotalDelayCycles == 0) io.stout.ready else sx_ready(i+1))\n1324:   \
      \  } else {\n1325:       val cur_kill   = sx_in(i).uop.robIdx.needFlush(io.redirect)\n\
      1326:       val cur_can_go = (if (i == TotalDelayCycles) io.stout.ready else
      sx_ready(i+1))\n1327:       val cur_fire   = sx_valid(i) && !cur_kill && cur_can_go\n\
      1328:       val prev_fire  = sx_valid(i-1) && !sx_in(i-1).uop.robIdx.needFlush(io.redirect)
      && sx_ready(i)\n1329: \n1330:       sx_ready(i) := !sx_valid(i) || cur_kill
      || (if (i == TotalDelayCycles) io.stout.ready else sx_ready(i+1))\n1331:   \
      \    val sx_valid_can_go = prev_fire || cur_fire || cur_kill\n1332:       sx_valid(i)
      := RegEnable(Mux(prev_fire, true.B, false.B), sx_valid_can_go)\n1333:      \
      \ sx_in(i) := RegEnable(sx_in(i-1), prev_fire)\n1334:     }\n1335:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1332-1347
    context: "1332:       sx_valid(i) := RegEnable(Mux(prev_fire, true.B, false.B),
      sx_valid_can_go)\n1333:       sx_in(i) := RegEnable(sx_in(i-1), prev_fire)\n\
      1334:     }\n1335:   }\n1336: \n1337:   val sx_last_valid = sx_valid.takeRight(1).head\n\
      1338:   val sx_last_ready = sx_ready.takeRight(1).head\n1339:   val sx_last_in\
      \    = sx_in.takeRight(1).head\n1340: \n1341:   sx_last_ready  := !sx_last_valid
      || sx_last_in.uop.robIdx.needFlush(io.redirect) || io.stout.ready\n1342:   io.stout.valid
      := sx_last_valid && !sx_last_in.uop.robIdx.needFlush(io.redirect) && FuType.isStore(sx_last_in.uop.fuType)\n\
      1343:   io.stout.bits  := sx_last_in\n1344: \n1345:   // FIXME: please move
      this part to LoadQueueReplay\n1346:   io.ldu_io.debug_ls := DontCare\n1347:\
      \   io.stu_io.debug_ls := DontCare"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1348-1358
    context: "1348:   io.stu_io.debug_ls.s1_isTlbFirstMiss := io.tlb.resp.valid &&
      io.tlb.resp.bits.miss && io.tlb.resp.bits.debug.isFirstIssue && !s1_in.isHWPrefetch
      && !s1_ld_flow\n1349:   io.stu_io.debug_ls.s1_robIdx := s1_in.uop.robIdx.value\n\
      1350: \n1351:  // Topdown\n1352:   io.ldu_io.lsTopdownInfo.s1.robIdx       \
      \   := s1_in.uop.robIdx.value\n1353:   io.ldu_io.lsTopdownInfo.s1.vaddr_valid\
      \     := s1_valid && s1_in.hasROBEntry\n1354:   io.ldu_io.lsTopdownInfo.s1.vaddr_bits\
      \      := s1_vaddr\n1355:   io.ldu_io.lsTopdownInfo.s2.robIdx          := s2_in.uop.robIdx.value\n\
      1356:   io.ldu_io.lsTopdownInfo.s2.paddr_valid     := s2_fire && s2_in.hasROBEntry
      && !s2_in.tlbMiss\n1357:   io.ldu_io.lsTopdownInfo.s2.paddr_bits      := s2_in.paddr\n\
      1358:   io.ldu_io.lsTopdownInfo.s2.first_real_miss := io.ldu_io.dcache.resp.bits.real_miss"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1358-1375
    context: "1358:   io.ldu_io.lsTopdownInfo.s2.first_real_miss := io.ldu_io.dcache.resp.bits.real_miss\n\
      1359:   io.ldu_io.lsTopdownInfo.s2.cache_miss_en   := s2_fire && s2_in.hasROBEntry
      && !s2_in.tlbMiss && !s2_in.missDbUpdated\n1360: \n1361:   // perf cnt\n1362:\
      \   XSPerfAccumulate(\"s0_in_valid\",                  io.lsin.valid)\n1363:\
      \   XSPerfAccumulate(\"s0_in_block\",                  io.lsin.valid && !io.lsin.fire)\n\
      1364:   XSPerfAccumulate(\"s0_in_fire_first_issue\",       s0_valid && s0_isFirstIssue)\n\
      1365:   XSPerfAccumulate(\"s0_lsq_fire_first_issue\",      io.ldu_io.replay.fire)\n\
      1366:   XSPerfAccumulate(\"s0_ldu_fire_first_issue\",      io.lsin.fire && s0_isFirstIssue)\n\
      1367:   XSPerfAccumulate(\"s0_fast_replay_issue\",         io.ldu_io.fast_rep_in.fire)\n\
      1368:   XSPerfAccumulate(\"s0_stall_out\",                 s0_valid && !s0_can_go)\n\
      1369:   XSPerfAccumulate(\"s0_stall_ld_dcache\",           s0_valid && !io.ldu_io.dcache.req.ready)\n\
      1370:   XSPerfAccumulate(\"s0_stall_st_dcache\",           s0_valid && !io.stu_io.dcache.req.ready)\n\
      1371:   XSPerfAccumulate(\"s0_addr_spec_success\",         s0_fire && s0_vaddr(VAddrBits-1,
      12) === io.lsin.bits.src(0)(VAddrBits-1, 12))\n1372:   XSPerfAccumulate(\"s0_addr_spec_failed\"\
      ,          s0_fire && s0_vaddr(VAddrBits-1, 12) =/= io.lsin.bits.src(0)(VAddrBits-1,
      12))\n1373:   XSPerfAccumulate(\"s0_addr_spec_success_once\",    s0_fire &&
      s0_vaddr(VAddrBits-1, 12) === io.lsin.bits.src(0)(VAddrBits-1, 12) && s0_isFirstIssue)\n\
      1374:   XSPerfAccumulate(\"s0_addr_spec_failed_once\",     s0_fire && s0_vaddr(VAddrBits-1,
      12) =/= io.lsin.bits.src(0)(VAddrBits-1, 12) && s0_isFirstIssue)\n1375:   XSPerfAccumulate(\"\
      s0_forward_tl_d_channel\",      s0_out.forward_tlDchannel)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1376-1394
    context: "1376:   XSPerfAccumulate(\"s0_hardware_prefetch_fire\",    s0_fire &&
      s0_hw_prf_select)\n1377:   XSPerfAccumulate(\"s0_software_prefetch_fire\", \
      \   s0_fire && s0_prf && s0_src_select_vec(int_iss_idx))\n1378:   XSPerfAccumulate(\"\
      s0_hardware_prefetch_blocked\", io.ldu_io.prefetch_req.valid && !s0_hw_prf_select)\n\
      1379:   XSPerfAccumulate(\"s0_hardware_prefetch_total\",   io.ldu_io.prefetch_req.valid)\n\
      1380: \n1381:   XSPerfAccumulate(\"s1_in_valid\",                  s1_valid)\n\
      1382:   XSPerfAccumulate(\"s1_in_fire\",                   s1_fire)\n1383: \
      \  XSPerfAccumulate(\"s1_in_fire_first_issue\",       s1_fire && s1_in.isFirstIssue)\n\
      1384:   XSPerfAccumulate(\"s1_tlb_miss\",                  s1_fire && s1_tlb_miss)\n\
      1385:   XSPerfAccumulate(\"s1_tlb_miss_first_issue\",      s1_fire && s1_tlb_miss
      && s1_in.isFirstIssue)\n1386:   XSPerfAccumulate(\"s1_stall_out\",         \
      \        s1_valid && !s1_can_go)\n1387:   XSPerfAccumulate(\"s1_late_kill\"\
      ,                 s1_valid && s1_fast_rep_kill)\n1388: \n1389:   XSPerfAccumulate(\"\
      s2_in_valid\",                  s2_valid)\n1390:   XSPerfAccumulate(\"s2_in_fire\"\
      ,                   s2_fire)\n1391:   XSPerfAccumulate(\"s2_in_fire_first_issue\"\
      ,       s2_fire && s2_in.isFirstIssue)\n1392:   XSPerfAccumulate(\"s2_dcache_miss\"\
      ,               s2_fire && io.ldu_io.dcache.resp.bits.miss)\n1393:   XSPerfAccumulate(\"\
      s2_dcache_miss_first_issue\",   s2_fire && io.ldu_io.dcache.resp.bits.miss &&
      s2_in.isFirstIssue)\n1394:   XSPerfAccumulate(\"s2_dcache_real_miss_first_issue\"\
      ,   s2_fire && io.ldu_io.dcache.resp.bits.miss && s2_in.isFirstIssue)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1392-1403
    context: "1392:   XSPerfAccumulate(\"s2_dcache_miss\",               s2_fire &&
      io.ldu_io.dcache.resp.bits.miss)\n1393:   XSPerfAccumulate(\"s2_dcache_miss_first_issue\"\
      ,   s2_fire && io.ldu_io.dcache.resp.bits.miss && s2_in.isFirstIssue)\n1394:\
      \   XSPerfAccumulate(\"s2_dcache_real_miss_first_issue\",   s2_fire && io.ldu_io.dcache.resp.bits.miss
      && s2_in.isFirstIssue)\n1395:   XSPerfAccumulate(\"s2_full_forward\",      \
      \        s2_fire && s2_full_fwd)\n1396:   XSPerfAccumulate(\"s2_dcache_miss_full_forward\"\
      ,  s2_fire && s2_dcache_miss)\n1397:   XSPerfAccumulate(\"s2_fwd_frm_d_can\"\
      ,             s2_valid && s2_fwd_frm_d_chan)\n1398:   XSPerfAccumulate(\"s2_fwd_frm_d_chan_or_mshr\"\
      ,    s2_valid && s2_fwd_frm_d_chan_or_mshr)\n1399:   XSPerfAccumulate(\"s2_stall_out\"\
      ,                 s2_fire && !s2_can_go)\n1400:   XSPerfAccumulate(\"s2_prefetch\"\
      ,                  s2_fire && s2_prf)\n1401:   XSPerfAccumulate(\"s2_prefetch_ignored\"\
      ,          s2_fire && s2_prf && io.ldu_io.dcache.s2_mq_nack) // ignore prefetch
      for mshr full / miss req port conflict\n1402:   XSPerfAccumulate(\"s2_prefetch_miss\"\
      ,             s2_fire && s2_prf && io.ldu_io.dcache.resp.bits.miss) // prefetch
      req miss in l1\n1403:   XSPerfAccumulate(\"s2_prefetch_hit\",              s2_fire
      && s2_prf && !io.ldu_io.dcache.resp.bits.miss) // prefetch req hit in l1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1401-1412
    context: "1401:   XSPerfAccumulate(\"s2_prefetch_ignored\",          s2_fire &&
      s2_prf && io.ldu_io.dcache.s2_mq_nack) // ignore prefetch for mshr full / miss
      req port conflict\n1402:   XSPerfAccumulate(\"s2_prefetch_miss\",          \
      \   s2_fire && s2_prf && io.ldu_io.dcache.resp.bits.miss) // prefetch req miss
      in l1\n1403:   XSPerfAccumulate(\"s2_prefetch_hit\",              s2_fire &&
      s2_prf && !io.ldu_io.dcache.resp.bits.miss) // prefetch req hit in l1\n1404:\
      \   XSPerfAccumulate(\"s2_prefetch_accept\",           s2_fire && s2_prf &&
      io.ldu_io.dcache.resp.bits.miss && !io.ldu_io.dcache.s2_mq_nack) // prefetch
      a missed line in l1, and l1 accepted it\n1405:   XSPerfAccumulate(\"s2_forward_req\"\
      ,               s2_fire && s2_in.forward_tlDchannel)\n1406:   XSPerfAccumulate(\"\
      s2_successfully_forward_channel_D\", s2_fire && s2_fwd_frm_d_chan && s2_fwd_data_valid)\n\
      1407:   XSPerfAccumulate(\"s2_successfully_forward_mshr\",      s2_fire && s2_fwd_frm_mshr
      && s2_fwd_data_valid)\n1408: \n1409:   XSPerfAccumulate(\"load_to_load_forward\"\
      ,                      s1_try_ptr_chasing && !s1_ptr_chasing_canceled)\n1410:\
      \   XSPerfAccumulate(\"load_to_load_forward_try\",                  s1_try_ptr_chasing)\n\
      1411:   XSPerfAccumulate(\"load_to_load_forward_fail\",                 s1_cancel_ptr_chasing)\n\
      1412:   XSPerfAccumulate(\"load_to_load_forward_fail_cancelled\",       s1_cancel_ptr_chasing
      && s1_ptr_chasing_canceled)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1418-1428
    context: "1418:   // bug lyq: some signals in perfEvents are no longer suitable
      for the current MemBlock design\n1419:   // hardware performance counter\n1420:\
      \   val perfEvents = Seq(\n1421:     (\"load_s0_in_fire         \", s0_fire\
      \                                                        ),\n1422:     (\"load_to_load_forward\
      \    \", s1_fire && s1_try_ptr_chasing && !s1_ptr_chasing_canceled      ),\n\
      1423:     (\"stall_dcache            \", s0_valid && s0_can_go && !io.ldu_io.dcache.req.ready\
      \           ),\n1424:     (\"load_s1_in_fire         \", s0_fire           \
      \                                             ),\n1425:     (\"load_s1_tlb_miss\
      \        \", s1_fire && io.tlb.resp.bits.miss                              \
      \ ),\n1426:     (\"load_s2_in_fire         \", s1_fire                     \
      \                                   ),\n1427:     (\"load_s2_dcache_miss   \
      \  \", s2_fire && io.ldu_io.dcache.resp.bits.miss                     ),\n1428:\
      \   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 27-37
    context: "27: import xiangshan.backend.fu.FuType\n28: import xiangshan.backend.Bundles.{MemExuInput,
      MemExuOutput}\n29: import xiangshan.backend.fu.NewCSR.TriggerUtil\n30: import
      xiangshan.backend.fu.util.SdtrigExt\n31: import xiangshan.mem.Bundles._\n32:
      import xiangshan.cache.mmu.Pbmt\n33: import xiangshan.cache.{AtomicWordIO, HasDCacheParameters,
      MemoryOpConstants}\n34: import xiangshan.cache.mmu.{TlbCmd, TlbRequestIO}\n\
      35: import difftest._\n36: \n37: class AtomicsUnit(implicit p: Parameters) extends
      XSModule"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 49-59
    context: "49:     val dcache        = new AtomicWordIO\n50:     val dtlb     \
      \     = new TlbRequestIO(2)\n51:     val pmpResp       = Flipped(new PMPRespBundle())\n\
      52:     val flush_sbuffer = new SbufferFlushBundle\n53:     val feedbackSlow\
      \  = ValidIO(new RSFeedback)\n54:     val redirect      = Flipped(ValidIO(new
      Redirect))\n55:     val exceptionInfo = ValidIO(new Bundle {\n56:       val
      vaddr = UInt(XLEN.W)\n57:       val gpaddr = UInt(XLEN.W)\n58:       val isForVSnonLeafPTE
      = Bool()\n59:     })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 64-76
    context: "64: \n65:   //-------------------------------------------------------\n\
      66:   // Atomics Memory Accsess FSM\n67:   //-------------------------------------------------------\n\
      68:   val s_invalid :: s_tlb_and_flush_sbuffer_req :: s_pm :: s_wait_flush_sbuffer_resp
      :: s_cache_req :: s_cache_resp :: s_cache_resp_latch :: s_finish :: s_finish2
      :: Nil = Enum(9)\n69:   val state = RegInit(s_invalid)\n70:   val out_valid
      = RegInit(false.B)\n71:   val data_valid = RegInit(false.B)\n72: \n73:   val
      uop = Reg(io.in.bits.uop.cloneType)\n74:   val isLr = LSUOpType.isLr(uop.fuOpType)\n\
      75:   val isSc = LSUOpType.isSc(uop.fuOpType)\n76:   val isAMOCAS = LSUOpType.isAMOCAS(uop.fuOpType)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 91-101
    context: "91:     * (1) For AMOs(except AMOCAS.Q) and LR/SC, 1 sta uop is wanted:
      X(rs1) with uopIdx = 0\n92:     * (2) For AMOCAS.Q, 2 sta uop is wanted: X(rs1)*2
      with uopIdx = 0, 2\n93:     */\n94:   val rs1, rs2_l, rs2_h, rd_l, rd_h = Reg(UInt(XLEN.W))\n\
      95:   val stds = Seq(rd_l, rs2_l, rd_h, rs2_h)\n96:   val rs2 = Cat(rs2_h, Mux(isAMOCAS,
      rs2_l, stds.head))\n97:   val rd = Cat(rd_h, rd_l)\n98:   val stdCnt = RegInit(0.U(log2Ceil(stds.length
      + 1).W))\n99: \n100:   val exceptionVec = RegInit(0.U.asTypeOf(ExceptionVec()))\n\
      101:   val trigger = RegInit(TriggerAction.None)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 104-114
    context: "104:   // paddr after translation\n105:   val paddr = Reg(UInt())\n\
      106:   val gpaddr = Reg(UInt())\n107:   val vaddr = rs1\n108: \n109:   val is_mmio
      = Reg(Bool())\n110:   val isForVSnonLeafPTE = Reg(Bool())\n111: \n112:   //
      dcache response data\n113:   val resp_data = Reg(UInt())\n114:   val resp_data_wire
      = WireInit(0.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 120-130
    context: "120:   // therefore the MSBs are reused to identify uopIdx\n121:   val
      stdUopIdxs = io.storeDataIn.map(_.bits.uop.fuOpType >> LSUOpType.AMOFuOpWidth)\n\
      122:   val staUopIdx = io.in.bits.uop.fuOpType >> LSUOpType.AMOFuOpWidth\n123:\
      \ \n124:   // assign default value to output signals\n125:   io.in.ready   \
      \       := false.B\n126: \n127:   io.dcache.req.valid  := false.B\n128:   io.dcache.req.bits\
      \   := DontCare\n129: \n130:   io.dtlb.req.valid    := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 128-151
    context: "128:   io.dcache.req.bits   := DontCare\n129: \n130:   io.dtlb.req.valid\
      \    := false.B\n131:   io.dtlb.req.bits     := DontCare\n132:   io.dtlb.req_kill\
      \     := false.B\n133:   io.dtlb.resp.ready   := true.B\n134: \n135:   io.flush_sbuffer.valid
      := false.B\n136: \n137:   when (state === s_invalid) {\n138:     when (io.in.fire)
      {\n139:       uop := io.in.bits.uop\n140:       rs1 := io.in.bits.src_rs1\n\
      141:       state := s_tlb_and_flush_sbuffer_req\n142:       have_sent_first_tlb_req
      := false.B\n143:     }\n144:   }\n145: \n146:   when (io.in.fire) {\n147:  \
      \   val pdest = io.in.bits.uop.pdest\n148:     when (staUopIdx === 0.U) {\n\
      149:       pdest1Valid := true.B\n150:       pdest1 := pdest\n151:     }.elsewhen
      (staUopIdx === 2.U) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 154-166
    context: "154:     }.otherwise {\n155:       assert(false.B, \"unrecognized sta
      uopIdx\")\n156:     }\n157:   }\n158: \n159:   stds.zipWithIndex.foreach { case
      (data, i) =>\n160:     val sels = io.storeDataIn.zip(stdUopIdxs).map { case
      (in, uopIdx) =>\n161:       val sel = in.fire && uopIdx === i.U\n162:      \
      \ when (sel) { data := in.bits.data }\n163:       sel\n164:     }\n165:    \
      \ OneHot.checkOneHot(sels)\n166:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 162-178
    context: "162:       when (sel) { data := in.bits.data }\n163:       sel\n164:\
      \     }\n165:     OneHot.checkOneHot(sels)\n166:   }\n167:   stdCnt := stdCnt
      + PopCount(io.storeDataIn.map(_.fire))\n168: \n169:   val StdCntNCAS = 1 //
      LR/SC and AMO need only 1 src besides rs1\n170:   val StdCntCASWD = 2 // AMOCAS.W/D
      needs 2 src regs (rs2 and rd) besides rs1\n171:   val StdCntCASQ = 4 // AMOCAS.Q
      needs 4 src regs (rs2, rs2+1, rd, rd+1) besides rs1\n172:   when (!data_valid)
      {\n173:     data_valid := state =/= s_invalid && (\n174:       LSUOpType.isAMOCASQ(uop.fuOpType)
      && stdCnt === StdCntCASQ.U ||\n175:       LSUOpType.isAMOCASWD(uop.fuOpType)
      && stdCnt === StdCntCASWD.U ||\n176:       !isAMOCAS && stdCnt === StdCntNCAS.U\n\
      177:     )\n178:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 175-185
    context: "175:       LSUOpType.isAMOCASWD(uop.fuOpType) && stdCnt === StdCntCASWD.U
      ||\n176:       !isAMOCAS && stdCnt === StdCntNCAS.U\n177:     )\n178:   }\n\
      179:   assert(stdCnt <= stds.length.U, \"unexpected std\")\n180:   assert(!(Cat(io.storeDataIn.map(_.fire)).orR
      && data_valid), \"atomic unit re-receive data\")\n181: \n182:   // atomic trigger\n\
      183:   val csrCtrl = io.csrCtrl\n184:   val tdata = Reg(Vec(TriggerNum, new
      MatchTriggerIO))\n185:   val tEnableVec = RegInit(VecInit(Seq.fill(TriggerNum)(false.B)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 193-203
    context: "193:   val backendTriggerTimingVec = VecInit(tdata.map(_.timing))\n\
      194:   val backendTriggerChainVec = VecInit(tdata.map(_.chain))\n195:   val
      backendTriggerHitVec = WireInit(VecInit(Seq.fill(TriggerNum)(false.B)))\n196:\
      \   val backendTriggerCanFireVec = RegInit(VecInit(Seq.fill(TriggerNum)(false.B)))\n\
      197: \n198:   assert(state === s_invalid ||\n199:     uop.fuOpType(1,0) ===
      \"b10\".U ||\n200:     uop.fuOpType(1,0) === \"b11\".U ||\n201:     LSUOpType.isAMOCASQ(uop.fuOpType),\n\
      202:     \"Only word or doubleword or quadword is supported\"\n203:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 233-243
    context: "233:   val triggerDebugMode = TriggerAction.isDmode(triggerAction)\n\
      234:   val triggerBreakpoint = TriggerAction.isExp(triggerAction)\n235: \n236:\
      \   // tlb translation, manipulating signals && deal with exception\n237:  \
      \ // at the same time, flush sbuffer\n238:   when (state === s_tlb_and_flush_sbuffer_req)
      {\n239:     // do not accept tlb resp in the first cycle\n240:     // this limition
      is for hw prefetcher\n241:     // when !have_sent_first_tlb_req, tlb resp may
      come from hw prefetch\n242:     have_sent_first_tlb_req := true.B\n243: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 239-249
    context: "239:     // do not accept tlb resp in the first cycle\n240:     // this
      limition is for hw prefetcher\n241:     // when !have_sent_first_tlb_req, tlb
      resp may come from hw prefetch\n242:     have_sent_first_tlb_req := true.B\n\
      243: \n244:     when (io.dtlb.resp.fire && have_sent_first_tlb_req) {\n245:\
      \       paddr   := io.dtlb.resp.bits.paddr(0)\n246:       gpaddr  := io.dtlb.resp.bits.gpaddr(0)\n\
      247:       vaddr   := io.dtlb.resp.bits.fullva\n248:       isForVSnonLeafPTE
      := io.dtlb.resp.bits.isForVSnonLeafPTE\n249:       // exception handling"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 268-282
    context: "268:         io.out.bits.uop.debugInfo.tlbRespTime := GTimer()\n269:\
      \         when (!addrAligned || triggerDebugMode || triggerBreakpoint) {\n270:\
      \           // NOTE: when addrAligned or trigger fire, do not need to wait tlb
      actually\n271:           // check for miss aligned exceptions, tlb exception
      are checked next cycle for timing\n272:           // if there are exceptions,
      no need to execute it\n273:           state := s_finish\n274:           out_valid
      := true.B\n275:           atom_override_xtval := true.B\n276:         }.otherwise
      {\n277:           state := s_pm\n278:         }\n279:       }\n280:     }\n\
      281:   }\n282: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 278-291
    context: "278:         }\n279:       }\n280:     }\n281:   }\n282: \n283:   val
      pbmtReg = RegEnable(io.dtlb.resp.bits.pbmt(0), io.dtlb.resp.fire && !io.dtlb.resp.bits.miss)\n\
      284:   when (state === s_pm) {\n285:     val pmp = WireInit(io.pmpResp)\n286:\
      \     is_mmio := Pbmt.isIO(pbmtReg) || (Pbmt.isPMA(pbmtReg) && pmp.mmio)\n287:\
      \ \n288:     // NOTE: only handle load/store exception here, if other exception
      happens, don't send here\n289:     val exception_va = exceptionVec(storePageFault)
      || exceptionVec(loadPageFault) ||\n290:       exceptionVec(storeGuestPageFault)
      || exceptionVec(loadGuestPageFault) ||\n291:       exceptionVec(storeAccessFault)
      || exceptionVec(loadAccessFault)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 287-305
    context: "287: \n288:     // NOTE: only handle load/store exception here, if other
      exception happens, don't send here\n289:     val exception_va = exceptionVec(storePageFault)
      || exceptionVec(loadPageFault) ||\n290:       exceptionVec(storeGuestPageFault)
      || exceptionVec(loadGuestPageFault) ||\n291:       exceptionVec(storeAccessFault)
      || exceptionVec(loadAccessFault)\n292:     val exception_pa_mmio_nc = pmp.mmio
      || Pbmt.isIO(pbmtReg) || Pbmt.isNC(pbmtReg)\n293:     val exception_pa = pmp.st
      || pmp.ld || exception_pa_mmio_nc\n294:     when (exception_va || exception_pa)
      {\n295:       state := s_finish\n296:       out_valid := true.B\n297:      \
      \ atom_override_xtval := true.B\n298:     }.otherwise {\n299:       // if sbuffer
      has been flushed, go to query dcache, otherwise wait for sbuffer.\n300:    \
      \   state := Mux(sbuffer_empty, s_cache_req, s_wait_flush_sbuffer_resp);\n301:\
      \     }\n302:     // update storeAccessFault bit\n303:     exceptionVec(loadAccessFault)
      := exceptionVec(loadAccessFault) ||\n304:       (pmp.ld || exception_pa_mmio_nc)
      && isLr\n305:     exceptionVec(storeAccessFault) := exceptionVec(storeAccessFault)
      || pmp.st ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 304-316
    context: "304:       (pmp.ld || exception_pa_mmio_nc) && isLr\n305:     exceptionVec(storeAccessFault)
      := exceptionVec(storeAccessFault) || pmp.st ||\n306:       (pmp.ld || exception_pa_mmio_nc)
      && !isLr\n307:   }\n308: \n309:   when (state === s_wait_flush_sbuffer_resp)
      {\n310:     when (sbuffer_empty) {\n311:       state := s_cache_req\n312:  \
      \   }\n313:   }\n314: \n315:   def genWdataAMO(data: UInt, sizeEncode: UInt):
      UInt = {\n316:     LookupTree(sizeEncode(1, 0), List("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 332-344
    context: "332:       \"b11\".U -> 0xff.U, // D\n333:       \"b00\".U -> 0xffff.U
      // Q\n334:     ))\n335:   }\n336: \n337:   when (state === s_cache_req) {\n\
      338:     when (io.dcache.req.fire) {\n339:       state := s_cache_resp\n340:\
      \     }\n341:   }\n342: \n343:   val dcache_resp_data  = Reg(UInt())\n344: \
      \  val dcache_resp_id    = Reg(UInt())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 342-352
    context: "342: \n343:   val dcache_resp_data  = Reg(UInt())\n344:   val dcache_resp_id\
      \    = Reg(UInt())\n345:   val dcache_resp_error = Reg(Bool())\n346: \n347:\
      \   when (state === s_cache_resp) {\n348:     // when not miss\n349:     //
      everything is OK, simply send response back to sbuffer\n350:     // when miss
      and not replay\n351:     // wait for missQueue to handling miss and replaying
      our request\n352:     // when miss and replay"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 352-365
    context: "352:     // when miss and replay\n353:     // req missed and fail to
      enter missQueue, manually replay it later\n354:     // TODO: add assertions:\n\
      355:     // 1. add a replay delay counter?\n356:     // 2. when req gets into
      MissQueue, it should not miss any more\n357:     when (io.dcache.resp.fire)
      {\n358:       when (io.dcache.resp.bits.miss) {\n359:         when (io.dcache.resp.bits.replay)
      {\n360:           state := s_cache_req\n361:         }\n362:       }.otherwise
      {\n363:         dcache_resp_data := io.dcache.resp.bits.data\n364:         dcache_resp_id
      := io.dcache.resp.bits.id\n365:         dcache_resp_error := io.dcache.resp.bits.error"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 361-376
    context: "361:         }\n362:       }.otherwise {\n363:         dcache_resp_data
      := io.dcache.resp.bits.data\n364:         dcache_resp_id := io.dcache.resp.bits.id\n\
      365:         dcache_resp_error := io.dcache.resp.bits.error\n366:         state
      := s_cache_resp_latch\n367:       }\n368:     }\n369:   }\n370: \n371:   when
      (state === s_cache_resp_latch) {\n372:     success := dcache_resp_id\n373: \
      \    val rdataSel = Mux(\n374:       paddr(2, 0) === 0.U,\n375:       dcache_resp_data,\n\
      376:       dcache_resp_data >> 32"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 393-411
    context: "393:       assert(!exceptionVec(loadAccessFault))\n394:       assert(!exceptionVec(storeAccessFault))\n\
      395:     }\n396: \n397:     resp_data := resp_data_wire\n398:     state := s_finish\n\
      399:     out_valid := true.B\n400:   }\n401: \n402:   when (state === s_finish)
      {\n403:     when (io.out.fire) {\n404:       when (LSUOpType.isAMOCASQ(uop.fuOpType))
      {\n405:         // enter `s_finish2` to write the 2nd uop back\n406:       \
      \  state := s_finish2\n407:         out_valid := true.B\n408:       }.otherwise
      {\n409:         // otherwise the FSM ends here\n410:         resetFSM()\n411:\
      \       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 410-433
    context: "410:         resetFSM()\n411:       }\n412:     }\n413:   }\n414: \n\
      415:   when (state === s_finish2) {\n416:     when (io.out.fire) {\n417:   \
      \    resetFSM()\n418:     }\n419:   }\n420: \n421:   when (io.redirect.valid)
      {\n422:     atom_override_xtval := false.B\n423:   }\n424: \n425:   def resetFSM():
      Unit = {\n426:     state := s_invalid\n427:     out_valid := false.B\n428: \
      \    data_valid := false.B\n429:     stdCnt := 0.U\n430:     pdest1Valid :=
      false.B\n431:     pdest2Valid := false.B\n432:   }\n433: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 446-456
    context: "446:   io.feedbackSlow.valid       := GatedValidRegNext(GatedValidRegNext(io.in.valid))\n\
      447:   io.feedbackSlow.bits.hit    := true.B\n448:   io.feedbackSlow.bits.robIdx\
      \  := RegEnable(io.in.bits.uop.robIdx, io.in.valid)\n449:   io.feedbackSlow.bits.sqIdx\
      \   := RegEnable(io.in.bits.uop.sqIdx, io.in.valid)\n450:   io.feedbackSlow.bits.lqIdx\
      \   := RegEnable(io.in.bits.uop.lqIdx, io.in.valid)\n451:   io.feedbackSlow.bits.flushState
      := DontCare\n452:   io.feedbackSlow.bits.sourceType := DontCare\n453:   io.feedbackSlow.bits.dataInvalidSqIdx
      := DontCare\n454: \n455:   // send req to dtlb\n456:   // keep firing until
      tlb hit"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 452-466
    context: "452:   io.feedbackSlow.bits.sourceType := DontCare\n453:   io.feedbackSlow.bits.dataInvalidSqIdx
      := DontCare\n454: \n455:   // send req to dtlb\n456:   // keep firing until
      tlb hit\n457:   io.dtlb.req.valid       := state === s_tlb_and_flush_sbuffer_req\n\
      458:   io.dtlb.req.bits.vaddr  := vaddr\n459:   io.dtlb.req.bits.fullva := vaddr\n\
      460:   io.dtlb.req.bits.checkfullva := true.B\n461:   io.dtlb.resp.ready   \
      \   := true.B\n462:   io.dtlb.req.bits.cmd    := Mux(isLr, TlbCmd.atom_read,
      TlbCmd.atom_write)\n463:   io.dtlb.req.bits.debug.pc := uop.pc\n464:   io.dtlb.req.bits.debug.robIdx
      := uop.robIdx\n465:   io.dtlb.req.bits.debug.isFirstIssue := false.B\n466: \
      \  io.out.bits.uop.debugInfo.tlbFirstReqTime := GTimer() // FIXME lyq: it will
      be always assigned"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 465-477
    context: "465:   io.dtlb.req.bits.debug.isFirstIssue := false.B\n466:   io.out.bits.uop.debugInfo.tlbFirstReqTime
      := GTimer() // FIXME lyq: it will be always assigned\n467: \n468:   // send
      req to sbuffer to flush it if it is not empty\n469:   io.flush_sbuffer.valid
      := !sbuffer_empty && (\n470:     state === s_tlb_and_flush_sbuffer_req ||\n\
      471:     state === s_pm ||\n472:     state === s_wait_flush_sbuffer_resp\n473:\
      \   )\n474: \n475:   // When is sta issue port ready:\n476:   // (1) AtomicsUnit
      is idle, or\n477:   // (2) For AMOCAS.Q, the second uop with the pdest of the
      higher bits of rd is not received yet"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 473-494
    context: "473:   )\n474: \n475:   // When is sta issue port ready:\n476:   //
      (1) AtomicsUnit is idle, or\n477:   // (2) For AMOCAS.Q, the second uop with
      the pdest of the higher bits of rd is not received yet\n478:   io.in.ready :=
      state === s_invalid || LSUOpType.isAMOCASQ(uop.fuOpType) && (!pdest2Valid ||
      !pdest1Valid)\n479: \n480:   io.out.valid := out_valid && Mux(state === s_finish2,
      pdest2Valid, pdest1Valid)\n481:   XSError((state === s_finish || state === s_finish2)
      =/= out_valid, \"out_valid reg error\\n\")\n482:   io.out.bits := DontCare\n\
      483:   io.out.bits.uop := uop\n484:   io.out.bits.uop.fuType := FuType.mou.U\n\
      485:   io.out.bits.uop.pdest := Mux(state === s_finish2, pdest2, pdest1)\n486:\
      \   io.out.bits.uop.exceptionVec := exceptionVec\n487:   io.out.bits.uop.trigger
      := trigger\n488:   io.out.bits.data := Mux(state === s_finish2, resp_data >>
      XLEN, resp_data)\n489:   io.out.bits.debug.isMMIO := is_mmio\n490:   io.out.bits.debug.paddr
      := paddr\n491: \n492:   io.dcache.req.valid := Mux(\n493:     io.dcache.req.bits.cmd
      === M_XLR,\n494:     !io.dcache.block_lr, // block lr to survive in lr storm"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 490-501
    context: "490:   io.out.bits.debug.paddr := paddr\n491: \n492:   io.dcache.req.valid
      := Mux(\n493:     io.dcache.req.bits.cmd === M_XLR,\n494:     !io.dcache.block_lr,
      // block lr to survive in lr storm\n495:     data_valid // wait until src(1)
      is ready\n496:   ) && state === s_cache_req\n497:   val pipe_req = io.dcache.req.bits\n\
      498:   pipe_req := DontCare\n499:   pipe_req.cmd := LookupTree(uop.fuOpType,
      List(\n500:     // TODO: optimize this\n501:     LSUOpType.lr_w      -> M_XLR,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 538-550
    context: "538:   pipe_req.amo_cmp  := genWdataAMO(rd, uop.fuOpType)\n539:   pipe_req.miss_fail_cause_evict_btot
      := false.B\n540: \n541:   if (env.EnableDifftest) {\n542:     val difftest =
      DifftestModule(new DiffAtomicEvent)\n543:     val en = io.dcache.req.fire\n\
      544:     difftest.coreid := io.hartId\n545:     difftest.valid  := state ===
      s_cache_resp_latch\n546:     difftest.addr   := RegEnable(paddr, en)\n547: \
      \    difftest.data   := RegEnable(io.dcache.req.bits.amo_data.asTypeOf(difftest.data),
      en)\n548:     difftest.mask   := RegEnable(io.dcache.req.bits.amo_mask, en)\n\
      549:     difftest.cmp    := RegEnable(io.dcache.req.bits.amo_cmp.asTypeOf(difftest.cmp),
      en)\n550:     difftest.fuop   := RegEnable(uop.fuOpType, en)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 553-561
    context: "553: \n554:   if (env.EnableDifftest || env.AlwaysBasicDiff) {\n555:\
      \     val uop = io.out.bits.uop\n556:     val difftest = DifftestModule(new
      DiffLrScEvent)\n557:     difftest.coreid := io.hartId\n558:     difftest.valid
      := io.out.fire && state === s_finish && isSc\n559:     difftest.success := success\n\
      560:   }\n561: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/mdp/StoreSet.scala
    lines: 140-162
    context: "140:   }\n141: \n142:   // flush SSIT\n143:   // reset period: ResetTimeMax2Pow\n\
      144:   val resetStepCounter = RegInit(0.U(log2Up(SSITSize + 1).W))\n145:   val
      s_idle :: s_flush :: Nil = Enum(2)\n146:   val state = RegInit(s_flush)\n147:\
      \ \n148:   switch (state) {\n149:     is(s_idle) {\n150:       when(resetCounter(ResetTimeMax2Pow
      - 1, ResetTimeMin2Pow)(RegNext(io.csrCtrl.lvpred_timeout))) {\n151:        \
      \ state := s_flush\n152:         resetCounter := 0.U\n153:       }\n154:   \
      \  }\n155:     is(s_flush) {\n156:       when(resetStepCounter === (SSITSize
      - 1).U) {\n157:         state := s_idle // reset finished\n158:         resetStepCounter
      := 0.U\n159:       }.otherwise{\n160:         resetStepCounter := resetStepCounter
      + 1.U\n161:       }\n162:       valid_array.io.wen(SSIT_MISC_WRITE_PORT) :=
      true.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/mdp/StoreSet.scala
    lines: 163-173
    context: "163:       valid_array.io.waddr(SSIT_MISC_WRITE_PORT) := resetStepCounter\n\
      164:       valid_array.io.wdata(SSIT_MISC_WRITE_PORT) := false.B\n165:     \
      \  debug_valid(resetStepCounter) := false.B\n166:     }\n167:   }\n168:   XSPerfAccumulate(\"\
      reset_timeout\", state === s_flush && resetCounter === 0.U)\n169: \n170:   //
      update SSIT if load violation redirect is detected\n171: \n172:   // update
      stage 0: read ssit\n173:   val s1_mempred_update_req_valid = RegNext(io.update.valid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/mdp/StoreSet.scala
    lines: 348-358
    context: "348: \n349: // Last Fetched Store Table\n350: class LFST(implicit p:
      Parameters) extends XSModule {\n351:   val io = IO(new Bundle {\n352:     //
      when redirect, mark canceled store as invalid\n353:     val redirect = Input(Valid(new
      Redirect))\n354:     val dispatch = Flipped(new DispatchLFSTIO)\n355:     //
      when store issued, mark store as invalid\n356:     val storeIssue = Vec(backendParams.StaExuCnt,
      Flipped(Valid(new DynInst)))\n357:     val csrCtrl = Input(new CustomCSRCtrlIO)\n\
      358:   })"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/mdp/StoreSet.scala
    lines: 418-428
    context: "418:   })\n419: \n420:   // when redirect, cancel store influenced\n\
      421:   (0 until LFSTSize).map(i => {\n422:     (0 until LFSTWidth).map(j =>
      {\n423:       when(validVec(i)(j) && robIdxVec(i)(j).needFlush(io.redirect)){\n\
      424:         validVec(i)(j) := false.B\n425:       }\n426:     })\n427:   })\n\
      428: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/mdp/StoreSet.scala
    lines: 426-436
    context: "426:     })\n427:   })\n428: \n429:   // recover robIdx after squash\n\
      430:   // behavior model, to be refactored later\n431:   when(RegNext(io.redirect.fire))
      {\n432:     (0 until LFSTSize).map(i => {\n433:       (0 until LFSTWidth).map(j
      => {\n434:         val check_position = WireInit(allocPtr(i) + (j+1).U)\n435:\
      \         when(!validVec(i)(check_position)){\n436:           allocPtr(i) :=
      check_position"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StridePrefetcher.scala
    lines: 111-121
    context: "111: \n112: class StrideMetaArray(implicit p: Parameters) extends XSModule
      with HasStridePrefetchHelper {\n113:   val io = IO(new XSBundle {\n114:    \
      \ val enable = Input(Bool())\n115:     // TODO: flush all entry when process
      changing happens, or disable stream prefetch for a while\n116:     val flush
      = Input(Bool())\n117:     val dynamic_depth = Input(UInt(32.W)) // TODO: enable
      dynamic stride depth\n118:     val train_req = Flipped(DecoupledIO(new PrefetchReqBundle))\n\
      119:     val l1_prefetch_req = ValidIO(new StreamPrefetchReqBundle)\n120:  \
      \   val l2_l3_prefetch_req = ValidIO(new StreamPrefetchReqBundle)\n121:    \
      \ // query Stream component to see if a stream pattern has already been detected"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StridePrefetcher.scala
    lines: 134-175
    context: "134: \n135:   val replacement = ReplacementPolicy.fromString(\"plru\"\
      , STRIDE_ENTRY_NUM)\n136: \n137:   // s0: hash pc -> cam all entries\n138: \
      \  val s0_can_accept = Wire(Bool())\n139:   val s0_valid = io.train_req.fire\n\
      140:   val s0_vaddr = io.train_req.bits.vaddr\n141:   val s0_pc = io.train_req.bits.pc\n\
      142:   val s0_pc_hash = pc_hash_tag(s0_pc)\n143:   val s0_pc_match_vec = VecInit(array
      zip valids map { case (e, v) => e.tag_match(v, s0_valid, s0_pc_hash) }).asUInt\n\
      144:   val s0_hit = s0_pc_match_vec.orR\n145:   val s0_index = Mux(s0_hit, OHToUInt(s0_pc_match_vec),
      replacement.way)\n146:   io.train_req.ready := s0_can_accept\n147:   io.stream_lookup_req.valid
      := s0_valid\n148:   io.stream_lookup_req.bits  := io.train_req.bits\n149: \n\
      150:   when(s0_valid) {\n151:     replacement.access(s0_index)\n152:   }\n153:\
      \ \n154:   assert(PopCount(s0_pc_match_vec) <= 1.U)\n155:   XSPerfAccumulate(\"\
      s0_valid\", s0_valid)\n156:   XSPerfAccumulate(\"s0_hit\", s0_valid && s0_hit)\n\
      157:   XSPerfAccumulate(\"s0_miss\", s0_valid && !s0_hit)\n158: \n159:   //
      s1: alloc or update\n160:   val s1_valid = GatedValidRegNext(s0_valid)\n161:\
      \   val s1_index = RegEnable(s0_index, s0_valid)\n162:   val s1_pc_hash = RegEnable(s0_pc_hash,
      s0_valid)\n163:   val s1_vaddr = RegEnable(s0_vaddr, s0_valid)\n164:   val s1_hit
      = RegEnable(s0_hit, s0_valid)\n165:   val s1_alloc = s1_valid && !s1_hit\n166:\
      \   val s1_update = s1_valid && s1_hit\n167:   val s1_stride = array(s1_index).stride\n\
      168:   val s1_new_stride = WireInit(0.U(STRIDE_BITS.W))\n169:   val s1_can_send_pf
      = WireInit(false.B)\n170:   s0_can_accept := !(s1_valid && s1_pc_hash === s0_pc_hash)\n\
      171: \n172:   val always_update = Constantin.createRecord(s\"always_update${p(XSCoreParamsKey).HartId}\"\
      , initValue = ALWAYS_UPDATE_PRE_VADDR)\n173: \n174:   when(s1_alloc) {\n175:\
      \     valids(s1_index) := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StridePrefetcher.scala
    lines: 186-198
    context: "186:   val l1_stride_ratio_const = Constantin.createRecord(s\"l1_stride_ratio${p(XSCoreParamsKey).HartId}\"\
      , initValue = 2)\n187:   val l1_stride_ratio = l1_stride_ratio_const(3, 0)\n\
      188:   val l2_stride_ratio_const = Constantin.createRecord(s\"l2_stride_ratio${p(XSCoreParamsKey).HartId}\"\
      , initValue = 5)\n189:   val l2_stride_ratio = l2_stride_ratio_const(3, 0)\n\
      190:   // s2: calculate L1 & L2 pf addr\n191:   val s2_valid = GatedValidRegNext(s1_valid
      && s1_can_send_pf)\n192:   val s2_vaddr = RegEnable(s1_vaddr, s1_valid && s1_can_send_pf)\n\
      193:   val s2_stride = RegEnable(s1_stride, s1_valid && s1_can_send_pf)\n194:\
      \   val s2_l1_depth = s2_stride << l1_stride_ratio\n195:   val s2_l1_pf_vaddr
      = (s2_vaddr + s2_l1_depth)(VAddrBits - 1, 0)\n196:   val s2_l2_depth = s2_stride
      << l2_stride_ratio\n197:   val s2_l2_pf_vaddr = (s2_vaddr + s2_l2_depth)(VAddrBits
      - 1, 0)\n198:   val s2_l1_pf_req_bits = (new StreamPrefetchReqBundle).getStreamPrefetchReqBundle("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StridePrefetcher.scala
    lines: 194-204
    context: "194:   val s2_l1_depth = s2_stride << l1_stride_ratio\n195:   val s2_l1_pf_vaddr
      = (s2_vaddr + s2_l1_depth)(VAddrBits - 1, 0)\n196:   val s2_l2_depth = s2_stride
      << l2_stride_ratio\n197:   val s2_l2_pf_vaddr = (s2_vaddr + s2_l2_depth)(VAddrBits
      - 1, 0)\n198:   val s2_l1_pf_req_bits = (new StreamPrefetchReqBundle).getStreamPrefetchReqBundle(\n\
      199:     valid = s2_valid,\n200:     vaddr = s2_l1_pf_vaddr,\n201:     width
      = STRIDE_WIDTH_BLOCKS,\n202:     decr_mode = false.B,\n203:     sink = SINK_L1,\n\
      204:     source = L1_HW_PREFETCH_STRIDE,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StridePrefetcher.scala
    lines: 205-215
    context: "205:     // TODO: add stride debug db, not useful for now\n206:    \
      \ t_pc = 0xdeadbeefL.U,\n207:     t_va = 0xdeadbeefL.U\n208:     )\n209:   val
      s2_l2_pf_req_bits = (new StreamPrefetchReqBundle).getStreamPrefetchReqBundle(\n\
      210:     valid = s2_valid,\n211:     vaddr = s2_l2_pf_vaddr,\n212:     width
      = STRIDE_WIDTH_BLOCKS,\n213:     decr_mode = false.B,\n214:     sink = SINK_L2,\n\
      215:     source = L1_HW_PREFETCH_STRIDE,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StridePrefetcher.scala
    lines: 217-242
    context: "217:     t_pc = 0xdeadbeefL.U,\n218:     t_va = 0xdeadbeefL.U\n219:\
      \     )\n220: \n221:   // s3: send l1 pf out\n222:   val s3_valid = if (LOOK_UP_STREAM)
      GatedValidRegNext(s2_valid) && !io.stream_lookup_resp else GatedValidRegNext(s2_valid)\n\
      223:   val s3_l1_pf_req_bits = RegEnable(s2_l1_pf_req_bits, s2_valid)\n224:\
      \   val s3_l2_pf_req_bits = RegEnable(s2_l2_pf_req_bits, s2_valid)\n225: \n\
      226:   // s4: send l2 pf out\n227:   val s4_valid = GatedValidRegNext(s3_valid)\n\
      228:   val s4_l2_pf_req_bits = RegEnable(s3_l2_pf_req_bits, s3_valid)\n229:\
      \ \n230:   io.l1_prefetch_req.valid := s3_valid\n231:   io.l1_prefetch_req.bits
      := s3_l1_pf_req_bits\n232:   io.l2_l3_prefetch_req.valid := s4_valid\n233: \
      \  io.l2_l3_prefetch_req.bits := s4_l2_pf_req_bits\n234: \n235:   XSPerfAccumulate(\"\
      pf_valid\", PopCount(Seq(io.l1_prefetch_req.valid, io.l2_l3_prefetch_req.valid)))\n\
      236:   XSPerfAccumulate(\"l1_pf_valid\", s3_valid)\n237:   XSPerfAccumulate(\"\
      l2_pf_valid\", s4_valid)\n238:   XSPerfAccumulate(\"detect_stream\", io.stream_lookup_resp)\n\
      239:   XSPerfHistogram(\"high_conf_num\", PopCount(VecInit(array.map(_.confidence
      === MAX_CONF.U))).asUInt, true.B, 0, STRIDE_ENTRY_NUM, 1)\n240:   for(i <- 0
      until STRIDE_ENTRY_NUM) {\n241:     XSPerfAccumulate(s\"entry_${i}_update\"\
      , i.U === s1_index && s1_update)\n242:     for(j <- 0 until 4) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StridePrefetcher.scala
    lines: 247-256
    context: "247:       )\n248:     }\n249:   }\n250: \n251:   for(i <- 0 until STRIDE_ENTRY_NUM)
      {\n252:     when(GatedValidRegNext(io.flush)) {\n253:       reset_array(i)\n\
      254:     }\n255:   }\n256: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 162-172
    context: "162: \n163: class StreamBitVectorArray(implicit p: Parameters) extends
      XSModule with HasStreamPrefetchHelper {\n164:   val io = IO(new XSBundle {\n\
      165:     val enable = Input(Bool())\n166:     // TODO: flush all entry when
      process changing happens, or disable stream prefetch for a while\n167:     val
      flush = Input(Bool())\n168:     val dynamic_depth = Input(UInt(DEPTH_BITS.W))\n\
      169:     val train_req = Flipped(DecoupledIO(new PrefetchReqBundle))\n170: \
      \    val l1_prefetch_req = ValidIO(new StreamPrefetchReqBundle)\n171:     val
      l2_l3_prefetch_req = ValidIO(new StreamPrefetchReqBundle)\n172: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 186-196
    context: "186: \n187:   val replacement = ReplacementPolicy.fromString(\"plru\"\
      , BIT_VEC_ARRAY_SIZE)\n188: \n189:   // s0: generate region tag, parallel match\n\
      190:   val s0_can_accept = Wire(Bool())\n191:   val s0_valid = io.train_req.fire\n\
      192:   val s0_pc    = io.train_req.bits.pc\n193:   val s0_vaddr = io.train_req.bits.vaddr\n\
      194:   val s0_miss  = io.train_req.bits.miss\n195:   val s0_pfHit = io.train_req.bits.pfHitStream\n\
      196:   val s0_region_bits = get_region_bits(s0_vaddr)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 195-207
    context: "195:   val s0_pfHit = io.train_req.bits.pfHitStream\n196:   val s0_region_bits
      = get_region_bits(s0_vaddr)\n197:   val s0_region_tag = get_region_tag(s0_vaddr)\n\
      198:   val s0_region_tag_plus_one = get_region_tag(s0_vaddr) + 1.U\n199:   val
      s0_region_tag_minus_one = get_region_tag(s0_vaddr) - 1.U\n200:   val s0_region_tag_match_vec
      = array zip valids map { case (e, v) => e.tag_match(v, s0_valid, s0_region_tag)
      }\n201:   val s0_region_tag_plus_one_match_vec = array zip valids map { case
      (e, v) => e.tag_match(v, s0_valid, s0_region_tag_plus_one) }\n202:   val s0_region_tag_minus_one_match_vec
      = array zip valids map { case (e, v) => e.tag_match(v, s0_valid, s0_region_tag_minus_one)
      }\n203:   val s0_hit = Cat(s0_region_tag_match_vec).orR\n204:   val s0_plus_one_hit
      = Cat(s0_region_tag_plus_one_match_vec).orR\n205:   val s0_minus_one_hit = Cat(s0_region_tag_minus_one_match_vec).orR\n\
      206:   val s0_hit_vec = VecInit(s0_region_tag_match_vec).asUInt\n207:   val
      s0_index = Mux(s0_hit, OHToUInt(s0_hit_vec), replacement.way)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 205-217
    context: "205:   val s0_minus_one_hit = Cat(s0_region_tag_minus_one_match_vec).orR\n\
      206:   val s0_hit_vec = VecInit(s0_region_tag_match_vec).asUInt\n207:   val
      s0_index = Mux(s0_hit, OHToUInt(s0_hit_vec), replacement.way)\n208:   val s0_plus_one_index
      = OHToUInt(VecInit(s0_region_tag_plus_one_match_vec).asUInt)\n209:   val s0_minus_one_index
      = OHToUInt(VecInit(s0_region_tag_minus_one_match_vec).asUInt)\n210:   io.train_req.ready
      := s0_can_accept\n211: \n212:   when(s0_valid) {\n213:     replacement.access(s0_index)\n\
      214:   }\n215: \n216:   val stream_pf_train_debug_table = ChiselDB.createTable(\"\
      StreamTrainTraceTable\" + p(XSCoreParamsKey).HartId.toString, new StreamTrainTraceEntry,
      basicDB = false)\n217: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 213-223
    context: "213:     replacement.access(s0_index)\n214:   }\n215: \n216:   val stream_pf_train_debug_table
      = ChiselDB.createTable(\"StreamTrainTraceTable\" + p(XSCoreParamsKey).HartId.toString,
      new StreamTrainTraceEntry, basicDB = false)\n217: \n218:   val spf_log_enable
      = s0_valid\n219:   val spf_log_data = Wire(new StreamTrainTraceEntry)\n220:\
      \ \n221:   // WARNING: the type here only indicates trigger by stream, not saying
      it's sink\n222:   spf_log_data.Type := MemReqSource.Prefetch2L2Stream.id.U\n\
      223:   spf_log_data.OldAddr := Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 236-261
    context: "236:     site = \"StreamTrainTraceTable\",\n237:     clock = clock,\n\
      238:     reset = reset\n239:   )\n240: \n241:   assert(!s0_valid || PopCount(VecInit(s0_region_tag_match_vec))
      <= 1.U, \"req region should match no more than 1 entry\")\n242:   assert(!s0_valid
      || PopCount(VecInit(s0_region_tag_plus_one_match_vec)) <= 1.U, \"req region
      plus 1 should match no more than 1 entry\")\n243:   assert(!s0_valid || PopCount(VecInit(s0_region_tag_minus_one_match_vec))
      <= 1.U, \"req region minus 1 should match no more than 1 entry\")\n244:   assert(!s0_valid
      || !(s0_hit && s0_plus_one_hit && (s0_index === s0_plus_one_index)), \"region
      and region plus 1 index match failed\")\n245:   assert(!s0_valid || !(s0_hit
      && s0_minus_one_hit && (s0_index === s0_minus_one_index)), \"region and region
      minus 1 index match failed\")\n246:   assert(!s0_valid || !(s0_plus_one_hit
      && s0_minus_one_hit && (s0_minus_one_index === s0_plus_one_index)), \"region
      plus 1 and region minus 1 index match failed\")\n247:   assert(!(s0_valid &&
      RegNext(s0_valid) && !s0_hit && !RegEnable(s0_hit, s0_valid) && replacement.way
      === RegEnable(replacement.way, s0_valid)), \"replacement error\")\n248: \n249:\
      \   XSPerfAccumulate(\"s0_valid_train_req\", s0_valid)\n250:   val s0_hit_pattern_vec
      = Seq(s0_hit, s0_plus_one_hit, s0_minus_one_hit)\n251:   for(i <- 0 until (1
      << s0_hit_pattern_vec.size)) {\n252:     XSPerfAccumulate(s\"s0_hit_pattern_${toBinary(i)}\"\
      , (VecInit(s0_hit_pattern_vec).asUInt === i.U) && s0_valid)\n253:   }\n254:\
      \   XSPerfAccumulate(\"s0_replace_the_neighbor\", s0_valid && !s0_hit && ((s0_plus_one_hit
      && (s0_index === s0_plus_one_index)) || (s0_minus_one_hit && (s0_index === s0_minus_one_index))))\n\
      255:   XSPerfAccumulate(\"s0_req_valid\", io.train_req.valid)\n256:   XSPerfAccumulate(\"\
      s0_req_cannot_accept\", io.train_req.valid && !io.train_req.ready)\n257: \n\
      258:   val ratio_const = Constantin.createRecord(s\"l2DepthRatio${p(XSCoreParamsKey).HartId}\"\
      , initValue = L2_DEPTH_RATIO)\n259:   val ratio = ratio_const(3, 0)\n260: \n\
      261:   val l3_ratio_const = Constantin.createRecord(s\"l3DepthRatio${p(XSCoreParamsKey).HartId}\"\
      , initValue = L3_DEPTH_RATIO)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 260-290
    context: "260: \n261:   val l3_ratio_const = Constantin.createRecord(s\"l3DepthRatio${p(XSCoreParamsKey).HartId}\"\
      , initValue = L3_DEPTH_RATIO)\n262:   val l3_ratio = l3_ratio_const(3, 0)\n\
      263: \n264:   // s1: alloc or update\n265:   val s1_valid = GatedValidRegNext(s0_valid)\n\
      266:   val s1_index = RegEnable(s0_index, s0_valid)\n267:   val s1_pc    = RegEnable(s0_pc,
      s0_valid)\n268:   val s1_vaddr = RegEnable(s0_vaddr, s0_valid)\n269:   val s1_miss\
      \  = RegEnable(s0_miss, s0_valid)\n270:   val s1_pfHit = RegEnable(s0_pfHit,
      s0_valid)\n271:   val s1_plus_one_index = RegEnable(s0_plus_one_index, s0_valid)\n\
      272:   val s1_minus_one_index = RegEnable(s0_minus_one_index, s0_valid)\n273:\
      \   val s1_hit = RegEnable(s0_hit, s0_valid)\n274:   val s1_plus_one_hit = if(ENABLE_STRICT_ACTIVE_DETECTION)\n\
      275:                             RegEnable(s0_plus_one_hit, s0_valid) && array(s1_plus_one_index).active
      && (array(s1_plus_one_index).cnt >= ACTIVE_THRESHOLD.U)\n276:              \
      \           else\n277:                             RegEnable(s0_plus_one_hit,
      s0_valid) && array(s1_plus_one_index).active\n278:   val s1_minus_one_hit =
      if(ENABLE_STRICT_ACTIVE_DETECTION)\n279:                             RegEnable(s0_minus_one_hit,
      s0_valid) && array(s1_minus_one_index).active && (array(s1_minus_one_index).cnt
      >= ACTIVE_THRESHOLD.U)\n280:                         else\n281:            \
      \                 RegEnable(s0_minus_one_hit, s0_valid) && array(s1_minus_one_index).active\n\
      282:   val s1_region_tag = RegEnable(s0_region_tag, s0_valid)\n283:   val s1_region_bits
      = RegEnable(s0_region_bits, s0_valid)\n284:   val s1_alloc = s1_valid && !s1_hit\n\
      285:   val s1_update = s1_valid && s1_hit\n286:   val s1_pf_l1_incr_vaddr =
      Cat(region_to_block_addr(s1_region_tag, s1_region_bits) + io.dynamic_depth,
      0.U(BLOCK_OFFSET.W))\n287:   val s1_pf_l1_decr_vaddr = Cat(region_to_block_addr(s1_region_tag,
      s1_region_bits) - io.dynamic_depth, 0.U(BLOCK_OFFSET.W))\n288:   val s1_pf_l2_incr_vaddr
      = Cat(region_to_block_addr(s1_region_tag, s1_region_bits) + (io.dynamic_depth
      << ratio), 0.U(BLOCK_OFFSET.W))\n289:   val s1_pf_l2_decr_vaddr = Cat(region_to_block_addr(s1_region_tag,
      s1_region_bits) - (io.dynamic_depth << ratio), 0.U(BLOCK_OFFSET.W))\n290:  \
      \ val s1_pf_l3_incr_vaddr = Cat(region_to_block_addr(s1_region_tag, s1_region_bits)
      + (io.dynamic_depth << l3_ratio), 0.U(BLOCK_OFFSET.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 293-303
    context: "293:   val strict_trigger_const = Constantin.createRecord(s\"StreamStrictTrigger_${p(XSCoreParamsKey).HartId}\"\
      , initValue = 1)\n294:   // If use strict triggering mode, the stream prefetcher
      will only trigger prefetching\n295:   // under **cache miss or prefetch hit
      stream**, but will still perform training on the entire memory access trace.\n\
      296:   val s1_can_trigger = Mux(strict_trigger_const.orR, s1_miss || s1_pfHit,
      true.B)\n297:   val s1_can_send_pf = Mux(s1_update, !((array(s1_index).bit_vec
      & UIntToOH(s1_region_bits)).orR), true.B) && s1_can_trigger\n298:   s0_can_accept
      := !(s1_valid && (region_hash_tag(s1_region_tag) === region_hash_tag(s0_region_tag)))\n\
      299: \n300:   when(s1_alloc) {\n301:     // alloc a new entry\n302:     valids(s1_index)
      := true.B\n303:     array(s1_index).alloc("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 302-313
    context: "302:     valids(s1_index) := true.B\n303:     array(s1_index).alloc(\n\
      304:       alloc_tag = s1_region_tag,\n305:       alloc_bit_vec = UIntToOH(s1_region_bits),\n\
      306:       alloc_active = s1_plus_one_hit || s1_minus_one_hit,\n307:       alloc_decr_mode
      = RegEnable(s0_plus_one_hit, s0_valid),\n308:       alloc_full_vaddr = RegEnable(s0_vaddr,
      s0_valid)\n309:       )\n310: \n311:   }.elsewhen(s1_update) {\n312:     //
      update a existing entry\n313:     assert(array(s1_index).cnt =/= 0.U || valids(s1_index),
      \"entry should have been allocated before\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 316-342
    context: "316:       update_active = s1_plus_one_hit || s1_minus_one_hit)\n317:\
      \   }\n318: \n319:   XSPerfAccumulate(\"s1_alloc\", s1_alloc)\n320:   XSPerfAccumulate(\"\
      s1_update\", s1_update)\n321:   XSPerfAccumulate(\"s1_active_plus_one_hit\"\
      , s1_valid && s1_plus_one_hit)\n322:   XSPerfAccumulate(\"s1_active_minus_one_hit\"\
      , s1_valid && s1_minus_one_hit)\n323: \n324:   // s2: trigger prefetch if hit
      active bit vector, compute meta of prefetch req\n325:   val s2_valid = GatedValidRegNext(s1_valid)\n\
      326:   val s2_index = RegEnable(s1_index, s1_valid)\n327:   val s2_pc    = RegEnable(s1_pc,
      s1_valid)\n328:   val s2_vaddr = RegEnable(s1_vaddr, s1_valid)\n329:   val s2_region_bits
      = RegEnable(s1_region_bits, s1_valid)\n330:   val s2_region_tag = RegEnable(s1_region_tag,
      s1_valid)\n331:   val s2_pf_l1_incr_vaddr = RegEnable(s1_pf_l1_incr_vaddr, s1_valid)\n\
      332:   val s2_pf_l1_decr_vaddr = RegEnable(s1_pf_l1_decr_vaddr, s1_valid)\n\
      333:   val s2_pf_l2_incr_vaddr = RegEnable(s1_pf_l2_incr_vaddr, s1_valid)\n\
      334:   val s2_pf_l2_decr_vaddr = RegEnable(s1_pf_l2_decr_vaddr, s1_valid)\n\
      335:   val s2_pf_l3_incr_vaddr = RegEnable(s1_pf_l3_incr_vaddr, s1_valid)\n\
      336:   val s2_pf_l3_decr_vaddr = RegEnable(s1_pf_l3_decr_vaddr, s1_valid)\n\
      337:   val s2_can_send_pf = RegEnable(s1_can_send_pf, s1_valid)\n338:   val
      s2_active = array(s2_index).active\n339:   val s2_decr_mode = array(s2_index).decr_mode\n\
      340:   val s2_l1_vaddr = Mux(s2_decr_mode, s2_pf_l1_decr_vaddr, s2_pf_l1_incr_vaddr)\n\
      341:   val s2_l2_vaddr = Mux(s2_decr_mode, s2_pf_l2_decr_vaddr, s2_pf_l2_incr_vaddr)\n\
      342:   val s2_l3_vaddr = Mux(s2_decr_mode, s2_pf_l3_decr_vaddr, s2_pf_l3_incr_vaddr)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 338-351
    context: "338:   val s2_active = array(s2_index).active\n339:   val s2_decr_mode
      = array(s2_index).decr_mode\n340:   val s2_l1_vaddr = Mux(s2_decr_mode, s2_pf_l1_decr_vaddr,
      s2_pf_l1_incr_vaddr)\n341:   val s2_l2_vaddr = Mux(s2_decr_mode, s2_pf_l2_decr_vaddr,
      s2_pf_l2_incr_vaddr)\n342:   val s2_l3_vaddr = Mux(s2_decr_mode, s2_pf_l3_decr_vaddr,
      s2_pf_l3_incr_vaddr)\n343:   val s2_will_send_pf = s2_valid && s2_active &&
      s2_can_send_pf\n344:   val s2_pf_req_valid = s2_will_send_pf && io.enable\n\
      345:   val s2_pf_l1_req_bits = (new StreamPrefetchReqBundle).getStreamPrefetchReqBundle(\n\
      346:     valid = s2_valid,\n347:     vaddr = s2_l1_vaddr,\n348:     width =
      WIDTH_CACHE_BLOCKS,\n349:     decr_mode = s2_decr_mode,\n350:     sink = SINK_L1,\n\
      351:     source = L1_HW_PREFETCH_STREAM,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 351-361
    context: "351:     source = L1_HW_PREFETCH_STREAM,\n352:     t_pc = s2_pc,\n353:\
      \     t_va = s2_vaddr\n354:     )\n355:   val s2_pf_l2_req_bits = (new StreamPrefetchReqBundle).getStreamPrefetchReqBundle(\n\
      356:     valid = s2_valid,\n357:     vaddr = s2_l2_vaddr,\n358:     width =
      L2_WIDTH_CACHE_BLOCKS,\n359:     decr_mode = s2_decr_mode,\n360:     sink =
      SINK_L2,\n361:     source = L1_HW_PREFETCH_STREAM,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 361-371
    context: "361:     source = L1_HW_PREFETCH_STREAM,\n362:     t_pc = s2_pc,\n363:\
      \     t_va = s2_vaddr\n364:     )\n365:   val s2_pf_l3_req_bits = (new StreamPrefetchReqBundle).getStreamPrefetchReqBundle(\n\
      366:     valid = s2_valid,\n367:     vaddr = s2_l3_vaddr,\n368:     width =
      L3_WIDTH_CACHE_BLOCKS,\n369:     decr_mode = s2_decr_mode,\n370:     sink =
      SINK_L3,\n371:     source = L1_HW_PREFETCH_STREAM,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 371-411
    context: "371:     source = L1_HW_PREFETCH_STREAM,\n372:     t_pc = s2_pc,\n373:\
      \     t_va = s2_vaddr\n374:     )\n375: \n376:   XSPerfAccumulate(\"s2_valid\"\
      , s2_valid)\n377:   XSPerfAccumulate(\"s2_will_not_send_pf\", s2_valid && !s2_will_send_pf)\n\
      378:   XSPerfAccumulate(\"s2_will_send_decr_pf\", s2_valid && s2_will_send_pf
      && s2_decr_mode)\n379:   XSPerfAccumulate(\"s2_will_send_incr_pf\", s2_valid
      && s2_will_send_pf && !s2_decr_mode)\n380: \n381:   // s3: send the l1 prefetch
      req out\n382:   val s3_pf_l1_valid = GatedValidRegNext(s2_pf_req_valid)\n383:\
      \   val s3_pf_l1_bits = RegEnable(s2_pf_l1_req_bits, s2_pf_req_valid)\n384:\
      \   val s3_pf_l2_valid = GatedValidRegNext(s2_pf_req_valid)\n385:   val s3_pf_l2_bits
      = RegEnable(s2_pf_l2_req_bits, s2_pf_req_valid)\n386:   val s3_pf_l3_bits =
      RegEnable(s2_pf_l3_req_bits, s2_pf_req_valid)\n387: \n388:   XSPerfAccumulate(\"\
      s3_pf_sent\", s3_pf_l1_valid)\n389: \n390:   // s4: send the l2 prefetch req
      out\n391:   val s4_pf_l2_valid = GatedValidRegNext(s3_pf_l2_valid)\n392:   val
      s4_pf_l2_bits = RegEnable(s3_pf_l2_bits, s3_pf_l2_valid)\n393:   val s4_pf_l3_bits
      = RegEnable(s3_pf_l3_bits, s3_pf_l2_valid)\n394: \n395:   val enable_l3_pf =
      Constantin.createRecord(s\"enableL3StreamPrefetch${p(XSCoreParamsKey).HartId}\"\
      , initValue = false)\n396:   // s5: send the l3 prefetch req out\n397:   val
      s5_pf_l3_valid = GatedValidRegNext(s4_pf_l2_valid) && enable_l3_pf\n398:   val
      s5_pf_l3_bits = RegEnable(s4_pf_l3_bits, s4_pf_l2_valid)\n399: \n400:   io.l1_prefetch_req.valid
      := s3_pf_l1_valid\n401:   io.l1_prefetch_req.bits := s3_pf_l1_bits\n402:   io.l2_l3_prefetch_req.valid
      := s4_pf_l2_valid || s5_pf_l3_valid\n403:   io.l2_l3_prefetch_req.bits := Mux(s4_pf_l2_valid,
      s4_pf_l2_bits, s5_pf_l3_bits)\n404: \n405:   XSPerfAccumulate(\"s4_pf_sent\"\
      , s4_pf_l2_valid)\n406:   XSPerfAccumulate(\"s5_pf_sent\", !s4_pf_l2_valid &&
      s5_pf_l3_valid)\n407:   XSPerfAccumulate(\"pf_sent\", PopCount(Seq(io.l1_prefetch_req.valid,
      io.l2_l3_prefetch_req.valid)))\n408: \n409:   // Stride lookup starts here\n\
      410:   // S0: Stride send req\n411:   val s0_lookup_valid = io.stream_lookup_req.valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 428-438
    context: "428:   val s3_lookup_active = RegEnable(s2_lookup_active, s2_lookup_valid)\n\
      429:   io.stream_lookup_resp := s3_lookup_valid && s3_lookup_hit && s3_lookup_active\n\
      430: \n431:   // reset meta to avoid muti-hit problem\n432:   for(i <- 0 until
      BIT_VEC_ARRAY_SIZE) {\n433:     when(GatedValidRegNext(io.flush)) {\n434:  \
      \     reset_array(i)\n435:     }\n436:   }\n437: \n438:   XSPerfHistogram(\"\
      bit_vector_active\", PopCount(VecInit(array.map(_.active)).asUInt), true.B,
      0, BIT_VEC_ARRAY_SIZE, 1)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1StreamPrefetcher.scala
    lines: 435-441
    context: "435:     }\n436:   }\n437: \n438:   XSPerfHistogram(\"bit_vector_active\"\
      , PopCount(VecInit(array.map(_.active)).asUInt), true.B, 0, BIT_VEC_ARRAY_SIZE,
      1)\n439:   XSPerfHistogram(\"bit_vector_decr_mode\", PopCount(VecInit(array.map(_.decr_mode)).asUInt),
      true.B, 0, BIT_VEC_ARRAY_SIZE, 1)\n440:   XSPerfAccumulate(\"hash_conflict\"\
      , s0_valid && s2_valid && (s0_region_tag =/= s2_region_tag) && (region_hash_tag(s0_region_tag)
      === region_hash_tag(s2_region_tag)))\n441: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/PrefetcherMonitor.scala
    lines: 24-34
    context: "24:   // val enableDynamicPrefetcher = false\n25: }\n26: \n27: class
      PrefetchControlBundle()(implicit p: Parameters) extends XSBundle with HasStreamPrefetchHelper
      {\n28:   val dynamic_depth = UInt(DEPTH_BITS.W)\n29:   val flush = Bool()\n\
      30:   val enable = Bool()\n31:   val confidence = UInt(1.W)\n32: }\n33: \n34:
      class PrefetcherMonitorBundle()(implicit p: Parameters) extends XSBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/PrefetcherMonitor.scala
    lines: 49-59
    context: "49: \n50: class PrefetcherMonitor()(implicit p: Parameters) extends
      XSModule with HasPrefetcherMonitorHelper with HasStreamPrefetchHelper {\n51:\
      \   val io = IO(new PrefetcherMonitorBundle)\n52: \n53:   val depth = Reg(UInt(DEPTH_BITS.W))\n\
      54:   val flush = RegInit(false.B)\n55:   val enable = RegInit(true.B)\n56:\
      \   val confidence = RegInit(1.U(1.W))\n57: \n58:   // TODO: mshr number\n59:\
      \   // mshr full && load miss && load send mshr req && !load match,  -> decr
      nmax prefetch"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/PrefetcherMonitor.scala
    lines: 58-68
    context: "58:   // TODO: mshr number\n59:   // mshr full && load miss && load
      send mshr req && !load match,  -> decr nmax prefetch\n60:   // mshr free\n61:\
      \ \n62:   io.pf_ctrl.dynamic_depth := depth\n63:   io.pf_ctrl.flush := flush\n\
      64:   io.pf_ctrl.enable := enable\n65:   io.pf_ctrl.confidence := confidence\n\
      66: \n67:   val depth_const = Wire(UInt(DEPTH_BITS.W))\n68:   depth_const :=
      Constantin.createRecord(s\"depth${p(XSCoreParamsKey).HartId}\", initValue =
      32)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/PrefetcherMonitor.scala
    lines: 97-107
    context: "97:   val trigger_late_hit = timely_reset && (late_hit_prefetch_cnt
      >= LATE_HIT_THRESHOLD.U)\n98:   val trigger_late_miss = timely_reset && (late_miss_prefetch_cnt
      >= LATE_MISS_THRESHOLD.U)\n99:   val trigger_bad_prefetch = validity_reset &&
      (bad_prefetch_cnt >= BAD_THRESHOLD.U)\n100:   val trigger_disable = validity_reset
      && (bad_prefetch_cnt >= DISABLE_THRESHOLD.U)\n101: \n102:   flush := Mux(flush,
      false.B, flush)\n103:   enable := Mux(back_off_reset, true.B, enable)\n104:\
      \   confidence := Mux(conf_reset, 1.U(1.W), confidence)\n105: \n106:   when(trigger_bad_prefetch)
      {\n107:     depth := Mux(depth === 1.U, depth, depth >> 1)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/PrefetcherMonitor.scala
    lines: 107-117
    context: "107:     depth := Mux(depth === 1.U, depth, depth >> 1)\n108:   }\n\
      109:   when(trigger_disable) {\n110:     confidence := 0.U(1.W)\n111:     enable
      := false.B\n112:     flush := true.B\n113:   }\n114: \n115:   when(trigger_late_miss)
      {\n116:     depth := Mux(depth === (1 << (DEPTH_BITS - 1)).U, depth, depth <<
      1)\n117:   }.elsewhen(trigger_late_hit) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/PrefetcherMonitor.scala
    lines: 123-133
    context: "123:   val enableDynamicPrefetcher_const = Constantin.createRecord(s\"\
      enableDynamicPrefetcher${p(XSCoreParamsKey).HartId}\", initValue = 1)\n124:\
      \   val enableDynamicPrefetcher = enableDynamicPrefetcher_const === 1.U\n125:\
      \ \n126:   when(!enableDynamicPrefetcher) {\n127:     depth := depth_const\n\
      128:     flush := false.B\n129:     enable := true.B\n130:     confidence :=
      1.U\n131:   }.otherwise {\n132:     // for now, only dynamically disable prefetcher,
      without depth and flush\n133:     depth := depth_const"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/PrefetcherMonitor.scala
    lines: 129-139
    context: "129:     enable := true.B\n130:     confidence := 1.U\n131:   }.otherwise
      {\n132:     // for now, only dynamically disable prefetcher, without depth and
      flush\n133:     depth := depth_const\n134:     flush := false.B\n135:   }\n\
      136: \n137:   when(reset.asBool) {\n138:     depth := depth_const\n139:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 151-161
    context: "151: // get prefetch train reqs from `exuParameters.LduCnt` load pipelines
      (up to `exuParameters.LduCnt`/cycle)\n152: // filter by cache line address,
      send out train req to stride (up to 1 req/cycle)\n153: class TrainFilter(size:
      Int, name: String)(implicit p: Parameters) extends XSModule with HasL1PrefetchHelper
      with HasTrainFilterHelper {\n154:   val io = IO(new Bundle() {\n155:     val
      enable = Input(Bool())\n156:     val flush = Input(Bool())\n157:     // train
      input, only from load for now\n158:     val ld_in = Flipped(Vec(backendParams.LduCnt,
      ValidIO(new LsPrefetchTrainBundle())))\n159:     // filter out\n160:     val
      train_req = DecoupledIO(new PrefetchReqBundle())\n161:   })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 208-223
    context: "208:       entries(allocPtr.value) := req\n209:     }\n210:   }\n211:\
      \   val allocNum = PopCount(canAlloc)\n212: \n213:   enqPtrExt.foreach{case
      x => when(canAlloc.asUInt.orR) {x := x + allocNum} }\n214: \n215:   // deq\n\
      216:   io.train_req.valid := false.B\n217:   io.train_req.bits := DontCare\n\
      218:   valids.zip(entries).zipWithIndex.foreach {\n219:     case((valid, entry),
      i) => {\n220:       when(deqPtr === i.U) {\n221:         io.train_req.valid
      := valid && io.enable\n222:         io.train_req.bits := entry\n223:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 222-238
    context: "222:         io.train_req.bits := entry\n223:       }\n224:     }\n\
      225:   }\n226: \n227:   when(io.train_req.fire) {\n228:     valids(deqPtr) :=
      false.B\n229:     deqPtrExt := deqPtrExt + 1.U\n230:   }\n231: \n232:   when(RegNext(io.flush))
      {\n233:     valids.foreach {case valid => valid := false.B}\n234:     (0 until
      enqLen).map {case i => enqPtrExt(i) := i.U.asTypeOf(new Ptr)}\n235:     deqPtrExt
      := 0.U.asTypeOf(new Ptr)\n236:   }\n237: \n238:   XSPerfAccumulate(s\"${name}_train_filter_full\"\
      , PopCount(valids) === size.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 241-251
    context: "241: \n242:   val raw_enq_pattern = Cat(reqs_vl)\n243:   val filtered_enq_pattern
      = Cat(needAlloc)\n244:   val actual_enq_pattern = Cat(canAlloc)\n245:   XSPerfAccumulate(s\"\
      ${name}_train_filter_enq\", allocNum > 0.U)\n246:   XSPerfAccumulate(s\"${name}_train_filter_deq\"\
      , io.train_req.fire)\n247:   for(i <- 0 until (1 << enqLen)) {\n248:     XSPerfAccumulate(s\"\
      ${name}_train_filter_raw_enq_pattern_${toBinary(i)}\", raw_enq_pattern === i.U)\n\
      249:     XSPerfAccumulate(s\"${name}_train_filter_filtered_enq_pattern_${toBinary(i)}\"\
      , filtered_enq_pattern === i.U)\n250:     XSPerfAccumulate(s\"${name}_train_filter_actual_enq_pattern_${toBinary(i)}\"\
      , actual_enq_pattern === i.U)\n251:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 328-338
    context: "328:     require((region.getWidth + REGION_TAG_OFFSET) == VAddrBits)\n\
      329:     Cat(region, 0.U(REGION_TAG_OFFSET.W))\n330:   }\n331: \n332:   def
      fromStreamPrefetchReqBundle(x : StreamPrefetchReqBundle): MLPReqFilterBundle
      = {\n333:     require(PAGE_OFFSET >= REGION_TAG_OFFSET, \"region is greater
      than 4k, alias bit may be incorrect\")\n334: \n335:     val res = Wire(new MLPReqFilterBundle)\n\
      336:     res.tag := region_hash_tag(x.region)\n337:     res.region := x.region\n\
      338:     res.bit_vec := x.bit_vec"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 365-375
    context: "365: // 4. actual l2 prefetch\n366: // 5. actual l3 prefetch\n367: class
      MutiLevelPrefetchFilter(implicit p: Parameters) extends XSModule with HasL1PrefetchHelper
      {\n368:   val io = IO(new XSBundle {\n369:     val enable = Input(Bool())\n\
      370:     val flush = Input(Bool())\n371:     val l1_prefetch_req = Flipped(ValidIO(new
      StreamPrefetchReqBundle))\n372:     val l2_l3_prefetch_req = Flipped(ValidIO(new
      StreamPrefetchReqBundle))\n373:     val tlb_req = new TlbRequestIO(nRespDups
      = 2)\n374:     val pmp_resp = Flipped(new PMPRespBundle())\n375:     val l1_req
      = DecoupledIO(new L1PrefetchReq())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 432-445
    context: "432:   val l2_real_replace_vec = Mux(Cat(l2_opt_replace_vec).orR, l2_opt_replace_vec,
      VecInit(Seq.fill(MLP_L2L3_SIZE)(true.B)))\n433: \n434:   // l1 pf req enq\n\
      435:   // s0: hash tag match\n436:   val s0_l1_can_accept = Wire(Bool())\n437:\
      \   val s0_l1_valid = io.l1_prefetch_req.valid && s0_l1_can_accept\n438:   val
      s0_l1_region = io.l1_prefetch_req.bits.region\n439:   val s0_l1_region_hash
      = region_hash_tag(s0_l1_region)\n440:   val s0_l1_match_vec = l1_array.zip(l1_valids).map{
      case (e, v) => e.tag_match(v, s0_l1_valid, s0_l1_region_hash)}\n441:   val s0_l1_hit
      = VecInit(s0_l1_match_vec).asUInt.orR\n442:   val s0_l1_index = Wire(UInt(log2Up(MLP_L1_SIZE).W))\n\
      443:   val s0_l1_prefetch_req = (new MLPReqFilterBundle).fromStreamPrefetchReqBundle(io.l1_prefetch_req.bits)\n\
      444: \n445:   s0_l1_index := Mux(s0_l1_hit, OHToUInt(VecInit(s0_l1_match_vec).asUInt),
      l1_replacement.way(l1_real_replace_vec.reverse)._2)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 442-471
    context: "442:   val s0_l1_index = Wire(UInt(log2Up(MLP_L1_SIZE).W))\n443:   val
      s0_l1_prefetch_req = (new MLPReqFilterBundle).fromStreamPrefetchReqBundle(io.l1_prefetch_req.bits)\n\
      444: \n445:   s0_l1_index := Mux(s0_l1_hit, OHToUInt(VecInit(s0_l1_match_vec).asUInt),
      l1_replacement.way(l1_real_replace_vec.reverse)._2)\n446: \n447:   when(s0_l1_valid)
      {\n448:     l1_replacement.access(s0_l1_index)\n449:   }\n450: \n451:   assert(!s0_l1_valid
      || PopCount(VecInit(s0_l1_match_vec)) <= 1.U, \"req region should match no more
      than 1 entry\")\n452: \n453:   XSPerfAccumulate(\"s0_l1_enq_fire\", s0_l1_valid)\n\
      454:   XSPerfAccumulate(\"s0_l1_enq_valid\", io.l1_prefetch_req.valid)\n455:\
      \   XSPerfAccumulate(\"s0_l1_cannot_enq\", io.l1_prefetch_req.valid && !s0_l1_can_accept)\n\
      456: \n457:   // s1: alloc or update\n458:   val s1_l1_valid = RegNext(s0_l1_valid)\n\
      459:   val s1_l1_region = RegEnable(s0_l1_region, s0_l1_valid)\n460:   val s1_l1_region_hash
      = RegEnable(s0_l1_region_hash, s0_l1_valid)\n461:   val s1_l1_hit = RegEnable(s0_l1_hit,
      s0_l1_valid)\n462:   val s1_l1_index = RegEnable(s0_l1_index, s0_l1_valid)\n\
      463:   val s1_l1_prefetch_req = RegEnable(s0_l1_prefetch_req, s0_l1_valid)\n\
      464:   val s1_l1_alloc = s1_l1_valid && !s1_l1_hit\n465:   val s1_l1_update
      = s1_l1_valid && s1_l1_hit\n466:   s0_l1_can_accept := !(s1_l1_valid && s1_l1_alloc
      && (s0_l1_region_hash === s1_l1_region_hash))\n467: \n468:   when(s1_l1_alloc)
      {\n469:     l1_valids(s1_l1_index) := true.B\n470:     l1_array(s1_l1_index)
      := s1_l1_prefetch_req\n471:   }.elsewhen(s1_l1_update) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 473-486
    context: "473:       update_bit_vec = s1_l1_prefetch_req.bit_vec,\n474:      \
      \ update_sink = s1_l1_prefetch_req.sink\n475:     )\n476:   }\n477: \n478: \
      \  XSPerfAccumulate(\"s1_l1_enq_valid\", s1_l1_valid)\n479:   XSPerfAccumulate(\"\
      s1_l1_enq_alloc\", s1_l1_alloc)\n480:   XSPerfAccumulate(\"s1_l1_enq_update\"\
      , s1_l1_update)\n481:   XSPerfAccumulate(\"l1_hash_conflict\", s0_l1_valid &&
      RegNext(s1_l1_valid) && (s0_l1_region =/= RegNext(s1_l1_region)) && (s0_l1_region_hash
      === RegNext(s1_l1_region_hash)))\n482:   XSPerfAccumulate(\"s1_l1_enq_evict_useful_entry\"\
      , s1_l1_alloc && l1_array(s1_l1_index).can_send_pf(l1_valids(s1_l1_index)))\n\
      483: \n484:   // l2 l3 pf req enq\n485:   // s0: hash tag match\n486:   val
      s0_l2_can_accept = Wire(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 482-495
    context: "482:   XSPerfAccumulate(\"s1_l1_enq_evict_useful_entry\", s1_l1_alloc
      && l1_array(s1_l1_index).can_send_pf(l1_valids(s1_l1_index)))\n483: \n484: \
      \  // l2 l3 pf req enq\n485:   // s0: hash tag match\n486:   val s0_l2_can_accept
      = Wire(Bool())\n487:   val s0_l2_valid = io.l2_l3_prefetch_req.valid && s0_l2_can_accept\n\
      488:   val s0_l2_region = io.l2_l3_prefetch_req.bits.region\n489:   val s0_l2_region_hash
      = region_hash_tag(s0_l2_region)\n490:   val s0_l2_match_vec = l2_array.zip(l2_valids).map{
      case (e, v) => e.tag_match(v, s0_l2_valid, s0_l2_region_hash) }\n491:   val
      s0_l2_hit = VecInit(s0_l2_match_vec).asUInt.orR\n492:   val s0_l2_index = Wire(UInt(log2Up(MLP_L2L3_SIZE).W))\n\
      493:   val s0_l2_prefetch_req = (new MLPReqFilterBundle).fromStreamPrefetchReqBundle(io.l2_l3_prefetch_req.bits)\n\
      494: \n495:   s0_l2_index := Mux(s0_l2_hit, OHToUInt(VecInit(s0_l2_match_vec).asUInt),
      l2_replacement.way(l2_real_replace_vec.reverse)._2)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 492-521
    context: "492:   val s0_l2_index = Wire(UInt(log2Up(MLP_L2L3_SIZE).W))\n493: \
      \  val s0_l2_prefetch_req = (new MLPReqFilterBundle).fromStreamPrefetchReqBundle(io.l2_l3_prefetch_req.bits)\n\
      494: \n495:   s0_l2_index := Mux(s0_l2_hit, OHToUInt(VecInit(s0_l2_match_vec).asUInt),
      l2_replacement.way(l2_real_replace_vec.reverse)._2)\n496: \n497:   when(s0_l2_valid)
      {\n498:     l2_replacement.access(s0_l2_index)\n499:   }\n500: \n501:   assert(!s0_l2_valid
      || PopCount(VecInit(s0_l2_match_vec)) <= 1.U, \"req region should match no more
      than 1 entry\")\n502: \n503:   XSPerfAccumulate(\"s0_l2_enq_fire\", s0_l2_valid)\n\
      504:   XSPerfAccumulate(\"s0_l2_enq_valid\", io.l2_l3_prefetch_req.valid)\n\
      505:   XSPerfAccumulate(\"s0_l2_cannot_enq\", io.l2_l3_prefetch_req.valid &&
      !s0_l2_can_accept)\n506: \n507:   // s1: alloc or update\n508:   val s1_l2_valid
      = RegNext(s0_l2_valid)\n509:   val s1_l2_region = RegEnable(s0_l2_region, s0_l2_valid)\n\
      510:   val s1_l2_region_hash = RegEnable(s0_l2_region_hash, s0_l2_valid)\n511:\
      \   val s1_l2_hit = RegEnable(s0_l2_hit, s0_l2_valid)\n512:   val s1_l2_index
      = RegEnable(s0_l2_index, s0_l2_valid)\n513:   val s1_l2_prefetch_req = RegEnable(s0_l2_prefetch_req,
      s0_l2_valid)\n514:   val s1_l2_alloc = s1_l2_valid && !s1_l2_hit\n515:   val
      s1_l2_update = s1_l2_valid && s1_l2_hit\n516:   s0_l2_can_accept := !(s1_l2_valid
      && s1_l2_alloc && (s0_l2_region_hash === s1_l2_region_hash))\n517: \n518:  \
      \ when(s1_l2_alloc) {\n519:     l2_valids(s1_l2_index) := true.B\n520:     l2_array(s1_l2_index)
      := s1_l2_prefetch_req\n521:   }.elsewhen(s1_l2_update) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 523-536
    context: "523:       update_bit_vec = s1_l2_prefetch_req.bit_vec,\n524:      \
      \ update_sink = s1_l2_prefetch_req.sink\n525:     )\n526:   }\n527: \n528: \
      \  XSPerfAccumulate(\"s1_l2_enq_valid\", s1_l2_valid)\n529:   XSPerfAccumulate(\"\
      s1_l2_enq_alloc\", s1_l2_alloc)\n530:   XSPerfAccumulate(\"s1_l2_enq_update\"\
      , s1_l2_update)\n531:   XSPerfAccumulate(\"l2_hash_conflict\", s0_l2_valid &&
      RegNext(s1_l2_valid) && (s0_l2_region =/= RegNext(s1_l2_region)) && (s0_l2_region_hash
      === RegNext(s1_l2_region_hash)))\n532:   XSPerfAccumulate(\"s1_l2_enq_evict_useful_entry\"\
      , s1_l2_alloc && l2_array(s1_l2_index).can_send_pf(l2_valids(s1_l2_index)))\n\
      533: \n534:   // stream pf debug db here\n535:   // Hit:\n536:   // now seens
      only pending = (region_bits & ~filter_bits) are the peeding request"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 544-554
    context: "544:     val new_req = Mux(\n545:       s0_l1_hit,\n546:       io.l1_prefetch_req.bits.bit_vec
      & ~(hit_entry.bit_vec),\n547:       io.l1_prefetch_req.bits.bit_vec\n548:  \
      \   )\n549:     val log_enable = s0_l1_valid && new_req(i) && (io.l1_prefetch_req.bits.source.value
      === L1_HW_PREFETCH_STREAM)\n550:     val log_data = Wire(new StreamPFTraceInEntry)\n\
      551: \n552:     log_data.TriggerPC := io.l1_prefetch_req.bits.trigger_pc\n553:\
      \     log_data.TriggerVaddr := io.l1_prefetch_req.bits.trigger_va\n554:    \
      \ log_data.PFVaddr := Cat(s0_l1_region, i.U(REGION_BITS.W), 0.U(log2Up(dcacheParameters.blockBytes).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 568-578
    context: "568:     val new_req = Mux(\n569:       s0_l2_hit,\n570:       io.l2_l3_prefetch_req.bits.bit_vec
      & ~(hit_entry.bit_vec),\n571:       io.l2_l3_prefetch_req.bits.bit_vec\n572:\
      \     )\n573:     val log_enable = s0_l2_valid && new_req(i) && (io.l2_l3_prefetch_req.bits.source.value
      === L1_HW_PREFETCH_STREAM)\n574:     val log_data = Wire(new StreamPFTraceInEntry)\n\
      575: \n576:     log_data.TriggerPC := io.l2_l3_prefetch_req.bits.trigger_pc\n\
      577:     log_data.TriggerVaddr := io.l2_l3_prefetch_req.bits.trigger_va\n578:\
      \     log_data.PFVaddr := Cat(s0_l2_region, i.U(REGION_BITS.W), 0.U(log2Up(dcacheParameters.blockBytes).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 587-597
    context: "587:     )\n588:   }\n589: \n590:   // tlb req\n591:   // s0: arb all
      tlb reqs\n592:   val s0_tlb_fire_vec = VecInit((0 until MLP_SIZE).map{case i
      => tlb_req_arb.io.in(i).fire})\n593:   val s1_tlb_fire_vec = GatedValidRegNext(s0_tlb_fire_vec)\n\
      594:   val s2_tlb_fire_vec = GatedValidRegNext(s1_tlb_fire_vec)\n595:   val
      s3_tlb_fire_vec = GatedValidRegNext(s2_tlb_fire_vec)\n596:   val not_tlbing_vec
      = VecInit((0 until MLP_SIZE).map{case i =>\n597:     !s1_tlb_fire_vec(i) &&
      !s2_tlb_fire_vec(i) && !s3_tlb_fire_vec(i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 605-615
    context: "605:       tlb_req_arb.io.in(i).bits.vaddr := l1_array(i).get_tlb_va()\n\
      606:     }else {\n607:       tlb_req_arb.io.in(i).valid := l2_valids(i - MLP_L1_SIZE)
      && l2_array(i - MLP_L1_SIZE).is_vaddr && not_tlbing_vec(i) && !l2_evict\n608:\
      \       tlb_req_arb.io.in(i).bits.vaddr := l2_array(i - MLP_L1_SIZE).get_tlb_va()\n\
      609:     }\n610:     tlb_req_arb.io.in(i).bits.cmd := TlbCmd.read\n611:    \
      \ tlb_req_arb.io.in(i).bits.isPrefetch := true.B\n612:     tlb_req_arb.io.in(i).bits.size
      := 3.U\n613:     tlb_req_arb.io.in(i).bits.kill := false.B\n614:     tlb_req_arb.io.in(i).bits.no_translate
      := false.B\n615:     tlb_req_arb.io.in(i).bits.fullva := 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 622-632
    context: "622:   }\n623: \n624:   assert(PopCount(s0_tlb_fire_vec) <= 1.U, \"\
      s0_tlb_fire_vec should be one-hot or empty\")\n625: \n626:   // s1: send out
      the req\n627:   val s1_tlb_req_valid = GatedValidRegNext(tlb_req_arb.io.out.valid)\n\
      628:   val s1_tlb_req_bits = RegEnable(tlb_req_arb.io.out.bits, tlb_req_arb.io.out.valid)\n\
      629:   val s1_tlb_req_index = RegEnable(OHToUInt(s0_tlb_fire_vec.asUInt), tlb_req_arb.io.out.valid)\n\
      630:   val s1_l1_tlb_evict = s1_l1_alloc && (s1_l1_index === s1_tlb_req_index)\n\
      631:   val s1_l2_tlb_evict = s1_l2_alloc && ((s1_l2_index + MLP_L1_SIZE.U) ===
      s1_tlb_req_index)\n632:   val s1_tlb_evict = s1_l1_tlb_evict || s1_l2_tlb_evict"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 628-649
    context: "628:   val s1_tlb_req_bits = RegEnable(tlb_req_arb.io.out.bits, tlb_req_arb.io.out.valid)\n\
      629:   val s1_tlb_req_index = RegEnable(OHToUInt(s0_tlb_fire_vec.asUInt), tlb_req_arb.io.out.valid)\n\
      630:   val s1_l1_tlb_evict = s1_l1_alloc && (s1_l1_index === s1_tlb_req_index)\n\
      631:   val s1_l2_tlb_evict = s1_l2_alloc && ((s1_l2_index + MLP_L1_SIZE.U) ===
      s1_tlb_req_index)\n632:   val s1_tlb_evict = s1_l1_tlb_evict || s1_l2_tlb_evict\n\
      633:   io.tlb_req.req.valid := s1_tlb_req_valid && !s1_tlb_evict\n634:   io.tlb_req.req.bits
      := s1_tlb_req_bits\n635:   io.tlb_req.req_kill := false.B\n636:   tlb_req_arb.io.out.ready
      := true.B\n637: \n638:   XSPerfAccumulate(\"s1_tlb_req_sent\", io.tlb_req.req.valid)\n\
      639:   XSPerfAccumulate(\"s1_tlb_req_evict\", s1_tlb_req_valid && s1_tlb_evict)\n\
      640: \n641:   // s2: get response from tlb\n642:   val s2_tlb_resp_valid = io.tlb_req.resp.valid\n\
      643:   val s2_tlb_resp = io.tlb_req.resp.bits\n644:   val s2_tlb_update_index
      = RegEnable(s1_tlb_req_index, s1_tlb_req_valid)\n645:   val s2_l1_tlb_evict
      = s1_l1_alloc && (s1_l1_index === s2_tlb_update_index)\n646:   val s2_l2_tlb_evict
      = s1_l2_alloc && ((s1_l2_index + MLP_L1_SIZE.U) === s2_tlb_update_index)\n647:\
      \   val s2_tlb_evict = s2_l1_tlb_evict || s2_l2_tlb_evict\n648: \n649:   //
      s3: get pmp response form PMPChecker"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 653-665
    context: "653:   val s3_tlb_evict = RegNext(s2_tlb_evict)\n654:   val s3_pmp_resp
      = io.pmp_resp\n655:   val s3_update_valid = s3_tlb_resp_valid && !s3_tlb_evict
      && !s3_tlb_resp.miss\n656:   val s3_drop = s3_update_valid && (\n657:     //
      page/access fault\n658:     s3_tlb_resp.excp.head.pf.ld || s3_tlb_resp.excp.head.gpf.ld
      || s3_tlb_resp.excp.head.af.ld ||\n659:     // uncache\n660:     s3_pmp_resp.mmio
      || Pbmt.isUncache(s3_tlb_resp.pbmt.head) ||\n661:     // pmp access fault\n\
      662:     s3_pmp_resp.ld\n663:   )\n664:   when(s3_tlb_resp_valid && !s3_tlb_evict)
      {\n665:     when(s3_tlb_update_index < MLP_L1_SIZE.U) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 664-674
    context: "664:   when(s3_tlb_resp_valid && !s3_tlb_evict) {\n665:     when(s3_tlb_update_index
      < MLP_L1_SIZE.U) {\n666:       l1_array(s3_tlb_update_index).is_vaddr := s3_tlb_resp.miss\n\
      667: \n668:       when(!s3_tlb_resp.miss) {\n669:         l1_array(s3_tlb_update_index).region
      := Cat(0.U((VAddrBits - PAddrBits).W), s3_tlb_resp.paddr.head(s3_tlb_resp.paddr.head.getWidth
      - 1, REGION_TAG_OFFSET))\n670:         when(s3_drop) {\n671:           invalid_array(s3_tlb_update_index,
      false)\n672:         }\n673:       }\n674:     }.otherwise {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 674-684
    context: "674:     }.otherwise {\n675:       val inner_index = s3_tlb_update_index
      - MLP_L1_SIZE.U\n676:       l2_array(inner_index).is_vaddr := s3_tlb_resp.miss\n\
      677: \n678:       when(!s3_tlb_resp.miss) {\n679:         l2_array(inner_index).region
      := Cat(0.U((VAddrBits - PAddrBits).W), s3_tlb_resp.paddr.head(s3_tlb_resp.paddr.head.getWidth
      - 1, REGION_TAG_OFFSET))\n680:         when(s3_drop) {\n681:           invalid_array(inner_index,
      true)\n682:         }\n683:       }\n684:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 681-691
    context: "681:           invalid_array(inner_index, true)\n682:         }\n683:\
      \       }\n684:     }\n685:   }\n686:   io.tlb_req.resp.ready := true.B\n687:\
      \ \n688:   XSPerfAccumulate(\"s3_tlb_resp_valid\", s3_tlb_resp_valid)\n689:\
      \   XSPerfAccumulate(\"s3_tlb_resp_evict\", s3_tlb_resp_valid && s3_tlb_evict)\n\
      690:   XSPerfAccumulate(\"s3_tlb_resp_miss\", s3_tlb_resp_valid && !s3_tlb_evict
      && s3_tlb_resp.miss)\n691:   XSPerfAccumulate(\"s3_tlb_resp_updated\", s3_update_valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 687-708
    context: "687: \n688:   XSPerfAccumulate(\"s3_tlb_resp_valid\", s3_tlb_resp_valid)\n\
      689:   XSPerfAccumulate(\"s3_tlb_resp_evict\", s3_tlb_resp_valid && s3_tlb_evict)\n\
      690:   XSPerfAccumulate(\"s3_tlb_resp_miss\", s3_tlb_resp_valid && !s3_tlb_evict
      && s3_tlb_resp.miss)\n691:   XSPerfAccumulate(\"s3_tlb_resp_updated\", s3_update_valid)\n\
      692:   XSPerfAccumulate(\"s3_tlb_resp_page_fault\", s3_update_valid && s3_tlb_resp.excp.head.pf.ld)\n\
      693:   XSPerfAccumulate(\"s3_tlb_resp_guestpage_fault\", s3_update_valid &&
      s3_tlb_resp.excp.head.gpf.ld)\n694:   XSPerfAccumulate(\"s3_tlb_resp_access_fault\"\
      , s3_update_valid && s3_tlb_resp.excp.head.af.ld)\n695:   XSPerfAccumulate(\"\
      s3_tlb_resp_pmp_access_fault\", s3_update_valid && s3_pmp_resp.ld)\n696:   XSPerfAccumulate(\"\
      s3_tlb_resp_uncache\", s3_update_valid && (Pbmt.isUncache(s3_tlb_resp.pbmt.head)
      || s3_pmp_resp.mmio))\n697: \n698:   // l1 pf\n699:   // s0: generate prefetch
      req paddr per entry, arb them\n700:   val s0_pf_fire_vec = VecInit((0 until
      MLP_L1_SIZE).map{case i => l1_pf_req_arb.io.in(i).fire})\n701:   val s1_pf_fire_vec
      = GatedValidRegNext(s0_pf_fire_vec)\n702: \n703:   val s0_pf_fire = l1_pf_req_arb.io.out.fire\n\
      704:   val s0_pf_index = l1_pf_req_arb.io.chosen\n705:   val s0_pf_candidate_oh
      = get_candidate_oh(l1_pf_req_arb.io.out.bits.req.paddr)\n706: \n707:   for(i
      <- 0 until MLP_L1_SIZE) {\n708:     val evict = s1_l1_alloc && (s1_l1_index
      === i.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 720-744
    context: "720:   }\n721: \n722:   assert(PopCount(s0_pf_fire_vec) <= 1.U, \"s0_pf_fire_vec
      should be one-hot or empty\")\n723: \n724:   // s1: send out to dcache\n725:\
      \   val s1_pf_valid = Reg(Bool())\n726:   val s1_pf_bits = RegEnable(l1_pf_req_arb.io.out.bits,
      l1_pf_req_arb.io.out.fire)\n727:   val s1_pf_index = RegEnable(s0_pf_index,
      l1_pf_req_arb.io.out.fire)\n728:   val s1_pf_candidate_oh = RegEnable(s0_pf_candidate_oh,
      l1_pf_req_arb.io.out.fire)\n729:   val s1_pf_evict = s1_l1_alloc && (s1_l1_index
      === s1_pf_index)\n730:   val s1_pf_update = s1_l1_update && (s1_l1_index ===
      s1_pf_index)\n731:   val s1_pf_can_go = io.l1_req.ready && !s1_pf_evict && !s1_pf_update\n\
      732:   val s1_pf_fire = s1_pf_valid && s1_pf_can_go\n733: \n734:   when(s1_pf_can_go)
      {\n735:     s1_pf_valid := false.B\n736:   }\n737: \n738:   when(l1_pf_req_arb.io.out.fire)
      {\n739:     s1_pf_valid := true.B\n740:   }\n741: \n742:   when(s1_pf_fire)
      {\n743:     l1_array(s1_pf_index).bit_vec := l1_array(s1_pf_index).bit_vec &
      ~s1_pf_candidate_oh\n744:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 742-762
    context: "742:   when(s1_pf_fire) {\n743:     l1_array(s1_pf_index).bit_vec :=
      l1_array(s1_pf_index).bit_vec & ~s1_pf_candidate_oh\n744:   }\n745: \n746: \
      \  val in_pmem = PmemRanges.map(_.cover(s1_pf_bits.req.paddr)).reduce(_ || _)\n\
      747:   io.l1_req.valid := s1_pf_valid && !s1_pf_evict && !s1_pf_update && in_pmem
      && io.enable\n748:   io.l1_req.bits := s1_pf_bits.req\n749: \n750:   l1_pf_req_arb.io.out.ready
      := s1_pf_can_go || !s1_pf_valid\n751: \n752:   assert(!((s1_l1_alloc || s1_l1_update)
      && s1_pf_fire && (s1_l1_index === s1_pf_index)), \"pf pipeline & enq pipeline
      bit_vec harzard!\")\n753: \n754:   XSPerfAccumulate(\"s1_pf_valid\", s1_pf_valid)\n\
      755:   XSPerfAccumulate(\"s1_pf_block_by_pipe_unready\", s1_pf_valid && !io.l1_req.ready)\n\
      756:   XSPerfAccumulate(\"s1_pf_block_by_enq_alloc_harzard\", s1_pf_valid &&
      s1_pf_evict)\n757:   XSPerfAccumulate(\"s1_pf_block_by_enq_update_harzard\"\
      , s1_pf_valid && s1_pf_update)\n758:   XSPerfAccumulate(\"s1_pf_fire\", s1_pf_fire)\n\
      759: \n760:   // l2 pf\n761:   // s0: generate prefetch req paddr per entry,
      arb them, sent out\n762:   io.l2_pf_addr.valid := l2_pf_req_arb.io.out.valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 760-770
    context: "760:   // l2 pf\n761:   // s0: generate prefetch req paddr per entry,
      arb them, sent out\n762:   io.l2_pf_addr.valid := l2_pf_req_arb.io.out.valid\n\
      763:   io.l2_pf_addr.bits := l2_pf_req_arb.io.out.bits.req\n764: \n765:   l2_pf_req_arb.io.out.ready
      := true.B\n766: \n767:   for(i <- 0 until MLP_L2L3_SIZE) {\n768:     val evict
      = s1_l2_alloc && (s1_l2_index === i.U)\n769:     l2_pf_req_arb.io.in(i).valid
      := l2_array(i).can_send_pf(l2_valids(i)) && (l2_array(i).sink === SINK_L2) &&
      !evict\n770:     l2_pf_req_arb.io.in(i).bits.req.addr := l2_array(i).get_pf_addr()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 787-797
    context: "787:   l2_debug_data.PFVaddr := l2_pf_req_arb.io.out.bits.debug_vaddr\n\
      788:   l2_debug_data.PFSink := SINK_L2\n789: \n790:   stream_out_debug_table.log(\n\
      791:     data = l1_debug_data,\n792:     en = l1_pf_req_arb.io.out.fire && (l1_pf_req_arb.io.out.bits.req.pf_source.value
      === L1_HW_PREFETCH_STREAM),\n793:     site = \"StreamPFTraceOut\",\n794:   \
      \  clock = clock,\n795:     reset = reset\n796:   )\n797:   stream_out_debug_table.log("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 794-804
    context: "794:     clock = clock,\n795:     reset = reset\n796:   )\n797:   stream_out_debug_table.log(\n\
      798:     data = l2_debug_data,\n799:     en = l2_pf_req_arb.io.out.fire && (l2_pf_req_arb.io.out.bits.req.source
      === MemReqSource.Prefetch2L2Stream.id.U),\n800:     site = \"StreamPFTraceOut\"\
      ,\n801:     clock = clock,\n802:     reset = reset\n803:   )\n804: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 805-815
    context: "805:   // last level cache pf\n806:   // s0: generate prefetch req paddr
      per entry, arb them, sent out\n807:   io.l3_pf_addr.valid := l3_pf_req_arb.io.out.valid\n\
      808:   io.l3_pf_addr.bits := l3_pf_req_arb.io.out.bits\n809: \n810:   l3_pf_req_arb.io.out.ready
      := true.B\n811: \n812:   for(i <- 0 until MLP_L2L3_SIZE) {\n813:     val evict
      = s1_l2_alloc && (s1_l2_index === i.U)\n814:     l3_pf_req_arb.io.in(i).valid
      := l2_array(i).can_send_pf(l2_valids(i)) && (l2_array(i).sink === SINK_L3) &&
      !evict\n815:     l3_pf_req_arb.io.in(i).bits := l2_array(i).get_pf_addr()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 820-834
    context: "820:   }\n821: \n822:   // reset meta to avoid muti-hit problem\n823:\
      \   for(i <- 0 until MLP_SIZE) {\n824:     if(i < MLP_L1_SIZE) {\n825:     \
      \  when(RegNext(io.flush)) {\n826:         reset_array(i, false)\n827:     \
      \  }\n828:     }else {\n829:       when(RegNext(io.flush)) {\n830:         reset_array(i
      - MLP_L1_SIZE, true)\n831:       }\n832:     }\n833:   }\n834: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 853-865
    context: "853:   val stream_bit_vec_array = Module(new StreamBitVectorArray)\n\
      854:   val pf_queue_filter = Module(new MutiLevelPrefetchFilter)\n855: \n856:\
      \   // for now, if the stream is disabled, train and prefetch process will continue,
      without sending out and reqs\n857:   val enable = io.enable\n858:   val flush
      = pf_ctrl.flush\n859: \n860:   stream_train_filter.io.ld_in.zipWithIndex.foreach
      {\n861:     case (ld_in, i) => {\n862:       ld_in.valid := io.ld_in(i).valid
      && enable\n863:       ld_in.bits := io.ld_in(i).bits\n864:     }\n865:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 862-874
    context: "862:       ld_in.valid := io.ld_in(i).valid && enable\n863:       ld_in.bits
      := io.ld_in(i).bits\n864:     }\n865:   }\n866:   stream_train_filter.io.enable
      := enable\n867:   stream_train_filter.io.flush := flush\n868: \n869:   stride_train_filter.io.ld_in.zipWithIndex.foreach
      {\n870:     case (ld_in, i) => {\n871:       ld_in.valid := stride_train(i).valid
      && enable\n872:       ld_in.bits := stride_train(i).bits\n873:     }\n874: \
      \  }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 871-889
    context: "871:       ld_in.valid := stride_train(i).valid && enable\n872:    \
      \   ld_in.bits := stride_train(i).bits\n873:     }\n874:   }\n875:   stride_train_filter.io.enable
      := enable\n876:   stride_train_filter.io.flush := flush\n877: \n878:   stream_bit_vec_array.io.enable
      := enable\n879:   stream_bit_vec_array.io.flush := flush\n880:   stream_bit_vec_array.io.dynamic_depth
      := pf_ctrl.dynamic_depth\n881:   stream_bit_vec_array.io.train_req <> stream_train_filter.io.train_req\n\
      882: \n883:   stride_meta_array.io.enable := enable\n884:   stride_meta_array.io.flush
      := flush\n885:   stride_meta_array.io.dynamic_depth := 0.U\n886:   stride_meta_array.io.train_req
      <> stride_train_filter.io.train_req\n887:   stride_meta_array.io.stream_lookup_req
      <> stream_bit_vec_array.io.stream_lookup_req\n888:   stride_meta_array.io.stream_lookup_resp
      <> stream_bit_vec_array.io.stream_lookup_resp\n889: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/L1PrefetchComponent.scala
    lines: 903-917
    context: "903:   )\n904: \n905:   io.l1_req.valid := pf_queue_filter.io.l1_req.valid
      && enable && pf_ctrl.enable\n906:   io.l1_req.bits := pf_queue_filter.io.l1_req.bits\n\
      907: \n908:   pf_queue_filter.io.l1_req.ready := Mux(pf_ctrl.enable, io.l1_req.ready,
      true.B)\n909:   pf_queue_filter.io.tlb_req <> io.tlb_req\n910:   pf_queue_filter.io.pmp_resp
      := io.pmp_resp\n911:   pf_queue_filter.io.enable := enable\n912:   pf_queue_filter.io.flush
      := flush\n913:   pf_queue_filter.io.confidence := pf_ctrl.confidence\n914: \
      \  pf_queue_filter.io.l2PfqBusy := l2PfqBusy\n915: \n916:   val l2_in_pmem =
      PmemRanges.map(_.cover(pf_queue_filter.io.l2_pf_addr.bits.addr)).reduce(_ ||
      _)\n917:   io.l2_req.valid := pf_queue_filter.io.l2_pf_addr.valid && l2_in_pmem
      && enable && pf_ctrl.enable"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/FDP.scala
    lines: 113-123
    context: "113: \n114:     assert(!needAlloc(i) || canAlloc(i), s\"port${i} can
      not accept CounterFilter enq request, check if SIZE >= (Ldu stages - 2) * LduCnt\"\
      )\n115:   }\n116:   val allocNum = PopCount(canAlloc)\n117: \n118:   enqPtrExt.foreach{case
      x => \n119:     when(canAlloc.asUInt.orR){\n120:       x := x + allocNum\n121:\
      \     }\n122:   }\n123:   last3CycleAlloc := RegNext(RegNext(allocNum))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/FDP.scala
    lines: 127-137
    context: "127:     when(i.U < last3CycleAlloc) {\n128:       valids(deqPtrExt(i).value)
      := false.B\n129:     }\n130:   }\n131: \n132:   deqPtrExt.foreach{case x =>
      x := x + last3CycleAlloc}\n133: \n134:   // query\n135:   val querys_l = io.query.map(_.req.bits)\n\
      136:   val querys_vl = io.query.map(_.req.valid)\n137:   for(i <- (0 until LduCnt
      + HyuCnt)) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/FDP.scala
    lines: 204-216
    context: "204: \n205:   XSPerfHistogram(\"valid_nums\", PopCount(data), true.B,
      0, n + 1, 20)\n206: }\n207: \n208: class FDPrefetcherMonitorBundle()(implicit
      p: Parameters) extends XSBundle {\n209:   val refill = Input(Bool()) // from
      refill pipe, fire\n210:   val accuracy = new XSBundle {\n211:     val total_prefetch
      = Input(Bool()) // from mshr enq, fire, alloc, prefetch\n212:     val useful_prefetch
      = Vec(LoadPipelineWidth, Input(Bool())) // from load pipeline, prefetch hit\n\
      213:   }\n214: \n215:   val timely = new XSBundle {\n216:     val late_prefetch
      = Input(Bool()) // from mshr enq, a load matches a mshr caused by prefetch"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/FDP.scala
    lines: 271-281
    context: "271: \n272:   // rolling by instr\n273:   XSPerfRolling(\n274:     \"\
      L1PrefetchAccuracyIns\",\n275:     PopCount(io.accuracy.useful_prefetch), PopCount(io.accuracy.total_prefetch),\n\
      276:     1000, io.debugRolling.robTrueCommit, clock, reset\n277:   )\n278: \n\
      279:   XSPerfRolling(\n280:     \"L1PrefetchLatenessIns\",\n281:     PopCount(io.timely.late_prefetch),
      PopCount(io.accuracy.total_prefetch),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/FDP.scala
    lines: 277-287
    context: "277:   )\n278: \n279:   XSPerfRolling(\n280:     \"L1PrefetchLatenessIns\"\
      ,\n281:     PopCount(io.timely.late_prefetch), PopCount(io.accuracy.total_prefetch),\n\
      282:     1000, io.debugRolling.robTrueCommit, clock, reset\n283:   )\n284: \n\
      285:   XSPerfRolling(\n286:     \"L1PrefetchPollutionIns\",\n287:     PopCount(io.pollution.cache_pollution),
      PopCount(io.pollution.demand_miss),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/FDP.scala
    lines: 283-299
    context: "283:   )\n284: \n285:   XSPerfRolling(\n286:     \"L1PrefetchPollutionIns\"\
      ,\n287:     PopCount(io.pollution.cache_pollution), PopCount(io.pollution.demand_miss),\n\
      288:     1000, io.debugRolling.robTrueCommit, clock, reset\n289:   )\n290: \n\
      291:   XSPerfRolling(\n292:     \"IPCIns\",\n293:     io.debugRolling.robTrueCommit,
      1.U,\n294:     1000, io.debugRolling.robTrueCommit, clock, reset\n295:   )\n\
      296: \n297:   XSPerfAccumulate(\"io_refill\", io.refill)\n298:   XSPerfAccumulate(\"\
      total_prefetch_en\", io.accuracy.total_prefetch)\n299:   XSPerfAccumulate(\"\
      useful_prefetch_en\", PopCount(io.accuracy.useful_prefetch) + io.timely.late_prefetch)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 142-152
    context: "142:     val s0_lookup = Flipped(new ValidIO(new Bundle() {\n143:  \
      \     val pc = UInt(STRIDE_PC_BITS.W)\n144:       val vaddr = UInt(VAddrBits.W)\n\
      145:       val paddr = UInt(PAddrBits.W)\n146:     }))\n147:     val s1_valid
      = Input(Bool())\n148:     val s2_gen_req = ValidIO(new PfGenReq())\n149:   })\n\
      150: \n151:   val prev_valid = GatedValidRegNext(io.s0_lookup.valid, false.B)\n\
      152:   val prev_pc = RegEnable(io.s0_lookup.bits.pc, io.s0_lookup.valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 149-159
    context: "149:   })\n150: \n151:   val prev_valid = GatedValidRegNext(io.s0_lookup.valid,
      false.B)\n152:   val prev_pc = RegEnable(io.s0_lookup.bits.pc, io.s0_lookup.valid)\n\
      153: \n154:   val s0_valid = io.s0_lookup.valid && !(prev_valid && prev_pc ===
      io.s0_lookup.bits.pc)\n155: \n156:   def entry_map[T](fn: Int => T) = (0 until
      smsParams.stride_entries).map(fn)\n157: \n158:   val replacement = ReplacementPolicy.fromString(\"\
      plru\", smsParams.stride_entries)\n159:   val valids = entry_map(_ => RegInit(false.B))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 165-188
    context: "165: \n166:   val s0_match_vec = valids.zip(entries_pc).map({\n167:\
      \     case (v, pc) => v && pc === io.s0_lookup.bits.pc\n168:   })\n169: \n170:\
      \   val s0_hit = s0_valid && Cat(s0_match_vec).orR\n171:   val s0_miss = s0_valid
      && !s0_hit\n172:   val s0_matched_conf = Mux1H(s0_match_vec, entries_conf)\n\
      173:   val s0_matched_last_addr = Mux1H(s0_match_vec, entries_last_addr)\n174:\
      \   val s0_matched_last_stride = Mux1H(s0_match_vec, entries_stride)\n175: \n\
      176:   val s1_hit = GatedValidRegNext(s0_hit) && io.s1_valid\n177:   val s1_alloc
      = GatedValidRegNext(s0_miss) && io.s1_valid\n178:   val s1_vaddr = RegEnable(io.s0_lookup.bits.vaddr,
      s0_valid)\n179:   val s1_paddr = RegEnable(io.s0_lookup.bits.paddr, s0_valid)\n\
      180:   val s1_conf = RegEnable(s0_matched_conf, s0_valid)\n181:   val s1_last_addr
      = RegEnable(s0_matched_last_addr, s0_valid)\n182:   val s1_last_stride = RegEnable(s0_matched_last_stride,
      s0_valid)\n183:   val s1_match_vec = RegEnable(VecInit(s0_match_vec), s0_valid)\n\
      184: \n185:   val BLOCK_OFFSET = log2Up(dcacheParameters.blockBytes)\n186: \
      \  val s1_new_stride_vaddr = s1_vaddr(BLOCK_OFFSET + STRIDE_BLK_ADDR_BITS -
      1, BLOCK_OFFSET)\n187:   val s1_new_stride = (0.U(1.W) ## s1_new_stride_vaddr).asSInt
      - (0.U(1.W) ## s1_last_addr).asSInt\n188:   val s1_stride_non_zero = s1_last_stride
      =/= 0.S"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 322-332
    context: "322:   val s0_lookup = io.s0_lookup.bits\n323:   val s0_lookup_valid
      = io.s0_lookup.valid\n324: \n325:   val s0_dcache_evict = io.s0_dcache_evict.bits\n\
      326:   val s0_dcache_evict_valid = io.s0_dcache_evict.valid\n327:   val s0_dcache_evict_tag
      = block_hash_tag(s0_dcache_evict.vaddr).head(REGION_TAG_WIDTH)\n328: \n329:\
      \   val prev_lookup = RegEnable(s0_lookup, s0_lookup_valid)\n330:   val prev_lookup_valid
      = GatedValidRegNext(s0_lookup_valid, false.B)\n331: \n332:   val s0_match_prev
      = prev_lookup_valid && s0_lookup.region_tag === prev_lookup.region_tag"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 347-359
    context: "347: \n348:   val region_match_vec_dcache_evict_s0 = gen_match_vec(s0_dcache_evict_tag)\n\
      349:   val any_region_dcache_evict_match = Cat(region_match_vec_dcache_evict_s0).orR\n\
      350:   // s0 dcache evict a entry that may be replaced in s1\n351:   val s0_dcache_evict_conflict
      = Cat(VecInit(region_match_vec_dcache_evict_s0).asUInt & s1_replace_mask_w).orR\n\
      352:   val s0_do_dcache_evict = io.s0_dcache_evict.fire && any_region_dcache_evict_match\n\
      353: \n354:   io.s0_dcache_evict.ready := !s0_lookup_valid && !s0_dcache_evict_conflict\n\
      355: \n356:   val s0_region_hit = any_region_match\n357:   val s0_cross_region_hit
      = any_region_m1_match || any_region_p1_match\n358:   val s0_alloc = s0_lookup_valid
      && !s0_region_hit && !s0_match_prev\n359:   val s0_pf_gen_match_vec = valids.indices.map(i
      => {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 456-467
    context: "456: \n457:   val s1_pf_gen_vaddr_inc = Cat(0.U, s1_region_vaddr(REGION_TAG_WIDTH
      - 1, 0), s1_region_offset) + io.act_stride\n458:   val s1_pf_gen_vaddr_dec =
      Cat(0.U, s1_region_vaddr(REGION_TAG_WIDTH - 1, 0), s1_region_offset) - io.act_stride\n\
      459:   val s1_vaddr_inc_cross_page = s1_pf_gen_vaddr_inc(BLOCK_ADDR_PAGE_BIT)
      =/= s1_region_vaddr(REGION_ADDR_PAGE_BIT)\n460:   val s1_vaddr_dec_cross_page
      = s1_pf_gen_vaddr_dec(BLOCK_ADDR_PAGE_BIT) =/= s1_region_vaddr(REGION_ADDR_PAGE_BIT)\n\
      461:   val s1_vaddr_inc_cross_max_lim = s1_pf_gen_vaddr_inc.head(1).asBool\n\
      462:   val s1_vaddr_dec_cross_max_lim = s1_pf_gen_vaddr_dec.head(1).asBool\n\
      463: \n464:   //val s1_pf_gen_vaddr_p1 = s1_region_vaddr(REGION_TAG_WIDTH -
      1, 0) + 1.U\n465:   //val s1_pf_gen_vaddr_m1 = s1_region_vaddr(REGION_TAG_WIDTH
      - 1, 0) - 1.U\n466:   val s1_pf_gen_vaddr = Cat(\n467:     s1_region_vaddr(REGION_ADDR_BITS
      - 1, REGION_TAG_WIDTH),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 464-475
    context: "464:   //val s1_pf_gen_vaddr_p1 = s1_region_vaddr(REGION_TAG_WIDTH -
      1, 0) + 1.U\n465:   //val s1_pf_gen_vaddr_m1 = s1_region_vaddr(REGION_TAG_WIDTH
      - 1, 0) - 1.U\n466:   val s1_pf_gen_vaddr = Cat(\n467:     s1_region_vaddr(REGION_ADDR_BITS
      - 1, REGION_TAG_WIDTH),\n468:     Mux(s1_pf_gen_decr_mode,\n469:       s1_pf_gen_vaddr_dec.tail(1).head(REGION_TAG_WIDTH),\n\
      470:       s1_pf_gen_vaddr_inc.tail(1).head(REGION_TAG_WIDTH)\n471:     )\n\
      472:   )\n473:   val s1_pf_gen_offset = Mux(s1_pf_gen_decr_mode,\n474:     s1_pf_gen_vaddr_dec(REGION_OFFSET
      - 1, 0),\n475:     s1_pf_gen_vaddr_inc(REGION_OFFSET - 1, 0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 606-616
    context: "606:   }))\n607:   val pht_valids_enable = WireInit(VecInit(Seq.fill(PHT_SETS)
      {false.B}))\n608:   val pht_valids_next = WireInit(pht_valids_reg)\n609:   for(j
      <- 0 until PHT_SETS){\n610:     when(pht_valids_enable(j)){\n611:       (0 until
      smsParams.pht_ways).foreach(i => pht_valids_reg(i)(j) := pht_valids_next(i)(j))\n\
      612:     }\n613:   }\n614: \n615:   val replacement = Seq.fill(PHT_SETS) { ReplacementPolicy.fromString(\"\
      plru\", smsParams.pht_ways) }\n616: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 620-643
    context: "620: \n621:   val evict_queue = Module(new OverrideableQueue(new AGTEntry,
      smsParams.pht_lookup_queue_size))\n622:   evict_queue.io.in := io.agt_update\n\
      623:   val evict = evict_queue.io.out\n624: \n625:   XSPerfAccumulate(\"sms_pht_lookup_in\"\
      , lookup_queue.io.in.fire)\n626:   XSPerfAccumulate(\"sms_pht_lookup_out\",
      lookup_queue.io.out.fire)\n627:   XSPerfAccumulate(\"sms_pht_evict_in\", evict_queue.io.in.fire)\n\
      628:   XSPerfAccumulate(\"sms_pht_evict_out\", evict_queue.io.out.fire)\n629:\
      \ \n630:   val s3_ram_en = Wire(Bool())\n631:   val s1_valid = Wire(Bool())\n\
      632:   // if s1.raddr == s2.waddr or s3 is using ram port, block s1\n633:  \
      \ val s1_wait = Wire(Bool())\n634:   // pipe s0: select an op from [lookup,
      update], generate ram read addr\n635:   val s0_valid = lookup.valid || evict.valid\n\
      636: \n637:   evict.ready := !s1_valid || !s1_wait\n638:   lookup.ready := evict.ready
      && !evict.valid\n639: \n640:   val s0_ram_raddr = Mux(evict.valid,\n641:   \
      \  evict.bits.pht_index,\n642:     lookup.bits.pht_index\n643:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 653-665
    context: "653:   val s0_has_been_single_update = evict.bits.has_been_signal_updated\n\
      654:   val s0_region_bit_single = evict.bits.region_bit_single\n655: \n656:\
      \   // pipe s1: send addr to ram\n657:   val s1_valid_r = RegInit(false.B)\n\
      658:   s1_valid_r := Mux(s1_valid && s1_wait, true.B, s0_valid)\n659:   s1_valid
      := s1_valid_r\n660:   val s1_reg_en = s0_valid && (!s1_wait || !s1_valid)\n\
      661:   val s1_ram_raddr = RegEnable(s0_ram_raddr, s1_reg_en)\n662:   val s1_tag
      = RegEnable(s0_tag, s1_reg_en)\n663:   val s1_access_cnt_signal = RegEnable(s0_access_cnt_signal,
      s1_reg_en)\n664:   val s1_region_bits = RegEnable(s0_region_bits, s1_reg_en)\n\
      665:   val s1_decr_mode = RegEnable(s0_decr_mode, s1_reg_en)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 680-690
    context: "680:   )\n681:   val s1_hist_update_mask = Cat(\n682:     Fill(REGION_BLKS
      - 1, true.B), 0.U((REGION_BLKS - 1).W)\n683:   ) >> s1_region_offset\n684: \
      \  val s1_hist_bits = Cat(\n685:     s1_region_bits.head(REGION_BLKS - 1) >>
      s1_region_offset,\n686:     (Cat(\n687:       s1_region_bits.tail(1), 0.U((REGION_BLKS
      - 1).W)\n688:     ) >> s1_region_offset)(REGION_BLKS - 2, 0)\n689:   )\n690:\
      \   val s1_hist_single_bit = Cat("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 686-696
    context: "686:     (Cat(\n687:       s1_region_bits.tail(1), 0.U((REGION_BLKS
      - 1).W)\n688:     ) >> s1_region_offset)(REGION_BLKS - 2, 0)\n689:   )\n690:\
      \   val s1_hist_single_bit = Cat(\n691:     s1_region_bit_single.head(REGION_BLKS
      - 1) >> s1_region_offset,\n692:     (Cat(\n693:       s1_region_bit_single.tail(1),
      0.U((REGION_BLKS - 1).W)\n694:     ) >> s1_region_offset)(REGION_BLKS - 2, 0)\n\
      695:   )\n696: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 693-704
    context: "693:       s1_region_bit_single.tail(1), 0.U((REGION_BLKS - 1).W)\n\
      694:     ) >> s1_region_offset)(REGION_BLKS - 2, 0)\n695:   )\n696: \n697: \
      \  // pipe s2: generate ram write addr/data\n698:   val s2_valid = GatedValidRegNext(s1_valid
      && !s1_wait, false.B)\n699:   val s2_reg_en = s1_valid && !s1_wait\n700:   val
      s2_hist_update_mask = RegEnable(s1_hist_update_mask, s2_reg_en)\n701:   val
      s2_single_update = RegEnable(s1_single_update, s2_reg_en)\n702:   val s2_has_been_single_update
      = RegEnable(s1_has_been_single_update, s2_reg_en)\n703:   val s2_hist_bits =
      RegEnable(s1_hist_bits, s2_reg_en)\n704:   val s2_hist_bit_single = RegEnable(s1_hist_single_bit,
      s2_reg_en)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 720-742
    context: "720:   val s2_hit_vec = s2_tag_match_vec.zip(s2_pht_valids).map({\n\
      721:     case (tag_match, v) => v && tag_match\n722:   })\n723: \n724:   //distinguish
      single update and evict update\n725:   val s2_hist_update = s2_ram_rdata.map(way
      => VecInit(way.hist.zipWithIndex.map({\n726:     case (h, i) =>\n727:      \
      \ val do_update = s2_hist_update_mask(i)\n728:       val hist_updated = Mux(!s2_single_update,\n\
      729:                             Mux(s2_has_been_single_update,\n730:      \
      \                         Mux(s2_hist_bits(i), h, Mux(h === 0.U, 0.U, h - 1.U)),
      Mux(s2_hist_bits(i),Mux(h.andR, h, h + 1.U), Mux(h === 0.U, 0.U, h - 1.U))),\n\
      731:                                 Mux(s2_hist_bit_single(i), Mux(h.andR,
      h, Mux(h===0.U, h+2.U, h+1.U)), h)\n732:                              )\n733:\
      \       Mux(do_update, hist_updated, h)\n734:   })))\n735: \n736: \n737:   val
      s2_hist_pf_gen = Mux1H(s2_hit_vec, s2_ram_rdata.map(way => VecInit(way.hist.map(_.head(1))).asUInt))\n\
      738:   val s2_new_hist = VecInit(s2_hist_bits.asBools.map(b => Cat(0.U((PHT_HIST_BITS
      - 1).W), b)))\n739:   val s2_new_hist_single = VecInit(s2_hist_bit_single.asBools.map(b
      => Cat(0.U((PHT_HIST_BITS - 1).W), b)))\n740:   val s2_new_hist_real = Mux(s2_single_update,s2_new_hist_single,s2_new_hist)\n\
      741:   val s2_pht_hit = Cat(s2_hit_vec).orR\n742:   // update when valid bits
      over 4"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 739-749
    context: "739:   val s2_new_hist_single = VecInit(s2_hist_bit_single.asBools.map(b
      => Cat(0.U((PHT_HIST_BITS - 1).W), b)))\n740:   val s2_new_hist_real = Mux(s2_single_update,s2_new_hist_single,s2_new_hist)\n\
      741:   val s2_pht_hit = Cat(s2_hit_vec).orR\n742:   // update when valid bits
      over 4\n743:   val signal_update_write = Mux(!s2_single_update, true.B, s2_pht_hit
      || s2_single_update && (s2_access_cnt_signal >4.U) )\n744:   val s2_hist = Mux(s2_pht_hit,
      Mux1H(s2_hit_vec, s2_hist_update), s2_new_hist_real)\n745:   val s2_repl_way_mask
      = UIntToOH(s2_replace_way)\n746:   val s2_incr_region_vaddr = s2_region_vaddr
      + 1.U\n747:   val s2_decr_region_vaddr = s2_region_vaddr - 1.U\n748: \n749: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 747-779
    context: "747:   val s2_decr_region_vaddr = s2_region_vaddr - 1.U\n748: \n749:\
      \ \n750: \n751:   // pipe s3: send addr/data to ram, gen pf_req\n752:   val
      s3_valid = GatedValidRegNext(s2_valid && signal_update_write, false.B)\n753:\
      \   val s3_evict = RegEnable(s2_evict, s2_valid)\n754:   val s3_hist = RegEnable(s2_hist,
      s2_valid)\n755:   val s3_hist_pf_gen = RegEnable(s2_hist_pf_gen, s2_valid)\n\
      756: \n757:   val s3_hist_update_mask = RegEnable(s2_hist_update_mask.asUInt,
      s2_valid)\n758: \n759:   val s3_region_offset = RegEnable(s2_region_offset,
      s2_valid)\n760:   val s3_region_offset_mask = RegEnable(s2_region_offset_mask,
      s2_valid)\n761:   val s3_decr_mode = RegEnable(s2_decr_mode, s2_valid)\n762:\
      \   val s3_region_paddr = RegEnable(s2_region_paddr, s2_valid)\n763:   val s3_region_vaddr
      = RegEnable(s2_region_vaddr, s2_valid)\n764:   val s3_pht_tag = RegEnable(s2_tag,
      s2_valid)\n765:   val s3_hit_vec = s2_hit_vec.map(h => RegEnable(h, s2_valid))\n\
      766:   val s3_hit = Cat(s3_hit_vec).orR\n767:   val s3_hit_way = OHToUInt(s3_hit_vec)\n\
      768:   val s3_repl_way = RegEnable(s2_replace_way, s2_valid)\n769:   val s3_repl_way_mask
      = RegEnable(s2_repl_way_mask, s2_valid)\n770:   val s3_repl_update_mask = RegEnable(VecInit((0
      until PHT_SETS).map(i => i.U === s2_ram_waddr)), s2_valid)\n771:   val s3_ram_waddr
      = RegEnable(s2_ram_waddr, s2_valid)\n772:   val s3_incr_region_vaddr = RegEnable(s2_incr_region_vaddr,
      s2_valid)\n773:   val s3_decr_region_vaddr = RegEnable(s2_decr_region_vaddr,
      s2_valid)\n774:   s3_ram_en := s3_valid && s3_evict\n775:   val s3_ram_wdata
      = Wire(new PhtEntry())\n776:   s3_ram_wdata.hist := s3_hist\n777:   s3_ram_wdata.tag
      := s3_pht_tag\n778:   s3_ram_wdata.decr_mode := s3_decr_mode\n779: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 775-785
    context: "775:   val s3_ram_wdata = Wire(new PhtEntry())\n776:   s3_ram_wdata.hist
      := s3_hist\n777:   s3_ram_wdata.tag := s3_pht_tag\n778:   s3_ram_wdata.decr_mode
      := s3_decr_mode\n779: \n780:   s1_wait := (s2_valid && s2_evict && s2_ram_waddr
      === s1_ram_raddr) || s3_ram_en\n781: \n782:   for((valids, way_idx) <- pht_valids_next.zipWithIndex){\n\
      783:     val update_way = s3_repl_way_mask(way_idx)\n784:     for((v, set_idx)
      <- valids.zipWithIndex){\n785:       val update_set = s3_repl_update_mask(set_idx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 781-791
    context: "781: \n782:   for((valids, way_idx) <- pht_valids_next.zipWithIndex){\n\
      783:     val update_way = s3_repl_way_mask(way_idx)\n784:     for((v, set_idx)
      <- valids.zipWithIndex){\n785:       val update_set = s3_repl_update_mask(set_idx)\n\
      786:       when(s3_valid && s3_evict && !s3_hit && update_set && update_way){\n\
      787:         pht_valids_enable(set_idx) := true.B\n788:         v := true.B\n\
      789:       }\n790:     }\n791:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 788-798
    context: "788:         v := true.B\n789:       }\n790:     }\n791:   }\n792: \
      \  for((r, i) <- replacement.zipWithIndex){\n793:     when(s3_valid && s3_repl_update_mask(i)){\n\
      794:       when(s3_hit){\n795:         r.access(s3_hit_way)\n796:       }.elsewhen(s3_evict){\n\
      797:         r.access(s3_repl_way)\n798:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 803-833
    context: "803:     VecInit(s3_hit_vec).asUInt,\n804:     s3_repl_way_mask,\n805:\
      \   ).asUInt\n806: \n807:   pht_ram.io.r(\n808:     s1_valid, s1_ram_raddr\n\
      809:   )\n810:   pht_ram.io.w(\n811:     s3_ram_en, s3_ram_wdata, s3_ram_waddr,
      s3_way_mask\n812:   )\n813:   when(s3_valid && s3_hit){\n814:     assert(!Cat(s3_hit_vec).andR,
      \"sms_pht: multi-hit!\")\n815:   }\n816: \n817:   // generate pf req if hit\n\
      818:   val s3_hist_hi = s3_hist_pf_gen.head(REGION_BLKS - 1)\n819:   val s3_hist_lo
      = s3_hist_pf_gen.tail(REGION_BLKS - 1)\n820:   val s3_hist_hi_shifted = (Cat(0.U((REGION_BLKS
      - 1).W), s3_hist_hi) << s3_region_offset)(2 * (REGION_BLKS - 1) - 1, 0)\n821:\
      \   val s3_hist_lo_shifted = (Cat(0.U((REGION_BLKS - 1).W), s3_hist_lo) << s3_region_offset)(2
      * (REGION_BLKS - 1) - 1, 0)\n822:   val s3_cur_region_bits = Cat(s3_hist_hi_shifted.tail(REGION_BLKS
      - 1), 0.U(1.W)) |\n823:     Cat(0.U(1.W), s3_hist_lo_shifted.head(REGION_BLKS
      - 1))\n824:   val s3_incr_region_bits = Cat(0.U(1.W), s3_hist_hi_shifted.head(REGION_BLKS
      - 1))\n825:   val s3_decr_region_bits = Cat(s3_hist_lo_shifted.tail(REGION_BLKS
      - 1), 0.U(1.W))\n826:   val s3_pf_gen_valid = s3_valid && s3_hit && !s3_evict\n\
      827:   val s3_cur_region_valid =  s3_pf_gen_valid && (s3_hist_pf_gen & s3_hist_update_mask).orR\n\
      828:   val s3_incr_region_valid = s3_pf_gen_valid && (s3_hist_hi & (~s3_hist_update_mask.head(REGION_BLKS
      - 1)).asUInt).orR\n829:   val s3_decr_region_valid = s3_pf_gen_valid && (s3_hist_lo
      & (~s3_hist_update_mask.tail(REGION_BLKS - 1)).asUInt).orR\n830:   val s3_incr_alias_bits
      = get_alias_bits(s3_incr_region_vaddr)\n831:   val s3_decr_alias_bits = get_alias_bits(s3_decr_region_vaddr)\n\
      832:   val s3_incr_region_paddr = Cat(\n833:     s3_region_paddr(REGION_ADDR_BITS
      - 1, REGION_ADDR_PAGE_BIT),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 859-869
    context: "859:     s4_pf_gen_cur_region.region_bits := s3_cur_region_bits\n860:\
      \     s4_pf_gen_cur_region.paddr_valid := true.B\n861:     s4_pf_gen_cur_region.decr_mode
      := false.B\n862:   }\n863:   s4_pf_gen_incr_region_valid := s3_incr_region_valid
      ||\n864:     (!pf_gen_req_arb.io.in(1).ready && s4_pf_gen_incr_region_valid)\n\
      865:   when(s3_incr_region_valid){\n866:     s4_pf_gen_incr_region.region_addr
      := Mux(s3_incr_crosspage, s3_incr_region_vaddr, s3_incr_region_paddr)\n867:\
      \     s4_pf_gen_incr_region.alias_bits := s3_incr_alias_bits\n868:     s4_pf_gen_incr_region.region_tag
      := s3_incr_region_tag\n869:     s4_pf_gen_incr_region.region_bits := s3_incr_region_bits"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 869-879
    context: "869:     s4_pf_gen_incr_region.region_bits := s3_incr_region_bits\n\
      870:     s4_pf_gen_incr_region.paddr_valid := !s3_incr_crosspage\n871:     s4_pf_gen_incr_region.decr_mode
      := false.B\n872:   }\n873:   s4_pf_gen_decr_region_valid := s3_decr_region_valid
      ||\n874:     (!pf_gen_req_arb.io.in(2).ready && s4_pf_gen_decr_region_valid)\n\
      875:   when(s3_decr_region_valid){\n876:     s4_pf_gen_decr_region.region_addr
      := Mux(s3_decr_crosspage, s3_decr_region_vaddr, s3_decr_region_paddr)\n877:\
      \     s4_pf_gen_decr_region.alias_bits := s3_decr_alias_bits\n878:     s4_pf_gen_decr_region.region_tag
      := s3_decr_region_tag\n879:     s4_pf_gen_decr_region.region_bits := s3_decr_region_bits"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 879-891
    context: "879:     s4_pf_gen_decr_region.region_bits := s3_decr_region_bits\n\
      880:     s4_pf_gen_decr_region.paddr_valid := !s3_decr_crosspage\n881:     s4_pf_gen_decr_region.decr_mode
      := true.B\n882:   }\n883: \n884:   pf_gen_req_arb.io.in.head.valid := s4_pf_gen_cur_region_valid\n\
      885:   pf_gen_req_arb.io.in.head.bits := s4_pf_gen_cur_region\n886:   pf_gen_req_arb.io.in.head.bits.debug_source_type
      := HW_PREFETCH_PHT_CUR.U\n887:   pf_gen_req_arb.io.in(1).valid := s4_pf_gen_incr_region_valid\n\
      888:   pf_gen_req_arb.io.in(1).bits := s4_pf_gen_incr_region\n889:   pf_gen_req_arb.io.in(1).bits.debug_source_type
      := HW_PREFETCH_PHT_INC.U\n890:   pf_gen_req_arb.io.in(2).valid := s4_pf_gen_decr_region_valid\n\
      891:   pf_gen_req_arb.io.in(2).bits := s4_pf_gen_decr_region"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 888-898
    context: "888:   pf_gen_req_arb.io.in(1).bits := s4_pf_gen_incr_region\n889: \
      \  pf_gen_req_arb.io.in(1).bits.debug_source_type := HW_PREFETCH_PHT_INC.U\n\
      890:   pf_gen_req_arb.io.in(2).valid := s4_pf_gen_decr_region_valid\n891:  \
      \ pf_gen_req_arb.io.in(2).bits := s4_pf_gen_decr_region\n892:   pf_gen_req_arb.io.in(2).bits.debug_source_type
      := HW_PREFETCH_PHT_DEC.U\n893:   pf_gen_req_arb.io.out.ready := true.B\n894:\
      \ \n895:   io.pf_gen_req.valid := pf_gen_req_arb.io.out.valid\n896:   io.pf_gen_req.bits
      := pf_gen_req_arb.io.out.bits\n897: \n898:   XSPerfAccumulate(\"sms_pht_update\"\
      , io.agt_update.valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 894-911
    context: "894: \n895:   io.pf_gen_req.valid := pf_gen_req_arb.io.out.valid\n896:\
      \   io.pf_gen_req.bits := pf_gen_req_arb.io.out.bits\n897: \n898:   XSPerfAccumulate(\"\
      sms_pht_update\", io.agt_update.valid)\n899:   XSPerfAccumulate(\"sms_pht_update_hit\"\
      , s2_valid && s2_evict && s2_pht_hit)\n900:   XSPerfAccumulate(\"sms_pht_lookup\"\
      , io.s2_agt_lookup.valid)\n901:   XSPerfAccumulate(\"sms_pht_lookup_hit\", s2_valid
      && !s2_evict && s2_pht_hit)\n902:   for(i <- 0 until smsParams.pht_ways){\n\
      903:     XSPerfAccumulate(s\"sms_pht_write_way_$i\", pht_ram.io.w.req.fire &&
      pht_ram.io.w.req.bits.waymask.get(i))\n904:   }\n905:   for(i <- 0 until PHT_SETS){\n\
      906:     XSPerfAccumulate(s\"sms_pht_write_set_$i\", pht_ram.io.w.req.fire &&
      pht_ram.io.w.req.bits.setIdx === i.U)\n907:   }\n908:   XSPerfAccumulate(s\"\
      sms_pht_pf_gen\", io.pf_gen_req.valid)\n909: }\n910: \n911: class PrefetchFilterEntry()(implicit
      p: Parameters) extends XSBundle with HasSMSModuleHelper {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 941-955
    context: "941:   io.l2_pf_addr.valid := pf_req_arb.io.out.valid\n942:   io.l2_pf_addr.bits
      := pf_req_arb.io.out.bits\n943:   io.pf_alias_bits := Mux1H(entries.zipWithIndex.map({\n\
      944:     case (entry, i) => (i.U === pf_req_arb.io.chosen) -> entry.alias_bits\n\
      945:   }))\n946:   pf_req_arb.io.out.ready := true.B\n947: \n948:   io.debug_source_type
      := VecInit(entries.map(_.debug_source_type))(pf_req_arb.io.chosen)\n949: \n\
      950:   val s1_valid = Wire(Bool())\n951:   val s1_hit = Wire(Bool())\n952: \
      \  val s1_replace_vec = Wire(UInt(smsParams.pf_filter_size.W))\n953:   val s1_tlb_fire_vec
      = Wire(UInt(smsParams.pf_filter_size.W))\n954:   val s2_tlb_fire_vec = Wire(UInt(smsParams.pf_filter_size.W))\n\
      955:   val s3_tlb_fire_vec = Wire(UInt(smsParams.pf_filter_size.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 960-970
    context: "960:   // s0: entries lookup\n961:   val s0_gen_req = io.gen_req.bits\n\
      962:   val s0_match_prev = prev_valid && (s0_gen_req.region_tag === prev_gen_req.region_tag)\n\
      963:   val s0_gen_req_valid = io.gen_req.valid && !s0_match_prev\n964:   val
      s0_match_vec = valids.indices.map(i => {\n965:     valids(i) && entries(i).region_tag
      === s0_gen_req.region_tag && !(s1_valid && !s1_hit && s1_replace_vec(i))\n966:\
      \   })\n967:   val s0_any_matched = Cat(s0_match_vec).orR\n968:   val s0_replace_vec
      = UIntToOH(replacement.way)\n969:   val s0_hit = s0_gen_req_valid && s0_any_matched\n\
      970: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 967-980
    context: "967:   val s0_any_matched = Cat(s0_match_vec).orR\n968:   val s0_replace_vec
      = UIntToOH(replacement.way)\n969:   val s0_hit = s0_gen_req_valid && s0_any_matched\n\
      970: \n971:   for(((v, ent), i) <- valids.zip(entries).zipWithIndex){\n972:\
      \     val is_evicted = s1_valid && s1_replace_vec(i)\n973:     tlb_req_arb.io.in(i).valid
      := v && not_tlbing_vec(i) && !ent.paddr_valid && !is_evicted\n974:     tlb_req_arb.io.in(i).bits.vaddr
      := Cat(ent.region_addr, 0.U(log2Up(REGION_SIZE).W))\n975:     tlb_req_arb.io.in(i).bits.cmd
      := TlbCmd.read\n976:     tlb_req_arb.io.in(i).bits.isPrefetch := true.B\n977:\
      \     tlb_req_arb.io.in(i).bits.size := 3.U\n978:     tlb_req_arb.io.in(i).bits.kill
      := false.B\n979:     tlb_req_arb.io.in(i).bits.no_translate := false.B\n980:\
      \     tlb_req_arb.io.in(i).bits.fullva := 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1001-1012
    context: "1001:     )\n1002:     pf_req_arb.io.in(i).valid := v && Cat(pending_req_vec).orR
      && ent.paddr_valid && !is_evicted\n1003:     pf_req_arb.io.in(i).bits := pf_addr\n\
      1004:   }\n1005: \n1006:   val s0_tlb_fire_vec = VecInit(tlb_req_arb.io.in.map(_.fire))\n\
      1007:   val s0_pf_fire_vec = VecInit(pf_req_arb.io.in.map(_.fire))\n1008: \n\
      1009:   val s0_update_way = OHToUInt(s0_match_vec)\n1010:   val s0_replace_way
      = replacement.way\n1011:   val s0_access_way = Mux(s0_any_matched, s0_update_way,
      s0_replace_way)\n1012:   when(s0_gen_req_valid){"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1019-1032
    context: "1019:   val s1_gen_req = RegEnable(s0_gen_req, s0_gen_req_valid)\n1020:\
      \   val s1_replace_vec_r = RegEnable(s0_replace_vec, s0_gen_req_valid && !s0_hit)\n\
      1021:   val s1_update_vec = RegEnable(VecInit(s0_match_vec).asUInt, s0_gen_req_valid
      && s0_hit)\n1022:   val s1_tlb_fire_vec_r = GatedValidRegNext(s0_tlb_fire_vec)\n\
      1023:   // tlb req will latch one cycle after tlb_arb\n1024:   val s1_tlb_req_valid
      = GatedValidRegNext(tlb_req_arb.io.out.fire)\n1025:   val s1_tlb_req_bits  =
      RegEnable(tlb_req_arb.io.out.bits, tlb_req_arb.io.out.fire)\n1026:   val s1_alloc_entry
      = Wire(new PrefetchFilterEntry())\n1027:   s1_valid := s1_valid_r\n1028:   s1_hit
      := s1_hit_r\n1029:   s1_replace_vec := s1_replace_vec_r\n1030:   s1_tlb_fire_vec
      := s1_tlb_fire_vec_r.asUInt\n1031:   s1_alloc_entry.region_tag := s1_gen_req.region_tag\n\
      1032:   s1_alloc_entry.region_addr := s1_gen_req.region_addr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1034-1048
    context: "1034:   s1_alloc_entry.paddr_valid := s1_gen_req.paddr_valid\n1035:\
      \   s1_alloc_entry.decr_mode := s1_gen_req.decr_mode\n1036:   s1_alloc_entry.filter_bits
      := 0.U\n1037:   s1_alloc_entry.alias_bits := s1_gen_req.alias_bits\n1038:  \
      \ s1_alloc_entry.debug_source_type := s1_gen_req.debug_source_type\n1039:  \
      \ io.tlb_req.req.valid := s1_tlb_req_valid && !((s1_tlb_fire_vec & s1_replace_vec).orR
      && s1_valid && !s1_hit)\n1040:   io.tlb_req.req.bits := s1_tlb_req_bits\n1041:\
      \   io.tlb_req.resp.ready := true.B\n1042:   io.tlb_req.req_kill := false.B\n\
      1043:   tlb_req_arb.io.out.ready := true.B\n1044: \n1045:   // s2: get response
      from tlb\n1046:   val s2_tlb_fire_vec_r = GatedValidRegNext(s1_tlb_fire_vec_r)\n\
      1047:   s2_tlb_fire_vec := s2_tlb_fire_vec_r.asUInt\n1048: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1046-1056
    context: "1046:   val s2_tlb_fire_vec_r = GatedValidRegNext(s1_tlb_fire_vec_r)\n\
      1047:   s2_tlb_fire_vec := s2_tlb_fire_vec_r.asUInt\n1048: \n1049:   // s3:
      get pmp response form PMPChecker\n1050:   val s3_tlb_fire_vec_r = GatedValidRegNext(s2_tlb_fire_vec_r)\n\
      1051:   val s3_tlb_resp_fire = RegNext(io.tlb_req.resp.fire)\n1052:   val s3_tlb_resp
      = RegEnable(io.tlb_req.resp.bits, io.tlb_req.resp.valid)\n1053:   val s3_pmp_resp
      = io.pmp_resp\n1054:   val s3_update_valid = s3_tlb_resp_fire && !s3_tlb_resp.miss\n\
      1055:   val s3_drop = s3_update_valid && (\n1056:     // page/access fault"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1052-1064
    context: "1052:   val s3_tlb_resp = RegEnable(io.tlb_req.resp.bits, io.tlb_req.resp.valid)\n\
      1053:   val s3_pmp_resp = io.pmp_resp\n1054:   val s3_update_valid = s3_tlb_resp_fire
      && !s3_tlb_resp.miss\n1055:   val s3_drop = s3_update_valid && (\n1056:    \
      \ // page/access fault\n1057:     s3_tlb_resp.excp.head.pf.ld || s3_tlb_resp.excp.head.gpf.ld
      || s3_tlb_resp.excp.head.af.ld ||\n1058:     // uncache\n1059:     s3_pmp_resp.mmio
      || Pbmt.isUncache(s3_tlb_resp.pbmt.head) ||\n1060:     // pmp access fault\n\
      1061:     s3_pmp_resp.ld\n1062:   )\n1063:   s3_tlb_fire_vec := s3_tlb_fire_vec_r.asUInt\n\
      1064: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1061-1074
    context: "1061:     s3_pmp_resp.ld\n1062:   )\n1063:   s3_tlb_fire_vec := s3_tlb_fire_vec_r.asUInt\n\
      1064: \n1065:   for(((v, ent), i) <- valids.zip(entries).zipWithIndex){\n1066:\
      \     val alloc = s1_valid && !s1_hit && s1_replace_vec(i)\n1067:     val update
      = s1_valid && s1_hit && s1_update_vec(i)\n1068:     // for pf: use s0 data\n\
      1069:     val pf_fired = s0_pf_fire_vec(i)\n1070:     val tlb_fired = s3_tlb_fire_vec(i)
      && s3_update_valid\n1071:     when(tlb_fired){\n1072:       when(s3_drop){\n\
      1073:         v := false.B\n1074:       }.otherwise{"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1071-1081
    context: "1071:     when(tlb_fired){\n1072:       when(s3_drop){\n1073:      \
      \   v := false.B\n1074:       }.otherwise{\n1075:         ent.paddr_valid :=
      !s3_tlb_resp.miss\n1076:         ent.region_addr := region_addr(s3_tlb_resp.paddr.head)\n\
      1077:       }\n1078:     }\n1079:     when(update){\n1080:       ent.region_bits
      := ent.region_bits | s1_gen_req.region_bits\n1081:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1077-1087
    context: "1077:       }\n1078:     }\n1079:     when(update){\n1080:       ent.region_bits
      := ent.region_bits | s1_gen_req.region_bits\n1081:     }\n1082:     when(pf_fired){\n\
      1083:       val curr_bit = UIntToOH(block_addr(pf_req_arb.io.in(i).bits)(REGION_OFFSET
      - 1, 0))\n1084:       ent.filter_bits := ent.filter_bits | curr_bit\n1085: \
      \    }\n1086:     when(alloc){\n1087:       ent := s1_alloc_entry"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1086-1110
    context: "1086:     when(alloc){\n1087:       ent := s1_alloc_entry\n1088:   \
      \    v := true.B\n1089:     }\n1090:   }\n1091:   when(s1_valid && s1_hit){\n\
      1092:     assert(PopCount(s1_update_vec) === 1.U, \"sms_pf_filter: multi-hit\"\
      )\n1093:   }\n1094:   assert(!io.tlb_req.resp.fire || Cat(s2_tlb_fire_vec).orR,
      \"sms_pf_filter: tlb resp fires, but no tlb req from tlb_req_arb 2 cycles ago\"\
      )\n1095: \n1096:   XSPerfAccumulate(\"sms_pf_filter_recv_req\", io.gen_req.valid)\n\
      1097:   XSPerfAccumulate(\"sms_pf_filter_hit\", s1_valid && s1_hit)\n1098: \
      \  XSPerfAccumulate(\"sms_pf_filter_tlb_req\", io.tlb_req.req.fire)\n1099: \
      \  XSPerfAccumulate(\"sms_pf_filter_tlb_resp_miss\", io.tlb_req.resp.fire &&
      io.tlb_req.resp.bits.miss)\n1100:   XSPerfAccumulate(\"sms_pf_filter_tlb_resp_drop\"\
      , s3_drop)\n1101:   XSPerfAccumulate(\"sms_pf_filter_tlb_resp_drop_by_pf_or_af\"\
      ,\n1102:     s3_update_valid && (s3_tlb_resp.excp.head.pf.ld || s3_tlb_resp.excp.head.gpf.ld
      || s3_tlb_resp.excp.head.af.ld)\n1103:   )\n1104:   XSPerfAccumulate(\"sms_pf_filter_tlb_resp_drop_by_uncache\"\
      ,\n1105:     s3_update_valid && (s3_pmp_resp.mmio || Pbmt.isUncache(s3_tlb_resp.pbmt.head))\n\
      1106:   )\n1107:   XSPerfAccumulate(\"sms_pf_filter_tlb_resp_drop_by_pmp_af\"\
      ,\n1108:     s3_update_valid && (s3_pmp_resp.ld)\n1109:   )\n1110:   for(i <-
      0 until smsParams.pf_filter_size){"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1175-1189
    context: "1175:       entries(allocPtr.value) := req\n1176:     }\n1177:   }\n\
      1178:   val allocNum = PopCount(canAlloc)\n1179: \n1180:   enqPtrExt.foreach{case
      x => when(canAlloc.asUInt.orR) {x := x + allocNum} }\n1181: \n1182:   io.train_req.valid
      := false.B\n1183:   io.train_req.bits := DontCare\n1184:   valids.zip(entries).zipWithIndex.foreach
      {\n1185:     case((valid, entry), i) => {\n1186:       when(deqPtr === i.U)
      {\n1187:         io.train_req.valid := valid\n1188:         io.train_req.bits
      := entry\n1189:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1201-1211
    context: "1201: \n1202:   val raw_enq_pattern = Cat(reqs_vls)\n1203:   val filtered_enq_pattern
      = Cat(needAlloc)\n1204:   val actual_enq_pattern = Cat(canAlloc)\n1205:   XSPerfAccumulate(\"\
      sms_train_filter_enq\", allocNum > 0.U)\n1206:   XSPerfAccumulate(\"sms_train_filter_deq\"\
      , io.train_req.fire)\n1207:   def toBinary(n: Int): String = n match {\n1208:\
      \     case 0|1 => s\"$n\"\n1209:     case _   => s\"${toBinary(n/2)}${n%2}\"\
      \n1210:   }\n1211:   for(i <- 0 until (1 << enqLen)) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1216-1226
    context: "1216: }\n1217: \n1218: class SMSPrefetcher()(implicit p: Parameters)
      extends BasePrefecher with HasSMSModuleHelper with HasL1PrefetchSourceParameter
      {\n1219:   import freechips.rocketchip.util._\n1220: \n1221:   val io_agt_en
      = IO(Input(Bool()))\n1222:   val io_stride_en = IO(Input(Bool()))\n1223:   val
      io_pht_en = IO(Input(Bool()))\n1224:   val io_act_threshold = IO(Input(UInt(REGION_OFFSET.W)))\n\
      1225:   val io_act_stride = IO(Input(UInt(6.W)))\n1226:   val io_dcache_evict
      = IO(Flipped(DecoupledIO(new AGTEvictReq)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1231-1241
    context: "1231:   train_filter.io.st_in <> io.st_in\n1232: \n1233:   val train_ld
      = train_filter.io.train_req.bits\n1234: \n1235:   val train_block_tag = block_hash_tag(train_ld.vaddr)\n\
      1236:   val train_region_tag = train_block_tag.head(REGION_TAG_WIDTH)\n1237:\
      \ \n1238:   val train_region_addr_raw = region_addr(train_ld.vaddr)(REGION_TAG_WIDTH
      + 2 * VADDR_HASH_WIDTH - 1, 0)\n1239:   val train_region_addr_p1 = Cat(0.U(1.W),
      train_region_addr_raw) + 1.U\n1240:   val train_region_addr_m1 = Cat(0.U(1.W),
      train_region_addr_raw) - 1.U\n1241:   // addr_p1 or addr_m1 is valid?"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1237-1248
    context: "1237: \n1238:   val train_region_addr_raw = region_addr(train_ld.vaddr)(REGION_TAG_WIDTH
      + 2 * VADDR_HASH_WIDTH - 1, 0)\n1239:   val train_region_addr_p1 = Cat(0.U(1.W),
      train_region_addr_raw) + 1.U\n1240:   val train_region_addr_m1 = Cat(0.U(1.W),
      train_region_addr_raw) - 1.U\n1241:   // addr_p1 or addr_m1 is valid?\n1242:\
      \   val train_allow_cross_region_p1 = !train_region_addr_p1.head(1).asBool\n\
      1243:   val train_allow_cross_region_m1 = !train_region_addr_m1.head(1).asBool\n\
      1244: \n1245:   val train_region_p1_tag = region_hash_tag(train_region_addr_p1.tail(1))\n\
      1246:   val train_region_m1_tag = region_hash_tag(train_region_addr_m1.tail(1))\n\
      1247: \n1248:   val train_region_p1_cross_page = page_bit(train_region_addr_p1)
      ^ page_bit(train_region_addr_raw)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1273-1283
    context: "1273:   val train_region_p1_cross_page_s0 = RegEnable(train_region_p1_cross_page,
      train_vld)\n1274:   val train_region_m1_cross_page_s0 = RegEnable(train_region_m1_cross_page,
      train_vld)\n1275:   val train_region_paddr_s0 = RegEnable(train_region_paddr,
      train_vld)\n1276:   val train_region_vaddr_s0 = RegEnable(train_region_vaddr,
      train_vld)\n1277: \n1278:   active_gen_table.io.agt_en := io_agt_en\n1279: \
      \  active_gen_table.io.act_threshold := io_act_threshold\n1280:   active_gen_table.io.act_stride
      := io_act_stride\n1281:   active_gen_table.io.s0_lookup.valid := train_vld_s0\n\
      1282:   active_gen_table.io.s0_lookup.bits.region_tag := train_region_tag_s0\n\
      1283:   active_gen_table.io.s0_lookup.bits.region_p1_tag := train_region_p1_tag_s0"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1301-1311
    context: "1301:     train_region_vaddr_s0, train_region_offset_s0, 0.U(log2Up(dcacheParameters.blockBytes).W)\n\
      1302:   )\n1303:   stride.io.s0_lookup.bits.paddr := Cat(\n1304:     train_region_paddr_s0,
      train_region_offset_s0, 0.U(log2Up(dcacheParameters.blockBytes).W)\n1305:  \
      \ )\n1306:   stride.io.s1_valid := active_gen_table.io.s1_sel_stride\n1307:\
      \ \n1308:   pht.io.s2_agt_lookup := active_gen_table.io.s2_pht_lookup\n1309:\
      \   pht.io.agt_update := active_gen_table.io.s2_evict\n1310: \n1311:   val pht_gen_valid
      = pht.io.pf_gen_req.valid && io_pht_en"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1339-1355
    context: "1339: \n1340:   for((train, i) <- io.ld_in.zipWithIndex){\n1341:   \
      \  XSPerfAccumulate(s\"pf_train_miss_${i}\", train.valid && train.bits.miss)\n\
      1342:     XSPerfAccumulate(s\"pf_train_prefetched_${i}\", train.valid && isFromL1Prefetch(train.bits.meta_prefetch))\n\
      1343:   }\n1344:   val trace = Wire(new L1MissTrace)\n1345:   trace.vaddr :=
      0.U\n1346:   trace.pc := 0.U\n1347:   trace.paddr := io.l2_req.bits.addr\n1348:\
      \   trace.source := pf_filter.io.debug_source_type\n1349:   val table = ChiselDB.createTable(\"\
      L1SMSMissTrace_hart\"+ p(XSCoreParamsKey).HartId.toString, new L1MissTrace)\n\
      1350:   table.log(trace, io.l2_req.fire, \"SMSPrefetcher\", clock, reset)\n\
      1351: \n1352:   XSPerfAccumulate(\"sms_pf_gen_conflict\",\n1353:     pht_gen_valid
      && agt_gen_valid\n1354:   )\n1355:   XSPerfAccumulate(\"sms_pht_disabled\",
      pht.io.pf_gen_req.valid && !io_pht_en)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/SMSPrefetcher.scala
    lines: 1351-1360
    context: "1351: \n1352:   XSPerfAccumulate(\"sms_pf_gen_conflict\",\n1353:   \
      \  pht_gen_valid && agt_gen_valid\n1354:   )\n1355:   XSPerfAccumulate(\"sms_pht_disabled\"\
      , pht.io.pf_gen_req.valid && !io_pht_en)\n1356:   XSPerfAccumulate(\"sms_agt_disabled\"\
      , active_gen_table.io.s2_pf_gen_req.valid && !io_agt_en)\n1357:   XSPerfAccumulate(\"\
      sms_pf_real_issued\", io.l2_req.valid)\n1358:   XSPerfAccumulate(\"sms_l1_req_valid\"\
      , io.l1_req.valid)\n1359:   XSPerfAccumulate(\"sms_l1_req_fire\", io.l1_req.fire)\n\
      1360: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecCommon.scala
    lines: 289-299
    context: "289: \n290: class VecMemExuOutput(isVector: Boolean = false)(implicit
      p: Parameters) extends VLSUBundle{\n291:   val output = new MemExuOutput(isVector)\n\
      292:   val vecFeedback = Bool()\n293:   val nc = Bool()\n294:   val mmio = Bool()\n\
      295:   val usSecondInv = Bool()\n296:   val hasException = Bool()\n297:   val
      elemIdx = UInt(elemIdxBits.W)\n298:   val alignedType = UInt(alignTypeBits.W)\n\
      299:   val mbIndex     = UInt(vsmBindexBits.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecCommon.scala
    lines: 868-882
    context: "868: }\n869: \n870: class skidBufferConnect[T <: Data](gen: T) extends
      Module {\n871:   val io = IO(new Bundle() {\n872:     val in = Flipped(DecoupledIO(gen.cloneType))\n\
      873:     val flush = Input(Bool())\n874:     val out = DecoupledIO(gen.cloneType)\n\
      875:   })\n876: \n877:   skidBuffer.connect(io.in, io.out, io.flush)\n878: }\n\
      879: \n880: object skidBuffer{\n881:   /*\n882:   * Skid Buffer used to break
      timing path of ready"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecCommon.scala
    lines: 882-908
    context: "882:   * Skid Buffer used to break timing path of ready\n883:   * */\n\
      884:   def connect[T <: Data](\n885:                           in: DecoupledIO[T],\n\
      886:                           out: DecoupledIO[T],\n887:                  \
      \         flush: Bool\n888:                         ): T = {\n889:     val empty
      :: skid :: Nil = Enum(2)\n890:     val state      = RegInit(empty)\n891:   \
      \  val stateNext  = WireInit(empty)\n892:     val dataBuffer = RegEnable(in.bits,
      (!out.ready && in.fire))\n893: \n894:     when(state === empty){\n895:     \
      \  stateNext := Mux(!out.ready && in.fire && !flush, skid, empty)\n896:    \
      \ }.elsewhen(state === skid){\n897:       stateNext := Mux(out.ready || flush,
      empty, skid)\n898:     }\n899:     state     := stateNext\n900: \n901:     in.ready\
      \  := state === empty\n902:     out.bits  := Mux(state === skid, dataBuffer,
      in.bits)\n903:     out.valid := in.valid || (state === skid)\n904: \n905:  \
      \   dataBuffer\n906:   }\n907:   def apply[T <: Data](\n908:               \
      \          in: DecoupledIO[T],"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecCommon.scala
    lines: 905-915
    context: "905:     dataBuffer\n906:   }\n907:   def apply[T <: Data](\n908:  \
      \                       in: DecoupledIO[T],\n909:                         out:
      DecoupledIO[T],\n910:                         flush: Bool,\n911:           \
      \              moduleName: String\n912:                       ): Unit = {\n\
      913:     val buffer = Module(new skidBufferConnect(in.bits))\n914:     buffer.suggestName(moduleName)\n\
      915:     buffer.io.in <> in"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecCommon.scala
    lines: 911-920
    context: "911:                         moduleName: String\n912:              \
      \         ): Unit = {\n913:     val buffer = Module(new skidBufferConnect(in.bits))\n\
      914:     buffer.suggestName(moduleName)\n915:     buffer.io.in <> in\n916: \
      \    buffer.io.flush := flush\n917:     out <> buffer.io.out\n918:   }\n919:
      }\n920: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 239-250
    context: "239:   * s_wait_to_sbuffer: Wait for data from the sbufferOut pipelayer
      to be sent to the sbuffer\n240:   * s_finish: normal uop is complete\n241: \
      \  * s_fof_fix_vl: Writeback the uop of the fof instruction to modify vl.\n\
      242:   * */\n243:   val s_idle :: s_flush_sbuffer_req :: s_wait_flush_sbuffer_resp
      :: s_tlb_req :: s_wait_tlb_resp :: s_pm ::s_cache_req :: s_cache_resp :: s_misalign_merge_data
      :: s_latch_and_merge_data :: s_send_data :: s_wait_to_sbuffer :: s_finish ::
      s_fof_fix_vl :: Nil = Enum(14)\n244:   val state             = RegInit(s_idle)\n\
      245:   val stateNext         = WireInit(s_idle)\n246:   val sbufferEmpty   \
      \   = io.flush_sbuffer.empty\n247:   val isEnqfof          = io.in.bits.uop.fuOpType
      === VlduType.vleff && io.in.valid\n248:   val isEnqFixVlUop     = isEnqfof &&
      io.in.bits.uop.vpu.lastUop\n249:   val nextBaseVaddr     = Wire(UInt(XLEN.W))\n\
      250: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 266-293
    context: "266:   val isFirstSplit       = !curPtr\n267:   val isSecondSplit  \
      \    = curPtr\n268:   /**\n269:    * state update\n270:    */\n271:   state\
      \  := stateNext\n272: \n273:   /**\n274:    * state transfer\n275:    */\n276:\
      \   when(state === s_idle){\n277:     stateNext := Mux(isAfter(enqPtr, deqPtr),
      s_flush_sbuffer_req, s_idle)\n278:   }.elsewhen(state === s_flush_sbuffer_req){\n\
      279:     stateNext := Mux(sbufferEmpty, s_tlb_req, s_wait_flush_sbuffer_resp)
      // if sbuffer is empty, go to query tlb\n280: \n281:   }.elsewhen(state ===
      s_wait_flush_sbuffer_resp){\n282:     stateNext := Mux(sbufferEmpty, s_tlb_req,
      s_wait_flush_sbuffer_resp)\n283: \n284:   }.elsewhen(state === s_tlb_req){\n\
      285:     stateNext := Mux(segmentActive, s_wait_tlb_resp, Mux(isVSegLoad, s_latch_and_merge_data,
      s_send_data))\n286: \n287:   }.elsewhen(state === s_wait_tlb_resp){\n288:  \
      \   stateNext := Mux(io.dtlb.resp.fire,\n289:                       Mux(!io.dtlb.resp.bits.miss,\n\
      290:                           s_pm,\n291:                           s_tlb_req),\n\
      292:                       s_wait_tlb_resp)\n293: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 289-366
    context: "289:                       Mux(!io.dtlb.resp.bits.miss,\n290:      \
      \                     s_pm,\n291:                           s_tlb_req),\n292:\
      \                       s_wait_tlb_resp)\n293: \n294:   }.elsewhen(state ===
      s_pm){\n295:     when(exception_pa || exception_va || exception_gpa) {\n296:\
      \       stateNext := s_finish\n297:     } .otherwise {\n298:       when(canHandleMisalign
      && isMisalignWire && !notCross16ByteWire || (isMisalignReg && !notCross16ByteReg
      && isFirstSplit && isVSegStore)) {\n299:         stateNext := s_tlb_req\n300:\
      \       } .otherwise {\n301:         /* if is vStore, send data to sbuffer,
      so don't need query dcache */\n302:         stateNext := Mux(isVSegLoad, s_cache_req,
      s_send_data)\n303:       }\n304:     }\n305: \n306:   }.elsewhen(state === s_cache_req){\n\
      307:     stateNext := Mux(io.rdcache.req.fire, s_cache_resp, s_cache_req)\n\
      308: \n309:   }.elsewhen(state === s_cache_resp){\n310:     when(io.rdcache.resp.fire)
      {\n311:       when(io.rdcache.resp.bits.miss || io.rdcache.s2_bank_conflict)
      {\n312:         stateNext := s_cache_req\n313:       }.otherwise {\n314:   \
      \      stateNext := Mux(isVSegLoad, Mux(isMisalignReg && !notCross16ByteReg,
      s_misalign_merge_data, s_latch_and_merge_data), s_send_data)\n315:       }\n\
      316:     }.otherwise{\n317:       stateNext := s_cache_resp\n318:     }\n319:\
      \   }.elsewhen(state === s_misalign_merge_data) {\n320:     when(exception_pa)
      {\n321:       stateNext := s_finish\n322:     } .otherwise {\n323:       stateNext
      := Mux(!curPtr, s_tlb_req, s_latch_and_merge_data)\n324:     }\n325:   }.elsewhen(state
      === s_latch_and_merge_data) {\n326:     when(exception_pa) {\n327:       stateNext
      := s_finish\n328:     } .otherwise {\n329:       when((segmentIdx === maxSegIdx)
      && (fieldIdx === maxNfields) ||\n330:         ((segmentIdx === maxSegIdx) &&
      !segmentActive)) {\n331: \n332:         stateNext := s_finish // segment instruction
      finish\n333:       }.otherwise {\n334:         stateNext := s_tlb_req // need
      continue\n335:       }\n336:     }\n337:     /* if segment is inactive, don't
      need to wait access all of the field */\n338:   }.elsewhen(state === s_send_data)
      { // when sbuffer accept data\n339:     when(!sbufferOut.fire && segmentActive
      || (isMisalignReg && !notCross16ByteReg && isFirstSplit)) {\n340:       stateNext
      := s_send_data\n341:     }.elsewhen(segmentIdx === maxSegIdx && (fieldIdx ===
      maxNfields && sbufferOut.fire || !segmentActive && io.sbuffer.valid && !io.sbuffer.ready))
      {\n342:       stateNext := s_wait_to_sbuffer\n343:     }.elsewhen(segmentIdx
      === maxSegIdx && !segmentActive){\n344:       stateNext := s_finish // segment
      instruction finish\n345:     }.otherwise {\n346:       stateNext := s_tlb_req
      // need continue\n347:     }\n348: \n349:   }.elsewhen(state === s_wait_to_sbuffer){\n\
      350:     stateNext := Mux(io.sbuffer.fire, s_finish, s_wait_to_sbuffer)\n351:\
      \ \n352:   }.elsewhen(state === s_finish){ // writeback uop\n353:     stateNext
      := Mux(\n354:       distanceBetween(enqPtr, deqPtr) === 0.U,\n355:       Mux(fofBufferValid,
      s_fof_fix_vl, s_idle),\n356:       s_finish\n357:     )\n358:   }.elsewhen(state
      === s_fof_fix_vl){ // writeback uop\n359:     stateNext := Mux(!fofBufferValid,
      s_idle, s_fof_fix_vl)\n360:   }.otherwise{ // unknown state\n361:     stateNext
      := s_idle\n362:     assert(false.B)\n363:   }\n364: \n365:   /*************************************************************************\n\
      366:    *                            enqueue logic"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 363-373
    context: "363:   }\n364: \n365:   /*************************************************************************\n\
      366:    *                            enqueue logic\n367:    *************************************************************************/\n\
      368:   io.in.ready                         := true.B\n369:   val fuOpType  \
      \                       = io.in.bits.uop.fuOpType\n370:   val vtype        \
      \                    = io.in.bits.uop.vpu.vtype\n371:   val mop            \
      \                  = fuOpType(6, 5)\n372:   val instType                   \
      \      = Cat(true.B, mop)\n373:   val eew                              = io.in.bits.uop.vpu.veew"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 377-387
    context: "377:   val vl                               = instMicroOp.vl\n378: \
      \  val vm                               = instMicroOp.uop.vpu.vm\n379:   val
      vstart                           = instMicroOp.uop.vpu.vstart\n380:   val srcMask\
      \                          = GenFlowMask(Mux(vm, Fill(VLEN, 1.U(1.W)), io.in.bits.src_mask),
      vstart, vl, true)\n381:   // first uop enqueue, we need to latch microOp of
      segment instruction\n382:   when(io.in.fire && !instMicroOpValid && !isEnqFixVlUop){\n\
      383:     // element number in a vd\n384:     // TODO Rewrite it in a more elegant
      way.\n385:     val uopFlowNum                    = ZeroExt(GenRealFlowNum(instType,
      emul, lmul, eew, sew, true), elemIdxBits)\n386:     instMicroOp.baseVaddr  \
      \           := io.in.bits.src_rs1\n387:     instMicroOpValid               \
      \   := true.B // if is first uop"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 400-410
    context: "400:     instMicroOp.isVSegStore           := FuType.isVSegStore(io.in.bits.uop.fuType)\n\
      401:     isMisalignReg                     := false.B\n402:     notCross16ByteReg\
      \                 := false.B\n403:   }\n404:   // latch data\n405:   when(io.in.fire
      && !isEnqFixVlUop){\n406:     data(enqPtr.value)                := io.in.bits.src_vs3\n\
      407:     stride(enqPtr.value)              := io.in.bits.src_stride\n408:  \
      \   uopq(enqPtr.value).uop            := io.in.bits.uop\n409:   }\n410: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 407-417
    context: "407:     stride(enqPtr.value)              := io.in.bits.src_stride\n\
      408:     uopq(enqPtr.value).uop            := io.in.bits.uop\n409:   }\n410:\
      \ \n411:   // update enqptr, only 1 port\n412:   when(io.in.fire && !isEnqFixVlUop){\n\
      413:     enqPtr                            := enqPtr + 1.U\n414:   }\n415: \n\
      416:   /*************************************************************************\n\
      417:    *                            output logic"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 437-447
    context: "437:  //  val misalignVaddr                   = Mux(notCross16ByteReg,
      notCross16ByteVaddr, Mux(isFirstSplit, misalignLowVaddr, misalignHighVaddr))\n\
      438:   val misalignVaddr                   = Mux(isFirstSplit, misalignLowVaddr,
      misalignHighVaddr)\n439:   val misalignVaddrDup                = Mux(isFirstSplit,
      misalignLowVaddrDup, misalignHighVaddrDup)\n440:   val tlbReqVaddr         \
      \            = Mux(isMisalignReg, misalignVaddr, vaddr)\n441:   //latch vaddr\n\
      442:   when(state === s_tlb_req && !isMisalignReg){\n443:     latchVaddr :=
      vaddr(VAddrBits - 1, 0)\n444:     latchVaddrDup := vaddr(VAddrBits - 1, 0)\n\
      445:   }\n446:   /**\n447:    * tlb req and tlb resq"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 447-459
    context: "447:    * tlb req and tlb resq\n448:    */\n449: \n450:   // query DTLB
      IO Assign\n451:   io.dtlb.req                         := DontCare\n452:   io.dtlb.resp.ready\
      \                  := true.B\n453:   io.dtlb.req.valid                   :=
      state === s_tlb_req && segmentActive\n454:   io.dtlb.req.bits.cmd          \
      \      := Mux(isVSegLoad, TlbCmd.read, TlbCmd.write)\n455:   io.dtlb.req.bits.vaddr\
      \              := tlbReqVaddr(VAddrBits - 1, 0)\n456:   io.dtlb.req.bits.fullva\
      \             := tlbReqVaddr\n457:   io.dtlb.req.bits.checkfullva        :=
      true.B\n458:   io.dtlb.req.bits.size               := instMicroOp.alignedType(2,0)\n\
      459:   io.dtlb.req.bits.memidx.is_ld       := isVSegLoad"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 479-495
    context: "479:   val triggerAction = segmentTrigger.io.toLoadStore.triggerAction\n\
      480:   val triggerDebugMode = TriggerAction.isDmode(triggerAction)\n481:   val
      triggerBreakpoint = TriggerAction.isExp(triggerAction)\n482: \n483:   // tlb
      resp\n484:   when(io.dtlb.resp.fire && state === s_wait_tlb_resp){\n485:   \
      \    exceptionVec(storePageFault)      := io.dtlb.resp.bits.excp(0).pf.st\n\
      486:       exceptionVec(loadPageFault)       := io.dtlb.resp.bits.excp(0).pf.ld\n\
      487:       exceptionVec(storeGuestPageFault) := io.dtlb.resp.bits.excp(0).gpf.st\n\
      488:       exceptionVec(loadGuestPageFault)  := io.dtlb.resp.bits.excp(0).gpf.ld\n\
      489:       exceptionVec(storeAccessFault)    := io.dtlb.resp.bits.excp(0).af.st
      || Pbmt.isUncache(io.dtlb.resp.bits.pbmt.head)\n490:       exceptionVec(loadAccessFault)\
      \     := io.dtlb.resp.bits.excp(0).af.ld || Pbmt.isUncache(io.dtlb.resp.bits.pbmt.head)\n\
      491:       when(!io.dtlb.resp.bits.miss){\n492:         instMicroOp.paddr  \
      \           := io.dtlb.resp.bits.paddr(0)\n493:         instMicroOp.exceptionVaddr\
      \    := io.dtlb.resp.bits.fullva\n494:         instMicroOp.exceptionGpaddr \
      \  := io.dtlb.resp.bits.gpaddr(0)\n495:         instMicroOp.exceptionIsForVSnonLeafPTE\
      \  := io.dtlb.resp.bits.isForVSnonLeafPTE"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 502-512
    context: "502:   }\n503:   // pmp\n504:   // NOTE: only handle load/store exception
      here, if other exception happens, don't send here\n505:   val exceptionWithPf
      = exceptionVec(storePageFault) || exceptionVec(loadPageFault) || exceptionVec(storeGuestPageFault)
      || exceptionVec(loadGuestPageFault)\n506:   val pmp = (io.pmpResp.asUInt & Fill(io.pmpResp.asUInt.getWidth,
      !exceptionWithPf)).asTypeOf(new PMPRespBundle())\n507:   when(state === s_pm)
      {\n508:     val highAddress = LookupTree(Mux(isIndexed(issueInstType), issueSew(1,
      0), issueEew(1, 0)), List(\n509:       \"b00\".U -> 0.U,\n510:       \"b01\"\
      .U -> 1.U,\n511:       \"b10\".U -> 3.U,\n512:       \"b11\".U -> 7.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 519-535
    context: "519:       \"b11\".U   -> (vaddr(2, 0) === 0.U)  //d\n520:     ))\n\
      521: \n522:     notCross16ByteWire   := highAddress(4) === vaddr(4)\n523:  \
      \   isMisalignWire       := !addr_aligned && !isMisalignReg\n524:     canHandleMisalign\
      \    := !pmp.mmio && !triggerBreakpoint && !triggerDebugMode\n525: \n526:  \
      \   exception_va  := exceptionVec(storePageFault) || exceptionVec(loadPageFault)
      ||\n527:                      exceptionVec(storeAccessFault) || exceptionVec(loadAccessFault)
      ||\n528:                      triggerBreakpoint || triggerDebugMode || pmp.mmio\n\
      529:     exception_gpa := exceptionVec(storeGuestPageFault) || exceptionVec(loadGuestPageFault)\n\
      530:     exception_pa  := pmp.st || pmp.ld || pmp.mmio\n531: \n532:     instMicroOp.exception_pa\
      \  := exception_pa\n533:     instMicroOp.exception_va  := exception_va\n534:\
      \     instMicroOp.exception_gpa := exception_gpa\n535:     // update storeAccessFault
      bit. Currently, we don't support vector MMIO"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 531-542
    context: "531: \n532:     instMicroOp.exception_pa  := exception_pa\n533:    \
      \ instMicroOp.exception_va  := exception_va\n534:     instMicroOp.exception_gpa
      := exception_gpa\n535:     // update storeAccessFault bit. Currently, we don't
      support vector MMIO\n536:     exceptionVec(loadAccessFault)  := (exceptionVec(loadAccessFault)
      || pmp.ld || pmp.mmio)   && isVSegLoad  && canTriggerException\n537:     exceptionVec(storeAccessFault)
      := (exceptionVec(storeAccessFault) || pmp.st || pmp.mmio)  && isVSegStore &&
      canTriggerException\n538:     exceptionVec(breakPoint)       := triggerBreakpoint
      && canTriggerException\n539: \n540:     exceptionVec(storePageFault)      :=
      exceptionVec(storePageFault)      && isVSegStore && canTriggerException\n541:\
      \     exceptionVec(loadPageFault)       := exceptionVec(loadPageFault)     \
      \  && isVSegLoad  && canTriggerException\n542:     exceptionVec(storeGuestPageFault)
      := exceptionVec(storeGuestPageFault) && isVSegStore && canTriggerException"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 562-577
    context: "562:   }\n563: \n564:   /**\n565:    * flush sbuffer IO Assign\n566:\
      \    */\n567:   io.flush_sbuffer.valid           := !sbufferEmpty && (state
      === s_flush_sbuffer_req || state === s_wait_flush_sbuffer_resp)\n568: \n569:\
      \   /**\n570:   * update curPtr\n571:   * */\n572:   when(state === s_finish
      || state === s_latch_and_merge_data || state === s_send_data && stateNext =/=
      s_send_data) {\n573:     isMisalignReg     := false.B\n574:     notCross16ByteReg
      := false.B\n575:     curPtr := false.B\n576:   } .otherwise {\n577:     when(isVSegLoad)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 573-591
    context: "573:     isMisalignReg     := false.B\n574:     notCross16ByteReg :=
      false.B\n575:     curPtr := false.B\n576:   } .otherwise {\n577:     when(isVSegLoad)
      {\n578:       when(isMisalignReg && !notCross16ByteReg && state === s_misalign_merge_data)
      {\n579:         curPtr := true.B\n580:       }\n581:     } .otherwise {\n582:\
      \       when(isMisalignReg && !notCross16ByteReg && state === s_pm) {\n583:\
      \         curPtr := !curPtr\n584:       } .elsewhen(isMisalignReg && !notCross16ByteReg
      && state === s_pm && stateNext === s_send_data) {\n585:         curPtr := false.B\n\
      586:       } .elsewhen(isMisalignReg && !notCross16ByteReg && state === s_send_data
      && stateNext === s_send_data && sbufferOut.fire) {\n587:         curPtr := !curPtr\n\
      588:       }\n589:     }\n590:   }\n591: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 590-600
    context: "590:   }\n591: \n592: \n593:   // HardwareError response will be one
      beat late\n594:   when(\n595:     (state === s_latch_and_merge_data || state
      === s_misalign_merge_data) &&\n596:     io.rdcache.resp.bits.error_delayed &&
      GatedValidRegNext(io.csrCtrl.cache_error_enable) &&\n597:     segmentActive\n\
      598:   ) {\n599:     exception_pa := true.B\n600:     instMicroOp.exception_pa
      := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 647-657
    context: "647:     \"b1100\".U -> Cat(io.rdcache.resp.bits.data_delayed, combinedData(31,\
      \    0))(63, 0),\n648:     \"b1101\".U -> Cat(io.rdcache.resp.bits.data_delayed,
      combinedData(23,    0))(63, 0),\n649:     \"b1110\".U -> Cat(io.rdcache.resp.bits.data_delayed,
      combinedData(15,    0))(63, 0),\n650:     \"b1111\".U -> Cat(io.rdcache.resp.bits.data_delayed,
      combinedData(7,     0))(63, 0)\n651:   ))\n652:   when(state === s_misalign_merge_data
      && segmentActive){\n653:     when(!curPtr) {\n654:       combinedData := misalignLowData\n\
      655:     } .otherwise {\n656:       combinedData := misalignCombinedData\n657:\
      \     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 665-675
    context: "665:     newData = Seq(pickData),\n666:     alignedType = alignedType(1,0),\n\
      667:     elemIdx = Seq(elemIdxInVd),\n668:     valids = Seq(true.B)\n669:  \
      \ )\n670:   when(state === s_latch_and_merge_data && segmentActive){\n671: \
      \    data(splitPtr.value) := mergedData\n672:   }\n673: \n674: \n675:   /**"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 688-698
    context: "688:   val dcacheReqPaddr = Mux(isMisalignReg, Cat(instMicroOp.paddr(instMicroOp.paddr.getWidth
      - 1, PageOffsetWidth), misalignVaddr(PageOffsetWidth - 1, 0)), instMicroOp.paddr)\n\
      689:   /**\n690:    * rdcache req, write request don't need to query dcache,
      because we write element to sbuffer\n691:    */\n692:   io.rdcache.req     \
      \               := DontCare\n693:   io.rdcache.req.valid              := state
      === s_cache_req && isVSegLoad\n694:   io.rdcache.req.bits.cmd           := MemoryOpConstants.M_XRD\n\
      695:   io.rdcache.req.bits.vaddr         := dcacheReqVaddr\n696:   io.rdcache.req.bits.vaddr_dup\
      \     := dcacheReqVaddrDup\n697:   io.rdcache.req.bits.mask          := mask\n\
      698:   io.rdcache.req.bits.data          := flowData"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 696-706
    context: "696:   io.rdcache.req.bits.vaddr_dup     := dcacheReqVaddrDup\n697:\
      \   io.rdcache.req.bits.mask          := mask\n698:   io.rdcache.req.bits.data\
      \          := flowData\n699:   io.rdcache.pf_source              := LOAD_SOURCE.U\n\
      700:   io.rdcache.req.bits.id            := DontCare\n701:   io.rdcache.resp.ready\
      \             := true.B\n702:   io.rdcache.s1_paddr_dup_lsu       := dcacheReqPaddr\n\
      703:   io.rdcache.s1_paddr_dup_dcache    := dcacheReqPaddr\n704:   io.rdcache.s1_kill\
      \                := false.B\n705:   io.rdcache.s1_kill_data_read      := false.B\n\
      706:   io.rdcache.s2_kill                := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 754-765
    context: "754:   val sbufferPaddr                 = Mux(isMisalignReg, sbuffermisalignPaddr,
      instMicroOp.paddr)\n755: \n756:   dontTouch(wmask)\n757:   dontTouch(Cross16ByteMask)\n\
      758:   sbufferOut.bits                  := DontCare\n759:   sbufferOut.valid\
      \                 := state === s_send_data && segmentActive\n760:   sbufferOut.bits.vecValid\
      \         := state === s_send_data && segmentActive\n761:   sbufferOut.bits.mask\
      \             := sbufferMask\n762:   sbufferOut.bits.data             := sbufferData\n\
      763:   sbufferOut.bits.vaddr            := sbufferVaddr\n764:   sbufferOut.bits.cmd\
      \              := MemoryOpConstants.M_XWR\n765:   sbufferOut.bits.id       \
      \        := DontCare"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 764-774
    context: "764:   sbufferOut.bits.cmd              := MemoryOpConstants.M_XWR\n\
      765:   sbufferOut.bits.id               := DontCare\n766:   sbufferOut.bits.addr\
      \             := sbufferPaddr\n767: \n768:   NewPipelineConnect(\n769:     sbufferOut,
      io.sbuffer, io.sbuffer.fire,\n770:     false.B,\n771:     Option(s\"VSegmentUnitPipelineConnect\"\
      )\n772:   )\n773: \n774:   io.vecDifftestInfo.valid         := io.sbuffer.valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 777-790
    context: "777:   io.vecDifftestInfo.bits.offset   := 0.U\n778: \n779:   /**\n\
      780:    * update ptr\n781:    * */\n782:   private val fieldActiveWirteFinish
      = sbufferOut.fire && segmentActive // writedata finish and is a active segment\n\
      783:   XSError(sbufferOut.fire && !segmentActive, \"Attempt write inactive segment
      to sbuffer, something wrong!\\n\")\n784: \n785:   private val segmentInactiveFinish
      = ((state === s_latch_and_merge_data) || (state === s_send_data && stateNext
      =/= s_send_data)) && !segmentActive\n786: \n787:   val splitPtrOffset = Mux(\n\
      788:     isIndexed(instType),\n789:     Mux(lmul.asSInt < 0.S, 1.U, (1.U <<
      lmul).asUInt),\n790:     Mux(emul.asSInt < 0.S, 1.U, (1.U << emul).asUInt)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 804-816
    context: "804:     dontTouch(stridePtr)\n805:     dontTouch(segmentActive)\n806:\
      \   }\n807: \n808:   // update splitPtr\n809:   when(state === s_latch_and_merge_data
      || (state === s_send_data && stateNext =/= s_send_data && (fieldActiveWirteFinish
      || !segmentActive))){\n810:     splitPtr := splitPtrNext\n811:   }.elsewhen(io.in.fire
      && !instMicroOpValid){\n812:     splitPtr := deqPtr // initial splitPtr\n813:\
      \   }\n814: \n815: \n816:   val fieldIdxWire      = WireInit(fieldIdx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 815-825
    context: "815: \n816:   val fieldIdxWire      = WireInit(fieldIdx)\n817:   val
      segmentIdxWire    = WireInit(segmentIdx)\n818:   val nextBaseVaddrWire = (baseVaddr
      + (fieldIdxWire << alignedType).asUInt)\n819: \n820:   nextBaseVaddr  := RegEnable(nextBaseVaddrWire,
      0.U, stateNext === s_tlb_req)\n821: \n822:   // update stridePtr, only use in
      index\n823:   val strideOffset     = Mux(isIndexed(issueInstType), segmentIdx
      >> issueMaxIdxInIndexLog2, 0.U)\n824:   val strideOffsetWire = Mux(isIndexed(issueInstType),
      segmentIdxWire >> issueMaxIdxInIndexLog2, 0.U)\n825:   stridePtr       := deqPtr
      + strideOffset"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 824-838
    context: "824:   val strideOffsetWire = Mux(isIndexed(issueInstType), segmentIdxWire
      >> issueMaxIdxInIndexLog2, 0.U)\n825:   stridePtr       := deqPtr + strideOffset\n\
      826:   stridePtrReg    := deqPtr + strideOffsetWire\n827: \n828:   // update
      fieldIdx\n829:   when(io.in.fire && !instMicroOpValid){ // init\n830:     fieldIdxWire
      := 0.U\n831:     fieldIdx := fieldIdxWire\n832:   }.elsewhen(state === s_latch_and_merge_data
      && segmentActive ||\n833:             (state === s_send_data && stateNext =/=
      s_send_data && fieldActiveWirteFinish)){ // only if segment is active\n834:\
      \ \n835:     /* next segment, only if segment complete */\n836:     fieldIdxWire
      := Mux(fieldIdx === maxNfields, 0.U, fieldIdx + 1.U)\n837:     fieldIdx := fieldIdxWire\n\
      838:   }.elsewhen(segmentInactiveFinish){ // segment is inactive, go to next
      segment"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 840-853
    context: "840:     fieldIdx := fieldIdxWire\n841:   }\n842: \n843: \n844:   //update
      segmentIdx\n845:   when(io.in.fire && !instMicroOpValid){\n846:     segmentIdxWire
      := 0.U\n847:     segmentIdx := segmentIdxWire\n848:   }.elsewhen(fieldIdx ===
      maxNfields && (state === s_latch_and_merge_data || (state === s_send_data &&
      stateNext =/= s_send_data && fieldActiveWirteFinish)) &&\n849:             \
      \ segmentIdx =/= maxSegIdx){ // next segment, only if segment is active\n850:\
      \ \n851:     segmentIdxWire := segmentIdx + 1.U\n852:     segmentIdx := segmentIdxWire\n\
      853:   }.elsewhen(segmentInactiveFinish && segmentIdx =/= maxSegIdx){ // if
      segment is inactive, go to next segment"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 856-866
    context: "856:   }\n857: \n858: \n859:   //update segmentOffset\n860:   /* when
      segment is active or segment is inactive, increase segmentOffset */\n861:  \
      \ when((fieldIdx === maxNfields && (state === s_latch_and_merge_data || (state
      === s_send_data && stateNext =/= s_send_data && fieldActiveWirteFinish))) ||\n\
      862:        segmentInactiveFinish){\n863: \n864:     segmentOffset := segmentOffset
      + Mux(isUnitStride(issueInstType), (maxNfields +& 1.U) << issueEew(1, 0), stride(stridePtr.value))\n\
      865:   }\n866: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 864-874
    context: "864:     segmentOffset := segmentOffset + Mux(isUnitStride(issueInstType),
      (maxNfields +& 1.U) << issueEew(1, 0), stride(stridePtr.value))\n865:   }\n\
      866: \n867: \n868:   //update deqPtr\n869:   when((state === s_finish) && !isEmpty(enqPtr,
      deqPtr)){\n870:     deqPtr := deqPtr + 1.U\n871:   }\n872: \n873: \n874:   /*************************************************************************"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 878-888
    context: "878:   //Enq\n879:   when(isEnqFixVlUop && !fofBufferValid) { fofBuffer
      := io.in.bits.uop }\n880:   when(isEnqFixVlUop && !fofBufferValid) { fofBufferValid
      := true.B }\n881: \n882:   //Deq\n883:   val fofFixVlValid                 \
      \   = state === s_fof_fix_vl && fofBufferValid\n884: \n885:   when(fofFixVlValid)
      { fofBuffer      := 0.U.asTypeOf(new DynInst) }\n886:   when(fofFixVlValid)
      { fofBufferValid := false.B }\n887: \n888: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 893-908
    context: "893:   /*select mask of vd, maybe remove in feature*/\n894:   val realEw\
      \        = Mux(isIndexed(issueInstType), issueSew(1, 0), issueEew(1, 0))\n895:\
      \   val maskDataVec: Vec[UInt] = VecDataToMaskDataVec(instMicroOp.mask, realEw)\n\
      896:   val maskUsed      = maskDataVec(vdIdxInField)\n897: \n898:   when(stateNext
      === s_idle){\n899:     instMicroOpValid := false.B\n900:   }\n901:   // writeback
      to backend\n902:   val writebackOut                     = WireInit(io.uopwriteback.bits)\n\
      903:   val writebackValid                   = (state === s_finish) && !isEmpty(enqPtr,
      deqPtr) || fofFixVlValid\n904: \n905:   when(fofFixVlValid) {\n906:     writebackOut.uop\
      \                    := fofBuffer\n907:     writebackOut.uop.vpu.vl        \
      \     := instMicroOp.exceptionVl.bits\n908:     writebackOut.data          \
      \         := instMicroOp.exceptionVl.bits"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 931-945
    context: "931: \n932:   dontTouch(writebackValid)\n933: \n934:   //to RS\n935:\
      \   val feedbackOut                      = WireInit(0.U.asTypeOf(io.feedback.bits))\n\
      936:   val feedbackValid                    = state === s_finish && !isEmpty(enqPtr,
      deqPtr)\n937:   feedbackOut.hit                     := true.B\n938:   feedbackOut.robIdx\
      \                  := instMicroOp.uop.robIdx\n939:   feedbackOut.sourceType\
      \              := DontCare\n940:   feedbackOut.flushState              := DontCare\n\
      941:   feedbackOut.dataInvalidSqIdx        := DontCare\n942:   feedbackOut.sqIdx\
      \                   := uopq(deqPtr.value).uop.sqIdx\n943:   feedbackOut.lqIdx\
      \                   := uopq(deqPtr.value).uop.lqIdx\n944: \n945:   io.feedback.valid\
      \                   := RegNext(feedbackValid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 954-961
    context: "954:   io.exceptionInfo.bits.vstart        := instMicroOp.exceptionVstart\n\
      955:   io.exceptionInfo.bits.vaddr         := instMicroOp.exceptionVaddr\n956:\
      \   io.exceptionInfo.bits.gpaddr        := instMicroOp.exceptionGpaddr\n957:\
      \   io.exceptionInfo.bits.isForVSnonLeafPTE := instMicroOp.exceptionIsForVSnonLeafPTE\n\
      958:   io.exceptionInfo.bits.vl            := instMicroOp.exceptionVl.bits\n\
      959:   io.exceptionInfo.valid              := (state === s_finish) && instMicroOp.uop.exceptionVec.asUInt.orR
      && !isEmpty(enqPtr, deqPtr)\n960: }\n961: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 38-49
    context: "38:   def us_mask(fuOpType: UInt): Bool = false.B\n39:   def us_fof(fuOpType:
      UInt): Bool = false.B\n40:   //TODO vdIdxReg should no longer be useful, don't
      delete it for now\n41:   val vdIdxReg = RegInit(0.U(3.W))\n42: \n43:   val s1_ready
      = WireInit(false.B)\n44:   io.in.ready := s1_ready\n45: \n46:   /**-----------------------------------------------------------\n\
      47:     * s0 stage\n48:     * decode and generate AlignedType, uop mask, preIsSplit\n\
      49:     * ----------------------------------------------------------"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 60-73
    context: "60:   val s0_vm = s0_uop.vpu.vm\n61:   val s0_emul = Mux(us_whole_reg(s0_fuOpType)
      ,GenUSWholeEmul(s0_uop.vpu.nf), Mux(us_mask(s0_fuOpType), 0.U(mulBits.W), EewLog2(s0_eew)
      - s0_sew + s0_lmul))\n62:   val s0_preIsSplit = !isUnitStride(s0_mop)\n63: \
      \  val s0_nfield        = s0_nf +& 1.U\n64: \n65:   val s0_valid         = Wire(Bool())\n\
      66:   val s0_kill          = io.in.bits.uop.robIdx.needFlush(io.redirect)\n\
      67:   val s0_can_go        = s1_ready\n68:   val s0_fire          = s0_valid
      && s0_can_go\n69:   val s0_out           = Wire(new VLSBundle(isVStore))\n70:\
      \ \n71:   val isUsWholeReg = isUnitStride(s0_mop) && us_whole_reg(s0_fuOpType)\n\
      72:   val isMaskReg = isUnitStride(s0_mop) && us_mask(s0_fuOpType)\n73:   val
      isSegment = s0_nf =/= 0.U && !us_whole_reg(s0_fuOpType)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 171-181
    context: "171:     x.vdIdxInField := vdIdxInField\n172:     x.preIsSplit  := s0_preIsSplit\n\
      173:     x.alignedType := broadenAligendType\n174:     x.indexVlMaxInVd := indexVlMaxInVd\n\
      175:   }\n176:   s0_valid := io.in.valid && !s0_kill\n177:   /**-------------------------------------\n\
      178:     * s1 stage\n179:     * ------------------------------------\n180: \
      \    * generate UopOffset\n181:     */"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 177-200
    context: "177:   /**-------------------------------------\n178:     * s1 stage\n\
      179:     * ------------------------------------\n180:     * generate UopOffset\n\
      181:     */\n182:   val s1_valid         = RegInit(false.B)\n183:   val s1_kill\
      \          = Wire(Bool())\n184:   val s1_in            = Wire(new VLSBundle(isVStore))\n\
      185:   val s1_can_go        = io.out.ready && io.toMergeBuffer.req.ready\n186:\
      \   val s1_fire          = s1_valid && !s1_kill && s1_can_go\n187: \n188:  \
      \ s1_ready         := s1_kill || !s1_valid || s1_can_go\n189: \n190:   when(s0_fire){\n\
      191:     s1_valid := true.B\n192:   }.elsewhen(s1_fire){\n193:     s1_valid
      := false.B\n194:   }.elsewhen(s1_kill){\n195:     s1_valid := false.B\n196:\
      \   }\n197:   s1_in := RegEnable(s0_out, s0_fire)\n198: \n199:   val s1_flowNum\
      \          = s1_in.flowNum\n200:   val s1_uop              = s1_in.uop"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 233-246
    context: "233:                           )\n234: \n235:   val activeNum      \
      \   = Mux(s1_in.preIsSplit, PopCount(s1_in.flowMask), usActiveNum)\n236: \n\
      237: \n238:   s1_kill               := s1_in.uop.robIdx.needFlush(io.redirect)\n\
      239: \n240:   // query mergeBuffer\n241:   io.toMergeBuffer.req.valid      \
      \       := io.out.ready && s1_valid// only can_go will get MergeBuffer entry\n\
      242:   io.toMergeBuffer.req.bits.flowNum      := activeNum\n243:   io.toMergeBuffer.req.bits.data\
      \         := s1_in.data\n244:   io.toMergeBuffer.req.bits.uop          := s1_in.uop\n\
      245:   io.toMergeBuffer.req.bits.uop.vpu.nf   := s1_in.rawNf\n246:   io.toMergeBuffer.req.bits.mask\
      \         := s1_mask"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 256-266
    context: "256: //  }.elsewhen(s1_fire) {\n257: //    vdIdxReg := vdIdxReg + 1.U\n\
      258: //    XSError(vdIdxReg + 1.U === 0.U, s\"Overflow! The number of vd should
      be less than 8\\n\")\n259: //  }\n260:   // out connect\n261:   io.out.valid\
      \          := s1_valid && io.toMergeBuffer.resp.valid && (activeNum =/= 0.U)
      // if activeNum == 0, this uop do nothing, can be killed.\n262:   io.out.bits\
      \           := s1_in\n263:   io.out.bits.uopOffset := uopOffset\n264:   io.out.bits.uopAddr\
      \   := s1_in.baseAddr + uopOffset\n265:   io.out.bits.stride    := stride\n\
      266:   io.out.bits.mBIndex   := io.toMergeBuffer.resp.bits.mBIndex"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 267-279
    context: "267:   io.out.bits.usLowBitsAddr := usLowBitsAddr\n268:   io.out.bits.usAligned128\
      \  := usAligned128\n269:   io.out.bits.usMask        := usMask\n270:   io.out.bits.uop.vpu.nf\
      \    := s1_in.rawNf\n271: \n272:   XSPerfAccumulate(\"split_out\",     io.out.fire)\n\
      273:   XSPerfAccumulate(\"pipe_block\",    io.out.valid && !io.out.ready)\n\
      274:   XSPerfAccumulate(\"mbuffer_block\", s1_valid && io.out.ready && !io.toMergeBuffer.resp.valid)\n\
      275: }\n276: \n277: abstract class VSplitBuffer(isVStore: Boolean = false)(implicit
      p: Parameters) extends VLSUModule{\n278:   val io = IO(new VSplitBufferIO(isVStore))\n\
      279:   lazy val fuCfg    = if(isVStore) VstuCfg else VlduCfg"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 290-300
    context: "290:   val strideOffsetReg = RegInit(0.U(VLEN.W))\n291: \n292:   /**\n\
      293:     * Redirect\n294:     */\n295:   val cancelEnq    = io.in.bits.uop.robIdx.needFlush(io.redirect)\n\
      296:   val canEnqueue   = io.in.valid\n297:   val needEnqueue  = canEnqueue
      && !cancelEnq\n298: \n299:   // enqueue\n300:   val offset    = PopCount(needEnqueue)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 297-307
    context: "297:   val needEnqueue  = canEnqueue && !cancelEnq\n298: \n299:   //
      enqueue\n300:   val offset    = PopCount(needEnqueue)\n301:   val canAccept
      = !allocated || allocated && splitFinish && (activeIssue || inActiveIssue) //
      if is valid entry, need split finish and send last uop\n302:   io.in.ready \
      \ := canAccept\n303:   val doEnqueue = canAccept && needEnqueue\n304: \n305:\
      \   when(doEnqueue){\n306:     uopq := io.in.bits\n307:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 398-408
    context: "398:     x.isFirstIssue          := DontCare\n399:     x.mBIndex   \
      \            := issueMbIndex\n400:   }\n401: \n402:   // redirect\n403:   needCancel
      := uopq.uop.robIdx.needFlush(io.redirect) && allocated\n404: \n405:  /* Execute
      logic */\n406:   /** Issue to scala pipeline**/\n407: \n408:   lazy val misalignedCanGo
      = true.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 404-414
    context: "404: \n405:  /* Execute logic */\n406:   /** Issue to scala pipeline**/\n\
      407: \n408:   lazy val misalignedCanGo = true.B\n409:   val allowIssue = (addrAligned
      || misalignedCanGo) && io.out.ready\n410:   val issueCount = Mux(usNoSplit,
      2.U, (PopCount(inActiveIssue) + PopCount(activeIssue))) // for dont need split
      unit-stride, issue two flow\n411:   splitFinish := splitIdx >= (issueFlowNum
      - issueCount)\n412: \n413:   // handshake\n414:   activeIssue := issueValid
      && allowIssue && vecActive // active issue, current use in no unit-stride"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 411-421
    context: "411:   splitFinish := splitIdx >= (issueFlowNum - issueCount)\n412:\
      \ \n413:   // handshake\n414:   activeIssue := issueValid && allowIssue && vecActive
      // active issue, current use in no unit-stride\n415:   inActiveIssue := issueValid
      && !vecActive\n416:   when (!issueEntry.uop.robIdx.needFlush(io.redirect)) {\n\
      417:     when (!splitFinish) {\n418:       when (activeIssue || inActiveIssue)
      {\n419:         // The uop has not been entirly splited yet\n420:         splitIdx
      := splitIdx + issueCount\n421:         strideOffsetReg := Mux(!issuePreIsSplit,
      0.U, strideOffsetReg + issueEntry.stride) // when normal unit-stride, don't
      use strideOffsetReg"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 432-442
    context: "432:     strideOffsetReg := 0.U\n433:   }\n434:   // allocated\n435:\
      \   when(doEnqueue){ // if enqueue need to been cancelled, it will be false,
      so this have high priority\n436:     allocated := true.B\n437:   }.elsewhen(needCancel)
      { // redirect\n438:     allocated := false.B\n439:   }.elsewhen(splitFinish
      && (activeIssue || inActiveIssue)){ //dequeue\n440:     allocated := false.B\n\
      441:   }\n442: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 442-455
    context: "442: \n443:   // out connect\n444:   io.out.valid := issueValid && vecActive
      && (addrAligned || misalignedCanGo) // TODO: inactive unit-stride uop do not
      send to pipeline\n445: \n446:   XSPerfAccumulate(\"out_valid\",            \
      \ io.out.valid)\n447:   XSPerfAccumulate(\"out_fire\",              io.out.fire)\n\
      448:   XSPerfAccumulate(\"out_fire_unitstride\",   io.out.fire && !issuePreIsSplit)\n\
      449:   XSPerfAccumulate(\"unitstride_vlenAlign\",  io.out.fire && !issuePreIsSplit
      && getCheckAddrLowBits(io.out.bits.vaddr, maxMemByteNum) === 0.U)\n450:   XSPerfAccumulate(\"\
      unitstride_invalid\",    io.out.ready && issueValid && !issuePreIsSplit && PopCount(io.out.bits.mask).orR)\n\
      451: }\n452: \n453: class VSSplitBufferImp(implicit p: Parameters) extends VSplitBuffer(isVStore
      = true){\n454:   override lazy val misalignedCanGo = io.vstdMisalign.get.storePipeEmpty
      && io.vstdMisalign.get.storeMisalignBufferEmpty\n455: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 518-540
    context: "518:   val splitPipeline = Module(new VLSplitPipelineImp())\n519:  \
      \ val splitBuffer = Module(new VLSplitBufferImp())\n520:   val mergeBufferNack
      = io.threshold.get.valid && io.threshold.get.bits =/= io.in.bits.uop.lqIdx\n\
      521:   // Split Pipeline\n522:   splitPipeline.io.in <> io.in\n523:   io.in.ready
      := splitPipeline.io.in.ready && !mergeBufferNack\n524:   splitPipeline.io.redirect
      <> io.redirect\n525:   io.toMergeBuffer <> splitPipeline.io.toMergeBuffer\n\
      526: \n527:   // skid buffer\n528:   skidBuffer(splitPipeline.io.out, splitBuffer.io.in,\n\
      529:     Mux(splitPipeline.io.out.fire,\n530:       splitPipeline.io.out.bits.uop.robIdx.needFlush(io.redirect),\n\
      531:       splitBuffer.io.in.bits.uop.robIdx.needFlush(io.redirect)),\n532:\
      \     \"VSSplitSkidBuffer\")\n533: \n534:   // Split Buffer\n535:   splitBuffer.io.redirect
      <> io.redirect\n536:   io.out <> splitBuffer.io.out\n537: }\n538: \n539: class
      VSSplitImp(implicit p: Parameters) extends VLSUModule{\n540:   val io = IO(new
      VSplitIO(isVStore=true))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 540-561
    context: "540:   val io = IO(new VSplitIO(isVStore=true))\n541:   val splitPipeline
      = Module(new VSSplitPipelineImp())\n542:   val splitBuffer = Module(new VSSplitBufferImp())\n\
      543:   // Split Pipeline\n544:   splitPipeline.io.in <> io.in\n545:   splitPipeline.io.redirect
      <> io.redirect\n546:   io.toMergeBuffer <> splitPipeline.io.toMergeBuffer\n\
      547: \n548:   // skid buffer\n549:   skidBuffer(splitPipeline.io.out, splitBuffer.io.in,\n\
      550:     Mux(splitPipeline.io.out.fire,\n551:       splitPipeline.io.out.bits.uop.robIdx.needFlush(io.redirect),\n\
      552:       splitBuffer.io.in.bits.uop.robIdx.needFlush(io.redirect)),\n553:\
      \     \"VSSplitSkidBuffer\")\n554: \n555:   // Split Buffer\n556:   splitBuffer.io.redirect
      <> io.redirect\n557:   io.out <> splitBuffer.io.out\n558:   io.vstd.get <> splitBuffer.io.vstd.get\n\
      559: \n560:   io.vstdMisalign.get <> splitBuffer.io.vstdMisalign.get\n561: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VfofBuffer.scala
    lines: 42-52
    context: "42:   val valid   = RegInit(false.B)\n43: \n44:   val entriesIsFixVl
      = entries.uop.vpu.lastUop && entries.uop.vpu.isVleff\n45: \n46:   //Enq\n47:\
      \   io.in.map(_.ready := true.B)\n48:   val enqIsfof = io.in.map { x =>\n49:\
      \     x.valid && x.bits.uop.vpu.isVleff\n50:   }\n51: \n52:   val enqValid =
      enqIsfof.reduce(_ || _)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VfofBuffer.scala
    lines: 49-59
    context: "49:     x.valid && x.bits.uop.vpu.isVleff\n50:   }\n51: \n52:   val
      enqValid = enqIsfof.reduce(_ || _)\n53:   val enqBits  = ParallelPriorityMux(enqIsfof,
      io.in.map(_.bits))\n54:   val enqNeedCancel = enqBits.uop.robIdx.needFlush(io.redirect)\n\
      55:   val enqIsFixVl = enqBits.uop.vpu.isVleff && enqBits.uop.vpu.lastUop\n\
      56: \n57:   XSError(entries.uop.robIdx.value =/= enqBits.uop.robIdx.value &&
      valid && enqValid, \"There should be no new fof instrction coming in!\\n\")\n\
      58:   XSError(entriesIsFixVl && valid && enqValid, \"There should not new uop
      enqueue!\\n\")\n59: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VfofBuffer.scala
    lines: 66-82
    context: "66:       entries.uop     := enqBits.uop\n67:     }\n68:   }\n69: \n\
      70:   //Control Signal\n71:   val needRedirect = entries.uop.robIdx.needFlush(io.redirect)\n\
      72: \n73: \n74:   when(io.uopWriteback.fire) {\n75:     valid := false.B  //Deq\n\
      76:   }.elsewhen(needRedirect) {\n77:     valid := false.B //Redirect\n78: \
      \  }.elsewhen(enqValid && !enqNeedCancel) {\n79:     valid := true.B //Enq\n\
      80:   }\n81: \n82: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VfofBuffer.scala
    lines: 107-121
    context: "107:         val left = getOldest_recursion(valid.take(valid.length
      / 2), bits.take(valid.length / 2))\n108:         val right = getOldest_recursion(valid.drop(valid.length
      / 2), bits.drop(valid.length / 2))\n109:         getOldest_recursion(left._1
      ++ right._1, left._2 ++ right._2)\n110:       }\n111:     }\n112:     getOldest_recursion(valid,
      bits)._2.head\n113:   }\n114: \n115:   //Update uop vl\n116:   io.mergeUopWriteback.map{_.ready
      := true.B}\n117:   val portUop         = Wire(Vec(VLUopWritebackWidth, new DynInst))\n\
      118:   portUop.zip(io.mergeUopWriteback.map(_.bits)).map{ case(sink, source)
      =>\n119:     sink              := WireInit(0.U.asTypeOf(new DynInst))\n120:\
      \     sink.robIdx       := source.robidx\n121:     sink.vpu.vl       := source.vl"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VfofBuffer.scala
    lines: 122-132
    context: "122:     sink.exceptionVec := source.exceptionVec\n123:   }\n124:  \
      \ val wbBits          = getOldest(wbIsfof, portUop)\n125:   val wbValid    \
      \     = wbIsfof.reduce(_ || _)\n126:   val wbHasException  = wbBits.exceptionVec.asUInt.orR\n\
      127:   val wbUpdateValid = wbValid && (wbBits.vpu.vl < entries.vl || wbHasException)
      && valid && !needRedirect && !entries.hasException\n128: \n129:   XSError(wbValid
      && wbHasException && valid && entries.hasException, \"The same instruction triggers
      an exception multiple times!\\n\")\n130: \n131:   when(wbUpdateValid) {\n132:\
      \     entries.vl                    := wbBits.vpu.vl"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VfofBuffer.scala
    lines: 139-147
    context: "139:   io.uopWriteback.bits.uop.exceptionVec := 0.U.asTypeOf(ExceptionVec())\n\
      140:   io.uopWriteback.bits.data             := entries.vl\n141:   io.uopWriteback.bits.uop.vpu.vl\
      \       := entries.vl\n142:   io.uopWriteback.bits.mask.get         := Fill(VLEN,
      1.U)\n143:   io.uopWriteback.bits.uop.vpu.vmask    := Fill(VLEN, 1.U)\n144:\
      \   io.uopWriteback.valid                 := valid && entries.uop.vpu.lastUop
      && entries.uop.vpu.isVleff && !needRedirect\n145: \n146: \n147: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 82-92
    context: "82: }\n83: \n84: object VSFQFeedbackType {\n85:   val tlbMiss = 0.U(3.W)\n\
      86:   val mshrFull = 1.U(3.W)\n87:   val dataInvalid = 2.U(3.W)\n88:   val bankConflict
      = 3.U(3.W)\n89:   val ldVioCheckRedo = 4.U(3.W)\n90:   val feedbackInvalid =
      7.U(3.W)\n91: \n92:   def apply() = UInt(3.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 97-107
    context: "97:   val hit   = Bool()\n98:   //val flushState = Bool()\n99:   val
      sourceType = VSFQFeedbackType()\n100:   //val dataInvalidSqIdx = new SqPtr\n\
      101:   val paddr = UInt(PAddrBits.W)\n102:   val mmio = Bool()\n103:   val atomic
      = Bool()\n104:   val exceptionVec = ExceptionVec()\n105: }\n106: \n107: class
      VecPipelineFeedbackIO(isVStore: Boolean=false) (implicit p: Parameters) extends
      VLSUBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 106-116
    context: "106: \n107: class VecPipelineFeedbackIO(isVStore: Boolean=false) (implicit
      p: Parameters) extends VLSUBundle {\n108:   val mBIndex              = if(isVStore)
      UInt(vsmBindexBits.W) else UInt(vlmBindexBits.W)\n109:   val hit           \
      \       = Bool()\n110:   val isvec                = Bool()\n111:   val flushState\
      \           = Bool()\n112:   val sourceType           = VSFQFeedbackType()\n\
      113:   val trigger              = TriggerAction()\n114:   //val dataInvalidSqIdx
      = new SqPtr\n115:   //val paddr                = UInt(PAddrBits.W)\n116:   val
      nc                   = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 112-122
    context: "112:   val sourceType           = VSFQFeedbackType()\n113:   val trigger\
      \              = TriggerAction()\n114:   //val dataInvalidSqIdx = new SqPtr\n\
      115:   //val paddr                = UInt(PAddrBits.W)\n116:   val nc       \
      \            = Bool()\n117:   val mmio                 = Bool()\n118:   //val
      atomic               = Bool()\n119:   val exceptionVec         = ExceptionVec()\n\
      120:   val hasException         = Bool() // Active\n121:   val vaddr       \
      \         = UInt(XLEN.W)\n122:   val vaNeedExt            = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 159-171
    context: "159:   val elemIdxInsideVd     = UInt(elemIdxBits.W) // only use in
      unit-stride\n160: }\n161: \n162: object VecFeedbacks {\n163:   // need to invalid
      lsq entry\n164:   val FLUSH  = 0\n165:   // merge buffer commits one uop\n166:\
      \   val COMMIT  = 1\n167:   // last uop of an inst, sq can commit\n168:   val
      LAST = 2\n169:   // total feedbacks\n170:   val allFeedbacks = 3\n171: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 213-224
    context: "213:     // for exception\n214:   val vstart           = UInt(elemIdxBits.W)\n\
      215:   val vl               = UInt(elemIdxBits.W)\n216:   val exceptionVec \
      \    = ExceptionVec()\n217: \n218:   def isFlush  = feedback(VecFeedbacks.FLUSH)\n\
      219:   def isCommit = feedback(VecFeedbacks.COMMIT)\n220:   def isLast = feedback(VecFeedbacks.LAST)\n\
      221: }\n222: \n223: class storeMisaignIO(implicit p: Parameters) extends Bundle{\n\
      224:   val storePipeEmpty           = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 224-234
    context: "224:   val storePipeEmpty           = Input(Bool())\n225:   val storeMisalignBufferEmpty
      = Input(Bool())\n226: }\n227: \n228: class VSplitIO(isVStore: Boolean=false)(implicit
      p: Parameters) extends VLSUBundle{\n229:   val redirect            = Flipped(ValidIO(new
      Redirect))\n230:   val in                  = Flipped(Decoupled(new MemExuInput(isVector
      = true))) // from iq\n231:   val toMergeBuffer       = new ToMergeBufferIO(isVStore)
      //to merge buffer req mergebuffer entry\n232:   val out                 = Decoupled(new
      VecPipeBundle(isVStore))// to scala pipeline\n233:   val vstd              \
      \  = OptionWrapper(isVStore, Valid(new MemExuOutput(isVector = true)))\n234:\
      \   val vstdMisalign        = OptionWrapper(isVStore, new storeMisaignIO)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 234-244
    context: "234:   val vstdMisalign        = OptionWrapper(isVStore, new storeMisaignIO)\n\
      235:   val threshold            = OptionWrapper(!isVStore, Flipped(ValidIO(new
      LqPtr)))\n236: }\n237: \n238: class VSplitPipelineIO(isVStore: Boolean=false)(implicit
      p: Parameters) extends VLSUBundle{\n239:   val redirect            = Flipped(ValidIO(new
      Redirect))\n240:   val in                  = Flipped(Decoupled(new MemExuInput(isVector
      = true)))\n241:   val toMergeBuffer       = new ToMergeBufferIO(isVStore) //
      req mergebuffer entry, inactive elem issue\n242:   val out                 =
      Decoupled(new VLSBundle())// to split buffer\n243: }\n244: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 241-251
    context: "241:   val toMergeBuffer       = new ToMergeBufferIO(isVStore) // req
      mergebuffer entry, inactive elem issue\n242:   val out                 = Decoupled(new
      VLSBundle())// to split buffer\n243: }\n244: \n245: class VSplitBufferIO(isVStore:
      Boolean=false)(implicit p: Parameters) extends VLSUBundle{\n246:   val redirect\
      \            = Flipped(ValidIO(new Redirect))\n247:   val in               \
      \   = Flipped(Decoupled(new VLSBundle()))\n248:   val out                 =
      Decoupled(new VecPipeBundle(isVStore))//to scala pipeline\n249:   val vstd \
      \               = OptionWrapper(isVStore, ValidIO(new MemExuOutput(isVector
      = true)))\n250:   val vstdMisalign        = OptionWrapper(isVStore, new storeMisaignIO)\n\
      251: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 249-259
    context: "249:   val vstd                = OptionWrapper(isVStore, ValidIO(new
      MemExuOutput(isVector = true)))\n250:   val vstdMisalign        = OptionWrapper(isVStore,
      new storeMisaignIO)\n251: }\n252: \n253: class VMergeBufferIO(isVStore : Boolean=false)(implicit
      p: Parameters) extends VLSUBundle{\n254:   val redirect            = Flipped(ValidIO(new
      Redirect))\n255:   val fromPipeline        = if(isVStore) Vec(StorePipelineWidth,
      Flipped(DecoupledIO(new VecPipelineFeedbackIO(isVStore)))) else Vec(LoadPipelineWidth,
      Flipped(DecoupledIO(new VecPipelineFeedbackIO(isVStore))))\n256:   val fromSplit\
      \           = if(isVStore) Vec(VecStorePipelineWidth, new FromSplitIO) else
      Vec(VecLoadPipelineWidth, new FromSplitIO) // req mergebuffer entry, inactive
      elem issue\n257:   val uopWriteback        = if(isVStore) Vec(VSUopWritebackWidth,
      DecoupledIO(new MemExuOutput(isVector = true))) else Vec(VLUopWritebackWidth,
      DecoupledIO(new MemExuOutput(isVector = true)))\n258:   val toSplit        \
      \     = OptionWrapper(!isVStore, new FeedbackToSplitIO())\n259:   val toLsq\
      \               = if(isVStore) Vec(VSUopWritebackWidth, ValidIO(new FeedbackToLsqIO))
      else Vec(VLUopWritebackWidth, ValidIO(new FeedbackToLsqIO)) // for lsq deq"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 255-265
    context: "255:   val fromPipeline        = if(isVStore) Vec(StorePipelineWidth,
      Flipped(DecoupledIO(new VecPipelineFeedbackIO(isVStore)))) else Vec(LoadPipelineWidth,
      Flipped(DecoupledIO(new VecPipelineFeedbackIO(isVStore))))\n256:   val fromSplit\
      \           = if(isVStore) Vec(VecStorePipelineWidth, new FromSplitIO) else
      Vec(VecLoadPipelineWidth, new FromSplitIO) // req mergebuffer entry, inactive
      elem issue\n257:   val uopWriteback        = if(isVStore) Vec(VSUopWritebackWidth,
      DecoupledIO(new MemExuOutput(isVector = true))) else Vec(VLUopWritebackWidth,
      DecoupledIO(new MemExuOutput(isVector = true)))\n258:   val toSplit        \
      \     = OptionWrapper(!isVStore, new FeedbackToSplitIO())\n259:   val toLsq\
      \               = if(isVStore) Vec(VSUopWritebackWidth, ValidIO(new FeedbackToLsqIO))
      else Vec(VLUopWritebackWidth, ValidIO(new FeedbackToLsqIO)) // for lsq deq\n\
      260:   val feedback            = if(isVStore) Vec(VSUopWritebackWidth, ValidIO(new
      RSFeedback(isVector = true))) else Vec(VLUopWritebackWidth, ValidIO(new RSFeedback(isVector
      = true)))//for rs replay\n261: \n262:   val fromMisalignBuffer  = OptionWrapper(isVStore,
      Flipped(new StoreMaBufToVecStoreMergeBufferIO))\n263: }\n264: \n265: class VSegmentUnitIO(implicit
      p: Parameters) extends VLSUBundle{"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 264-274
    context: "264: \n265: class VSegmentUnitIO(implicit p: Parameters) extends VLSUBundle{\n\
      266:   val in                  = Flipped(Decoupled(new MemExuInput(isVector
      = true))) // from iq\n267:   val uopwriteback        = DecoupledIO(new MemExuOutput(isVector
      = true)) // writeback data\n268:   val csrCtrl             = Flipped(new CustomCSRCtrlIO)\n\
      269:   val rdcache             = new DCacheLoadIO // read dcache port\n270:\
      \   val sbuffer             = Decoupled(new DCacheWordReqWithVaddrAndPfFlag)\n\
      271:   val vecDifftestInfo     = Decoupled(new ToSbufferDifftestInfoBundle)
      // to sbuffer\n272:   val dtlb                = new TlbRequestIO(2)\n273:  \
      \ val pmpResp             = Flipped(new PMPRespBundle())\n274:   val flush_sbuffer\
      \       = new SbufferFlushBundle"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 271-281
    context: "271:   val vecDifftestInfo     = Decoupled(new ToSbufferDifftestInfoBundle)
      // to sbuffer\n272:   val dtlb                = new TlbRequestIO(2)\n273:  \
      \ val pmpResp             = Flipped(new PMPRespBundle())\n274:   val flush_sbuffer\
      \       = new SbufferFlushBundle\n275:   val feedback            = ValidIO(new
      RSFeedback(isVector = true))\n276:   val redirect            = Flipped(ValidIO(new
      Redirect))\n277:   val exceptionInfo       = ValidIO(new FeedbackToLsqIO)\n\
      278:   //trigger\n279:   val fromCsrTrigger      = Input(new CsrTriggerBundle)\n\
      280: }\n281: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 278-288
    context: "278:   //trigger\n279:   val fromCsrTrigger      = Input(new CsrTriggerBundle)\n\
      280: }\n281: \n282: class VfofDataBuffIO(implicit p: Parameters) extends VLSUBundle{\n\
      283:   val redirect            = Flipped(ValidIO(new Redirect))\n284:   val
      in                  = Vec(VecLoadPipelineWidth, Flipped(Decoupled(new MemExuInput(isVector=true))))\n\
      285:   val mergeUopWriteback   = Vec(VLUopWritebackWidth, Flipped(DecoupledIO(new
      FeedbackToLsqIO)))\n286: \n287:   val uopWriteback        = DecoupledIO(new
      MemExuOutput(isVector = true))\n288: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 39-49
    context: "39:   val flowNum          = UInt(flowIdxBits.W)\n40:   val exceptionVec\
      \     = ExceptionVec()\n41:   val uop              = new DynInst\n42:   // val
      vdOffset         = UInt(vOffsetBits.W)\n43:   val sourceType       = VSFQFeedbackType()\n\
      44:   val flushState       = Bool()\n45:   val vdIdx            = UInt(3.W)\n\
      46:   val elemIdx          = UInt(elemIdxBits.W) // element index\n47:   //
      for exception\n48:   val vstart           = UInt(elemIdxBits.W)\n49:   val vl\
      \               = UInt(elemIdxBits.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 53-63
    context: "53:   val gpaddr           = UInt(GPAddrBits.W)\n54:   val isForVSnonLeafPTE=
      Bool()\n55:   val fof              = Bool()\n56:   val vlmax            = UInt(elemIdxBits.W)\n\
      57: \n58:   def allReady(): Bool = (flowNum === 0.U)\n59: }\n60: \n61: abstract
      class BaseVMergeBuffer(isVStore: Boolean=false)(implicit p: Parameters) extends
      VLSUModule{\n62:   val io = IO(new VMergeBufferIO(isVStore))\n63: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 77-87
    context: "77:     sink.mask         := source.mask\n78:     sink.flowNum     \
      \ := source.flowNum\n79:     sink.exceptionVec := ExceptionNO.selectByFu(0.U.asTypeOf(ExceptionVec()),
      fuCfg)\n80:     sink.uop          := source.uop\n81:     sink.sourceType   :=
      0.U.asTypeOf(VSFQFeedbackType())\n82:     sink.flushState   := false.B\n83:\
      \     sink.vdIdx        := source.vdIdx\n84:     sink.elemIdx      := Fill(elemIdxBits,
      1.U)\n85:     sink.fof          := source.fof\n86:     sink.vlmax        :=
      source.vlmax\n87:     sink.vl           := source.uop.vpu.vl"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 106-117
    context: "106:   def ToLsqConnect(source: MBufferBundle): FeedbackToLsqIO = {\n\
      107:     val sink                                 = WireInit(0.U.asTypeOf(new
      FeedbackToLsqIO))\n108:     val hasExp                               = ExceptionNO.selectByFu(source.exceptionVec,
      fuCfg).asUInt.orR\n109:     sink.robidx                             := source.uop.robIdx\n\
      110:     sink.uopidx                             := source.uop.uopIdx\n111:\
      \     sink.feedback(VecFeedbacks.COMMIT)      := !hasExp\n112:     sink.feedback(VecFeedbacks.FLUSH)\
      \       := hasExp\n113:     sink.feedback(VecFeedbacks.LAST)        := true.B\n\
      114:     sink.vstart                             := source.vstart // TODO: if
      lsq need vl for fof?\n115:     sink.vaddr                              := source.vaddr\n\
      116:     sink.vaNeedExt                          := source.vaNeedExt\n117: \
      \    sink.gpaddr                             := source.gpaddr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 128-138
    context: "128:   val freeMaskVec  = WireInit(VecInit(Seq.fill(uopSize)(false.B)))\n\
      129:   val uopFinish    = RegInit(VecInit(Seq.fill(uopSize)(false.B)))\n130:\
      \   val needRSReplay = RegInit(VecInit(Seq.fill(uopSize)(false.B)))\n131:  \
      \ // enq, from splitPipeline\n132:   // val allowEnqueue =\n133:   val cancelEnq\
      \    = io.fromSplit.map(_.req.bits.uop.robIdx.needFlush(io.redirect))\n134:\
      \   val canEnqueue   = io.fromSplit.map(_.req.valid)\n135:   val needEnqueue\
      \  = (0 until enqWidth).map{i =>\n136:     canEnqueue(i) && !cancelEnq(i)\n\
      137:   }\n138: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 144-156
    context: "144:     freeList.io.allocateReq(i) := true.B\n145: \n146:     val offset\
      \    = PopCount(needEnqueue.take(i))\n147:     val canAccept = freeList.io.canAllocate(offset)\n\
      148:     val enqIndex  = freeList.io.allocateSlot(offset)\n149:     enq.req.ready
      := freeCount >= (i + 1).U // for better timing\n150: \n151:     when(needEnqueue(i)
      && enq.req.ready){\n152:       freeList.io.doAllocate(i) := true.B\n153:   \
      \    // enqueue\n154:       allocated(enqIndex)       := true.B\n155:      \
      \ uopFinish(enqIndex)       := false.B\n156:       needRSReplay(enqIndex)  \
      \  := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 163-173
    context: "163:     enq.resp.valid        := freeCount >= (i + 1).U // for better
      timing\n164:   }\n165: \n166:   //redirect\n167:   for (i <- 0 until uopSize){\n\
      168:     needCancel(i) := entries(i).uop.robIdx.needFlush(io.redirect) && allocated(i)\n\
      169:     when (needCancel(i)) {\n170:       allocated(i)   := false.B\n171:\
      \       freeMaskVec(i) := true.B\n172:       uopFinish(i)   := false.B\n173:\
      \       needRSReplay(i):= false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 171-181
    context: "171:       freeMaskVec(i) := true.B\n172:       uopFinish(i)   := false.B\n\
      173:       needRSReplay(i):= false.B\n174:     }\n175:   }\n176:   freeList.io.free
      := freeMaskVec.asUInt\n177:   //pipelineWriteback\n178:   // handle the situation
      where multiple ports are going to write the same uop queue entry\n179:   //
      select the oldest exception and count the flownum of the pipeline writeback.\n\
      180:   val mergePortMatrix        = Wire(Vec(pipeWidth, Vec(pipeWidth, Bool())))\n\
      181:   val mergePortMatrixHasExcp = Wire(Vec(pipeWidth, Vec(pipeWidth, Bool())))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 298-312
    context: "298:     val flowNumOffset    = PopCount(mergePortMatrix(i))\n299: \
      \    val sourceTypeNext   = entries(wbIndex).sourceType | pipewb.bits.sourceType\n\
      300:     val hasExp           = ExceptionNO.selectByFu(pipewb.bits.exceptionVec,
      fuCfg).asUInt.orR\n301: \n302:     // if is VLoad, need latch 1 cycle to merge
      data. only flowNum and wbIndex need to latch\n303:     val latchWbValid    \
      \ = if(isVStore) pipewb.valid else RegNext(pipewb.valid)\n304:     val latchWbIndex\
      \     = if(isVStore) wbIndex      else RegEnable(wbIndex, pipewb.valid)\n305:\
      \     val latchFlowNum     = if(isVStore) flowNumOffset else RegEnable(flowNumOffset,
      pipewb.valid)\n306:     val latchMergeByPre  = if(isVStore) mergedByPrevPortVec(i)
      else RegEnable(mergedByPrevPortVec(i), pipewb.valid)\n307:     when(latchWbValid
      && !latchMergeByPre){\n308:       entries(latchWbIndex).flowNum := entries(latchWbIndex).flowNum
      - latchFlowNum\n309:     }\n310: \n311:     when(pipewb.valid){\n312:      \
      \ entries(wbIndex).sourceType   := sourceTypeNext"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 308-330
    context: "308:       entries(latchWbIndex).flowNum := entries(latchWbIndex).flowNum
      - latchFlowNum\n309:     }\n310: \n311:     when(pipewb.valid){\n312:      \
      \ entries(wbIndex).sourceType   := sourceTypeNext\n313:       entries(wbIndex).flushState\
      \   := pipewb.bits.flushState\n314:     }\n315:     when(pipewb.valid && !pipewb.bits.hit){\n\
      316:       needRSReplay(wbIndex) := true.B\n317:     }\n318:     pipewb.ready
      := true.B\n319:     XSError((entries(latchWbIndex).flowNum - latchFlowNum >
      entries(latchWbIndex).flowNum) && latchWbValid && !latchMergeByPre, s\"entry:
      $latchWbIndex, FlowWriteback overflow!!\\n\")\n320:     XSError(!allocated(latchWbIndex)
      && latchWbValid, s\"entry: $latchWbIndex, Writeback error flow!!\\n\")\n321:\
      \   }\n322: \n323:   //uopwriteback(deq)\n324:   for (i <- 0 until uopSize){\n\
      325:     when(allocated(i) && entries(i).allReady() && !needCancel(i)){\n326:\
      \       uopFinish(i) := true.B\n327:     }\n328:   }\n329:    val selPolicy
      = SelectOne(\"circ\", uopFinish, deqWidth) // select one entry to deq\n330:\
      \    private val pipelineOut              = Wire(Vec(deqWidth, DecoupledIO(new
      MemExuOutput(isVector = true))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 329-344
    context: "329:    val selPolicy = SelectOne(\"circ\", uopFinish, deqWidth) //
      select one entry to deq\n330:    private val pipelineOut              = Wire(Vec(deqWidth,
      DecoupledIO(new MemExuOutput(isVector = true))))\n331:    private val writeBackOut\
      \             = Wire(Vec(deqWidth, DecoupledIO(new MemExuOutput(isVector = true))))\n\
      332:    private val writeBackOutExceptionVec = writeBackOut.map(_.bits.uop.exceptionVec)\n\
      333:    for(((port, lsqport), i) <- (pipelineOut zip io.toLsq).zipWithIndex){\n\
      334:     val canGo    = port.ready\n335:     val (selValid, selOHVec) = selPolicy.getNthOH(i
      + 1)\n336:     val entryIdx = OHToUInt(selOHVec)\n337:     val selEntry = entries(entryIdx)\n\
      338:     val selAllocated = allocated(entryIdx)\n339:     val selFire  = selValid
      && canGo\n340:     when(selFire){\n341:       freeMaskVec(entryIdx) := selAllocated\n\
      342:       allocated(entryIdx)   := false.B\n343:       uopFinish(entryIdx)\
      \   := false.B\n344:       needRSReplay(entryIdx):= false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 342-355
    context: "342:       allocated(entryIdx)   := false.B\n343:       uopFinish(entryIdx)\
      \   := false.B\n344:       needRSReplay(entryIdx):= false.B\n345:     }\n346:\
      \     //writeback connect\n347:     port.valid   := selFire && selAllocated
      && !needRSReplay(entryIdx) && !selEntry.uop.robIdx.needFlush(io.redirect)\n\
      348:     port.bits    := DeqConnect(selEntry)\n349:     //to lsq\n350:     lsqport.bits
      := ToLsqConnect(selEntry) // when uopwriteback, free MBuffer entry, write to
      lsq\n351:     lsqport.valid:= selFire && selAllocated && !needRSReplay(entryIdx)\n\
      352:     //to RS\n353:     val feedbackOut                       = WireInit(0.U.asTypeOf(io.feedback(i).bits)).suggestName(s\"\
      feedbackOut_${i}\")\n354:     val feedbackValid                     = selFire
      && selAllocated\n355:     feedbackOut.hit                      := !needRSReplay(entryIdx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 353-363
    context: "353:     val feedbackOut                       = WireInit(0.U.asTypeOf(io.feedback(i).bits)).suggestName(s\"\
      feedbackOut_${i}\")\n354:     val feedbackValid                     = selFire
      && selAllocated\n355:     feedbackOut.hit                      := !needRSReplay(entryIdx)\n\
      356:     feedbackOut.robIdx                   := selEntry.uop.robIdx\n357: \
      \    feedbackOut.sourceType               := selEntry.sourceType\n358:     feedbackOut.flushState\
      \               := selEntry.flushState\n359:     feedbackOut.dataInvalidSqIdx\
      \         := DontCare\n360:     feedbackOut.sqIdx                    := selEntry.uop.sqIdx\n\
      361:     feedbackOut.lqIdx                    := selEntry.uop.lqIdx\n362: \n\
      363:     io.feedback(i).valid                 := RegNext(feedbackValid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 362-375
    context: "362: \n363:     io.feedback(i).valid                 := RegNext(feedbackValid)\n\
      364:     io.feedback(i).bits                  := RegEnable(feedbackOut, feedbackValid)\n\
      365: \n366:     NewPipelineConnect(\n367:       port, writeBackOut(i), writeBackOut(i).fire,\n\
      368:       Mux(port.fire,\n369:         selEntry.uop.robIdx.needFlush(io.redirect),\n\
      370:         writeBackOut(i).bits.uop.robIdx.needFlush(io.redirect)),\n371:\
      \       Option(s\"VMergebufferPipelineConnect${i}\")\n372:     )\n373:     \
      \ io.uopWriteback(i)                  <> writeBackOut(i)\n374:      io.uopWriteback(i).bits.uop.exceptionVec
      := ExceptionNO.selectByFu(writeBackOutExceptionVec(i), fuCfg)\n375:    }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 478-486
    context: "478:     sink.vecDebug.get     := DontCare\n479:     sink\n480:   }\n\
      481: \n482:   // from misalignBuffer flush\n483:   when(io.fromMisalignBuffer.get.flush){\n\
      484:     needRSReplay(io.fromMisalignBuffer.get.mbIndex) := true.B\n485:   }\n\
      486: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 77-87
    context: "77: }\n78: \n79: abstract class MemBlockBundle(implicit val p: Parameters)
      extends Bundle with HasMemBlockParameters\n80: \n81: class Std(cfg: FuConfig)(implicit
      p: Parameters) extends FuncUnit(cfg) {\n82:   io.in.ready := io.out.ready\n\
      83:   io.out.valid := io.in.valid\n84:   io.out.bits := 0.U.asTypeOf(io.out.bits)\n\
      85:   io.out.bits.res.data := io.in.bits.data.src(0)\n86:   io.out.bits.ctrl.robIdx
      := io.in.bits.ctrl.robIdx\n87: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 99-109
    context: "99:     val scommit = Input(UInt(log2Up(CommitWidth + 1).W))\n100: \
      \    val pendingMMIOld = Input(Bool())\n101:     val pendingld = Input(Bool())\n\
      102:     val pendingst = Input(Bool())\n103:     val pendingVst = Input(Bool())\n\
      104:     val commit = Input(Bool())\n105:     val pendingPtr = Input(new RobPtr)\n\
      106:     val pendingPtrNext = Input(new RobPtr)\n107:   }\n108: \n109:   val
      isStoreException = Input(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 108-127
    context: "108: \n109:   val isStoreException = Input(Bool())\n110:   val isVlsException
      = Input(Bool())\n111:   val csrCtrl = Flipped(new CustomCSRCtrlIO)\n112:   val
      enqLsq = new LsqEnqIO\n113:   val flushSb = Input(Bool())\n114: \n115:   val
      storePc = Vec(StaCnt, Input(UInt(VAddrBits.W))) // for hw prefetch\n116:   val
      hybridPc = Vec(HyuCnt, Input(UInt(VAddrBits.W))) // for hw prefetch\n117: \n\
      118:   val issueLda = MixedVec(Seq.fill(LduCnt)(Flipped(DecoupledIO(new MemExuInput))))\n\
      119:   val issueSta = MixedVec(Seq.fill(StaCnt)(Flipped(DecoupledIO(new MemExuInput))))\n\
      120:   val issueStd = MixedVec(Seq.fill(StdCnt)(Flipped(DecoupledIO(new MemExuInput))))\n\
      121:   val issueHya = MixedVec(Seq.fill(HyuCnt)(Flipped(DecoupledIO(new MemExuInput))))\n\
      122:   val issueVldu = MixedVec(Seq.fill(VlduCnt)(Flipped(DecoupledIO(new MemExuInput(isVector=true)))))\n\
      123: \n124:   def issueUops = issueLda ++ issueSta ++ issueStd ++ issueHya ++
      issueVldu\n125: }\n126: \n127: class mem_to_ooo(implicit p: Parameters) extends
      MemBlockBundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 136-146
    context: "136:   val sqDeqPtr = Output(new SqPtr)\n137:   val lqDeqPtr = Output(new
      LqPtr)\n138:   val stIn = Vec(StAddrCnt, ValidIO(new MemExuInput))\n139:   val
      stIssuePtr = Output(new SqPtr())\n140: \n141:   val memoryViolation = ValidIO(new
      Redirect)\n142:   val sbIsEmpty = Output(Bool())\n143: \n144:   val lsTopdownInfo
      = Vec(LdExuCnt, Output(new LsTopdownInfo))\n145: \n146:   val lsqio = new Bundle
      {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 147-157
    context: "147:     val vaddr = Output(UInt(XLEN.W))\n148:     val vstart = Output(UInt((log2Up(VLEN)
      + 1).W))\n149:     val vl = Output(UInt((log2Up(VLEN) + 1).W))\n150:     val
      gpaddr = Output(UInt(XLEN.W))\n151:     val isForVSnonLeafPTE = Output(Bool())\n\
      152:     val mmio = Output(Vec(LoadPipelineWidth, Bool()))\n153:     val uop
      = Output(Vec(LoadPipelineWidth, new DynInst))\n154:     val lqCanAccept = Output(Bool())\n\
      155:     val sqCanAccept = Output(Bool())\n156:   }\n157: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 192-202
    context: "192:   val robHeadLoadVio = Output(Bool())\n193:   val robHeadLoadMSHR
      = Output(Bool())\n194: }\n195: \n196: class fetch_to_mem(implicit p: Parameters)
      extends XSBundle{\n197:   val itlb = Flipped(new TlbPtwIO())\n198: }\n199: \n\
      200: // triple buffer applied in i-mmio path (two at MemBlock, one at L2Top)\n\
      201: class InstrUncacheBuffer()(implicit p: Parameters) extends LazyModule with
      HasInstrMMIOConst {\n202:   val node = new TLBufferNode(BufferParams.default,
      BufferParams.default, BufferParams.default, BufferParams.default, BufferParams.default)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 201-211
    context: "201: class InstrUncacheBuffer()(implicit p: Parameters) extends LazyModule
      with HasInstrMMIOConst {\n202:   val node = new TLBufferNode(BufferParams.default,
      BufferParams.default, BufferParams.default, BufferParams.default, BufferParams.default)\n\
      203:   lazy val module = new InstrUncacheBufferImpl\n204: \n205:   class InstrUncacheBufferImpl
      extends LazyModuleImp(this) {\n206:     (node.in zip node.out) foreach { case
      ((in, edgeIn), (out, edgeOut)) =>\n207:       out.a <> BufferParams.default(BufferParams.default(in.a))\n\
      208:       in.d <> BufferParams.default(BufferParams.default(out.d))\n209: \n\
      210:       // only a.valid, a.ready, a.address can change\n211:       // hoping
      that the rest would be optimized to keep MemBlock port unchanged after adding
      buffer"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 208-220
    context: "208:       in.d <> BufferParams.default(BufferParams.default(out.d))\n\
      209: \n210:       // only a.valid, a.ready, a.address can change\n211:     \
      \  // hoping that the rest would be optimized to keep MemBlock port unchanged
      after adding buffer\n212:       out.a.bits.data := 0.U\n213:       out.a.bits.mask
      := Fill(mmioBusBytes, 1.U(1.W))\n214:       out.a.bits.opcode := 4.U // Get\n\
      215:       out.a.bits.size := log2Ceil(mmioBusBytes).U\n216:       out.a.bits.source
      := 0.U\n217:     }\n218:   }\n219: }\n220: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 222-232
    context: "222: class ICacheBuffer()(implicit p: Parameters) extends LazyModule
      {\n223:   val node = new TLBufferNode(BufferParams.default, BufferParams.default,
      BufferParams.default, BufferParams.default, BufferParams.default)\n224:   lazy
      val module = new ICacheBufferImpl\n225: \n226:   class ICacheBufferImpl extends
      LazyModuleImp(this) {\n227:     (node.in zip node.out) foreach { case ((in,
      edgeIn), (out, edgeOut)) =>\n228:       out.a <> BufferParams.default(BufferParams.default(in.a))\n\
      229:       in.d <> BufferParams.default(BufferParams.default(out.d))\n230: \
      \    }\n231:   }\n232: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 234-244
    context: "234: class ICacheCtrlBuffer()(implicit p: Parameters) extends LazyModule
      {\n235:   val node = new TLBufferNode(BufferParams.default, BufferParams.default,
      BufferParams.default, BufferParams.default, BufferParams.default)\n236:   lazy
      val module = new ICacheCtrlBufferImpl\n237: \n238:   class ICacheCtrlBufferImpl
      extends LazyModuleImp(this) {\n239:     (node.in zip node.out) foreach { case
      ((in, edgeIn), (out, edgeOut)) =>\n240:       out.a <> BufferParams.default(BufferParams.default(in.a))\n\
      241:       in.d <> BufferParams.default(BufferParams.default(out.d))\n242: \
      \    }\n243:   }\n244: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 301-311
    context: "301:   with HasTlbConst\n302:   with SdtrigExt\n303: {\n304:   val io
      = IO(new Bundle {\n305:     val hartId = Input(UInt(hartIdLen.W))\n306:    \
      \ val redirect = Flipped(ValidIO(new Redirect))\n307: \n308:     val ooo_to_mem
      = new ooo_to_mem\n309:     val mem_to_ooo = new mem_to_ooo\n310:     val fetch_to_mem
      = new fetch_to_mem\n311: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 322-332
    context: "322:     val debug_ls = new DebugLSIO\n323:     val l2_hint = Input(Valid(new
      L2ToL1Hint()))\n324:     val l2PfqBusy = Input(Bool())\n325:     val l2_tlb_req
      = Flipped(new TlbRequestIO(nRespDups = 2))\n326:     val l2_pmp_resp = new PMPRespBundle\n\
      327:     val l2_flush_done = Input(Bool())\n328: \n329:     val debugTopDown
      = new Bundle {\n330:       val robHeadVaddr = Flipped(Valid(UInt(VAddrBits.W)))\n\
      331:       val toCore = new MemCoreTopDownIO\n332:     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 374-384
    context: "374:     val dft_reset_frnt = Option.when(hasMbist)(Output(new DFTResetSignals()))\n\
      375:     val dft_bcknd = Option.when(hasDFT)(Output(new SramBroadcastBundle))\n\
      376:     val dft_reset_bcknd = Option.when(hasMbist)(Output(new DFTResetSignals()))\n\
      377:   })\n378: \n379:   io.mem_to_ooo.writeBack.zipWithIndex.foreach{ case
      (wb, i) =>\n380:     PerfCCT.updateInstPos(wb.bits.uop.debug_seqNum, PerfCCT.InstPos.AtBypassVal.id.U,
      wb.valid, clock, reset)\n381:   }\n382: \n383:   dontTouch(io.inner_hartId)\n\
      384:   dontTouch(io.inner_reset_vector)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 390-400
    context: "390:   dontTouch(io.inner_beu_errors_icache)\n391:   dontTouch(io.outer_beu_errors_icache)\n\
      392:   dontTouch(io.inner_hc_perfEvents)\n393:   dontTouch(io.outer_hc_perfEvents)\n\
      394: \n395:   val redirect = RegNextWithEnable(io.redirect)\n396: \n397:   private
      val dcache = outer.dcache.module\n398:   val uncache = outer.uncache.module\n\
      399: \n400:   //val delayedDcacheRefill = RegNext(dcache.io.lsu.lsq)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 399-410
    context: "399: \n400:   //val delayedDcacheRefill = RegNext(dcache.io.lsu.lsq)\n\
      401: \n402:   val csrCtrl = DelayN(io.ooo_to_mem.csrCtrl, 2)\n403:   dcache.io.l2_pf_store_only
      := RegNext(io.ooo_to_mem.csrCtrl.pf_ctrl.l2_pf_store_only, false.B)\n404:  \
      \ io.dcacheError <> DelayNWithValid(dcache.io.error, 2)\n405:   io.uncacheError.ecc_error
      <> DelayNWithValid(uncache.io.busError.ecc_error, 2)\n406:   when(!csrCtrl.cache_error_enable){\n\
      407:     io.dcacheError.bits.report_to_beu := false.B\n408:     io.dcacheError.valid
      := false.B\n409:     io.uncacheError.ecc_error.valid := false.B\n410:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 409-419
    context: "409:     io.uncacheError.ecc_error.valid := false.B\n410:   }\n411:\
      \ \n412:   val loadUnits = Seq.fill(LduCnt)(Module(new LoadUnit))\n413:   val
      storeUnits = Seq.fill(StaCnt)(Module(new StoreUnit))\n414:   val stdExeUnits
      = Seq.fill(StdCnt)(Module(new MemExeUnit(backendParams.memSchdParams.get.issueBlockParams.find(_.StdCnt
      != 0).get.exuBlockParams.head)))\n415:   val hybridUnits = Seq.fill(HyuCnt)(Module(new
      HybridUnit)) // Todo: replace it with HybridUnit\n416:   val stData = stdExeUnits.map(_.io.out)\n\
      417:   val exeUnits = loadUnits ++ storeUnits\n418: \n419:   // The number of
      vector load/store units is decoupled with the number of load/store units"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 427-437
    context: "427:   // misalign Buffer\n428:   val loadMisalignBuffer = Module(new
      LoadMisalignBuffer)\n429:   val storeMisalignBuffer = Module(new StoreMisalignBuffer)\n\
      430: \n431:   val l1_pf_req = Wire(Decoupled(new L1PrefetchReq()))\n432:   dcache.io.sms_agt_evict_req.ready
      := false.B\n433:   val l1D_pf_enable = GatedRegNextN(io.ooo_to_mem.csrCtrl.pf_ctrl.l1D_pf_enable,
      2, Some(false.B))\n434:   val prefetcherOpt: Option[BasePrefecher] = coreParams.prefetcher.map
      {\n435:     case _: SMSParams =>\n436:       val sms = Module(new SMSPrefetcher())\n\
      437:       val enableSMS = Constantin.createRecord(s\"enableSMS$hartId\", initValue
      = true)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 436-446
    context: "436:       val sms = Module(new SMSPrefetcher())\n437:       val enableSMS
      = Constantin.createRecord(s\"enableSMS$hartId\", initValue = true)\n438:   \
      \    // constantinCtrl && master switch csrCtrl && single switch csrCtrl\n439:\
      \       sms.io.enable := enableSMS && l1D_pf_enable &&\n440:         GatedRegNextN(io.ooo_to_mem.csrCtrl.pf_ctrl.l2_pf_recv_enable,
      2, Some(false.B))\n441:       sms.io_agt_en := GatedRegNextN(io.ooo_to_mem.csrCtrl.pf_ctrl.l1D_pf_enable_agt,
      2, Some(false.B))\n442:       sms.io_pht_en := GatedRegNextN(io.ooo_to_mem.csrCtrl.pf_ctrl.l1D_pf_enable_pht,
      2, Some(false.B))\n443:       sms.io_act_threshold := GatedRegNextN(io.ooo_to_mem.csrCtrl.pf_ctrl.l1D_pf_active_threshold,
      2, Some(12.U))\n444:       sms.io_act_stride := GatedRegNextN(io.ooo_to_mem.csrCtrl.pf_ctrl.l1D_pf_active_stride,
      2, Some(30.U))\n445:       sms.io_stride_en := false.B\n446:       sms.io_dcache_evict
      <> dcache.io.sms_agt_evict_req"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 445-455
    context: "445:       sms.io_stride_en := false.B\n446:       sms.io_dcache_evict
      <> dcache.io.sms_agt_evict_req\n447:       val mbistSmsPl = MbistPipeline.PlaceMbistPipeline(1,
      \"MbistPipeSms\", hasMbist)\n448:       sms\n449:   }\n450:   prefetcherOpt.foreach{
      pf => pf.io.l1_req.ready := false.B }\n451:   val hartId = p(XSCoreParamsKey).HartId\n\
      452:   val l1PrefetcherOpt: Option[BasePrefecher] = coreParams.prefetcher.map
      {\n453:     case _ =>\n454:       val l1Prefetcher = Module(new L1Prefetcher())\n\
      455:       val enableL1StreamPrefetcher = Constantin.createRecord(s\"enableL1StreamPrefetcher$hartId\"\
      , initValue = true)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 509-523
    context: "509:     atomicsUnit.io.out.bits,\n510:     loadUnits(AtomicWBPort).io.ldout.bits\n\
      511:   )\n512:   ldaExeWbReqs(AtomicWBPort).valid := atomicsUnit.io.out.valid
      || loadUnits(AtomicWBPort).io.ldout.valid\n513:   ldaExeWbReqs(AtomicWBPort).bits\
      \  := atomicWritebackOverride\n514:   atomicsUnit.io.out.ready := ldaExeWbReqs(AtomicWBPort).ready\n\
      515:   loadUnits(AtomicWBPort).io.ldout.ready := ldaExeWbReqs(AtomicWBPort).ready\n\
      516: \n517:   val st_data_atomics = Seq.tabulate(StdCnt)(i =>\n518:     stData(i).valid
      && FuType.storeIsAMO(stData(i).bits.uop.fuType)\n519:   )\n520: \n521:   //
      misalignBuffer will overwrite the source from ldu if it is about to writeback\n\
      522:   val misalignWritebackOverride = Mux(\n523:     loadUnits(MisalignWBPort).io.ldout.valid,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 524-537
    context: "524:     loadUnits(MisalignWBPort).io.ldout.bits,\n525:     loadMisalignBuffer.io.writeBack.bits\n\
      526:   )\n527:   ldaExeWbReqs(MisalignWBPort).valid    := loadMisalignBuffer.io.writeBack.valid
      || loadUnits(MisalignWBPort).io.ldout.valid\n528:   ldaExeWbReqs(MisalignWBPort).bits\
      \     := misalignWritebackOverride\n529:   loadMisalignBuffer.io.writeBack.ready
      := ldaExeWbReqs(MisalignWBPort).ready && !loadUnits(MisalignWBPort).io.ldout.valid\n\
      530:   loadMisalignBuffer.io.loadOutValid    := loadUnits(MisalignWBPort).io.ldout.valid\n\
      531:   loadMisalignBuffer.io.loadVecOutValid := loadUnits(MisalignWBPort).io.vecldout.valid\n\
      532:   loadUnits(MisalignWBPort).io.ldout.ready := ldaExeWbReqs(MisalignWBPort).ready\n\
      533:   ldaExeWbReqs(MisalignWBPort).bits.isFromLoadUnit := loadUnits(MisalignWBPort).io.ldout.bits.isFromLoadUnit
      || loadMisalignBuffer.io.writeBack.valid\n534: \n535:   // loadUnit will overwrite
      the source from uncache if it is about to writeback\n536:   ldaExeWbReqs(UncacheWBPort)
      <> loadUnits(UncacheWBPort).io.ldout\n537:   io.mem_to_ooo.writebackLda <> ldaExeWbReqs"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 534-553
    context: "534: \n535:   // loadUnit will overwrite the source from uncache if
      it is about to writeback\n536:   ldaExeWbReqs(UncacheWBPort) <> loadUnits(UncacheWBPort).io.ldout\n\
      537:   io.mem_to_ooo.writebackLda <> ldaExeWbReqs\n538:   io.mem_to_ooo.writebackSta
      <> storeUnits.map(_.io.stout)\n539:   io.mem_to_ooo.writebackStd.zip(stdExeUnits).foreach
      {x =>\n540:     x._1.bits  := x._2.io.out.bits\n541:     // AMOs do not need
      to write back std now.\n542:     x._1.valid := x._2.io.out.fire && !FuType.storeIsAMO(x._2.io.out.bits.uop.fuType)\n\
      543:   }\n544:   io.mem_to_ooo.writebackHyuLda <> hybridUnits.map(_.io.ldout)\n\
      545:   io.mem_to_ooo.writebackHyuSta <> hybridUnits.map(_.io.stout)\n546:  \
      \ io.mem_to_ooo.otherFastWakeup := DontCare\n547:   io.mem_to_ooo.otherFastWakeup.drop(HyuCnt).take(LduCnt).zip(loadUnits.map(_.io.fast_uop)).foreach{case(a,b)=>
      a := b}\n548:   io.mem_to_ooo.otherFastWakeup.take(HyuCnt).zip(hybridUnits.map(_.io.ldu_io.fast_uop)).foreach{case(a,b)=>
      a:=b}\n549:   val stOut = io.mem_to_ooo.writebackSta ++ io.mem_to_ooo.writebackHyuSta\n\
      550: \n551:   // prefetch to l1 req\n552:   // Stream's confidence is always
      1\n553:   // (LduCnt + HyuCnt) l1_pf_reqs ?"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 549-564
    context: "549:   val stOut = io.mem_to_ooo.writebackSta ++ io.mem_to_ooo.writebackHyuSta\n\
      550: \n551:   // prefetch to l1 req\n552:   // Stream's confidence is always
      1\n553:   // (LduCnt + HyuCnt) l1_pf_reqs ?\n554:   loadUnits.foreach(load_unit
      => {\n555:     load_unit.io.prefetch_req.valid <> l1_pf_req.valid\n556:    \
      \ load_unit.io.prefetch_req.bits <> l1_pf_req.bits\n557:   })\n558: \n559: \
      \  hybridUnits.foreach(hybrid_unit => {\n560:     hybrid_unit.io.ldu_io.prefetch_req.valid
      <> l1_pf_req.valid\n561:     hybrid_unit.io.ldu_io.prefetch_req.bits <> l1_pf_req.bits\n\
      562:   })\n563: \n564:   // NOTE: loadUnits(0) has higher bank conflict and
      miss queue arb priority than loadUnits(1) and loadUnits(2)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 563-573
    context: "563: \n564:   // NOTE: loadUnits(0) has higher bank conflict and miss
      queue arb priority than loadUnits(1) and loadUnits(2)\n565:   // when loadUnits(1)/loadUnits(2)
      stage 0 is busy, hw prefetch will never use that pipeline\n566:   val LowConfPorts
      = if (LduCnt == 2) Seq(1) else if (LduCnt == 3) Seq(1, 2) else Seq(0)\n567:\
      \   LowConfPorts.map{case i => loadUnits(i).io.prefetch_req.bits.confidence
      := 0.U}\n568:   hybridUnits.foreach(hybrid_unit => { hybrid_unit.io.ldu_io.prefetch_req.bits.confidence
      := 0.U })\n569: \n570:   val canAcceptHighConfPrefetch = loadUnits.map(_.io.canAcceptHighConfPrefetch)
      ++\n571:                                   hybridUnits.map(_.io.canAcceptLowConfPrefetch)\n\
      572:   val canAcceptLowConfPrefetch = loadUnits.map(_.io.canAcceptLowConfPrefetch)
      ++\n573:                                  hybridUnits.map(_.io.canAcceptLowConfPrefetch)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 569-579
    context: "569: \n570:   val canAcceptHighConfPrefetch = loadUnits.map(_.io.canAcceptHighConfPrefetch)
      ++\n571:                                   hybridUnits.map(_.io.canAcceptLowConfPrefetch)\n\
      572:   val canAcceptLowConfPrefetch = loadUnits.map(_.io.canAcceptLowConfPrefetch)
      ++\n573:                                  hybridUnits.map(_.io.canAcceptLowConfPrefetch)\n\
      574:   l1_pf_req.ready := (0 until LduCnt + HyuCnt).map{\n575:     case i =>
      {\n576:       if (LowConfPorts.contains(i)) {\n577:         loadUnits(i).io.canAcceptLowConfPrefetch\n\
      578:       } else {\n579:         Mux(l1_pf_req.bits.confidence === 1.U, canAcceptHighConfPrefetch(i),
      canAcceptLowConfPrefetch(i))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 588-598
    context: "588:     val fuzzer = Module(new L1PrefetchFuzzer())\n589:     fuzzer.io.vaddr
      := DontCare\n590:     fuzzer.io.paddr := DontCare\n591: \n592:     // override
      load_unit prefetch_req\n593:     loadUnits.foreach(load_unit => {\n594:    \
      \   load_unit.io.prefetch_req.valid <> fuzzer.io.req.valid\n595:       load_unit.io.prefetch_req.bits
      <> fuzzer.io.req.bits\n596:     })\n597: \n598:     // override hybrid_unit
      prefetch_req"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 594-609
    context: "594:       load_unit.io.prefetch_req.valid <> fuzzer.io.req.valid\n\
      595:       load_unit.io.prefetch_req.bits <> fuzzer.io.req.bits\n596:     })\n\
      597: \n598:     // override hybrid_unit prefetch_req\n599:     hybridUnits.foreach(hybrid_unit
      => {\n600:       hybrid_unit.io.ldu_io.prefetch_req.valid <> fuzzer.io.req.valid\n\
      601:       hybrid_unit.io.ldu_io.prefetch_req.bits <> fuzzer.io.req.bits\n602:\
      \     })\n603: \n604:     fuzzer.io.req.ready := l1_pf_req.ready\n605:   }\n\
      606: \n607:   // TODO: fast load wakeup\n608:   val lsq     = Module(new LsqWrapper)\n\
      609:   val sbuffer = Module(new Sbuffer)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 619-640
    context: "619:   dcache.io.lqEmpty := lsq.io.lqEmpty\n620:   dcache.io.wfi.wfiReq
      := io.wfi.wfiReq\n621:   lsq.io.wfi.wfiReq := io.wfi.wfiReq\n622: \n623:   //
      load/store prefetch to l2 cache\n624:   prefetcherOpt.foreach(sms_pf => {\n\
      625:     l1PrefetcherOpt.foreach(l1_pf => {\n626:       val sms_pf_to_l2 = DelayNWithValid(sms_pf.io.l2_req,
      2)\n627:       val l1_pf_to_l2 = DelayNWithValid(l1_pf.io.l2_req, 2)\n628: \n\
      629:       outer.l2_pf_sender_opt.get.out.head._1.addr_valid := sms_pf_to_l2.valid
      || l1_pf_to_l2.valid\n630:       outer.l2_pf_sender_opt.get.out.head._1.addr
      := Mux(l1_pf_to_l2.valid, l1_pf_to_l2.bits.addr, sms_pf_to_l2.bits.addr)\n631:\
      \       outer.l2_pf_sender_opt.get.out.head._1.pf_source := Mux(l1_pf_to_l2.valid,
      l1_pf_to_l2.bits.source, sms_pf_to_l2.bits.source)\n632:       outer.l2_pf_sender_opt.get.out.head._1.l2_pf_en
      := RegNextN(io.ooo_to_mem.csrCtrl.pf_ctrl.l2_pf_enable, 2, Some(true.B))\n633:\
      \ \n634:       val l2_trace = Wire(new LoadPfDbBundle)\n635:       l2_trace.paddr
      := outer.l2_pf_sender_opt.get.out.head._1.addr\n636:       val table = ChiselDB.createTable(s\"\
      L2PrefetchTrace$hartId\", new LoadPfDbBundle, basicDB = false)\n637:       table.log(l2_trace,
      l1_pf_to_l2.valid, \"StreamPrefetchTrace\", clock, reset)\n638:       table.log(l2_trace,
      !l1_pf_to_l2.valid && sms_pf_to_l2.valid, \"L2PrefetchTrace\", clock, reset)\n\
      639: \n640:       val l1_pf_to_l3 = ValidIODelay(l1_pf.io.l3_req, 4)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 636-656
    context: "636:       val table = ChiselDB.createTable(s\"L2PrefetchTrace$hartId\"\
      , new LoadPfDbBundle, basicDB = false)\n637:       table.log(l2_trace, l1_pf_to_l2.valid,
      \"StreamPrefetchTrace\", clock, reset)\n638:       table.log(l2_trace, !l1_pf_to_l2.valid
      && sms_pf_to_l2.valid, \"L2PrefetchTrace\", clock, reset)\n639: \n640:     \
      \  val l1_pf_to_l3 = ValidIODelay(l1_pf.io.l3_req, 4)\n641:       outer.l3_pf_sender_opt.foreach(_.out.head._1.addr_valid
      := l1_pf_to_l3.valid)\n642:       outer.l3_pf_sender_opt.foreach(_.out.head._1.addr
      := l1_pf_to_l3.bits)\n643:       outer.l3_pf_sender_opt.foreach(_.out.head._1.l2_pf_en
      := RegNextN(io.ooo_to_mem.csrCtrl.pf_ctrl.l2_pf_enable, 4, Some(true.B)))\n\
      644: \n645:       val l3_trace = Wire(new LoadPfDbBundle)\n646:       l3_trace.paddr
      := outer.l3_pf_sender_opt.map(_.out.head._1.addr).getOrElse(0.U)\n647:     \
      \  val l3_table = ChiselDB.createTable(s\"L3PrefetchTrace$hartId\", new LoadPfDbBundle,
      basicDB = false)\n648:       l3_table.log(l3_trace, l1_pf_to_l3.valid, \"StreamPrefetchTrace\"\
      , clock, reset)\n649: \n650:       XSPerfAccumulate(\"prefetch_fire_l2\", outer.l2_pf_sender_opt.get.out.head._1.addr_valid)\n\
      651:       XSPerfAccumulate(\"prefetch_fire_l3\", outer.l3_pf_sender_opt.map(_.out.head._1.addr_valid).getOrElse(false.B))\n\
      652:       XSPerfAccumulate(\"l1pf_fire_l2\", l1_pf_to_l2.valid)\n653:     \
      \  XSPerfAccumulate(\"sms_fire_l2\", !l1_pf_to_l2.valid && sms_pf_to_l2.valid)\n\
      654:       XSPerfAccumulate(\"sms_block_by_l1pf\", l1_pf_to_l2.valid && sms_pf_to_l2.valid)\n\
      655:     })\n656:   })"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 676-686
    context: "676:   }\n677: \n678:   // dtlb\n679:   val dtlb_ld_tlb_ld = Module(new
      TLBNonBlock(LduCnt + HyuCnt + 1, 2, ldtlbParams))\n680:   val dtlb_st_tlb_st
      = Module(new TLBNonBlock(StaCnt, 1, sttlbParams))\n681:   val dtlb_prefetch_tlb_prefetch
      = Module(new TLBNonBlock(2, 2, pftlbParams))\n682:   val dtlb_ld = Seq(dtlb_ld_tlb_ld.io)\n\
      683:   val dtlb_st = Seq(dtlb_st_tlb_st.io)\n684:   val dtlb_prefetch = Seq(dtlb_prefetch_tlb_prefetch.io)\n\
      685:   /* tlb vec && constant variable */\n686:   val dtlb = dtlb_ld ++ dtlb_st
      ++ dtlb_prefetch"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 694-709
    context: "694:   val dtlb_reqs = dtlb.map(_.requestor).flatten\n695:   val dtlb_pmps
      = dtlb.map(_.pmp).flatten\n696:   dtlb.map(_.hartId := io.hartId)\n697:   dtlb.map(_.sfence
      := sfence)\n698:   dtlb.map(_.csr := tlbcsr)\n699:   dtlb.map(_.flushPipe.map(a
      => a := false.B)) // non-block doesn't need\n700:   dtlb.map(_.redirect := redirect)\n\
      701:   if (refillBothTlb) {\n702:     require(ldtlbParams.outReplace == sttlbParams.outReplace)\n\
      703:     require(ldtlbParams.outReplace == hytlbParams.outReplace)\n704:   \
      \  require(ldtlbParams.outReplace == pftlbParams.outReplace)\n705:     require(ldtlbParams.outReplace)\n\
      706: \n707:     val replace = Module(new TlbReplace(DTlbSize, ldtlbParams))\n\
      708:     replace.io.apply_sep(dtlb_ld.map(_.replace) ++ dtlb_st.map(_.replace)
      ++ dtlb_prefetch.map(_.replace), ptwio.resp.bits.data.s1.entry.tag)\n709:  \
      \ } else {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 718-729
    context: "718:     }\n719:     if (sttlbParams.outReplace) {\n720:       val replace_st
      = Module(new TlbReplace(StaCnt, sttlbParams))\n721:       replace_st.io.apply_sep(dtlb_st.map(_.replace),
      ptwio.resp.bits.data.s1.entry.tag)\n722:     }\n723:     if (pftlbParams.outReplace)
      {\n724:       val replace_pf = Module(new TlbReplace(2, pftlbParams))\n725:\
      \       replace_pf.io.apply_sep(dtlb_prefetch.map(_.replace), ptwio.resp.bits.data.s1.entry.tag)\n\
      726:     }\n727:   }\n728: \n729:   val ptw_resp_next = RegEnable(ptwio.resp.bits,
      ptwio.resp.valid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 726-736
    context: "726:     }\n727:   }\n728: \n729:   val ptw_resp_next = RegEnable(ptwio.resp.bits,
      ptwio.resp.valid)\n730:   val ptw_resp_v = RegNext(ptwio.resp.valid && !(sfence.valid
      || tlbcsr.satp.changed || tlbcsr.vsatp.changed || tlbcsr.hgatp.changed || tlbcsr.priv.virt_changed),
      init = false.B)\n731:   ptwio.resp.ready := true.B\n732: \n733:   val tlbreplay
      = WireInit(VecInit(Seq.fill(LdExuCnt)(false.B)))\n734:   val tlbreplay_reg =
      GatedValidRegNext(tlbreplay)\n735:   val dtlb_ld0_tlbreplay_reg = GatedValidRegNext(dtlb_ld(0).tlbreplay)\n\
      736: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 742-753
    context: "742:         allType = true, ignoreAsid = true) // Maybe need not ignoreAsid
      here, however not a functional bug\n743:   }\n744: \n745:   dtlb.flatMap(a =>
      a.ptw.req)\n746:     .zipWithIndex\n747:     .foreach{ case (tlb, i) =>\n748:\
      \       tlb.ready := ptwio.req(i).ready\n749:       ptwio.req(i).bits := tlb.bits\n\
      750:     val vector_hit = if (refillBothTlb) Cat(ptw_resp_next.vector).orR\n\
      751:       else if (i < TlbEndVec(dtlb_ld_idx)) Cat(ptw_resp_next.vector.slice(TlbStartVec(dtlb_ld_idx),
      TlbEndVec(dtlb_ld_idx))).orR\n752:       else if (i < TlbEndVec(dtlb_st_idx))
      Cat(ptw_resp_next.vector.slice(TlbStartVec(dtlb_st_idx), TlbEndVec(dtlb_st_idx))).orR\n\
      753:       else                                 Cat(ptw_resp_next.vector.slice(TlbStartVec(dtlb_pf_idx),
      TlbEndVec(dtlb_pf_idx))).orR"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 754-777
    context: "754:     ptwio.req(i).valid := tlb.valid &&\n755:       !(ptw_resp_v
      && vector_hit &&\n756:         ptw_resp_next.data.hit(tlb.bits.vpn, tlbcsr.satp.asid,
      tlbcsr.vsatp.asid, tlbcsr.hgatp.vmid,\n757:           allType = true, ignoreAsid
      = true)) // // Maybe need not ignoreAsid here, however not a functional bug\n\
      758:   }\n759:   dtlb.foreach(_.ptw.resp.bits := ptw_resp_next.data)\n760: \
      \  if (refillBothTlb) {\n761:     dtlb.foreach(_.ptw.resp.valid := ptw_resp_v
      && Cat(ptw_resp_next.vector).orR)\n762:   } else {\n763:     dtlb_ld.foreach(_.ptw.resp.valid
      := ptw_resp_v && Cat(ptw_resp_next.vector.slice(TlbStartVec(dtlb_ld_idx), TlbEndVec(dtlb_ld_idx))).orR)\n\
      764:     dtlb_st.foreach(_.ptw.resp.valid := ptw_resp_v && Cat(ptw_resp_next.vector.slice(TlbStartVec(dtlb_st_idx),
      TlbEndVec(dtlb_st_idx))).orR)\n765:     dtlb_prefetch.foreach(_.ptw.resp.valid
      := ptw_resp_v && Cat(ptw_resp_next.vector.slice(TlbStartVec(dtlb_pf_idx), TlbEndVec(dtlb_pf_idx))).orR)\n\
      766:   }\n767:   dtlb_ld.foreach(_.ptw.resp.bits.getGpa := Cat(ptw_resp_next.getGpa.take(LduCnt
      + HyuCnt + 1)).orR)\n768:   dtlb_st.foreach(_.ptw.resp.bits.getGpa := Cat(ptw_resp_next.getGpa.slice(LduCnt
      + HyuCnt + 1, LduCnt + HyuCnt + 1 + StaCnt)).orR)\n769:   dtlb_prefetch.foreach(_.ptw.resp.bits.getGpa
      := Cat(ptw_resp_next.getGpa.drop(LduCnt + HyuCnt + 1 + StaCnt)).orR)\n770: \n\
      771:   val dtlbRepeater  = PTWNewFilter(ldtlbParams.fenceDelay, ptwio, ptw.io.tlb(1),
      sfence, tlbcsr, l2tlbParams.dfilterSize)\n772:   val itlbRepeater3 = PTWRepeaterNB(passReady
      = false, itlbParams.fenceDelay, io.fetch_to_mem.itlb, ptw.io.tlb(0), sfence,
      tlbcsr)\n773: \n774:   lsq.io.debugTopDown.robHeadMissInDTlb := dtlbRepeater.io.rob_head_miss_in_tlb\n\
      775: \n776:   // pmp\n777:   val pmp = Module(new PMP())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 822-832
    context: "822: \n823:   // The segment instruction is executed atomically.\n824:\
      \   // After the segment instruction directive starts executing, no other instructions
      should be executed.\n825:   val vSegmentFlag = RegInit(false.B)\n826: \n827:\
      \   when(GatedValidRegNext(vSegmentUnit.io.in.fire)) {\n828:     vSegmentFlag
      := true.B\n829:   }.elsewhen(GatedValidRegNext(vSegmentUnit.io.uopwriteback.valid))
      {\n830:     vSegmentFlag := false.B\n831:   }\n832: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 842-852
    context: "842: \n843:   // LoadUnit\n844:   val correctMissTrain = Constantin.createRecord(s\"\
      CorrectMissTrain$hartId\", initValue = false)\n845: \n846:   for (i <- 0 until
      LduCnt) {\n847:     loadUnits(i).io.redirect <> redirect\n848:     loadUnits(i).io.misalign_allow_spec
      := misalign_allow_spec\n849: \n850:     // get input form dispatch\n851:   \
      \  loadUnits(i).io.ldin <> io.ooo_to_mem.issueLda(i)\n852:     loadUnits(i).io.feedback_slow
      <> io.mem_to_ooo.ldaIqFeedback(i).feedbackSlow"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 855-869
    context: "855:     io.mem_to_ooo.ldCancel.drop(HyuCnt)(i) := loadUnits(i).io.ldCancel\n\
      856:     io.mem_to_ooo.wakeup.drop(HyuCnt)(i) := loadUnits(i).io.wakeup\n857:\
      \ \n858:     // vector\n859:     if (i < VlduCnt) {\n860:       loadUnits(i).io.vecldout.ready
      := false.B\n861:     } else {\n862:       loadUnits(i).io.vecldin.valid := false.B\n\
      863:       loadUnits(i).io.vecldin.bits := DontCare\n864:       loadUnits(i).io.vecldout.ready
      := false.B\n865:     }\n866: \n867:     // fast replay\n868:     loadUnits(i).io.fast_rep_in
      <> loadUnits(i).io.fast_rep_out\n869: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 877-892
    context: "877:       dcache.io.lsu.load(i).req.valid := loadUnits(i).io.dcache.req.valid
      || vSegmentUnit.io.rdcache.req.valid\n878:       dcache.io.lsu.load(i).req.bits\
      \  := Mux1H(Seq(\n879:         vSegmentUnit.io.rdcache.req.valid -> vSegmentUnit.io.rdcache.req.bits,\n\
      880:         loadUnits(i).io.dcache.req.valid -> loadUnits(i).io.dcache.req.bits\n\
      881:       ))\n882:       vSegmentUnit.io.rdcache.req.ready := dcache.io.lsu.load(i).req.ready\n\
      883:     }\n884: \n885:     // Dcache requests must also be preempted by the
      segment.\n886:     when(vSegmentFlag){\n887:       loadUnits(i).io.dcache.req.ready\
      \             := false.B // Dcache is preempted.\n888: \n889:       dcache.io.lsu.load(0).pf_source\
      \              := vSegmentUnit.io.rdcache.pf_source\n890:       dcache.io.lsu.load(0).s1_paddr_dup_lsu\
      \       := vSegmentUnit.io.rdcache.s1_paddr_dup_lsu\n891:       dcache.io.lsu.load(0).s1_paddr_dup_dcache\
      \    := vSegmentUnit.io.rdcache.s1_paddr_dup_dcache\n892:       dcache.io.lsu.load(0).s1_kill\
      \                := vSegmentUnit.io.rdcache.s1_kill"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 894-904
    context: "894:       dcache.io.lsu.load(0).s0_pc                  := vSegmentUnit.io.rdcache.s0_pc\n\
      895:       dcache.io.lsu.load(0).s1_pc                  := vSegmentUnit.io.rdcache.s1_pc\n\
      896:       dcache.io.lsu.load(0).s2_pc                  := vSegmentUnit.io.rdcache.s2_pc\n\
      897:       dcache.io.lsu.load(0).is128Req               := vSegmentUnit.io.rdcache.is128Req\n\
      898:     }.otherwise {\n899:       loadUnits(i).io.dcache.req.ready        \
      \     := dcache.io.lsu.load(i).req.ready\n900: \n901:       dcache.io.lsu.load(0).pf_source\
      \              := loadUnits(0).io.dcache.pf_source\n902:       dcache.io.lsu.load(0).s1_paddr_dup_lsu\
      \       := loadUnits(0).io.dcache.s1_paddr_dup_lsu\n903:       dcache.io.lsu.load(0).s1_paddr_dup_dcache\
      \    := loadUnits(0).io.dcache.s1_paddr_dup_dcache\n904:       dcache.io.lsu.load(0).s1_kill\
      \                := loadUnits(0).io.dcache.s1_kill"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 908-920
    context: "908:       dcache.io.lsu.load(0).s2_pc                  := loadUnits(0).io.dcache.s2_pc\n\
      909:       dcache.io.lsu.load(0).is128Req               := loadUnits(0).io.dcache.is128Req\n\
      910:     }\n911: \n912:     // forward\n913:     loadUnits(i).io.lsq.forward
      <> lsq.io.forward(i)\n914:     loadUnits(i).io.sbuffer <> sbuffer.io.forward(i)\n\
      915:     loadUnits(i).io.ubuffer <> uncache.io.forward(i)\n916:     loadUnits(i).io.tl_d_channel
      := dcache.io.lsu.forward_D(i)\n917:     loadUnits(i).io.forward_mshr <> dcache.io.lsu.forward_mshr(i)\n\
      918:     // ld-ld violation check\n919:     loadUnits(i).io.lsq.ldld_nuke_query
      <> lsq.io.ldu.ldld_nuke_query(i)\n920:     loadUnits(i).io.lsq.stld_nuke_query
      <> lsq.io.ldu.stld_nuke_query(i)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 926-936
    context: "926:     // dtlb\n927:     loadUnits(i).io.tlb <> dtlb_reqs.take(LduCnt)(i)\n\
      928:     if(i == 0 ){ // port 0 assign to vsegmentUnit\n929:       val vsegmentDtlbReqValid
      = vSegmentUnit.io.dtlb.req.valid // segment tlb resquest need to delay 1 cycle\n\
      930:       dtlb_reqs.take(LduCnt)(i).req.valid := loadUnits(i).io.tlb.req.valid
      || RegNext(vsegmentDtlbReqValid)\n931:       vSegmentUnit.io.dtlb.req.ready\
      \      := dtlb_reqs.take(LduCnt)(i).req.ready\n932:       dtlb_reqs.take(LduCnt)(i).req.bits\
      \  := ParallelPriorityMux(Seq(\n933:         RegNext(vsegmentDtlbReqValid) \
      \    -> RegEnable(vSegmentUnit.io.dtlb.req.bits, vsegmentDtlbReqValid),\n934:\
      \         loadUnits(i).io.tlb.req.valid     -> loadUnits(i).io.tlb.req.bits\n\
      935:       ))\n936:     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 941-951
    context: "941:     for (s <- 0 until StorePipelineWidth) {\n942:       loadUnits(i).io.stld_nuke_query(s)
      := stld_nuke_query(s)\n943:     }\n944:     loadUnits(i).io.lq_rep_full <> lsq.io.lq_rep_full\n\
      945:     // load prefetch train\n946:     prefetcherOpt.foreach(pf => {\n947:\
      \       // sms will train on all miss load sources\n948:       val source =
      loadUnits(i).io.prefetch_train\n949:       pf.io.ld_in(i).valid := Mux(pf_train_on_hit,\n\
      950:         source.valid,\n951:         source.valid && source.bits.isFirstIssue
      && source.bits.miss"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 956-966
    context: "956:         loadUnits(i).io.s2_ptr_chasing,\n957:         RegEnable(loadPc,
      loadUnits(i).io.s2_prefetch_spec),\n958:         RegEnable(RegEnable(loadPc,
      loadUnits(i).io.s1_prefetch_spec), loadUnits(i).io.s2_prefetch_spec)\n959: \
      \      )\n960:     })\n961:     l1PrefetcherOpt.foreach(pf => {\n962:      \
      \ // stream will train on all load sources\n963:       val source = loadUnits(i).io.prefetch_train_l1\n\
      964:       pf.io.ld_in(i).valid := source.valid && source.bits.isFirstIssue\n\
      965:       pf.io.ld_in(i).bits := source.bits\n966:     })"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 966-987
    context: "966:     })\n967: \n968:     // load to load fast forward: load(i) prefers
      data(i)\n969:     val l2l_fwd_out = loadUnits.map(_.io.l2l_fwd_out) ++ hybridUnits.map(_.io.ldu_io.l2l_fwd_out)\n\
      970:     val fastPriority = (i until LduCnt + HyuCnt) ++ (0 until i)\n971: \
      \    val fastValidVec = fastPriority.map(j => l2l_fwd_out(j).valid)\n972:  \
      \   val fastDataVec = fastPriority.map(j => l2l_fwd_out(j).data)\n973:     val
      fastErrorVec = fastPriority.map(j => l2l_fwd_out(j).dly_ld_err)\n974:     val
      fastMatchVec = fastPriority.map(j => io.ooo_to_mem.loadFastMatch(i)(j))\n975:\
      \     loadUnits(i).io.l2l_fwd_in.valid := VecInit(fastValidVec).asUInt.orR\n\
      976:     loadUnits(i).io.l2l_fwd_in.data := ParallelPriorityMux(fastValidVec,
      fastDataVec)\n977:     loadUnits(i).io.l2l_fwd_in.dly_ld_err := ParallelPriorityMux(fastValidVec,
      fastErrorVec)\n978:     val fastMatch = ParallelPriorityMux(fastValidVec, fastMatchVec)\n\
      979:     loadUnits(i).io.ld_fast_match := fastMatch\n980:     loadUnits(i).io.ld_fast_imm
      := io.ooo_to_mem.loadFastImm(i)\n981:     loadUnits(i).io.ld_fast_fuOpType :=
      io.ooo_to_mem.loadFastFuOpType(i)\n982:     loadUnits(i).io.replay <> lsq.io.replay(i)\n\
      983: \n984:     val l2_hint = RegNext(io.l2_hint)\n985: \n986:     // L2 Hint
      for DCache\n987:     dcache.io.l2_hint <> l2_hint"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 994-1004
    context: "994:     // passdown to lsq (load s2)\n995:     lsq.io.ldu.ldin(i) <>
      loadUnits(i).io.lsq.ldin\n996:     if (i == UncacheWBPort) {\n997:       lsq.io.ldout(i)
      <> loadUnits(i).io.lsq.uncache\n998:     } else {\n999:       lsq.io.ldout(i).ready
      := true.B\n1000:       loadUnits(i).io.lsq.uncache.valid := false.B\n1001: \
      \      loadUnits(i).io.lsq.uncache.bits := DontCare\n1002:     }\n1003:    \
      \ lsq.io.ld_raw_data(i) <> loadUnits(i).io.lsq.ld_raw_data\n1004:     lsq.io.ncOut(i)
      <> loadUnits(i).io.lsq.nc_ldin"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1033-1043
    context: "1033:     loadUnits(i).io.fromCsrTrigger.triggerCanRaiseBpExp := triggerCanRaiseBpExp\n\
      1034:     loadUnits(i).io.fromCsrTrigger.debugMode := debugMode\n1035:   }\n\
      1036: \n1037:   for (i <- 0 until HyuCnt) {\n1038:     hybridUnits(i).io.redirect
      <> redirect\n1039: \n1040:     // get input from dispatch\n1041:     hybridUnits(i).io.lsin
      <> io.ooo_to_mem.issueHya(i)\n1042:     hybridUnits(i).io.feedback_slow <> io.mem_to_ooo.hyuIqFeedback(i).feedbackSlow\n\
      1043:     hybridUnits(i).io.feedback_fast <> io.mem_to_ooo.hyuIqFeedback(i).feedbackFast"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1054-1067
    context: "1054:     // get input from dispatch\n1055:     hybridUnits(i).io.ldu_io.dcache
      <> dcache.io.lsu.load(LduCnt + i)\n1056:     hybridUnits(i).io.stu_io.dcache
      <> dcache.io.lsu.sta(StaCnt + i)\n1057: \n1058:     // dcache access\n1059:\
      \     hybridUnits(i).io.ldu_io.lsq.forward <> lsq.io.forward(LduCnt + i)\n1060:\
      \     // forward\n1061:     hybridUnits(i).io.ldu_io.sbuffer <> sbuffer.io.forward(LduCnt
      + i)\n1062:     hybridUnits(i).io.ldu_io.ubuffer <> uncache.io.forward(LduCnt
      + i)\n1063:     // hybridUnits(i).io.ldu_io.vec_forward <> vsFlowQueue.io.forward(LduCnt
      + i)\n1064:     hybridUnits(i).io.ldu_io.vec_forward := DontCare\n1065:    \
      \ hybridUnits(i).io.ldu_io.tl_d_channel := dcache.io.lsu.forward_D(LduCnt +
      i)\n1066:     hybridUnits(i).io.ldu_io.forward_mshr <> dcache.io.lsu.forward_mshr(LduCnt
      + i)\n1067:     // ld-ld violation check"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1072-1082
    context: "1072:     hybridUnits(i).io.ldu_io.tlb_hint.id := dtlbRepeater.io.hint.get.req(LduCnt
      + i).id\n1073:     hybridUnits(i).io.ldu_io.tlb_hint.full := dtlbRepeater.io.hint.get.req(LduCnt
      + i).full ||\n1074:       tlbreplay_reg(LduCnt + i) || dtlb_ld0_tlbreplay_reg(LduCnt
      + i)\n1075: \n1076:     // dtlb\n1077:     hybridUnits(i).io.tlb <> dtlb_ld.head.requestor(LduCnt
      + i)\n1078:     // pmp\n1079:     hybridUnits(i).io.pmp <> pmp_check.drop(LduCnt)(i).resp\n\
      1080:     // st-ld violation query\n1081:     val stld_nuke_query = VecInit(storeUnits.map(_.io.stld_nuke_query)
      ++ hybridUnits.map(_.io.stu_io.stld_nuke_query))\n1082:     hybridUnits(i).io.ldu_io.stld_nuke_query
      := stld_nuke_query"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1080-1090
    context: "1080:     // st-ld violation query\n1081:     val stld_nuke_query =
      VecInit(storeUnits.map(_.io.stld_nuke_query) ++ hybridUnits.map(_.io.stu_io.stld_nuke_query))\n\
      1082:     hybridUnits(i).io.ldu_io.stld_nuke_query := stld_nuke_query\n1083:\
      \     hybridUnits(i).io.ldu_io.lq_rep_full <> lsq.io.lq_rep_full\n1084:    \
      \ // load prefetch train\n1085:     prefetcherOpt.foreach(pf => {\n1086:   \
      \    val source = hybridUnits(i).io.prefetch_train\n1087:       pf.io.ld_in(LduCnt
      + i).valid := Mux(pf_train_on_hit,\n1088:         source.valid,\n1089:     \
      \    source.valid && source.bits.isFirstIssue && source.bits.miss\n1090:   \
      \    )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1089-1099
    context: "1089:         source.valid && source.bits.isFirstIssue && source.bits.miss\n\
      1090:       )\n1091:       pf.io.ld_in(LduCnt + i).bits := source.bits\n1092:\
      \       pf.io.ld_in(LduCnt + i).bits.uop.pc := Mux(hybridUnits(i).io.ldu_io.s2_ptr_chasing,
      io.ooo_to_mem.hybridPc(i), RegNext(io.ooo_to_mem.hybridPc(i)))\n1093:     })\n\
      1094:     l1PrefetcherOpt.foreach(pf => {\n1095:       // stream will train
      on all load sources\n1096:       val source = hybridUnits(i).io.prefetch_train_l1\n\
      1097:       pf.io.ld_in(LduCnt + i).valid := source.valid && source.bits.isFirstIssue
      &&\n1098:                                        FuType.isLoad(source.bits.uop.fuType)\n\
      1099:       pf.io.ld_in(LduCnt + i).bits := source.bits"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1098-1108
    context: "1098:                                        FuType.isLoad(source.bits.uop.fuType)\n\
      1099:       pf.io.ld_in(LduCnt + i).bits := source.bits\n1100:       pf.io.st_in(StaCnt
      + i).valid := false.B\n1101:       pf.io.st_in(StaCnt + i).bits := DontCare\n\
      1102:     })\n1103:     prefetcherOpt.foreach(pf => {\n1104:       val source
      = hybridUnits(i).io.prefetch_train\n1105:       pf.io.st_in(StaCnt + i).valid
      := Mux(pf_train_on_hit,\n1106:         source.valid,\n1107:         source.valid
      && source.bits.isFirstIssue && source.bits.miss\n1108:       ) && FuType.isStore(source.bits.uop.fuType)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1111-1132
    context: "1111:     })\n1112: \n1113:     // load to load fast forward: load(i)
      prefers data(i)\n1114:     val l2l_fwd_out = loadUnits.map(_.io.l2l_fwd_out)
      ++ hybridUnits.map(_.io.ldu_io.l2l_fwd_out)\n1115:     val fastPriority = (LduCnt
      + i until LduCnt + HyuCnt) ++ (0 until LduCnt + i)\n1116:     val fastValidVec
      = fastPriority.map(j => l2l_fwd_out(j).valid)\n1117:     val fastDataVec = fastPriority.map(j
      => l2l_fwd_out(j).data)\n1118:     val fastErrorVec = fastPriority.map(j =>
      l2l_fwd_out(j).dly_ld_err)\n1119:     val fastMatchVec = fastPriority.map(j
      => io.ooo_to_mem.loadFastMatch(LduCnt + i)(j))\n1120:     hybridUnits(i).io.ldu_io.l2l_fwd_in.valid
      := VecInit(fastValidVec).asUInt.orR\n1121:     hybridUnits(i).io.ldu_io.l2l_fwd_in.data
      := ParallelPriorityMux(fastValidVec, fastDataVec)\n1122:     hybridUnits(i).io.ldu_io.l2l_fwd_in.dly_ld_err
      := ParallelPriorityMux(fastValidVec, fastErrorVec)\n1123:     val fastMatch
      = ParallelPriorityMux(fastValidVec, fastMatchVec)\n1124:     hybridUnits(i).io.ldu_io.ld_fast_match
      := fastMatch\n1125:     hybridUnits(i).io.ldu_io.ld_fast_imm := io.ooo_to_mem.loadFastImm(LduCnt
      + i)\n1126:     hybridUnits(i).io.ldu_io.ld_fast_fuOpType := io.ooo_to_mem.loadFastFuOpType(LduCnt
      + i)\n1127:     hybridUnits(i).io.ldu_io.replay <> lsq.io.replay(LduCnt + i)\n\
      1128:     hybridUnits(i).io.ldu_io.l2_hint <> io.l2_hint\n1129: \n1130:    \
      \ // uncache\n1131:     lsq.io.ldout.drop(LduCnt)(i) <> hybridUnits(i).io.ldu_io.lsq.uncache\n\
      1132:     lsq.io.ld_raw_data.drop(LduCnt)(i) <> hybridUnits(i).io.ldu_io.lsq.ld_raw_data"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1170-1180
    context: "1170:     hybridUnits(i).io.fromCsrTrigger.triggerCanRaiseBpExp := triggerCanRaiseBpExp\n\
      1171:     hybridUnits(i).io.fromCsrTrigger.debugMode := debugMode\n1172:   }\n\
      1173: \n1174:   // misalignBuffer\n1175:   loadMisalignBuffer.io.redirect  \
      \              <> redirect\n1176:   loadMisalignBuffer.io.rob.lcommit      \
      \       := io.ooo_to_mem.lsqio.lcommit\n1177:   loadMisalignBuffer.io.rob.scommit\
      \             := io.ooo_to_mem.lsqio.scommit\n1178:   loadMisalignBuffer.io.rob.pendingMMIOld\
      \       := io.ooo_to_mem.lsqio.pendingMMIOld\n1179:   loadMisalignBuffer.io.rob.pendingld\
      \           := io.ooo_to_mem.lsqio.pendingld\n1180:   loadMisalignBuffer.io.rob.pendingst\
      \           := io.ooo_to_mem.lsqio.pendingst"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1177-1187
    context: "1177:   loadMisalignBuffer.io.rob.scommit             := io.ooo_to_mem.lsqio.scommit\n\
      1178:   loadMisalignBuffer.io.rob.pendingMMIOld       := io.ooo_to_mem.lsqio.pendingMMIOld\n\
      1179:   loadMisalignBuffer.io.rob.pendingld           := io.ooo_to_mem.lsqio.pendingld\n\
      1180:   loadMisalignBuffer.io.rob.pendingst           := io.ooo_to_mem.lsqio.pendingst\n\
      1181:   loadMisalignBuffer.io.rob.pendingVst          := io.ooo_to_mem.lsqio.pendingVst\n\
      1182:   loadMisalignBuffer.io.rob.commit              := io.ooo_to_mem.lsqio.commit\n\
      1183:   loadMisalignBuffer.io.rob.pendingPtr          := io.ooo_to_mem.lsqio.pendingPtr\n\
      1184:   loadMisalignBuffer.io.rob.pendingPtrNext      := io.ooo_to_mem.lsqio.pendingPtrNext\n\
      1185: \n1186:   lsq.io.loadMisalignFull                       := loadMisalignBuffer.io.loadMisalignFull\n\
      1187:   lsq.io.misalignAllowSpec                      := misalign_allow_spec"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1184-1194
    context: "1184:   loadMisalignBuffer.io.rob.pendingPtrNext      := io.ooo_to_mem.lsqio.pendingPtrNext\n\
      1185: \n1186:   lsq.io.loadMisalignFull                       := loadMisalignBuffer.io.loadMisalignFull\n\
      1187:   lsq.io.misalignAllowSpec                      := misalign_allow_spec\n\
      1188: \n1189:   storeMisalignBuffer.io.redirect               <> redirect\n\
      1190:   storeMisalignBuffer.io.rob.lcommit            := io.ooo_to_mem.lsqio.lcommit\n\
      1191:   storeMisalignBuffer.io.rob.scommit            := io.ooo_to_mem.lsqio.scommit\n\
      1192:   storeMisalignBuffer.io.rob.pendingMMIOld      := io.ooo_to_mem.lsqio.pendingMMIOld\n\
      1193:   storeMisalignBuffer.io.rob.pendingld          := io.ooo_to_mem.lsqio.pendingld\n\
      1194:   storeMisalignBuffer.io.rob.pendingst          := io.ooo_to_mem.lsqio.pendingst"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1191-1201
    context: "1191:   storeMisalignBuffer.io.rob.scommit            := io.ooo_to_mem.lsqio.scommit\n\
      1192:   storeMisalignBuffer.io.rob.pendingMMIOld      := io.ooo_to_mem.lsqio.pendingMMIOld\n\
      1193:   storeMisalignBuffer.io.rob.pendingld          := io.ooo_to_mem.lsqio.pendingld\n\
      1194:   storeMisalignBuffer.io.rob.pendingst          := io.ooo_to_mem.lsqio.pendingst\n\
      1195:   storeMisalignBuffer.io.rob.pendingVst         := io.ooo_to_mem.lsqio.pendingVst\n\
      1196:   storeMisalignBuffer.io.rob.commit             := io.ooo_to_mem.lsqio.commit\n\
      1197:   storeMisalignBuffer.io.rob.pendingPtr         := io.ooo_to_mem.lsqio.pendingPtr\n\
      1198:   storeMisalignBuffer.io.rob.pendingPtrNext     := io.ooo_to_mem.lsqio.pendingPtrNext\n\
      1199: \n1200:   lsq.io.maControl                              <> storeMisalignBuffer.io.sqControl\n\
      1201: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1211-1221
    context: "1211:     dtlb_reqs(PrefetcherDTLBPortIndex) <> pf.io.tlb_req\n1212:\
      \     pf.io.pmp_resp := pmp_check(PrefetcherDTLBPortIndex).resp\n1213:   case
      None =>\n1214:     dtlb_reqs(PrefetcherDTLBPortIndex) := DontCare\n1215:   \
      \  dtlb_reqs(PrefetcherDTLBPortIndex).req.valid := false.B\n1216:     dtlb_reqs(PrefetcherDTLBPortIndex).resp.ready
      := true.B\n1217:   }\n1218:   l1PrefetcherOpt match {\n1219:     case Some(pf)
      =>\n1220:       dtlb_reqs(StreamDTLBPortIndex) <> pf.io.tlb_req\n1221:     \
      \  pf.io.pmp_resp := pmp_check(StreamDTLBPortIndex).resp"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1220-1240
    context: "1220:       dtlb_reqs(StreamDTLBPortIndex) <> pf.io.tlb_req\n1221: \
      \      pf.io.pmp_resp := pmp_check(StreamDTLBPortIndex).resp\n1222:     case
      None =>\n1223:         dtlb_reqs(StreamDTLBPortIndex) := DontCare\n1224:   \
      \      dtlb_reqs(StreamDTLBPortIndex).req.valid := false.B\n1225:         dtlb_reqs(StreamDTLBPortIndex).resp.ready
      := true.B\n1226:   }\n1227:   dtlb_reqs(L2toL1DLBPortIndex) <> io.l2_tlb_req\n\
      1228:   dtlb_reqs(L2toL1DLBPortIndex).resp.ready := true.B\n1229:   io.l2_pmp_resp
      := pmp_check(L2toL1DLBPortIndex).resp\n1230: \n1231:   // StoreUnit\n1232: \
      \  for (i <- 0 until StdCnt) {\n1233:     stdExeUnits(i).io.flush <> redirect\n\
      1234:     stdExeUnits(i).io.in.valid := io.ooo_to_mem.issueStd(i).valid\n1235:\
      \     io.ooo_to_mem.issueStd(i).ready := stdExeUnits(i).io.in.ready\n1236: \
      \    stdExeUnits(i).io.in.bits := io.ooo_to_mem.issueStd(i).bits\n1237:   }\n\
      1238: \n1239:   for (i <- 0 until StaCnt) {\n1240:     val stu = storeUnits(i)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1237-1247
    context: "1237:   }\n1238: \n1239:   for (i <- 0 until StaCnt) {\n1240:     val
      stu = storeUnits(i)\n1241: \n1242:     stu.io.redirect      <> redirect\n1243:\
      \     stu.io.csrCtrl       <> csrCtrl\n1244:     stu.io.dcache        <> dcache.io.lsu.sta(i)\n\
      1245:     stu.io.feedback_slow <> io.mem_to_ooo.staIqFeedback(i).feedbackSlow\n\
      1246:     stu.io.stin         <> io.ooo_to_mem.issueSta(i)\n1247:     stu.io.lsq\
      \          <> lsq.io.sta.storeAddrIn(i)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1245-1255
    context: "1245:     stu.io.feedback_slow <> io.mem_to_ooo.staIqFeedback(i).feedbackSlow\n\
      1246:     stu.io.stin         <> io.ooo_to_mem.issueSta(i)\n1247:     stu.io.lsq\
      \          <> lsq.io.sta.storeAddrIn(i)\n1248:     stu.io.lsq_replenish <> lsq.io.sta.storeAddrInRe(i)\n\
      1249:     // dtlb\n1250:     stu.io.tlb          <> dtlb_st.head.requestor(i)\n\
      1251:     stu.io.pmp          <> pmp_check(LduCnt + HyuCnt + 1 + i).resp\n1252:\
      \ \n1253:     // -------------------------\n1254:     // Store Triggers\n1255:\
      \     // -------------------------"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1281-1291
    context: "1281:     // Lsq to std unit's rs\n1282:     if (i < VstuCnt){\n1283:\
      \       when (vsSplit(i).io.vstd.get.valid) {\n1284:         lsq.io.std.storeDataIn(i).valid
      := true.B\n1285:         lsq.io.std.storeDataIn(i).bits := vsSplit(i).io.vstd.get.bits\n\
      1286:         stData(i).ready := false.B\n1287:       }.otherwise {\n1288: \
      \        lsq.io.std.storeDataIn(i).valid := stData(i).valid && !st_data_atomics(i)\n\
      1289:         lsq.io.std.storeDataIn(i).bits.uop := stData(i).bits.uop\n1290:\
      \         lsq.io.std.storeDataIn(i).bits.data := stData(i).bits.data\n1291:\
      \         lsq.io.std.storeDataIn(i).bits.mask.map(_ := 0.U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1290-1300
    context: "1290:         lsq.io.std.storeDataIn(i).bits.data := stData(i).bits.data\n\
      1291:         lsq.io.std.storeDataIn(i).bits.mask.map(_ := 0.U)\n1292:     \
      \    lsq.io.std.storeDataIn(i).bits.vdIdx.map(_ := 0.U)\n1293:         lsq.io.std.storeDataIn(i).bits.vdIdxInField.map(_
      := 0.U)\n1294:         lsq.io.std.storeDataIn(i).bits.vecDebug.map(_ := DontCare)\n\
      1295:         stData(i).ready := true.B\n1296:       }\n1297:     } else {\n\
      1298:         lsq.io.std.storeDataIn(i).valid := stData(i).valid && !st_data_atomics(i)\n\
      1299:         lsq.io.std.storeDataIn(i).bits.uop := stData(i).bits.uop\n1300:\
      \         lsq.io.std.storeDataIn(i).bits.data := stData(i).bits.data"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1300-1317
    context: "1300:         lsq.io.std.storeDataIn(i).bits.data := stData(i).bits.data\n\
      1301:         lsq.io.std.storeDataIn(i).bits.mask.map(_ := 0.U)\n1302:     \
      \    lsq.io.std.storeDataIn(i).bits.vdIdx.map(_ := 0.U)\n1303:         lsq.io.std.storeDataIn(i).bits.vdIdxInField.map(_
      := 0.U)\n1304:         lsq.io.std.storeDataIn(i).bits.vecDebug.map(_ := DontCare)\n\
      1305:         stData(i).ready := true.B\n1306:     }\n1307:     lsq.io.std.storeDataIn.map(_.bits.debug
      := 0.U.asTypeOf(new DebugBundle))\n1308:     lsq.io.std.storeDataIn.foreach(_.bits.isFromLoadUnit
      := DontCare)\n1309: \n1310: \n1311:     // store prefetch train\n1312:     l1PrefetcherOpt.foreach(pf
      => {\n1313:       // stream will train on all load sources\n1314:       pf.io.st_in(i).valid
      := false.B\n1315:       pf.io.st_in(i).bits := DontCare\n1316:     })\n1317: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1313-1323
    context: "1313:       // stream will train on all load sources\n1314:       pf.io.st_in(i).valid
      := false.B\n1315:       pf.io.st_in(i).bits := DontCare\n1316:     })\n1317:\
      \ \n1318:     prefetcherOpt.foreach(pf => {\n1319:       pf.io.st_in(i).valid
      := Mux(pf_train_on_hit,\n1320:         stu.io.prefetch_train.valid,\n1321: \
      \        stu.io.prefetch_train.valid && stu.io.prefetch_train.bits.isFirstIssue
      && (\n1322:           stu.io.prefetch_train.bits.miss\n1323:           )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1331-1341
    context: "1331:     // io.stIn(i).valid := io.issue(exuParameters.LduCnt + i).valid\n\
      1332:     // io.stIn(i).bits := io.issue(exuParameters.LduCnt + i).bits\n1333:\
      \     io.mem_to_ooo.stIn(i).valid := stu.io.issue.valid\n1334:     io.mem_to_ooo.stIn(i).bits
      := stu.io.issue.bits\n1335: \n1336:     stu.io.stout.ready := true.B\n1337:\
      \ \n1338:     // vector\n1339:     if (i < VstuCnt) {\n1340:       stu.io.vecstin
      <> vsSplit(i).io.out\n1341:       // vsFlowQueue.io.pipeFeedback(i) <> stu.io.vec_feedback_slow
      // need connect"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1340-1350
    context: "1340:       stu.io.vecstin <> vsSplit(i).io.out\n1341:       // vsFlowQueue.io.pipeFeedback(i)
      <> stu.io.vec_feedback_slow // need connect\n1342:     } else {\n1343:     \
      \  stu.io.vecstin.valid := false.B\n1344:       stu.io.vecstin.bits := DontCare\n\
      1345:       stu.io.vecstout.ready := false.B\n1346:     }\n1347:     stu.io.vec_isFirstIssue
      := true.B // TODO\n1348:   }\n1349: \n1350:   val sqOtherStout = WireInit(0.U.asTypeOf(DecoupledIO(new
      MemExuOutput)))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1346-1358
    context: "1346:     }\n1347:     stu.io.vec_isFirstIssue := true.B // TODO\n1348:\
      \   }\n1349: \n1350:   val sqOtherStout = WireInit(0.U.asTypeOf(DecoupledIO(new
      MemExuOutput)))\n1351:   sqOtherStout.valid := lsq.io.mmioStout.valid || lsq.io.cboZeroStout.valid\n\
      1352:   sqOtherStout.bits  := Mux(lsq.io.cboZeroStout.valid, lsq.io.cboZeroStout.bits,
      lsq.io.mmioStout.bits)\n1353:   assert(!(lsq.io.mmioStout.valid && lsq.io.cboZeroStout.valid),
      \"Cannot writeback to mmio and cboZero at the same time.\")\n1354: \n1355: \
      \  // Store writeback by StoreQueue:\n1356:   //   1. cbo Zero\n1357:   // \
      \  2. mmio\n1358:   // Currently, the two should not be present at the same
      time, so simply make cbo zero a higher priority."
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1354-1384
    context: "1354: \n1355:   // Store writeback by StoreQueue:\n1356:   //   1. cbo
      Zero\n1357:   //   2. mmio\n1358:   // Currently, the two should not be present
      at the same time, so simply make cbo zero a higher priority.\n1359:   val otherStout
      = WireInit(0.U.asTypeOf(lsq.io.mmioStout))\n1360:   NewPipelineConnect(\n1361:\
      \     sqOtherStout, otherStout, otherStout.fire,\n1362:     false.B,\n1363:\
      \     Option(\"otherStoutConnect\")\n1364:   )\n1365:   otherStout.ready :=
      false.B\n1366:   when (otherStout.valid && !storeUnits(0).io.stout.valid) {\n\
      1367:     stOut(0).valid := true.B\n1368:     stOut(0).bits  := otherStout.bits\n\
      1369:     otherStout.ready := true.B\n1370:   }\n1371:   lsq.io.mmioStout.ready
      := sqOtherStout.ready\n1372:   lsq.io.cboZeroStout.ready := sqOtherStout.ready\n\
      1373: \n1374:   // vec mmio writeback\n1375:   lsq.io.vecmmioStout.ready :=
      false.B\n1376: \n1377:   // miss align buffer will overwrite stOut(0)\n1378:\
      \   val storeMisalignCanWriteBack = !otherStout.valid && !storeUnits(0).io.stout.valid
      && !storeUnits(0).io.vecstout.valid\n1379:   storeMisalignBuffer.io.writeBack.ready
      := storeMisalignCanWriteBack\n1380:   storeMisalignBuffer.io.storeOutValid :=
      storeUnits(0).io.stout.valid\n1381:   storeMisalignBuffer.io.storeVecOutValid
      := storeUnits(0).io.vecstout.valid\n1382:   when (storeMisalignBuffer.io.writeBack.valid
      && storeMisalignCanWriteBack) {\n1383:     stOut(0).valid := true.B\n1384: \
      \    stOut(0).bits  := storeMisalignBuffer.io.writeBack.bits"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1389-1399
    context: "1389:   uncache.io.hartId := io.hartId\n1390:   uncache.io.wfi.wfiReq
      := io.wfi.wfiReq\n1391:   lsq.io.uncacheOutstanding := io.ooo_to_mem.csrCtrl.uncache_write_outstanding_enable\n\
      1392: \n1393:   // Lsq\n1394:   io.mem_to_ooo.lsqio.mmio       := lsq.io.rob.mmio\n\
      1395:   io.mem_to_ooo.lsqio.uop        := lsq.io.rob.uop\n1396:   lsq.io.rob.lcommit\
      \             := io.ooo_to_mem.lsqio.lcommit\n1397:   lsq.io.rob.scommit   \
      \          := io.ooo_to_mem.lsqio.scommit\n1398:   lsq.io.rob.pendingMMIOld\
      \       := io.ooo_to_mem.lsqio.pendingMMIOld\n1399:   lsq.io.rob.pendingld \
      \          := io.ooo_to_mem.lsqio.pendingld"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1397-1407
    context: "1397:   lsq.io.rob.scommit             := io.ooo_to_mem.lsqio.scommit\n\
      1398:   lsq.io.rob.pendingMMIOld       := io.ooo_to_mem.lsqio.pendingMMIOld\n\
      1399:   lsq.io.rob.pendingld           := io.ooo_to_mem.lsqio.pendingld\n1400:\
      \   lsq.io.rob.pendingst           := io.ooo_to_mem.lsqio.pendingst\n1401: \
      \  lsq.io.rob.pendingVst          := io.ooo_to_mem.lsqio.pendingVst\n1402: \
      \  lsq.io.rob.commit              := io.ooo_to_mem.lsqio.commit\n1403:   lsq.io.rob.pendingPtr\
      \          := io.ooo_to_mem.lsqio.pendingPtr\n1404:   lsq.io.rob.pendingPtrNext\
      \      := io.ooo_to_mem.lsqio.pendingPtrNext\n1405: \n1406:   //  lsq.io.rob\
      \            <> io.lsqio.rob\n1407:   lsq.io.enq            <> io.ooo_to_mem.enqLsq"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1403-1417
    context: "1403:   lsq.io.rob.pendingPtr          := io.ooo_to_mem.lsqio.pendingPtr\n\
      1404:   lsq.io.rob.pendingPtrNext      := io.ooo_to_mem.lsqio.pendingPtrNext\n\
      1405: \n1406:   //  lsq.io.rob            <> io.lsqio.rob\n1407:   lsq.io.enq\
      \            <> io.ooo_to_mem.enqLsq\n1408:   lsq.io.brqRedirect    <> redirect\n\
      1409: \n1410:   //  violation rollback\n1411:   def selectOldestRedirect(xs:
      Seq[Valid[Redirect]]): Vec[Bool] = {\n1412:     val compareVec = (0 until xs.length).map(i
      => (0 until i).map(j => isAfter(xs(j).bits.robIdx, xs(i).bits.robIdx)))\n1413:\
      \     val resultOnehot = VecInit((0 until xs.length).map(i => Cat((0 until xs.length).map(j
      =>\n1414:       (if (j < i) !xs(j).valid || compareVec(i)(j)\n1415:       else
      if (j == i) xs(i).valid\n1416:       else !xs(j).valid || !compareVec(j)(i))\n\
      1417:     )).andR))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1415-1432
    context: "1415:       else if (j == i) xs(i).valid\n1416:       else !xs(j).valid
      || !compareVec(j)(i))\n1417:     )).andR))\n1418:     resultOnehot\n1419:  \
      \ }\n1420:   val allRedirect = loadUnits.map(_.io.rollback) ++ hybridUnits.map(_.io.ldu_io.rollback)
      ++ lsq.io.nack_rollback ++ lsq.io.nuke_rollback\n1421:   val oldestOneHot =
      selectOldestRedirect(allRedirect)\n1422:   val oldestRedirect = WireDefault(Mux1H(oldestOneHot,
      allRedirect))\n1423:   // memory replay would not cause IAF/IPF/IGPF\n1424:\
      \   oldestRedirect.bits.cfiUpdate.backendIAF := false.B\n1425:   oldestRedirect.bits.cfiUpdate.backendIPF
      := false.B\n1426:   oldestRedirect.bits.cfiUpdate.backendIGPF := false.B\n1427:\
      \   io.mem_to_ooo.memoryViolation := oldestRedirect\n1428:   io.mem_to_ooo.lsqio.lqCanAccept\
      \  := lsq.io.lqCanAccept\n1429:   io.mem_to_ooo.lsqio.sqCanAccept  := lsq.io.sqCanAccept\n\
      1430: \n1431:   // lsq.io.uncache        <> uncache.io.lsq\n1432:   val s_idle
      :: s_scalar_uncache :: s_vector_uncache :: Nil = Enum(3)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1435-1449
    context: "1435:   val uncacheIdResp = uncache.io.lsq.idResp\n1436:   val uncacheResp
      = Wire(Decoupled(new UncacheWordResp))\n1437: \n1438:   uncacheReq.bits := DontCare\n\
      1439:   uncacheReq.valid := false.B\n1440:   uncacheReq.ready := false.B\n1441:\
      \   uncacheResp.bits := DontCare\n1442:   uncacheResp.valid := false.B\n1443:\
      \   uncacheResp.ready := false.B\n1444:   lsq.io.uncache.req.ready := false.B\n\
      1445:   lsq.io.uncache.idResp.valid := false.B\n1446:   lsq.io.uncache.idResp.bits
      := DontCare\n1447:   lsq.io.uncache.resp.valid := false.B\n1448:   lsq.io.uncache.resp.bits
      := DontCare\n1449: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1447-1457
    context: "1447:   lsq.io.uncache.resp.valid := false.B\n1448:   lsq.io.uncache.resp.bits
      := DontCare\n1449: \n1450:   switch (uncacheState) {\n1451:     is (s_idle)
      {\n1452:       when (uncacheReq.fire) {\n1453:         when (lsq.io.uncache.req.valid)
      {\n1454:           when (!lsq.io.uncache.req.bits.nc || !io.ooo_to_mem.csrCtrl.uncache_write_outstanding_enable)
      {\n1455:             uncacheState := s_scalar_uncache\n1456:           }\n1457:\
      \         }.otherwise {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1462-1472
    context: "1462:         }\n1463:       }\n1464:     }\n1465: \n1466:     is (s_scalar_uncache)
      {\n1467:       when (uncacheResp.fire) {\n1468:         uncacheState := s_idle\n\
      1469:       }\n1470:     }\n1471: \n1472:     is (s_vector_uncache) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1468-1478
    context: "1468:         uncacheState := s_idle\n1469:       }\n1470:     }\n1471:\
      \ \n1472:     is (s_vector_uncache) {\n1473:       when (uncacheResp.fire) {\n\
      1474:         uncacheState := s_idle\n1475:       }\n1476:     }\n1477:   }\n\
      1478: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1508-1518
    context: "1508:   sbuffer.io.in(0).valid := lsq.io.sbuffer(0).valid || vSegmentUnit.io.sbuffer.valid\n\
      1509:   sbuffer.io.in(0).bits  := Mux1H(Seq(\n1510:     vSegmentUnit.io.sbuffer.valid
      -> vSegmentUnit.io.sbuffer.bits,\n1511:     lsq.io.sbuffer(0).valid       ->
      lsq.io.sbuffer(0).bits\n1512:   ))\n1513:   vSegmentUnit.io.sbuffer.ready :=
      sbuffer.io.in(0).ready\n1514:   lsq.io.sqEmpty        <> sbuffer.io.sqempty\n\
      1515:   dcache.io.force_write := lsq.io.force_write\n1516: \n1517:   // Initialize
      when unenabled difftest.\n1518:   sbuffer.io.diffStore := DontCare"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1520-1534
    context: "1520:   vSegmentUnit.io.vecDifftestInfo := DontCare\n1521:   io.mem_to_ooo.storeDebugInfo
      := DontCare\n1522:   // store event difftest information\n1523:   if (env.EnableDifftest)
      {\n1524:     // diffStoreEvent for vSegment, pmaStore and ncStore\n1525:   \
      \  (0 until EnsbufferWidth).foreach{i =>\n1526:       if(i == 0) {\n1527:  \
      \       when(vSegmentUnit.io.sbuffer.valid) {\n1528:           sbuffer.io.diffStore.diffInfo(0)
      := vSegmentUnit.io.vecDifftestInfo.bits\n1529:           sbuffer.io.diffStore.pmaStore(0).valid
      := vSegmentUnit.io.sbuffer.fire\n1530:           sbuffer.io.diffStore.pmaStore(0).bits
      := vSegmentUnit.io.sbuffer.bits\n1531:         }.otherwise{\n1532:         \
      \  sbuffer.io.diffStore.diffInfo(0) := lsq.io.diffStore.diffInfo(0)\n1533: \
      \          sbuffer.io.diffStore.pmaStore(0) := lsq.io.diffStore.pmaStore(0)\n\
      1534:         }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1547-1562
    context: "1547:   //   vlWrapper.io.uopWriteback.bits.uop.vpu.lastUop\n1548: \
      \  // lsq.io.vecWriteback.bits := vlWrapper.io.uopWriteback.bits\n1549: \n1550:\
      \   // vector\n1551:   val vLoadCanAccept  = (0 until VlduCnt).map(i =>\n1552:\
      \     vlSplit(i).io.in.ready && VlduType.isVecLd(io.ooo_to_mem.issueVldu(i).bits.uop.fuOpType)\n\
      1553:   )\n1554:   val vStoreCanAccept = (0 until VstuCnt).map(i =>\n1555: \
      \    vsSplit(i).io.in.ready && VstuType.isVecSt(io.ooo_to_mem.issueVldu(i).bits.uop.fuOpType)\n\
      1556:   )\n1557:   val isSegment     = io.ooo_to_mem.issueVldu.head.valid &&
      isVsegls(io.ooo_to_mem.issueVldu.head.bits.uop.fuType)\n1558:   val isFixVlUop\
      \    = io.ooo_to_mem.issueVldu.map{x =>\n1559:     x.bits.uop.vpu.isVleff &&
      x.bits.uop.vpu.lastUop && x.valid\n1560:   }\n1561: \n1562:   // init port"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1570-1596
    context: "1570:    *\n1571:    *  RS0 -> VlSplit0  -> ldu0 -> |\n1572:    *  RS1
      -> VlSplit1  -> ldu1 -> |  -> vlMergebuffer\n1573:    *        replayIO   ->
      ldu3 -> |\n1574:    * */\n1575:   (0 until VstuCnt).foreach{i =>\n1576:    \
      \ vsMergeBuffer(i).io.fromPipeline := DontCare\n1577:     vsMergeBuffer(i).io.fromSplit
      := DontCare\n1578: \n1579:     vsMergeBuffer(i).io.fromMisalignBuffer.get.flush
      := storeMisalignBuffer.io.toVecStoreMergeBuffer(i).flush\n1580:     vsMergeBuffer(i).io.fromMisalignBuffer.get.mbIndex
      := storeMisalignBuffer.io.toVecStoreMergeBuffer(i).mbIndex\n1581:   }\n1582:\
      \ \n1583:   (0 until VstuCnt).foreach{i =>\n1584:     vsSplit(i).io.redirect
      <> redirect\n1585:     vsSplit(i).io.in <> io.ooo_to_mem.issueVldu(i)\n1586:\
      \     vsSplit(i).io.in.valid := io.ooo_to_mem.issueVldu(i).valid &&\n1587: \
      \                              vStoreCanAccept(i) && !isSegment\n1588:     vsSplit(i).io.toMergeBuffer
      <> vsMergeBuffer(i).io.fromSplit.head\n1589:     NewPipelineConnect(\n1590:\
      \       vsSplit(i).io.out, storeUnits(i).io.vecstin, storeUnits(i).io.vecstin.fire,\n\
      1591:       Mux(vsSplit(i).io.out.fire, vsSplit(i).io.out.bits.uop.robIdx.needFlush(io.redirect),
      storeUnits(i).io.vecstin.bits.uop.robIdx.needFlush(io.redirect)),\n1592:   \
      \    Option(\"VsSplitConnectStu\")\n1593:     )\n1594:     vsSplit(i).io.vstd.get
      := DontCare // Todo: Discuss how to pass vector store data\n1595: \n1596:  \
      \   vsSplit(i).io.vstdMisalign.get.storeMisalignBufferEmpty := !storeMisalignBuffer.io.full"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1595-1606
    context: "1595: \n1596:     vsSplit(i).io.vstdMisalign.get.storeMisalignBufferEmpty
      := !storeMisalignBuffer.io.full\n1597:     vsSplit(i).io.vstdMisalign.get.storePipeEmpty
      := !storeUnits(i).io.s0_s1_valid\n1598: \n1599:   }\n1600:   (0 until VlduCnt).foreach{i
      =>\n1601:     vlSplit(i).io.redirect <> redirect\n1602:     vlSplit(i).io.in
      <> io.ooo_to_mem.issueVldu(i)\n1603:     vlSplit(i).io.in.valid := io.ooo_to_mem.issueVldu(i).valid
      &&\n1604:                               vLoadCanAccept(i) && !isSegment && !isFixVlUop(i)\n\
      1605:     vlSplit(i).io.toMergeBuffer <> vlMergeBuffer.io.fromSplit(i)\n1606:\
      \     vlSplit(i).io.threshold.get.valid := vlMergeBuffer.io.toSplit.get.threshold"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1604-1615
    context: "1604:                               vLoadCanAccept(i) && !isSegment
      && !isFixVlUop(i)\n1605:     vlSplit(i).io.toMergeBuffer <> vlMergeBuffer.io.fromSplit(i)\n\
      1606:     vlSplit(i).io.threshold.get.valid := vlMergeBuffer.io.toSplit.get.threshold\n\
      1607:     vlSplit(i).io.threshold.get.bits  := lsq.io.lqDeqPtr\n1608:     NewPipelineConnect(\n\
      1609:       vlSplit(i).io.out, loadUnits(i).io.vecldin, loadUnits(i).io.vecldin.fire,\n\
      1610:       Mux(vlSplit(i).io.out.fire, vlSplit(i).io.out.bits.uop.robIdx.needFlush(io.redirect),
      loadUnits(i).io.vecldin.bits.uop.robIdx.needFlush(io.redirect)),\n1611:    \
      \   Option(\"VlSplitConnectLdu\")\n1612:     )\n1613: \n1614:     //Subsequent
      instrction will be blocked\n1615:     vfofBuffer.io.in(i).valid := io.ooo_to_mem.issueVldu(i).valid"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1613-1625
    context: "1613: \n1614:     //Subsequent instrction will be blocked\n1615:   \
      \  vfofBuffer.io.in(i).valid := io.ooo_to_mem.issueVldu(i).valid\n1616:    \
      \ vfofBuffer.io.in(i).bits  := io.ooo_to_mem.issueVldu(i).bits\n1617:   }\n\
      1618:   (0 until LduCnt).foreach{i=>\n1619:     loadUnits(i).io.vecldout.ready\
      \         := vlMergeBuffer.io.fromPipeline(i).ready\n1620:     loadMisalignBuffer.io.vecWriteBack.ready
      := true.B\n1621: \n1622:     if (i == MisalignWBPort) {\n1623:       when(loadUnits(i).io.vecldout.valid)
      {\n1624:         vlMergeBuffer.io.fromPipeline(i).valid := loadUnits(i).io.vecldout.valid\n\
      1625:         vlMergeBuffer.io.fromPipeline(i).bits  := loadUnits(i).io.vecldout.bits"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1631-1717
    context: "1631:       vlMergeBuffer.io.fromPipeline(i).valid := loadUnits(i).io.vecldout.valid\n\
      1632:       vlMergeBuffer.io.fromPipeline(i).bits  := loadUnits(i).io.vecldout.bits\n\
      1633:     }\n1634:   }\n1635: \n1636:   (0 until StaCnt).foreach{i=>\n1637:\
      \     if(i < VstuCnt){\n1638:       storeUnits(i).io.vecstout.ready := true.B\n\
      1639:       storeMisalignBuffer.io.vecWriteBack(i).ready := vsMergeBuffer(i).io.fromPipeline.head.ready\n\
      1640: \n1641:       when(storeUnits(i).io.vecstout.valid) {\n1642:         vsMergeBuffer(i).io.fromPipeline.head.valid
      := storeUnits(i).io.vecstout.valid\n1643:         vsMergeBuffer(i).io.fromPipeline.head.bits\
      \  := storeUnits(i).io.vecstout.bits\n1644:       } .otherwise {\n1645:    \
      \     vsMergeBuffer(i).io.fromPipeline.head.valid   := storeMisalignBuffer.io.vecWriteBack(i).valid\n\
      1646:         vsMergeBuffer(i).io.fromPipeline.head.bits    := storeMisalignBuffer.io.vecWriteBack(i).bits\n\
      1647:       }\n1648:     }\n1649:   }\n1650: \n1651:   (0 until VlduCnt).foreach{i=>\n\
      1652:     io.ooo_to_mem.issueVldu(i).ready := vLoadCanAccept(i) || vStoreCanAccept(i)\n\
      1653:   }\n1654: \n1655:   vlMergeBuffer.io.redirect <> redirect\n1656:   vsMergeBuffer.map(_.io.redirect
      <> redirect)\n1657:   (0 until VlduCnt).foreach{i=>\n1658:     vlMergeBuffer.io.toLsq(i)
      <> lsq.io.ldvecFeedback(i)\n1659:   }\n1660:   (0 until VstuCnt).foreach{i=>\n\
      1661:     vsMergeBuffer(i).io.toLsq.head <> lsq.io.stvecFeedback(i)\n1662: \
      \  }\n1663: \n1664:   (0 until VlduCnt).foreach{i=>\n1665:     // send to RS\n\
      1666:     vlMergeBuffer.io.feedback(i) <> io.mem_to_ooo.vlduIqFeedback(i).feedbackSlow\n\
      1667:     io.mem_to_ooo.vlduIqFeedback(i).feedbackFast := DontCare\n1668:  \
      \ }\n1669:   (0 until VstuCnt).foreach{i =>\n1670:     // send to RS\n1671:\
      \     if (i == 0){\n1672:       io.mem_to_ooo.vstuIqFeedback(i).feedbackSlow.valid
      := vsMergeBuffer(i).io.feedback.head.valid || vSegmentUnit.io.feedback.valid\n\
      1673:       io.mem_to_ooo.vstuIqFeedback(i).feedbackSlow.bits := Mux1H(Seq(\n\
      1674:         vSegmentUnit.io.feedback.valid -> vSegmentUnit.io.feedback.bits,\n\
      1675:         vsMergeBuffer(i).io.feedback.head.valid ->  vsMergeBuffer(i).io.feedback.head.bits\n\
      1676:       ))\n1677:       io.mem_to_ooo.vstuIqFeedback(i).feedbackFast :=
      DontCare\n1678:     } else {\n1679:       vsMergeBuffer(i).io.feedback.head
      <> io.mem_to_ooo.vstuIqFeedback(i).feedbackSlow\n1680:       io.mem_to_ooo.vstuIqFeedback(i).feedbackFast
      := DontCare\n1681:     }\n1682:   }\n1683: \n1684:   (0 until VlduCnt).foreach{i=>\n\
      1685:     if (i == 0){ // for segmentUnit, segmentUnit use port0 writeback\n\
      1686:       io.mem_to_ooo.writebackVldu(i).valid := vlMergeBuffer.io.uopWriteback(i).valid
      || vsMergeBuffer(i).io.uopWriteback.head.valid || vSegmentUnit.io.uopwriteback.valid\n\
      1687:       io.mem_to_ooo.writebackVldu(i).bits := PriorityMux(Seq(\n1688: \
      \        vSegmentUnit.io.uopwriteback.valid          -> vSegmentUnit.io.uopwriteback.bits,\n\
      1689:         vlMergeBuffer.io.uopWriteback(i).valid      -> vlMergeBuffer.io.uopWriteback(i).bits,\n\
      1690:         vsMergeBuffer(i).io.uopWriteback.head.valid -> vsMergeBuffer(i).io.uopWriteback.head.bits,\n\
      1691:       ))\n1692:       vlMergeBuffer.io.uopWriteback(i).ready := io.mem_to_ooo.writebackVldu(i).ready
      && !vSegmentUnit.io.uopwriteback.valid\n1693:       vsMergeBuffer(i).io.uopWriteback.head.ready
      := io.mem_to_ooo.writebackVldu(i).ready && !vlMergeBuffer.io.uopWriteback(i).valid
      && !vSegmentUnit.io.uopwriteback.valid\n1694:       vSegmentUnit.io.uopwriteback.ready
      := io.mem_to_ooo.writebackVldu(i).ready\n1695:     } else if (i == 1) {\n1696:\
      \       io.mem_to_ooo.writebackVldu(i).valid := vlMergeBuffer.io.uopWriteback(i).valid
      || vsMergeBuffer(i).io.uopWriteback.head.valid || vfofBuffer.io.uopWriteback.valid\n\
      1697:       io.mem_to_ooo.writebackVldu(i).bits := PriorityMux(Seq(\n1698: \
      \        vfofBuffer.io.uopWriteback.valid            -> vfofBuffer.io.uopWriteback.bits,\n\
      1699:         vlMergeBuffer.io.uopWriteback(i).valid      -> vlMergeBuffer.io.uopWriteback(i).bits,\n\
      1700:         vsMergeBuffer(i).io.uopWriteback.head.valid -> vsMergeBuffer(i).io.uopWriteback.head.bits,\n\
      1701:       ))\n1702:       vlMergeBuffer.io.uopWriteback(i).ready := io.mem_to_ooo.writebackVldu(i).ready
      && !vfofBuffer.io.uopWriteback.valid\n1703:       vsMergeBuffer(i).io.uopWriteback.head.ready
      := io.mem_to_ooo.writebackVldu(i).ready && !vlMergeBuffer.io.uopWriteback(i).valid
      && !vfofBuffer.io.uopWriteback.valid\n1704:       vfofBuffer.io.uopWriteback.ready
      := io.mem_to_ooo.writebackVldu(i).ready\n1705:     } else {\n1706:       io.mem_to_ooo.writebackVldu(i).valid
      := vlMergeBuffer.io.uopWriteback(i).valid || vsMergeBuffer(i).io.uopWriteback.head.valid\n\
      1707:       io.mem_to_ooo.writebackVldu(i).bits := PriorityMux(Seq(\n1708: \
      \        vlMergeBuffer.io.uopWriteback(i).valid -> vlMergeBuffer.io.uopWriteback(i).bits,\n\
      1709:         vsMergeBuffer(i).io.uopWriteback.head.valid -> vsMergeBuffer(i).io.uopWriteback.head.bits,\n\
      1710:       ))\n1711:       vlMergeBuffer.io.uopWriteback(i).ready := io.mem_to_ooo.writebackVldu(i).ready\n\
      1712:       vsMergeBuffer(i).io.uopWriteback.head.ready := io.mem_to_ooo.writebackVldu(i).ready
      && !vlMergeBuffer.io.uopWriteback(i).valid\n1713:     }\n1714: \n1715:     vfofBuffer.io.mergeUopWriteback(i).valid
      := vlMergeBuffer.io.toLsq(i).valid\n1716:     vfofBuffer.io.mergeUopWriteback(i).bits\
      \  := vlMergeBuffer.io.toLsq(i).bits\n1717:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1715-1725
    context: "1715:     vfofBuffer.io.mergeUopWriteback(i).valid := vlMergeBuffer.io.toLsq(i).valid\n\
      1716:     vfofBuffer.io.mergeUopWriteback(i).bits  := vlMergeBuffer.io.toLsq(i).bits\n\
      1717:   }\n1718: \n1719: \n1720:   vfofBuffer.io.redirect <> redirect\n1721:\
      \ \n1722:   // Sbuffer\n1723:   sbuffer.io.csrCtrl    <> csrCtrl\n1724:   sbuffer.io.dcache\
      \     <> dcache.io.lsu.store\n1725:   sbuffer.io.memSetPattenDetected := dcache.io.memSetPattenDetected"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1723-1770
    context: "1723:   sbuffer.io.csrCtrl    <> csrCtrl\n1724:   sbuffer.io.dcache\
      \     <> dcache.io.lsu.store\n1725:   sbuffer.io.memSetPattenDetected := dcache.io.memSetPattenDetected\n\
      1726:   sbuffer.io.force_write <> lsq.io.force_write\n1727:   // flush sbuffer\n\
      1728:   val cmoFlush = lsq.io.flushSbuffer.valid\n1729:   val fenceFlush = io.ooo_to_mem.flushSb\n\
      1730:   val atomicsFlush = atomicsUnit.io.flush_sbuffer.valid || vSegmentUnit.io.flush_sbuffer.valid\n\
      1731:   val stIsEmpty = sbuffer.io.flush.empty && uncache.io.flush.empty\n1732:\
      \   io.mem_to_ooo.sbIsEmpty := RegNext(stIsEmpty)\n1733: \n1734:   // if both
      of them tries to flush sbuffer at the same time\n1735:   // something must have
      gone wrong\n1736:   assert(!(fenceFlush && atomicsFlush && cmoFlush))\n1737:\
      \   sbuffer.io.flush.valid := RegNext(fenceFlush || atomicsFlush || cmoFlush)\n\
      1738:   uncache.io.flush.valid := sbuffer.io.flush.valid\n1739: \n1740:   //
      AtomicsUnit: AtomicsUnit will override other control signials,\n1741:   // as
      atomics insts (LR/SC/AMO) will block the pipeline\n1742:   val s_normal +: s_atomics
      = Enum(StaCnt + HyuCnt + 1)\n1743:   val state = RegInit(s_normal)\n1744: \n\
      1745:   val st_atomics = Seq.tabulate(StaCnt)(i =>\n1746:     io.ooo_to_mem.issueSta(i).valid
      && FuType.storeIsAMO((io.ooo_to_mem.issueSta(i).bits.uop.fuType))\n1747:   )
      ++ Seq.tabulate(HyuCnt)(i =>\n1748:     io.ooo_to_mem.issueHya(i).valid && FuType.storeIsAMO((io.ooo_to_mem.issueHya(i).bits.uop.fuType))\n\
      1749:   )\n1750: \n1751:   for (i <- 0 until StaCnt) when(st_atomics(i)) {\n\
      1752:     io.ooo_to_mem.issueSta(i).ready := atomicsUnit.io.in.ready\n1753:\
      \     storeUnits(i).io.stin.valid := false.B\n1754: \n1755:     state := s_atomics(i)\n\
      1756:   }\n1757:   for (i <- 0 until HyuCnt) when(st_atomics(StaCnt + i)) {\n\
      1758:     io.ooo_to_mem.issueHya(i).ready := atomicsUnit.io.in.ready\n1759:\
      \     hybridUnits(i).io.lsin.valid := false.B\n1760: \n1761:     state := s_atomics(StaCnt
      + i)\n1762:     assert(!st_atomics.zipWithIndex.filterNot(_._2 == StaCnt + i).unzip._1.reduce(_
      || _))\n1763:   }\n1764:   when (atomicsUnit.io.out.valid) {\n1765:     state
      := s_normal\n1766:   }\n1767: \n1768:   atomicsUnit.io.in.valid := st_atomics.reduce(_
      || _)\n1769:   atomicsUnit.io.in.bits  := Mux1H(Seq.tabulate(StaCnt)(i =>\n\
      1770:     st_atomics(i) -> io.ooo_to_mem.issueSta(i).bits) ++"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1767-1781
    context: "1767: \n1768:   atomicsUnit.io.in.valid := st_atomics.reduce(_ || _)\n\
      1769:   atomicsUnit.io.in.bits  := Mux1H(Seq.tabulate(StaCnt)(i =>\n1770:  \
      \   st_atomics(i) -> io.ooo_to_mem.issueSta(i).bits) ++\n1771:     Seq.tabulate(HyuCnt)(i
      => st_atomics(StaCnt+i) -> io.ooo_to_mem.issueHya(i).bits))\n1772:   atomicsUnit.io.storeDataIn.zipWithIndex.foreach
      { case (stdin, i) =>\n1773:     stdin.valid := st_data_atomics(i)\n1774:   \
      \  stdin.bits := stData(i).bits\n1775:   }\n1776:   atomicsUnit.io.redirect
      <> redirect\n1777: \n1778:   // TODO: complete amo's pmp support\n1779:   val
      amoTlb = dtlb_ld(0).requestor(0)\n1780:   atomicsUnit.io.dtlb.resp.valid :=
      false.B\n1781:   atomicsUnit.io.dtlb.resp.bits  := DontCare"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1777-1787
    context: "1777: \n1778:   // TODO: complete amo's pmp support\n1779:   val amoTlb
      = dtlb_ld(0).requestor(0)\n1780:   atomicsUnit.io.dtlb.resp.valid := false.B\n\
      1781:   atomicsUnit.io.dtlb.resp.bits  := DontCare\n1782:   atomicsUnit.io.dtlb.req.ready\
      \  := amoTlb.req.ready\n1783:   atomicsUnit.io.pmpResp := pmp_check(0).resp\n\
      1784: \n1785:   atomicsUnit.io.dcache <> dcache.io.lsu.atomics\n1786:   atomicsUnit.io.flush_sbuffer.empty
      := stIsEmpty\n1787: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1787-1799
    context: "1787: \n1788:   atomicsUnit.io.csrCtrl := csrCtrl\n1789: \n1790:   //
      for atomicsUnit, it uses loadUnit(0)'s TLB port\n1791: \n1792:   when (state
      =/= s_normal) {\n1793:     // use store wb port instead of load\n1794:     loadUnits(0).io.ldout.ready
      := false.B\n1795:     // use load_0's TLB\n1796:     atomicsUnit.io.dtlb <>
      amoTlb\n1797: \n1798:     // hw prefetch should be disabled while executing
      atomic insts\n1799:     loadUnits.map(i => i.io.prefetch_req.valid := false.B)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1803-1813
    context: "1803:   }\n1804: \n1805:   lsq.io.flushSbuffer.empty := sbuffer.io.sbempty\n\
      1806: \n1807:   for (i <- 0 until StaCnt) {\n1808:     when (state === s_atomics(i))
      {\n1809:       io.mem_to_ooo.staIqFeedback(i).feedbackSlow := atomicsUnit.io.feedbackSlow\n\
      1810:       assert(!storeUnits(i).io.feedback_slow.valid)\n1811:     }\n1812:\
      \   }\n1813:   for (i <- 0 until HyuCnt) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1809-1819
    context: "1809:       io.mem_to_ooo.staIqFeedback(i).feedbackSlow := atomicsUnit.io.feedbackSlow\n\
      1810:       assert(!storeUnits(i).io.feedback_slow.valid)\n1811:     }\n1812:\
      \   }\n1813:   for (i <- 0 until HyuCnt) {\n1814:     when (state === s_atomics(StaCnt
      + i)) {\n1815:       io.mem_to_ooo.hyuIqFeedback(i).feedbackSlow := atomicsUnit.io.feedbackSlow\n\
      1816:       assert(!hybridUnits(i).io.feedback_slow.valid)\n1817:     }\n1818:\
      \   }\n1819: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1819-1829
    context: "1819: \n1820:   lsq.io.exceptionAddr.isStore := io.ooo_to_mem.isStoreException\n\
      1821:   // Exception address is used several cycles after flush.\n1822:   //
      We delay it by 10 cycles to ensure its flush safety.\n1823:   val atomicsException
      = RegInit(false.B)\n1824:   when (DelayN(redirect.valid, 10) && atomicsException)
      {\n1825:     atomicsException := false.B\n1826:   }.elsewhen (atomicsUnit.io.exceptionInfo.valid)
      {\n1827:     atomicsException := true.B\n1828:   }\n1829: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1844-1854
    context: "1844:     loadMisalignBuffer.io.overwriteExpBuf.isForVSnonLeafPTE,\n\
      1845:     storeMisalignBuffer.io.overwriteExpBuf.isForVSnonLeafPTE\n1846:  \
      \ )\n1847: \n1848:   val vSegmentException = RegInit(false.B)\n1849:   when
      (DelayN(redirect.valid, 10) && vSegmentException) {\n1850:     vSegmentException
      := false.B\n1851:   }.elsewhen (vSegmentUnit.io.exceptionInfo.valid) {\n1852:\
      \     vSegmentException := true.B\n1853:   }\n1854:   val atomicsExceptionAddress
      = RegEnable(atomicsUnit.io.exceptionInfo.bits.vaddr, atomicsUnit.io.exceptionInfo.valid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1978-1997
    context: "1978:       )\n1979:     )\n1980:   ))\n1981:   io.mem_to_ooo.topToBackendBypass
      match { case x =>\n1982:     x.hartId            := io.hartId\n1983:     x.l2FlushDone\
      \       := RegNext(io.l2_flush_done)\n1984:     x.externalInterrupt.msip  :=
      outer.clint_int_sink.in.head._1(0)\n1985:     x.externalInterrupt.mtip  := outer.clint_int_sink.in.head._1(1)\n\
      1986:     x.externalInterrupt.meip  := outer.plic_int_sink.in.head._1(0)\n1987:\
      \     x.externalInterrupt.seip  := outer.plic_int_sink.in.last._1(0)\n1988:\
      \     x.externalInterrupt.debug := outer.debug_int_sink.in.head._1(0)\n1989:\
      \     x.externalInterrupt.nmi.nmi_31 := outer.nmi_int_sink.in.head._1(0) | outer.beu_local_int_sink.in.head._1(0)\n\
      1990:     x.externalInterrupt.nmi.nmi_43 := outer.nmi_int_sink.in.head._1(1)\n\
      1991:     x.msiInfo           := DelayNWithValid(io.fromTopToBackend.msiInfo,
      1)\n1992:     x.clintTime         := DelayNWithValid(io.fromTopToBackend.clintTime,
      1)\n1993:   }\n1994: \n1995:   io.memInfo.sqFull := RegNext(lsq.io.sqFull)\n\
      1996:   io.memInfo.lqFull := RegNext(lsq.io.lqFull)\n1997:   io.memInfo.dcacheMSHRFull
      := RegNext(dcache.io.mshrFull)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 2005-2022
    context: "2005:   io.outer_msi_ack := io.ooo_to_mem.backendToTopBypass.msiAck\n\
      2006:   io.outer_beu_errors_icache := RegNext(io.inner_beu_errors_icache)\n\
      2007:   io.inner_hc_perfEvents <> RegNext(io.outer_hc_perfEvents)\n2008: \n\
      2009:   // vector segmentUnit\n2010:   vSegmentUnit.io.in.bits <> io.ooo_to_mem.issueVldu.head.bits\n\
      2011:   vSegmentUnit.io.csrCtrl <> csrCtrl\n2012:   vSegmentUnit.io.in.valid
      := isSegment && io.ooo_to_mem.issueVldu.head.valid// is segment instruction\n\
      2013:   vSegmentUnit.io.dtlb.resp.bits <> dtlb_reqs.take(LduCnt).head.resp.bits\n\
      2014:   vSegmentUnit.io.dtlb.resp.valid <> dtlb_reqs.take(LduCnt).head.resp.valid\n\
      2015:   vSegmentUnit.io.pmpResp <> pmp_check.head.resp\n2016:   vSegmentUnit.io.flush_sbuffer.empty
      := stIsEmpty\n2017:   vSegmentUnit.io.redirect <> redirect\n2018:   vSegmentUnit.io.rdcache.resp.bits
      := dcache.io.lsu.load(0).resp.bits\n2019:   vSegmentUnit.io.rdcache.resp.valid
      := dcache.io.lsu.load(0).resp.valid\n2020:   vSegmentUnit.io.rdcache.s2_bank_conflict
      := dcache.io.lsu.load(0).s2_bank_conflict\n2021:   // -------------------------\n\
      2022:   // Vector Segment Triggers"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 2066-2078
    context: "2066:   )\n2067:   traceToL2Top.toEncoder.priv := RegEnable(\n2068:\
      \     traceFromBackend.toEncoder.priv,\n2069:     traceFromBackend.toEncoder.groups(0).valid\n\
      2070:   )\n2071:   (0 until TraceGroupNum).foreach { i =>\n2072:     traceToL2Top.toEncoder.groups(i).valid
      := RegNext(traceFromBackend.toEncoder.groups(i).valid)\n2073:     traceToL2Top.toEncoder.groups(i).bits.iretire
      := RegNext(traceFromBackend.toEncoder.groups(i).bits.iretire)\n2074:     traceToL2Top.toEncoder.groups(i).bits.itype
      := RegNext(traceFromBackend.toEncoder.groups(i).bits.itype)\n2075:     traceToL2Top.toEncoder.groups(i).bits.ilastsize
      := RegEnable(\n2076:       traceFromBackend.toEncoder.groups(i).bits.ilastsize,\n\
      2077:       traceFromBackend.toEncoder.groups(i).valid\n2078:     )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 2143-2153
    context: "2143:       params = Seq(params),\n2144:       ids = Seq(mbistPl.get.childrenIds),\n\
      2145:       name = s\"MbistIntfMemBlk\",\n2146:       pipelineNum = 1\n2147:\
      \     )))\n2148:     intf.get.toPipeline.head <> mbistPl.get.mbist\n2149:  \
      \   mbistPl.get.registerCSV(intf.get.info, \"MbistMemBlk\")\n2150:     intf.get.mbist
      := DontCare\n2151:     dontTouch(intf.get.mbist)\n2152:     //TODO: add mbist
      controller connections here\n2153:     intf"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 2163-2174
    context: "2163:   } else {\n2164:     cg.cgen := false.B\n2165:   }\n2166: \n\
      2167:   // sram debug\n2168:   sigFromSrams.foreach({ case sig => sig := DontCare
      })\n2169:   sigFromSrams.zip(io.dft).foreach {\n2170:     case (sig, dft) =>\n\
      2171:       if (hasMbist) {\n2172:         sig.ram_hold := dft.ram_hold\n2173:\
      \         sig.ram_bypass := dft.ram_bypass\n2174:         sig.ram_bp_clken :=
      dft.ram_bp_clken"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 2179-2192
    context: "2179:       }\n2180:       if (hasSramCtl) {\n2181:         sig.ram_ctl
      := dft.ram_ctl\n2182:       }\n2183:   }\n2184:   io.dft_frnt.zip(sigFromSrams).foreach({
      case (a, b) => a := b })\n2185:   io.dft_reset_frnt.zip(io.dft_reset).foreach({
      case (a, b) => a := b })\n2186:   io.dft_bcknd.zip(sigFromSrams).foreach({ case
      (a, b) => a := b })\n2187:   io.dft_reset_bcknd.zip(io.dft_reset).foreach({
      case (a, b) => a := b })\n2188: }\n2189: \n2190: class MemBlock()(implicit p:
      Parameters) extends LazyModule\n2191:   with HasXSParameter {\n2192:   override
      def shouldBeInlined: Boolean = false"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 93-103
    context: "93: class PredecodeWritebackBundle(implicit p: Parameters) extends XSBundle
      {\n94:   val pc         = Vec(PredictWidth, UInt(VAddrBits.W))\n95:   val pd\
      \         = Vec(PredictWidth, new PreDecodeInfo) // TODO: redefine Predecode\n\
      96:   val ftqIdx     = new FtqPtr\n97:   val ftqOffset  = UInt(log2Ceil(PredictWidth).W)\n\
      98:   val misOffset  = ValidUndirectioned(UInt(log2Ceil(PredictWidth).W))\n\
      99:   val cfiOffset  = ValidUndirectioned(UInt(log2Ceil(PredictWidth).W))\n\
      100:   val target     = UInt(VAddrBits.W)\n101:   val jalTarget  = UInt(VAddrBits.W)\n\
      102:   val instrRange = Vec(PredictWidth, Bool())\n103: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 100-112
    context: "100:   val target     = UInt(VAddrBits.W)\n101:   val jalTarget  = UInt(VAddrBits.W)\n\
      102:   val instrRange = Vec(PredictWidth, Bool())\n103: }\n104: \n105: class
      mmioCommitRead(implicit p: Parameters) extends XSBundle {\n106:   val mmioFtqPtr\
      \     = Output(new FtqPtr)\n107:   val mmioLastCommit = Input(Bool())\n108:
      }\n109: \n110: object ExceptionType {\n111:   def width: Int  = 2\n112:   def
      none:  UInt = \"b00\".U(width.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 194-204
    context: "194: //      exceptions.head\n195: //    } else {\n196: //      Mux(exceptions.head
      =/= none, exceptions.head, merge(exceptions.tail: _*))\n197: //    }\n198: \
      \    // use MuxCase with default\n199:     exceptions.foreach(e => require(e.getWidth
      == width))\n200:     val mapping = exceptions.init.map(e => (e =/= none) ->
      e)\n201:     val default = exceptions.last\n202:     MuxCase(default, mapping)\n\
      203:   }\n204: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 227-238
    context: "227: //      VecInit((exceptionVecs.head zip merge(exceptionVecs.tail:
      _*)).map{ case (high, low) =>\n228: //        Mux(high =/= none, high, low)\n\
      229: //      })\n230: //    }\n231:     // merge port-by-port\n232:     val
      length = exceptionVecs.head.length\n233:     exceptionVecs.tail.foreach(vec
      => require(vec.length == length))\n234:     VecInit((0 until length).map(i =>
      merge(exceptionVecs.map(_(i)): _*)))\n235:   }\n236: }\n237: \n238: class FetchToIBuffer(implicit
      p: Parameters) extends XSBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 275-290
    context: "275:   }\n276: \n277:   def update(br_valids: Vec[Bool], real_taken_mask:
      Vec[Bool]): ShiftingGlobalHistory = {\n278:     require(br_valids.length ==
      numBr)\n279:     require(real_taken_mask.length == numBr)\n280:     val last_valid_idx
      = PriorityMux(\n281:       br_valids.reverse :+ true.B,\n282:       (numBr to
      0 by -1).map(_.U(log2Ceil(numBr + 1).W))\n283:     )\n284:     val first_taken_idx
      = PriorityEncoder(false.B +: real_taken_mask)\n285:     val smaller        \
      \ = Mux(last_valid_idx < first_taken_idx, last_valid_idx, first_taken_idx)\n\
      286:     val shift           = smaller\n287:     val taken           = real_taken_mask.reduce(_
      || _)\n288:     update(shift, taken, this.predHist)\n289:   }\n290: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 287-297
    context: "287:     val taken           = real_taken_mask.reduce(_ || _)\n288:\
      \     update(shift, taken, this.predHist)\n289:   }\n290: \n291:   // static
      read\n292:   def read(n: Int): Bool = predHist.asBools(n)\n293: \n294:   final
      def ===(that: ShiftingGlobalHistory): Bool =\n295:     predHist === that.predHist\n\
      296: \n297:   final def =/=(that: ShiftingGlobalHistory): Bool = !(this ===
      that)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 329-339
    context: "329:   def need_oldest_bits           = len > compLen\n330:   def info\
      \                       = (len, compLen)\n331:   def oldest_bit_to_get_from_ghr
      = (0 until max_update_num).map(len - _ - 1)\n332:   def oldest_bit_pos_in_folded\
      \   = oldest_bit_to_get_from_ghr map (_ % compLen)\n333:   def oldest_bit_wrap_around\
      \     = oldest_bit_to_get_from_ghr map (_ / compLen > 0)\n334:   def oldest_bit_start\
      \           = oldest_bit_pos_in_folded.head\n335: \n336:   def get_oldest_bits_from_ghr(ghr:
      Vec[Bool], histPtr: CGHPtr) =\n337:     // TODO: wrap inc for histPtr value\n\
      338:     oldest_bit_to_get_from_ghr.map(i => ghr((histPtr + (i + 1).U).value))\n\
      339: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 427-437
    context: "427:   }\n428: }\n429: \n430: class AllAheadFoldedHistoryOldestBits(val
      gen: Seq[Tuple2[Int, Int]])(implicit p: Parameters) extends XSBundle\n431: \
      \    with HasBPUConst {\n432:   val afhob = MixedVec(gen.filter(t => t._1 >
      t._2).map(_._1)\n433:     .toSet.toList.map(l => new AheadFoldedHistoryOldestBits(l,
      numBr))) // remove duplicates\n434:   require(gen.toSet.toList.equals(gen))\n\
      435:   def getObWithInfo(info: Tuple2[Int, Int]) = {\n436:     val selected
      = afhob.filter(_.len == info._1)\n437:     require(selected.length == 1)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 435-445
    context: "435:   def getObWithInfo(info: Tuple2[Int, Int]) = {\n436:     val selected
      = afhob.filter(_.len == info._1)\n437:     require(selected.length == 1)\n438:\
      \     selected(0)\n439:   }\n440:   def read(ghv: Vec[Bool], ptr: CGHPtr) =
      {\n441:     val hisLens      = afhob.map(_.len)\n442:     val bitsToRead   =
      hisLens.flatMap(l => (0 until numBr * 2).map(i => l - i - 1)).toSet // remove
      duplicates\n443:     val bitsWithInfo = bitsToRead.map(pos => (pos, ghv((ptr
      + (pos + 1).U).value)))\n444:     for (ob <- afhob) {\n445:       for (i <-
      0 until numBr * 2) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 451-461
    context: "451:     }\n452:   }\n453: }\n454: \n455: class AllFoldedHistories(val
      gen: Seq[Tuple2[Int, Int]])(implicit p: Parameters) extends XSBundle with HasBPUConst
      {\n456:   val hist = MixedVec(gen.map { case (l, cl) => new FoldedHistory(l,
      cl, numBr) })\n457:   // println(gen.mkString)\n458:   require(gen.toSet.toList.equals(gen))\n\
      459:   def getHistWithInfo(info: Tuple2[Int, Int]) = {\n460:     val selected
      = hist.filter(_.info.equals(info))\n461:     require(selected.length == 1)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 539-549
    context: "539:   val br_taken_mask = Vec(numBr, Bool())\n540: \n541:   val slot_valids
      = Vec(totalSlot, Bool())\n542: \n543:   val targets         = Vec(totalSlot,
      UInt(VAddrBits.W))\n544:   val jalr_target     = UInt(VAddrBits.W) // special
      path for indirect predictors\n545:   val offsets         = Vec(totalSlot, UInt(log2Ceil(PredictWidth).W))\n\
      546:   val fallThroughAddr = UInt(VAddrBits.W)\n547:   val fallThroughErr  =
      Bool()\n548:   val multiHit        = Bool()\n549: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 682-692
    context: "682: //\n683: class BranchPredictionBundle(val isNotS3: Boolean)(implicit
      p: Parameters) extends XSBundle\n684:     with HasBPUConst with BPUUtils {\n\
      685:   val pc          = Vec(numDup, UInt(VAddrBits.W))\n686:   val valid  \
      \     = Vec(numDup, Bool())\n687:   val hasRedirect = Vec(numDup, Bool())\n\
      688:   val ftq_idx     = new FtqPtr\n689:   val full_pred   = Vec(numDup, new
      FullBranchPrediction(isNotS3))\n690: \n691:   def target(pc:     UInt)     \
      \ = VecInit(full_pred.map(_.target(pc)))\n692:   def targets(pc:    Vec[UInt])
      = VecInit(pc.zipWithIndex.map { case (pc, idx) => full_pred(idx).target(pc)
      })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 725-736
    context: "725:   val topdown_info = new FrontendTopDownBundle\n726: \n727:   def
      selectedResp = {\n728:     val res =\n729:       PriorityMux(Seq(\n730:    \
      \     (s3.valid(3) && s3.hasRedirect(3)) -> s3,\n731:         (s2.valid(3) &&
      s2.hasRedirect(3)) -> s2,\n732:         s1.valid(3)                        ->
      s1\n733:       ))\n734:     res\n735:   }\n736:   def selectedRespIdxForFtq
      ="
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 733-744
    context: "733:       ))\n734:     res\n735:   }\n736:   def selectedRespIdxForFtq
      =\n737:     PriorityMux(Seq(\n738:       (s3.valid(3) && s3.hasRedirect(3))
      -> BP_S3,\n739:       (s2.valid(3) && s2.hasRedirect(3)) -> BP_S2,\n740:   \
      \    s1.valid(3)                        -> BP_S1\n741:     ))\n742:   def lastStage
      = s3\n743: }\n744: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 749-759
    context: "749:   val spec_info = new SpeculativeInfo\n750:   val ftb_entry = new
      FTBEntry()\n751: \n752:   val cfi_idx           = ValidUndirectioned(UInt(log2Ceil(PredictWidth).W))\n\
      753:   val br_taken_mask     = Vec(numBr, Bool())\n754:   val br_committed \
      \     = Vec(numBr, Bool()) // High only when br valid && br committed\n755:\
      \   val jmp_taken         = Bool()\n756:   val mispred_mask      = Vec(numBr
      + 1, Bool())\n757:   val pred_hit          = Bool()\n758:   val false_hit  \
      \       = Bool()\n759:   val new_br_insert_pos = Vec(numBr, Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 777-787
    context: "777:     XSDebug(cond, p\"[new_br_insert_pos] ${Binary(new_br_insert_pos.asUInt)}\\\
      n\")\n778:     XSDebug(cond, p\"--------------------------------------------\\\
      n\")\n779:   }\n780: }\n781: \n782: class BranchPredictionRedirect(implicit
      p: Parameters) extends Redirect with HasBPUConst {\n783:   // override def toPrintable:
      Printable = {\n784:   //   p\"-----------BranchPredictionRedirect-----------
      \" +\n785:   //     p\"-----------cfiUpdate----------- \" +\n786:   //     p\"\
      [pc] ${Hexadecimal(cfiUpdate.pc)} \" +\n787:   //     p\"[predTaken] ${cfiUpdate.predTaken},
      [taken] ${cfiUpdate.taken}, [isMisPred] ${cfiUpdate.isMisPred} \" +"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 797-807
    context: "797: \n798:   // }\n799: \n800:   // TODO: backend should pass topdown
      signals here\n801:   // must not change its parent since BPU has used asTypeOf(this
      type) from its parent class\n802:   require(isInstanceOf[Redirect])\n803:  \
      \ val BTBMissBubble         = Bool()\n804:   def ControlRedirectBubble = debugIsCtrl\n\
      805:   // if mispred br not in ftb, count as BTB miss\n806:   def ControlBTBMissBubble
      = ControlRedirectBubble && !cfiUpdate.br_hit && !cfiUpdate.jr_hit\n807:   def
      TAGEMissBubble       = ControlRedirectBubble && cfiUpdate.br_hit && !cfiUpdate.sc_hit"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 806-819
    context: "806:   def ControlBTBMissBubble = ControlRedirectBubble && !cfiUpdate.br_hit
      && !cfiUpdate.jr_hit\n807:   def TAGEMissBubble       = ControlRedirectBubble
      && cfiUpdate.br_hit && !cfiUpdate.sc_hit\n808:   def SCMissBubble         =
      ControlRedirectBubble && cfiUpdate.br_hit && cfiUpdate.sc_hit\n809:   def ITTAGEMissBubble\
      \     = ControlRedirectBubble && cfiUpdate.jr_hit && !cfiUpdate.pd.isRet\n810:\
      \   def RASMissBubble        = ControlRedirectBubble && cfiUpdate.jr_hit &&
      cfiUpdate.pd.isRet\n811:   def MemVioRedirectBubble = debugIsMemVio\n812:  \
      \ def OtherRedirectBubble  = !debugIsCtrl && !debugIsMemVio\n813: \n814:   def
      connectRedirect(source: Redirect): Unit =\n815:     for ((name, data) <- this.elements)
      {\n816:       if (source.elements.contains(name)) {\n817:         data := source.elements(name)\n\
      818:       }\n819:     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/WrBypass.scala
    lines: 66-76
    context: "66:   val hit     = hits_oh.reduce(_ || _)\n67: \n68:   io.hit := hit\n\
      69:   for (i <- 0 until numWays) {\n70:     io.hit_data(i).valid := Mux1H(hits_oh,
      valids)(i)\n71:     io.hit_data(i).bits  := data_mem.read(hit_idx)(i)\n72: \
      \  }\n73: \n74:   // Replacer\n75:   // Because data_mem can only write to one
      index\n76:   // Implementing a per-way replacer is meaningless"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FauFTB.scala
    lines: 48-58
    context: "48:     val update_req_tag = Input(UInt(tagSize.W))\n49:     val update_hit\
      \     = Output(Bool())\n50:     val write_valid    = Input(Bool())\n51:    \
      \ val write_entry    = Input(new FauFTBEntry)\n52:     val write_tag      =
      Input(UInt(tagSize.W))\n53:     val tag_read       = Output(UInt(tagSize.W))\n\
      54:   })\n55: \n56:   val data  = Reg(new FauFTBEntry)\n57:   val tag   = Reg(UInt(tagSize.W))\n\
      58:   val valid = RegInit(false.B)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FauFTB.scala
    lines: 60-70
    context: "60:   io.resp     := data\n61:   io.resp_hit := tag === io.req_tag &&
      valid\n62:   // write bypass to avoid multiple hit\n63:   io.update_hit := ((tag
      === io.update_req_tag) && valid) ||\n64:     ((io.write_tag === io.update_req_tag)
      && io.write_valid)\n65:   io.tag_read := tag\n66: \n67:   when(io.write_valid)
      {\n68:     when(!valid) {\n69:       valid := true.B\n70:     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FauFTB.scala
    lines: 74-84
    context: "74: }\n75: \n76: class FauFTB(implicit p: Parameters) extends BasePredictor
      with FauFTBParams {\n77: \n78:   class FauFTBMeta(implicit p: Parameters) extends
      XSBundle with FauFTBParams {\n79:     val pred_way = if (!env.FPGAPlatform)
      Some(UInt(log2Ceil(numWays).W)) else None\n80:     val hit      = Bool()\n81:\
      \   }\n82:   val resp_meta             = Wire(new FauFTBMeta)\n83:   override
      val meta_size    = resp_meta.getWidth\n84:   override val is_fast_pred = true"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FauFTB.scala
    lines: 88-98
    context: "88:   val ctrs                = Seq.tabulate(numWays)(w => Seq.tabulate(numBr)(b
      => RegInit(2.U(2.W))))\n89:   val replacer            = ReplacementPolicy.fromString(\"\
      plru\", numWays)\n90:   val replacer_touch_ways = Wire(Vec(2, Valid(UInt(log2Ceil(numWays).W))))\n\
      91: \n92:   // pred req\n93:   ways.foreach(_.io.req_tag := getTag(s1_pc_dup(0)))\n\
      94: \n95:   // pred resp\n96:   val s1_hit_oh              = VecInit(ways.map(_.io.resp_hit)).asUInt\n\
      97:   val s1_hit                 = s1_hit_oh.orR\n98:   val s1_hit_way     \
      \        = OHToUInt(s1_hit_oh)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FauFTB.scala
    lines: 119-129
    context: "119:   // Illegal check for FTB entry reading\n120:   val s1_pc_startLower
      = Cat(0.U(1.W), s1_pc_dup(0)(instOffsetBits + log2Ceil(PredictWidth) - 1, instOffsetBits))\n\
      121:   val uftb_entry_endLowerwithCarry = Cat(s1_hit_fauftbentry.carry, s1_hit_fauftbentry.pftAddr)\n\
      122:   val fallThroughErr               = s1_pc_startLower + PredictWidth.U
      >= uftb_entry_endLowerwithCarry\n123:   when(io.s1_fire(0) && s1_hit) {\n124:\
      \     assert(fallThroughErr, s\"FauFTB read entry fallThrough address error!\"\
      )\n125:   }\n126: \n127:   // assign metas\n128:   io.out.last_stage_meta :=
      resp_meta.asUInt\n129:   resp_meta.hit          := RegEnable(RegEnable(s1_hit,
      io.s1_fire(0)), io.s2_fire(0))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FauFTB.scala
    lines: 125-136
    context: "125:   }\n126: \n127:   // assign metas\n128:   io.out.last_stage_meta
      := resp_meta.asUInt\n129:   resp_meta.hit          := RegEnable(RegEnable(s1_hit,
      io.s1_fire(0)), io.s2_fire(0))\n130:   if (resp_meta.pred_way.isDefined) {\n\
      131:     resp_meta.pred_way.get := RegEnable(RegEnable(s1_hit_way, io.s1_fire(0)),
      io.s2_fire(0))\n132:   }\n133: \n134:   // pred update replacer state\n135:\
      \   val s1_fire = io.s1_fire(0)\n136:   replacer_touch_ways(0).valid := RegNext(s1_fire(0)
      && s1_hit)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FauFTB.scala
    lines: 148-158
    context: "148:   // so io.update.bits.pc is used directly here\n149:   val u_pc
      = io.update.bits.pc\n150: \n151:   val u_meta   = u_bits.meta.asTypeOf(new FauFTBMeta)\n\
      152:   val u_s0_tag = getTag(u_pc)\n153:   ways.foreach(_.io.update_req_tag
      := u_s0_tag)\n154:   val u_s0_hit_oh = VecInit(ways.map(_.io.update_hit)).asUInt\n\
      155:   val u_s0_hit    = u_s0_hit_oh.orR\n156:   val u_s0_br_update_valids =\n\
      157:     VecInit((0 until numBr).map(w =>\n158:       u_bits.ftb_entry.brValids(w)
      && u_valid && !u_bits.ftb_entry.strong_bias(w) &&"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FauFTB.scala
    lines: 215-226
    context: "215:   for (w <- 0 until numWays) {\n216:     XSPerfAccumulate(f\"uftb_pred_hit_way_${w}\"\
      , u_pred_hit_way_map(w))\n217:     XSPerfAccumulate(f\"uftb_replace_way_${w}\"\
      , !u_s1_hit && u_s1_alloc_way === w.U)\n218:   }\n219: \n220:   if (u_meta.pred_way.isDefined)
      {\n221:     val u_commit_hit_way_map = (0 until numWays).map(w => u_valid &&
      u_meta.hit && u_meta.pred_way.get === w.U)\n222:     for (w <- 0 until numWays)
      {\n223:       XSPerfAccumulate(f\"uftb_commit_hit_way_${w}\", u_commit_hit_way_map(w))\n\
      224:     }\n225:   }\n226: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 106-118
    context: "106:   val bpu          = Module(new Predictor)\n107:   val ifu    \
      \      = Module(new NewIFU)\n108:   val ibuffer      = Module(new IBuffer)\n\
      109:   val ftq          = Module(new Ftq)\n110: \n111:   val needFlush     \
      \       = RegNext(io.backend.toFtq.redirect.valid)\n112:   val FlushControlRedirect
      = RegNext(io.backend.toFtq.redirect.bits.debugIsCtrl)\n113:   val FlushMemVioRedirect\
      \  = RegNext(io.backend.toFtq.redirect.bits.debugIsMemVio)\n114:   val FlushControlBTBMiss\
      \  = Wire(Bool())\n115:   val FlushTAGEMiss        = Wire(Bool())\n116:   val
      FlushSCMiss          = Wire(Bool())\n117:   val FlushITTAGEMiss      = Wire(Bool())\n\
      118:   val FlushRASMiss         = Wire(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 135-145
    context: "135:   val PortNumber = ICacheParameters().PortNumber\n136:   val pmp\
      \        = Module(new PMP())\n137:   val pmp_check  = VecInit(Seq.fill(coreParams.ipmpPortNum)(Module(new
      PMPChecker(3, sameCycle = true)).io))\n138:   pmp.io.distribute_csr := csrCtrl.distribute_csr\n\
      139:   val pmp_req_vec = Wire(Vec(coreParams.ipmpPortNum, Valid(new PMPReqBundle())))\n\
      140:   (0 until 2 * PortNumber).foreach(i => pmp_req_vec(i) <> icache.io.pmp(i).req)\n\
      141:   pmp_req_vec.last <> ifu.io.pmp.req\n142: \n143:   for (i <- pmp_check.indices)
      {\n144:     if (HasBitmapCheck) {\n145:       pmp_check(i).apply(tlbCsr.mbmc.CMODE.asBool,
      tlbCsr.priv.imode, pmp.io.pmp, pmp.io.pma, pmp_req_vec(i))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 145-171
    context: "145:       pmp_check(i).apply(tlbCsr.mbmc.CMODE.asBool, tlbCsr.priv.imode,
      pmp.io.pmp, pmp.io.pma, pmp_req_vec(i))\n146:     } else {\n147:       pmp_check(i).apply(tlbCsr.priv.imode,
      pmp.io.pmp, pmp.io.pma, pmp_req_vec(i))\n148:     }\n149:   }\n150:   (0 until
      2 * PortNumber).foreach(i => icache.io.pmp(i).resp <> pmp_check(i).resp)\n151:\
      \   ifu.io.pmp.resp <> pmp_check.last.resp\n152: \n153:   val itlb =\n154: \
      \    Module(new TLB(coreParams.itlbPortNum, nRespDups = 1, Seq.fill(PortNumber)(false)
      ++ Seq(true), itlbParams))\n155:   itlb.io.requestor.take(PortNumber) zip icache.io.itlb
      foreach { case (a, b) => a <> b }\n156:   itlb.io.requestor.last <> ifu.io.iTLBInter
      // mmio may need re-tlb, blocked\n157:   itlb.io.hartId := io.hartId\n158: \
      \  itlb.io.base_connect(sfence, tlbCsr)\n159:   itlb.io.flushPipe.foreach(_
      := icache.io.itlbFlushPipe)\n160:   itlb.io.redirect := DontCare // itlb has
      flushpipe, don't need redirect signal\n161: \n162:   val itlb_ptw = Wire(new
      VectorTlbPtwIO(coreParams.itlbPortNum))\n163:   itlb_ptw.connect(itlb.io.ptw)\n\
      164:   val itlbRepeater1 = PTWFilter(itlbParams.fenceDelay, itlb_ptw, sfence,
      tlbCsr, l2tlbParams.ifilterSize)\n165:   val itlbRepeater2 =\n166:     PTWRepeaterNB(passReady
      = false, itlbParams.fenceDelay, itlbRepeater1.io.ptw, io.ptw, sfence, tlbCsr)\n\
      167: \n168:   icache.io.ftqPrefetch <> ftq.io.toPrefetch\n169:   icache.io.softPrefetch
      <> io.softPrefetch\n170: \n171:   // wfi (backend-icache, backend-instrUncache)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 176-186
    context: "176:   // return safe only when both icache & instrUncache are safe,
      also only when has wfiReq (like, safe := wfiReq.fire)\n177:   io.backend.wfi.wfiSafe
      := DelayN(wfiReq && icache.io.wfi.wfiSafe && instrUncache.io.wfi.wfiSafe, 1)\n\
      178: \n179:   // IFU-Ftq\n180:   ifu.io.ftqInter.fromFtq <> ftq.io.toIfu\n181:\
      \   ftq.io.toIfu.req.ready := ifu.io.ftqInter.fromFtq.req.ready && icache.io.fetch.req.ready\n\
      182: \n183:   ftq.io.fromIfu <> ifu.io.ftqInter.toFtq\n184:   bpu.io.ftq_to_bpu
      <> ftq.io.toBpu\n185:   ftq.io.fromBpu <> bpu.io.bpu_to_ftq\n186: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 182-196
    context: "182: \n183:   ftq.io.fromIfu <> ifu.io.ftqInter.toFtq\n184:   bpu.io.ftq_to_bpu
      <> ftq.io.toBpu\n185:   ftq.io.fromBpu <> bpu.io.bpu_to_ftq\n186: \n187:   ftq.io.mmioCommitRead
      <> ifu.io.mmioCommitRead\n188: \n189:   // IFU-ICache\n190:   icache.io.fetch.req
      <> ftq.io.toICache.req\n191:   ftq.io.toICache.req.ready := ifu.io.ftqInter.fromFtq.req.ready
      && icache.io.fetch.req.ready\n192: \n193:   ifu.io.icacheInter.resp <> icache.io.fetch.resp\n\
      194:   ifu.io.icacheInter.icacheReady       := icache.io.toIFU\n195:   ifu.io.icacheInter.topdownIcacheMiss
      := icache.io.fetch.topdownIcacheMiss\n196:   ifu.io.icacheInter.topdownItlbMiss\
      \   := icache.io.fetch.topdownItlbMiss"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 193-203
    context: "193:   ifu.io.icacheInter.resp <> icache.io.fetch.resp\n194:   ifu.io.icacheInter.icacheReady\
      \       := icache.io.toIFU\n195:   ifu.io.icacheInter.topdownIcacheMiss := icache.io.fetch.topdownIcacheMiss\n\
      196:   ifu.io.icacheInter.topdownItlbMiss   := icache.io.fetch.topdownItlbMiss\n\
      197:   icache.io.stop                       := ifu.io.icacheStop\n198:   icache.io.flush\
      \                      := ftq.io.icacheFlush\n199: \n200:   ifu.io.icachePerfInfo
      := icache.io.perfInfo\n201: \n202:   icache.io.csr_pf_enable := RegNext(csrCtrl.pf_ctrl.l1I_pf_enable)\n\
      203: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 233-244
    context: "233:     val prevNotTakenValid  = RegInit(0.B)\n234:     val prevNotTakenFtqPtr
      = Reg(new FtqPtr)\n235:     for (i <- 0 until DecodeWidth - 1) {\n236:     \
      \  // for instrs that is not the last, if a not-taken br, the next instr should
      have the same ftqPtr\n237:       // for instrs that is the last, record and
      check next request\n238:       when(ibuffer.io.out(i).fire && ibuffer.io.out(i).bits.pd.isBr)
      {\n239:         when(ibuffer.io.out(i + 1).fire) {\n240:           // not last
      br, check now\n241:         }.otherwise {\n242:           // last br, record
      its info\n243:           prevNotTakenValid  := true.B\n244:           prevNotTakenFtqPtr
      := checkTargetPtr(i)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 243-273
    context: "243:           prevNotTakenValid  := true.B\n244:           prevNotTakenFtqPtr
      := checkTargetPtr(i)\n245:         }\n246:       }\n247:       XSError(\n248:\
      \         ibuffer.io.out(i).fire && ibuffer.io.out(i).bits.pd.isBr &&\n249:\
      \           ibuffer.io.out(i + 1).fire &&\n250:           checkTargetPtr(i).value
      =/= checkTargetPtr(i + 1).value,\n251:         \"not-taken br should have same
      ftqPtr\\n\"\n252:       )\n253:     }\n254:     when(ibuffer.io.out(DecodeWidth
      - 1).fire && ibuffer.io.out(DecodeWidth - 1).bits.pd.isBr) {\n255:       //
      last instr is a br, record its info\n256:       prevNotTakenValid  := true.B\n\
      257:       prevNotTakenFtqPtr := checkTargetPtr(DecodeWidth - 1)\n258:     }\n\
      259:     when(prevNotTakenValid && ibuffer.io.out(0).fire) {\n260:       prevNotTakenValid
      := false.B\n261:     }\n262:     XSError(\n263:       prevNotTakenValid && ibuffer.io.out(0).fire
      &&\n264:         prevNotTakenFtqPtr.value =/= checkTargetPtr(0).value,\n265:\
      \       \"not-taken br should have same ftqPtr\\n\"\n266:     )\n267: \n268:\
      \     when(needFlush) {\n269:       prevNotTakenValid := false.B\n270:     }\n\
      271:   }\n272: \n273:   def checkTakenNotConsecutive = {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 274-285
    context: "274:     val prevTakenValid  = RegInit(0.B)\n275:     val prevTakenFtqPtr
      = Reg(new FtqPtr)\n276:     for (i <- 0 until DecodeWidth - 1) {\n277:     \
      \  // for instrs that is not the last, if a taken br, the next instr should
      not have the same ftqPtr\n278:       // for instrs that is the last, record
      and check next request\n279:       when(ibuffer.io.out(i).fire && ibuffer.io.out(i).bits.pd.isBr
      && ibuffer.io.out(i).bits.pred_taken) {\n280:         when(ibuffer.io.out(i
      + 1).fire) {\n281:           // not last br, check now\n282:         }.otherwise
      {\n283:           // last br, record its info\n284:           prevTakenValid\
      \  := true.B\n285:           prevTakenFtqPtr := checkTargetPtr(i)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 284-300
    context: "284:           prevTakenValid  := true.B\n285:           prevTakenFtqPtr
      := checkTargetPtr(i)\n286:         }\n287:       }\n288:       XSError(\n289:\
      \         ibuffer.io.out(i).fire && ibuffer.io.out(i).bits.pd.isBr && ibuffer.io.out(i).bits.pred_taken
      &&\n290:           ibuffer.io.out(i + 1).fire &&\n291:           (checkTargetPtr(i)
      + 1.U).value =/= checkTargetPtr(i + 1).value,\n292:         \"taken br should
      have consecutive ftqPtr\\n\"\n293:       )\n294:     }\n295:     when(ibuffer.io.out(DecodeWidth
      - 1).fire && ibuffer.io.out(DecodeWidth - 1).bits.pd.isBr && ibuffer.io.out(\n\
      296:       DecodeWidth - 1\n297:     ).bits.pred_taken) {\n298:       // last
      instr is a br, record its info\n299:       prevTakenValid  := true.B\n300: \
      \      prevTakenFtqPtr := checkTargetPtr(DecodeWidth - 1)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 297-315
    context: "297:     ).bits.pred_taken) {\n298:       // last instr is a br, record
      its info\n299:       prevTakenValid  := true.B\n300:       prevTakenFtqPtr :=
      checkTargetPtr(DecodeWidth - 1)\n301:     }\n302:     when(prevTakenValid &&
      ibuffer.io.out(0).fire) {\n303:       prevTakenValid := false.B\n304:     }\n\
      305:     XSError(\n306:       prevTakenValid && ibuffer.io.out(0).fire &&\n\
      307:         (prevTakenFtqPtr + 1.U).value =/= checkTargetPtr(0).value,\n308:\
      \       \"taken br should have consecutive ftqPtr\\n\"\n309:     )\n310:   \
      \  when(needFlush) {\n311:       prevTakenValid := false.B\n312:     }\n313:\
      \   }\n314: \n315:   def checkNotTakenPC = {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 316-327
    context: "316:     val prevNotTakenPC    = Reg(UInt(VAddrBits.W))\n317:     val
      prevIsRVC         = Reg(Bool())\n318:     val prevNotTakenValid = RegInit(0.B)\n\
      319: \n320:     for (i <- 0 until DecodeWidth - 1) {\n321:       when(ibuffer.io.out(i).fire
      && ibuffer.io.out(i).bits.pd.isBr && !ibuffer.io.out(i).bits.pred_taken) {\n\
      322:         when(ibuffer.io.out(i + 1).fire) {}.otherwise {\n323:         \
      \  prevNotTakenValid := true.B\n324:           prevIsRVC         := ibuffer.io.out(i).bits.pd.isRVC\n\
      325:           prevNotTakenPC    := ibuffer.io.out(i).bits.pc\n326:        \
      \ }\n327:       }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 324-335
    context: "324:           prevIsRVC         := ibuffer.io.out(i).bits.pd.isRVC\n\
      325:           prevNotTakenPC    := ibuffer.io.out(i).bits.pc\n326:        \
      \ }\n327:       }\n328:       XSError(\n329:         ibuffer.io.out(i).fire
      && ibuffer.io.out(i).bits.pd.isBr && !ibuffer.io.out(i).bits.pred_taken &&\n\
      330:           ibuffer.io.out(i + 1).fire &&\n331:           ibuffer.io.out(i).bits.pc
      + Mux(ibuffer.io.out(i).bits.pd.isRVC, 2.U, 4.U) =/= ibuffer.io.out(\n332: \
      \            i + 1\n333:           ).bits.pc,\n334:         \"not-taken br should
      have consecutive pc\\n\"\n335:       )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 332-342
    context: "332:             i + 1\n333:           ).bits.pc,\n334:         \"not-taken
      br should have consecutive pc\\n\"\n335:       )\n336:     }\n337:     when(ibuffer.io.out(DecodeWidth
      - 1).fire && ibuffer.io.out(DecodeWidth - 1).bits.pd.isBr && !ibuffer.io.out(\n\
      338:       DecodeWidth - 1\n339:     ).bits.pred_taken) {\n340:       prevNotTakenValid
      := true.B\n341:       prevIsRVC         := ibuffer.io.out(DecodeWidth - 1).bits.pd.isRVC\n\
      342:       prevNotTakenPC    := ibuffer.io.out(DecodeWidth - 1).bits.pc"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 339-357
    context: "339:     ).bits.pred_taken) {\n340:       prevNotTakenValid := true.B\n\
      341:       prevIsRVC         := ibuffer.io.out(DecodeWidth - 1).bits.pd.isRVC\n\
      342:       prevNotTakenPC    := ibuffer.io.out(DecodeWidth - 1).bits.pc\n343:\
      \     }\n344:     when(prevNotTakenValid && ibuffer.io.out(0).fire) {\n345:\
      \       prevNotTakenValid := false.B\n346:     }\n347:     XSError(\n348:  \
      \     prevNotTakenValid && ibuffer.io.out(0).fire &&\n349:         prevNotTakenPC
      + Mux(prevIsRVC, 2.U, 4.U) =/= ibuffer.io.out(0).bits.pc,\n350:       \"not-taken
      br should have same pc\\n\"\n351:     )\n352:     when(needFlush) {\n353:  \
      \     prevNotTakenValid := false.B\n354:     }\n355:   }\n356: \n357:   def
      checkTakenPC = {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 359-370
    context: "359:     val prevTakenValid  = RegInit(0.B)\n360:     val prevTakenTarget
      = Wire(UInt(VAddrBits.W))\n361:     prevTakenTarget := checkPcMem((prevTakenFtqPtr
      + 1.U).value).startAddr\n362: \n363:     for (i <- 0 until DecodeWidth - 1)
      {\n364:       when(ibuffer.io.out(i).fire && !ibuffer.io.out(i).bits.pd.notCFI
      && ibuffer.io.out(i).bits.pred_taken) {\n365:         when(ibuffer.io.out(i
      + 1).fire) {}.otherwise {\n366:           prevTakenValid  := true.B\n367:  \
      \         prevTakenFtqPtr := checkTargetPtr(i)\n368:         }\n369:       }\n\
      370:       XSError("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 366-382
    context: "366:           prevTakenValid  := true.B\n367:           prevTakenFtqPtr
      := checkTargetPtr(i)\n368:         }\n369:       }\n370:       XSError(\n371:\
      \         ibuffer.io.out(i).fire && !ibuffer.io.out(i).bits.pd.notCFI && ibuffer.io.out(i).bits.pred_taken
      &&\n372:           ibuffer.io.out(i + 1).fire &&\n373:           checkTarget(i)
      =/= ibuffer.io.out(i + 1).bits.pc,\n374:         \"taken instr should follow
      target pc\\n\"\n375:       )\n376:     }\n377:     when(ibuffer.io.out(DecodeWidth
      - 1).fire && !ibuffer.io.out(DecodeWidth - 1).bits.pd.notCFI && ibuffer.io.out(\n\
      378:       DecodeWidth - 1\n379:     ).bits.pred_taken) {\n380:       prevTakenValid\
      \  := true.B\n381:       prevTakenFtqPtr := checkTargetPtr(DecodeWidth - 1)\n\
      382:     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 378-396
    context: "378:       DecodeWidth - 1\n379:     ).bits.pred_taken) {\n380:    \
      \   prevTakenValid  := true.B\n381:       prevTakenFtqPtr := checkTargetPtr(DecodeWidth
      - 1)\n382:     }\n383:     when(prevTakenValid && ibuffer.io.out(0).fire) {\n\
      384:       prevTakenValid := false.B\n385:     }\n386:     XSError(\n387:  \
      \     prevTakenValid && ibuffer.io.out(0).fire &&\n388:         prevTakenTarget
      =/= ibuffer.io.out(0).bits.pc,\n389:       \"taken instr should follow target
      pc\\n\"\n390:     )\n391:     when(needFlush) {\n392:       prevTakenValid :=
      false.B\n393:     }\n394:   }\n395: \n396:   // checkNotTakenConsecutive"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 398-410
    context: "398:   checkTakenPC\n399:   checkNotTakenPC\n400: \n401:   ifu.io.rob_commits
      <> io.backend.toFtq.rob_commits\n402: \n403:   ibuffer.io.flush            \
      \    := needFlush\n404:   ibuffer.io.ControlRedirect      := FlushControlRedirect\n\
      405:   ibuffer.io.MemVioRedirect       := FlushMemVioRedirect\n406:   ibuffer.io.ControlBTBMissBubble
      := FlushControlBTBMiss\n407:   ibuffer.io.TAGEMissBubble       := FlushTAGEMiss\n\
      408:   ibuffer.io.SCMissBubble         := FlushSCMiss\n409:   ibuffer.io.ITTAGEMissBubble\
      \     := FlushITTAGEMiss\n410:   ibuffer.io.RASMissBubble        := FlushRASMiss"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 419-429
    context: "419:   io.backend.cfVec <> ibuffer.io.out\n420:   io.backend.stallReason
      <> ibuffer.io.stallReason\n421: \n422:   instrUncache.io.req <> ifu.io.uncacheInter.toUncache\n\
      423:   ifu.io.uncacheInter.fromUncache <> instrUncache.io.resp\n424:   instrUncache.io.flush
      := false.B\n425:   io.error <> RegNext(RegNext(icache.io.error))\n426: \n427:\
      \   icache.io.hartId := io.hartId\n428: \n429:   itlbRepeater1.io.debugTopDown.robHeadVaddr
      := io.debugTopDown.robHeadVaddr"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 459-469
    context: "459:       params = Seq(params),\n460:       ids = Seq(mbistPl.get.childrenIds),\n\
      461:       name = s\"MbistIntfFrontend\",\n462:       pipelineNum = 1\n463:\
      \     )))\n464:     intf.get.toPipeline.head <> mbistPl.get.mbist\n465:    \
      \ mbistPl.get.registerCSV(intf.get.info, \"MbistFrontend\")\n466:     intf.get.mbist
      := DontCare\n467:     dontTouch(intf.get.mbist)\n468:     // TODO: add mbist
      controller connections here\n469:     intf"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 478-489
    context: "478:     cg.cgen := io.dft.get.cgen\n479:   } else {\n480:     cg.cgen
      := false.B\n481:   }\n482: \n483:   sigFromSrams.foreach { case sig => sig :=
      DontCare }\n484:   sigFromSrams.zip(io.dft).foreach {\n485:     case (sig, dft)
      =>\n486:       if (hasMbist) {\n487:         sig.ram_hold     := dft.ram_hold\n\
      488:         sig.ram_bypass   := dft.ram_bypass\n489:         sig.ram_bp_clken
      := dft.ram_bp_clken"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 25-35
    context: "25: \n26: import scala.{Tuple2 => &}\n27: \n28: \n29: class RASEntry()(implicit
      p: Parameters) extends XSBundle {\n30:     val retAddr = UInt(VAddrBits.W)\n\
      31:     val ctr = UInt(8.W) // layer of nested call functions\n32: }\n33: \n\
      34: class RAS(implicit p: Parameters) extends BasePredictor {\n35:   object
      RASEntry {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 31-43
    context: "31:     val ctr = UInt(8.W) // layer of nested call functions\n32: }\n\
      33: \n34: class RAS(implicit p: Parameters) extends BasePredictor {\n35:   object
      RASEntry {\n36:     def apply(retAddr: UInt, ctr: UInt): RASEntry = {\n37: \
      \      val e = Wire(new RASEntry)\n38:       e.retAddr := retAddr\n39:     \
      \  e.ctr := ctr\n40:       e\n41:     }\n42:   }\n43: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 41-51
    context: "41:     }\n42:   }\n43: \n44:   class RASStack(val rasSize: Int) extends
      XSModule {\n45:     val io = IO(new Bundle {\n46:       val push_valid = Input(Bool())\n\
      47:       val pop_valid = Input(Bool())\n48:       val spec_new_addr = Input(UInt(VAddrBits.W))\n\
      49: \n50:       val recover_sp = Input(UInt(log2Up(rasSize).W))\n51:       val
      recover_top = Input(new RASEntry)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 88-99
    context: "88:     }\n89: \n90:     def ptrInc(ptr: UInt) = Mux(ptr === (rasSize-1).U,
      0.U, ptr + 1.U)\n91:     def ptrDec(ptr: UInt) = Mux(ptr === 0.U, (rasSize-1).U,
      ptr - 1.U)\n92: \n93:     val spec_alloc_new = io.spec_new_addr =/= top.retAddr
      || top.ctr.andR\n94:     val recover_alloc_new = io.recover_new_addr =/= io.recover_top.retAddr
      || io.recover_top.ctr.andR\n95: \n96:     // TODO: fix overflow and underflow
      bugs\n97:     def update(recover: Bool)(do_push: Bool, do_pop: Bool, do_alloc_new:
      Bool,\n98:                               do_sp: UInt, do_top_ptr: UInt, do_new_addr:
      UInt,\n99:                               do_top: RASEntry) = {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 99-109
    context: "99:                               do_top: RASEntry) = {\n100:      \
      \ when (do_push) {\n101:         when (do_alloc_new) {\n102:           sp  \
      \   := ptrInc(do_sp)\n103:           topPtr := do_sp\n104:           top.retAddr
      := do_new_addr\n105:           top.ctr := 0.U\n106:           // write bypass\n\
      107:           wen := true.B\n108:           write_bypass_entry := RASEntry(do_new_addr,
      0.U)\n109:           write_bypass_ptr := do_sp"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 109-119
    context: "109:           write_bypass_ptr := do_sp\n110:         }.otherwise {\n\
      111:           when (recover) {\n112:             sp := do_sp\n113:        \
      \     topPtr := do_top_ptr\n114:             top.retAddr := do_top.retAddr\n\
      115:           }\n116:           top.ctr := do_top.ctr + 1.U\n117:         \
      \  // write bypass\n118:           wen := true.B\n119:           write_bypass_entry
      := RASEntry(do_new_addr, do_top.ctr + 1.U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 125-135
    context: "125:           topPtr := ptrDec(do_top_ptr)\n126:           // read
      bypass\n127:           top :=\n128:             Mux(ptrDec(do_top_ptr) === write_bypass_ptr
      && write_bypass_valid,\n129:               write_bypass_entry,\n130:       \
      \        stack.read(ptrDec(do_top_ptr))\n131:             )\n132:         }.otherwise
      {\n133:           when (recover) {\n134:             sp := do_sp\n135:     \
      \        topPtr := do_top_ptr"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 131-146
    context: "131:             )\n132:         }.otherwise {\n133:           when
      (recover) {\n134:             sp := do_sp\n135:             topPtr := do_top_ptr\n\
      136:             top.retAddr := do_top.retAddr\n137:           }\n138:     \
      \      top.ctr := do_top.ctr - 1.U\n139:           // write bypass\n140:   \
      \        wen := true.B\n141:           write_bypass_entry := RASEntry(do_top.retAddr,
      do_top.ctr - 1.U)\n142:           write_bypass_ptr := do_top_ptr\n143:     \
      \    }\n144:       }.otherwise {\n145:         when (recover) {\n146:      \
      \     sp := do_sp"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 154-164
    context: "154:       }\n155:     }\n156: \n157: \n158:     update(io.recover_valid)(\n\
      159:       Mux(io.recover_valid, io.recover_push,     io.push_valid),\n160:\
      \       Mux(io.recover_valid, io.recover_pop,      io.pop_valid),\n161:    \
      \   Mux(io.recover_valid, recover_alloc_new,   spec_alloc_new),\n162:      \
      \ Mux(io.recover_valid, io.recover_sp,       sp),\n163:       Mux(io.recover_valid,
      io.recover_sp - 1.U, topPtr),\n164:       Mux(io.recover_valid, io.recover_new_addr,
      io.spec_new_addr),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 182-192
    context: "182:     debugIO.recover_push_entry := RASEntry(io.recover_new_addr,
      Mux(recover_alloc_new, 1.U, io.recover_top.ctr + 1.U))\n183:     debugIO.recover_alloc_new
      := recover_alloc_new\n184:     debugIO.sp := sp\n185:     debugIO.topRegister
      := top\n186:     for (i <- 0 until RasSize) {\n187:         debugIO.out_mem(i)
      := Mux(i.U === write_bypass_ptr && write_bypass_valid, write_bypass_entry, stack.read(i.U))\n\
      188:     }\n189:   }\n190: \n191:   val spec = Module(new RASStack(RasSize))\n\
      192:   val spec_ras = spec.io"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 188-198
    context: "188:     }\n189:   }\n190: \n191:   val spec = Module(new RASStack(RasSize))\n\
      192:   val spec_ras = spec.io\n193:   val spec_top_addr = spec_ras.top.retAddr\n\
      194: \n195: \n196:   val s2_spec_push = WireInit(false.B)\n197:   val s2_spec_pop
      = WireInit(false.B)\n198:   val s2_full_pred = io.in.bits.resp_in(0).s2.full_pred"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 196-212
    context: "196:   val s2_spec_push = WireInit(false.B)\n197:   val s2_spec_pop
      = WireInit(false.B)\n198:   val s2_full_pred = io.in.bits.resp_in(0).s2.full_pred\n\
      199:   // when last inst is an rvi call, fall through address would be set to
      the middle of it, so an addition is needed\n200:   val s2_spec_new_addr = s2_full_pred(2).fallThroughAddr
      + Mux(s2_full_pred(2).last_may_be_rvi_call, 2.U, 0.U)\n201:   spec_ras.push_valid
      := s2_spec_push\n202:   spec_ras.pop_valid  := s2_spec_pop\n203:   spec_ras.spec_new_addr
      := s2_spec_new_addr\n204: \n205:   // confirm that the call/ret is the taken
      cfi\n206:   s2_spec_push := io.s2_fire(2) && s2_full_pred(2).hit_taken_on_call
      && !io.s3_redirect(2)\n207:   s2_spec_pop  := io.s2_fire(2) && s2_full_pred(2).hit_taken_on_ret\
      \  && !io.s3_redirect(2)\n208: \n209:   val s2_jalr_target_dup = io.out.s2.full_pred.map(_.jalr_target)\n\
      210:   val s2_last_target_in_dup = s2_full_pred.map(_.targets.last)\n211:  \
      \ val s2_last_target_out_dup = io.out.s2.full_pred.map(_.targets.last)\n212:\
      \   val s2_is_jalr_dup = s2_full_pred.map(_.is_jalr)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 238-248
    context: "238:   // assert(is_jalr && is_ret || !is_ret)\n239: \n240:   for (ras_enable
      & s3_is_ret & s3_jalr_target & s3_top <-\n241:     ras_enable_dup zip s3_is_ret_dup
      zip s3_jalr_target_dup zip s3_top_dup) {\n242:       when(s3_is_ret && ras_enable)
      {\n243:         s3_jalr_target := s3_top.retAddr\n244:         // FIXME: should
      use s1 globally\n245:       }\n246:     }\n247:   for (s3_lto & s3_is_jalr &
      s3_jalr_target & s3_lti <-\n248:     s3_last_target_out_dup zip s3_is_jalr_dup
      zip s3_jalr_target_dup zip s3_last_target_in_dup) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 257-286
    context: "257:   val s3_recover = io.s3_fire(2) && (s3_pushed_in_s2 =/= s3_push
      || s3_popped_in_s2 =/= s3_pop)\n258:   io.out.last_stage_spec_info.rasSp  :=
      s3_sp\n259:   io.out.last_stage_spec_info.rasTop := s3_top_dup(2)\n260: \n261:\
      \ \n262:   val redirect = RegNext(io.redirect)\n263:   val do_recover = redirect.valid
      || s3_recover\n264:   val recover_cfi = redirect.bits.cfiUpdate\n265: \n266:\
      \   val retMissPred  = do_recover && redirect.bits.level === 0.U && recover_cfi.pd.isRet\n\
      267:   val callMissPred = do_recover && redirect.bits.level === 0.U && recover_cfi.pd.isCall\n\
      268:   // when we mispredict a call, we must redo a push operation\n269:   //
      similarly, when we mispredict a return, we should redo a pop\n270:   spec_ras.recover_valid
      := do_recover\n271:   spec_ras.recover_push := Mux(redirect.valid, callMissPred,
      s3_push)\n272:   spec_ras.recover_pop  := Mux(redirect.valid, retMissPred, s3_pop)\n\
      273: \n274:   spec_ras.recover_sp  := Mux(redirect.valid, recover_cfi.rasSp,
      s3_sp)\n275:   spec_ras.recover_top := Mux(redirect.valid, recover_cfi.rasEntry,
      s3_top_dup(2))\n276:   spec_ras.recover_new_addr := Mux(redirect.valid, recover_cfi.pc
      + Mux(recover_cfi.pd.isRVC, 2.U, 4.U), s3_spec_new_addr)\n277: \n278: \n279:\
      \   XSPerfAccumulate(\"ras_s3_recover\", s3_recover)\n280:   XSPerfAccumulate(\"\
      ras_redirect_recover\", redirect.valid)\n281:   XSPerfAccumulate(\"ras_s3_and_redirect_recover_at_the_same_time\"\
      , s3_recover && redirect.valid)\n282:   // TODO: back-up stack for ras\n283:\
      \   // use checkpoint to recover RAS\n284: \n285:   val spec_debug = spec.debugIO\n\
      286:   XSDebug(\"----------------RAS----------------\\n\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 282-295
    context: "282:   // TODO: back-up stack for ras\n283:   // use checkpoint to recover
      RAS\n284: \n285:   val spec_debug = spec.debugIO\n286:   XSDebug(\"----------------RAS----------------\\\
      n\")\n287:   XSDebug(\" TopRegister: 0x%x   %d \\n\",spec_debug.topRegister.retAddr,spec_debug.topRegister.ctr)\n\
      288:   XSDebug(\"  index       addr           ctr \\n\")\n289:   for(i <- 0
      until RasSize){\n290:       XSDebug(\"  (%d)   0x%x      %d\",i.U,spec_debug.out_mem(i).retAddr,spec_debug.out_mem(i).ctr)\n\
      291:       when(i.U === spec_debug.sp){XSDebug(false,true.B,\"   <----sp\")}\n\
      292:       XSDebug(false,true.B,\"\\n\")\n293:   }\n294:   XSDebug(s2_spec_push,
      \"s2_spec_push  inAddr: 0x%x  inCtr: %d |  allocNewEntry:%d |   sp:%d \\n\"\
      ,\n295:   s2_spec_new_addr,spec_debug.spec_push_entry.ctr,spec_debug.spec_alloc_new,spec_debug.sp.asUInt)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 294-309
    context: "294:   XSDebug(s2_spec_push, \"s2_spec_push  inAddr: 0x%x  inCtr: %d
      |  allocNewEntry:%d |   sp:%d \\n\",\n295:   s2_spec_new_addr,spec_debug.spec_push_entry.ctr,spec_debug.spec_alloc_new,spec_debug.sp.asUInt)\n\
      296:   XSDebug(s2_spec_pop, \"s2_spec_pop  outAddr: 0x%x \\n\",io.out.s2.getTarget(2))\n\
      297:   val s3_recover_entry = spec_debug.recover_push_entry\n298:   XSDebug(s3_recover
      && s3_push, \"s3_recover_push  inAddr: 0x%x  inCtr: %d |  allocNewEntry:%d |\
      \   sp:%d \\n\",\n299:     s3_recover_entry.retAddr, s3_recover_entry.ctr, spec_debug.recover_alloc_new,
      s3_sp.asUInt)\n300:   XSDebug(s3_recover && s3_pop, \"s3_recover_pop  outAddr:
      0x%x \\n\",io.out.s3.getTarget(2))\n301:   val redirectUpdate = redirect.bits.cfiUpdate\n\
      302:   XSDebug(do_recover && callMissPred, \"redirect_recover_push\\n\")\n303:\
      \   XSDebug(do_recover && retMissPred, \"redirect_recover_pop\\n\")\n304:  \
      \ XSDebug(do_recover, \"redirect_recover(SP:%d retAddr:%x ctr:%d) \\n\",\n305:\
      \       redirectUpdate.rasSp,redirectUpdate.rasEntry.retAddr,redirectUpdate.rasEntry.ctr)\n\
      306: \n307:   generatePerfEvent()\n308: }\n309:  */"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheCtrlUnit.scala
    lines: 107-120
    context: "107:       def rsvd1: UInt = 1.U(width.W)\n108:       @unused\n109:\
      \       def rsvd3: UInt = 3.U(width.W)\n110:     }\n111:     private class eccctrlBundle
      extends Bundle {\n112:       val ierror:  UInt = eccctrlInjError()  // inject
      error code, read-only, valid only when istatus === error\n113:       val istatus:
      UInt = eccctrlInjStatus() // inject status, read-only\n114:       val itarget:
      UInt = eccctrlInjTarget() // inject target\n115:       val inject:  Bool = Bool()\
      \             // request to inject, write-only, read 0\n116:       val enable:\
      \  Bool = Bool()             // enable ECC\n117:     }\n118:     private object
      eccctrlBundle {\n119:       def default: eccctrlBundle = {\n120:         val
      x = Wire(new eccctrlBundle)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheCtrlUnit.scala
    lines: 117-127
    context: "117:     }\n118:     private object eccctrlBundle {\n119:       def
      default: eccctrlBundle = {\n120:         val x = Wire(new eccctrlBundle)\n121:\
      \         x.ierror  := eccctrlInjError.notEnabled\n122:         x.istatus :=
      eccctrlInjStatus.idle\n123:         x.itarget := eccctrlInjTarget.metaArray\n\
      124:         x.inject  := false.B\n125:         x.enable  := true.B\n126:  \
      \       x\n127:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheCtrlUnit.scala
    lines: 145-167
    context: "145:     require(params.regWidth >= eccctrl.asUInt.getWidth)\n146: \
      \    require(params.regWidth >= ecciaddr.asUInt.getWidth)\n147: \n148:     //
      control signal\n149:     io.ecc_enable := eccctrl.enable\n150:     io.injecting\
      \  := eccctrl.istatus === eccctrlInjStatus.working\n151: \n152:     // inject
      position\n153:     private val ivirIdx  = get_idx(ecciaddr.paddr)\n154:    \
      \ private val iphyTag  = get_tag(ecciaddr.paddr)\n155:     private val iwaymask
      = RegInit(0.U(nWays.W)) // read from metaArray, valid after istate === is_readMetaResp\n\
      156: \n157:     // inject FSM\n158:     private val is_idle :: is_readMetaReq
      :: is_readMetaResp :: is_writeMeta :: is_writeData :: Nil =\n159:       Enum(5)\n\
      160:     private val istate = RegInit(is_idle)\n161: \n162:     io.metaRead.valid\
      \             := istate === is_readMetaReq\n163:     io.metaRead.bits.isDoubleLine
      := false.B // we inject into first cacheline and ignore the rest port\n164:\
      \     io.metaRead.bits.vSetIdx      := VecInit(Seq.fill(PortNumber)(ivirIdx))\n\
      165:     io.metaRead.bits.waymask   := VecInit(Seq.fill(PortNumber)(VecInit(Seq.fill(nWays)(false.B))))
      // dontcare\n166:     io.metaRead.bits.blkOffset := 0.U(blockBits.W)       \
      \                                          // dontcare\n167: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheCtrlUnit.scala
    lines: 163-173
    context: "163:     io.metaRead.bits.isDoubleLine := false.B // we inject into
      first cacheline and ignore the rest port\n164:     io.metaRead.bits.vSetIdx\
      \      := VecInit(Seq.fill(PortNumber)(ivirIdx))\n165:     io.metaRead.bits.waymask\
      \   := VecInit(Seq.fill(PortNumber)(VecInit(Seq.fill(nWays)(false.B)))) // dontcare\n\
      166:     io.metaRead.bits.blkOffset := 0.U(blockBits.W)                    \
      \                             // dontcare\n167: \n168:     io.metaWrite.valid
      := istate === is_writeMeta\n169:     io.metaWrite.bits.generate(\n170:     \
      \  tag = iphyTag,\n171:       idx = ivirIdx,\n172:       waymask = iwaymask,\n\
      173:       bankIdx = ivirIdx(0),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheCtrlUnit.scala
    lines: 172-182
    context: "172:       waymask = iwaymask,\n173:       bankIdx = ivirIdx(0),\n174:\
      \       poison = true.B\n175:     )\n176: \n177:     io.dataWrite.valid := istate
      === is_writeData\n178:     io.dataWrite.bits.generate(\n179:       data = 0.U,
      // inject poisoned data, don't care actual data\n180:       idx = ivirIdx,\n\
      181:       waymask = iwaymask,\n182:       bankIdx = ivirIdx(0),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheCtrlUnit.scala
    lines: 181-200
    context: "181:       waymask = iwaymask,\n182:       bankIdx = ivirIdx(0),\n183:\
      \       poison = true.B\n184:     )\n185: \n186:     switch(istate) {\n187:\
      \       is(is_idle) {\n188:         when(eccctrl.istatus === eccctrlInjStatus.working)
      {\n189:           // we need to read meta first to get waymask, whether itarget
      is metaArray or dataArray\n190:           istate := is_readMetaReq\n191:   \
      \      }\n192:       }\n193:       is(is_readMetaReq) {\n194:         when(io.metaRead.fire)
      {\n195:           istate := is_readMetaResp\n196:         }\n197:       }\n\
      198:       is(is_readMetaResp) {\n199:         // metaArray ensures resp is
      valid one cycle after req\n200:         val waymask = VecInit((0 until nWays).map
      { w =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheCtrlUnit.scala
    lines: 196-227
    context: "196:         }\n197:       }\n198:       is(is_readMetaResp) {\n199:\
      \         // metaArray ensures resp is valid one cycle after req\n200:     \
      \    val waymask = VecInit((0 until nWays).map { w =>\n201:           io.metaReadResp.entryValid.head(w)
      && io.metaReadResp.tags.head(w) === iphyTag\n202:         }).asUInt\n203:  \
      \       iwaymask := waymask\n204:         when(!waymask.orR) {\n205:       \
      \    // not hit, refuse to inject\n206:           istate          := is_idle\n\
      207:           eccctrl.istatus := eccctrlInjStatus.error\n208:           eccctrl.ierror\
      \  := eccctrlInjError.notFound\n209:         }.otherwise {\n210:           istate
      := Mux(eccctrl.itarget === eccctrlInjTarget.metaArray, is_writeMeta, is_writeData)\n\
      211:         }\n212:       }\n213:       is(is_writeMeta) {\n214:         when(io.metaWrite.fire)
      {\n215:           istate          := is_idle\n216:           eccctrl.istatus
      := eccctrlInjStatus.injected\n217:         }\n218:       }\n219:       is(is_writeData)
      {\n220:         when(io.dataWrite.fire) {\n221:           istate          :=
      is_idle\n222:           eccctrl.istatus := eccctrlInjStatus.injected\n223: \
      \        }\n224:       }\n225:     }\n226: \n227:     private def eccctrlRegDesc:
      RegFieldDesc ="
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheCtrlUnit.scala
    lines: 243-259
    context: "243:       )\n244: \n245:     private def eccctrlRegField(x: eccctrlBundle):
      RegField =\n246:       RegField(\n247:         params.regWidth,\n248:      \
      \   RegReadFn { ready =>\n249:           val res = WireInit(x)\n250:       \
      \    res.inject := false.B // read always 0\n251:           when(ready) {\n\
      252:             // if istatus is injected or error, clear it after read\n253:\
      \             when(x.istatus === eccctrlInjStatus.injected || x.istatus ===
      eccctrlInjStatus.error) {\n254:               x.istatus := eccctrlInjStatus.idle\n\
      255:               x.ierror  := eccctrlInjError.notEnabled\n256:           \
      \  }\n257:           }\n258:           // always read valid\n259:          \
      \ (true.B, res.asUInt)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheCtrlUnit.scala
    lines: 260-281
    context: "260:         },\n261:         RegWriteFn { (valid, data) =>\n262:  \
      \         when(valid) {\n263:             val req = data.asTypeOf(new eccctrlBundle)\n\
      264:             x.enable := req.enable\n265:             when(req.inject &&
      x.istatus === eccctrlInjStatus.idle) {\n266:               // if istatus is
      not idle, ignore the inject request\n267:               when(req.enable ===
      false.B) {\n268:                 // check if enable is not valid\n269:     \
      \            x.istatus := eccctrlInjStatus.error\n270:                 x.ierror\
      \  := eccctrlInjError.notEnabled\n271:               }.elsewhen(req.itarget
      =/= eccctrlInjTarget.metaArray && req.itarget =/= eccctrlInjTarget.dataArray)
      {\n272:                 // check if itarget is not valid\n273:             \
      \    x.istatus := eccctrlInjStatus.error\n274:                 x.ierror  :=
      eccctrlInjError.targetInvalid\n275:               }.otherwise {\n276:      \
      \           x.istatus := eccctrlInjStatus.working\n277:               }\n278:\
      \             }\n279:             x.itarget := req.itarget\n280:           \
      \  // istatus is read-only, ignore req.istatus\n281:             // ierror is
      read-only, ignore req.ierror"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/FIFO.scala
    lines: 19-32
    context: "19: \n20: import chisel3._\n21: import chisel3.util._\n22: import utility._\n\
      23: \n24: class FIFORegIO[T <: Data](gen: T, hasFlush: Boolean = false) extends
      Bundle {\n25:   val enq:   DecoupledIO[T] = Flipped(DecoupledIO(gen))\n26: \
      \  val deq:   DecoupledIO[T] = DecoupledIO(gen)\n27:   val flush: Option[Bool]\
      \   = Option.when(hasFlush)(Input(Bool()))\n28: }\n29: \n30: class FIFOReg[T
      <: Data](\n31:     val gen:      T,\n32:     val entries:  Int,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/FIFO.scala
    lines: 29-44
    context: "29: \n30: class FIFOReg[T <: Data](\n31:     val gen:      T,\n32: \
      \    val entries:  Int,\n33:     val pipe:     Boolean = false,\n34:     val
      hasFlush: Boolean = false\n35: ) extends Module() {\n36:   require(entries >
      0, \"Queue must have non-negative number of entries\")\n37: \n38:   val io:
      FIFORegIO[T] = IO(new FIFORegIO(gen, hasFlush))\n39:   private val flush = io.flush.getOrElse(false.B)\n\
      40: \n41:   private class FIFOPtr extends CircularQueuePtr[FIFOPtr](entries)\n\
      42:   private object FIFOPtr {\n43:     def apply(f: Bool, v: UInt): FIFOPtr
      = {\n44:       val ptr = Wire(new FIFOPtr)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/FIFO.scala
    lines: 53-69
    context: "53:   private val deq_ptr  = RegInit(FIFOPtr(false.B, 0.U))\n54: \n\
      55:   private val empty = enq_ptr === deq_ptr\n56:   private val full  = (enq_ptr.value
      === deq_ptr.value) && (enq_ptr.flag ^ deq_ptr.flag)\n57: \n58:   when(io.enq.fire)
      {\n59:     enq_ptr := enq_ptr + 1.U\n60:   }\n61:   when(io.deq.fire) {\n62:\
      \     deq_ptr := deq_ptr + 1.U\n63:   }\n64:   when(flush) {\n65:     enq_ptr.value
      := 0.U\n66:     enq_ptr.flag  := false.B\n67:     deq_ptr.value := 0.U\n68:\
      \     deq_ptr.flag  := false.B\n69:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/FIFO.scala
    lines: 66-76
    context: "66:     enq_ptr.flag  := false.B\n67:     deq_ptr.value := 0.U\n68:\
      \     deq_ptr.flag  := false.B\n69:   }\n70: \n71:   when(io.enq.fire) {\n72:\
      \     regFiles(enq_ptr.value) := io.enq.bits\n73:   }\n74:   io.deq.bits :=
      regFiles(deq_ptr.value)\n75: \n76:   io.deq.valid := !empty"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/FIFO.scala
    lines: 72-81
    context: "72:     regFiles(enq_ptr.value) := io.enq.bits\n73:   }\n74:   io.deq.bits
      := regFiles(deq_ptr.value)\n75: \n76:   io.deq.valid := !empty\n77:   io.enq.ready
      := !full\n78:   if (pipe) {\n79:     when(io.deq.ready)(io.enq.ready := true.B)\n\
      80:   }\n81: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 55-69
    context: "55: \n56: class IPrefetchIO(implicit p: Parameters) extends IPrefetchBundle
      {\n57:   // control\n58:   val csr_pf_enable: Bool = Input(Bool())\n59:   val
      ecc_enable:    Bool = Input(Bool())\n60:   val flush:         Bool = Input(Bool())\n\
      61: \n62:   val req:            DecoupledIO[IPrefetchReq]  = Flipped(Decoupled(new
      IPrefetchReq))\n63:   val flushFromBpu:   BpuFlushInfo               = Flipped(new
      BpuFlushInfo)\n64:   val itlb:           Vec[TlbRequestIO]          = Vec(PortNumber,
      new TlbRequestIO)\n65:   val itlbFlushPipe:  Bool                       = Bool()\n\
      66:   val pmp:            Vec[ICachePMPBundle]       = Vec(PortNumber, new ICachePMPBundle)\n\
      67:   val metaRead:       ICacheMetaReqBundle        = new ICacheMetaReqBundle\n\
      68:   val MSHRReq:        DecoupledIO[ICacheMissReq] = DecoupledIO(new ICacheMissReq)\n\
      69:   val MSHRResp:       Valid[ICacheMissResp]      = Flipped(ValidIO(new ICacheMissResp))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 71-81
    context: "71: }\n72: \n73: class IPrefetchPipe(implicit p: Parameters) extends
      IPrefetchModule with HasICacheECCHelper {\n74:   val io: IPrefetchIO = IO(new
      IPrefetchIO)\n75: \n76:   private val (toITLB, fromITLB) = (io.itlb.map(_.req),
      io.itlb.map(_.resp))\n77:   private val (toPMP, fromPMP)   = (io.pmp.map(_.req),
      io.pmp.map(_.resp))\n78:   private val (toMeta, fromMeta) = (io.metaRead.toIMeta,
      io.metaRead.fromIMeta)\n79:   private val (toMSHR, fromMSHR) = (io.MSHRReq,
      io.MSHRResp)\n80:   private val toWayLookup        = io.wayLookupWrite\n81: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 78-90
    context: "78:   private val (toMeta, fromMeta) = (io.metaRead.toIMeta, io.metaRead.fromIMeta)\n\
      79:   private val (toMSHR, fromMSHR) = (io.MSHRReq, io.MSHRResp)\n80:   private
      val toWayLookup        = io.wayLookupWrite\n81: \n82:   private val s0_fire,
      s1_fire, s2_fire            = WireInit(false.B)\n83:   private val s1_ready,
      s2_ready                   = WireInit(false.B)\n84:   private val s0_flush,
      s1_flush, s2_flush         = WireInit(false.B)\n85:   private val from_bpu_s0_flush,
      from_bpu_s1_flush = WireInit(false.B)\n86: \n87:   /**\n88:     ******************************************************************************\n\
      89:     * IPrefetch Stage 0\n90:     * - 1. receive ftq req"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 90-100
    context: "90:     * - 1. receive ftq req\n91:     * - 2. send req to ITLB\n92:\
      \     * - 3. send req to Meta SRAM\n93:     ******************************************************************************\n\
      94:     */\n95:   private val s0_valid = io.req.valid\n96: \n97:   /**\n98:\
      \     ******************************************************************************\n\
      99:     * receive ftq req\n100:     ******************************************************************************"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 98-108
    context: "98:     ******************************************************************************\n\
      99:     * receive ftq req\n100:     ******************************************************************************\n\
      101:     */\n102:   private val s0_req_vaddr        = VecInit(Seq(io.req.bits.startAddr,
      io.req.bits.nextlineStart))\n103:   private val s0_req_ftqIdx       = io.req.bits.ftqIdx\n\
      104:   private val s0_isSoftPrefetch   = io.req.bits.isSoftPrefetch\n105:  \
      \ private val s0_doubleline       = io.req.bits.crossCacheline\n106:   private
      val s0_req_vSetIdx      = s0_req_vaddr.map(get_idx)\n107:   private val s0_backendException
      = VecInit(Seq.fill(PortNumber)(io.req.bits.backendException))\n108: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 104-121
    context: "104:   private val s0_isSoftPrefetch   = io.req.bits.isSoftPrefetch\n\
      105:   private val s0_doubleline       = io.req.bits.crossCacheline\n106:  \
      \ private val s0_req_vSetIdx      = s0_req_vaddr.map(get_idx)\n107:   private
      val s0_backendException = VecInit(Seq.fill(PortNumber)(io.req.bits.backendException))\n\
      108: \n109:   from_bpu_s0_flush := !s0_isSoftPrefetch && (io.flushFromBpu.shouldFlushByStage2(s0_req_ftqIdx)
      ||\n110:     io.flushFromBpu.shouldFlushByStage3(s0_req_ftqIdx))\n111:   s0_flush
      := io.flush || from_bpu_s0_flush || s1_flush\n112: \n113:   private val s0_can_go
      = s1_ready && toITLB(0).ready && toITLB(1).ready && toMeta.ready\n114:   io.req.ready
      := s0_can_go\n115: \n116:   s0_fire := s0_valid && s0_can_go && !s0_flush\n\
      117: \n118:   /**\n119:     ******************************************************************************\n\
      120:     * IPrefetch Stage 1\n121:     * - 1. Receive resp from ITLB"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 122-138
    context: "122:     * - 2. Receive resp from IMeta and check\n123:     * - 3. Monitor
      the requests from missUnit to write to SRAM.\n124:     * - 4. Write wayLookup\n\
      125:     ******************************************************************************\n\
      126:     */\n127:   private val s1_valid =\n128:     generatePipeControl(lastFire
      = s0_fire, thisFire = s1_fire, thisFlush = s1_flush, lastFlush = false.B)\n\
      129: \n130:   private val s1_req_vaddr        = RegEnable(s0_req_vaddr, 0.U.asTypeOf(s0_req_vaddr),
      s0_fire)\n131:   private val s1_isSoftPrefetch   = RegEnable(s0_isSoftPrefetch,
      0.U.asTypeOf(s0_isSoftPrefetch), s0_fire)\n132:   private val s1_doubleline\
      \       = RegEnable(s0_doubleline, 0.U.asTypeOf(s0_doubleline), s0_fire)\n133:\
      \   private val s1_req_ftqIdx       = RegEnable(s0_req_ftqIdx, 0.U.asTypeOf(s0_req_ftqIdx),
      s0_fire)\n134:   private val s1_req_vSetIdx      = VecInit(s1_req_vaddr.map(get_idx))\n\
      135:   private val s1_backendException = RegEnable(s0_backendException, 0.U.asTypeOf(s0_backendException),
      s0_fire)\n136: \n137:   private val m_idle :: m_itlbResend :: m_metaResend ::
      m_enqWay :: m_enterS2 :: Nil = Enum(5)\n138: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 134-149
    context: "134:   private val s1_req_vSetIdx      = VecInit(s1_req_vaddr.map(get_idx))\n\
      135:   private val s1_backendException = RegEnable(s0_backendException, 0.U.asTypeOf(s0_backendException),
      s0_fire)\n136: \n137:   private val m_idle :: m_itlbResend :: m_metaResend ::
      m_enqWay :: m_enterS2 :: Nil = Enum(5)\n138: \n139:   private val state    \
      \  = RegInit(m_idle)\n140:   private val next_state = WireDefault(state)\n141:\
      \   private val s0_fire_r  = RegNext(s0_fire)\n142:   dontTouch(state)\n143:\
      \   dontTouch(next_state)\n144:   state := next_state\n145: \n146:   /**\n147:\
      \     ******************************************************************************\n\
      148:     * resend itlb req if miss\n149:     ******************************************************************************"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 147-158
    context: "147:     ******************************************************************************\n\
      148:     * resend itlb req if miss\n149:     ******************************************************************************\n\
      150:     */\n151:   private val s1_wait_itlb = RegInit(VecInit(Seq.fill(PortNumber)(false.B)))\n\
      152:   (0 until PortNumber).foreach { i =>\n153:     when(s1_flush) {\n154:\
      \       s1_wait_itlb(i) := false.B\n155:     }.elsewhen(RegNext(s0_fire) &&
      fromITLB(i).bits.miss) {\n156:       s1_wait_itlb(i) := true.B\n157:     }.elsewhen(s1_wait_itlb(i)
      && !fromITLB(i).bits.miss) {\n158:       s1_wait_itlb(i) := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 165-179
    context: "165:   private val tlb_valid_pulse = VecInit(Seq(\n166:     (RegNext(s0_fire)
      || s1_wait_itlb(0)) && !fromITLB(0).bits.miss,\n167:     (RegNext(s0_fire) ||
      s1_wait_itlb(1)) && !fromITLB(1).bits.miss && s1_doubleline\n168:   ))\n169:\
      \   private val tlb_valid_latch =\n170:     VecInit((0 until PortNumber).map(i
      => ValidHoldBypass(tlb_valid_pulse(i), s1_fire, flush = s1_flush)))\n171:  \
      \ private val itlb_finish = tlb_valid_latch(0) && (!s1_doubleline || tlb_valid_latch(1))\n\
      172: \n173:   (0 until PortNumber).foreach { i =>\n174:     toITLB(i).valid\
      \             := s1_need_itlb(i) || (s0_valid && (if (i == 0) true.B else s0_doubleline))\n\
      175:     toITLB(i).bits              := DontCare\n176:     toITLB(i).bits.size\
      \         := 3.U\n177:     toITLB(i).bits.vaddr        := Mux(s1_need_itlb(i),
      s1_req_vaddr(i), s0_req_vaddr(i))\n178:     toITLB(i).bits.debug.pc     := Mux(s1_need_itlb(i),
      s1_req_vaddr(i), s0_req_vaddr(i))\n179:     toITLB(i).bits.cmd          := TlbCmd.exec"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 177-188
    context: "177:     toITLB(i).bits.vaddr        := Mux(s1_need_itlb(i), s1_req_vaddr(i),
      s0_req_vaddr(i))\n178:     toITLB(i).bits.debug.pc     := Mux(s1_need_itlb(i),
      s1_req_vaddr(i), s0_req_vaddr(i))\n179:     toITLB(i).bits.cmd          := TlbCmd.exec\n\
      180:     toITLB(i).bits.no_translate := false.B\n181:   }\n182:   fromITLB.foreach(_.ready
      := true.B)\n183:   io.itlb.foreach(_.req_kill := false.B)\n184: \n185:   /**\n\
      186:     ******************************************************************************\n\
      187:     * Receive resp from ITLB\n188:     ******************************************************************************"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 214-228
    context: "214:       valid = tlb_valid_pulse(i),\n215:       init = 0.U(ExceptionType.width.W),\n\
      216:       data = ExceptionType.fromTlbResp(fromITLB(i).bits)\n217:     )\n\
      218:   })\n219:   private val s1_itlb_pbmt = VecInit((0 until PortNumber).map
      { i =>\n220:     ResultHoldBypass(\n221:       valid = tlb_valid_pulse(i),\n\
      222:       init = 0.U.asTypeOf(fromITLB(i).bits.pbmt(0)),\n223:       data =
      fromITLB(i).bits.pbmt(0)\n224:     )\n225:   })\n226: \n227:   // merge backend
      exception and itlb exception\n228:   // for area concern, we don't have 64 bits
      vaddr in frontend, but spec asks page fault when high bits are not all 0/1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 256-271
    context: "256:   /**\n257:     ******************************************************************************\n\
      258:     * resend metaArray read req when itlb miss finish\n259:     ******************************************************************************\n\
      260:     */\n261:   private val s1_need_meta = ((state === m_itlbResend) &&
      itlb_finish) || (state === m_metaResend)\n262:   toMeta.valid             :=
      s1_need_meta || s0_valid\n263:   toMeta.bits              := DontCare\n264:\
      \   toMeta.bits.isDoubleLine := Mux(s1_need_meta, s1_doubleline, s0_doubleline)\n\
      265: \n266:   (0 until PortNumber).foreach { i =>\n267:     toMeta.bits.vSetIdx(i)
      := Mux(s1_need_meta, s1_req_vSetIdx(i), s0_req_vSetIdx(i))\n268:   }\n269: \n\
      270:   /**\n271:     ******************************************************************************"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 273-283
    context: "273:     ******************************************************************************\n\
      274:     */\n275:   private val s1_req_ptags = VecInit(s1_req_paddr.map(get_phy_tag))\n\
      276: \n277:   private val s1_meta_ptags  = fromMeta.tags\n278:   private val
      s1_meta_valids = fromMeta.entryValid\n279: \n280:   private def getWaymask(paddrs:
      Vec[UInt]): Vec[UInt] = {\n281:     val ptags = paddrs.map(get_phy_tag)\n282:\
      \     val tag_eq_vec =\n283:       VecInit((0 until PortNumber).map(p => VecInit((0
      until nWays).map(w => s1_meta_ptags(p)(w) === ptags(p)))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 280-290
    context: "280:   private def getWaymask(paddrs: Vec[UInt]): Vec[UInt] = {\n281:\
      \     val ptags = paddrs.map(get_phy_tag)\n282:     val tag_eq_vec =\n283: \
      \      VecInit((0 until PortNumber).map(p => VecInit((0 until nWays).map(w =>
      s1_meta_ptags(p)(w) === ptags(p)))))\n284:     val tag_match_vec = VecInit((0
      until PortNumber).map { k =>\n285:       VecInit(tag_eq_vec(k).zipWithIndex.map
      { case (way_tag_eq, w) => way_tag_eq && s1_meta_valids(k)(w) })\n286:     })\n\
      287:     val waymasks = VecInit(tag_match_vec.map(_.asUInt))\n288:     waymasks\n\
      289:   }\n290: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 334-344
    context: "334:       }\n335:     }\n336:     (new_mask, new_code)\n337:   }\n\
      338: \n339:   private val s1_SRAM_valid   = s0_fire_r || RegNext(s1_need_meta
      && toMeta.ready)\n340:   private val s1_MSHR_valid   = fromMSHR.valid && !fromMSHR.bits.corrupt\n\
      341:   private val s1_waymasks     = WireInit(VecInit(Seq.fill(PortNumber)(0.U(nWays.W))))\n\
      342:   private val s1_waymasks_r   = RegEnable(s1_waymasks, 0.U.asTypeOf(s1_waymasks),
      s1_SRAM_valid || s1_MSHR_valid)\n343:   private val s1_meta_codes   = WireInit(VecInit(Seq.fill(PortNumber)(0.U(ICacheMetaCodeBits.W))))\n\
      344:   private val s1_meta_codes_r = RegEnable(s1_meta_codes, 0.U.asTypeOf(s1_meta_codes),
      s1_SRAM_valid || s1_MSHR_valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 342-352
    context: "342:   private val s1_waymasks_r   = RegEnable(s1_waymasks, 0.U.asTypeOf(s1_waymasks),
      s1_SRAM_valid || s1_MSHR_valid)\n343:   private val s1_meta_codes   = WireInit(VecInit(Seq.fill(PortNumber)(0.U(ICacheMetaCodeBits.W))))\n\
      344:   private val s1_meta_codes_r = RegEnable(s1_meta_codes, 0.U.asTypeOf(s1_meta_codes),
      s1_SRAM_valid || s1_MSHR_valid)\n345: \n346:   // update waymasks and meta_codes\n\
      347:   (0 until PortNumber).foreach { i =>\n348:     val old_waymask    = Mux(s1_SRAM_valid,
      s1_SRAM_waymasks(i), s1_waymasks_r(i))\n349:     val old_meta_codes = Mux(s1_SRAM_valid,
      s1_SRAM_meta_codes(i), s1_meta_codes_r(i))\n350:     val new_info       = updateMetaInfo(old_waymask,
      s1_req_vSetIdx(i), s1_req_ptags(i), old_meta_codes)\n351:     s1_waymasks(i)\
      \   := new_info._1\n352:     s1_meta_codes(i) := new_info._2"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 356-367
    context: "356:     ******************************************************************************\n\
      357:     * send enqueue req to WayLookup\n358:     ******** **********************************************************************\n\
      359:     */\n360:   // Disallow enqueuing wayLookup when SRAM write occurs.\n\
      361:   toWayLookup.valid := ((state === m_enqWay) || ((state === m_idle) &&
      itlb_finish)) &&\n362:     !s1_flush && !fromMSHR.valid && !s1_isSoftPrefetch
      // do not enqueue soft prefetch\n363:   toWayLookup.bits.vSetIdx           :=
      s1_req_vSetIdx\n364:   toWayLookup.bits.waymask           := s1_waymasks\n365:\
      \   toWayLookup.bits.ptag              := s1_req_ptags\n366:   toWayLookup.bits.gpaddr\
      \            := s1_req_gpaddr\n367:   toWayLookup.bits.isForVSnonLeafPTE :=
      s1_req_isForVSnonLeafPTE"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 364-374
    context: "364:   toWayLookup.bits.waymask           := s1_waymasks\n365:   toWayLookup.bits.ptag\
      \              := s1_req_ptags\n366:   toWayLookup.bits.gpaddr            :=
      s1_req_gpaddr\n367:   toWayLookup.bits.isForVSnonLeafPTE := s1_req_isForVSnonLeafPTE\n\
      368:   toWayLookup.bits.meta_codes        := s1_meta_codes\n369:   (0 until
      PortNumber).foreach { i =>\n370:     // exception in first line is always valid,
      in second line is valid iff is doubleline request\n371:     val excpValid =
      if (i == 0) true.B else s1_doubleline\n372:     // Send s1_itlb_exception to
      WayLookup (instead of s1_exception_out) for better timing.\n373:     // Will
      check pmp again in mainPipe\n374:     toWayLookup.bits.itlb_exception(i) :=
      Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 374-388
    context: "374:     toWayLookup.bits.itlb_exception(i) := Mux(\n375:       excpValid,\n\
      376:       s1_itlb_exception(i), // includes backend exception\n377:       ExceptionType.none\n\
      378:     )\n379:     toWayLookup.bits.itlb_pbmt(i) := Mux(excpValid, s1_itlb_pbmt(i),
      Pbmt.pma)\n380:   }\n381: \n382:   private val s1_waymasks_vec = s1_waymasks.map(_.asTypeOf(Vec(nWays,
      Bool())))\n383:   when(toWayLookup.fire) {\n384:     assert(\n385:       PopCount(s1_waymasks_vec(0))
      <= 1.U && (PopCount(s1_waymasks_vec(1)) <= 1.U || !s1_doubleline),\n386:   \
      \    \"Multi-hit:\\nport0: count=%d ptag=0x%x vSet=0x%x vaddr=0x%x\\nport1:
      count=%d ptag=0x%x vSet=0x%x vaddr=0x%x\",\n387:       PopCount(s1_waymasks_vec(0))
      > 1.U,\n388:       s1_req_ptags(0),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 398-410
    context: "398:   /**\n399:     ******************************************************************************\n\
      400:     * PMP check\n401:     ******************************************************************************\n\
      402:     */\n403:   toPMP.zipWithIndex.foreach { case (p, i) =>\n404:     //
      if itlb has exception, paddr can be invalid, therefore pmp check can be skipped\n\
      405:     p.valid     := s1_valid // !ExceptionType.hasException(s1_itlb_exception(i))\n\
      406:     p.bits.addr := s1_req_paddr(i)\n407:     p.bits.size := 3.U\n408: \
      \    p.bits.cmd  := TlbCmd.exec\n409:   }\n410:   private val s1_pmp_exception
      = VecInit(fromPMP.map(ExceptionType.fromPMPResp))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 406-416
    context: "406:     p.bits.addr := s1_req_paddr(i)\n407:     p.bits.size := 3.U\n\
      408:     p.bits.cmd  := TlbCmd.exec\n409:   }\n410:   private val s1_pmp_exception
      = VecInit(fromPMP.map(ExceptionType.fromPMPResp))\n411:   private val s1_pmp_mmio\
      \      = VecInit(fromPMP.map(_.mmio))\n412: \n413:   // merge s1 itlb/pmp exceptions,
      itlb has the highest priority, pmp next\n414:   // for timing consideration,
      meta_corrupt is not merged, and it will NOT cancel prefetch\n415:   private
      val s1_exception_out = ExceptionType.merge(\n416:     s1_itlb_exception, //
      includes backend exception"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 416-427
    context: "416:     s1_itlb_exception, // includes backend exception\n417:    \
      \ s1_pmp_exception\n418:   )\n419: \n420:   // merge pmp mmio and itlb pbmt\n\
      421:   private val s1_mmio = VecInit((s1_pmp_mmio zip s1_itlb_pbmt).map { case
      (mmio, pbmt) =>\n422:     mmio || Pbmt.isUncache(pbmt)\n423:   })\n424: \n425:\
      \   /**\n426:     ******************************************************************************\n\
      427:     * state machine"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 426-452
    context: "426:     ******************************************************************************\n\
      427:     * state machine\n428:     ******** **********************************************************************\n\
      429:     */\n430: \n431:   switch(state) {\n432:     is(m_idle) {\n433:    \
      \   when(s1_valid) {\n434:         when(!itlb_finish) {\n435:           next_state
      := m_itlbResend\n436:         }.elsewhen(!toWayLookup.fire) { // itlb_finish\n\
      437:           next_state := m_enqWay\n438:         }.elsewhen(!s2_ready) {
      // itlb_finish && toWayLookup.fire\n439:           next_state := m_enterS2\n\
      440:         } // .otherwise { next_state := m_idle }\n441:       }   // .otherwise
      { next_state := m_idle }  // !s1_valid\n442:     }\n443:     is(m_itlbResend)
      {\n444:       when(itlb_finish) {\n445:         when(!toMeta.ready) {\n446:\
      \           next_state := m_metaResend\n447:         }.otherwise { // toMeta.ready\n\
      448:           next_state := m_enqWay\n449:         }\n450:       } // .otherwise
      { next_state := m_itlbResend }  // !itlb_finish\n451:     }\n452:     is(m_metaResend)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 448-466
    context: "448:           next_state := m_enqWay\n449:         }\n450:       }
      // .otherwise { next_state := m_itlbResend }  // !itlb_finish\n451:     }\n\
      452:     is(m_metaResend) {\n453:       when(toMeta.ready) {\n454:         next_state
      := m_enqWay\n455:       } // .otherwise { next_state := m_metaResend }  // !toMeta.ready\n\
      456:     }\n457:     is(m_enqWay) {\n458:       when(toWayLookup.fire || s1_isSoftPrefetch)
      {\n459:         when(!s2_ready) {\n460:           next_state := m_enterS2\n\
      461:         }.otherwise { // s2_ready\n462:           next_state := m_idle\n\
      463:         }\n464:       } // .otherwise { next_state := m_enqWay }\n465:\
      \     }\n466:     is(m_enterS2) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 462-472
    context: "462:           next_state := m_idle\n463:         }\n464:       } //
      .otherwise { next_state := m_enqWay }\n465:     }\n466:     is(m_enterS2) {\n\
      467:       when(s2_ready) {\n468:         next_state := m_idle\n469:       }\n\
      470:     }\n471:   }\n472: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 468-490
    context: "468:         next_state := m_idle\n469:       }\n470:     }\n471:  \
      \ }\n472: \n473:   when(s1_flush) {\n474:     next_state := m_idle\n475:   }\n\
      476: \n477:   /** Stage 1 control */\n478:   from_bpu_s1_flush := s1_valid &&
      !s1_isSoftPrefetch && io.flushFromBpu.shouldFlushByStage3(s1_req_ftqIdx)\n479:\
      \   s1_flush          := io.flush || from_bpu_s1_flush\n480:   // when s1 is
      flushed, itlb pipeline should also be flushed\n481:   io.itlbFlushPipe := s1_flush\n\
      482: \n483:   s1_ready := next_state === m_idle\n484:   s1_fire  := (next_state
      === m_idle) && s1_valid && !s1_flush // used to clear s1_valid & itlb_valid_latch\n\
      485:   private val s1_real_fire = s1_fire && io.csr_pf_enable // real \"s1 fire\"\
      \ that s1 enters s2\n486: \n487:   /**\n488:     ******************************************************************************\n\
      489:     * IPrefetch Stage 2\n490:     * - 1. Monitor the requests from missUnit
      to write to SRAM."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 489-500
    context: "489:     * IPrefetch Stage 2\n490:     * - 1. Monitor the requests from
      missUnit to write to SRAM.\n491:     * - 2. send req to missUnit\n492:     ******************************************************************************\n\
      493:     */\n494:   private val s2_valid =\n495:     generatePipeControl(lastFire
      = s1_real_fire, thisFire = s2_fire, thisFlush = s2_flush, lastFlush = false.B)\n\
      496: \n497:   private val s2_req_vaddr      = RegEnable(s1_req_vaddr, 0.U.asTypeOf(s1_req_vaddr),
      s1_real_fire)\n498:   private val s2_isSoftPrefetch = RegEnable(s1_isSoftPrefetch,
      0.U.asTypeOf(s1_isSoftPrefetch), s1_real_fire)\n499:   private val s2_doubleline\
      \     = RegEnable(s1_doubleline, 0.U.asTypeOf(s1_doubleline), s1_real_fire)\n\
      500:   private val s2_req_paddr      = RegEnable(s1_req_paddr, 0.U.asTypeOf(s1_req_paddr),
      s1_real_fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 497-511
    context: "497:   private val s2_req_vaddr      = RegEnable(s1_req_vaddr, 0.U.asTypeOf(s1_req_vaddr),
      s1_real_fire)\n498:   private val s2_isSoftPrefetch = RegEnable(s1_isSoftPrefetch,
      0.U.asTypeOf(s1_isSoftPrefetch), s1_real_fire)\n499:   private val s2_doubleline\
      \     = RegEnable(s1_doubleline, 0.U.asTypeOf(s1_doubleline), s1_real_fire)\n\
      500:   private val s2_req_paddr      = RegEnable(s1_req_paddr, 0.U.asTypeOf(s1_req_paddr),
      s1_real_fire)\n501:   private val s2_exception =\n502:     RegEnable(s1_exception_out,
      0.U.asTypeOf(s1_exception_out), s1_real_fire) // includes itlb/pmp exception\n\
      503:   // disabled for timing consideration\n504: // private val s2_exception_in
      =\n505: //   RegEnable(s1_exception_out, 0.U.asTypeOf(s1_exception_out), s1_real_fire)\n\
      506:   private val s2_mmio     = RegEnable(s1_mmio, 0.U.asTypeOf(s1_mmio), s1_real_fire)\n\
      507:   private val s2_waymasks = RegEnable(s1_waymasks, 0.U.asTypeOf(s1_waymasks),
      s1_real_fire)\n508:   // disabled for timing consideration\n509: // private
      val s2_meta_codes   = RegEnable(s1_meta_codes, 0.U.asTypeOf(s1_meta_codes),
      s1_real_fire)\n510: \n511:   private val s2_req_vSetIdx = s2_req_vaddr.map(get_idx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 537-549
    context: "537:    *   in which we should set s2_MSHR_hits to true.B, and send
      error to ifu.\n538:    */\n539:   private val s2_MSHR_match = VecInit((0 until
      PortNumber).map { i =>\n540:     (s2_req_vSetIdx(i) === fromMSHR.bits.vSetIdx)
      &&\n541:     (s2_req_ptags(i) === getPhyTagFromBlk(fromMSHR.bits.blkPaddr))
      &&\n542:     s2_valid && fromMSHR.valid && !fromMSHR.bits.corrupt\n543:   })\n\
      544:   private val s2_MSHR_hits = (0 until PortNumber).map(i => ValidHoldBypass(s2_MSHR_match(i),
      s2_fire || s2_flush))\n545: \n546:   private val s2_SRAM_hits = s2_waymasks.map(_.orR)\n\
      547:   private val s2_hits      = VecInit((0 until PortNumber).map(i => s2_MSHR_hits(i)
      || s2_SRAM_hits(i)))\n548: \n549:   /* s2_exception includes itlb pf/gpf/af,
      pmp af and meta corruption (af), neither of which should be prefetched"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 551-561
    context: "551:    * also, if previous has exception, latter port should also not
      be prefetched\n552:    */\n553:   private val s2_miss = VecInit((0 until PortNumber).map
      { i =>\n554:     !s2_hits(i) && (if (i == 0) true.B else s2_doubleline) &&\n\
      555:     !ExceptionType.hasException(s2_exception.take(i + 1)) &&\n556:    \
      \ s2_mmio.take(i + 1).map(!_).reduce(_ && _)\n557:   })\n558: \n559:   /**\n\
      560:     ******************************************************************************\n\
      561:     * send req to missUnit"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 563-582
    context: "563:     */\n564:   private val toMSHRArbiter = Module(new Arbiter(new
      ICacheMissReq, PortNumber))\n565: \n566:   // To avoid sending duplicate requests.\n\
      567:   private val has_send = RegInit(VecInit(Seq.fill(PortNumber)(false.B)))\n\
      568:   (0 until PortNumber).foreach { i =>\n569:     when(s1_real_fire) {\n\
      570:       has_send(i) := false.B\n571:     }.elsewhen(toMSHRArbiter.io.in(i).fire)
      {\n572:       has_send(i) := true.B\n573:     }\n574:   }\n575: \n576:   (0
      until PortNumber).foreach { i =>\n577:     toMSHRArbiter.io.in(i).valid    \
      \     := s2_valid && s2_miss(i) && !has_send(i)\n578:     toMSHRArbiter.io.in(i).bits.blkPaddr
      := getBlkAddr(s2_req_paddr(i))\n579:     toMSHRArbiter.io.in(i).bits.vSetIdx\
      \  := s2_req_vSetIdx(i)\n580:   }\n581: \n582:   toMSHR <> toMSHRArbiter.io.out"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 579-589
    context: "579:     toMSHRArbiter.io.in(i).bits.vSetIdx  := s2_req_vSetIdx(i)\n\
      580:   }\n581: \n582:   toMSHR <> toMSHRArbiter.io.out\n583: \n584:   s2_flush
      := io.flush\n585: \n586:   // toMSHRArbiter.io.in(i).fire is not used here for
      timing consideration\n587: // private val s2_finish =\n588: //   (0 until PortNumber).map(i
      => has_send(i) || !s2_miss(i) || toMSHRArbiter.io.in(i).fire).reduce(_ && _)\n\
      589:   private val s2_finish = (0 until PortNumber).map(i => has_send(i) ||
      !s2_miss(i)).reduce(_ && _)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/IPrefetch.scala
    lines: 585-610
    context: "585: \n586:   // toMSHRArbiter.io.in(i).fire is not used here for timing
      consideration\n587: // private val s2_finish =\n588: //   (0 until PortNumber).map(i
      => has_send(i) || !s2_miss(i) || toMSHRArbiter.io.in(i).fire).reduce(_ && _)\n\
      589:   private val s2_finish = (0 until PortNumber).map(i => has_send(i) ||
      !s2_miss(i)).reduce(_ && _)\n590:   s2_ready := s2_finish || !s2_valid\n591:\
      \   s2_fire  := s2_valid && s2_finish && !s2_flush\n592: \n593:   /** PerfAccumulate
      */\n594:   // the number of bpu flush\n595:   XSPerfAccumulate(\"bpu_s0_flush\"\
      , from_bpu_s0_flush)\n596:   XSPerfAccumulate(\"bpu_s1_flush\", from_bpu_s1_flush)\n\
      597:   // the number of prefetch request received from ftq or backend (software
      prefetch)\n598: //  XSPerfAccumulate(\"prefetch_req_receive\", io.req.fire)\n\
      599:   XSPerfAccumulate(\"prefetch_req_receive_hw\", io.req.fire && !io.req.bits.isSoftPrefetch)\n\
      600:   XSPerfAccumulate(\"prefetch_req_receive_sw\", io.req.fire && io.req.bits.isSoftPrefetch)\n\
      601:   // the number of prefetch request sent to missUnit\n602: //  XSPerfAccumulate(\"\
      prefetch_req_send\", toMSHR.fire)\n603:   XSPerfAccumulate(\"prefetch_req_send_hw\"\
      , toMSHR.fire && !s2_isSoftPrefetch)\n604:   XSPerfAccumulate(\"prefetch_req_send_sw\"\
      , toMSHR.fire && s2_isSoftPrefetch)\n605:   XSPerfAccumulate(\"to_missUnit_stall\"\
      , toMSHR.valid && !toMSHR.ready)\n606: \n607:   /**\n608:     * Count the number
      of requests that are filtered for various reasons.\n609:     * The number of
      prefetch discard in Performance Accumulator may be\n610:     * a little larger
      the number of really discarded. Because there can"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 63-73
    context: "63:     DataCodeUnit:        Int = 64,\n64:     ICacheDataBanks:   \
      \  Int = 8,\n65:     ICacheDataSRAMWidth: Int = 66,\n66:     // TODO: hard code,
      need delete\n67:     partWayNum:          Int = 4,\n68:     nMMIOs:        \
      \      Int = 1,\n69:     blockBytes:          Int = 64,\n70:     cacheCtrlAddressOpt:
      Option[AddressSet] = None\n71: ) extends L1CacheParameters {\n72: \n73:   val
      setBytes:     Int         = nSets * blockBytes"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 120-133
    context: "120:   require((ICacheDataBanks >= 2) && isPow2(ICacheDataBanks))\n\
      121:   require(ICacheDataSRAMWidth >= ICacheDataEntryBits)\n122:   require(isPow2(ICacheSets),
      s\"nSets($ICacheSets) must be pow2\")\n123:   require(isPow2(ICacheWays), s\"\
      nWays($ICacheWays) must be pow2\")\n124: \n125:   def generatePipeControl(lastFire:
      Bool, thisFire: Bool, thisFlush: Bool, lastFlush: Bool): Bool = {\n126:    \
      \ val valid = RegInit(false.B)\n127:     when(thisFlush)(valid := false.B)\n\
      128:       .elsewhen(lastFire && !lastFlush)(valid := true.B)\n129:       .elsewhen(thisFire)(valid
      := false.B)\n130:     valid\n131:   }\n132: \n133:   def ResultHoldBypass[T
      <: Data](data: T, valid: Bool): T ="
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 134-146
    context: "134:     Mux(valid, data, RegEnable(data, valid))\n135: \n136:   def
      ResultHoldBypass[T <: Data](data: T, init: T, valid: Bool): T =\n137:     Mux(valid,
      data, RegEnable(data, init, valid))\n138: \n139:   def holdReleaseLatch(valid:
      Bool, release: Bool, flush: Bool): Bool = {\n140:     val bit = RegInit(false.B)\n\
      141:     when(flush)(bit := false.B)\n142:       .elsewhen(valid && !release)(bit
      := true.B)\n143:       .elsewhen(release)(bit := false.B)\n144:     bit || valid\n\
      145:   }\n146: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 142-155
    context: "142:       .elsewhen(valid && !release)(bit := true.B)\n143:       .elsewhen(release)(bit
      := false.B)\n144:     bit || valid\n145:   }\n146: \n147:   def blockCounter(block:
      Bool, flush: Bool, threshold: Int): Bool = {\n148:     val counter = RegInit(0.U(log2Up(threshold
      + 1).W))\n149:     when(block)(counter := counter + 1.U)\n150:     when(flush)(counter
      := 0.U)\n151:     counter > threshold.U\n152:   }\n153: \n154:   def InitQueue[T
      <: Data](entry: T, size: Int): Vec[T] =\n155:     RegInit(VecInit(Seq.fill(size)(0.U.asTypeOf(entry.cloneType))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 217-230
    context: "217:   }\n218: }\n219: \n220: class ICacheMetaArrayIO(implicit p: Parameters)
      extends ICacheBundle {\n221:   val write:    DecoupledIO[ICacheMetaWriteBundle]
      = Flipped(DecoupledIO(new ICacheMetaWriteBundle))\n222:   val read:     DecoupledIO[ICacheReadBundle]\
      \      = Flipped(DecoupledIO(new ICacheReadBundle))\n223:   val readResp: ICacheMetaRespBundle\
      \               = Output(new ICacheMetaRespBundle)\n224:   val flush:    Vec[Valid[ICacheMetaFlushBundle]]\
      \  = Vec(PortNumber, Flipped(ValidIO(new ICacheMetaFlushBundle)))\n225:   val
      flushAll: Bool                               = Input(Bool())\n226: }\n227: \n\
      228: class ICacheMetaArray(implicit p: Parameters) extends ICacheArray with
      HasICacheECCHelper {\n229:   class ICacheMetaEntry(implicit p: Parameters) extends
      ICacheBundle {\n230:     val meta: ICacheMetadata = new ICacheMetadata"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 243-264
    context: "243:   // sanity check\n244:   require(ICacheMetaEntryBits == (new ICacheMetaEntry).getWidth)\n\
      245: \n246:   val io: ICacheMetaArrayIO = IO(new ICacheMetaArrayIO)\n247: \n\
      248:   private val port_0_read_0 = io.read.valid && !io.read.bits.vSetIdx(0)(0)\n\
      249:   private val port_0_read_1 = io.read.valid && io.read.bits.vSetIdx(0)(0)\n\
      250:   private val port_1_read_1 = io.read.valid && io.read.bits.vSetIdx(1)(0)
      && io.read.bits.isDoubleLine\n251:   private val port_1_read_0 = io.read.valid
      && !io.read.bits.vSetIdx(1)(0) && io.read.bits.isDoubleLine\n252: \n253:   private
      val port_0_read_0_reg = RegEnable(port_0_read_0, 0.U.asTypeOf(port_0_read_0),
      io.read.fire)\n254:   private val port_0_read_1_reg = RegEnable(port_0_read_1,
      0.U.asTypeOf(port_0_read_1), io.read.fire)\n255:   private val port_1_read_1_reg
      = RegEnable(port_1_read_1, 0.U.asTypeOf(port_1_read_1), io.read.fire)\n256:\
      \   private val port_1_read_0_reg = RegEnable(port_1_read_0, 0.U.asTypeOf(port_1_read_0),
      io.read.fire)\n257: \n258:   private val bank_0_idx = Mux(port_0_read_0, io.read.bits.vSetIdx(0),
      io.read.bits.vSetIdx(1))\n259:   private val bank_1_idx = Mux(port_0_read_1,
      io.read.bits.vSetIdx(0), io.read.bits.vSetIdx(1))\n260: \n261:   private val
      write_bank_0 = io.write.valid && !io.write.bits.bankIdx\n262:   private val
      write_bank_1 = io.write.valid && io.write.bits.bankIdx\n263: \n264:   private
      val write_meta_bits = ICacheMetaEntry("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 306-321
    context: "306: \n307:     tagArray\n308:   }\n309:   private val mbistPl = MbistPipeline.PlaceMbistPipeline(1,
      \"MbistPipeIcacheTag\", hasMbist)\n310: \n311:   private val read_set_idx_next
      = RegEnable(io.read.bits.vSetIdx, 0.U.asTypeOf(io.read.bits.vSetIdx), io.read.fire)\n\
      312:   private val valid_array       = RegInit(VecInit(Seq.fill(nWays)(0.U(nSets.W))))\n\
      313:   private val valid_metas       = Wire(Vec(PortNumber, Vec(nWays, Bool())))\n\
      314:   // valid read\n315:   (0 until PortNumber).foreach(i =>\n316:     (0
      until nWays).foreach(way =>\n317:       valid_metas(i)(way) := valid_array(way)(read_set_idx_next(i))\n\
      318:     )\n319:   )\n320:   io.readResp.entryValid := valid_metas\n321: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 317-328
    context: "317:       valid_metas(i)(way) := valid_array(way)(read_set_idx_next(i))\n\
      318:     )\n319:   )\n320:   io.readResp.entryValid := valid_metas\n321: \n\
      322:   io.read.ready := !io.write.valid && !io.flush.map(_.valid).reduce(_ ||
      _) && !io.flushAll &&\n323:     tagArrays.map(_.io.r.req.ready).reduce(_ &&
      _)\n324: \n325:   // valid write\n326:   private val way_num = OHToUInt(io.write.bits.waymask)\n\
      327:   when(io.write.valid) {\n328:     valid_array(way_num) := valid_array(way_num).bitSet(io.write.bits.virIdx,
      true.B)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 336-346
    context: "336:   private val readMetas       = readMetaEntries.map(_.map(_.meta))\n\
      337:   private val readCodes       = readMetaEntries.map(_.map(_.code))\n338:\
      \ \n339:   // TEST: force ECC to fail by setting readCodes to 0\n340:   if (ICacheForceMetaECCError)
      {\n341:     readCodes.foreach(_.foreach(_ := 0.U))\n342:   }\n343: \n344:  \
      \ when(port_0_read_0_reg) {\n345:     io.readResp.metas(0) := readMetas(0)\n\
      346:     io.readResp.codes(0) := readCodes(0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 355-365
    context: "355:   }.elsewhen(port_1_read_1_reg) {\n356:     io.readResp.metas(1)
      := readMetas(1)\n357:     io.readResp.codes(1) := readCodes(1)\n358:   }\n359:\
      \ \n360:   io.write.ready := true.B // TODO : has bug ? should be !io.cacheOp.req.valid\n\
      361: \n362:   /*\n363:    * flush logic\n364:    */\n365:   // flush standalone
      set (e.g. flushed by mainPipe before doing re-fetch)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 361-377
    context: "361: \n362:   /*\n363:    * flush logic\n364:    */\n365:   // flush
      standalone set (e.g. flushed by mainPipe before doing re-fetch)\n366:   when(io.flush.map(_.valid).reduce(_
      || _)) {\n367:     (0 until nWays).foreach { w =>\n368:       valid_array(w)
      := (0 until PortNumber).map { i =>\n369:         Mux(\n370:           // check
      if set `virIdx` in way `w` is requested to be flushed by port `i`\n371:    \
      \       io.flush(i).valid && io.flush(i).bits.waymask(w),\n372:           valid_array(w).bitSet(io.flush(i).bits.virIdx,
      false.B),\n373:           valid_array(w)\n374:         )\n375:       }.reduce(_
      & _)\n376:     }\n377:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 375-396
    context: "375:       }.reduce(_ & _)\n376:     }\n377:   }\n378: \n379:   // flush
      all (e.g. fence.i)\n380:   when(io.flushAll) {\n381:     (0 until nWays).foreach(w
      => valid_array(w) := 0.U)\n382:   }\n383: \n384:   // PERF: flush counter\n\
      385:   XSPerfAccumulate(\"flush\", io.flush.map(_.valid).reduce(_ || _))\n386:\
      \   XSPerfAccumulate(\"flush_all\", io.flushAll)\n387: }\n388: \n389: class
      ICacheDataArrayIO(implicit p: Parameters) extends ICacheBundle {\n390:   val
      write:    DecoupledIO[ICacheDataWriteBundle] = Flipped(DecoupledIO(new ICacheDataWriteBundle))\n\
      391:   val read:     Vec[DecoupledIO[ICacheReadBundle]] = Flipped(Vec(partWayNum,
      DecoupledIO(new ICacheReadBundle)))\n392:   val readResp: ICacheDataRespBundle\
      \               = Output(new ICacheDataRespBundle)\n393: }\n394: \n395: class
      ICacheDataArray(implicit p: Parameters) extends ICacheArray with HasICacheECCHelper
      {\n396:   class ICacheDataEntry(implicit p: Parameters) extends ICacheBundle
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 416-431
    context: "416:     */\n417:   private val writeDatas   = io.write.bits.data.asTypeOf(Vec(ICacheDataBanks,
      UInt(ICacheDataBits.W)))\n418:   private val writeEntries = writeDatas.map(ICacheDataEntry(_,
      io.write.bits.poison).asUInt)\n419: \n420:   // io.read() are copies to control
      fan-out, we can simply use .head here\n421:   private val bankSel  = getBankSel(io.read.head.bits.blkOffset,
      io.read.head.valid)\n422:   private val lineSel  = getLineSel(io.read.head.bits.blkOffset)\n\
      423:   private val waymasks = io.read.head.bits.waymask\n424:   private val
      masks    = Wire(Vec(nWays, Vec(ICacheDataBanks, Bool())))\n425:   (0 until nWays).foreach
      { way =>\n426:     (0 until ICacheDataBanks).foreach { bank =>\n427:       masks(way)(bank)
      := Mux(\n428:         lineSel(bank),\n429:         waymasks(1)(way) && bankSel(1)(bank).asBool,\n\
      430:         waymasks(0)(way) && bankSel(0)(bank).asBool\n431:       )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 445-457
    context: "445:         hasMbist = hasMbist,\n446:         hasSramCtl = hasSramCtl\n\
      447:       ))\n448: \n449:       // read\n450:       sramBank.io.r.req.valid
      := io.read(bank % 4).valid && masks(way)(bank)\n451:       sramBank.io.r.req.bits.apply(setIdx
      =\n452:         Mux(lineSel(bank), io.read(bank % 4).bits.vSetIdx(1), io.read(bank
      % 4).bits.vSetIdx(0))\n453:       )\n454:       // write\n455:       sramBank.io.w.req.valid
      := io.write.valid && io.write.bits.waymask(way).asBool\n456:       sramBank.io.w.req.bits.apply(\n\
      457:         data = writeEntries(bank),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 468-478
    context: "468:   /**\n469:     ******************************************************************************\n\
      470:     * read logic\n471:     ******************************************************************************\n\
      472:     */\n473:   private val masksReg = RegEnable(masks, 0.U.asTypeOf(masks),
      io.read(0).valid)\n474:   private val readDataWithCode = (0 until ICacheDataBanks).map
      { bank =>\n475:     Mux1H(VecInit(masksReg.map(_(bank))).asTypeOf(UInt(nWays.W)),
      dataArrays.map(_(bank).io.r.resp.asUInt))\n476:   }\n477:   private val readEntries
      = readDataWithCode.map(_.asTypeOf(new ICacheDataEntry()))\n478:   private val
      readDatas   = VecInit(readEntries.map(_.data))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 478-488
    context: "478:   private val readDatas   = VecInit(readEntries.map(_.data))\n\
      479:   private val readCodes   = VecInit(readEntries.map(_.code))\n480: \n481:\
      \   // TEST: force ECC to fail by setting readCodes to 0\n482:   if (ICacheForceDataECCError)
      {\n483:     readCodes.foreach(_ := 0.U)\n484:   }\n485: \n486:   /**\n487: \
      \    ******************************************************************************\n\
      488:     * IO"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 488-499
    context: "488:     * IO\n489:     ******************************************************************************\n\
      490:     */\n491:   io.readResp.datas := readDatas\n492:   io.readResp.codes
      := readCodes\n493:   io.write.ready    := true.B\n494:   io.read.foreach(_.ready
      := !io.write.valid)\n495: }\n496: \n497: class ICacheReplacerIO(implicit p:
      Parameters) extends ICacheBundle {\n498:   val touch:  Vec[Valid[ReplacerTouch]]
      = Vec(PortNumber, Flipped(ValidIO(new ReplacerTouch)))\n499:   val victim: ReplacerVictim\
      \            = Flipped(new ReplacerVictim)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 506-516
    context: "506:     Seq.fill(PortNumber)(ReplacementPolicy.fromString(cacheParams.replacer,
      nWays, nSets / PortNumber))\n507: \n508:   // touch\n509:   private val touch_sets
      = Seq.fill(PortNumber)(Wire(Vec(PortNumber, UInt(log2Ceil(nSets / PortNumber).W))))\n\
      510:   private val touch_ways = Seq.fill(PortNumber)(Wire(Vec(PortNumber, Valid(UInt(wayBits.W)))))\n\
      511:   (0 until PortNumber).foreach { i =>\n512:     touch_sets(i)(0) := Mux(\n\
      513:       io.touch(i).bits.vSetIdx(0),\n514:       io.touch(1).bits.vSetIdx(highestIdxBit,
      1),\n515:       io.touch(0).bits.vSetIdx(highestIdxBit, 1)\n516:     )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 527-537
    context: "527: \n528:   // touch the victim in next cycle\n529:   private val
      victim_vSetIdx_reg =\n530:     RegEnable(io.victim.vSetIdx.bits, 0.U.asTypeOf(io.victim.vSetIdx.bits),
      io.victim.vSetIdx.valid)\n531:   private val victim_way_reg = RegEnable(io.victim.way,
      0.U.asTypeOf(io.victim.way), io.victim.vSetIdx.valid)\n532:   (0 until PortNumber).foreach
      { i =>\n533:     touch_sets(i)(1)       := victim_vSetIdx_reg(highestIdxBit,
      1)\n534:     touch_ways(i)(1).bits  := victim_way_reg\n535:     touch_ways(i)(1).valid
      := RegNext(io.victim.vSetIdx.valid) && (victim_vSetIdx_reg(0) === i.U)\n536:\
      \   }\n537: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 533-543
    context: "533:     touch_sets(i)(1)       := victim_vSetIdx_reg(highestIdxBit,
      1)\n534:     touch_ways(i)(1).bits  := victim_way_reg\n535:     touch_ways(i)(1).valid
      := RegNext(io.victim.vSetIdx.valid) && (victim_vSetIdx_reg(0) === i.U)\n536:\
      \   }\n537: \n538:   ((replacers zip touch_sets) zip touch_ways).foreach { case
      ((r, s), w) => r.access(s, w) }\n539: }\n540: \n541: class ICacheIO(implicit
      p: Parameters) extends ICacheBundle {\n542:   val hartId: UInt = Input(UInt(hartIdLen.W))\n\
      543:   // FTQ"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 550-560
    context: "550:   val stop:  Bool = Input(Bool())\n551:   val toIFU: Bool = Output(Bool())\n\
      552:   // PMP: mainPipe & prefetchPipe need PortNumber each\n553:   val pmp:
      Vec[ICachePMPBundle] = Vec(2 * PortNumber, new ICachePMPBundle)\n554:   // iTLB\n\
      555:   val itlb:          Vec[TlbRequestIO] = Vec(PortNumber, new TlbRequestIO)\n\
      556:   val itlbFlushPipe: Bool              = Bool()\n557:   // backend/BEU\n\
      558:   val error: Valid[L1CacheErrorInfo] = ValidIO(new L1CacheErrorInfo)\n\
      559:   // backend/CSR\n560:   val csr_pf_enable: Bool = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 558-568
    context: "558:   val error: Valid[L1CacheErrorInfo] = ValidIO(new L1CacheErrorInfo)\n\
      559:   // backend/CSR\n560:   val csr_pf_enable: Bool = Input(Bool())\n561:\
      \   // flush\n562:   val fencei: Bool = Input(Bool())\n563:   val flush:  Bool
      = Input(Bool())\n564:   // wfi\n565:   val wfi: WfiReqBundle = Flipped(new WfiReqBundle)\n\
      566: \n567:   // perf\n568:   val perfInfo: ICachePerfInfo = Output(new ICachePerfInfo)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 601-611
    context: "601:   println(\"  nWayLookupSize: \" + cacheParams.nWayLookupSize)\n\
      602:   println(\"  DataCodeUnit: \" + cacheParams.DataCodeUnit)\n603:   println(\"\
      \  ICacheDataBanks: \" + cacheParams.ICacheDataBanks)\n604:   println(\"  ICacheDataSRAMWidth:
      \" + cacheParams.ICacheDataSRAMWidth)\n605: \n606:   val (bus, edge) = outer.clientNode.out.head\n\
      607: \n608:   private val metaArray  = Module(new ICacheMetaArray)\n609:   private
      val dataArray  = Module(new ICacheDataArray)\n610:   private val mainPipe  \
      \ = Module(new ICacheMainPipe)\n611:   private val missUnit   = Module(new ICacheMissUnit(edge))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 618-630
    context: "618:   // dataArray io\n619:   if (outer.ctrlUnitOpt.nonEmpty) {\n620:\
      \     val ctrlUnit = outer.ctrlUnitOpt.get.module\n621:     when(ctrlUnit.io.injecting)
      {\n622:       dataArray.io.write <> ctrlUnit.io.dataWrite\n623:       missUnit.io.data_write.ready
      := false.B\n624:     }.otherwise {\n625:       ctrlUnit.io.dataWrite.ready :=
      false.B\n626:       dataArray.io.write <> missUnit.io.data_write\n627:     }\n\
      628:   } else {\n629:     dataArray.io.write <> missUnit.io.data_write\n630:\
      \   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 626-662
    context: "626:       dataArray.io.write <> missUnit.io.data_write\n627:     }\n\
      628:   } else {\n629:     dataArray.io.write <> missUnit.io.data_write\n630:\
      \   }\n631:   dataArray.io.read <> mainPipe.io.dataArray.toIData\n632:   mainPipe.io.dataArray.fromIData
      := dataArray.io.readResp\n633: \n634:   // metaArray io\n635:   metaArray.io.flushAll
      := io.fencei\n636:   metaArray.io.flush <> mainPipe.io.metaArrayFlush\n637:\
      \   if (outer.ctrlUnitOpt.nonEmpty) {\n638:     val ctrlUnit = outer.ctrlUnitOpt.get.module\n\
      639:     when(ctrlUnit.io.injecting) {\n640:       metaArray.io.write <> ctrlUnit.io.metaWrite\n\
      641:       metaArray.io.read <> ctrlUnit.io.metaRead\n642:       missUnit.io.meta_write.ready\
      \         := false.B\n643:       prefetcher.io.metaRead.toIMeta.ready := false.B\n\
      644:     }.otherwise {\n645:       ctrlUnit.io.metaWrite.ready := false.B\n\
      646:       ctrlUnit.io.metaRead.ready  := false.B\n647:       metaArray.io.write
      <> missUnit.io.meta_write\n648:       metaArray.io.read <> prefetcher.io.metaRead.toIMeta\n\
      649:     }\n650:     ctrlUnit.io.metaReadResp := metaArray.io.readResp\n651:\
      \   } else {\n652:     metaArray.io.write <> missUnit.io.meta_write\n653:  \
      \   metaArray.io.read <> prefetcher.io.metaRead.toIMeta\n654:   }\n655:   prefetcher.io.metaRead.fromIMeta
      := metaArray.io.readResp\n656: \n657:   prefetcher.io.flush         := io.flush\n\
      658:   prefetcher.io.csr_pf_enable := io.csr_pf_enable\n659:   prefetcher.io.ecc_enable\
      \    := ecc_enable\n660:   prefetcher.io.MSHRResp      := missUnit.io.fetch_resp\n\
      661:   prefetcher.io.flushFromBpu  := io.ftqPrefetch.flushFromBpu\n662:   //
      cache softPrefetch"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 673-683
    context: "673:     softPrefetchValid := true.B\n674:     softPrefetch.fromSoftPrefetch(MuxCase(\n\
      675:       0.U.asTypeOf(new SoftIfetchPrefetchBundle),\n676:       io.softPrefetch.map(req
      => req.valid -> req.bits)\n677:     ))\n678:   }.elsewhen(prefetcher.io.req.fire)
      {\n679:     softPrefetchValid := false.B\n680:   }\n681:   // pass ftqPrefetch\n\
      682:   private val ftqPrefetch = WireInit(0.U.asTypeOf(new IPrefetchReq))\n\
      683:   ftqPrefetch.fromFtqICacheInfo(io.ftqPrefetch.req.bits)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 683-697
    context: "683:   ftqPrefetch.fromFtqICacheInfo(io.ftqPrefetch.req.bits)\n684:\
      \   // software prefetch has higher priority\n685:   prefetcher.io.req.valid\
      \                 := softPrefetchValid || io.ftqPrefetch.req.valid\n686:   prefetcher.io.req.bits\
      \                  := Mux(softPrefetchValid, softPrefetch, ftqPrefetch)\n687:\
      \   prefetcher.io.req.bits.backendException := io.ftqPrefetch.backendException\n\
      688:   io.ftqPrefetch.req.ready                := prefetcher.io.req.ready &&
      !softPrefetchValid\n689: \n690:   missUnit.io.hartId := io.hartId\n691:   missUnit.io.fencei
      := io.fencei\n692:   missUnit.io.flush  := io.flush\n693:   missUnit.io.wfi
      <> io.wfi\n694:   missUnit.io.fetch_req <> mainPipe.io.mshr.req\n695:   missUnit.io.prefetch_req
      <> prefetcher.io.MSHRReq\n696:   missUnit.io.mem_grant.valid := false.B\n697:\
      \   missUnit.io.mem_grant.bits  := DontCare"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 695-705
    context: "695:   missUnit.io.prefetch_req <> prefetcher.io.MSHRReq\n696:   missUnit.io.mem_grant.valid
      := false.B\n697:   missUnit.io.mem_grant.bits  := DontCare\n698:   missUnit.io.mem_grant
      <> bus.d\n699: \n700:   mainPipe.io.flush      := io.flush\n701:   mainPipe.io.respStall\
      \  := io.stop\n702:   mainPipe.io.ecc_enable := ecc_enable\n703:   mainPipe.io.hartId\
      \     := io.hartId\n704:   mainPipe.io.mshr.resp  := missUnit.io.fetch_resp\n\
      705:   mainPipe.io.fetch.req <> io.fetch.req"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 701-713
    context: "701:   mainPipe.io.respStall  := io.stop\n702:   mainPipe.io.ecc_enable
      := ecc_enable\n703:   mainPipe.io.hartId     := io.hartId\n704:   mainPipe.io.mshr.resp\
      \  := missUnit.io.fetch_resp\n705:   mainPipe.io.fetch.req <> io.fetch.req\n\
      706:   mainPipe.io.wayLookupRead <> wayLookup.io.read\n707: \n708:   wayLookup.io.flush
      := io.flush\n709:   wayLookup.io.write <> prefetcher.io.wayLookupWrite\n710:\
      \   wayLookup.io.update := missUnit.io.fetch_resp\n711: \n712:   replacer.io.touch
      <> mainPipe.io.touch\n713:   replacer.io.victim <> missUnit.io.victim"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 715-730
    context: "715:   io.pmp(0) <> mainPipe.io.pmp(0)\n716:   io.pmp(1) <> mainPipe.io.pmp(1)\n\
      717:   io.pmp(2) <> prefetcher.io.pmp(0)\n718:   io.pmp(3) <> prefetcher.io.pmp(1)\n\
      719: \n720:   io.itlb(0) <> prefetcher.io.itlb(0)\n721:   io.itlb(1) <> prefetcher.io.itlb(1)\n\
      722:   io.itlbFlushPipe := prefetcher.io.itlbFlushPipe\n723: \n724:   // notify
      IFU that Icache pipeline is available\n725:   io.toIFU    := mainPipe.io.fetch.req.ready\n\
      726:   io.perfInfo := mainPipe.io.perfInfo\n727: \n728:   io.fetch.resp <> mainPipe.io.fetch.resp\n\
      729:   io.fetch.topdownIcacheMiss := mainPipe.io.fetch.topdownIcacheMiss\n730:\
      \   io.fetch.topdownItlbMiss   := mainPipe.io.fetch.topdownItlbMiss"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 727-737
    context: "727: \n728:   io.fetch.resp <> mainPipe.io.fetch.resp\n729:   io.fetch.topdownIcacheMiss
      := mainPipe.io.fetch.topdownIcacheMiss\n730:   io.fetch.topdownItlbMiss   :=
      mainPipe.io.fetch.topdownItlbMiss\n731: \n732:   bus.b.ready := false.B\n733:\
      \   bus.c.valid := false.B\n734:   bus.c.bits  := DontCare\n735:   bus.e.valid
      := false.B\n736:   bus.e.bits  := DontCare\n737: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 747-757
    context: "747:   )\n748:   io.error.valid := RegNext(errors_valid, false.B)\n\
      749: \n750:   XSPerfAccumulate(\n751:     \"softPrefetch_drop_not_ready\",\n\
      752:     io.softPrefetch.map(_.valid).reduce(_ || _) && softPrefetchValid &&
      !prefetcher.io.req.fire\n753:   )\n754:   XSPerfAccumulate(\"softPrefetch_drop_multi_req\"\
      , PopCount(io.softPrefetch.map(_.valid)) > 1.U)\n755:   XSPerfAccumulate(\"\
      softPrefetch_block_ftq\", softPrefetchValid && io.ftqPrefetch.req.valid)\n756:\
      \ \n757:   val perfEvents: Seq[(String, Bool)] = Seq("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 878-894
    context: "878: \n879:     // write req\n880:     sramBank.io.w.req.valid     \
      \  := io.w.req.valid\n881:     sramBank.io.w.req.bits.setIdx := io.w.req.bits.setIdx\n\
      882:     sramBank.io.w.req.bits.data   := writeDatas(bank)\n883:     sramBank.io.w.req.bits.waymask.foreach(_
      := io.w.req.bits.waymask.get)\n884: \n885:     sramBank\n886:   }\n887: \n888:\
      \   io.r.req.ready := !io.w.req.valid\n889:   (0 until way).foreach { i =>\n\
      890:     io.r.resp.data(i) := VecInit((0 until bankNum).map(bank =>\n891:  \
      \     srams(bank).io.r.resp.data(i)\n892:     )).asTypeOf(UInt(totalBits.W))(dataBits
      - 1, 0).asTypeOf(gen.cloneType)\n893:   }\n894: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICache.scala
    lines: 890-897
    context: "890:     io.r.resp.data(i) := VecInit((0 until bankNum).map(bank =>\n\
      891:       srams(bank).io.r.resp.data(i)\n892:     )).asTypeOf(UInt(totalBits.W))(dataBits
      - 1, 0).asTypeOf(gen.cloneType)\n893:   }\n894: \n895:   io.r.req.ready := srams.head.io.r.req.ready\n\
      896:   io.w.req.ready := srams.head.io.w.req.ready\n897: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 36-53
    context: "36:  */\n37: class DeMultiplexer[T <: Data](val gen: T, val n: Int)
      extends Module {\n38:   require(n >= 2)\n39:   val io: DeMultiplexerIO[T] =
      IO(new DeMultiplexerIO(gen, n))\n40: \n41:   private val grant = false.B +:
      (1 until n).map(i => (0 until i).map(io.out(_).ready).reduce(_ || _))\n42: \
      \  (0 until n).foreach { i =>\n43:     io.out(i).bits  := io.in.bits\n44:  \
      \   io.out(i).valid := !grant(i) && io.in.valid\n45:   }\n46: \n47:   io.in.ready
      := grant.last || io.out.last.ready\n48:   io.chosen   := PriorityEncoder(VecInit(io.out.map(_.ready)))\n\
      49: }\n50: \n51: class MuxBundleIO[T <: Data](gen: T, n: Int) extends Bundle
      {\n52:   val sel: UInt                = Input(UInt(log2Ceil(n).W))\n53:   val
      in:  Vec[DecoupledIO[T]] = Flipped(Vec(n, DecoupledIO(gen)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 58-72
    context: "58:   require(n >= 2)\n59:   val io: MuxBundleIO[T] = IO(new MuxBundleIO[T](gen,
      n))\n60: \n61:   io.in <> DontCare\n62:   io.out <> DontCare\n63:   (0 until
      n).foreach { i =>\n64:     when(io.sel === i.U) {\n65:       io.out <> io.in(i)\n\
      66:     }\n67:     io.in(i).ready := (io.sel === i.U) && io.out.ready\n68: \
      \  }\n69: }\n70: \n71: class ICacheMissReq(implicit p: Parameters) extends ICacheBundle
      {\n72:   val blkPaddr: UInt = UInt((PAddrBits - blockOffBits).W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 97-107
    context: "97:   val vSetIdx: UInt      = UInt(idxBits.W)\n98: }\n99: \n100: class
      ICacheMSHRIO(edge: TLEdgeOut)(implicit p: Parameters) extends ICacheBundle {\n\
      101:   val fencei:    Bool                       = Input(Bool())\n102:   val
      flush:     Bool                       = Input(Bool())\n103:   val wfi:     \
      \  WfiReqBundle               = Flipped(new WfiReqBundle)\n104:   val invalid:\
      \   Bool                       = Input(Bool())\n105:   val req:       DecoupledIO[ICacheMissReq]
      = Flipped(DecoupledIO(new ICacheMissReq))\n106:   val acquire:   DecoupledIO[MSHRAcquire]\
      \   = DecoupledIO(new MSHRAcquire(edge))\n107:   val lookUps:   Vec[LookUpMSHR]\
      \            = Flipped(Vec(2, new LookUpMSHR))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 112-122
    context: "112: class ICacheMSHR(edge: TLEdgeOut, isFetch: Boolean, ID: Int)(implicit
      p: Parameters) extends ICacheModule {\n113:   val io: ICacheMSHRIO = IO(new
      ICacheMSHRIO(edge))\n114: \n115:   private val valid = RegInit(Bool(), false.B)\n\
      116:   // this MSHR doesn't respond to fetch and sram\n117:   private val flush\
      \  = RegInit(Bool(), false.B)\n118:   private val fencei = RegInit(Bool(), false.B)\n\
      119:   // this MSHR has been issued\n120:   private val issue = RegInit(Bool(),
      false.B)\n121: \n122:   private val blkPaddr = RegInit(UInt((PAddrBits - blockOffBits).W),
      0.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 123-137
    context: "123:   private val vSetIdx  = RegInit(UInt(idxBits.W), 0.U)\n124:  \
      \ private val way      = RegInit(UInt(wayBits.W), 0.U)\n125: \n126:   // look
      up and return result at the same cycle\n127:   private val hits = io.lookUps.map
      { lookup =>\n128:     valid && !fencei && !flush && (lookup.info.bits.vSetIdx
      === vSetIdx) &&\n129:     (lookup.info.bits.blkPaddr === blkPaddr)\n130:   }\n\
      131:   // Decoupling valid and bits\n132:   (0 until 2).foreach(i => io.lookUps(i).hit
      := hits(i))\n133: \n134:   // disable wake up when hit MSHR (fencei is low)\n\
      135:   // when(hit) {\n136:   //   flush := false.B\n137:   // }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 135-147
    context: "135:   // when(hit) {\n136:   //   flush := false.B\n137:   // }\n138:\
      \ \n139:   // invalid when the req hasn't been issued\n140:   when(io.fencei
      || io.flush) {\n141:     fencei := true.B\n142:     flush  := true.B\n143: \
      \    when(!issue) {\n144:       valid := false.B\n145:     }\n146:   }\n147: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 144-157
    context: "144:       valid := false.B\n145:     }\n146:   }\n147: \n148:   //
      receive request and register\n149:   io.req.ready := !valid && !io.flush &&
      !io.fencei\n150:   when(io.req.fire) {\n151:     valid    := true.B\n152:  \
      \   flush    := false.B\n153:     issue    := false.B\n154:     fencei   :=
      false.B\n155:     blkPaddr := io.req.bits.blkPaddr\n156:     vSetIdx  := io.req.bits.vSetIdx\n\
      157:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 155-165
    context: "155:     blkPaddr := io.req.bits.blkPaddr\n156:     vSetIdx  := io.req.bits.vSetIdx\n\
      157:   }\n158: \n159:   // send request to L2\n160:   io.acquire.valid := valid
      && !issue && !io.flush && !io.fencei && !io.wfi.wfiReq\n161:   private val getBlock
      = edge.Get(\n162:     fromSource = ID.U,\n163:     toAddress = Cat(blkPaddr,
      0.U(blockOffBits.W)),\n164:     lgSize = log2Up(cacheParams.blockBytes).U\n\
      165:   )._2"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 162-176
    context: "162:     fromSource = ID.U,\n163:     toAddress = Cat(blkPaddr, 0.U(blockOffBits.W)),\n\
      164:     lgSize = log2Up(cacheParams.blockBytes).U\n165:   )._2\n166:   io.acquire.bits.acquire
      := getBlock\n167:   io.acquire.bits.acquire.user.lift(ReqSourceKey).foreach(_
      := MemReqSource.CPUInst.id.U)\n168:   io.acquire.bits.vSetIdx := vSetIdx\n169:\
      \ \n170:   // get victim way when acquire fire\n171:   when(io.acquire.fire)
      {\n172:     issue := true.B\n173:     way   := io.victimWay\n174:   }\n175:\
      \ \n176:   // invalid request when grant finish"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 177-187
    context: "177:   when(io.invalid) {\n178:     valid := false.B\n179:   }\n180:\
      \ \n181:   // offer the information other than data for write sram and response
      fetch\n182:   io.resp.valid         := valid && (!flush && !fencei)\n183:  \
      \ io.resp.bits.blkPaddr := blkPaddr\n184:   io.resp.bits.vSetIdx  := vSetIdx\n\
      185:   io.resp.bits.way      := way\n186: \n187:   // we are safe to enter wfi
      if we have no pending response from L2"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 191-201
    context: "191: class ICacheMissUnitIO(edge: TLEdgeOut)(implicit p: Parameters)
      extends ICacheBundle {\n192:   // difftest\n193:   val hartId: Bool = Input(Bool())\n\
      194:   // control\n195:   val fencei: Bool         = Input(Bool())\n196:   val
      flush:  Bool         = Input(Bool())\n197:   val wfi:    WfiReqBundle = Flipped(new
      WfiReqBundle)\n198:   // fetch\n199:   val fetch_req:  DecoupledIO[ICacheMissReq]
      = Flipped(DecoupledIO(new ICacheMissReq))\n200:   val fetch_resp: Valid[ICacheMissResp]\
      \      = ValidIO(new ICacheMissResp)\n201:   // prefetch"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 242-255
    context: "242:   // To avoid duplicate request reception.\n243:   private val
      fetchHit    = Wire(Bool())\n244:   private val prefetchHit = Wire(Bool())\n\
      245:   fetchDemux.io.in <> io.fetch_req\n246:   fetchDemux.io.in.valid := io.fetch_req.valid
      && !fetchHit\n247:   io.fetch_req.ready     := fetchDemux.io.in.ready || fetchHit\n\
      248:   prefetchDemux.io.in <> io.prefetch_req\n249:   prefetchDemux.io.in.valid
      := io.prefetch_req.valid && !prefetchHit\n250:   io.prefetch_req.ready     :=
      prefetchDemux.io.in.ready || prefetchHit\n251:   acquireArb.io.in.last <> prefetchArb.io.out\n\
      252: \n253:   // mem_acquire connect\n254:   io.mem_acquire.valid    := acquireArb.io.out.valid\n\
      255:   io.mem_acquire.bits     := acquireArb.io.out.bits.acquire"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 251-265
    context: "251:   acquireArb.io.in.last <> prefetchArb.io.out\n252: \n253:   //
      mem_acquire connect\n254:   io.mem_acquire.valid    := acquireArb.io.out.valid\n\
      255:   io.mem_acquire.bits     := acquireArb.io.out.bits.acquire\n256:   acquireArb.io.out.ready
      := io.mem_acquire.ready\n257: \n258:   private val fetchMSHRs = (0 until nFetchMshr).map
      { i =>\n259:     val mshr = Module(new ICacheMSHR(edge, true, i))\n260:    \
      \ mshr.io.flush      := false.B\n261:     mshr.io.fencei     := io.fencei\n\
      262:     mshr.io.wfi.wfiReq := io.wfi.wfiReq\n263:     mshr.io.req <> fetchDemux.io.out(i)\n\
      264:     mshr.io.lookUps(0).info.valid := io.fetch_req.valid\n265:     mshr.io.lookUps(0).info.bits\
      \  := io.fetch_req.bits"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 270-280
    context: "270:     mshr\n271:   }\n272: \n273:   private val prefetchMSHRs = (0
      until nPrefetchMshr).map { i =>\n274:     val mshr = Module(new ICacheMSHR(edge,
      false, nFetchMshr + i))\n275:     mshr.io.flush      := io.flush\n276:     mshr.io.fencei\
      \     := io.fencei\n277:     mshr.io.wfi.wfiReq := io.wfi.wfiReq\n278:     mshr.io.req
      <> prefetchDemux.io.out(i)\n279:     mshr.io.lookUps(0).info.valid := io.fetch_req.valid\n\
      280:     mshr.io.lookUps(0).info.bits  := io.fetch_req.bits"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 307-329
    context: "307:     ******************************************************************************\n\
      308:     */\n309:   // When the FIFO is full, enqueue and dequeue operations
      do not occur at the same cycle.\n310:   // So the depth of the FIFO is set to
      match the number of MSHRs.\n311:   // val priorityFIFO = Module(new Queue(UInt(log2Ceil(nPrefetchMshr).W),
      nPrefetchMshr, hasFlush=true))\n312:   private val priorityFIFO = Module(new
      FIFOReg(UInt(log2Ceil(nPrefetchMshr).W), nPrefetchMshr, hasFlush = true))\n\
      313:   priorityFIFO.io.flush.get := io.flush || io.fencei\n314:   priorityFIFO.io.enq.valid
      := prefetchDemux.io.in.fire\n315:   priorityFIFO.io.enq.bits  := prefetchDemux.io.chosen\n\
      316:   priorityFIFO.io.deq.ready := prefetchArb.io.out.fire\n317:   prefetchArb.io.sel\
      \        := priorityFIFO.io.deq.bits\n318:   assert(\n319:     !(priorityFIFO.io.enq.fire
      ^ prefetchDemux.io.in.fire),\n320:     \"priorityFIFO.io.enq and io.prefetch_req
      must fire at the same cycle\"\n321:   )\n322:   assert(\n323:     !(priorityFIFO.io.deq.fire
      ^ prefetchArb.io.out.fire),\n324:     \"priorityFIFO.io.deq and prefetchArb.io.out
      must fire at the same cycle\"\n325:   )\n326: \n327:   /**\n328:     ******************************************************************************\n\
      329:     * Tilelink D channel (grant)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 332-342
    context: "332:   // cacheline register\n333:   private val readBeatCnt = RegInit(UInt(log2Up(refillCycles).W),
      0.U)\n334:   private val respDataReg = RegInit(VecInit(Seq.fill(refillCycles)(0.U(beatBits.W))))\n\
      335: \n336:   private val wait_last = readBeatCnt === (refillCycles - 1).U\n\
      337:   when(io.mem_grant.fire && edge.hasData(io.mem_grant.bits)) {\n338:  \
      \   respDataReg(readBeatCnt) := io.mem_grant.bits.data\n339:     readBeatCnt\
      \              := Mux(wait_last, 0.U, readBeatCnt + 1.U)\n340:   }\n341: \n\
      342:   // last transition finish or corrupt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 338-352
    context: "338:     respDataReg(readBeatCnt) := io.mem_grant.bits.data\n339:  \
      \   readBeatCnt              := Mux(wait_last, 0.U, readBeatCnt + 1.U)\n340:\
      \   }\n341: \n342:   // last transition finish or corrupt\n343:   private val
      last_fire = io.mem_grant.fire && edge.hasData(io.mem_grant.bits) && wait_last\n\
      344: \n345:   private val (_, _, refill_done, _) = edge.addr_inc(io.mem_grant)\n\
      346:   assert(!(refill_done ^ last_fire), \"refill not done!\")\n347:   io.mem_grant.ready
      := true.B\n348: \n349:   private val last_fire_r = RegNext(last_fire)\n350:\
      \   private val id_r        = RegNext(io.mem_grant.bits.source)\n351: \n352:\
      \   // if any beat is corrupt, the whole response (to mainPipe/metaArray/dataArray)
      is corrupt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 349-359
    context: "349:   private val last_fire_r = RegNext(last_fire)\n350:   private
      val id_r        = RegNext(io.mem_grant.bits.source)\n351: \n352:   // if any
      beat is corrupt, the whole response (to mainPipe/metaArray/dataArray) is corrupt\n\
      353:   private val corrupt_r = RegInit(false.B)\n354:   when(io.mem_grant.fire
      && edge.hasData(io.mem_grant.bits) && io.mem_grant.bits.corrupt) {\n355:   \
      \  // Set corrupt_r when any beat is corrupt\n356:     // This is actually when(xxx.fire
      && xxx.hasData) { corrupt_r := corrupt_r || io.mem_grant.bits.corrupt }\n357:\
      \     corrupt_r := true.B\n358:   }.elsewhen(last_fire_r) {\n359:     // Clear
      corrupt_r when response it sent to mainPipe"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 367-377
    context: "367:   /**\n368:     ******************************************************************************\n\
      369:     * invalid mshr when finish transition\n370:     ******************************************************************************\n\
      371:     */\n372:   (0 until (nFetchMshr + nPrefetchMshr)).foreach(i => allMSHRs(i).io.invalid
      := last_fire_r && (id_r === i.U))\n373: \n374:   /**\n375:     ******************************************************************************\n\
      376:     * response fetch and write SRAM\n377:     ******************************************************************************"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 381-394
    context: "381:   // select MSHR response 1 cycle before sending response to mainPipe/prefetchPipe
      for better timing\n382:   private val mshr_resp =\n383:     RegEnable(allMSHRs_resp(io.mem_grant.bits.source).bits,
      0.U.asTypeOf(allMSHRs_resp(0).bits), last_fire)\n384:   // we can latch mshr.io.resp.bits
      since they are set on req.fire or acquire.fire, and keeps unchanged during response\n\
      385:   // however, we should not latch mshr.io.resp.valid, since io.flush/fencei
      may clear it at any time\n386:   private val mshr_valid = allMSHRs_resp(id_r).valid\n\
      387: \n388:   // get waymask from replacer when acquire fire\n389:   io.victim.vSetIdx.valid
      := acquireArb.io.out.fire\n390:   io.victim.vSetIdx.bits  := acquireArb.io.out.bits.vSetIdx\n\
      391:   private val waymask = UIntToOH(mshr_resp.way)\n392:   // NOTE: when flush/fencei,
      missUnit will still send response to mainPipe/prefetchPipe\n393:   //      \
      \ this is intentional to fix timing (io.flush -> mainPipe/prefetchPipe s2_miss
      -> s2_ready -> ftq ready)\n394:   //       unnecessary response will be dropped
      by mainPipe/prefetchPipe/wayLookup since their sx_valid is set to false"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 390-402
    context: "390:   io.victim.vSetIdx.bits  := acquireArb.io.out.bits.vSetIdx\n391:\
      \   private val waymask = UIntToOH(mshr_resp.way)\n392:   // NOTE: when flush/fencei,
      missUnit will still send response to mainPipe/prefetchPipe\n393:   //      \
      \ this is intentional to fix timing (io.flush -> mainPipe/prefetchPipe s2_miss
      -> s2_ready -> ftq ready)\n394:   //       unnecessary response will be dropped
      by mainPipe/prefetchPipe/wayLookup since their sx_valid is set to false\n395:\
      \   private val fetch_resp_valid = mshr_valid && last_fire_r\n396:   // NOTE:
      but we should not write meta/dataArray when flush/fencei\n397:   private val
      write_sram_valid = fetch_resp_valid && !corrupt_r && !io.flush && !io.fencei\n\
      398: \n399:   // write SRAM\n400:   io.meta_write.bits.generate(\n401:     tag
      = getPhyTagFromBlk(mshr_resp.blkPaddr),\n402:     idx = mshr_resp.vSetIdx,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMissUnit.scala
    lines: 430-441
    context: "430:     ******************************************************************************\n\
      431:     * performance counter\n432:     ******************************************************************************\n\
      433:     */\n434:   // Duplicate requests will be excluded.\n435:   XSPerfAccumulate(\"\
      enq_fetch_req\", fetchDemux.io.in.fire)\n436:   XSPerfAccumulate(\"enq_prefetch_req\"\
      , prefetchDemux.io.in.fire)\n437: \n438:   /**\n439:     ******************************************************************************\n\
      440:     * ChiselDB: record ICache SRAM write log\n441:     ******************************************************************************"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 34-44
    context: "34:   val vaddr:            Vec[UInt] = Vec(PortNumber, UInt(VAddrBits.W))\n\
      35:   val data:             UInt      = UInt(blockBits.W)\n36:   val paddr:\
      \            Vec[UInt] = Vec(PortNumber, UInt(PAddrBits.W))\n37:   val exception:\
      \        Vec[UInt] = Vec(PortNumber, UInt(ExceptionType.width.W))\n38:   val
      pmp_mmio:         Vec[Bool] = Vec(PortNumber, Bool())\n39:   val itlb_pbmt:\
      \        Vec[UInt] = Vec(PortNumber, UInt(Pbmt.width.W))\n40:   val backendException:
      Bool      = Bool()\n41:   /* NOTE: GPAddrBits(=50bit) is not enough for gpaddr
      here, refer to PR#3795\n42:    * Sv48*4 only allows 50bit gpaddr, when software
      violates this requirement\n43:    * it needs to fill the mtval2 register with
      the full XLEN(=64bit) gpaddr,\n44:    * PAddrBitsMax(=56bit currently) is required
      for the frontend datapath due to the itlb ppn length limitation"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 101-111
    context: "101:   val ecc_enable:     Bool                              = Input(Bool())\n\
      102: \n103:   /*** outside interface ***/\n104:   // FTQ\n105:   val fetch:
      ICacheMainPipeBundle = new ICacheMainPipeBundle\n106:   val flush: Bool    \
      \             = Input(Bool())\n107:   // PMP\n108:   val pmp: Vec[ICachePMPBundle]
      = Vec(PortNumber, new ICachePMPBundle)\n109:   // IFU\n110:   val respStall:
      Bool = Input(Bool())\n111:   // backend/BEU"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 125-135
    context: "125:   val io: ICacheMainPipeInterface = IO(new ICacheMainPipeInterface)\n\
      126: \n127:   /** Input/Output port */\n128:   private val (fromFtq, toIFU)\
      \   = (io.fetch.req, io.fetch.resp)\n129:   private val (toData, fromData) =
      (io.dataArray.toIData, io.dataArray.fromIData)\n130:   private val toMetaFlush\
      \        = io.metaArrayFlush\n131:   private val (toMSHR, fromMSHR) = (io.mshr.req,
      io.mshr.resp)\n132:   private val (toPMP, fromPMP)   = (io.pmp.map(_.req), io.pmp.map(_.resp))\n\
      133:   private val fromWayLookup      = io.wayLookupRead\n134:   private val
      ecc_enable =\n135:     if (ICacheForceMetaECCError || ICacheForceDataECCError)
      true.B else io.ecc_enable"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 136-150
    context: "136: \n137:   // Statistics on the frequency distribution of FTQ fire
      interval\n138:   private val cntFtqFireInterval      = RegInit(0.U(32.W))\n\
      139:   private val cntFtqFireIntervalStart = 1\n140:   private val cntFtqFireIntervalEnd\
      \   = 300\n141:   cntFtqFireInterval := Mux(fromFtq.fire, 1.U, cntFtqFireInterval
      + 1.U)\n142:   XSPerfHistogram(\n143:     \"ftq2icache_fire\",\n144:     cntFtqFireInterval,\n\
      145:     fromFtq.fire,\n146:     cntFtqFireIntervalStart,\n147:     cntFtqFireIntervalEnd,\n\
      148:     right_strict = true\n149:   )\n150: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 147-159
    context: "147:     cntFtqFireIntervalEnd,\n148:     right_strict = true\n149:\
      \   )\n150: \n151:   /** pipeline control signal */\n152:   val s1_ready, s2_ready\
      \           = Wire(Bool())\n153:   val s0_fire, s1_fire, s2_fire    = Wire(Bool())\n\
      154:   val s0_flush, s1_flush, s2_flush = Wire(Bool())\n155: \n156:   /**\n\
      157:     ******************************************************************************\n\
      158:     * ICache Stage 0\n159:     * - send req to data SRAM"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 163-173
    context: "163: \n164:   /** s0 control */\n165:   // 0,1,2,3 -> dataArray(data);
      4 -> mainPipe\n166:   // Ftq RegNext Register\n167:   private val fromFtqReq\
      \       = fromFtq.bits.pcMemRead\n168:   private val s0_valid         = fromFtq.valid\n\
      169:   private val s0_req_valid_all = (0 until partWayNum + 1).map(i => fromFtq.bits.readValid(i))\n\
      170:   private val s0_req_vaddr_all =\n171:     (0 until partWayNum + 1).map(i
      => VecInit(Seq(fromFtqReq(i).startAddr, fromFtqReq(i).nextlineStart)))\n172:\
      \   private val s0_req_vSetIdx_all = (0 until partWayNum + 1).map(i => VecInit(s0_req_vaddr_all(i).map(get_idx)))\n\
      173:   private val s0_req_offset_all = (0 until partWayNum + 1).map(i => s0_req_vaddr_all(i)(0)(log2Ceil(blockBytes)
      - 1, 0))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 183-193
    context: "183:   /**\n184:     ******************************************************************************\n\
      185:     * get waymask and tlb info from wayLookup\n186:     ******************************************************************************\n\
      187:     */\n188:   fromWayLookup.ready := s0_fire\n189:   private val s0_waymasks\
      \              = VecInit(fromWayLookup.bits.waymask.map(_.asTypeOf(Vec(nWays,
      Bool()))))\n190:   private val s0_req_ptags             = fromWayLookup.bits.ptag\n\
      191:   private val s0_req_gpaddr            = fromWayLookup.bits.gpaddr\n192:\
      \   private val s0_req_isForVSnonLeafPTE = fromWayLookup.bits.isForVSnonLeafPTE\n\
      193:   private val s0_itlb_exception        = fromWayLookup.bits.itlb_exception"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 189-199
    context: "189:   private val s0_waymasks              = VecInit(fromWayLookup.bits.waymask.map(_.asTypeOf(Vec(nWays,
      Bool()))))\n190:   private val s0_req_ptags             = fromWayLookup.bits.ptag\n\
      191:   private val s0_req_gpaddr            = fromWayLookup.bits.gpaddr\n192:\
      \   private val s0_req_isForVSnonLeafPTE = fromWayLookup.bits.isForVSnonLeafPTE\n\
      193:   private val s0_itlb_exception        = fromWayLookup.bits.itlb_exception\n\
      194:   private val s0_itlb_pbmt             = fromWayLookup.bits.itlb_pbmt\n\
      195:   private val s0_meta_codes            = fromWayLookup.bits.meta_codes\n\
      196:   private val s0_hits                  = VecInit(fromWayLookup.bits.waymask.map(_.orR))\n\
      197: \n198:   when(s0_fire) {\n199:     assert("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 210-220
    context: "210:   /**\n211:     ******************************************************************************\n\
      212:     * data SRAM request\n213:     ******************************************************************************\n\
      214:     */\n215:   (0 until partWayNum).foreach { i =>\n216:     toData(i).valid\
      \             := s0_req_valid_all(i)\n217:     toData(i).bits.isDoubleLine :=
      s0_doubleline_all(i)\n218:     toData(i).bits.vSetIdx      := s0_req_vSetIdx_all(i)\n\
      219:     toData(i).bits.blkOffset    := s0_req_offset_all(i)\n220:     toData(i).bits.waymask\
      \      := s0_waymasks"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 218-232
    context: "218:     toData(i).bits.vSetIdx      := s0_req_vSetIdx_all(i)\n219:\
      \     toData(i).bits.blkOffset    := s0_req_offset_all(i)\n220:     toData(i).bits.waymask\
      \      := s0_waymasks\n221:   }\n222: \n223:   private val s0_can_go = toData.last.ready
      && fromWayLookup.valid && s1_ready\n224:   s0_flush := io.flush\n225:   s0_fire\
      \  := s0_valid && s0_can_go && !s0_flush\n226: \n227:   fromFtq.ready := s0_can_go\n\
      228: \n229:   /**\n230:     ******************************************************************************\n\
      231:     * ICache Stage 1\n232:     * - PMP check"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 232-243
    context: "232:     * - PMP check\n233:     * - get Data SRAM read responses (latched
      for pipeline stop)\n234:     * - monitor missUint response port\n235:     ******************************************************************************\n\
      236:     */\n237:   private val s1_valid =\n238:     generatePipeControl(lastFire
      = s0_fire, thisFire = s1_fire, thisFlush = s1_flush, lastFlush = false.B)\n\
      239: \n240:   private val s1_req_vaddr  = RegEnable(s0_req_vaddr, 0.U.asTypeOf(s0_req_vaddr),
      s0_fire)\n241:   private val s1_req_ptags  = RegEnable(s0_req_ptags, 0.U.asTypeOf(s0_req_ptags),
      s0_fire)\n242:   private val s1_req_gpaddr = RegEnable(s0_req_gpaddr, 0.U.asTypeOf(s0_req_gpaddr),
      s0_fire)\n243:   private val s1_req_isForVSnonLeafPTE ="
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 244-254
    context: "244:     RegEnable(s0_req_isForVSnonLeafPTE, 0.U.asTypeOf(s0_req_isForVSnonLeafPTE),
      s0_fire)\n245:   private val s1_doubleline       = RegEnable(s0_doubleline,
      0.U.asTypeOf(s0_doubleline), s0_fire)\n246:   private val s1_SRAMhits      \
      \   = RegEnable(s0_hits, 0.U.asTypeOf(s0_hits), s0_fire)\n247:   private val
      s1_itlb_exception   = RegEnable(s0_itlb_exception, 0.U.asTypeOf(s0_itlb_exception),
      s0_fire)\n248:   private val s1_backendException = RegEnable(s0_backendException,
      false.B, s0_fire)\n249:   private val s1_itlb_pbmt        = RegEnable(s0_itlb_pbmt,
      0.U.asTypeOf(s0_itlb_pbmt), s0_fire)\n250:   private val s1_waymasks       \
      \  = RegEnable(s0_waymasks, 0.U.asTypeOf(s0_waymasks), s0_fire)\n251:   private
      val s1_meta_codes       = RegEnable(s0_meta_codes, 0.U.asTypeOf(s0_meta_codes),
      s0_fire)\n252: \n253:   private val s1_req_vSetIdx = s1_req_vaddr.map(get_idx)\n\
      254:   private val s1_req_paddr   = getPaddrFromPtag(s1_req_vaddr, s1_req_ptags)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 275-285
    context: "275:   /**\n276:     ******************************************************************************\n\
      277:     * update replacement status register\n278:     ******************************************************************************\n\
      279:     */\n280:   (0 until PortNumber).foreach { i =>\n281:     io.touch(i).bits.vSetIdx
      := s1_req_vSetIdx(i)\n282:     io.touch(i).bits.way     := OHToUInt(s1_waymasks(i))\n\
      283:   }\n284:   io.touch(0).valid := RegNext(s0_fire) && s1_SRAMhits(0)\n285:\
      \   io.touch(1).valid := RegNext(s0_fire) && s1_SRAMhits(1) && s1_doubleline"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 287-299
    context: "287:   /**\n288:     ******************************************************************************\n\
      289:     * PMP check\n290:     ******************************************************************************\n\
      291:     */\n292:   toPMP.zipWithIndex.foreach { case (p, i) =>\n293:     //
      if itlb has exception, paddr can be invalid, therefore pmp check can be skipped
      do not do this now for timing\n294:     p.valid     := s1_valid // && !ExceptionType.hasException(s1_itlb_exception(i))\n\
      295:     p.bits.addr := s1_req_paddr(i)\n296:     p.bits.size := 3.U\n297: \
      \    p.bits.cmd  := TlbCmd.exec\n298:   }\n299:   private val s1_pmp_exception
      = VecInit(fromPMP.map(ExceptionType.fromPMPResp))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 295-305
    context: "295:     p.bits.addr := s1_req_paddr(i)\n296:     p.bits.size := 3.U\n\
      297:     p.bits.cmd  := TlbCmd.exec\n298:   }\n299:   private val s1_pmp_exception
      = VecInit(fromPMP.map(ExceptionType.fromPMPResp))\n300:   private val s1_pmp_mmio\
      \      = VecInit(fromPMP.map(_.mmio))\n301: \n302:   // merge s1 itlb/pmp exceptions,
      itlb has the highest priority, pmp next\n303:   private val s1_exception_out
      = ExceptionType.merge(\n304:     s1_itlb_exception,\n305:     s1_pmp_exception"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 313-327
    context: "313:   private val s1_MSHR_match = VecInit((0 until PortNumber).map
      { i =>\n314:     (s1_req_vSetIdx(i) === fromMSHR.bits.vSetIdx) &&\n315:    \
      \ (s1_req_ptags(i) === getPhyTagFromBlk(fromMSHR.bits.blkPaddr)) &&\n316:  \
      \   fromMSHR.valid && !fromMSHR.bits.corrupt\n317:   })\n318:   private val
      s1_MSHR_hits  = Seq(s1_valid && s1_MSHR_match(0), s1_valid && (s1_MSHR_match(1)
      && s1_doubleline))\n319:   private val s1_MSHR_datas = fromMSHR.bits.data.asTypeOf(Vec(ICacheDataBanks,
      UInt((blockBits / ICacheDataBanks).W)))\n320: \n321:   private val s1_hits =
      (0 until PortNumber).map { i =>\n322:     ValidHoldBypass(s1_MSHR_hits(i) ||
      (RegNext(s0_fire) && s1_SRAMhits(i)), s1_fire || s1_flush)\n323:   }\n324: \n\
      325:   private val s1_bankIdxLow = (s1_req_offset >> log2Ceil(blockBytes / ICacheDataBanks)).asUInt\n\
      326:   private val s1_bankMSHRHit = VecInit((0 until ICacheDataBanks).map {
      i =>\n327:     (i.U >= s1_bankIdxLow) && s1_MSHR_hits(0) ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 333-345
    context: "333:   private val s1_data_is_from_MSHR = VecInit((0 until ICacheDataBanks).map
      { i =>\n334:     DataHoldBypass(s1_bankMSHRHit(i), s1_bankMSHRHit(i) || RegNext(s0_fire))\n\
      335:   })\n336:   private val s1_codes = DataHoldBypass(fromData.codes, RegNext(s0_fire))\n\
      337: \n338:   s1_flush := io.flush\n339:   s1_ready := s2_ready || !s1_valid\n\
      340:   s1_fire  := s1_valid && s2_ready && !s1_flush\n341: \n342:   /**\n343:\
      \     ******************************************************************************\n\
      344:     * ICache Stage 2\n345:     * - send request to MSHR if ICache miss"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 346-357
    context: "346:     * - monitor missUint response port\n347:     * - response to
      IFU\n348:     ******************************************************************************\n\
      349:     */\n350: \n351:   private val s2_valid =\n352:     generatePipeControl(lastFire
      = s1_fire, thisFire = s2_fire, thisFlush = s2_flush, lastFlush = false.B)\n\
      353: \n354:   private val s2_req_vaddr  = RegEnable(s1_req_vaddr, 0.U.asTypeOf(s1_req_vaddr),
      s1_fire)\n355:   private val s2_req_ptags  = RegEnable(s1_req_ptags, 0.U.asTypeOf(s1_req_ptags),
      s1_fire)\n356:   private val s2_req_gpaddr = RegEnable(s1_req_gpaddr, 0.U.asTypeOf(s1_req_gpaddr),
      s1_fire)\n357:   private val s2_req_isForVSnonLeafPTE ="
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 358-368
    context: "358:     RegEnable(s1_req_isForVSnonLeafPTE, 0.U.asTypeOf(s1_req_isForVSnonLeafPTE),
      s1_fire)\n359:   private val s2_doubleline       = RegEnable(s1_doubleline,
      0.U.asTypeOf(s1_doubleline), s1_fire)\n360:   private val s2_exception     \
      \   = RegEnable(s1_exception_out, 0.U.asTypeOf(s1_exception_out), s1_fire)\n\
      361:   private val s2_backendException = RegEnable(s1_backendException, false.B,
      s1_fire)\n362:   private val s2_pmp_mmio         = RegEnable(s1_pmp_mmio, 0.U.asTypeOf(s1_pmp_mmio),
      s1_fire)\n363:   private val s2_itlb_pbmt        = RegEnable(s1_itlb_pbmt, 0.U.asTypeOf(s1_itlb_pbmt),
      s1_fire)\n364:   private val s2_waymasks         = RegEnable(s1_waymasks, 0.U.asTypeOf(s1_waymasks),
      s1_fire)\n365: \n366:   private val s2_req_vSetIdx = s2_req_vaddr.map(get_idx)\n\
      367:   private val s2_req_offset  = s2_req_vaddr(0)(log2Ceil(blockBytes) - 1,
      0)\n368:   private val s2_req_paddr   = getPaddrFromPtag(s2_req_vaddr, s2_req_ptags)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 377-387
    context: "377:     ******************************************************************************\n\
      378:     * ECC check\n379:     ******************************************************************************\n\
      380:     */\n381:   // check data error\n382:   private val s2_bankSel     \
      \ = getBankSel(s2_req_offset, s2_valid)\n383:   private val s2_bank_corrupt
      = (0 until ICacheDataBanks).map(i => encodeDataECC(s2_datas(i)) =/= s2_codes(i))\n\
      384:   // if data is from MSHR, we don't need to check ECC\n385:   private val
      s2_data_corrupt = VecInit((0 until PortNumber).map { port =>\n386:     (0 until
      ICacheDataBanks).map { bank =>\n387:       s2_bank_corrupt(bank) && s2_bankSel(port)(bank).asBool
      && !s2_data_is_from_MSHR(bank)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 405-415
    context: "405:     \"meta or data corrupt detected on line 1 but s2_doubleline
      is false.B\"\n406:   )\n407: \n408:   // send errors to top\n409:   // TODO:
      support RERI spec standard interface\n410:   (0 until PortNumber).foreach {
      i =>\n411:     io.errors(i).valid              := (s2_meta_corrupt(i) || s2_data_corrupt(i))
      && RegNext(s1_fire)\n412:     io.errors(i).bits.report_to_beu := (s2_meta_corrupt(i)
      || s2_data_corrupt(i)) && RegNext(s1_fire)\n413:     io.errors(i).bits.paddr\
      \         := s2_req_paddr(i)\n414:     io.errors(i).bits.source        := DontCare\n\
      415:     io.errors(i).bits.source.tag    := s2_meta_corrupt(i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 417-432
    context: "417:     io.errors(i).bits.source.l2     := false.B\n418:     io.errors(i).bits.opType\
      \        := DontCare\n419:     io.errors(i).bits.opType.fetch  := true.B\n420:\
      \   }\n421:   // flush metaArray to prepare for re-fetch\n422:   (0 until PortNumber).foreach
      { i =>\n423:     toMetaFlush(i).valid       := (s2_meta_corrupt(i) || s2_data_corrupt(i))
      && RegNext(s1_fire)\n424:     toMetaFlush(i).bits.virIdx := s2_req_vSetIdx(i)\n\
      425:     // if is meta corrupt, clear all way (since waymask may be unreliable)\n\
      426:     // if is data corrupt, only clear the way that has error\n427:    \
      \ toMetaFlush(i).bits.waymask := Mux(s2_meta_corrupt(i), Fill(nWays, true.B),
      s2_waymasks(i).asUInt)\n428:   }\n429:   // PERF: count the number of data parity
      errors\n430:   XSPerfAccumulate(\"data_corrupt_0\", s2_data_corrupt(0) && RegNext(s1_fire))\n\
      431:   XSPerfAccumulate(\"data_corrupt_1\", s2_data_corrupt(1) && RegNext(s1_fire))\n\
      432:   XSPerfAccumulate(\"meta_corrupt_0\", s2_meta_corrupt(0) && RegNext(s1_fire))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 445-455
    context: "445:   private val s2_MSHR_match = VecInit((0 until PortNumber).map
      { i =>\n446:     (s2_req_vSetIdx(i) === fromMSHR.bits.vSetIdx) &&\n447:    \
      \ (s2_req_ptags(i) === getPhyTagFromBlk(fromMSHR.bits.blkPaddr)) &&\n448:  \
      \   fromMSHR.valid // we don't care about whether it's corrupt here\n449:  \
      \ })\n450:   private val s2_MSHR_hits  = Seq(s2_valid && s2_MSHR_match(0), s2_valid
      && s2_MSHR_match(1) && s2_doubleline)\n451:   private val s2_MSHR_datas = fromMSHR.bits.data.asTypeOf(Vec(ICacheDataBanks,
      UInt((blockBits / ICacheDataBanks).W)))\n452: \n453:   private val s2_bankIdxLow
      = (s2_req_offset >> log2Ceil(blockBytes / ICacheDataBanks)).asUInt\n454:   private
      val s2_bankMSHRHit = VecInit((0 until ICacheDataBanks).map { i =>\n455:    \
      \ ((i.U >= s2_bankIdxLow) && s2_MSHR_hits(0)) || ((i.U < s2_bankIdxLow) && s2_MSHR_hits(1))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 453-463
    context: "453:   private val s2_bankIdxLow = (s2_req_offset >> log2Ceil(blockBytes
      / ICacheDataBanks)).asUInt\n454:   private val s2_bankMSHRHit = VecInit((0 until
      ICacheDataBanks).map { i =>\n455:     ((i.U >= s2_bankIdxLow) && s2_MSHR_hits(0))
      || ((i.U < s2_bankIdxLow) && s2_MSHR_hits(1))\n456:   })\n457: \n458:   (0 until
      ICacheDataBanks).foreach { i =>\n459:     when(s1_fire) {\n460:       s2_datas\
      \             := s1_datas\n461:       s2_data_is_from_MSHR := s1_data_is_from_MSHR\n\
      462:     }.elsewhen(s2_bankMSHRHit(i)) {\n463:       s2_datas(i) := s2_MSHR_datas(i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 464-474
    context: "464:       // also update s2_data_is_from_MSHR when re-fetched, to clear
      s2_data_corrupt flag and let s2_fire\n465:       s2_data_is_from_MSHR(i) :=
      true.B\n466:     }\n467:   }\n468: \n469:   (0 until PortNumber).foreach { i
      =>\n470:     when(s1_fire) {\n471:       s2_hits := s1_hits\n472:     }.elsewhen(s2_MSHR_hits(i))
      {\n473:       // update s2_hits even if it's corrupt, to let s2_fire\n474: \
      \      s2_hits(i) := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 476-486
    context: "476:       s2_meta_corrupt(i) := false.B\n477:     }\n478:   }\n479:\
      \ \n480:   private val s2_l2_corrupt = RegInit(VecInit(Seq.fill(PortNumber)(false.B)))\n\
      481:   (0 until PortNumber).foreach { i =>\n482:     when(s1_fire) {\n483: \
      \      s2_l2_corrupt(i) := false.B\n484:     }.elsewhen(s2_MSHR_hits(i)) {\n\
      485:       s2_l2_corrupt(i) := fromMSHR.bits.corrupt\n486:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 491-502
    context: "491:     * send request to MSHR if ICache miss / ECC corrupt\n492: \
      \    ******************************************************************************\n\
      493:     */\n494: \n495:   // merge pmp mmio and itlb pbmt\n496:   private val
      s2_mmio = VecInit((s2_pmp_mmio zip s2_itlb_pbmt).map { case (mmio, pbmt) =>\n\
      497:     mmio || Pbmt.isUncache(pbmt)\n498:   })\n499: \n500:   // try re-fetch
      data from L2 cache if ECC error is detected, unless it's from MSHR\n501:   private
      val s2_corrupt_refetch = (s2_meta_corrupt zip s2_data_corrupt).map {\n502: \
      \    case (meta, data) => meta || data"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 508-518
    context: "508:    */\n509:   private val s2_should_fetch = VecInit((0 until PortNumber).map
      { i =>\n510:     (!s2_hits(i) || s2_corrupt_refetch(i)) &&\n511:     (if (i
      == 0) true.B else s2_doubleline) &&\n512:     !ExceptionType.hasException(s2_exception.take(i
      + 1)) &&\n513:     s2_mmio.take(i + 1).map(!_).reduce(_ && _)\n514:   })\n515:\
      \ \n516:   private val toMSHRArbiter = Module(new Arbiter(new ICacheMissReq,
      PortNumber))\n517: \n518:   // To avoid sending duplicate requests."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 515-534
    context: "515: \n516:   private val toMSHRArbiter = Module(new Arbiter(new ICacheMissReq,
      PortNumber))\n517: \n518:   // To avoid sending duplicate requests.\n519:  \
      \ private val s2_has_send = RegInit(VecInit(Seq.fill(PortNumber)(false.B)))\n\
      520:   (0 until PortNumber).foreach { i =>\n521:     when(s1_fire) {\n522: \
      \      s2_has_send(i) := false.B\n523:     }.elsewhen(toMSHRArbiter.io.in(i).fire)
      {\n524:       s2_has_send(i) := true.B\n525:     }\n526:   }\n527: \n528:  \
      \ (0 until PortNumber).foreach { i =>\n529:     toMSHRArbiter.io.in(i).valid\
      \         := s2_valid && s2_should_fetch(i) && !s2_has_send(i) && !s2_flush\n\
      530:     toMSHRArbiter.io.in(i).bits.blkPaddr := getBlkAddr(s2_req_paddr(i))\n\
      531:     toMSHRArbiter.io.in(i).bits.vSetIdx  := s2_req_vSetIdx(i)\n532:   }\n\
      533:   toMSHR <> toMSHRArbiter.io.out\n534: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 530-540
    context: "530:     toMSHRArbiter.io.in(i).bits.blkPaddr := getBlkAddr(s2_req_paddr(i))\n\
      531:     toMSHRArbiter.io.in(i).bits.vSetIdx  := s2_req_vSetIdx(i)\n532:   }\n\
      533:   toMSHR <> toMSHRArbiter.io.out\n534: \n535:   XSPerfAccumulate(\"to_missUnit_stall\"\
      , toMSHR.valid && !toMSHR.ready)\n536: \n537:   private val s2_fetch_finish
      = !s2_should_fetch.reduce(_ || _)\n538: \n539:   // also raise af if l2 corrupt
      is detected\n540:   private val s2_l2_exception = VecInit(s2_l2_corrupt.map(ExceptionType.fromTilelink))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 540-550
    context: "540:   private val s2_l2_exception = VecInit(s2_l2_corrupt.map(ExceptionType.fromTilelink))\n\
      541:   // NOTE: do NOT raise af if meta/data corrupt is detected, they are automatically
      recovered by re-fetching from L2\n542: \n543:   // merge s2 exceptions, itlb
      has the highest priority, then l2\n544:   private val s2_exception_out = ExceptionType.merge(\n\
      545:     s2_exception, // includes itlb/pmp exception\n546:     s2_l2_exception\n\
      547:   )\n548: \n549:   /**\n550:     ******************************************************************************"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 553-563
    context: "553:     */\n554:   toIFU.valid                 := s2_fire\n555:   toIFU.bits.doubleline\
      \       := s2_doubleline\n556:   toIFU.bits.data             := s2_datas.asTypeOf(UInt(blockBits.W))\n\
      557:   toIFU.bits.backendException := s2_backendException\n558:   (0 until PortNumber).foreach
      { i =>\n559:     toIFU.bits.vaddr(i) := s2_req_vaddr(i)\n560:     toIFU.bits.paddr(i)
      := s2_req_paddr(i)\n561:     val needThisLine = if (i == 0) true.B else s2_doubleline\n\
      562:     toIFU.bits.exception(i) := Mux(needThisLine, s2_exception_out(i), ExceptionType.none)\n\
      563:     toIFU.bits.pmp_mmio(i)  := Mux(needThisLine, s2_pmp_mmio(i), false.B)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 559-569
    context: "559:     toIFU.bits.vaddr(i) := s2_req_vaddr(i)\n560:     toIFU.bits.paddr(i)
      := s2_req_paddr(i)\n561:     val needThisLine = if (i == 0) true.B else s2_doubleline\n\
      562:     toIFU.bits.exception(i) := Mux(needThisLine, s2_exception_out(i), ExceptionType.none)\n\
      563:     toIFU.bits.pmp_mmio(i)  := Mux(needThisLine, s2_pmp_mmio(i), false.B)\n\
      564:     toIFU.bits.itlb_pbmt(i) := Mux(needThisLine, s2_itlb_pbmt(i), Pbmt.pma)\n\
      565:   }\n566:   // valid only for the first gpf\n567:   toIFU.bits.gpaddr \
      \           := s2_req_gpaddr\n568:   toIFU.bits.isForVSnonLeafPTE := s2_req_isForVSnonLeafPTE\n\
      569: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 565-577
    context: "565:   }\n566:   // valid only for the first gpf\n567:   toIFU.bits.gpaddr\
      \            := s2_req_gpaddr\n568:   toIFU.bits.isForVSnonLeafPTE := s2_req_isForVSnonLeafPTE\n\
      569: \n570:   s2_flush := io.flush\n571:   s2_ready := (s2_fetch_finish && !io.respStall)
      || !s2_valid\n572:   s2_fire  := s2_valid && s2_fetch_finish && !io.respStall
      && !s2_flush\n573: \n574:   /**\n575:     ******************************************************************************\n\
      576:     * report Tilelink corrupt error\n577:     ******************************************************************************"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 574-584
    context: "574:   /**\n575:     ******************************************************************************\n\
      576:     * report Tilelink corrupt error\n577:     ******************************************************************************\n\
      578:     */\n579:   (0 until PortNumber).foreach { i =>\n580:     when(RegNext(s2_fire
      && s2_l2_corrupt(i))) {\n581:       io.errors(i).valid              := true.B\n\
      582:       io.errors(i).bits.report_to_beu := false.B // l2 should have report
      that to bus error unit, no need to do it again\n583:       io.errors(i).bits.paddr\
      \         := RegNext(s2_req_paddr(i))\n584:       io.errors(i).bits.source.tag\
      \    := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 604-618
    context: "604:   io.perfInfo.bank_hit(1)     := s2_hits(1) && s2_doubleline\n\
      605:   io.perfInfo.except_0        := ExceptionType.hasException(s2_exception(0))\n\
      606:   io.perfInfo.hit             := s2_hits(0) && (!s2_doubleline || s2_hits(1))\n\
      607: \n608:   /** <PERF> fetch bubble generated by icache miss */\n609:   XSPerfAccumulate(\"\
      icache_bubble_s2_miss\", s2_valid && !s2_fetch_finish)\n610:   XSPerfAccumulate(\"\
      icache_bubble_s0_wayLookup\", s0_valid && !fromWayLookup.ready)\n611: \n612:\
      \   io.fetch.topdownIcacheMiss := !s2_fetch_finish\n613:   io.fetch.topdownItlbMiss\
      \   := s0_valid && !fromWayLookup.ready\n614: \n615:   // class ICacheTouchDB(implicit
      p: Parameters) extends ICacheBundle{\n616:   //   val blkPaddr  = UInt((PAddrBits
      - blockOffBits).W)\n617:   //   val vSetIdx   = UInt(idxBits.W)\n618:   // \
      \  val waymask   = UInt(wayBits.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheMainPipe.scala
    lines: 644-662
    context: "644:     */\n645:   if (env.EnableDifftest) {\n646:     val discards
      = (0 until PortNumber).map { i =>\n647:       ExceptionType.hasException(toIFU.bits.exception(i))
      ||\n648:       toIFU.bits.pmp_mmio(i) ||\n649:       Pbmt.isUncache(toIFU.bits.itlb_pbmt(i))\n\
      650:     }\n651:     val blkPaddrAll = s2_req_paddr.map(addr => (addr(PAddrBits
      - 1, blockOffBits) << blockOffBits).asUInt)\n652:     (0 until ICacheDataBanks).foreach
      { i =>\n653:       val diffMainPipeOut = DifftestModule(new DiffRefillEvent,
      dontCare = true)\n654:       diffMainPipeOut.coreid := io.hartId\n655:     \
      \  diffMainPipeOut.index  := (3 + i).U\n656: \n657:       val bankSel = getBankSel(s2_req_offset,
      s2_valid).reduce(_ | _)\n658:       val lineSel = getLineSel(s2_req_offset)\n\
      659: \n660:       diffMainPipeOut.valid := s2_fire && bankSel(i).asBool && Mux(lineSel(i),
      !discards(1), !discards(0))\n661:       diffMainPipeOut.addr := Mux(\n662: \
      \        lineSel(i),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/WayLookup.scala
    lines: 19-29
    context: "19: \n20: import chisel3._\n21: import chisel3.util._\n22: import org.chipsalliance.cde.config.Parameters\n\
      23: import utility._\n24: import xiangshan.cache.mmu.Pbmt\n25: import xiangshan.frontend.ExceptionType\n\
      26: \n27: /* WayLookupEntry is for internal storage, while WayLookupInfo is
      for interface\n28:  * Notes:\n29:  *   1. there must be a flush (caused by guest
      page fault) after excp_tlb_gpf === true.B,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/WayLookup.scala
    lines: 33-43
    context: "33: class WayLookupEntry(implicit p: Parameters) extends ICacheBundle
      {\n34:   val vSetIdx:        Vec[UInt] = Vec(PortNumber, UInt(idxBits.W))\n\
      35:   val waymask:        Vec[UInt] = Vec(PortNumber, UInt(nWays.W))\n36:  \
      \ val ptag:           Vec[UInt] = Vec(PortNumber, UInt(tagBits.W))\n37:   val
      itlb_exception: Vec[UInt] = Vec(PortNumber, UInt(ExceptionType.width.W))\n38:\
      \   val itlb_pbmt:      Vec[UInt] = Vec(PortNumber, UInt(Pbmt.width.W))\n39:\
      \   val meta_codes:     Vec[UInt] = Vec(PortNumber, UInt(ICacheMetaCodeBits.W))\n\
      40: }\n41: \n42: class WayLookupGPFEntry(implicit p: Parameters) extends ICacheBundle
      {\n43:   // NOTE: we don't use GPAddrBits here, refer to ICacheMainPipe.scala
      L43-48 and PR#3795"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/WayLookup.scala
    lines: 52-62
    context: "52:   // for compatibility\n53:   def vSetIdx:           Vec[UInt] =
      entry.vSetIdx\n54:   def waymask:           Vec[UInt] = entry.waymask\n55: \
      \  def ptag:              Vec[UInt] = entry.ptag\n56:   def itlb_exception:\
      \    Vec[UInt] = entry.itlb_exception\n57:   def itlb_pbmt:         Vec[UInt]
      = entry.itlb_pbmt\n58:   def meta_codes:        Vec[UInt] = entry.meta_codes\n\
      59:   def gpaddr:            UInt      = gpf.gpaddr\n60:   def isForVSnonLeafPTE:
      Bool      = gpf.isForVSnonLeafPTE\n61: }\n62: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/WayLookup.scala
    lines: 59-70
    context: "59:   def gpaddr:            UInt      = gpf.gpaddr\n60:   def isForVSnonLeafPTE:
      Bool      = gpf.isForVSnonLeafPTE\n61: }\n62: \n63: class WayLookupInterface(implicit
      p: Parameters) extends ICacheBundle {\n64:   val flush:  Bool              \
      \         = Input(Bool())\n65:   val read:   DecoupledIO[WayLookupInfo] = DecoupledIO(new
      WayLookupInfo)\n66:   val write:  DecoupledIO[WayLookupInfo] = Flipped(DecoupledIO(new
      WayLookupInfo))\n67:   val update: Valid[ICacheMissResp]      = Flipped(ValidIO(new
      ICacheMissResp))\n68: }\n69: \n70: class WayLookup(implicit p: Parameters) extends
      ICacheModule with HasICacheECCHelper {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/WayLookup.scala
    lines: 79-113
    context: "79:       ptr\n80:     }\n81:   }\n82: \n83:   private val entries \
      \ = RegInit(VecInit(Seq.fill(nWayLookupSize)(0.U.asTypeOf(new WayLookupEntry))))\n\
      84:   private val readPtr  = RegInit(WayLookupPtr(false.B, 0.U))\n85:   private
      val writePtr = RegInit(WayLookupPtr(false.B, 0.U))\n86: \n87:   private val
      empty = readPtr === writePtr\n88:   private val full  = (readPtr.value === writePtr.value)
      && (readPtr.flag ^ writePtr.flag)\n89: \n90:   when(io.flush) {\n91:     writePtr.value
      := 0.U\n92:     writePtr.flag  := false.B\n93:   }.elsewhen(io.write.fire) {\n\
      94:     writePtr := writePtr + 1.U\n95:   }\n96: \n97:   when(io.flush) {\n\
      98:     readPtr.value := 0.U\n99:     readPtr.flag  := false.B\n100:   }.elsewhen(io.read.fire)
      {\n101:     readPtr := readPtr + 1.U\n102:   }\n103: \n104:   private val gpf_entry
      = RegInit(0.U.asTypeOf(Valid(new WayLookupGPFEntry)))\n105:   private val gpfPtr\
      \    = RegInit(WayLookupPtr(false.B, 0.U))\n106:   private val gpf_hit   = gpfPtr
      === readPtr && gpf_entry.valid\n107: \n108:   when(io.flush) {\n109:     //
      we don't need to reset gpfPtr, since the valid is actually gpf_entries.excp_tlb_gpf\n\
      110:     gpf_entry.valid := false.B\n111:     gpf_entry.bits  := 0.U.asTypeOf(new
      WayLookupGPFEntry)\n112:   }\n113: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/WayLookup.scala
    lines: 115-127
    context: "115:     ******************************************************************************\n\
      116:     * update\n117:     ******************************************************************************\n\
      118:     */\n119:   private val hits = Wire(Vec(nWayLookupSize, Bool()))\n120:\
      \   entries.zip(hits).foreach { case (entry, hit) =>\n121:     val hit_vec =
      Wire(Vec(PortNumber, Bool()))\n122:     (0 until PortNumber).foreach { i =>\n\
      123:       val vset_same = (io.update.bits.vSetIdx === entry.vSetIdx(i)) &&
      !io.update.bits.corrupt && io.update.valid\n124:       val ptag_same = getPhyTagFromBlk(io.update.bits.blkPaddr)
      === entry.ptag(i)\n125:       val way_same  = io.update.bits.waymask === entry.waymask(i)\n\
      126:       when(vset_same) {\n127:         when(ptag_same) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/WayLookup.scala
    lines: 147-169
    context: "147:     * read\n148:     ******************************************************************************\n\
      149:     */\n150:   // if the entry is empty, but there is a valid write, we
      can bypass it to read port (maybe timing critical)\n151:   private val can_bypass
      = empty && io.write.valid\n152:   io.read.valid := !empty || io.write.valid\n\
      153:   when(can_bypass) {\n154:     io.read.bits := io.write.bits\n155:   }.otherwise
      { // can't bypass\n156:     io.read.bits.entry := entries(readPtr.value)\n157:\
      \     when(gpf_hit) { // ptr match && entry valid\n158:       io.read.bits.gpf
      := gpf_entry.bits\n159:       // also clear gpf_entry.valid when it's read,
      note this will be overridden by write (L175)\n160:       when(io.read.fire)
      {\n161:         gpf_entry.valid := false.B\n162:       }\n163:     }.otherwise
      { // gpf not hit\n164:       io.read.bits.gpf := 0.U.asTypeOf(new WayLookupGPFEntry)\n\
      165:     }\n166:   }\n167: \n168:   /**\n169:     ******************************************************************************"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/WayLookup.scala
    lines: 169-186
    context: "169:     ******************************************************************************\n\
      170:     * write\n171:     ******************************************************************************\n\
      172:     */\n173:   // if there is a valid gpf to be read, we should stall write\n\
      174:   private val gpf_stall = gpf_entry.valid && !(io.read.fire && gpf_hit)\n\
      175:   io.write.ready := !full && !gpf_stall\n176:   when(io.write.fire) {\n\
      177:     entries(writePtr.value) := io.write.bits.entry\n178:     when(io.write.bits.itlb_exception.map(_
      === ExceptionType.gpf).reduce(_ || _)) {\n179:       // if gpf_entry is bypassed,
      we don't need to save it\n180:       // note this will override the read (L156)\n\
      181:       gpf_entry.valid := !(can_bypass && io.read.fire)\n182:       gpf_entry.bits\
      \  := io.write.bits.gpf\n183:       gpfPtr          := writePtr\n184:     }\n\
      185:   }\n186: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/InstrUncache.scala
    lines: 42-60
    context: "42:   val data:    UInt = UInt(maxInstrLen.W)\n43:   val corrupt: Bool
      = Bool()\n44: }\n45: \n46: class InstrMMIOEntryIO(edge: TLEdgeOut)(implicit
      p: Parameters) extends ICacheBundle {\n47:   val id: UInt = Input(UInt(log2Up(cacheParams.nMMIOs).W))\n\
      48:   // client requests\n49:   val req:  DecoupledIO[InsUncacheReq]  = Flipped(DecoupledIO(new
      InsUncacheReq))\n50:   val resp: DecoupledIO[InsUncacheResp] = DecoupledIO(new
      InsUncacheResp)\n51: \n52:   val mmio_acquire: DecoupledIO[TLBundleA] = DecoupledIO(new
      TLBundleA(edge.bundle))\n53:   val mmio_grant:   DecoupledIO[TLBundleD] = Flipped(DecoupledIO(new
      TLBundleD(edge.bundle)))\n54: \n55:   val flush: Bool         = Input(Bool())\n\
      56:   val wfi:   WfiReqBundle = Flipped(new WfiReqBundle)\n57: }\n58: \n59:
      // One miss entry deals with one mmio request\n60: class InstrMMIOEntry(edge:
      TLEdgeOut)(implicit p: Parameters) extends ICacheModule with HasIFUConst {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/InstrUncache.scala
    lines: 60-70
    context: "60: class InstrMMIOEntry(edge: TLEdgeOut)(implicit p: Parameters) extends
      ICacheModule with HasIFUConst {\n61:   val io: InstrMMIOEntryIO = IO(new InstrMMIOEntryIO(edge))\n\
      62: \n63:   private val s_invalid :: s_refill_req :: s_refill_resp :: s_send_resp
      :: Nil = Enum(4)\n64: \n65:   private val state = RegInit(s_invalid)\n66: \n\
      67:   private val req            = Reg(new InsUncacheReq)\n68:   private val
      respDataReg    = RegInit(0.U(mmioBusWidth.W))\n69:   private val respCorruptReg
      = RegInit(false.B)\n70: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/InstrUncache.scala
    lines: 67-127
    context: "67:   private val req            = Reg(new InsUncacheReq)\n68:   private
      val respDataReg    = RegInit(0.U(mmioBusWidth.W))\n69:   private val respCorruptReg
      = RegInit(false.B)\n70: \n71:   // assign default values to output signals\n\
      72:   io.req.ready  := false.B\n73:   io.resp.valid := false.B\n74:   io.resp.bits\
      \  := DontCare\n75: \n76:   io.mmio_acquire.valid := false.B\n77:   io.mmio_acquire.bits\
      \  := DontCare\n78: \n79:   io.mmio_grant.ready := false.B\n80: \n81:   // we
      are safe to enter wfi if we have no pending response from L2\n82:   io.wfi.wfiSafe
      := state =/= s_refill_resp\n83: \n84:   private val needFlush = RegInit(false.B)\n\
      85: \n86:   when(io.flush && (state =/= s_invalid) && (state =/= s_send_resp))(needFlush
      := true.B)\n87:     .elsewhen((state === s_send_resp) && needFlush)(needFlush
      := false.B)\n88: \n89:   // --------------------------------------------\n90:\
      \   // s_invalid: receive requests\n91:   when(state === s_invalid) {\n92: \
      \    io.req.ready := true.B\n93: \n94:     when(io.req.fire) {\n95:       req\
      \   := io.req.bits\n96:       state := s_refill_req\n97:     }\n98:   }\n99:\
      \ \n100:   when(state === s_refill_req) {\n101:     val address_aligned = req.addr(req.addr.getWidth
      - 1, log2Ceil(mmioBusBytes))\n102:     io.mmio_acquire.valid := !io.wfi.wfiReq
      // if there is a pending wfi request, we should not send new requests to L2\n\
      103:     io.mmio_acquire.bits := edge.Get(\n104:       fromSource = io.id,\n\
      105:       toAddress = Cat(address_aligned, 0.U(log2Ceil(mmioBusBytes).W)),\n\
      106:       lgSize = log2Ceil(mmioBusBytes).U\n107:     )._2\n108: \n109:   \
      \  when(io.mmio_acquire.fire) {\n110:       state := s_refill_resp\n111:   \
      \  }\n112:   }\n113: \n114:   val (_, _, refill_done, _) = edge.addr_inc(io.mmio_grant)\n\
      115: \n116:   when(state === s_refill_resp) {\n117:     io.mmio_grant.ready
      := true.B\n118: \n119:     when(io.mmio_grant.fire) {\n120:       respDataReg\
      \    := io.mmio_grant.bits.data\n121:       respCorruptReg := io.mmio_grant.bits.corrupt
      // this includes bits.denied, as tilelink spec defines\n122:       state   \
      \       := s_send_resp\n123:     }\n124:   }\n125: \n126:   private def getDataFromBus(pc:
      UInt): UInt = {\n127:     val respData = Wire(UInt(maxInstrLen.W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/InstrUncache.scala
    lines: 135-151
    context: "135:       )\n136:     )\n137:     respData\n138:   }\n139: \n140: \
      \  when(state === s_send_resp) {\n141:     io.resp.valid        := !needFlush\n\
      142:     io.resp.bits.data    := getDataFromBus(req.addr)\n143:     io.resp.bits.corrupt
      := respCorruptReg\n144:     // metadata should go with the response\n145:  \
      \   when(io.resp.fire || needFlush) {\n146:       state := s_invalid\n147: \
      \    }\n148:   }\n149: }\n150: \n151: class InstrUncacheIO(implicit p: Parameters)
      extends ICacheBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/InstrUncache.scala
    lines: 149-159
    context: "149: }\n150: \n151: class InstrUncacheIO(implicit p: Parameters) extends
      ICacheBundle {\n152:   val req:   DecoupledIO[InsUncacheReq]  = Flipped(DecoupledIO(new
      InsUncacheReq))\n153:   val resp:  DecoupledIO[InsUncacheResp] = DecoupledIO(new
      InsUncacheResp)\n154:   val flush: Bool                        = Input(Bool())\n\
      155:   val wfi:   WfiReqBundle                = Flipped(new WfiReqBundle)\n\
      156: }\n157: \n158: class InstrUncache()(implicit p: Parameters) extends LazyModule
      with HasICacheParameters {\n159:   override def shouldBeInlined: Boolean = false"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/InstrUncache.scala
    lines: 159-169
    context: "159:   override def shouldBeInlined: Boolean = false\n160: \n161:  \
      \ val clientParameters: TLMasterPortParameters = TLMasterPortParameters.v1(\n\
      162:     clients = Seq(TLMasterParameters.v1(\n163:       \"InstrUncache\",\n\
      164:       sourceId = IdRange(0, cacheParams.nMMIOs)\n165:     ))\n166:   )\n\
      167:   val clientNode: TLClientNode = TLClientNode(Seq(clientParameters))\n\
      168: \n169:   lazy val module: InstrUncacheImp = new InstrUncacheImp(this)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/InstrUncache.scala
    lines: 173-207
    context: "173:     extends LazyModuleImp(outer)\n174:     with HasICacheParameters\n\
      175:     with HasTLDump {\n176:   val io: InstrUncacheIO = IO(new InstrUncacheIO)\n\
      177: \n178:   private val (bus, edge) = outer.clientNode.out.head\n179: \n180:\
      \   private val resp_arb = Module(new Arbiter(new InsUncacheResp, cacheParams.nMMIOs))\n\
      181: \n182:   private val req          = io.req\n183:   private val resp   \
      \      = io.resp\n184:   private val mmio_acquire = bus.a\n185:   private val
      mmio_grant   = bus.d\n186: \n187:   private val entry_alloc_idx = Wire(UInt())\n\
      188:   private val req_ready       = WireInit(false.B)\n189: \n190:   // assign
      default values to output signals\n191:   bus.b.ready := false.B\n192:   bus.c.valid
      := false.B\n193:   bus.c.bits  := DontCare\n194:   bus.d.ready := false.B\n\
      195:   bus.e.valid := false.B\n196:   bus.e.bits  := DontCare\n197: \n198: \
      \  private val entries = (0 until cacheParams.nMMIOs).map { i =>\n199:     val
      entry = Module(new InstrMMIOEntry(edge))\n200: \n201:     entry.io.id    :=
      i.U(log2Up(cacheParams.nMMIOs).W)\n202:     entry.io.flush := io.flush\n203:\
      \ \n204:     entry.io.wfi.wfiReq := io.wfi.wfiReq\n205: \n206:     // entry
      req\n207:     entry.io.req.valid := (i.U === entry_alloc_idx) && req.valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/InstrUncache.scala
    lines: 205-215
    context: "205: \n206:     // entry req\n207:     entry.io.req.valid := (i.U ===
      entry_alloc_idx) && req.valid\n208:     entry.io.req.bits  := req.bits\n209:\
      \     when(i.U === entry_alloc_idx) {\n210:       req_ready := entry.io.req.ready\n\
      211:     }\n212: \n213:     // entry resp\n214:     resp_arb.io.in(i) <> entry.io.resp\n\
      215: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/InstrUncache.scala
    lines: 211-224
    context: "211:     }\n212: \n213:     // entry resp\n214:     resp_arb.io.in(i)
      <> entry.io.resp\n215: \n216:     entry.io.mmio_grant.valid := false.B\n217:\
      \     entry.io.mmio_grant.bits  := DontCare\n218:     when(mmio_grant.bits.source
      === i.U) {\n219:       entry.io.mmio_grant <> mmio_grant\n220:     }\n221: \
      \    entry\n222:   }\n223: \n224:   // override mmio_grant.ready to prevent
      x-propagation"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/InstrUncache.scala
    lines: 220-236
    context: "220:     }\n221:     entry\n222:   }\n223: \n224:   // override mmio_grant.ready
      to prevent x-propagation\n225:   mmio_grant.ready := true.B\n226: \n227:   entry_alloc_idx
      := PriorityEncoder(entries.map(m => m.io.req.ready))\n228: \n229:   req.ready
      := req_ready\n230:   resp <> resp_arb.io.out\n231: \n232:   TLArbiter.lowestFromSeq(edge,
      mmio_acquire, entries.map(_.io.mmio_acquire))\n233: \n234:   // we are safe
      to enter wfi if all entries have no pending response from L2\n235:   io.wfi.wfiSafe
      := entries.map(_.io.wfi.wfiSafe).reduce(_ && _)\n236: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 34-46
    context: "34: import utils._\n35: import xiangshan._\n36: import xiangshan.frontend._\n\
      37: \n38: class RASEntry()(implicit p: Parameters) extends XSBundle {\n39: \
      \  val retAddr = UInt(VAddrBits.W)\n40:   val ctr     = UInt(RasCtrSize.W) //
      layer of nested call functions\n41:   def =/=(that: RASEntry) = this.retAddr
      =/= that.retAddr || this.ctr =/= that.ctr\n42: }\n43: \n44: class RASPtr(implicit
      p: Parameters) extends CircularQueuePtr[RASPtr](p => p(XSCoreParamsKey).RasSpecSize)
      {}\n45: \n46: object RASPtr {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 88-98
    context: "88: }\n89: \n90: class RASDebug(implicit p: Parameters) extends XSBundle
      {\n91:   val spec_queue   = Output(Vec(RasSpecSize, new RASEntry))\n92:   val
      spec_nos     = Output(Vec(RasSpecSize, new RASPtr))\n93:   val commit_stack
      = Output(Vec(RasSize, new RASEntry))\n94: }\n95: \n96: class RAS(implicit p:
      Parameters) extends BasePredictor with HasCircularQueuePtrHelper {\n97:   override
      val meta_size = WireInit(0.U.asTypeOf(new RASMeta)).getWidth\n98: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 95-107
    context: "95: \n96: class RAS(implicit p: Parameters) extends BasePredictor with
      HasCircularQueuePtrHelper {\n97:   override val meta_size = WireInit(0.U.asTypeOf(new
      RASMeta)).getWidth\n98: \n99:   object RASEntry {\n100:     def apply(retAddr:
      UInt, ctr: UInt): RASEntry = {\n101:       val e = Wire(new RASEntry)\n102:\
      \       e.retAddr := retAddr\n103:       e.ctr     := ctr\n104:       e\n105:\
      \     }\n106:   }\n107: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 127-144
    context: "127:       val commit_push_addr  = Input(UInt(VAddrBits.W))\n128:  \
      \     val commit_meta_TOSW  = Input(new RASPtr)\n129:       // for debug purpose
      only\n130:       val commit_meta_ssp = Input(UInt(log2Up(RasSize).W))\n131:\
      \ \n132:       val redirect_valid     = Input(Bool())\n133:       val redirect_isCall\
      \    = Input(Bool())\n134:       val redirect_isRet     = Input(Bool())\n135:\
      \       val redirect_meta_ssp  = Input(UInt(log2Up(RasSize).W))\n136:      \
      \ val redirect_meta_sctr = Input(UInt(RasCtrSize.W))\n137:       val redirect_meta_TOSW
      = Input(new RASPtr)\n138:       val redirect_meta_TOSR = Input(new RASPtr)\n\
      139:       val redirect_meta_NOS  = Input(new RASPtr)\n140:       val redirect_callAddr\
      \  = Input(UInt(VAddrBits.W))\n141: \n142:       val ssp  = Output(UInt(log2Up(RasSize).W))\n\
      143:       val sctr = Output(UInt(RasCtrSize.W))\n144:       val nsp  = Output(UInt(log2Up(RasSize).W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 150-160
    context: "150:       val spec_near_overflow = Output(Bool())\n151: \n152:    \
      \   val debug = new RASDebug\n153:     })\n154: \n155:     val commit_stack
      = RegInit(VecInit(Seq.fill(RasSize)(RASEntry(0.U, 0.U))))\n156:     val spec_queue\
      \   = RegInit(VecInit(Seq.fill(rasSpecSize)(RASEntry(0.U, 0.U))))\n157:    \
      \ val spec_nos     = RegInit(VecInit(Seq.fill(rasSpecSize)(RASPtr(false.B, 0.U))))\n\
      158: \n159:     val nsp = RegInit(0.U(log2Up(rasSize).W))\n160:     val ssp
      = RegInit(0.U(log2Up(rasSize).W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 180-190
    context: "180:       }\n181:       inflightValid\n182:     }\n183: \n184:    \
      \ def getCommitTop(currentSsp: UInt) =\n185:       commit_stack(currentSsp)\n\
      186: \n187:     def getTopNos(currentTOSR: RASPtr, allowBypass: Boolean): RASPtr
      = {\n188:       val ret = Wire(new RASPtr)\n189:       if (allowBypass) {\n\
      190:         when(writeBypassValid) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 232-245
    context: "232:     def ptrDec(ptr: UInt) = ptr - 1.U\n233: \n234:     def specPtrInc(ptr:
      RASPtr) = ptr + 1.U\n235:     def specPtrDec(ptr: RASPtr) = ptr - 1.U\n236:\
      \ \n237:     when(io.redirect_valid && io.redirect_isCall) {\n238:       writeBypassValidWire
      := true.B\n239:       writeBypassValid     := true.B\n240:     }.elsewhen(io.redirect_valid)
      {\n241:       // clear current top writeBypass if doing redirect\n242:     \
      \  writeBypassValidWire := false.B\n243:       writeBypassValid     := false.B\n\
      244:     }.elsewhen(io.s2_fire) {\n245:       writeBypassValidWire := io.spec_push_valid"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 251-263
    context: "251:       writeBypassValidWire := writeBypassValid\n252:     }\n253:\
      \ \n254:     val topEntry = getTop(ssp, sctr, TOSR, TOSW, true)\n255:     val
      topNos   = getTopNos(TOSR, true)\n256:     val redirectTopEntry =\n257:    \
      \   getTop(io.redirect_meta_ssp, io.redirect_meta_sctr, io.redirect_meta_TOSR,
      io.redirect_meta_TOSW, false)\n258:     val redirectTopNos = io.redirect_meta_NOS\n\
      259:     val s3TopEntry     = getTop(io.s3_meta.ssp, io.s3_meta.sctr, io.s3_meta.TOSR,
      io.s3_meta.TOSW, false)\n260:     val s3TopNos       = io.s3_meta.NOS\n261:\
      \ \n262:     val writeEntry = Wire(new RASEntry)\n263:     val writeNos   =
      Wire(new RASPtr)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 259-282
    context: "259:     val s3TopEntry     = getTop(io.s3_meta.ssp, io.s3_meta.sctr,
      io.s3_meta.TOSR, io.s3_meta.TOSW, false)\n260:     val s3TopNos       = io.s3_meta.NOS\n\
      261: \n262:     val writeEntry = Wire(new RASEntry)\n263:     val writeNos \
      \  = Wire(new RASPtr)\n264:     writeEntry.retAddr := Mux(io.redirect_valid
      && io.redirect_isCall, io.redirect_callAddr, io.spec_push_addr)\n265:     writeEntry.ctr
      := Mux(\n266:       io.redirect_valid && io.redirect_isCall,\n267:       Mux(\n\
      268:         redirectTopEntry.retAddr === io.redirect_callAddr && redirectTopEntry.ctr
      < ctrMax,\n269:         io.redirect_meta_sctr + 1.U,\n270:         0.U\n271:\
      \       ),\n272:       Mux(topEntry.retAddr === io.spec_push_addr && topEntry.ctr
      < ctrMax, sctr + 1.U, 0.U)\n273:     )\n274: \n275:     writeNos := Mux(io.redirect_valid
      && io.redirect_isCall, io.redirect_meta_TOSR, TOSR)\n276: \n277:     when(io.spec_push_valid
      || (io.redirect_valid && io.redirect_isCall)) {\n278:       writeBypassEntry
      := writeEntry\n279:       writeBypassNos   := writeNos\n280:     }\n281: \n\
      282:     val realPush       = Wire(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 283-293
    context: "283:     val realWriteEntry = Wire(new RASEntry)\n284:     val timingTop\
      \      = RegInit(0.U.asTypeOf(new RASEntry))\n285:     val timingNos      =
      RegInit(0.U.asTypeOf(new RASPtr))\n286: \n287:     when(writeBypassValidWire)
      {\n288:       when((io.redirect_valid && io.redirect_isCall) || io.spec_push_valid)
      {\n289:         timingTop := writeEntry\n290:         timingNos := writeNos\n\
      291:       }.otherwise {\n292:         timingTop := writeBypassEntry\n293: \
      \        timingNos := writeBypassNos"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 291-325
    context: "291:       }.otherwise {\n292:         timingTop := writeBypassEntry\n\
      293:         timingNos := writeBypassNos\n294:       }\n295: \n296:     }.elsewhen(io.redirect_valid
      && io.redirect_isRet) {\n297:       // getTop using redirect Nos as TOSR\n298:\
      \       val popRedSsp  = Wire(UInt(log2Up(rasSize).W))\n299:       val popRedSctr
      = Wire(UInt(RasCtrSize.W))\n300:       val popRedTOSR = io.redirect_meta_NOS\n\
      301:       val popRedTOSW = io.redirect_meta_TOSW\n302: \n303:       when(io.redirect_meta_sctr
      > 0.U) {\n304:         popRedSctr := io.redirect_meta_sctr - 1.U\n305:     \
      \    popRedSsp  := io.redirect_meta_ssp\n306:       }.elsewhen(TOSRinRange(popRedTOSR,
      TOSW)) {\n307:         popRedSsp  := ptrDec(io.redirect_meta_ssp)\n308:    \
      \     popRedSctr := spec_queue(popRedTOSR.value).ctr\n309:       }.otherwise
      {\n310:         popRedSsp  := ptrDec(io.redirect_meta_ssp)\n311:         popRedSctr
      := getCommitTop(ptrDec(io.redirect_meta_ssp)).ctr\n312:       }\n313:      \
      \ // We are deciding top for the next cycle, no need to use bypass here\n314:\
      \       timingTop := getTop(popRedSsp, popRedSctr, popRedTOSR, popRedTOSW, false)\n\
      315:     }.elsewhen(io.redirect_valid) {\n316:       // Neither call nor ret\n\
      317:       val popSsp  = io.redirect_meta_ssp\n318:       val popSctr = io.redirect_meta_sctr\n\
      319:       val popTOSR = io.redirect_meta_TOSR\n320:       val popTOSW = io.redirect_meta_TOSW\n\
      321: \n322:       timingTop := getTop(popSsp, popSctr, popTOSR, popTOSW, false)\n\
      323: \n324:     }.elsewhen(io.spec_pop_valid) {\n325:       // getTop using
      current Nos as TOSR"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 347-359
    context: "347:       // s3 is different with s2\n348:       timingTop := getTop(io.s3_meta.ssp,
      io.s3_meta.sctr, io.s3_meta.TOSR, io.s3_meta.TOSW, false)\n349:       when(io.s3_missed_push)
      {\n350:         val writeEntry_s3 = Wire(new RASEntry)\n351:         timingTop\
      \             := writeEntry_s3\n352:         writeEntry_s3.retAddr := io.s3_pushAddr\n\
      353:         writeEntry_s3.ctr := Mux(\n354:           timingTop.retAddr ===
      io.s3_pushAddr && io.s3_meta.sctr < ctrMax,\n355:           io.s3_meta.sctr
      + 1.U,\n356:           0.U\n357:         )\n358:       }.elsewhen(io.s3_missed_pop)
      {\n359:         val popRedSsp_s3  = Wire(UInt(log2Up(rasSize).W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 380-402
    context: "380:       val popSctr = sctr\n381:       val popTOSR = TOSR\n382: \
      \      val popTOSW = TOSW\n383:       timingTop := getTop(popSsp, popSctr, popTOSR,
      popTOSW, false)\n384:     }\n385:     val diffTop = Mux(writeBypassValid, writeBypassEntry.retAddr,
      topEntry.retAddr)\n386: \n387:     XSPerfAccumulate(\"ras_top_mismatch\", diffTop
      =/= timingTop.retAddr);\n388:     // could diff when more pop than push and
      a commit stack is updated with inflight info\n389: \n390:     val realWriteEntry_next
      = RegEnable(writeEntry, io.s2_fire || io.redirect_isCall)\n391:     val s3_missPushEntry\
      \    = Wire(new RASEntry)\n392:     val s3_missPushAddr     = Wire(new RASPtr)\n\
      393:     val s3_missPushNos      = Wire(new RASPtr)\n394: \n395:     s3_missPushEntry.retAddr
      := io.s3_pushAddr\n396:     s3_missPushEntry.ctr := Mux(\n397:       s3TopEntry.retAddr
      === io.s3_pushAddr && s3TopEntry.ctr < ctrMax,\n398:       io.s3_meta.sctr +
      1.U,\n399:       0.U\n400:     )\n401:     s3_missPushAddr := io.s3_meta.TOSW\n\
      402:     s3_missPushNos  := io.s3_meta.TOSR"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 400-410
    context: "400:     )\n401:     s3_missPushAddr := io.s3_meta.TOSW\n402:     s3_missPushNos\
      \  := io.s3_meta.TOSR\n403: \n404:     realWriteEntry := Mux(\n405:       io.redirect_isCall,\n\
      406:       realWriteEntry_next,\n407:       Mux(io.s3_missed_push, s3_missPushEntry,
      realWriteEntry_next)\n408:     )\n409: \n410:     val realWriteAddr_next = RegEnable("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 406-430
    context: "406:       realWriteEntry_next,\n407:       Mux(io.s3_missed_push, s3_missPushEntry,
      realWriteEntry_next)\n408:     )\n409: \n410:     val realWriteAddr_next = RegEnable(\n\
      411:       Mux(io.redirect_valid && io.redirect_isCall, io.redirect_meta_TOSW,
      TOSW),\n412:       io.s2_fire || (io.redirect_valid && io.redirect_isCall)\n\
      413:     )\n414:     val realWriteAddr =\n415:       Mux(io.redirect_isCall,
      realWriteAddr_next, Mux(io.s3_missed_push, s3_missPushAddr, realWriteAddr_next))\n\
      416:     val realNos_next = RegEnable(\n417:       Mux(io.redirect_valid &&
      io.redirect_isCall, io.redirect_meta_TOSR, TOSR),\n418:       io.s2_fire ||
      (io.redirect_valid && io.redirect_isCall)\n419:     )\n420:     val realNos
      = Mux(io.redirect_isCall, realNos_next, Mux(io.s3_missed_push, s3_missPushNos,
      realNos_next))\n421: \n422:     realPush := (io.s3_fire && (!io.s3_cancel &&
      RegEnable(\n423:       io.spec_push_valid,\n424:       io.s2_fire\n425:    \
      \ ) || io.s3_missed_push)) || RegNext(io.redirect_valid && io.redirect_isCall)\n\
      426: \n427:     when(realPush) {\n428:       spec_queue(realWriteAddr.value)
      := realWriteEntry\n429:       spec_nos(realWriteAddr.value)   := realNos\n430:\
      \     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 428-438
    context: "428:       spec_queue(realWriteAddr.value) := realWriteEntry\n429: \
      \      spec_nos(realWriteAddr.value)   := realNos\n430:     }\n431: \n432: \
      \    def specPush(\n433:         retAddr:     UInt,\n434:         currentSsp:\
      \  UInt,\n435:         currentSctr: UInt,\n436:         currentTOSR: RASPtr,\n\
      437:         currentTOSW: RASPtr,\n438:         topEntry:    RASEntry"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 438-448
    context: "438:         topEntry:    RASEntry\n439:     ) = {\n440:       TOSR
      := currentTOSW\n441:       TOSW := specPtrInc(currentTOSW)\n442:       // spec
      sp and ctr should always be maintained\n443:       when(topEntry.retAddr ===
      retAddr && currentSctr < ctrMax) {\n444:         sctr := currentSctr + 1.U\n\
      445:       }.otherwise {\n446:         ssp  := ptrInc(currentSsp)\n447:    \
      \     sctr := 0.U\n448:       }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 480-490
    context: "480:       specPop(ssp, sctr, TOSR, TOSW, topNos)\n481:     }\n482:\
      \ \n483:     // io.spec_pop_addr := Mux(writeBypassValid, writeBypassEntry.retAddr,
      topEntry.retAddr)\n484: \n485:     io.spec_pop_addr := timingTop.retAddr\n486:\
      \     io.BOS           := BOS\n487:     io.TOSW          := TOSW\n488:     io.TOSR\
      \          := TOSR\n489:     io.NOS           := topNos\n490:     io.ssp   \
      \        := ssp"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 506-516
    context: "506:         // do not use any bypass from f2\n507:         specPush(io.s3_pushAddr,
      io.s3_meta.ssp, io.s3_meta.sctr, io.s3_meta.TOSR, io.s3_meta.TOSW, s3TopEntry)\n\
      508:       }\n509:     }\n510: \n511:     val commitTop = commit_stack(nsp)\n\
      512: \n513:     when(io.commit_pop_valid) {\n514: \n515:       val nsp_update
      = Wire(UInt(log2Up(rasSize).W))\n516:       when(io.commit_meta_ssp =/= nsp)
      {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 520-530
    context: "520:         nsp_update := nsp\n521:       }\n522: \n523:       // if
      ctr > 0, --ctr in stack, otherwise --nsp\n524:       when(commitTop.ctr > 0.U)
      {\n525:         commit_stack(nsp_update).ctr := commitTop.ctr - 1.U\n526:  \
      \       nsp                          := nsp_update\n527:       }.otherwise {\n\
      528:         nsp := ptrDec(nsp_update);\n529:       }\n530:       // XSError(io.commit_meta_ssp
      =/= nsp, \"nsp mismatch with expected ssp\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 528-538
    context: "528:         nsp := ptrDec(nsp_update);\n529:       }\n530:       //
      XSError(io.commit_meta_ssp =/= nsp, \"nsp mismatch with expected ssp\")\n531:\
      \     }\n532: \n533:     val commit_push_addr = spec_queue(io.commit_meta_TOSW.value).retAddr\n\
      534: \n535:     when(io.commit_push_valid) {\n536:       val nsp_update = Wire(UInt(log2Up(rasSize).W))\n\
      537:       when(io.commit_meta_ssp =/= nsp) {\n538:         // force set nsp
      to commit ssp to avoid permanent errors"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 539-555
    context: "539:         nsp_update := io.commit_meta_ssp\n540:       }.otherwise
      {\n541:         nsp_update := nsp\n542:       }\n543:       // if ctr < max
      && topAddr == push addr, ++ctr, otherwise ++nsp\n544:       when(commitTop.ctr
      < ctrMax && commitTop.retAddr === commit_push_addr) {\n545:         commit_stack(nsp_update).ctr
      := commitTop.ctr + 1.U\n546:         nsp                          := nsp_update\n\
      547:       }.otherwise {\n548:         nsp                                 \
      \     := ptrInc(nsp_update)\n549:         commit_stack(ptrInc(nsp_update)).retAddr
      := commit_push_addr\n550:         commit_stack(ptrInc(nsp_update)).ctr     :=
      0.U\n551:       }\n552: \n553:       // XSError(io.commit_meta_ssp =/= nsp,
      \"nsp mismatch with expected ssp\")\n554:       // XSError(io.commit_push_addr
      =/= commit_push_addr, \"addr from commit mismatch with addr from spec\")\n555:\
      \     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 562-594
    context: "562:     XSError(\n563:       io.commit_valid && (distanceBetween(io.commit_meta_TOSW,
      BOS) > 2.U),\n564:       \"The use of inference queue of the RAS module has
      unexpected situations\"\n565:     )\n566: \n567:     when(io.redirect_valid)
      {\n568:       TOSR := io.redirect_meta_TOSR\n569:       TOSW := io.redirect_meta_TOSW\n\
      570:       ssp  := io.redirect_meta_ssp\n571:       sctr := io.redirect_meta_sctr\n\
      572: \n573:       when(io.redirect_isCall) {\n574:         specPush(\n575: \
      \          io.redirect_callAddr,\n576:           io.redirect_meta_ssp,\n577:\
      \           io.redirect_meta_sctr,\n578:           io.redirect_meta_TOSR,\n\
      579:           io.redirect_meta_TOSW,\n580:           redirectTopEntry\n581:\
      \         )\n582:       }\n583:       when(io.redirect_isRet) {\n584:      \
      \   specPop(\n585:           io.redirect_meta_ssp,\n586:           io.redirect_meta_sctr,\n\
      587:           io.redirect_meta_TOSR,\n588:           io.redirect_meta_TOSW,\n\
      589:           redirectTopNos\n590:         )\n591:       }\n592:     }\n593:\
      \ \n594:     when(distanceBetween(TOSW, BOS) > (rasSpecSize - 2).U) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 597-609
    context: "597:       spec_near_overflowed := false.B\n598:     }\n599: \n600:\
      \     io.spec_near_overflow := spec_near_overflowed\n601:     XSPerfAccumulate(\"\
      spec_near_overflow\", spec_near_overflowed)\n602:     io.debug.commit_stack.zipWithIndex.foreach
      { case (a, i) => a := commit_stack(i) }\n603:     io.debug.spec_nos.zipWithIndex.foreach
      { case (a, i) => a := spec_nos(i) }\n604:     io.debug.spec_queue.zipWithIndex.foreach
      { case (a, i) => a := spec_queue(i) }\n605:   }\n606: \n607:   val stack = Module(new
      RASStack(RasSize, RasSpecSize)).io\n608: \n609:   val stack_near_overflow =
      stack.spec_near_overflow"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 615-626
    context: "615:   stack.spec_push_valid := s2_spec_push && !stack_near_overflow\n\
      616:   stack.spec_pop_valid  := s2_spec_pop && !stack_near_overflow\n617:  \
      \ stack.spec_push_addr  := s2_spec_new_addr\n618: \n619:   // confirm that the
      call/ret is the taken cfi\n620:   s2_spec_push := io.s2_fire(2) && s2_full_pred.hit_taken_on_call
      && !io.s3_redirect(2)\n621:   s2_spec_pop  := io.s2_fire(2) && s2_full_pred.hit_taken_on_ret
      && !io.s3_redirect(2)\n622: \n623:   // val s2_jalr_target = io.out.s2.full_pred.jalr_target\n\
      624:   // val s2_last_target_in = s2_full_pred.targets.last\n625:   // val s2_last_target_out
      = io.out.s2.full_pred(2).targets.last\n626:   val s2_is_jalr = s2_full_pred.is_jalr"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 626-640
    context: "626:   val s2_is_jalr = s2_full_pred.is_jalr\n627:   val s2_is_ret \
      \ = s2_full_pred.is_ret\n628:   val s2_top     = stack.spec_pop_addr\n629: \
      \  // assert(is_jalr && is_ret || !is_ret)\n630:   when(s2_is_ret && io.ctrl.ras_enable)
      {\n631:     io.out.s2.full_pred.map(_.jalr_target).foreach(_ := s2_top)\n632:\
      \     // FIXME: should use s1 globally\n633:   }\n634:   // s2_last_target_out
      := Mux(s2_is_jalr, s2_jalr_target, s2_last_target_in)\n635:   io.out.s2.full_pred.zipWithIndex.foreach
      { case (a, i) =>\n636:     a.targets.last := Mux(\n637:       s2_is_jalr,\n\
      638:       io.out.s2.full_pred(i).jalr_target,\n639:       io.in.bits.resp_in(0).s2.full_pred(i).targets.last\n\
      640:     )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 656-670
    context: "656:   val s3_is_jalr =\n657:     io.in.bits.resp_in(0).s3.full_pred(2).is_jalr
      && !io.in.bits.resp_in(0).s3.full_pred(2).fallThroughErr\n658:   val s3_is_ret
      = io.in.bits.resp_in(0).s3.full_pred(2).is_ret && !io.in.bits.resp_in(0).s3.full_pred(2).fallThroughErr\n\
      659:   // assert(is_jalr && is_ret || !is_ret)\n660:   when(s3_is_ret && io.ctrl.ras_enable)
      {\n661:     io.out.s3.full_pred.map(_.jalr_target).foreach(_ := s3_top)\n662:\
      \     // FIXME: should use s1 globally\n663:   }\n664:   // s3_last_target_out
      := Mux(s3_is_jalr, s3_jalr_target, s3_last_target_in)\n665:   io.out.s3.full_pred.zipWithIndex.foreach
      { case (a, i) =>\n666:     a.targets.last := Mux(\n667:       s3_is_jalr,\n\
      668:       io.out.s3.full_pred(i).jalr_target,\n669:       io.in.bits.resp_in(0).s3.full_pred(i).targets.last\n\
      670:     )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 703-730
    context: "703:   io.out.last_stage_spec_info.TOSR    := s3_meta.TOSR\n704:   io.out.last_stage_spec_info.NOS\
      \     := s3_meta.NOS\n705:   io.out.last_stage_spec_info.topAddr := s3_top\n\
      706:   io.out.last_stage_meta              := last_stage_meta.asUInt\n707: \n\
      708:   val redirect    = RegNextWithEnable(io.redirect)\n709:   val do_recover\
      \  = redirect.valid\n710:   val recover_cfi = redirect.bits.cfiUpdate\n711:\
      \ \n712:   val retMissPred  = do_recover && redirect.bits.level === 0.U && recover_cfi.pd.isRet
      && recover_cfi.pd.valid\n713:   val callMissPred = do_recover && redirect.bits.level
      === 0.U && recover_cfi.pd.isCall && recover_cfi.pd.valid\n714:   // when we
      mispredict a call, we must redo a push operation\n715:   // similarly, when
      we mispredict a return, we should redo a pop\n716:   val stack_TOSW    = stack.TOSW\n\
      717:   val redirect_TOSW = recover_cfi.TOSW\n718:   stack.redirect_valid   \
      \  := do_recover && (isBefore(redirect_TOSW, stack_TOSW) || !stack_near_overflow)\n\
      719:   stack.redirect_isCall    := callMissPred\n720:   stack.redirect_isRet\
      \     := retMissPred\n721:   stack.redirect_meta_ssp  := recover_cfi.ssp\n722:\
      \   stack.redirect_meta_sctr := recover_cfi.sctr\n723:   stack.redirect_meta_TOSW
      := recover_cfi.TOSW\n724:   stack.redirect_meta_TOSR := recover_cfi.TOSR\n725:\
      \   stack.redirect_meta_NOS  := recover_cfi.NOS\n726:   stack.redirect_callAddr\
      \  := recover_cfi.pc + Mux(recover_cfi.pd.isRVC, 2.U, 4.U)\n727: \n728:   val
      updateValid = RegNext(io.update.valid, init = false.B)\n729:   val update  \
      \    = Wire(new BranchPredictionUpdate)\n730:   update := RegEnable(io.update.bits,
      io.update.valid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 749-760
    context: "749:   )\n750:   stack.commit_meta_TOSW := updateMeta.TOSW\n751:   stack.commit_meta_ssp\
      \  := updateMeta.ssp\n752: \n753:   XSPerfAccumulate(\"ras_s3_cancel\", s3_cancel)\n\
      754:   XSPerfAccumulate(\"ras_redirect_recover\", redirect.valid)\n755:   XSPerfAccumulate(\"\
      ras_s3_and_redirect_recover_at_the_same_time\", s3_cancel && redirect.valid)\n\
      756: \n757:   val spec_debug = stack.debug\n758:   XSDebug(io.s2_fire(2), \"\
      ----------------RAS----------------\\n\")\n759:   XSDebug(io.s2_fire(2), \"\
      \ TopRegister: 0x%x\\n\", stack.spec_pop_addr)\n760:   XSDebug(io.s2_fire(2),
      \"  index       addr           ctr           nos (spec part)\\n\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 761-771
    context: "761:   for (i <- 0 until RasSpecSize) {\n762:     XSDebug(\n763:   \
      \    io.s2_fire(2),\n764:       \"  (%d)   0x%x      %d       %d\",\n765:  \
      \     i.U,\n766:       spec_debug.spec_queue(i).retAddr,\n767:       spec_debug.spec_queue(i).ctr,\n\
      768:       spec_debug.spec_nos(i).value\n769:     )\n770:     XSDebug(io.s2_fire(2)
      && i.U === stack.TOSW.value, \"   <----TOSW\")\n771:     XSDebug(io.s2_fire(2)
      && i.U === stack.TOSR.value, \"   <----TOSR\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 770-780
    context: "770:     XSDebug(io.s2_fire(2) && i.U === stack.TOSW.value, \"   <----TOSW\"\
      )\n771:     XSDebug(io.s2_fire(2) && i.U === stack.TOSR.value, \"   <----TOSR\"\
      )\n772:     XSDebug(io.s2_fire(2) && i.U === stack.BOS.value, \"   <----BOS\"\
      )\n773:     XSDebug(io.s2_fire(2), \"\\n\")\n774:   }\n775:   XSDebug(io.s2_fire(2),
      \"  index       addr           ctr   (committed part)\\n\")\n776:   for (i <-
      0 until RasSize) {\n777:     XSDebug(\n778:       io.s2_fire(2),\n779:     \
      \  \"  (%d)   0x%x      %d\",\n780:       i.U,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 776-787
    context: "776:   for (i <- 0 until RasSize) {\n777:     XSDebug(\n778:       io.s2_fire(2),\n\
      779:       \"  (%d)   0x%x      %d\",\n780:       i.U,\n781:       spec_debug.commit_stack(i).retAddr,\n\
      782:       spec_debug.commit_stack(i).ctr\n783:     )\n784:     XSDebug(io.s2_fire(2)
      && i.U === stack.ssp, \"   <----ssp\")\n785:     XSDebug(io.s2_fire(2) && i.U
      === stack.nsp, \"   <----nsp\")\n786:     XSDebug(io.s2_fire(2), \"\\n\")\n\
      787:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 789-804
    context: "789:   XSDebug(s2_spec_push, \"s2_spec_push  inAddr: 0x%x  inCtr: %d
      |  allocNewEntry:%d |   sp:%d \\n\",\n790:   s2_spec_new_addr,spec_debug.spec_push_entry.ctr,spec_debug.spec_alloc_new,spec_debug.sp.asUInt)\n\
      791:   XSDebug(s2_spec_pop, \"s2_spec_pop  outAddr: 0x%x \\n\",io.out.s2.getTarget)\n\
      792:   val s3_recover_entry = spec_debug.recover_push_entry\n793:   XSDebug(s3_recover
      && s3_push, \"s3_recover_push  inAddr: 0x%x  inCtr: %d |  allocNewEntry:%d |\
      \   sp:%d \\n\",\n794:     s3_recover_entry.retAddr, s3_recover_entry.ctr, spec_debug.recover_alloc_new,
      s3_sp.asUInt)\n795:   XSDebug(s3_recover && s3_pop, \"s3_recover_pop  outAddr:
      0x%x \\n\",io.out.s3.getTarget)\n796:   val redirectUpdate = redirect.bits.cfiUpdate\n\
      797:   XSDebug(do_recover && callMissPred, \"redirect_recover_push\\n\")\n798:\
      \   XSDebug(do_recover && retMissPred, \"redirect_recover_pop\\n\")\n799:  \
      \ XSDebug(do_recover, \"redirect_recover(SP:%d retAddr:%x ctr:%d) \\n\",\n800:\
      \       redirectUpdate.rasSp,redirectUpdate.rasEntry.retAddr,redirectUpdate.rasEntry.ctr)\n\
      801:    */\n802: \n803:   generatePerfEvent()\n804: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 106-116
    context: "106:       Mux(oldSatNotTaken && !taken, (-(1 << (len - 1))).S, Mux(taken,
      old + 1.S, old - 1.S))\n107:     )\n108:   }\n109: \n110:   def getFallThroughAddr(start:
      UInt, carry: Bool, pft: UInt) = {\n111:     val higher = start.head(VAddrBits
      - log2Ceil(PredictWidth) - instOffsetBits)\n112:     Cat(Mux(carry, higher +
      1.U, higher), pft, 0.U(instOffsetBits.W))\n113:   }\n114: \n115:   def foldTag(tag:
      UInt, l: Int): UInt = {\n116:     val nChunks = (tag.getWidth + l - 1) / l"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 136-146
    context: "136:   // val s0_all_ready = Bool()\n137: }\n138: \n139: class BasePredictorOutput(implicit
      p: Parameters) extends BranchPredictionResp {}\n140: \n141: class BasePredictorIO(implicit
      p: Parameters) extends XSBundle with HasBPUConst {\n142:   val reset_vector
      = Input(UInt(PAddrBits.W))\n143:   val in           = Flipped(DecoupledIO(new
      BasePredictorInput)) // TODO: Remove DecoupledIO\n144:   // val out = DecoupledIO(new
      BasePredictorOutput)\n145:   val out = Output(new BasePredictorOutput)\n146:\
      \   // val flush_out = Valid(UInt(VAddrBits.W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 155-174
    context: "155:   val s0_fire = Input(Vec(numDup, Bool()))\n156:   val s1_fire
      = Input(Vec(numDup, Bool()))\n157:   val s2_fire = Input(Vec(numDup, Bool()))\n\
      158:   val s3_fire = Input(Vec(numDup, Bool()))\n159: \n160:   val s2_redirect
      = Input(Vec(numDup, Bool()))\n161:   val s3_redirect = Input(Vec(numDup, Bool()))\n\
      162: \n163:   val s1_ready = Output(Bool())\n164:   val s2_ready = Output(Bool())\n\
      165:   val s3_ready = Output(Bool())\n166: \n167:   val update          = Flipped(Valid(new
      BranchPredictionUpdate))\n168:   val redirect        = Flipped(Valid(new BranchPredictionRedirect))\n\
      169:   val redirectFromIFU = Input(Bool())\n170: }\n171: \n172: abstract class
      BasePredictor(implicit p: Parameters) extends XSModule\n173:     with HasBPUConst
      with BPUUtils with HasPerfEvents {\n174:   val meta_size      = 0"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 172-182
    context: "172: abstract class BasePredictor(implicit p: Parameters) extends XSModule\n\
      173:     with HasBPUConst with BPUUtils with HasPerfEvents {\n174:   val meta_size\
      \      = 0\n175:   val spec_meta_size = 0\n176:   val is_fast_pred   = false\n\
      177:   val io             = IO(new BasePredictorIO())\n178: \n179:   val modified_reset
      = RegInit(true.B)\n180:   when(modified_reset)(modified_reset := false.B)\n\
      181: \n182:   io.out := io.in.bits.resp_in(0)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 184-198
    context: "184:   io.fauftb_entry_out     := io.fauftb_entry_in\n185:   io.fauftb_entry_hit_out
      := io.fauftb_entry_hit_in\n186: \n187:   io.out.last_stage_meta := 0.U\n188:\
      \ \n189:   io.in.ready := !io.redirect.valid\n190: \n191:   io.s1_ready := true.B\n\
      192:   io.s2_ready := true.B\n193:   io.s3_ready := true.B\n194: \n195:   val
      s0_pc_dup = WireInit(io.in.bits.s0_pc) // fetchIdx(io.f0_pc)\n196:   val s1_pc_dup
      = s0_pc_dup.zip(io.s0_fire).map { case (s0_pc, s0_fire) =>\n197:     RegEnable(s0_pc,
      s0_fire)\n198:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 214-224
    context: "214: \n215:   def getFoldedHistoryInfo: Option[Set[FoldedHistoryInfo]]
      = None\n216: }\n217: \n218: class FakePredictor(implicit p: Parameters) extends
      BasePredictor {\n219:   io.in.ready            := true.B\n220:   io.out.last_stage_meta
      := 0.U\n221:   io.out                 := io.in.bits.resp_in(0)\n222: }\n223:\
      \ \n224: class BpuToFtqIO(implicit p: Parameters) extends XSBundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 223-233
    context: "223: \n224: class BpuToFtqIO(implicit p: Parameters) extends XSBundle
      {\n225:   val resp = DecoupledIO(new BpuToFtqBundle())\n226: }\n227: \n228:
      class PredictorIO(implicit p: Parameters) extends XSBundle {\n229:   val bpu_to_ftq\
      \   = new BpuToFtqIO()\n230:   val ftq_to_bpu   = Flipped(new FtqToBpuIO)\n\
      231:   val ctrl         = Input(new BPUCtrl)\n232:   val reset_vector = Input(UInt(PAddrBits.W))\n\
      233: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 232-242
    context: "232:   val reset_vector = Input(UInt(PAddrBits.W))\n233: }\n234: \n\
      235: class Predictor(implicit p: Parameters) extends XSModule with HasBPUConst
      with HasPerfEvents\n236:     with HasCircularQueuePtrHelper {\n237:   val io
      = IO(new PredictorIO)\n238: \n239:   val modified_reset = RegInit(true.B)\n\
      240:   when(modified_reset)(modified_reset := false.B)\n241: \n242:   val ctrl\
      \       = DelayN(io.ctrl, 1)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 240-252
    context: "240:   when(modified_reset)(modified_reset := false.B)\n241: \n242:\
      \   val ctrl       = DelayN(io.ctrl, 1)\n243:   val predictors = Module(if (useBPD)
      new Composer else new FakePredictor)\n244: \n245:   def numOfStage = 3\n246:\
      \   require(numOfStage > 1, \"BPU numOfStage must be greater than 1\")\n247:\
      \   val topdown_stages = RegInit(VecInit(Seq.fill(numOfStage)(0.U.asTypeOf(new
      FrontendTopDownBundle))))\n248: \n249:   // following can only happen on s1\n\
      250:   val controlRedirectBubble = Wire(Bool())\n251:   val ControlBTBMissBubble\
      \  = Wire(Bool())\n252:   val TAGEMissBubble        = Wire(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 252-272
    context: "252:   val TAGEMissBubble        = Wire(Bool())\n253:   val SCMissBubble\
      \          = Wire(Bool())\n254:   val ITTAGEMissBubble      = Wire(Bool())\n\
      255:   val RASMissBubble         = Wire(Bool())\n256: \n257:   val memVioRedirectBubble
      = Wire(Bool())\n258:   val otherRedirectBubble  = Wire(Bool())\n259:   val btbMissBubble\
      \        = Wire(Bool())\n260:   otherRedirectBubble  := false.B\n261:   memVioRedirectBubble
      := false.B\n262: \n263:   // override can happen between s1-s2 and s2-s3\n264:\
      \   val overrideBubble = Wire(Vec(numOfStage - 1, Bool()))\n265:   def overrideStage\
      \  = 1\n266:   // ftq update block can happen on s1, s2 and s3\n267:   val ftqUpdateBubble
      = Wire(Vec(numOfStage, Bool()))\n268:   def ftqUpdateStage  = 0\n269:   // ftq
      full stall only happens on s3 (last stage)\n270:   val ftqFullStall = Wire(Bool())\n\
      271: \n272:   // by default, no bubble event"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 270-280
    context: "270:   val ftqFullStall = Wire(Bool())\n271: \n272:   // by default,
      no bubble event\n273:   topdown_stages(0) := 0.U.asTypeOf(new FrontendTopDownBundle)\n\
      274:   // event movement driven by clock only\n275:   for (i <- 0 until numOfStage
      - 1) {\n276:     topdown_stages(i + 1) := topdown_stages(i)\n277:   }\n278:\
      \ \n279:   // ctrl signal\n280:   predictors.io.ctrl         := ctrl"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 281-291
    context: "281:   predictors.io.reset_vector := io.reset_vector\n282: \n283:  \
      \ val s0_stall_dup = dup_wire(Bool()) // For some reason s0 stalled, usually
      FTQ Full\n284:   val s0_fire_dup, s1_fire_dup, s2_fire_dup, s3_fire_dup    \
      \                    = dup_wire(Bool())\n285:   val s1_valid_dup, s2_valid_dup,
      s3_valid_dup                                  = dup_seq(RegInit(false.B))\n\
      286:   val s1_ready_dup, s2_ready_dup, s3_ready_dup                        \
      \          = dup_wire(Bool())\n287:   val s1_components_ready_dup, s2_components_ready_dup,
      s3_components_ready_dup = dup_wire(Bool())\n288: \n289:   val s0_pc_dup = dup(WireInit(0.U(VAddrBits.W)))\n\
      290:   val s0_pc_reg_dup = s0_pc_dup.zip(s0_stall_dup).map { case (s0_pc, s0_stall)
      =>\n291:     RegEnable(s0_pc, !s0_stall)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 353-366
    context: "353:   def getHist(ptr: CGHPtr): UInt = (Cat(ghv_wire.asUInt, ghv_wire.asUInt)
      >> (ptr.value + 1.U))(HistoryLength - 1, 0)\n354:   s0_ghist := getHist(s0_ghist_ptr_dup(0))\n\
      355: \n356:   val resp = predictors.io.out\n357: \n358:   val toFtq_fire = io.bpu_to_ftq.resp.valid
      && io.bpu_to_ftq.resp.ready\n359: \n360:   val s1_flush_dup, s2_flush_dup, s3_flush_dup
      = dup_wire(Bool())\n361:   val s2_redirect_dup, s3_redirect_dup         = dup_wire(Bool())\n\
      362: \n363:   // predictors.io := DontCare\n364:   predictors.io.in.valid  \
      \             := s0_fire_dup(0)\n365:   predictors.io.in.bits.s0_pc        \
      \  := s0_pc_dup\n366:   predictors.io.in.bits.ghist          := s0_ghist"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 367-377
    context: "367:   predictors.io.in.bits.folded_hist    := s0_folded_gh_dup\n368:\
      \   predictors.io.in.bits.s1_folded_hist := s1_folded_gh_dup\n369:   predictors.io.in.bits.resp_in(0)\
      \     := 0.U.asTypeOf(new BranchPredictionResp)\n370:   predictors.io.fauftb_entry_in\
      \        := 0.U.asTypeOf(new FTBEntry)\n371:   predictors.io.fauftb_entry_hit_in\
      \    := false.B\n372:   predictors.io.redirectFromIFU        := RegNext(io.ftq_to_bpu.redirctFromIFU,
      init = false.B)\n373:   // predictors.io.in.bits.resp_in(0).s1.pc := s0_pc\n\
      374:   // predictors.io.in.bits.toFtq_fire := toFtq_fire\n375: \n376:   // predictors.io.out.ready
      := io.bpu_to_ftq.resp.ready\n377: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 373-460
    context: "373:   // predictors.io.in.bits.resp_in(0).s1.pc := s0_pc\n374:   //
      predictors.io.in.bits.toFtq_fire := toFtq_fire\n375: \n376:   // predictors.io.out.ready
      := io.bpu_to_ftq.resp.ready\n377: \n378:   val redirect_req    = io.ftq_to_bpu.redirect\n\
      379:   val do_redirect_dup = dup_seq(RegNextWithEnable(redirect_req))\n380:\
      \ \n381:   // Pipeline logic\n382:   s2_redirect_dup.map(_ := false.B)\n383:\
      \   s3_redirect_dup.map(_ := false.B)\n384: \n385:   s3_flush_dup.map(_ := redirect_req.valid)
      // flush when redirect comes\n386:   for (((s2_flush, s3_flush), s3_redirect)
      <- s2_flush_dup zip s3_flush_dup zip s3_redirect_dup)\n387:     s2_flush :=
      s3_flush || s3_redirect\n388:   for (((s1_flush, s2_flush), s2_redirect) <-
      s1_flush_dup zip s2_flush_dup zip s2_redirect_dup)\n389:     s1_flush := s2_flush
      || s2_redirect\n390: \n391:   s1_components_ready_dup.map(_ := predictors.io.s1_ready)\n\
      392:   for (((s1_ready, s1_fire), s1_valid) <- s1_ready_dup zip s1_fire_dup
      zip s1_valid_dup)\n393:     s1_ready := s1_fire || !s1_valid\n394:   for (((s0_fire,
      s1_components_ready), s1_ready) <- s0_fire_dup zip s1_components_ready_dup zip
      s1_ready_dup)\n395:     s0_fire             := s1_components_ready && s1_ready\n\
      396:   predictors.io.s0_fire := s0_fire_dup\n397: \n398:   s2_components_ready_dup.map(_
      := predictors.io.s2_ready)\n399:   for (((s2_ready, s2_fire), s2_valid) <- s2_ready_dup
      zip s2_fire_dup zip s2_valid_dup)\n400:     s2_ready := s2_fire || !s2_valid\n\
      401:   for (\n402:     (((s1_fire, s2_components_ready), s2_ready), s1_valid)
      <-\n403:       s1_fire_dup zip s2_components_ready_dup zip s2_ready_dup zip
      s1_valid_dup\n404:   )\n405:     s1_fire := s1_valid && s2_components_ready
      && s2_ready && io.bpu_to_ftq.resp.ready\n406: \n407:   s3_components_ready_dup.map(_
      := predictors.io.s3_ready)\n408:   for (((s3_ready, s3_fire), s3_valid) <- s3_ready_dup
      zip s3_fire_dup zip s3_valid_dup)\n409:     s3_ready := s3_fire || !s3_valid\n\
      410:   for (\n411:     (((s2_fire, s3_components_ready), s3_ready), s2_valid)
      <-\n412:       s2_fire_dup zip s3_components_ready_dup zip s3_ready_dup zip
      s2_valid_dup\n413:   )\n414:     s2_fire := s2_valid && s3_components_ready
      && s3_ready\n415: \n416:   for ((((s0_fire, s1_flush), s1_fire), s1_valid) <-
      s0_fire_dup zip s1_flush_dup zip s1_fire_dup zip s1_valid_dup) {\n417:     when(redirect_req.valid)(s1_valid
      := false.B)\n418:       .elsewhen(s0_fire)(s1_valid := true.B)\n419:       .elsewhen(s1_flush)(s1_valid
      := false.B)\n420:       .elsewhen(s1_fire)(s1_valid := false.B)\n421:   }\n\
      422:   predictors.io.s1_fire := s1_fire_dup\n423: \n424:   for (\n425:     ((((s1_fire,
      s2_flush), s2_fire), s2_valid), s1_flush) <-\n426:       s1_fire_dup zip s2_flush_dup
      zip s2_fire_dup zip s2_valid_dup zip s1_flush_dup\n427:   ) {\n428: \n429: \
      \    when(s2_flush)(s2_valid := false.B)\n430:       .elsewhen(s1_fire)(s2_valid
      := !s1_flush)\n431:       .elsewhen(s2_fire)(s2_valid := false.B)\n432:   }\n\
      433: \n434:   predictors.io.s2_fire     := s2_fire_dup\n435:   predictors.io.s2_redirect
      := s2_redirect_dup\n436: \n437:   s3_fire_dup := s3_valid_dup\n438: \n439: \
      \  for (\n440:     ((((s2_fire, s3_flush), s3_fire), s3_valid), s2_flush) <-\n\
      441:       s2_fire_dup zip s3_flush_dup zip s3_fire_dup zip s3_valid_dup zip
      s2_flush_dup\n442:   ) {\n443: \n444:     when(s3_flush)(s3_valid := false.B)\n\
      445:       .elsewhen(s2_fire)(s3_valid := !s2_flush)\n446:       .elsewhen(s3_fire)(s3_valid
      := false.B)\n447:   }\n448: \n449:   predictors.io.s3_fire     := s3_fire_dup\n\
      450:   predictors.io.s3_redirect := s3_redirect_dup\n451: \n452:   io.bpu_to_ftq.resp.valid
      :=\n453:     s1_valid_dup(2) && s2_components_ready_dup(2) && s2_ready_dup(2)
      ||\n454:       s2_fire_dup(2) && s2_redirect_dup(2) ||\n455:       s3_fire_dup(2)
      && s3_redirect_dup(2)\n456:   io.bpu_to_ftq.resp.bits                      \
      \        := predictors.io.out\n457:   io.bpu_to_ftq.resp.bits.last_stage_spec_info.histPtr
      := s3_ghist_ptr_dup(2)\n458: \n459:   val full_pred_diff        = WireInit(false.B)\n\
      460:   val full_pred_diff_stage  = WireInit(0.U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 486-498
    context: "486:     }\n487:   }\n488:   XSError(full_pred_diff, \"Full prediction
      difference detected!\")\n489: \n490:   // s0_stall should be exclusive with
      any other PC source\n491:   s0_stall_dup.zip(s1_valid_dup).zip(s2_redirect_dup).zip(s3_redirect_dup).zip(do_redirect_dup).foreach
      {\n492:     case ((((s0_stall, s1_valid), s2_redirect), s3_redirect), do_redirect)
      => {\n493:       s0_stall := !(s1_valid || s2_redirect || s3_redirect || do_redirect.valid)\n\
      494:     }\n495:   }\n496:   // Power-on reset\n497:   val powerOnResetState
      = RegInit(true.B)\n498:   when(s0_fire_dup(0)) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 542-552
    context: "542:   val s1_predicted_fh_dup = resp.s1.lastBrPosOH.zip(s1_possible_predicted_fhs_dup).map
      { case (oh, fh) =>\n543:     Mux1H(oh, fh)\n544:   }\n545: \n546:   val s1_ahead_fh_ob_src_dup
      = dup_wire(new AllAheadFoldedHistoryOldestBits(foldedGHistInfos))\n547:   s1_ahead_fh_ob_src_dup.zip(s1_ghist_ptr_dup).map
      { case (src, ptr) => src.read(ghv, ptr) }\n548: \n549:   if (EnableGHistDiff)
      {\n550:     val s1_predicted_ghist = WireInit(getHist(s1_predicted_ghist_ptr_dup(0)).asTypeOf(Vec(HistoryLength,
      Bool())))\n551:     for (i <- 0 until numBr) {\n552:       when(resp.s1.shouldShiftVec(0)(i))
      {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 573-597
    context: "573:         )\n574:       )\n575:     )\n576:   )\n577: \n578:   for
      (((npcGen, s1_valid), s1_target) <- npcGen_dup zip s1_valid_dup zip resp.s1.getTarget)\n\
      579:     npcGen.register(s1_valid, s1_target, Some(\"s1_target\"), 4)\n580:\
      \   for (((foldedGhGen, s1_valid), s1_predicted_fh) <- foldedGhGen_dup zip s1_valid_dup
      zip s1_predicted_fh_dup)\n581:     foldedGhGen.register(s1_valid, s1_predicted_fh,
      Some(\"s1_FGH\"), 4)\n582:   for (\n583:     ((ghistPtrGen, s1_valid), s1_predicted_ghist_ptr)
      <- ghistPtrGen_dup zip s1_valid_dup zip s1_predicted_ghist_ptr_dup\n584:   )\n\
      585:     ghistPtrGen.register(s1_valid, s1_predicted_ghist_ptr, Some(\"s1_GHPtr\"\
      ), 4)\n586:   for (\n587:     ((lastBrNumOHGen, s1_valid), s1_brPosOH) <-\n\
      588:       lastBrNumOHGen_dup zip s1_valid_dup zip resp.s1.lastBrPosOH.map(_.asUInt)\n\
      589:   )\n590:     lastBrNumOHGen.register(s1_valid, s1_brPosOH, Some(\"s1_BrNumOH\"\
      ), 4)\n591:   for (((aheadFhObGen, s1_valid), s1_ahead_fh_ob_src) <- aheadFhObGen_dup
      zip s1_valid_dup zip s1_ahead_fh_ob_src_dup)\n592:     aheadFhObGen.register(s1_valid,
      s1_ahead_fh_ob_src, Some(\"s1_AFHOB\"), 4)\n593:   ghvBitWriteGens.zip(s1_ghv_wens).zipWithIndex.map
      { case ((b, w), i) =>\n594:     b.register(w.reduce(_ || _), s1_ghv_wdatas(i),
      Some(s\"s1_new_bit_$i\"), 4)\n595:   }\n596: \n597:   class PreviousPredInfo
      extends Bundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 652-662
    context: "652:   val s2_predicted_fh_dup = resp.s2.lastBrPosOH.zip(s2_possible_predicted_fhs_dup).map
      { case (oh, fh) =>\n653:     Mux1H(oh, fh)\n654:   }\n655: \n656:   val s2_ahead_fh_ob_src_dup
      = dup_wire(new AllAheadFoldedHistoryOldestBits(foldedGHistInfos))\n657:   s2_ahead_fh_ob_src_dup.zip(s2_ghist_ptr_dup).map
      { case (src, ptr) => src.read(ghv, ptr) }\n658: \n659:   if (EnableGHistDiff)
      {\n660:     val s2_predicted_ghist = WireInit(getHist(s2_predicted_ghist_ptr_dup(0)).asTypeOf(Vec(HistoryLength,
      Bool())))\n661:     for (i <- 0 until numBr) {\n662:       when(resp.s2.shouldShiftVec(0)(i))
      {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 661-671
    context: "661:     for (i <- 0 until numBr) {\n662:       when(resp.s2.shouldShiftVec(0)(i))
      {\n663:         s2_predicted_ghist(i) := resp.s2.brTaken(0) && (i == 0).B\n\
      664:       }\n665:     }\n666:     when(s2_redirect_dup(0)) {\n667:       s0_ghist
      := s2_predicted_ghist.asUInt\n668:     }\n669:   }\n670: \n671:   val s2_ghv_wens
      = (0 until HistoryLength).map(n =>"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 669-679
    context: "669:   }\n670: \n671:   val s2_ghv_wens = (0 until HistoryLength).map(n
      =>\n672:     (0 until numBr).map(b =>\n673:       s2_ghist_ptr_dup(0).value
      === (CGHPtr(false.B, n.U) + b.U).value &&\n674:         resp.s2.shouldShiftVec(0)(b)
      && s2_redirect_dup(0)\n675:     )\n676:   )\n677:   val s2_ghv_wdatas = (0 until
      HistoryLength).map(n =>\n678:     Mux1H(\n679:       (0 until numBr).map(b =>"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 696-728
    context: "696:   val previous_s1_pred_info = RegEnable(s1_pred_info, 0.U.asTypeOf(new
      PreviousPredInfo), s1_fire_dup(0))\n697: \n698:   val s2_redirect_s1_last_pred_vec_dup
      = preds_needs_redirect_vec_dup(previous_s1_pred_info, resp.s2)\n699: \n700:\
      \   for (\n701:     ((s2_redirect, s2_fire), s2_redirect_s1_last_pred_vec) <-\n\
      702:       s2_redirect_dup zip s2_fire_dup zip s2_redirect_s1_last_pred_vec_dup\n\
      703:   )\n704:     s2_redirect := s2_fire && s2_redirect_s1_last_pred_vec.reduce(_
      || _)\n705: \n706:   for (((npcGen, s2_redirect), s2_target) <- npcGen_dup zip
      s2_redirect_dup zip resp.s2.getTarget)\n707:     npcGen.register(s2_redirect,
      s2_target, Some(\"s2_target\"), 5)\n708:   for (((foldedGhGen, s2_redirect),
      s2_predicted_fh) <- foldedGhGen_dup zip s2_redirect_dup zip s2_predicted_fh_dup)\n\
      709:     foldedGhGen.register(s2_redirect, s2_predicted_fh, Some(\"s2_FGH\"\
      ), 5)\n710:   for (\n711:     ((ghistPtrGen, s2_redirect), s2_predicted_ghist_ptr)
      <-\n712:       ghistPtrGen_dup zip s2_redirect_dup zip s2_predicted_ghist_ptr_dup\n\
      713:   )\n714:     ghistPtrGen.register(s2_redirect, s2_predicted_ghist_ptr,
      Some(\"s2_GHPtr\"), 5)\n715:   for (\n716:     ((lastBrNumOHGen, s2_redirect),
      s2_brPosOH) <-\n717:       lastBrNumOHGen_dup zip s2_redirect_dup zip resp.s2.lastBrPosOH.map(_.asUInt)\n\
      718:   )\n719:     lastBrNumOHGen.register(s2_redirect, s2_brPosOH, Some(\"\
      s2_BrNumOH\"), 5)\n720:   for (\n721:     ((aheadFhObGen, s2_redirect), s2_ahead_fh_ob_src)
      <- aheadFhObGen_dup zip s2_redirect_dup zip s2_ahead_fh_ob_src_dup\n722:   )\n\
      723:     aheadFhObGen.register(s2_redirect, s2_ahead_fh_ob_src, Some(\"s2_AFHOB\"\
      ), 5)\n724:   ghvBitWriteGens.zip(s2_ghv_wens).zipWithIndex.map { case ((b,
      w), i) =>\n725:     b.register(w.reduce(_ || _), s2_ghv_wdatas(i), Some(s\"\
      s2_new_bit_$i\"), 5)\n726:   }\n727: \n728:   XSPerfAccumulate(\"s2_redirect_because_target_diff\"\
      , s2_fire_dup(0) && s2_redirect_s1_last_pred_vec_dup(0)(0))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 731-743
    context: "731:   XSPerfAccumulate(\"s2_redirect_because_cfi_idx_diff\", s2_fire_dup(0)
      && s2_redirect_s1_last_pred_vec_dup(0)(3))\n732:   // XSPerfAccumulate(\"s2_redirect_because_shouldShiftVec_diff\"\
      , s2_fire && s2_redirect_s1_last_pred_vec(4))\n733:   // XSPerfAccumulate(\"\
      s2_redirect_because_brTaken_diff\", s2_fire && s2_redirect_s1_last_pred_vec(5))\n\
      734:   XSPerfAccumulate(\"s2_redirect_because_fallThroughError\", s2_fire_dup(0)
      && resp.s2.fallThruError(0))\n735: \n736:   XSPerfAccumulate(\"s2_redirect_when_taken\"\
      , s2_redirect_dup(0) && resp.s2.taken(0) && resp.s2.full_pred(0).hit)\n737:\
      \   XSPerfAccumulate(\"s2_redirect_when_not_taken\", s2_redirect_dup(0) && !resp.s2.taken(0)
      && resp.s2.full_pred(0).hit)\n738:   XSPerfAccumulate(\"s2_redirect_when_not_hit\"\
      , s2_redirect_dup(0) && !resp.s2.full_pred(0).hit)\n739: \n740:   // s3\n741:\
      \   val s3_possible_predicted_ghist_ptrs_dup = s3_ghist_ptr_dup.map(ptr => (0
      to numBr).map(ptr - _.U))\n742:   val s3_predicted_ghist_ptr_dup = s3_possible_predicted_ghist_ptrs_dup.zip(resp.s3.lastBrPosOH).map
      { case (ptr, oh) =>\n743:     Mux1H(oh, ptr)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 754-764
    context: "754:   val s3_predicted_fh_dup = resp.s3.lastBrPosOH.zip(s3_possible_predicted_fhs_dup).map
      { case (oh, fh) =>\n755:     Mux1H(oh, fh)\n756:   }\n757: \n758:   val s3_ahead_fh_ob_src_dup
      = dup_wire(new AllAheadFoldedHistoryOldestBits(foldedGHistInfos))\n759:   s3_ahead_fh_ob_src_dup.zip(s3_ghist_ptr_dup).map
      { case (src, ptr) => src.read(ghv, ptr) }\n760: \n761:   if (EnableGHistDiff)
      {\n762:     val s3_predicted_ghist = WireInit(getHist(s3_predicted_ghist_ptr_dup(0)).asTypeOf(Vec(HistoryLength,
      Bool())))\n763:     for (i <- 0 until numBr) {\n764:       when(resp.s3.shouldShiftVec(0)(i))
      {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 763-773
    context: "763:     for (i <- 0 until numBr) {\n764:       when(resp.s3.shouldShiftVec(0)(i))
      {\n765:         s3_predicted_ghist(i) := resp.s3.brTaken(0) && (i == 0).B\n\
      766:       }\n767:     }\n768:     when(s3_redirect_dup(0)) {\n769:       s0_ghist
      := s3_predicted_ghist.asUInt\n770:     }\n771:   }\n772: \n773:   val s3_ghv_wens
      = (0 until HistoryLength).map(n =>"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 772-782
    context: "772: \n773:   val s3_ghv_wens = (0 until HistoryLength).map(n =>\n774:\
      \     (0 until numBr).map(b =>\n775:       s3_ghist_ptr_dup(0).value === (CGHPtr(false.B,
      n.U) + b.U).value && resp.s3.shouldShiftVec(0)(\n776:         b\n777:      \
      \ ) && s3_redirect_dup(0)\n778:     )\n779:   )\n780:   val s3_ghv_wdatas =
      (0 until HistoryLength).map(n =>\n781:     Mux1H(\n782:       (0 until numBr).map(b
      =>"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 794-806
    context: "794:     s\"previous_s2_pred_pc\"\n795:   )\n796:   previous_s2_pred.valid
      := RegEnable(resp.s2.valid, 0.U.asTypeOf(resp.s2.valid), s2_fire_dup(0)).suggestName(\n\
      797:     s\"previous_s2_pred_valid\"\n798:   )\n799:   previous_s2_pred.hasRedirect
      := RegEnable(\n800:     resp.s2.hasRedirect,\n801:     0.U.asTypeOf(resp.s2.hasRedirect),\n\
      802:     s2_fire_dup(0)\n803:   ).suggestName(s\"previous_s2_pred_hasRedirect\"\
      )\n804:   previous_s2_pred.ftq_idx := RegEnable(resp.s2.ftq_idx, 0.U.asTypeOf(resp.s2.ftq_idx),
      s2_fire_dup(0)).suggestName(\n805:     s\"previous_s2_pred_ftq_idx\"\n806: \
      \  )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 822-832
    context: "822:       0.U.asTypeOf(new_fp.fallThroughAddr),\n823:       s2_fire_dup(0)
      && resp.s2.full_pred(0).hit && !resp.s2.full_pred(0).taken_mask_on_slot(0)\n\
      824:     )\n825:   }\n826: \n827:   val s3_redirect_on_br_taken_dup = resp.s3.full_pred.zip(previous_s2_pred.full_pred).map
      { case (fp1, fp2) =>\n828:     fp1.real_br_taken_mask().asUInt =/= fp2.real_br_taken_mask().asUInt\n\
      829:   }\n830:   val s3_both_first_taken_dup = resp.s3.full_pred.zip(previous_s2_pred.full_pred).map
      { case (fp1, fp2) =>\n831:     fp1.real_br_taken_mask()(0) && fp2.real_br_taken_mask()(0)\n\
      832:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 838-885
    context: "838:   val s3_redirect_on_ftb_multi_hit_dup   = resp.s3.ftbMultiHit\n\
      839: \n840:   for (\n841:     (\n842:       (\n843:         ((((s3_redirect,
      s3_fire), s3_redirect_on_br_taken), s3_redirect_on_target), s3_redirect_on_fall_thru_error),\n\
      844:         s3_redirect_on_ftb_multi_hit\n845:       ),\n846:       s3_both_first_taken\n\
      847:     ) <-\n848:       s3_redirect_dup zip s3_fire_dup zip s3_redirect_on_br_taken_dup
      zip s3_redirect_on_target_dup zip s3_redirect_on_fall_thru_error_dup zip s3_redirect_on_ftb_multi_hit_dup
      zip s3_both_first_taken_dup\n849:   ) {\n850: \n851:     s3_redirect := s3_fire
      && (\n852:       (s3_redirect_on_br_taken && !s3_both_first_taken) || s3_redirect_on_target
      || s3_redirect_on_fall_thru_error || s3_redirect_on_ftb_multi_hit\n853:    \
      \ )\n854:   }\n855: \n856:   XSPerfAccumulate(f\"s3_redirect_on_br_taken\",
      s3_fire_dup(0) && s3_redirect_on_br_taken_dup(0))\n857:   XSPerfAccumulate(f\"\
      s3_redirect_on_jalr_target\", s3_fire_dup(0) && s3_redirect_on_jalr_target_dup(0))\n\
      858:   XSPerfAccumulate(\n859:     f\"s3_redirect_on_others\",\n860:     s3_redirect_dup(0)
      && !(s3_redirect_on_br_taken_dup(0) || s3_redirect_on_jalr_target_dup(0))\n\
      861:   )\n862: \n863:   for (((npcGen, s3_redirect), s3_target) <- npcGen_dup
      zip s3_redirect_dup zip resp.s3.getTarget)\n864:     npcGen.register(s3_redirect,
      s3_target, Some(\"s3_target\"), 3)\n865:   for (((foldedGhGen, s3_redirect),
      s3_predicted_fh) <- foldedGhGen_dup zip s3_redirect_dup zip s3_predicted_fh_dup)\n\
      866:     foldedGhGen.register(s3_redirect, s3_predicted_fh, Some(\"s3_FGH\"\
      ), 3)\n867:   for (\n868:     ((ghistPtrGen, s3_redirect), s3_predicted_ghist_ptr)
      <-\n869:       ghistPtrGen_dup zip s3_redirect_dup zip s3_predicted_ghist_ptr_dup\n\
      870:   )\n871:     ghistPtrGen.register(s3_redirect, s3_predicted_ghist_ptr,
      Some(\"s3_GHPtr\"), 3)\n872:   for (\n873:     ((lastBrNumOHGen, s3_redirect),
      s3_brPosOH) <-\n874:       lastBrNumOHGen_dup zip s3_redirect_dup zip resp.s3.lastBrPosOH.map(_.asUInt)\n\
      875:   )\n876:     lastBrNumOHGen.register(s3_redirect, s3_brPosOH, Some(\"\
      s3_BrNumOH\"), 3)\n877:   for (\n878:     ((aheadFhObGen, s3_redirect), s3_ahead_fh_ob_src)
      <- aheadFhObGen_dup zip s3_redirect_dup zip s3_ahead_fh_ob_src_dup\n879:   )\n\
      880:     aheadFhObGen.register(s3_redirect, s3_ahead_fh_ob_src, Some(\"s3_AFHOB\"\
      ), 3)\n881:   ghvBitWriteGens.zip(s3_ghv_wens).zipWithIndex.map { case ((b,
      w), i) =>\n882:     b.register(w.reduce(_ || _), s3_ghv_wdatas(i), Some(s\"\
      s3_new_bit_$i\"), 3)\n883:   }\n884: \n885:   // Send signal tell Ftq override"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 884-907
    context: "884: \n885:   // Send signal tell Ftq override\n886:   val s2_ftq_idx
      = RegEnable(io.ftq_to_bpu.enq_ptr, s1_fire_dup(0))\n887:   val s3_ftq_idx =
      RegEnable(s2_ftq_idx, s2_fire_dup(0))\n888: \n889:   for (((to_ftq_s1_valid,
      s1_fire), s1_flush) <- io.bpu_to_ftq.resp.bits.s1.valid zip s1_fire_dup zip
      s1_flush_dup) {\n890:     to_ftq_s1_valid := s1_fire && !s1_flush\n891:   }\n\
      892:   io.bpu_to_ftq.resp.bits.s1.hasRedirect.map(_ := false.B)\n893:   io.bpu_to_ftq.resp.bits.s1.ftq_idx
      := DontCare\n894:   for (((to_ftq_s2_valid, s2_fire), s2_flush) <- io.bpu_to_ftq.resp.bits.s2.valid
      zip s2_fire_dup zip s2_flush_dup) {\n895:     to_ftq_s2_valid := s2_fire &&
      !s2_flush\n896:   }\n897:   io.bpu_to_ftq.resp.bits.s2.hasRedirect.zip(s2_redirect_dup).map
      { case (hr, r) => hr := r }\n898:   io.bpu_to_ftq.resp.bits.s2.ftq_idx := s2_ftq_idx\n\
      899:   for (((to_ftq_s3_valid, s3_fire), s3_flush) <- io.bpu_to_ftq.resp.bits.s3.valid
      zip s3_fire_dup zip s3_flush_dup) {\n900:     to_ftq_s3_valid := s3_fire &&
      !s3_flush\n901:   }\n902:   io.bpu_to_ftq.resp.bits.s3.hasRedirect.zip(s3_redirect_dup).map
      { case (hr, r) => hr := r }\n903:   io.bpu_to_ftq.resp.bits.s3.ftq_idx := s3_ftq_idx\n\
      904: \n905:   predictors.io.update            := io.ftq_to_bpu.update\n906:\
      \   predictors.io.update.bits.ghist := getHist(io.ftq_to_bpu.update.bits.spec_info.histPtr)\n\
      907:   // Move the update pc registers out of predictors."
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 910-925
    context: "910:     pcSegments,\n911:     io.ftq_to_bpu.update.valid,\n912:   \
      \  Some(\"predictors_io_update_pc\")\n913:   ).getAddr()\n914: \n915:   val
      redirect_dup = do_redirect_dup.map(_.bits)\n916:   predictors.io.redirect :=
      do_redirect_dup(0)\n917: \n918:   // Redirect logic\n919:   val shift_dup  \
      \     = redirect_dup.map(_.cfiUpdate.shift)\n920:   val addIntoHist_dup = redirect_dup.map(_.cfiUpdate.addIntoHist)\n\
      921:   // TODO: remove these below\n922:   val shouldShiftVec_dup = shift_dup.map(shift
      =>\n923:     Mux(\n924:       shift === 0.U,\n925:       VecInit(0.U((1 << (log2Ceil(numBr)
      + 1)).W).asBools),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 925-944
    context: "925:       VecInit(0.U((1 << (log2Ceil(numBr) + 1)).W).asBools),\n926:\
      \       VecInit(LowerMask(1.U << (shift - 1.U)).asBools)\n927:     )\n928: \
      \  )\n929:   // TODO end\n930:   val afhob_dup       = redirect_dup.map(_.cfiUpdate.afhob)\n\
      931:   val lastBrNumOH_dup = redirect_dup.map(_.cfiUpdate.lastBrNumOH)\n932:\
      \ \n933:   val isBr_dup  = redirect_dup.map(_.cfiUpdate.pd.isBr)\n934:   val
      taken_dup = redirect_dup.map(_.cfiUpdate.taken)\n935:   val real_br_taken_mask_dup
      =\n936:     for (((shift, taken), addIntoHist) <- shift_dup zip taken_dup zip
      addIntoHist_dup)\n937:       yield (0 until numBr).map(i => shift === (i + 1).U
      && taken && addIntoHist)\n938: \n939:   val oldPtr_dup      = redirect_dup.map(_.cfiUpdate.histPtr)\n\
      940:   val updated_ptr_dup = oldPtr_dup.zip(shift_dup).map { case (oldPtr, shift)
      => oldPtr - shift }\n941:   def computeFoldedHist(hist: UInt, compLen: Int)(histLen:
      Int): UInt =\n942:     if (histLen > 0) {\n943:       val nChunks     = (histLen
      + compLen - 1) / compLen\n944:       val hist_chunks = (0 until nChunks) map
      { i => hist(min((i + 1) * compLen, histLen) - 1, i * compLen) }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 945-955
    context: "945:       ParallelXOR(hist_chunks)\n946:     } else 0.U\n947: \n948:\
      \   val oldFh_dup = dup_seq(WireInit(0.U.asTypeOf(new AllFoldedHistories(foldedGHistInfos))))\n\
      949:   oldFh_dup.zip(oldPtr_dup).map { case (oldFh, oldPtr) =>\n950:     foldedGHistInfos.foreach
      { case (histLen, compLen) =>\n951:       oldFh.getHistWithInfo((histLen, compLen)).folded_hist
      := computeFoldedHist(getHist(oldPtr), compLen)(histLen)\n952:     }\n953:  \
      \ }\n954: \n955:   val updated_fh_dup ="
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 958-974
    context: "958:         oldFh_dup zip oldPtr_dup zip taken_dup zip addIntoHist_dup
      zip shift_dup\n959:     )\n960:       yield VecInit((0 to numBr).map(i => oldFh.update(ghv,
      oldPtr, i, taken && addIntoHist)))(shift)\n961:   val thisBrNumOH_dup   = shift_dup.map(shift
      => UIntToOH(shift, numBr + 1))\n962:   val thisAheadFhOb_dup = dup_wire(new
      AllAheadFoldedHistoryOldestBits(foldedGHistInfos))\n963:   thisAheadFhOb_dup.zip(oldPtr_dup).map
      { case (afhob, oldPtr) => afhob.read(ghv, oldPtr) }\n964:   val redirect_ghv_wens
      = (0 until HistoryLength).map(n =>\n965:     (0 until numBr).map(b =>\n966:\
      \       oldPtr_dup(0).value === (CGHPtr(false.B, n.U) + b.U).value && shouldShiftVec_dup(0)(b)
      && do_redirect_dup(0).valid\n967:     )\n968:   )\n969:   val redirect_ghv_wdatas
      = (0 until HistoryLength).map(n =>\n970:     Mux1H(\n971:       (0 until numBr).map(b
      => oldPtr_dup(0).value === (CGHPtr(false.B, n.U) + b.U).value && shouldShiftVec_dup(0)(b)),\n\
      972:       real_br_taken_mask_dup(0)\n973:     )\n974:   )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 978-988
    context: "978:     for (i <- 0 until numBr) {\n979:       when(shift_dup(0) >=
      (i + 1).U) {\n980:         updated_ghist(i) := taken_dup(0) && addIntoHist_dup(0)
      && (i == 0).B\n981:       }\n982:     }\n983:     when(do_redirect_dup(0).valid)
      {\n984:       s0_ghist := updated_ghist.asUInt\n985:     }\n986:   }\n987: \n\
      988:   // Commit time history checker"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 992-1010
    context: "992:     def getCommitHist(ptr: CGHPtr): UInt =\n993:       (Cat(commitGHist.asUInt,
      commitGHist.asUInt) >> (ptr.value + 1.U))(HistoryLength - 1, 0)\n994: \n995:\
      \     val updateValid:         Bool      = io.ftq_to_bpu.update.valid\n996:\
      \     val branchValidMask:     UInt      = io.ftq_to_bpu.update.bits.ftb_entry.brValids.asUInt\n\
      997:     val branchCommittedMask: Vec[Bool] = io.ftq_to_bpu.update.bits.br_committed\n\
      998:     val misPredictMask:      UInt      = io.ftq_to_bpu.update.bits.mispred_mask.asUInt\n\
      999:     val takenMask: UInt =\n1000:       io.ftq_to_bpu.update.bits.br_taken_mask.asUInt
      |\n1001:         io.ftq_to_bpu.update.bits.ftb_entry.strong_bias.asUInt // Always
      taken branch is recorded in history\n1002:     val takenIdx:      UInt = (PriorityEncoder(takenMask)
      + 1.U((log2Ceil(numBr) + 1).W)).asUInt\n1003:     val misPredictIdx: UInt =
      (PriorityEncoder(misPredictMask) + 1.U((log2Ceil(numBr) + 1).W)).asUInt\n1004:\
      \     val shouldShiftMask: UInt = Mux(takenMask.orR, LowerMask(takenIdx).asUInt,
      ((1 << numBr) - 1).asUInt) &\n1005:       Mux(misPredictMask.orR, LowerMask(misPredictIdx).asUInt,
      ((1 << numBr) - 1).asUInt) &\n1006:       branchCommittedMask.asUInt\n1007:\
      \     val updateShift: UInt =\n1008:       Mux(updateValid && branchValidMask.orR,
      PopCount(branchValidMask & shouldShiftMask), 0.U)\n1009: \n1010:     // Maintain
      the commitGHist"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 1026-1036
    context: "1026:         val predictGHistPtr = io.ftq_to_bpu.update.bits.spec_info.histPtr\n\
      1027:         val commitTrueHist: UInt = computeFoldedHist(getCommitHist(commitGHistPtr),
      log2Ceil(nRowsPerBr))(histLen)\n1028:         val predictFHist:   UInt = computeFoldedHist(getHist(predictGHistPtr),
      log2Ceil(nRowsPerBr))(histLen)\n1029:         XSWarn(\n1030:           updateValid
      && predictFHist =/= commitTrueHist,\n1031:           p\"predict time ghist:
      ${predictFHist} is different from commit time: ${commitTrueHist}\\n\"\n1032:\
      \         )\n1033:       }\n1034:     }\n1035:   }\n1036: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 1033-1054
    context: "1033:       }\n1034:     }\n1035:   }\n1036: \n1037:   // val updatedGh
      = oldGh.update(shift, taken && addIntoHist)\n1038:   for ((npcGen, do_redirect)
      <- npcGen_dup zip do_redirect_dup)\n1039:     npcGen.register(do_redirect.valid,
      do_redirect.bits.cfiUpdate.target, Some(\"redirect_target\"), 2)\n1040:   for
      (((foldedGhGen, do_redirect), updated_fh) <- foldedGhGen_dup zip do_redirect_dup
      zip updated_fh_dup)\n1041:     foldedGhGen.register(do_redirect.valid, updated_fh,
      Some(\"redirect_FGHT\"), 2)\n1042:   for (((ghistPtrGen, do_redirect), updated_ptr)
      <- ghistPtrGen_dup zip do_redirect_dup zip updated_ptr_dup)\n1043:     ghistPtrGen.register(do_redirect.valid,
      updated_ptr, Some(\"redirect_GHPtr\"), 2)\n1044:   for (((lastBrNumOHGen, do_redirect),
      thisBrNumOH) <- lastBrNumOHGen_dup zip do_redirect_dup zip thisBrNumOH_dup)\n\
      1045:     lastBrNumOHGen.register(do_redirect.valid, thisBrNumOH, Some(\"redirect_BrNumOH\"\
      ), 2)\n1046:   for (((aheadFhObGen, do_redirect), thisAheadFhOb) <- aheadFhObGen_dup
      zip do_redirect_dup zip thisAheadFhOb_dup)\n1047:     aheadFhObGen.register(do_redirect.valid,
      thisAheadFhOb, Some(\"redirect_AFHOB\"), 2)\n1048:   ghvBitWriteGens.zip(redirect_ghv_wens).zipWithIndex.map
      { case ((b, w), i) =>\n1049:     b.register(w.reduce(_ || _), redirect_ghv_wdatas(i),
      Some(s\"redirect_new_bit_$i\"), 2)\n1050:   }\n1051:   // no need to assign
      s0_last_pred\n1052: \n1053:   // val need_reset = RegNext(reset.asBool) && !reset.asBool\n\
      1054: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 1066-1076
    context: "1066:   s0_last_br_num_oh_dup.zip(lastBrNumOHGen_dup).map { case (s0_last_br_num_oh,
      lastBrNumOHGen) =>\n1067:     s0_last_br_num_oh := lastBrNumOHGen()\n1068: \
      \  }\n1069:   (ghv_write_datas zip ghvBitWriteGens).map { case (wd, d) => wd
      := d() }\n1070:   for (i <- 0 until HistoryLength) {\n1071:     ghv_wens(i)
      := Seq(s1_ghv_wens, s2_ghv_wens, s3_ghv_wens, redirect_ghv_wens).map(_(i).reduce(_
      || _)).reduce(_ || _)\n1072:     when(ghv_wens(i)) {\n1073:       ghv(i) :=
      ghv_write_datas(i)\n1074:     }\n1075:   }\n1076: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 1073-1147
    context: "1073:       ghv(i) := ghv_write_datas(i)\n1074:     }\n1075:   }\n1076:\
      \ \n1077:   // TODO: signals for memVio and other Redirects\n1078:   controlRedirectBubble
      := do_redirect_dup(0).valid && do_redirect_dup(0).bits.ControlRedirectBubble\n\
      1079:   ControlBTBMissBubble  := do_redirect_dup(0).bits.ControlBTBMissBubble\n\
      1080:   TAGEMissBubble        := do_redirect_dup(0).bits.TAGEMissBubble\n1081:\
      \   SCMissBubble          := do_redirect_dup(0).bits.SCMissBubble\n1082:   ITTAGEMissBubble\
      \      := do_redirect_dup(0).bits.ITTAGEMissBubble\n1083:   RASMissBubble  \
      \       := do_redirect_dup(0).bits.RASMissBubble\n1084: \n1085:   memVioRedirectBubble\
      \                 := do_redirect_dup(0).valid && do_redirect_dup(0).bits.MemVioRedirectBubble\n\
      1086:   otherRedirectBubble                  := do_redirect_dup(0).valid &&
      do_redirect_dup(0).bits.OtherRedirectBubble\n1087:   btbMissBubble         \
      \               := do_redirect_dup(0).valid && do_redirect_dup(0).bits.BTBMissBubble\n\
      1088:   overrideBubble(0)                    := s2_redirect_dup(0)\n1089:  \
      \ overrideBubble(1)                    := s3_redirect_dup(0)\n1090:   ftqUpdateBubble(0)\
      \                   := !s1_components_ready_dup(0)\n1091:   ftqUpdateBubble(1)\
      \                   := !s2_components_ready_dup(0)\n1092:   ftqUpdateBubble(2)\
      \                   := !s3_components_ready_dup(0)\n1093:   ftqFullStall   \
      \                      := !io.bpu_to_ftq.resp.ready\n1094:   io.bpu_to_ftq.resp.bits.topdown_info
      := topdown_stages(numOfStage - 1)\n1095: \n1096:   // topdown handling logic
      here\n1097:   when(controlRedirectBubble) {\n1098:     /*\n1099:     for (i
      <- 0 until numOfStage)\n1100:       topdown_stages(i).reasons(TopDownCounters.ControlRedirectBubble.id)
      := true.B\n1101:     io.bpu_to_ftq.resp.bits.topdown_info.reasons(TopDownCounters.ControlRedirectBubble.id)
      := true.B\n1102:      */\n1103:     when(ControlBTBMissBubble) {\n1104:    \
      \   for (i <- 0 until numOfStage)\n1105:         topdown_stages(i).reasons(TopDownCounters.BTBMissBubble.id)\
      \                  := true.B\n1106:       io.bpu_to_ftq.resp.bits.topdown_info.reasons(TopDownCounters.BTBMissBubble.id)
      := true.B\n1107:     }.elsewhen(TAGEMissBubble) {\n1108:       for (i <- 0 until
      numOfStage)\n1109:         topdown_stages(i).reasons(TopDownCounters.TAGEMissBubble.id)\
      \                  := true.B\n1110:       io.bpu_to_ftq.resp.bits.topdown_info.reasons(TopDownCounters.TAGEMissBubble.id)
      := true.B\n1111:     }.elsewhen(SCMissBubble) {\n1112:       for (i <- 0 until
      numOfStage)\n1113:         topdown_stages(i).reasons(TopDownCounters.SCMissBubble.id)\
      \                  := true.B\n1114:       io.bpu_to_ftq.resp.bits.topdown_info.reasons(TopDownCounters.SCMissBubble.id)
      := true.B\n1115:     }.elsewhen(ITTAGEMissBubble) {\n1116:       for (i <- 0
      until numOfStage)\n1117:         topdown_stages(i).reasons(TopDownCounters.ITTAGEMissBubble.id)\
      \                  := true.B\n1118:       io.bpu_to_ftq.resp.bits.topdown_info.reasons(TopDownCounters.ITTAGEMissBubble.id)
      := true.B\n1119:     }.elsewhen(RASMissBubble) {\n1120:       for (i <- 0 until
      numOfStage)\n1121:         topdown_stages(i).reasons(TopDownCounters.RASMissBubble.id)\
      \                  := true.B\n1122:       io.bpu_to_ftq.resp.bits.topdown_info.reasons(TopDownCounters.RASMissBubble.id)
      := true.B\n1123:     }\n1124:   }\n1125:   when(memVioRedirectBubble) {\n1126:\
      \     for (i <- 0 until numOfStage)\n1127:       topdown_stages(i).reasons(TopDownCounters.MemVioRedirectBubble.id)\
      \                  := true.B\n1128:     io.bpu_to_ftq.resp.bits.topdown_info.reasons(TopDownCounters.MemVioRedirectBubble.id)
      := true.B\n1129:   }\n1130:   when(otherRedirectBubble) {\n1131:     for (i
      <- 0 until numOfStage)\n1132:       topdown_stages(i).reasons(TopDownCounters.OtherRedirectBubble.id)\
      \                  := true.B\n1133:     io.bpu_to_ftq.resp.bits.topdown_info.reasons(TopDownCounters.OtherRedirectBubble.id)
      := true.B\n1134:   }\n1135:   when(btbMissBubble) {\n1136:     for (i <- 0 until
      numOfStage)\n1137:       topdown_stages(i).reasons(TopDownCounters.BTBMissBubble.id)\
      \                  := true.B\n1138:     io.bpu_to_ftq.resp.bits.topdown_info.reasons(TopDownCounters.BTBMissBubble.id)
      := true.B\n1139:   }\n1140: \n1141:   for (i <- 0 until numOfStage) {\n1142:\
      \     if (i < numOfStage - overrideStage) {\n1143:       when(overrideBubble(i))
      {\n1144:         for (j <- 0 to i)\n1145:           topdown_stages(j).reasons(TopDownCounters.OverrideBubble.id)
      := true.B\n1146:       }\n1147:     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 1143-1153
    context: "1143:       when(overrideBubble(i)) {\n1144:         for (j <- 0 to
      i)\n1145:           topdown_stages(j).reasons(TopDownCounters.OverrideBubble.id)
      := true.B\n1146:       }\n1147:     }\n1148:     if (i < numOfStage - ftqUpdateStage)
      {\n1149:       when(ftqUpdateBubble(i)) {\n1150:         topdown_stages(i).reasons(TopDownCounters.FtqUpdateBubble.id)
      := true.B\n1151:       }\n1152:     }\n1153:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 1154-1210
    context: "1154:   when(ftqFullStall) {\n1155:     topdown_stages(0).reasons(TopDownCounters.FtqFullStall.id)
      := true.B\n1156:   }\n1157: \n1158:   XSError(\n1159:     isBefore(redirect_dup(0).cfiUpdate.histPtr,
      s3_ghist_ptr_dup(0)) && do_redirect_dup(0).valid,\n1160:     p\"s3_ghist_ptr
      ${s3_ghist_ptr_dup(0)} exceeds redirect histPtr ${redirect_dup(0).cfiUpdate.histPtr}\\\
      n\"\n1161:   )\n1162:   XSError(\n1163:     isBefore(redirect_dup(0).cfiUpdate.histPtr,
      s2_ghist_ptr_dup(0)) && do_redirect_dup(0).valid,\n1164:     p\"s2_ghist_ptr
      ${s2_ghist_ptr_dup(0)} exceeds redirect histPtr ${redirect_dup(0).cfiUpdate.histPtr}\\\
      n\"\n1165:   )\n1166:   XSError(\n1167:     isBefore(redirect_dup(0).cfiUpdate.histPtr,
      s1_ghist_ptr_dup(0)) && do_redirect_dup(0).valid,\n1168:     p\"s1_ghist_ptr
      ${s1_ghist_ptr_dup(0)} exceeds redirect histPtr ${redirect_dup(0).cfiUpdate.histPtr}\\\
      n\"\n1169:   )\n1170: \n1171:   XSDebug(RegNext(reset.asBool) && !reset.asBool,
      \"Reseting...\\n\")\n1172:   XSDebug(io.ftq_to_bpu.update.valid, p\"Update from
      ftq\\n\")\n1173:   XSDebug(io.ftq_to_bpu.redirect.valid, p\"Redirect from ftq\\\
      n\")\n1174: \n1175:   XSDebug(\"[BP0]                 fire=%d              \
      \        pc=%x\\n\", s0_fire_dup(0), s0_pc_dup(0))\n1176:   XSDebug(\n1177:\
      \     \"[BP1] v=%d r=%d cr=%d fire=%d             flush=%d pc=%x\\n\",\n1178:\
      \     s1_valid_dup(0),\n1179:     s1_ready_dup(0),\n1180:     s1_components_ready_dup(0),\n\
      1181:     s1_fire_dup(0),\n1182:     s1_flush_dup(0),\n1183:     s1_pc\n1184:\
      \   )\n1185:   XSDebug(\n1186:     \"[BP2] v=%d r=%d cr=%d fire=%d redirect=%d
      flush=%d pc=%x\\n\",\n1187:     s2_valid_dup(0),\n1188:     s2_ready_dup(0),\n\
      1189:     s2_components_ready_dup(0),\n1190:     s2_fire_dup(0),\n1191:    \
      \ s2_redirect_dup(0),\n1192:     s2_flush_dup(0),\n1193:     s2_pc\n1194:  \
      \ )\n1195:   XSDebug(\n1196:     \"[BP3] v=%d r=%d cr=%d fire=%d redirect=%d
      flush=%d pc=%x\\n\",\n1197:     s3_valid_dup(0),\n1198:     s3_ready_dup(0),\n\
      1199:     s3_components_ready_dup(0),\n1200:     s3_fire_dup(0),\n1201:    \
      \ s3_redirect_dup(0),\n1202:     s3_flush_dup(0),\n1203:     s3_pc\n1204:  \
      \ )\n1205:   XSDebug(\"[FTQ] ready=%d\\n\", io.bpu_to_ftq.resp.ready)\n1206:\
      \   XSDebug(\"resp.s1.target=%x\\n\", resp.s1.getTarget(0))\n1207:   XSDebug(\"\
      resp.s2.target=%x\\n\", resp.s2.getTarget(0))\n1208:   // XSDebug(\"s0_ghist:
      %b\\n\", s0_ghist.predHist)\n1209:   // XSDebug(\"s1_ghist: %b\\n\", s1_ghist.predHist)\n\
      1210:   // XSDebug(\"s2_ghist: %b\\n\", s2_ghist.predHist)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 1213-1226
    context: "1213:   XSDebug(p\"s1_ghist_ptr: ${s1_ghist_ptr_dup(0)}\\n\")\n1214:\
      \   XSDebug(p\"s2_ghist_ptr: ${s2_ghist_ptr_dup(0)}\\n\")\n1215:   XSDebug(p\"\
      s3_ghist_ptr: ${s3_ghist_ptr_dup(0)}\\n\")\n1216: \n1217:   io.ftq_to_bpu.update.bits.display(io.ftq_to_bpu.update.valid)\n\
      1218:   io.ftq_to_bpu.redirect.bits.display(io.ftq_to_bpu.redirect.valid)\n\
      1219: \n1220:   XSPerfAccumulate(\"s2_redirect\", s2_redirect_dup(0))\n1221:\
      \   XSPerfAccumulate(\"s3_redirect\", s3_redirect_dup(0))\n1222:   XSPerfAccumulate(\"\
      s1_not_valid\", !s1_valid_dup(0))\n1223: \n1224:   val perfEvents = predictors.asInstanceOf[Composer].getPerfEvents\n\
      1225:   generatePerfEvent()\n1226: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Bim.scala
    lines: 42-60
    context: "42: \n43:   // bim.io.r.req.valid := io.s0_fire\n44:   bim.io.r.req.valid
      := false.B\n45:   bim.io.r.req.bits.setIdx := s0_idx\n46: \n47:   io.in.ready
      := bim.io.r.req.ready\n48:   io.s1_ready := bim.io.r.req.ready\n49: \n50:  \
      \ val s1_read = bim.io.r.resp.data\n51: \n52:   io.out := io.in.bits.resp_in(0)\n\
      53: \n54:   val s1_latch_taken_mask = VecInit(Cat(((0 until numBr).reverse).map(i
      => s1_read(i)(1))).asBools)\n55:   val s1_latch_meta       = s1_read.asUInt\n\
      56:   override val meta_size = s1_latch_meta.getWidth\n57: \n58:   // io.out.s1.full_pred.br_taken_mask
      := s1_latch_taken_mask\n59:   // io.out.s2.full_pred.br_taken_mask := RegEnable(s1_latch_taken_mask,
      0.U.asTypeOf(Vec(numBr, Bool())), io.s1_fire)\n60: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Bim.scala
    lines: 103-113
    context: "103:   XSDebug(doing_reset, \"Doing reset...\\n\")\n104: \n105:   XSDebug(io.s0_fire,
      \"req_pc=%x, req_idx=%d\\n\", s0_pc_dup(0), s0_idx)\n106: \n107:   for(i <-
      0 until numBr) {\n108:     XSDebug(latch_s0_fire, \"last_cycle req %d: ctr=%b\\\
      n\", i.U, s1_read(i))\n109:   }\n110: \n111:   XSDebug(u_valid, \"update_pc=%x,
      update_idx=%d, is_br=%b\\n\", update.pc, u_idx, update.ftb_entry.brValids.asUInt)\n\
      112: \n113:   XSDebug(u_valid, \"newTakens=%b\\n\", newTakens.asUInt)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 89-99
    context: "89: class ITTageUpdate(implicit p: Parameters) extends ITTageBundle
      {\n90:   val pc    = UInt(VAddrBits.W)\n91:   val ghist = UInt(HistoryLength.W)\n\
      92:   // update tag and ctr\n93:   val valid   = Bool()\n94:   val correct =
      Bool()\n95:   val alloc   = Bool()\n96:   val oldCtr  = UInt(ITTageCtrBits.W)\n\
      97:   // update u\n98:   val uValid  = Bool()\n99:   val u       = Bool()"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 256-272
    context: "256:   require(ittageEntrySz == (new ITTageEntry).getWidth)\n257: \n\
      258:   // pc is start address of basic block, most 2 branch inst in block\n\
      259:   def getUnhashedIdx(pc: UInt): UInt = (pc >> instOffsetBits).asUInt\n\
      260: \n261:   val s0_valid        = io.req.valid\n262:   val s0_pc         \
      \  = io.req.bits.pc\n263:   val s0_unhashed_idx = getUnhashedIdx(io.req.bits.pc)\n\
      264: \n265:   val (s0_idx, s0_tag) = computeTagAndHash(s0_unhashed_idx, io.req.bits.folded_hist)\n\
      266:   val (s1_idx, s1_tag) = (RegEnable(s0_idx, io.req.fire), RegEnable(s0_tag,
      io.req.fire))\n267:   val s1_valid         = RegNext(s0_valid)\n268: \n269:\
      \   val table = Module(new FoldedSRAMTemplate(\n270:     new ITTageEntry,\n\
      271:     setSplit = 1,\n272:     waySplit = 1,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 280-290
    context: "280:     withClockGate = true,\n281:     hasMbist = hasMbist,\n282:\
      \     hasSramCtl = hasSramCtl\n283:   ))\n284:   private val mbistPl = MbistPipeline.PlaceMbistPipeline(1,
      \"MbistPipeIttage\", hasMbist)\n285:   table.io.r.req.valid       := io.req.fire\n\
      286:   table.io.r.req.bits.setIdx := s0_idx\n287: \n288:   val table_read_data
      = table.io.r.resp.data(0)\n289: \n290:   val s1_req_rhit = table_read_data.valid
      && table_read_data.tag === s1_tag"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 290-300
    context: "290:   val s1_req_rhit = table_read_data.valid && table_read_data.tag
      === s1_tag\n291: \n292:   val read_write_conflict    = io.update.valid && io.req.valid\n\
      293:   val s1_read_write_conflict = RegEnable(read_write_conflict, io.req.valid)\n\
      294: \n295:   io.resp.valid    := (if (tagLen != 0) s1_req_rhit && !s1_read_write_conflict
      else true.B) && s1_valid // && s1_mask(b)\n296:   io.resp.bits.ctr := table_read_data.ctr\n\
      297:   io.resp.bits.u   := table_read_data.useful\n298:   io.resp.bits.target_offset
      := table_read_data.target_offset\n299: \n300:   // Use fetchpc to compute hash"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 311-321
    context: "311:   val updateNoUsBitmask =\n312:     VecInit.tabulate(ittageEntrySz)(_.U
      >= ITTageUsBits.U).asUInt // update others besides useful bit\n313:   val updateUsBitmask
      = VecInit.tabulate(ittageEntrySz)(_.U < ITTageUsBits.U).asUInt // update useful
      bit\n314: \n315:   val needReset               = RegInit(false.B)\n316:   val
      useful_can_reset        = !(io.req.fire || io.update.valid) && needReset\n317:\
      \   val (resetSet, resetFinish) = Counter(useful_can_reset, nRows)\n318:   when(io.update.reset_u)
      {\n319:     needReset := true.B\n320:   }.elsewhen(resetFinish) {\n321:    \
      \ needReset := false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 334-344
    context: "334:     bitmask = update_bitmask\n335:   )\n336: \n337:   // Power-on
      reset\n338:   val powerOnResetState = RegInit(true.B)\n339:   when(table.io.r.req.ready)
      {\n340:     // When all the SRAM first reach ready state, we consider power-on
      reset is done\n341:     powerOnResetState := false.B\n342:   }\n343:   // Do
      not use table banks io.r.req.ready directly\n344:   // All table_banks are single
      port SRAM, ready := !wen"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 342-352
    context: "342:   }\n343:   // Do not use table banks io.r.req.ready directly\n\
      344:   // All table_banks are single port SRAM, ready := !wen\n345:   // We
      do not want write request block the whole BPU pipeline\n346:   // Once read
      priority is higher than write, table_banks(*).io.r.req.ready can be used\n347:\
      \   io.req.ready := !powerOnResetState\n348: \n349:   val wrbypass = Module(new
      WrBypass(UInt(ITTageCtrBits.W), wrBypassEntries, log2Ceil(nRows)))\n350: \n\
      351:   wrbypass.io.wen       := io.update.valid\n352:   wrbypass.io.write_idx
      := update_idx"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 352-362
    context: "352:   wrbypass.io.write_idx := update_idx\n353:   wrbypass.io.write_data.map(_
      := update_wdata.ctr)\n354: \n355:   val old_ctr = Mux(wrbypass.io.hit, wrbypass.io.hit_data(0).bits,
      io.update.oldCtr)\n356:   update_wdata.valid  := true.B\n357:   update_wdata.ctr\
      \    := Mux(io.update.alloc, 2.U, incCtr(old_ctr, io.update.correct))\n358:\
      \   update_wdata.tag    := update_tag\n359:   update_wdata.useful := Mux(useful_can_reset,
      false.B, io.update.u)\n360:   // only when ctr is null\n361:   update_wdata.target_offset
      := Mux(\n362:     io.update.alloc || ctrNull(old_ctr),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 372-387
    context: "372:   if (BPUDebug && debug) {\n373:     val u   = io.update\n374:\
      \     val idx = s0_idx\n375:     val tag = s0_tag\n376:     XSDebug(\n377: \
      \      io.req.fire,\n378:       p\"ITTageTableReq: pc=0x${Hexadecimal(io.req.bits.pc)},
      \" +\n379:         p\"idx=$idx, tag=$tag\\n\"\n380:     )\n381:     XSDebug(\n\
      382:       RegNext(io.req.fire) && s1_req_rhit,\n383:       p\"ITTageTableResp:
      idx=$s1_idx, hit:${s1_req_rhit}, \" +\n384:         p\"ctr:${io.resp.bits.ctr},
      u:${io.resp.bits.u}, tar:${Hexadecimal(io.resp.bits.target_offset.offset)}\\\
      n\"\n385:     )\n386:     XSDebug(\n387:       io.update.valid,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 384-394
    context: "384:         p\"ctr:${io.resp.bits.ctr}, u:${io.resp.bits.u}, tar:${Hexadecimal(io.resp.bits.target_offset.offset)}\\\
      n\"\n385:     )\n386:     XSDebug(\n387:       io.update.valid,\n388:      \
      \ p\"update ITTAGE Table: pc:${Hexadecimal(u.pc)}}, \" +\n389:         p\"correct:${u.correct},
      alloc:${u.alloc}, oldCtr:${u.oldCtr}, \" +\n390:         p\"target:${Hexadecimal(u.target_offset.offset)},
      old_target:${Hexadecimal(u.old_target_offset.offset)}\\n\"\n391:     )\n392:\
      \     XSDebug(\n393:       io.update.valid,\n394:       p\"update ITTAGE Table:
      writing tag:${update_tag}, \" +"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 393-403
    context: "393:       io.update.valid,\n394:       p\"update ITTAGE Table: writing
      tag:${update_tag}, \" +\n395:         p\"ctr: ${update_wdata.ctr}, target:${Hexadecimal(update_wdata.target_offset.offset)}\"\
      \ +\n396:         p\" in idx $update_idx\\n\"\n397:     )\n398:     XSDebug(RegNext(io.req.fire)
      && !s1_req_rhit, \"TageTableResp: no hits!\\n\")\n399: \n400:     // ------------------------------Debug-------------------------------------\n\
      401:     val valids = RegInit(0.U.asTypeOf(Vec(nRows, Bool())))\n402:     when(io.update.valid)(valids(update_idx)
      := true.B)\n403:     XSDebug(\"ITTAGE Table usage:------------------------\\\
      n\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 409-420
    context: "409: abstract class BaseITTage(implicit p: Parameters) extends BasePredictor
      with ITTageParams with BPUUtils {}\n410: \n411: class FakeITTage(implicit p:
      Parameters) extends BaseITTage {\n412:   io.out <> 0.U.asTypeOf(DecoupledIO(new
      BasePredictorOutput))\n413: \n414:   io.s1_ready := true.B\n415:   io.s2_ready
      := true.B\n416: }\n417: \n418: class ITTage(implicit p: Parameters) extends
      BaseITTage {\n419:   override val meta_size = 0.U.asTypeOf(new ITTageMeta).getWidth\n\
      420: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 431-441
    context: "431:   val rTable = Module(new RegionWays)\n432: \n433:   // uftb miss
      or hasIndirect\n434:   val s1_uftbHit         = io.in.bits.resp_in(0).s1_uftbHit\n\
      435:   val s1_uftbHasIndirect = io.in.bits.resp_in(0).s1_uftbHasIndirect\n436:\
      \   val s1_isIndirect      = (!s1_uftbHit && !io.in.bits.resp_in(0).s1_ftbCloseReq)
      || s1_uftbHasIndirect\n437: \n438:   // Keep the table responses to process
      in s2\n439: \n440:   val s2_resps = VecInit(tables.map(t => t.io.resp))\n441: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 536-546
    context: "536: \n537:   val updateMisPred = update.mispred_mask(numBr) // the
      last one indicates jmp results\n538: \n539:   // Predict\n540:   tables.map
      { t =>\n541:     t.io.req.valid            := io.s1_fire(3) && s1_isIndirect\n\
      542:     t.io.req.bits.pc          := s1_pc_dup(3)\n543:     t.io.req.bits.folded_hist
      := io.in.bits.s1_folded_hist(3)\n544:   }\n545: \n546:   // access tag tables
      and output meta info"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 544-554
    context: "544:   }\n545: \n546:   // access tag tables and output meta info\n\
      547:   class ITTageTableInfo(implicit p: Parameters) extends ITTageResp {\n\
      548:     val tableIdx   = UInt(log2Ceil(ITTageNTables).W)\n549:     val maskTarget
      = Vec(ITTageNTables, UInt(VAddrBits.W))\n550:   }\n551: \n552:   val inputRes
      = VecInit(s2_resps.zipWithIndex.map {\n553:     case (r, i) =>\n554:       val
      tableInfo = Wire(new ITTageTableInfo)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 554-565
    context: "554:       val tableInfo = Wire(new ITTageTableInfo)\n555:       tableInfo.u\
      \             := r.bits.u\n556:       tableInfo.ctr           := r.bits.ctr\n\
      557:       tableInfo.target_offset := r.bits.target_offset\n558:       tableInfo.tableIdx\
      \      := i.U(log2Ceil(ITTageNTables).W)\n559:       tableInfo.maskTarget  \
      \  := VecInit(Seq.fill(ITTageNTables)(0.U(VAddrBits.W)))\n560:       tableInfo.maskTarget(i)
      := \"hffff_ffff_ffff_ffff\".U\n561:       SelectTwoInterRes(r.valid, tableInfo)\n\
      562:   })\n563: \n564:   val selectedInfo = ParallelSelectTwo(inputRes.reverse)\n\
      565:   val provided     = selectedInfo.hasOne"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 567-577
    context: "567: \n568:   val providerInfo    = selectedInfo.first\n569:   val altProviderInfo
      = selectedInfo.second\n570:   val providerNull    = providerInfo.ctr === 0.U\n\
      571: \n572:   val baseTarget             = io.in.bits.resp_in(0).s2.full_pred(3).jalr_target
      // use ftb pred as base target\n573:   val region_r_target_offset = VecInit(s2_resps.map(r
      => r.bits.target_offset))\n574: \n575:   rTable.io.req_pointer.zipWithIndex.map
      { case (req_pointer, i) =>\n576:     req_pointer := region_r_target_offset(i).pointer\n\
      577:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 583-597
    context: "583:       Cat(rTable.io.resp_region(i), region_r_target_offset(i).offset),\n\
      584:       Cat(targetGetRegion(s2_pc_dup(0).getAddr()), region_r_target_offset(i).offset)\n\
      585:     )\n586:   }\n587: \n588:   val providerCatTarget = providerInfo.maskTarget.zipWithIndex.map
      {\n589:     case (mask, i) => mask & region_targets(i)\n590:   }.reduce(_ |
      _)\n591: \n592:   val altproviderCatTarget = altProviderInfo.maskTarget.zipWithIndex.map
      {\n593:     case (mask, i) => mask & region_targets(i)\n594:   }.reduce(_ |
      _)\n595: \n596:   s2_tageTarget := Mux1H(Seq(\n597:     (provided && !(providerNull
      && altProvided), providerCatTarget),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 624-634
    context: "624:   resp_meta.providerU         := s3_providerU\n625:   resp_meta.providerCtr\
      \       := s3_providerCtr\n626:   resp_meta.altProviderCtr    := s3_altProviderCtr\n\
      627:   resp_meta.providerTarget    := s3_providerTarget\n628:   resp_meta.altProviderTarget
      := s3_altProviderTarget\n629:   resp_meta.pred_cycle.foreach(_ := GTimer())\n\
      630:   // TODO: adjust for ITTAGE\n631:   // Create a mask fo tables which did
      not hit our query, and also contain useless entries\n632:   // and also uses
      a longer history than the provider\n633:   val s2_allocatableSlots = VecInit(s2_resps.map(r
      => !r.valid && !r.bits.u)).asUInt &\n634:     (~(LowerMask(UIntToOH(s2_provider),
      ITTageNTables) & Fill(ITTageNTables, s2_provided.asUInt))).asUInt"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 670-680
    context: "670:   val provider    = updateMeta.provider.bits\n671:   val altProvider
      = updateMeta.altProvider.bits\n672:   val usedAltpred = updateMeta.altProvider.valid
      && updateMeta.providerCtr === 0.U\n673:   when(updateValid) {\n674:     when(updateMeta.provider.valid)
      {\n675:       when(usedAltpred && updateMisPred) { // update altpred if used
      as pred\n676:         updateMask(altProvider)            := true.B\n677:   \
      \      updateUMask(altProvider)           := false.B\n678:         updateCorrect(altProvider)\
      \         := false.B\n679:         updateOldCtr(altProvider)          := updateMeta.altProviderCtr\n\
      680:         updateAlloc(altProvider)           := false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 697-711
    context: "697:       updateOldTargetOffset(provider) := metaProviderTargetOffset\n\
      698:     }\n699:   }\n700:   XSDebug(\n701:     updateValid && updateMeta.provider.valid,\n\
      702:     p\"update provider $provider, pred cycle ${updateMeta.pred_cycle.getOrElse(0.U)}\\\
      n\"\n703:   )\n704:   XSDebug(\n705:     updateValid && updateMeta.provider.valid
      && usedAltpred && updateMisPred,\n706:     p\"update altprovider $altProvider,
      pred cycle ${updateMeta.pred_cycle.getOrElse(0.U)}\\n\"\n707:   )\n708: \n709:\
      \   // if mispredicted and not the case that\n710:   // provider offered correct
      target but used altpred due to unconfident\n711:   val providerCorrect = updateMeta.provider.valid
      && updateMeta.providerTarget === updateRealTarget"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 722-732
    context: "722:       updateTargetOffset(allocate.bits) := updateRealTargetOffset\n\
      723:     }\n724:   }\n725:   XSDebug(\n726:     updateValid && updateMisPred
      && !(providerCorrect && providerUnconf) && allocate.valid,\n727:     p\"allocate
      new table entry, pred cycle ${updateMeta.pred_cycle.getOrElse(0.U)}\\n\"\n728:\
      \   )\n729: \n730:   when(tickCtr === ((1 << TickWidth) - 1).U) {\n731:    \
      \ tickCtr      := 0.U\n732:     updateResetU := true.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 733-743
    context: "733:   }\n734: \n735:   for (i <- 0 until ITTageNTables) {\n736:   \
      \  tables(i).io.update.valid             := RegNext(updateMask(i), init = false.B)\n\
      737:     tables(i).io.update.reset_u           := RegNext(updateResetU, init
      = false.B)\n738:     tables(i).io.update.correct           := RegEnable(updateCorrect(i),
      updateMask(i))\n739:     tables(i).io.update.alloc             := RegEnable(updateAlloc(i),
      updateMask(i))\n740:     tables(i).io.update.oldCtr            := RegEnable(updateOldCtr(i),
      updateMask(i))\n741:     tables(i).io.update.target_offset     := RegEnable(updateTargetOffset(i),
      updateMask(i))\n742:     tables(i).io.update.old_target_offset := RegEnable(updateOldTargetOffset(i),
      updateMask(i))\n743: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 746-761
    context: "746:     tables(i).io.update.pc     := RegEnable(update_pc, updateMask(i))\n\
      747:     tables(i).io.update.ghist  := RegEnable(update.ghist, updateMask(i))\n\
      748:   }\n749: \n750:   // all should be ready for req\n751:   io.s1_ready :=
      tables.map(_.io.req.ready).reduce(_ && _)\n752: \n753:   // Debug and perf info\n\
      754:   XSPerfAccumulate(\"ittage_reset_u\", updateResetU)\n755:   XSPerfAccumulate(\"\
      ittage_used\", io.s1_fire(0) && s1_isIndirect)\n756:   XSPerfAccumulate(\"ittage_closed_due_to_uftb_info\"\
      , io.s1_fire(0) && !s1_isIndirect)\n757:   XSPerfAccumulate(\"ittage_allocate\"\
      , updateAlloc.reduce(_ || _))\n758: \n759:   private def pred_perf(name:   String,
      cond: Bool) = XSPerfAccumulate(s\"${name}_at_pred\", cond && io.s2_fire(3))\n\
      760:   private def commit_perf(name: String, cond: Bool) = XSPerfAccumulate(s\"\
      ${name}_at_commit\", cond && updateValid)\n761:   private def ittage_perf(name:
      String, pred_cond: Bool, commit_cond: Bool) = {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 825-833
    context: "825:       )\n826:     }\n827:   }\n828:   XSDebug(updateValid, p\"\
      pc: ${Hexadecimal(update_pc)}, target: ${Hexadecimal(update.full_target)}\\\
      n\")\n829:   XSDebug(updateValid, updateMeta.toPrintable + p\"\\n\")\n830: \
      \  XSDebug(updateValid, p\"correct(${!updateMisPred})\\n\")\n831: \n832:   generatePerfEvent()\n\
      833: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Composer.scala
    lines: 26-36
    context: "26:   // shorter path for s1 pred\n27:   val all_fast_pred = components.filter(_.is_fast_pred)\n\
      28:   require(all_fast_pred.length <= 1)\n29:   if (all_fast_pred.length ==
      1) {\n30:     val fast_pred = all_fast_pred(0)\n31:     println(\"[composer]
      bypassing output of fast pred: \" + fast_pred.name)\n32:     io.out.s1 := fast_pred.io.out.s1\n\
      33:   }\n34: \n35:   var metas   = 0.U(1.W)\n36:   var meta_sz = 0"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Composer.scala
    lines: 45-60
    context: "45:     c.io.s0_fire := io.s0_fire\n46:     c.io.s1_fire := io.s1_fire\n\
      47:     c.io.s2_fire := io.s2_fire\n48:     c.io.s3_fire := io.s3_fire\n49:\
      \ \n50:     c.io.s2_redirect := io.s2_redirect\n51:     c.io.s3_redirect :=
      io.s3_redirect\n52: \n53:     c.io.redirect        := io.redirect\n54:     c.io.ctrl\
      \            := DelayN(io.ctrl, 1)\n55:     c.io.redirectFromIFU := io.redirectFromIFU\n\
      56: \n57:     if (c.meta_size > 0) {\n58:       metas = (metas << c.meta_size)
      | c.io.out.last_stage_meta(c.meta_size - 1, 0)\n59:     }\n60:     meta_sz =
      meta_sz + c.meta_size"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Composer.scala
    lines: 59-72
    context: "59:     }\n60:     meta_sz = meta_sz + c.meta_size\n61:   }\n62:   println(s\"\
      total meta size: $meta_sz\\n\\n\")\n63: \n64:   io.in.ready := components.map(_.io.s1_ready).reduce(_
      && _)\n65: \n66:   io.s1_ready := components.map(_.io.s1_ready).reduce(_ &&
      _)\n67:   io.s2_ready := components.map(_.io.s2_ready).reduce(_ && _)\n68: \n\
      69:   require(meta_sz <= MaxMetaLength)\n70:   io.out.last_stage_meta := metas\n\
      71: \n72:   var update_meta = io.update.bits.meta"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 42-52
    context: "42:   val isBr      = Bool()\n43:   val isJmp     = Bool()\n44:   val
      isCall    = Bool()\n45:   val isRet     = Bool()\n46:   val misPred   = Bool()\n\
      47:   val isTaken   = Bool()\n48:   val predStage = UInt(2.W)\n49: }\n50: \n\
      51: class FtqPtr(entries: Int) extends CircularQueuePtr[FtqPtr](\n52:      \
      \ entries"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 63-78
    context: "63:   }\n64:   def inverse(ptr: FtqPtr)(implicit p: Parameters): FtqPtr
      =\n65:     apply(!ptr.flag, ptr.value)\n66: }\n67: \n68: class FtqNRSRAM[T <:
      Data](gen: T, numRead: Int)(implicit p: Parameters) extends XSModule {\n69:\
      \ \n70:   val io = IO(new Bundle() {\n71:     val raddr = Input(Vec(numRead,
      UInt(log2Up(FtqSize).W)))\n72:     val ren   = Input(Vec(numRead, Bool()))\n\
      73:     val rdata = Output(Vec(numRead, gen))\n74:     val waddr = Input(UInt(log2Up(FtqSize).W))\n\
      75:     val wen   = Input(Bool())\n76:     val wdata = Input(gen)\n77:   })\n\
      78: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 74-84
    context: "74:     val waddr = Input(UInt(log2Up(FtqSize).W))\n75:     val wen\
      \   = Input(Bool())\n76:     val wdata = Input(gen)\n77:   })\n78: \n79:   for
      (i <- 0 until numRead) {\n80:     val sram = Module(new SplittedSRAMTemplate(\n\
      81:       gen,\n82:       set = FtqSize,\n83:       way = 1,\n84:       dataSplit
      = 4,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 181-191
    context: "181: class Ftq_Pred_Info(implicit p: Parameters) extends XSBundle {\n\
      182:   val target   = UInt(VAddrBits.W)\n183:   val cfiIndex = ValidUndirectioned(UInt(log2Ceil(PredictWidth).W))\n\
      184: }\n185: \n186: class FtqRead[T <: Data](private val gen: T)(implicit p:
      Parameters) extends XSBundle {\n187:   val valid  = Output(Bool())\n188:   val
      ptr    = Output(new FtqPtr)\n189:   val offset = Output(UInt(log2Ceil(PredictWidth).W))\n\
      190:   val data   = Input(gen)\n191:   def apply(valid: Bool, ptr: FtqPtr, offset:
      UInt) = {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 195-208
    context: "195:     this.data\n196:   }\n197: }\n198: \n199: class FtqToBpuIO(implicit
      p: Parameters) extends XSBundle {\n200:   val redirect       = Valid(new BranchPredictionRedirect)\n\
      201:   val update         = Valid(new BranchPredictionUpdate)\n202:   val enq_ptr\
      \        = Output(new FtqPtr)\n203:   val redirctFromIFU = Output(Bool())\n\
      204: }\n205: \n206: class BpuFlushInfo(implicit p: Parameters) extends XSBundle
      with HasCircularQueuePtrHelper {\n207:   // when ifu pipeline is not stalled,\n\
      208:   // a packet from bpu s3 can reach f1 at most"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 206-217
    context: "206: class BpuFlushInfo(implicit p: Parameters) extends XSBundle with
      HasCircularQueuePtrHelper {\n207:   // when ifu pipeline is not stalled,\n208:\
      \   // a packet from bpu s3 can reach f1 at most\n209:   val s2 = Valid(new
      FtqPtr)\n210:   val s3 = Valid(new FtqPtr)\n211:   def shouldFlushBy(src: Valid[FtqPtr],
      idx_to_flush: FtqPtr) =\n212:     src.valid && !isAfter(src.bits, idx_to_flush)\n\
      213:   def shouldFlushByStage2(idx: FtqPtr) = shouldFlushBy(s2, idx)\n214: \
      \  def shouldFlushByStage3(idx: FtqPtr) = shouldFlushBy(s3, idx)\n215: }\n216:\
      \ \n217: class FtqToIfuIO(implicit p: Parameters) extends XSBundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 214-225
    context: "214:   def shouldFlushByStage3(idx: FtqPtr) = shouldFlushBy(s3, idx)\n\
      215: }\n216: \n217: class FtqToIfuIO(implicit p: Parameters) extends XSBundle
      {\n218:   val req              = Decoupled(new FetchRequestBundle)\n219:   val
      redirect         = Valid(new BranchPredictionRedirect)\n220:   val topdown_redirect
      = Valid(new BranchPredictionRedirect)\n221:   val flushFromBpu     = new BpuFlushInfo\n\
      222: }\n223: \n224: class FtqToICacheIO(implicit p: Parameters) extends XSBundle
      {\n225:   // NOTE: req.bits must be prepare in T cycle"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 232-242
    context: "232:   val flushFromBpu     = new BpuFlushInfo\n233:   val backendException
      = UInt(ExceptionType.width.W)\n234: }\n235: \n236: trait HasBackendRedirectInfo
      extends HasXSParameter {\n237:   def isLoadReplay(r: Valid[Redirect]) = r.bits.flushItself()\n\
      238: }\n239: \n240: class FtqToCtrlIO(implicit p: Parameters) extends XSBundle
      with HasBackendRedirectInfo {\n241:   // write to backend pc mem\n242:   val
      pc_mem_wen   = Output(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 254-264
    context: "254:     val old_entry      = Input(new FTBEntry)\n255:     val pd \
      \            = Input(new Ftq_pd_Entry)\n256:     val cfiIndex       = Flipped(Valid(UInt(log2Ceil(PredictWidth).W)))\n\
      257:     val target         = Input(UInt(VAddrBits.W))\n258:     val hit   \
      \         = Input(Bool())\n259:     val mispredict_vec = Input(Vec(PredictWidth,
      Bool()))\n260: \n261:     val new_entry         = Output(new FTBEntry)\n262:\
      \     val new_br_insert_pos = Output(Vec(numBr, Bool()))\n263:     val taken_mask\
      \        = Output(Vec(numBr, Bool()))\n264:     val jmp_taken         = Output(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 383-393
    context: "383:     val new_pft_offset =\n384:       Mux(!new_br_insert_onehot.asUInt.orR,
      new_br_offset, oe.allSlotsForBr.last.offset)\n385: \n386:     // set jmp to
      invalid\n387:     old_entry_modified.pftAddr              := getLower(io.start_addr)
      + new_pft_offset\n388:     old_entry_modified.carry                := (getLower(io.start_addr)
      +& new_pft_offset).head(1).asBool\n389:     old_entry_modified.last_may_be_rvi_call
      := false.B\n390:     old_entry_modified.isCall               := false.B\n391:\
      \     old_entry_modified.isRet                := false.B\n392:     old_entry_modified.isJalr\
      \               := false.B\n393:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 427-439
    context: "427:   io.taken_mask := VecInit((io.new_entry.brOffset zip io.new_entry.brValids).map
      {\n428:     case (off, v) => io.cfiIndex.bits === off && io.cfiIndex.valid &&
      v\n429:   })\n430:   io.jmp_taken := io.new_entry.jmpValid && io.new_entry.tailSlot.offset
      === io.cfiIndex.bits\n431:   for (i <- 0 until numBr) {\n432:     io.mispred_mask(i)
      := io.new_entry.brValids(i) && io.mispredict_vec(io.new_entry.brOffset(i))\n\
      433:   }\n434:   io.mispred_mask.last := io.new_entry.jmpValid && io.mispredict_vec(pd.jmpOffset)\n\
      435: \n436:   // for perf counters\n437:   io.is_init_entry           := !hit\n\
      438:   io.is_old_entry            := hit && !is_new_br && !jalr_target_modified
      && !strong_bias_modified\n439:   io.is_new_br               := hit && is_new_br"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 510-520
    context: "510:     val bpuInfo = new Bundle {\n511:       val bpRight = Output(UInt(XLEN.W))\n\
      512:       val bpWrong = Output(UInt(XLEN.W))\n513:     }\n514: \n515:     val
      mmioCommitRead = Flipped(new mmioCommitRead)\n516: \n517:     // for perf\n\
      518:     val ControlBTBMissBubble = Output(Bool())\n519:     val TAGEMissBubble\
      \       = Output(Bool())\n520:     val SCMissBubble         = Output(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 526-536
    context: "526:   val topdown_stage = RegInit(0.U.asTypeOf(new FrontendTopDownBundle))\n\
      527:   // only driven by clock, not valid-ready\n528:   topdown_stage      \
      \            := io.fromBpu.resp.bits.topdown_info\n529:   io.toIfu.req.bits.topdown_info
      := topdown_stage\n530: \n531:   val ifuRedirected = RegInit(VecInit(Seq.fill(FtqSize)(false.B)))\n\
      532: \n533:   // io.fromBackend.ftqIdxAhead: bju(BjuCnt) + ldReplay + exception\n\
      534:   val ftqIdxAhead = VecInit(Seq.tabulate(FtqRedirectAheadNum)(i => io.fromBackend.ftqIdxAhead(i)))
      // only bju\n535:   val ftqIdxSelOH = io.fromBackend.ftqIdxSelOH.bits(FtqRedirectAheadNum
      - 1, 0)\n536: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 532-560
    context: "532: \n533:   // io.fromBackend.ftqIdxAhead: bju(BjuCnt) + ldReplay
      + exception\n534:   val ftqIdxAhead = VecInit(Seq.tabulate(FtqRedirectAheadNum)(i
      => io.fromBackend.ftqIdxAhead(i))) // only bju\n535:   val ftqIdxSelOH = io.fromBackend.ftqIdxSelOH.bits(FtqRedirectAheadNum
      - 1, 0)\n536: \n537:   val aheadValid         = ftqIdxAhead.map(_.valid).reduce(_
      | _) && !io.fromBackend.redirect.valid\n538:   val realAhdValid       = io.fromBackend.redirect.valid
      && (ftqIdxSelOH > 0.U) && RegNext(aheadValid)\n539:   val backendRedirect  \
      \  = Wire(Valid(new BranchPredictionRedirect))\n540:   val backendRedirectReg
      = Wire(Valid(new BranchPredictionRedirect))\n541:   backendRedirectReg.valid
      := RegNext(Mux(realAhdValid, false.B, backendRedirect.valid))\n542:   backendRedirectReg.bits\
      \  := RegEnable(backendRedirect.bits, backendRedirect.valid)\n543:   val fromBackendRedirect
      = Wire(Valid(new BranchPredictionRedirect))\n544:   fromBackendRedirect := Mux(realAhdValid,
      backendRedirect, backendRedirectReg)\n545: \n546:   val stage2Flush  = backendRedirect.valid\n\
      547:   val backendFlush = stage2Flush || RegNext(stage2Flush)\n548:   val ifuFlush\
      \     = Wire(Bool())\n549: \n550:   val flush = stage2Flush || RegNext(stage2Flush)\n\
      551: \n552:   val allowBpuIn, allowToIfu = WireInit(false.B)\n553:   val flushToIfu\
      \             = !allowToIfu\n554:   allowBpuIn := !ifuFlush && !backendRedirect.valid
      && !backendRedirectReg.valid\n555:   allowToIfu := !ifuFlush && !backendRedirect.valid
      && !backendRedirectReg.valid\n556: \n557:   def copyNum                    \
      \                          = 5\n558:   val bpuPtr, ifuPtr, pfPtr, ifuWbPtr,
      commPtr, robCommPtr = RegInit(FtqPtr(false.B, 0.U))\n559:   val ifuPtrPlus1\
      \                                          = RegInit(FtqPtr(false.B, 1.U))\n\
      560:   val ifuPtrPlus2                                          = RegInit(FtqPtr(false.B,
      2.U))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 613-632
    context: "613: \n614:   // **********************************************************************\n\
      615:   // **************************** enq from bpu ****************************\n\
      616:   // **********************************************************************\n\
      617:   val new_entry_ready = validEntries < FtqSize.U || canCommit\n618:   io.fromBpu.resp.ready
      := new_entry_ready\n619: \n620:   val bpu_s2_resp     = io.fromBpu.resp.bits.s2\n\
      621:   val bpu_s3_resp     = io.fromBpu.resp.bits.s3\n622:   val bpu_s2_redirect
      = bpu_s2_resp.valid(3) && bpu_s2_resp.hasRedirect(3)\n623:   val bpu_s3_redirect
      = bpu_s3_resp.valid(3) && bpu_s3_resp.hasRedirect(3)\n624: \n625:   io.toBpu.enq_ptr
      := bpuPtr\n626:   val enq_fire    = io.fromBpu.resp.fire && allowBpuIn // from
      bpu s1\n627:   val bpu_in_fire = (io.fromBpu.resp.fire || bpu_s2_redirect ||
      bpu_s3_redirect) && allowBpuIn\n628: \n629:   val bpu_in_resp     = io.fromBpu.resp.bits.selectedResp\n\
      630:   val bpu_in_stage    = io.fromBpu.resp.bits.selectedRespIdxForFtq\n631:\
      \   val bpu_in_resp_ptr = Mux(bpu_in_stage === BP_S1, bpuPtr, bpu_in_resp.ftq_idx)\n\
      632:   val bpu_in_resp_idx = bpu_in_resp_ptr.value"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 637-658
    context: "637:   ftq_pc_mem.io.wen   := bpu_in_fire\n638:   ftq_pc_mem.io.waddr
      := bpu_in_resp_idx\n639:   ftq_pc_mem.io.wdata.fromBranchPrediction(bpu_in_resp)\n\
      640: \n641:   //                                                           \
      \ ifuRedirect + backendRedirect + commit\n642:   val ftq_redirect_mem = Module(new
      SyncDataModuleTemplate(\n643:     new Ftq_Redirect_SRAMEntry,\n644:     FtqSize,\n\
      645:     IfuRedirectNum + FtqRedirectAheadNum + 1,\n646:     1,\n647:     hasRen
      = true\n648:   ))\n649:   // these info is intended to enq at the last stage
      of bpu\n650:   ftq_redirect_mem.io.wen(0)   := io.fromBpu.resp.bits.lastStage.valid(3)\n\
      651:   ftq_redirect_mem.io.waddr(0) := io.fromBpu.resp.bits.lastStage.ftq_idx.value\n\
      652:   ftq_redirect_mem.io.wdata(0) := io.fromBpu.resp.bits.last_stage_spec_info\n\
      653:   println(f\"ftq redirect MEM: entry ${ftq_redirect_mem.io.wdata(0).getWidth}
      * ${FtqSize} * 3\")\n654: \n655:   val ftq_meta_1r_sram = Module(new FtqNRSRAM(new
      Ftq_1R_SRAMEntry, 1))\n656:   // these info is intended to enq at the last stage
      of bpu\n657:   ftq_meta_1r_sram.io.wen             := io.fromBpu.resp.bits.lastStage.valid(3)\n\
      658:   ftq_meta_1r_sram.io.waddr           := io.fromBpu.resp.bits.lastStage.ftq_idx.value"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 660-670
    context: "660:   ftq_meta_1r_sram.io.wdata.ftb_entry := io.fromBpu.resp.bits.last_stage_ftb_entry\n\
      661:   //                                                            ifuRedirect
      + backendRedirect (commit moved to ftq_meta_1r_sram)\n662:   val ftb_entry_mem
      = Module(new SyncDataModuleTemplate(\n663:     new FTBEntry_FtqMem,\n664:  \
      \   FtqSize,\n665:     IfuRedirectNum + FtqRedirectAheadNum,\n666:     1,\n\
      667:     hasRen = true\n668:   ))\n669:   ftb_entry_mem.io.wen(0)   := io.fromBpu.resp.bits.lastStage.valid(3)\n\
      670:   ftb_entry_mem.io.waddr(0) := io.fromBpu.resp.bits.lastStage.ftq_idx.value"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 676-699
    context: "676:   val newest_entry_target          = Reg(UInt(VAddrBits.W))\n677:\
      \   val newest_entry_target_modified = RegInit(false.B)\n678:   val newest_entry_ptr\
      \             = Reg(new FtqPtr)\n679:   val newest_entry_ptr_modified    = RegInit(false.B)\n\
      680:   val cfiIndex_vec                 = Reg(Vec(FtqSize, ValidUndirectioned(UInt(log2Ceil(PredictWidth).W))))\n\
      681:   val mispredict_vec               = Reg(Vec(FtqSize, Vec(PredictWidth,
      Bool())))\n682:   val pred_stage                   = Reg(Vec(FtqSize, UInt(2.W)))\n\
      683:   val pred_s1_cycle                = if (!env.FPGAPlatform) Some(Reg(Vec(FtqSize,
      UInt(64.W)))) else None\n684: \n685:   val c_empty :: c_toCommit :: c_committed
      :: c_flushed :: Nil = Enum(4)\n686:   val commitStateQueueReg = RegInit(VecInit(Seq.fill(FtqSize)
      {\n687:     VecInit(Seq.fill(PredictWidth)(c_empty))\n688:   }))\n689:   val
      commitStateQueueEnable = WireInit(VecInit(Seq.fill(FtqSize)(false.B)))\n690:\
      \   val commitStateQueueNext   = WireInit(commitStateQueueReg)\n691: \n692:\
      \   for (f <- 0 until FtqSize) {\n693:     when(commitStateQueueEnable(f)) {\n\
      694:       commitStateQueueReg(f) := commitStateQueueNext(f)\n695:     }\n696:\
      \   }\n697: \n698:   val f_to_send :: f_sent :: Nil = Enum(2)\n699:   val entry_fetch_status\
      \         = RegInit(VecInit(Seq.fill(FtqSize)(f_sent)))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 729-739
    context: "729:     newest_entry_ptr                     := last_cycle_bpu_in_ptr\n\
      730:   }\n731: \n732:   // reduce fanout by delay write for a cycle\n733:  \
      \ when(RegNext(last_cycle_bpu_in)) {\n734:     mispredict_vec(RegEnable(last_cycle_bpu_in_idx,
      last_cycle_bpu_in)) :=\n735:       WireInit(VecInit(Seq.fill(PredictWidth)(false.B)))\n\
      736:   }\n737: \n738:   // record s1 pred cycles\n739:   pred_s1_cycle.map {
      vec =>"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 749-759
    context: "749:       when(in) {\n750:         val perSetEntries = FtqSize / extra_copyNum_for_commitStateQueue
      // 32\n751:         require(FtqSize % extra_copyNum_for_commitStateQueue ==
      0)\n752:         for (j <- 0 until perSetEntries) {\n753:           when(ptr.value
      === (i * perSetEntries + j).U) {\n754:             commitStateQueueNext(i *
      perSetEntries + j) := VecInit(Seq.fill(PredictWidth)(c_empty))\n755:       \
      \      // Clock gating optimization, use 1 gate cell to control a row\n756:\
      \             commitStateQueueEnable(i * perSetEntries + j) := true.B\n757:\
      \           }\n758:         }\n759:       }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 759-774
    context: "759:       }\n760:   }\n761: \n762:   bpuPtr := bpuPtr + enq_fire\n\
      763:   copied_bpu_ptr.map(_ := bpuPtr + enq_fire)\n764:   when(io.toIfu.req.fire
      && allowToIfu) {\n765:     ifuPtr_write      := ifuPtrPlus1\n766:     ifuPtrPlus1_write
      := ifuPtrPlus2\n767:     ifuPtrPlus2_write := ifuPtrPlus2 + 1.U\n768:   }\n\
      769:   when(io.toPrefetch.req.fire && allowToIfu) {\n770:     pfPtr_write  \
      \    := pfPtrPlus1\n771:     pfPtrPlus1_write := pfPtrPlus1 + 1.U\n772:   }\n\
      773: \n774:   // only use ftb result to assign hit status"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 774-788
    context: "774:   // only use ftb result to assign hit status\n775:   when(bpu_s2_resp.valid(3))
      {\n776:     entry_hit_status(bpu_s2_resp.ftq_idx.value) := Mux(bpu_s2_resp.full_pred(3).hit,
      h_hit, h_not_hit)\n777:   }\n778: \n779:   io.toIfu.flushFromBpu.s2.valid  \
      \    := bpu_s2_redirect\n780:   io.toIfu.flushFromBpu.s2.bits       := bpu_s2_resp.ftq_idx\n\
      781:   io.toPrefetch.flushFromBpu.s2.valid := bpu_s2_redirect\n782:   io.toPrefetch.flushFromBpu.s2.bits\
      \  := bpu_s2_resp.ftq_idx\n783:   when(bpu_s2_redirect) {\n784:     bpuPtr :=
      bpu_s2_resp.ftq_idx + 1.U\n785:     copied_bpu_ptr.map(_ := bpu_s2_resp.ftq_idx
      + 1.U)\n786:     // only when ifuPtr runs ahead of bpu s2 resp should we recover
      it\n787:     when(!isBefore(ifuPtr, bpu_s2_resp.ftq_idx)) {\n788:       ifuPtr_write\
      \      := bpu_s2_resp.ftq_idx"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 793-807
    context: "793:       pfPtr_write      := bpu_s2_resp.ftq_idx\n794:       pfPtrPlus1_write
      := bpu_s2_resp.ftq_idx + 1.U\n795:     }\n796:   }\n797: \n798:   io.toIfu.flushFromBpu.s3.valid\
      \      := bpu_s3_redirect\n799:   io.toIfu.flushFromBpu.s3.bits       := bpu_s3_resp.ftq_idx\n\
      800:   io.toPrefetch.flushFromBpu.s3.valid := bpu_s3_redirect\n801:   io.toPrefetch.flushFromBpu.s3.bits\
      \  := bpu_s3_resp.ftq_idx\n802:   when(bpu_s3_redirect) {\n803:     bpuPtr :=
      bpu_s3_resp.ftq_idx + 1.U\n804:     copied_bpu_ptr.map(_ := bpu_s3_resp.ftq_idx
      + 1.U)\n805:     // only when ifuPtr runs ahead of bpu s2 resp should we recover
      it\n806:     when(!isBefore(ifuPtr, bpu_s3_resp.ftq_idx)) {\n807:       ifuPtr_write\
      \      := bpu_s3_resp.ftq_idx"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 826-840
    context: "826:   // 0  for ifu, and 1-4 for ICache\n827:   val bpu_in_bypass_buf\
      \         = RegEnable(ftq_pc_mem.io.wdata, bpu_in_fire)\n828:   val copied_bpu_in_bypass_buf\
      \  = VecInit(Seq.fill(copyNum)(RegEnable(ftq_pc_mem.io.wdata, bpu_in_fire)))\n\
      829:   val bpu_in_bypass_buf_for_ifu = bpu_in_bypass_buf\n830:   val bpu_in_bypass_ptr\
      \         = RegEnable(bpu_in_resp_ptr, bpu_in_fire)\n831:   val last_cycle_to_ifu_fire\
      \    = RegNext(io.toIfu.req.fire)\n832:   val last_cycle_to_pf_fire     = RegNext(io.toPrefetch.req.fire)\n\
      833: \n834:   val copied_bpu_in_bypass_ptr      = VecInit(Seq.fill(copyNum)(RegEnable(bpu_in_resp_ptr,
      bpu_in_fire)))\n835:   val copied_last_cycle_to_ifu_fire = VecInit(Seq.fill(copyNum)(RegNext(io.toIfu.req.fire)))\n\
      836: \n837:   // read pc and target\n838:   ftq_pc_mem.io.ifuPtr_w       :=
      ifuPtr_write\n839:   ftq_pc_mem.io.ifuPtrPlus1_w  := ifuPtrPlus1_write\n840:\
      \   ftq_pc_mem.io.ifuPtrPlus2_w  := ifuPtrPlus2_write"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 882-892
    context: "882: \n883:   // Calculate requests sent to prefetcher one cycle in
      advance to cut critical path\n884:   when(bpu_in_fire && bpu_in_resp_ptr ===
      pfPtr_write) {\n885:     nextCycleToPrefetchPcBundle    := ftq_pc_mem.io.wdata\n\
      886:     nextCycleToPrefetchEntryToSend := true.B\n887:   }.elsewhen(io.toPrefetch.req.fire)
      {\n888:     nextCycleToPrefetchPcBundle := ftq_pc_mem.io.pfPtrPlus1_rdata\n\
      889:     nextCycleToPrefetchEntryToSend := entry_fetch_status(pfPtrPlus1.value)
      === f_to_send ||\n890:       last_cycle_bpu_in && bpu_in_bypass_ptr === pfPtrPlus1\n\
      891:   }.otherwise {\n892:     nextCycleToPrefetchPcBundle := ftq_pc_mem.io.pfPtr_rdata"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 928-938
    context: "928: \n929:   io.toICache.req.valid := entry_is_to_send && ifuPtr =/=
      bpuPtr\n930:   io.toICache.req.bits.readValid.zipWithIndex.map { case (copy,
      i) =>\n931:     copy := toICacheEntryToSend(i) && copied_ifu_ptr(i) =/= copied_bpu_ptr(i)\n\
      932:   }\n933:   io.toICache.req.bits.pcMemRead.zipWithIndex.foreach { case
      (copy, i) =>\n934:     copy.fromFtqPcBundle(toICachePcBundle(i))\n935:     copy.ftqIdx
      := ifuPtr\n936:   }\n937:   io.toICache.req.bits.backendException := ExceptionType.hasException(backendException)
      && backendPcFaultPtr === ifuPtr\n938: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 952-964
    context: "952:     p\"\\nifu_req_target wrong! ifuPtr: ${ifuPtr}, entry_next_addr:
      ${Hexadecimal(entry_next_addr)} diff_entry_next_addr: ${Hexadecimal(diff_entry_next_addr)}\\\
      n\"\n953:   )\n954: \n955:   // when fall through is smaller in value than start
      address, there must be a false hit\n956:   when(toIfuPcBundle.fallThruError
      && entry_hit_status(ifuPtr.value) === h_hit) {\n957:     when(io.toIfu.req.fire
      &&\n958:       !(bpu_s2_redirect && bpu_s2_resp.ftq_idx === ifuPtr) &&\n959:\
      \       !(bpu_s3_redirect && bpu_s3_resp.ftq_idx === ifuPtr)) {\n960:      \
      \ entry_hit_status(ifuPtr.value) := h_false_hit\n961:       // XSError(true.B,
      \"FTB false hit by fallThroughError, startAddr: %x, fallTHru: %x\\n\", io.toIfu.req.bits.startAddr,
      io.toIfu.req.bits.nextStartAddr)\n962:     }\n963:   }\n964:   XSDebug("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 969-979
    context: "969:   )\n970: \n971:   XSPerfAccumulate(\n972:     f\"fall_through_error_to_ifu\"\
      ,\n973:     toIfuPcBundle.fallThruError && entry_hit_status(ifuPtr.value) ===
      h_hit &&\n974:       io.toIfu.req.fire && !(bpu_s2_redirect && bpu_s2_resp.ftq_idx
      === ifuPtr) && !(bpu_s3_redirect && bpu_s3_resp.ftq_idx === ifuPtr)\n975:  \
      \ )\n976: \n977:   val ifu_req_should_be_flushed =\n978:     io.toIfu.flushFromBpu.shouldFlushByStage2(io.toIfu.req.bits.ftqIdx)
      ||\n979:       io.toIfu.flushFromBpu.shouldFlushByStage3(io.toIfu.req.bits.ftqIdx)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 976-986
    context: "976: \n977:   val ifu_req_should_be_flushed =\n978:     io.toIfu.flushFromBpu.shouldFlushByStage2(io.toIfu.req.bits.ftqIdx)
      ||\n979:       io.toIfu.flushFromBpu.shouldFlushByStage3(io.toIfu.req.bits.ftqIdx)\n\
      980: \n981:   when(io.toIfu.req.fire && !ifu_req_should_be_flushed) {\n982:\
      \     entry_fetch_status(ifuPtr.value) := f_sent\n983:   }\n984: \n985:   //
      *********************************************************************\n986:\
      \   // **************************** wb from ifu ****************************"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 995-1005
    context: "995:   ftq_pd_mem.io.wen(0)   := ifu_wb_valid\n996:   ftq_pd_mem.io.waddr(0)
      := pdWb.bits.ftqIdx.value\n997:   ftq_pd_mem.io.wdata(0).fromPdWb(pdWb.bits)\n\
      998: \n999:   val hit_pd_valid       = entry_hit_status(ifu_wb_idx) === h_hit
      && ifu_wb_valid\n1000:   val hit_pd_mispred     = hit_pd_valid && pdWb.bits.misOffset.valid\n\
      1001:   val hit_pd_mispred_reg = RegNext(hit_pd_mispred, init = false.B)\n1002:\
      \   val pd_reg             = RegEnable(pds, pdWb.valid)\n1003:   val start_pc_reg\
      \       = RegEnable(pdWb.bits.pc(0), pdWb.valid)\n1004:   val wb_idx_reg   \
      \      = RegEnable(ifu_wb_idx, pdWb.valid)\n1005: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1006-1018
    context: "1006:   when(ifu_wb_valid) {\n1007:     val comm_stq_wen = VecInit(pds.map(_.valid).zip(pdWb.bits.instrRange).map
      {\n1008:       case (v, inRange) => v && inRange\n1009:     })\n1010:     commitStateQueueEnable(ifu_wb_idx)
      := true.B\n1011:     (commitStateQueueNext(ifu_wb_idx) zip comm_stq_wen).map
      {\n1012:       case (qe, v) => when(v) {\n1013:           qe := c_toCommit\n\
      1014:         }\n1015:     }\n1016:   }\n1017: \n1018:   when(ifu_wb_valid)
      {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1017-1034
    context: "1017: \n1018:   when(ifu_wb_valid) {\n1019:     ifuWbPtr_write := ifuWbPtr
      + 1.U\n1020:   }\n1021: \n1022:   XSError(ifu_wb_valid && isAfter(pdWb.bits.ftqIdx,
      ifuPtr), \"IFU returned a predecode before its req, check IFU\")\n1023: \n1024:\
      \   ftb_entry_mem.io.ren.get.head := ifu_wb_valid\n1025:   ftb_entry_mem.io.raddr.head\
      \   := ifu_wb_idx\n1026:   val has_false_hit = WireInit(false.B)\n1027:   when(RegNext(hit_pd_valid))
      {\n1028:     // check for false hit\n1029:     val pred_ftb_entry = ftb_entry_mem.io.rdata.head\n\
      1030:     val brSlots        = pred_ftb_entry.brSlots\n1031:     val tailSlot\
      \       = pred_ftb_entry.tailSlot\n1032:     // we check cfis that bpu predicted\n\
      1033: \n1034:     // bpu predicted branches but denied by predecode"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1064-1116
    context: "1064:   // **************************** redirect from backend ****************************\n\
      1065:   // *******************************************************************************\n\
      1066: \n1067:   // redirect read cfiInfo, couples to redirectGen s2\n1068: \
      \  // ftqIdxAhead(0-3) => ftq_redirect_mem(1-4), reuse ftq_redirect_mem(1)\n\
      1069:   val ftq_redirect_rdata = Wire(Vec(FtqRedirectAheadNum, new Ftq_Redirect_SRAMEntry))\n\
      1070:   val ftb_redirect_rdata = Wire(Vec(FtqRedirectAheadNum, new FTBEntry_FtqMem))\n\
      1071: \n1072:   val ftq_pd_rdata = Wire(Vec(FtqRedirectAheadNum, new Ftq_pd_Entry))\n\
      1073:   for (i <- 1 until FtqRedirectAheadNum) {\n1074:     ftq_redirect_mem.io.ren.get(i
      + IfuRedirectNum) := ftqIdxAhead(i).valid\n1075:     ftq_redirect_mem.io.raddr(i
      + IfuRedirectNum)   := ftqIdxAhead(i).bits.value\n1076:     ftb_entry_mem.io.ren.get(i
      + IfuRedirectNum)    := ftqIdxAhead(i).valid\n1077:     ftb_entry_mem.io.raddr(i
      + IfuRedirectNum)      := ftqIdxAhead(i).bits.value\n1078: \n1079:     ftq_pd_mem.io.ren.get(i)
      := ftqIdxAhead(i).valid\n1080:     ftq_pd_mem.io.raddr(i)   := ftqIdxAhead(i).bits.value\n\
      1081:   }\n1082:   ftq_redirect_mem.io.ren.get(IfuRedirectNum) := Mux(aheadValid,
      ftqIdxAhead(0).valid, backendRedirect.valid)\n1083:   ftq_redirect_mem.io.raddr(IfuRedirectNum)
      := Mux(\n1084:     aheadValid,\n1085:     ftqIdxAhead(0).bits.value,\n1086:\
      \     backendRedirect.bits.ftqIdx.value\n1087:   )\n1088:   ftb_entry_mem.io.ren.get(IfuRedirectNum)
      := Mux(aheadValid, ftqIdxAhead(0).valid, backendRedirect.valid)\n1089:   ftb_entry_mem.io.raddr(IfuRedirectNum)
      := Mux(\n1090:     aheadValid,\n1091:     ftqIdxAhead(0).bits.value,\n1092:\
      \     backendRedirect.bits.ftqIdx.value\n1093:   )\n1094: \n1095:   ftq_pd_mem.io.ren.get(0)
      := Mux(aheadValid, ftqIdxAhead(0).valid, backendRedirect.valid)\n1096:   ftq_pd_mem.io.raddr(0)\
      \   := Mux(aheadValid, ftqIdxAhead(0).bits.value, backendRedirect.bits.ftqIdx.value)\n\
      1097: \n1098:   for (i <- 0 until FtqRedirectAheadNum) {\n1099:     ftq_redirect_rdata(i)
      := ftq_redirect_mem.io.rdata(i + IfuRedirectNum)\n1100:     ftb_redirect_rdata(i)
      := ftb_entry_mem.io.rdata(i + IfuRedirectNum)\n1101: \n1102:     ftq_pd_rdata(i)
      := ftq_pd_mem.io.rdata(i)\n1103:   }\n1104:   val stage3CfiInfo =\n1105:   \
      \  Mux(realAhdValid, Mux1H(ftqIdxSelOH, ftq_redirect_rdata), ftq_redirect_mem.io.rdata(IfuRedirectNum))\n\
      1106:   val stage3PdInfo       = Mux(realAhdValid, Mux1H(ftqIdxSelOH, ftq_pd_rdata),
      ftq_pd_mem.io.rdata(0))\n1107:   val backendRedirectCfi = fromBackendRedirect.bits.cfiUpdate\n\
      1108:   backendRedirectCfi.fromFtqRedirectSram(stage3CfiInfo)\n1109:   backendRedirectCfi.pd
      := stage3PdInfo.toPd(fromBackendRedirect.bits.ftqOffset)\n1110: \n1111:   val
      r_ftb_entry = Mux(realAhdValid, Mux1H(ftqIdxSelOH, ftb_redirect_rdata), ftb_entry_mem.io.rdata(IfuRedirectNum))\n\
      1112:   val r_ftqOffset = fromBackendRedirect.bits.ftqOffset\n1113: \n1114:\
      \   backendRedirectCfi.br_hit := r_ftb_entry.brIsSaved(r_ftqOffset)\n1115: \
      \  backendRedirectCfi.jr_hit := r_ftb_entry.isJalr && r_ftb_entry.tailSlot.offset
      === r_ftqOffset\n1116:   // FIXME: not portable"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1134-1178
    context: "1134:   }\n1135: \n1136:   // ***************************************************************************\n\
      1137:   // **************************** redirect from ifu ****************************\n\
      1138:   // ***************************************************************************\n\
      1139:   val fromIfuRedirect = WireInit(0.U.asTypeOf(Valid(new BranchPredictionRedirect)))\n\
      1140:   fromIfuRedirect.valid              := pdWb.valid && pdWb.bits.misOffset.valid
      && !backendFlush\n1141:   fromIfuRedirect.bits.ftqIdx        := pdWb.bits.ftqIdx\n\
      1142:   fromIfuRedirect.bits.ftqOffset     := pdWb.bits.misOffset.bits\n1143:\
      \   fromIfuRedirect.bits.level         := RedirectLevel.flushAfter\n1144:  \
      \ fromIfuRedirect.bits.BTBMissBubble := true.B\n1145:   fromIfuRedirect.bits.debugIsMemVio
      := false.B\n1146:   fromIfuRedirect.bits.debugIsCtrl   := false.B\n1147: \n\
      1148:   val ifuRedirectCfiUpdate = fromIfuRedirect.bits.cfiUpdate\n1149:   ifuRedirectCfiUpdate.pc\
      \        := pdWb.bits.pc(pdWb.bits.misOffset.bits)\n1150:   ifuRedirectCfiUpdate.pd\
      \        := pdWb.bits.pd(pdWb.bits.misOffset.bits)\n1151:   ifuRedirectCfiUpdate.predTaken
      := cfiIndex_vec(pdWb.bits.ftqIdx.value).valid\n1152:   ifuRedirectCfiUpdate.target\
      \    := pdWb.bits.target\n1153:   ifuRedirectCfiUpdate.taken     := pdWb.bits.cfiOffset.valid\n\
      1154:   ifuRedirectCfiUpdate.isMisPred := pdWb.bits.misOffset.valid\n1155: \n\
      1156:   val ifuRedirectReg   = RegNextWithEnable(fromIfuRedirect, hasInit =
      true)\n1157:   val ifuRedirectToBpu = WireInit(ifuRedirectReg)\n1158:   ifuFlush
      := fromIfuRedirect.valid || ifuRedirectToBpu.valid\n1159: \n1160:   ftq_redirect_mem.io.ren.get.head
      := fromIfuRedirect.valid\n1161:   ftq_redirect_mem.io.raddr.head   := fromIfuRedirect.bits.ftqIdx.value\n\
      1162: \n1163:   val toBpuCfi = ifuRedirectToBpu.bits.cfiUpdate\n1164:   toBpuCfi.fromFtqRedirectSram(ftq_redirect_mem.io.rdata.head)\n\
      1165:   when(ifuRedirectReg.bits.cfiUpdate.pd.isRet && ifuRedirectReg.bits.cfiUpdate.pd.valid)
      {\n1166:     toBpuCfi.target := toBpuCfi.topAddr\n1167:   }\n1168: \n1169: \
      \  when(ifuRedirectReg.valid) {\n1170:     ifuRedirected(ifuRedirectReg.bits.ftqIdx.value)
      := true.B\n1171:   }.elsewhen(RegNext(pdWb.valid)) {\n1172:     // if pdWb and
      no redirect, set to false\n1173:     ifuRedirected(last_cycle_bpu_in_ptr.value)
      := false.B\n1174:   }\n1175: \n1176:   // **********************************************************************\n\
      1177:   // ***************************** to backend *****************************\n\
      1178:   // **********************************************************************"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1180-1190
    context: "1180:   io.toBackend.pc_mem_wen   := RegNext(last_cycle_bpu_in)\n1181:\
      \   io.toBackend.pc_mem_waddr := RegEnable(last_cycle_bpu_in_idx, last_cycle_bpu_in)\n\
      1182:   io.toBackend.pc_mem_wdata := RegEnable(bpu_in_bypass_buf_for_ifu, last_cycle_bpu_in)\n\
      1183: \n1184:   // num cycle is fixed\n1185:   val newest_entry_en: Bool = RegNext(last_cycle_bpu_in
      || backendRedirect.valid || ifuRedirectToBpu.valid)\n1186:   io.toBackend.newest_entry_en\
      \     := RegNext(newest_entry_en)\n1187:   io.toBackend.newest_entry_ptr   \
      \ := RegEnable(newest_entry_ptr, newest_entry_en)\n1188:   io.toBackend.newest_entry_target
      := RegEnable(newest_entry_target, newest_entry_en)\n1189: \n1190:   // *********************************************************************"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1189-1203
    context: "1189: \n1190:   // *********************************************************************\n\
      1191:   // **************************** wb from exu ****************************\n\
      1192:   // *********************************************************************\n\
      1193: \n1194:   backendRedirect.valid := io.fromBackend.redirect.valid\n1195:\
      \   backendRedirect.bits.connectRedirect(io.fromBackend.redirect.bits)\n1196:\
      \   backendRedirect.bits.BTBMissBubble := false.B\n1197: \n1198:   def extractRedirectInfo(wb:
      Valid[Redirect]) = {\n1199:     val ftqPtr    = wb.bits.ftqIdx\n1200:     val
      ftqOffset = wb.bits.ftqOffset\n1201:     val taken     = wb.bits.cfiUpdate.taken\n\
      1202:     val mispred   = wb.bits.cfiUpdate.isMisPred\n1203:     (wb.valid,
      ftqPtr, ftqOffset, taken, mispred)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1203-1218
    context: "1203:     (wb.valid, ftqPtr, ftqOffset, taken, mispred)\n1204:   }\n\
      1205: \n1206:   // fix mispredict entry\n1207:   val lastIsMispredict = RegNext(\n\
      1208:     backendRedirect.valid && backendRedirect.bits.level === RedirectLevel.flushAfter,\n\
      1209:     init = false.B\n1210:   )\n1211: \n1212:   def updateCfiInfo(redirect:
      Valid[Redirect], isBackend: Boolean = true) = {\n1213:     val (r_valid, r_ptr,
      r_offset, r_taken, r_mispred) = extractRedirectInfo(redirect)\n1214:     val
      r_idx                                          = r_ptr.value\n1215:     val
      cfiIndex_bits_wen                              = r_valid && r_taken && r_offset
      < cfiIndex_vec(r_idx).bits\n1216:     val cfiIndex_valid_wen               \
      \              = r_valid && r_offset === cfiIndex_vec(r_idx).bits\n1217:   \
      \  when(cfiIndex_bits_wen || cfiIndex_valid_wen) {\n1218:       cfiIndex_vec(r_idx).valid
      := cfiIndex_bits_wen || cfiIndex_valid_wen && r_taken"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1221-1237
    context: "1221:     }\n1222:     when(cfiIndex_bits_wen) {\n1223:       cfiIndex_vec(r_idx).bits
      := r_offset\n1224:     }\n1225:     newest_entry_target_modified := true.B\n\
      1226:     newest_entry_target          := redirect.bits.cfiUpdate.target\n1227:\
      \     newest_entry_ptr_modified    := true.B\n1228:     newest_entry_ptr   \
      \          := r_ptr\n1229: \n1230:     update_target(r_idx) := redirect.bits.cfiUpdate.target
      // TODO: remove this\n1231:     if (isBackend) {\n1232:       mispredict_vec(r_idx)(r_offset)
      := r_mispred\n1233:     }\n1234:   }\n1235: \n1236:   when(fromBackendRedirect.valid)
      {\n1237:     updateCfiInfo(fromBackendRedirect)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1233-1244
    context: "1233:     }\n1234:   }\n1235: \n1236:   when(fromBackendRedirect.valid)
      {\n1237:     updateCfiInfo(fromBackendRedirect)\n1238:   }.elsewhen(ifuRedirectToBpu.valid)
      {\n1239:     updateCfiInfo(ifuRedirectToBpu, isBackend = false)\n1240:   }\n\
      1241: \n1242:   when(fromBackendRedirect.valid) {\n1243:     when(fromBackendRedirect.bits.ControlRedirectBubble)
      {\n1244:       when(fromBackendRedirect.bits.ControlBTBMissBubble) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1256-1273
    context: "1256:       }.elsewhen(fromBackendRedirect.bits.RASMissBubble) {\n1257:\
      \         topdown_stage.reasons(TopDownCounters.RASMissBubble.id)          \
      \        := true.B\n1258:         io.toIfu.req.bits.topdown_info.reasons(TopDownCounters.RASMissBubble.id)
      := true.B\n1259:       }\n1260: \n1261:     }.elsewhen(backendRedirect.bits.MemVioRedirectBubble)
      {\n1262:       topdown_stage.reasons(TopDownCounters.MemVioRedirectBubble.id)\
      \                  := true.B\n1263:       io.toIfu.req.bits.topdown_info.reasons(TopDownCounters.MemVioRedirectBubble.id)
      := true.B\n1264:     }.otherwise {\n1265:       topdown_stage.reasons(TopDownCounters.OtherRedirectBubble.id)\
      \                  := true.B\n1266:       io.toIfu.req.bits.topdown_info.reasons(TopDownCounters.OtherRedirectBubble.id)
      := true.B\n1267:     }\n1268:   }.elsewhen(ifuRedirectReg.valid) {\n1269:  \
      \   topdown_stage.reasons(TopDownCounters.BTBMissBubble.id)                \
      \  := true.B\n1270:     io.toIfu.req.bits.topdown_info.reasons(TopDownCounters.BTBMissBubble.id)
      := true.B\n1271:   }\n1272: \n1273:   io.ControlBTBMissBubble := fromBackendRedirect.bits.ControlBTBMissBubble"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1278-1297
    context: "1278: \n1279:   // ***********************************************************************************\n\
      1280:   // **************************** flush ptr and state queue ****************************\n\
      1281:   // ***********************************************************************************\n\
      1282: \n1283:   val redirectVec = VecInit(backendRedirect, fromIfuRedirect)\n\
      1284: \n1285:   // when redirect, we should reset ptrs and status queues\n1286:\
      \   io.icacheFlush := redirectVec.map(r => r.valid).reduce(_ || _)\n1287:  \
      \ XSPerfAccumulate(\"icacheFlushFromBackend\", backendRedirect.valid)\n1288:\
      \   XSPerfAccumulate(\"icacheFlushFromIFU\", fromIfuRedirect.valid)\n1289: \
      \  when(redirectVec.map(r => r.valid).reduce(_ || _)) {\n1290:     val r   \
      \                       = PriorityMux(redirectVec.map(r => r.valid -> r.bits))\n\
      1291:     val notIfu                     = redirectVec.dropRight(1).map(r =>
      r.valid).reduce(_ || _)\n1292:     val (idx, offset, flushItSelf) = (r.ftqIdx,
      r.ftqOffset, RedirectLevel.flushItself(r.level))\n1293:     val next       \
      \                = idx + 1.U\n1294:     bpuPtr := next\n1295:     copied_bpu_ptr.map(_
      := next)\n1296:     ifuPtr_write      := next\n1297:     ifuWbPtr_write    :=
      next"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1298-1319
    context: "1298:     ifuPtrPlus1_write := idx + 2.U\n1299:     ifuPtrPlus2_write
      := idx + 3.U\n1300:     pfPtr_write       := next\n1301:     pfPtrPlus1_write\
      \  := idx + 2.U\n1302:   }\n1303:   when(RegNext(redirectVec.map(r => r.valid).reduce(_
      || _))) {\n1304:     val r                          = PriorityMux(redirectVec.map(r
      => r.valid -> r.bits))\n1305:     val notIfu                     = redirectVec.dropRight(1).map(r
      => r.valid).reduce(_ || _)\n1306:     val (idx, offset, flushItSelf) = (r.ftqIdx,
      r.ftqOffset, RedirectLevel.flushItself(r.level))\n1307:     when(RegNext(notIfu))
      {\n1308:       commitStateQueueEnable(RegNext(idx.value)) := true.B\n1309: \
      \      commitStateQueueNext(RegNext(idx.value)).zipWithIndex.foreach { case
      (s, i) =>\n1310:         when(i.U > RegNext(offset)) {\n1311:           s :=
      c_empty\n1312:         }\n1313:         when(i.U === RegNext(offset) && RegNext(flushItSelf))
      {\n1314:           s := c_flushed\n1315:         }\n1316:       }\n1317:   \
      \  }\n1318:   }\n1319: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1316-1328
    context: "1316:       }\n1317:     }\n1318:   }\n1319: \n1320:   // only the valid
      bit is actually needed\n1321:   io.toIfu.redirect.bits    := backendRedirect.bits\n\
      1322:   io.toIfu.redirect.valid   := stage2Flush\n1323:   io.toIfu.topdown_redirect
      := fromBackendRedirect\n1324: \n1325:   // commit\n1326:   for (c <- io.fromBackend.rob_commits)
      {\n1327:     when(c.valid) {\n1328:       commitStateQueueEnable(c.bits.ftqIdx.value)\
      \                 := true.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1324-1348
    context: "1324: \n1325:   // commit\n1326:   for (c <- io.fromBackend.rob_commits)
      {\n1327:     when(c.valid) {\n1328:       commitStateQueueEnable(c.bits.ftqIdx.value)\
      \                 := true.B\n1329:       commitStateQueueNext(c.bits.ftqIdx.value)(c.bits.ftqOffset)
      := c_committed\n1330:       // TODO: remove this\n1331:       // For instruction
      fusions, we also update the next instruction\n1332:       when(c.bits.commitType
      === 4.U) {\n1333:         commitStateQueueNext(c.bits.ftqIdx.value)(c.bits.ftqOffset
      + 1.U) := c_committed\n1334:       }.elsewhen(c.bits.commitType === 5.U) {\n\
      1335:         commitStateQueueNext(c.bits.ftqIdx.value)(c.bits.ftqOffset + 2.U)
      := c_committed\n1336:       }.elsewhen(c.bits.commitType === 6.U) {\n1337: \
      \        val index = (c.bits.ftqIdx + 1.U).value\n1338:         commitStateQueueEnable(index)\
      \  := true.B\n1339:         commitStateQueueNext(index)(0) := c_committed\n\
      1340:       }.elsewhen(c.bits.commitType === 7.U) {\n1341:         val index
      = (c.bits.ftqIdx + 1.U).value\n1342:         commitStateQueueEnable(index) \
      \ := true.B\n1343:         commitStateQueueNext(index)(1) := c_committed\n1344:\
      \       }\n1345:     }\n1346:   }\n1347: \n1348:   // ****************************************************************"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1347-1366
    context: "1347: \n1348:   // ****************************************************************\n\
      1349:   // **************************** to bpu ****************************\n\
      1350:   // ****************************************************************\n\
      1351: \n1352:   io.toBpu.redirctFromIFU := ifuRedirectToBpu.valid\n1353:   io.toBpu.redirect\
      \       := Mux(fromBackendRedirect.valid, fromBackendRedirect, ifuRedirectToBpu)\n\
      1354:   val dummy_s1_pred_cycle_vec = VecInit(List.tabulate(FtqSize)(_ => 0.U(64.W)))\n\
      1355:   val redirect_latency =\n1356:     GTimer() - pred_s1_cycle.getOrElse(dummy_s1_pred_cycle_vec)(io.toBpu.redirect.bits.ftqIdx.value)
      + 1.U\n1357:   XSPerfHistogram(\"backend_redirect_latency\", redirect_latency,
      fromBackendRedirect.valid, 0, 60, 1)\n1358:   XSPerfHistogram(\n1359:     \"\
      ifu_redirect_latency\",\n1360:     redirect_latency,\n1361:     !fromBackendRedirect.valid
      && ifuRedirectToBpu.valid,\n1362:     0,\n1363:     60,\n1364:     1\n1365:\
      \   )\n1366: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1363-1390
    context: "1363:     60,\n1364:     1\n1365:   )\n1366: \n1367:   XSError(\n1368:\
      \     io.toBpu.redirect.valid && isBefore(io.toBpu.redirect.bits.ftqIdx, commPtr),\n\
      1369:     \"Ftq received a redirect after its commit, check backend or replay\"\
      \n1370:   )\n1371: \n1372:   val may_have_stall_from_bpu = Wire(Bool())\n1373:\
      \   val bpu_ftb_update_stall    = RegInit(0.U(2.W)) // 2-cycle stall, so we
      need 3 states\n1374:   may_have_stall_from_bpu := bpu_ftb_update_stall =/= 0.U\n\
      1375: \n1376:   val validInstructions     = commitStateQueueReg(commPtr.value).map(s
      => s === c_toCommit || s === c_committed)\n1377:   val lastInstructionStatus
      = PriorityMux(validInstructions.reverse.zip(commitStateQueueReg(commPtr.value).reverse))\n\
      1378:   val firstInstructionFlushed = commitStateQueueReg(commPtr.value)(0)
      === c_flushed ||\n1379:     commitStateQueueReg(commPtr.value)(0) === c_empty
      && commitStateQueueReg(commPtr.value)(1) === c_flushed\n1380:   canCommit :=
      commPtr =/= ifuWbPtr && !may_have_stall_from_bpu &&\n1381:     (isAfter(robCommPtr,
      commPtr) ||\n1382:       validInstructions.reduce(_ || _) && lastInstructionStatus
      === c_committed)\n1383:   val canMoveCommPtr = commPtr =/= ifuWbPtr && !may_have_stall_from_bpu
      &&\n1384:     (isAfter(robCommPtr, commPtr) ||\n1385:       validInstructions.reduce(_
      || _) && lastInstructionStatus === c_committed ||\n1386:       firstInstructionFlushed)\n\
      1387: \n1388:   when(io.fromBackend.rob_commits.map(_.valid).reduce(_ | _))
      {\n1389:     robCommPtr_write := ParallelPriorityMux(\n1390:       io.fromBackend.rob_commits.map(_.valid).reverse,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1388-1398
    context: "1388:   when(io.fromBackend.rob_commits.map(_.valid).reduce(_ | _))
      {\n1389:     robCommPtr_write := ParallelPriorityMux(\n1390:       io.fromBackend.rob_commits.map(_.valid).reverse,\n\
      1391:       io.fromBackend.rob_commits.map(_.bits.ftqIdx).reverse\n1392:   \
      \  )\n1393:   }.elsewhen(isAfter(commPtr, robCommPtr)) {\n1394:     robCommPtr_write
      := commPtr\n1395:   }.otherwise {\n1396:     robCommPtr_write := robCommPtr\n\
      1397:   }\n1398: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1399-1416
    context: "1399:   /**\n1400:     *************************************************************************************\n\
      1401:     * MMIO instruction fetch is allowed only if MMIO is the oldest instruction.\n\
      1402:     *************************************************************************************\n\
      1403:     */\n1404:   val mmioReadPtr = io.mmioCommitRead.mmioFtqPtr\n1405:\
      \   val mmioLastCommit = isAfter(commPtr, mmioReadPtr) ||\n1406:     commPtr
      === mmioReadPtr && validInstructions.reduce(_ || _) && lastInstructionStatus
      === c_committed\n1407:   io.mmioCommitRead.mmioLastCommit := RegNext(mmioLastCommit)\n\
      1408: \n1409:   // commit reads\n1410:   val commit_pc_bundle = RegNext(ftq_pc_mem.io.commPtr_rdata)\n\
      1411:   val commit_target =\n1412:     Mux(\n1413:       RegNext(commPtr ===
      newest_entry_ptr),\n1414:       RegEnable(newest_entry_target, newest_entry_target_modified),\n\
      1415:       RegNext(ftq_pc_mem.io.commPtrPlus1_rdata.startAddr)\n1416:     )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1415-1440
    context: "1415:       RegNext(ftq_pc_mem.io.commPtrPlus1_rdata.startAddr)\n1416:\
      \     )\n1417:   ftq_pd_mem.io.ren.get.last := canCommit\n1418:   ftq_pd_mem.io.raddr.last\
      \   := commPtr.value\n1419:   val commit_pd = ftq_pd_mem.io.rdata.last\n1420:\
      \   ftq_redirect_mem.io.ren.get.last := canCommit\n1421:   ftq_redirect_mem.io.raddr.last\
      \   := commPtr.value\n1422:   val commit_spec_meta = ftq_redirect_mem.io.rdata.last\n\
      1423:   ftq_meta_1r_sram.io.ren(0)   := canCommit\n1424:   ftq_meta_1r_sram.io.raddr(0)
      := commPtr.value\n1425:   val commit_meta      = ftq_meta_1r_sram.io.rdata(0).meta\n\
      1426:   val commit_ftb_entry = ftq_meta_1r_sram.io.rdata(0).ftb_entry\n1427:\
      \ \n1428:   // need one cycle to read mem and srams\n1429:   val do_commit_ptr
      = RegEnable(commPtr, canCommit)\n1430:   val do_commit     = RegNext(canCommit,
      init = false.B)\n1431:   when(canMoveCommPtr) {\n1432:     commPtr_write   \
      \   := commPtrPlus1\n1433:     commPtrPlus1_write := commPtrPlus1 + 1.U\n1434:\
      \   }\n1435:   val commit_state   = RegEnable(commitStateQueueReg(commPtr.value),
      canCommit)\n1436:   val can_commit_cfi = WireInit(cfiIndex_vec(commPtr.value))\n\
      1437:   val do_commit_cfi  = WireInit(cfiIndex_vec(do_commit_ptr.value))\n1438:\
      \   //\n1439:   // when (commitStateQueue(commPtr.value)(can_commit_cfi.bits)
      =/= c_commited) {\n1440:   //  can_commit_cfi.valid := false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1438-1458
    context: "1438:   //\n1439:   // when (commitStateQueue(commPtr.value)(can_commit_cfi.bits)
      =/= c_commited) {\n1440:   //  can_commit_cfi.valid := false.B\n1441:   // }\n\
      1442:   val commit_cfi = RegEnable(can_commit_cfi, canCommit)\n1443:   val debug_cfi\
      \  = commitStateQueueReg(do_commit_ptr.value)(do_commit_cfi.bits) =/= c_committed
      && do_commit_cfi.valid\n1444: \n1445:   val commit_mispredict: Vec[Bool] =\n\
      1446:     VecInit((RegEnable(mispredict_vec(commPtr.value), canCommit) zip commit_state).map
      {\n1447:       case (mis, state) => mis && state === c_committed\n1448:    \
      \ })\n1449:   val commit_instCommited: Vec[Bool] = VecInit(commit_state.map(_
      === c_committed)) // [PredictWidth]\n1450:   val can_commit_hit     = entry_hit_status(commPtr.value)\n\
      1451:   val commit_hit         = RegEnable(can_commit_hit, canCommit)\n1452:\
      \   val diff_commit_target = RegEnable(update_target(commPtr.value), canCommit)
      // TODO: remove this\n1453:   val commit_stage       = RegEnable(pred_stage(commPtr.value),
      canCommit)\n1454:   val commit_valid       = commit_hit === h_hit || commit_cfi.valid\
      \           // hit or taken\n1455: \n1456:   val to_bpu_hit = can_commit_hit
      === h_hit || can_commit_hit === h_false_hit\n1457:   switch(bpu_ftb_update_stall)
      {\n1458:     is(0.U) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1471-1481
    context: "1471:     }\n1472:   }\n1473:   XSError(bpu_ftb_update_stall === 3.U,
      \"bpu_ftb_update_stall should be 0, 1 or 2\")\n1474: \n1475:   // TODO: remove
      this\n1476:   XSError(do_commit && diff_commit_target =/= commit_target, \"\\
      ncommit target should be the same as update target\\n\")\n1477: \n1478:   //
      update latency stats\n1479:   val update_latency = GTimer() - pred_s1_cycle.getOrElse(dummy_s1_pred_cycle_vec)(do_commit_ptr.value)
      + 1.U\n1480:   XSPerfHistogram(\"bpu_update_latency\", update_latency, io.toBpu.update.valid,
      0, 64, 2)\n1481: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1478-1497
    context: "1478:   // update latency stats\n1479:   val update_latency = GTimer()
      - pred_s1_cycle.getOrElse(dummy_s1_pred_cycle_vec)(do_commit_ptr.value) + 1.U\n\
      1480:   XSPerfHistogram(\"bpu_update_latency\", update_latency, io.toBpu.update.valid,
      0, 64, 2)\n1481: \n1482:   io.toBpu.update       := DontCare\n1483:   io.toBpu.update.valid
      := commit_valid && do_commit\n1484:   val update = io.toBpu.update.bits\n1485:\
      \   update.false_hit   := commit_hit === h_false_hit\n1486:   update.pc    \
      \      := commit_pc_bundle.startAddr\n1487:   update.meta        := commit_meta\n\
      1488:   update.cfi_idx     := commit_cfi\n1489:   update.full_target := commit_target\n\
      1490:   update.from_stage  := commit_stage\n1491:   update.spec_info   := commit_spec_meta\n\
      1492:   XSError(commit_valid && do_commit && debug_cfi, \"\\ncommit cfi can
      be non c_commited\\n\")\n1493: \n1494:   val commit_real_hit  = commit_hit ===
      h_hit\n1495:   val update_ftb_entry = update.ftb_entry\n1496: \n1497:   val
      ftbEntryGen = Module(new FTBEntryGen).io"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1497-1509
    context: "1497:   val ftbEntryGen = Module(new FTBEntryGen).io\n1498:   ftbEntryGen.start_addr\
      \     := commit_pc_bundle.startAddr\n1499:   ftbEntryGen.old_entry      := commit_ftb_entry\n\
      1500:   ftbEntryGen.pd             := commit_pd\n1501:   ftbEntryGen.cfiIndex\
      \       := commit_cfi\n1502:   ftbEntryGen.target         := commit_target\n\
      1503:   ftbEntryGen.hit            := commit_real_hit\n1504:   ftbEntryGen.mispredict_vec
      := commit_mispredict\n1505: \n1506:   update_ftb_entry         := ftbEntryGen.new_entry\n\
      1507:   update.new_br_insert_pos := ftbEntryGen.new_br_insert_pos\n1508:   update.mispred_mask\
      \      := ftbEntryGen.mispred_mask\n1509:   update.old_entry         := ftbEntryGen.is_old_entry"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1507-1517
    context: "1507:   update.new_br_insert_pos := ftbEntryGen.new_br_insert_pos\n\
      1508:   update.mispred_mask      := ftbEntryGen.mispred_mask\n1509:   update.old_entry\
      \         := ftbEntryGen.is_old_entry\n1510:   update.pred_hit          := commit_hit
      === h_hit || commit_hit === h_false_hit\n1511:   update.br_taken_mask     :=
      ftbEntryGen.taken_mask\n1512:   update.br_committed := (ftbEntryGen.new_entry.brValids
      zip ftbEntryGen.new_entry.brOffset) map {\n1513:     case (valid, offset) =>
      valid && commit_instCommited(offset)\n1514:   }\n1515:   update.jmp_taken :=
      ftbEntryGen.jmp_taken\n1516: \n1517:   // update.full_pred.fromFtbEntry(ftbEntryGen.new_entry,
      update.pc)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1523-1534
    context: "1523: \n1524:   // ******************************************************************************\n\
      1525:   // **************************** commit perf counters ****************************\n\
      1526:   // ******************************************************************************\n\
      1527: \n1528:   val commit_inst_mask        = VecInit(commit_state.map(c =>
      c === c_committed && do_commit)).asUInt\n1529:   val commit_mispred_mask   \
      \  = commit_mispredict.asUInt\n1530:   val commit_not_mispred_mask = ~commit_mispred_mask\n\
      1531: \n1532:   val commit_br_mask  = commit_pd.brMask.asUInt\n1533:   val commit_jmp_mask
      = UIntToOH(commit_pd.jmpOffset) & Fill(PredictWidth, commit_pd.jmpInfo.valid.asTypeOf(UInt(1.W)))\n\
      1534:   val commit_cfi_mask = commit_br_mask | commit_jmp_mask"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1545-1564
    context: "1545:   val isWriteFTQTable  = Constantin.createRecord(s\"isWriteFTQTable$hartId\"\
      )\n1546:   val ftqBranchTraceDB = ChiselDB.createTable(s\"FTQTable$hartId\"\
      , new FtqDebugBundle)\n1547:   // Cfi Info\n1548:   for (i <- 0 until PredictWidth)
      {\n1549:     val pc      = commit_pc_bundle.startAddr + (i * instBytes).U\n\
      1550:     val v       = commit_state(i) === c_committed\n1551:     val isBr\
      \    = commit_pd.brMask(i)\n1552:     val isJmp   = commit_pd.jmpInfo.valid
      && commit_pd.jmpOffset === i.U\n1553:     val isCfi   = isBr || isJmp\n1554:\
      \     val isTaken = commit_cfi.valid && commit_cfi.bits === i.U\n1555:     val
      misPred = commit_mispredict(i)\n1556:     // val ghist = commit_spec_meta.ghist.predHist\n\
      1557:     val histPtr   = commit_spec_meta.histPtr\n1558:     val predCycle
      = commit_meta(63, 0)\n1559:     val target    = commit_target\n1560: \n1561:\
      \     val brIdx = OHToUInt(Reverse(Cat(update_ftb_entry.brValids.zip(update_ftb_entry.brOffset).map
      { case (v, offset) =>\n1562:       v && offset === i.U\n1563:     })))\n1564:\
      \     val inFtbEntry = update_ftb_entry.brValids.zip(update_ftb_entry.brOffset).map
      { case (v, offset) =>"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1565-1577
    context: "1565:       v && offset === i.U\n1566:     }.reduce(_ || _)\n1567: \
      \    val addIntoHist =\n1568:       ((commit_hit === h_hit) && inFtbEntry) ||
      (!(commit_hit === h_hit) && i.U === commit_cfi.bits && isBr && commit_cfi.valid)\n\
      1569:     XSDebug(\n1570:       v && do_commit && isCfi,\n1571:       p\"cfi_update:
      isBr(${isBr}) pc(${Hexadecimal(pc)}) \" +\n1572:         p\"taken(${isTaken})
      mispred(${misPred}) cycle($predCycle) hist(${histPtr.value}) \" +\n1573:   \
      \      p\"startAddr(${Hexadecimal(commit_pc_bundle.startAddr)}) AddIntoHist(${addIntoHist})
      \" +\n1574:         p\"brInEntry(${inFtbEntry}) brIdx(${brIdx}) target(${Hexadecimal(target)})\\\
      n\"\n1575:     )\n1576: \n1577:     val logbundle = Wire(new FtqDebugBundle)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1580-1595
    context: "1580:     logbundle.isBr      := isBr\n1581:     logbundle.isJmp   \
      \  := isJmp\n1582:     logbundle.isCall    := isJmp && commit_pd.hasCall\n1583:\
      \     logbundle.isRet     := isJmp && commit_pd.hasRet\n1584:     logbundle.misPred\
      \   := misPred\n1585:     logbundle.isTaken   := isTaken\n1586:     logbundle.predStage
      := commit_stage\n1587: \n1588:     ftqBranchTraceDB.log(\n1589:       data =
      logbundle /* hardware of type T */,\n1590:       en = isWriteFTQTable.orR &&
      v && do_commit && isCfi,\n1591:       site = \"FTQ\" + p(XSCoreParamsKey).HartId.toString,\n\
      1592:       clock = clock,\n1593:       reset = reset\n1594:     )\n1595:  \
      \ }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1593-1628
    context: "1593:       reset = reset\n1594:     )\n1595:   }\n1596: \n1597:   val
      enq           = io.fromBpu.resp\n1598:   val perf_redirect = backendRedirect\n\
      1599: \n1600:   XSPerfAccumulate(\"entry\", validEntries)\n1601:   XSPerfAccumulate(\"\
      bpu_to_ftq_stall\", enq.valid && !enq.ready)\n1602:   XSPerfAccumulate(\"mispredictRedirect\"\
      , perf_redirect.valid && RedirectLevel.flushAfter === perf_redirect.bits.level)\n\
      1603:   XSPerfAccumulate(\"replayRedirect\", perf_redirect.valid && RedirectLevel.flushItself(perf_redirect.bits.level))\n\
      1604:   XSPerfAccumulate(\"predecodeRedirect\", fromIfuRedirect.valid)\n1605:\
      \ \n1606:   XSPerfAccumulate(\"to_ifu_bubble\", io.toIfu.req.ready && !io.toIfu.req.valid)\n\
      1607: \n1608:   XSPerfAccumulate(\"to_ifu_stall\", io.toIfu.req.valid && !io.toIfu.req.ready)\n\
      1609:   XSPerfAccumulate(\"from_bpu_real_bubble\", !enq.valid && enq.ready &&
      allowBpuIn)\n1610:   XSPerfAccumulate(\"bpu_to_ifu_bubble\", bpuPtr === ifuPtr)\n\
      1611:   XSPerfAccumulate(\n1612:     \"bpu_to_ifu_bubble_when_ftq_full\",\n\
      1613:     (bpuPtr === ifuPtr) && isFull(bpuPtr, commPtr) && io.toIfu.req.ready\n\
      1614:   )\n1615: \n1616:   XSPerfAccumulate(\"redirectAhead_ValidNum\", ftqIdxAhead.map(_.valid).reduce(_
      | _))\n1617:   XSPerfAccumulate(\"fromBackendRedirect_ValidNum\", io.fromBackend.redirect.valid)\n\
      1618:   XSPerfAccumulate(\"toBpuRedirect_ValidNum\", io.toBpu.redirect.valid)\n\
      1619: \n1620:   val from_bpu = io.fromBpu.resp.bits\n1621:   val to_ifu   =
      io.toIfu.req.bits\n1622: \n1623:   XSPerfHistogram(\"commit_num_inst\", PopCount(commit_inst_mask),
      do_commit, 0, PredictWidth + 1, 1)\n1624: \n1625:   val commit_jal_mask  = UIntToOH(commit_pd.jmpOffset)
      & Fill(PredictWidth, commit_pd.hasJal.asTypeOf(UInt(1.W)))\n1626:   val commit_jalr_mask
      = UIntToOH(commit_pd.jmpOffset) & Fill(PredictWidth, commit_pd.hasJalr.asTypeOf(UInt(1.W)))\n\
      1627:   val commit_call_mask = UIntToOH(commit_pd.jmpOffset) & Fill(PredictWidth,
      commit_pd.hasCall.asTypeOf(UInt(1.W)))\n1628:   val commit_ret_mask  = UIntToOH(commit_pd.jmpOffset)
      & Fill(PredictWidth, commit_pd.hasRet.asTypeOf(UInt(1.W)))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1644-1657
    context: "1644:   def pred_stage_map(src: UInt, name: String) =\n1645:     (0
      until numBpStages).map(i =>\n1646:       f\"${name}_stage_${i + 1}\" -> PopCount(src.asBools.map(_
      && commit_pred_stage === BP_STAGES(i)))\n1647:     ).foldLeft(Map[String, UInt]())(_
      + _)\n1648: \n1649:   val mispred_stage_map      = pred_stage_map(mbpWrongs,
      \"mispredict\")\n1650:   val br_mispred_stage_map   = pred_stage_map(mbpBWrongs,
      \"br_mispredict\")\n1651:   val jalr_mispred_stage_map = pred_stage_map(mbpIWrongs,
      \"jalr_mispredict\")\n1652:   val correct_stage_map      = pred_stage_map(mbpRights,
      \"correct\")\n1653:   val br_correct_stage_map   = pred_stage_map(mbpBRights,
      \"br_correct\")\n1654:   val jalr_correct_stage_map = pred_stage_map(mbpIRights,
      \"jalr_correct\")\n1655: \n1656:   val update_valid = io.toBpu.update.valid\n\
      1657:   def u(cond: Bool) = update_valid && cond"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1667-1677
    context: "1667:   val ftb_old_entry = u(ftbEntryGen.is_old_entry)\n1668: \n1669:\
      \   val ftb_modified_entry =\n1670:     u(ftbEntryGen.is_new_br || ftbEntryGen.is_jalr_target_modified
      || ftbEntryGen.is_strong_bias_modified)\n1671:   val ftb_modified_entry_new_br\
      \               = u(ftbEntryGen.is_new_br)\n1672:   val ftb_modified_entry_ifu_redirected\
      \       = u(ifuRedirected(do_commit_ptr.value))\n1673:   val ftb_modified_entry_jalr_target_modified
      = u(ftbEntryGen.is_jalr_target_modified)\n1674:   val ftb_modified_entry_br_full\
      \              = ftb_modified_entry && ftbEntryGen.is_br_full\n1675:   val ftb_modified_entry_strong_bias\
      \          = ftb_modified_entry && ftbEntryGen.is_strong_bias_modified\n1676:\
      \ \n1677:   def getFtbEntryLen(pc: UInt, entry: FTBEntry) = (entry.getFallThrough(pc)
      - pc) >> instOffsetBits"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1717-1735
    context: "1717:     XSPerfAccumulate(key, value)\n1718:   }\n1719: \n1720:   //
      --------------------------- Debug --------------------------------\n1721:  \
      \ // XSDebug(enq_fire, p\"enq! \" + io.fromBpu.resp.bits.toPrintable)\n1722:\
      \   XSDebug(io.toIfu.req.fire, p\"fire to ifu \" + io.toIfu.req.bits.toPrintable)\n\
      1723:   XSDebug(do_commit, p\"deq! [ptr] $do_commit_ptr\\n\")\n1724:   XSDebug(true.B,
      p\"[bpuPtr] $bpuPtr, [ifuPtr] $ifuPtr, [ifuWbPtr] $ifuWbPtr [commPtr] $commPtr\\\
      n\")\n1725:   XSDebug(\n1726:     true.B,\n1727:     p\"[in] v:${io.fromBpu.resp.valid}
      r:${io.fromBpu.resp.ready} \" +\n1728:       p\"[out] v:${io.toIfu.req.valid}
      r:${io.toIfu.req.ready}\\n\"\n1729:   )\n1730:   XSDebug(do_commit, p\"[deq
      info] cfiIndex: $commit_cfi, $commit_pc_bundle, target: ${Hexadecimal(commit_target)}\\\
      n\")\n1731: \n1732:   //   def ubtbCheck(commit: FtqEntry, predAns: Seq[PredictorAnswer],
      isWrong: Bool) = {\n1733:   //     commit.valids.zip(commit.pd).zip(predAns).zip(commit.takens).map
      {\n1734:   //       case (((valid, pd), ans), taken) =>\n1735:   //       Mux(valid
      && pd.isBr,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1793-1810
    context: "1793: \n1794:   //   val rasRights = rasCheck(commitEntry, commitEntry.metas.map(_.rasAns),
      false.B)\n1795:   //   val rasWrongs = rasCheck(commitEntry, commitEntry.metas.map(_.rasAns),
      true.B)\n1796: \n1797:   val perfEvents = Seq(\n1798:     (\"bpu_s2_redirect\
      \        \", bpu_s2_redirect),\n1799:     (\"bpu_s3_redirect        \", bpu_s3_redirect),\n\
      1800:     (\"bpu_to_ftq_stall       \", enq.valid && ~enq.ready),\n1801:   \
      \  (\"mispredictRedirect     \", perf_redirect.valid && RedirectLevel.flushAfter
      === perf_redirect.bits.level),\n1802:     (\"replayRedirect         \", perf_redirect.valid
      && RedirectLevel.flushItself(perf_redirect.bits.level)),\n1803:     (\"predecodeRedirect\
      \      \", fromIfuRedirect.valid),\n1804:     (\"to_ifu_bubble          \",
      io.toIfu.req.ready && !io.toIfu.req.valid),\n1805:     (\"from_bpu_real_bubble\
      \   \", !enq.valid && enq.ready && allowBpuIn),\n1806:     (\"BpInstr      \
      \          \", PopCount(mbpInstrs)),\n1807:     (\"BpBInstr               \"\
      , PopCount(mbpBRights | mbpBWrongs)),\n1808:     (\"BpRight                \"\
      , PopCount(mbpRights)),\n1809:     (\"BpWrong                \", PopCount(mbpWrongs)),\n\
      1810:     (\"BpBRight               \", PopCount(mbpBRights)),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 31-42
    context: "31:     ) {}\n32: \n33: class IBufBankPtr(implicit p: Parameters) extends
      CircularQueuePtr[IBufBankPtr](p => p(XSCoreParamsKey).IBufNBank) {}\n34: \n\
      35: class IBufferIO(implicit p: Parameters) extends XSBundle {\n36:   val flush\
      \                = Input(Bool())\n37:   val ControlRedirect      = Input(Bool())\n\
      38:   val ControlBTBMissBubble = Input(Bool())\n39:   val TAGEMissBubble   \
      \    = Input(Bool())\n40:   val SCMissBubble         = Input(Bool())\n41:  \
      \ val ITTAGEMissBubble     = Input(Bool())\n42:   val RASMissBubble        =
      Input(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 38-48
    context: "38:   val ControlBTBMissBubble = Input(Bool())\n39:   val TAGEMissBubble\
      \       = Input(Bool())\n40:   val SCMissBubble         = Input(Bool())\n41:\
      \   val ITTAGEMissBubble     = Input(Bool())\n42:   val RASMissBubble      \
      \  = Input(Bool())\n43:   val MemVioRedirect       = Input(Bool())\n44:   val
      in                   = Flipped(DecoupledIO(new FetchToIBuffer))\n45:   val out\
      \                  = Vec(DecodeWidth, DecoupledIO(new CtrlFlow))\n46:   val
      full                 = Output(Bool())\n47:   val decodeCanAccept      = Input(Bool())\n\
      48:   val stallReason          = new StallReasonIO(DecodeWidth)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 204-214
    context: "204: \n205:   val enqPtrVec = RegInit(VecInit.tabulate(PredictWidth)(_.U.asTypeOf(new
      IBufPtr)))\n206:   val enqPtr    = enqPtrVec(0)\n207: \n208:   val numTryEnq
      = WireDefault(0.U)\n209:   val numEnq    = Mux(io.in.fire, numTryEnq, 0.U)\n\
      210: \n211:   // empty and decode can accept insts\n212:   val useBypass = enqPtr
      === deqPtr && decodeCanAccept\n213: \n214:   // The number of decode accepted
      insts."
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 253-263
    context: "253:   }\n254: \n255:   /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\
      256:   // Bypass\n257:   /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\
      258:   bypassEntries.zipWithIndex.foreach {\n259:     case (entry, idx) =>\n\
      260:       // Select\n261:       val validOH = Range(0, PredictWidth).map {\n\
      262:         i =>\n263:           io.in.bits.valid(i) &&"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 262-272
    context: "262:         i =>\n263:           io.in.bits.valid(i) &&\n264:     \
      \      io.in.bits.enqEnable(i) &&\n265:           enqOffset(i) === idx.asUInt\n\
      266:       } // Should be OneHot\n267:       entry.valid := validOH.reduce(_
      || _) && io.in.fire && !io.flush\n268:       entry.bits  := Mux1H(validOH, enqData)\n\
      269: \n270:       // Debug Assertion\n271:       XSError(io.in.valid && PopCount(validOH)
      > 1.asUInt, \"validOH is not OneHot\")\n272:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 271-286
    context: "271:       XSError(io.in.valid && PopCount(validOH) > 1.asUInt, \"validOH
      is not OneHot\")\n272:   }\n273: \n274:   // => Decode Output\n275:   // clean
      register output\n276:   io.out zip outputEntries foreach {\n277:     case (io,
      reg) =>\n278:       io.valid := reg.valid\n279:       io.bits  := reg.bits.toCtrlFlow\n\
      280:   }\n281:   (outputEntries zip bypassEntries).zipWithIndex.foreach {\n\
      282:     case ((out, bypass), i) =>\n283:       when(decodeCanAccept) {\n284:\
      \         when(useBypass && io.in.valid) {\n285:           out := bypass\n286:\
      \         }.otherwise {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 297-309
    context: "297:   }\n298: \n299:   /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\
      300:   // Enqueue\n301:   /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\
      302:   io.in.ready := allowEnq\n303:   // Data\n304:   ibuf.zipWithIndex.foreach
      {\n305:     case (entry, idx) => {\n306:       // Select\n307:       val validOH
      = Range(0, PredictWidth).map {\n308:         i =>\n309:           val useBypassMatch
      = enqOffset(i) >= DecodeWidth.U &&"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 311-321
    context: "311:           val normalMatch = enqPtrVec(enqOffset(i)).value === idx.asUInt\n\
      312:           val m = Mux(useBypass, useBypassMatch, normalMatch) // when using
      bypass, bypassed entries do not enqueue\n313: \n314:           io.in.bits.valid(i)
      && io.in.bits.enqEnable(i) && m\n315:       } // Should be OneHot\n316:    \
      \   val wen = validOH.reduce(_ || _) && io.in.fire && !io.flush\n317: \n318:\
      \       // Write port\n319:       // Each IBuffer entry has a PredictWidth ->
      1 Mux\n320:       val writeEntry = Mux1H(validOH, enqData)\n321:       entry
      := Mux(wen, writeEntry, entry)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 323-333
    context: "323:       // Debug Assertion\n324:       XSError(io.in.valid && PopCount(validOH)
      > 1.asUInt, \"validOH is not OneHot\")\n325:     }\n326:   }\n327:   // Pointer
      maintenance\n328:   when(io.in.fire && !io.flush) {\n329:     enqPtrVec := VecInit(enqPtrVec.map(_
      + numTryEnq))\n330:   }\n331: \n332:   /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\
      333:   // Dequeue"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 353-363
    context: "353:     deqEntries(i).bits  := Mux1H(UIntToOH(deqBankPtrVec(i).value),
      readStage1)\n354:   }\n355:   // Pointer maintenance\n356:   deqBankPtrVecNext
      := VecInit(deqBankPtrVec.map(_ + numDeq))\n357:   deqPtrNext        := deqPtr
      + numDeq\n358:   deqInBankPtrNext.zip(deqInBankPtr).zipWithIndex.foreach {\n\
      359:     case ((ptrNext, ptr), idx) => {\n360:       // validVec[k] == bankValid[deqBankPtr
      + k]\n361:       // So bankValid[n] == validVec[n - deqBankPtr]\n362:      \
      \ val validIdx = Mux(\n363:         idx.asUInt >= deqBankPtr.value,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 368-378
    context: "368:       ptrNext := Mux(bankAdvance, ptr + 1.U, ptr)\n369:     }\n\
      370:   }\n371: \n372:   // Flush\n373:   when(io.flush) {\n374:     allowEnq\
      \      := true.B\n375:     enqPtrVec     := enqPtrVec.indices.map(_.U.asTypeOf(new
      IBufPtr))\n376:     deqBankPtrVec := deqBankPtrVec.indices.map(_.U.asTypeOf(new
      IBufBankPtr))\n377:     deqInBankPtr  := VecInit.fill(IBufNBank)(0.U.asTypeOf(new
      IBufInBankPtr))\n378:     deqPtr        := 0.U.asTypeOf(new IBufPtr())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 374-384
    context: "374:     allowEnq      := true.B\n375:     enqPtrVec     := enqPtrVec.indices.map(_.U.asTypeOf(new
      IBufPtr))\n376:     deqBankPtrVec := deqBankPtrVec.indices.map(_.U.asTypeOf(new
      IBufBankPtr))\n377:     deqInBankPtr  := VecInit.fill(IBufNBank)(0.U.asTypeOf(new
      IBufInBankPtr))\n378:     deqPtr        := 0.U.asTypeOf(new IBufPtr())\n379:\
      \     outputEntries.foreach(_.valid := false.B)\n380:   }.otherwise {\n381:\
      \     deqPtr        := deqPtrNext\n382:     deqInBankPtr  := deqInBankPtrNext\n\
      383:     deqBankPtrVec := deqBankPtrVecNext\n384:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 387-398
    context: "387:   /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\
      388:   // TopDown\n389:   /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\
      390:   val topdown_stage = RegInit(0.U.asTypeOf(new FrontendTopDownBundle))\n\
      391:   topdown_stage := io.in.bits.topdown_info\n392:   when(io.flush) {\n393:\
      \     when(io.ControlRedirect) {\n394:       when(io.ControlBTBMissBubble) {\n\
      395:         topdown_stage.reasons(TopDownCounters.BTBMissBubble.id) := true.B\n\
      396:       }.elsewhen(io.TAGEMissBubble) {\n397:         topdown_stage.reasons(TopDownCounters.TAGEMissBubble.id)
      := true.B\n398:       }.elsewhen(io.SCMissBubble) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 400-411
    context: "400:       }.elsewhen(io.ITTAGEMissBubble) {\n401:         topdown_stage.reasons(TopDownCounters.ITTAGEMissBubble.id)
      := true.B\n402:       }.elsewhen(io.RASMissBubble) {\n403:         topdown_stage.reasons(TopDownCounters.RASMissBubble.id)
      := true.B\n404:       }\n405:     }.elsewhen(io.MemVioRedirect) {\n406:    \
      \   topdown_stage.reasons(TopDownCounters.MemVioRedirectBubble.id) := true.B\n\
      407:     }.otherwise {\n408:       topdown_stage.reasons(TopDownCounters.OtherRedirectBubble.id)
      := true.B\n409:     }\n410:   }\n411: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 440-462
    context: "440:     deqPtr.value =/= deqBankPtr.value + deqInBankPtr(deqBankPtr.value).value
      * IBufNBank.asUInt,\n441:     \"Dequeue PTR mismatch\"\n442:   )\n443:   XSError(isBefore(enqPtr,
      deqPtr) && !isFull(enqPtr, deqPtr), \"\\ndeqPtr is older than enqPtr!\\n\")\n\
      444: \n445:   XSDebug(io.flush, \"IBuffer Flushed\\n\")\n446: \n447:   XSDebug(io.in.fire,
      \"Enque:\\n\")\n448:   XSDebug(io.in.fire, p\"MASK=${Binary(io.in.bits.valid)}\\\
      n\")\n449:   for (i <- 0 until PredictWidth) {\n450:     XSDebug(io.in.fire,
      p\"PC=${Hexadecimal(io.in.bits.pc(i))} ${Hexadecimal(io.in.bits.instrs(i))}\\\
      n\")\n451:   }\n452: \n453:   for (i <- 0 until DecodeWidth) {\n454:     XSDebug(\n\
      455:       io.out(i).fire,\n456:       p\"deq: ${Hexadecimal(io.out(i).bits.instr)}
      PC=${Hexadecimal(io.out(i).bits.pc)}\" +\n457:         p\"v=${io.out(i).valid}
      r=${io.out(i).ready} \" +\n458:         p\"excpVec=${Binary(io.out(i).bits.exceptionVec.asUInt)}
      crossPageIPF=${io.out(i).bits.crossPageIPFFix}\\n\"\n459:     )\n460:   }\n\
      461: \n462:   XSDebug(p\"numValid: ${numValid}\\n\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 463-474
    context: "463:   XSDebug(p\"EnqNum: ${numEnq}\\n\")\n464:   XSDebug(p\"DeqNum:
      ${numDeq}\\n\")\n465: \n466:   val afterInit  = RegInit(false.B)\n467:   val
      headBubble = RegInit(false.B)\n468:   when(io.in.fire)(afterInit := true.B)\n\
      469:   when(io.flush) {\n470:     headBubble := true.B\n471:   }.elsewhen(numValid
      =/= 0.U) {\n472:     headBubble := false.B\n473:   }\n474:   val instrHungry
      = afterInit && (numValid === 0.U) && !headBubble"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 472-482
    context: "472:     headBubble := false.B\n473:   }\n474:   val instrHungry = afterInit
      && (numValid === 0.U) && !headBubble\n475: \n476:   QueuePerf(IBufSize, numValid,
      !allowEnq)\n477:   XSPerfAccumulate(\"flush\", io.flush)\n478:   XSPerfAccumulate(\"\
      hungry\", instrHungry)\n479: \n480:   val ibuffer_IDWidth_hvButNotFull = afterInit
      && (numValid =/= 0.U) && (numValid < DecodeWidth.U) && !headBubble\n481:   XSPerfAccumulate(\"\
      ibuffer_IDWidth_hvButNotFull\", ibuffer_IDWidth_hvButNotFull)\n482: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IBuffer.scala
    lines: 486-496
    context: "486: \n487:   XSPerfAccumulate(\"if_fetch_bubble\", FrontBubble)\n488:\
      \   XSPerfAccumulate(\"if_fetch_bubble_eq_max\", fetchLatency)\n489: \n490:\
      \   val perfEvents = Seq(\n491:     (\"IBuffer_Flushed  \", io.flush),\n492:\
      \     (\"IBuffer_hungry   \", instrHungry),\n493:     (\"IBuffer_1_4_valid\"\
      , (numValid > (0 * (IBufSize / 4)).U) & (numValid < (1 * (IBufSize / 4)).U)),\n\
      494:     (\"IBuffer_2_4_valid\", (numValid >= (1 * (IBufSize / 4)).U) & (numValid
      < (2 * (IBufSize / 4)).U)),\n495:     (\"IBuffer_3_4_valid\", (numValid >= (2
      * (IBufSize / 4)).U) & (numValid < (3 * (IBufSize / 4)).U)),\n496:     (\"IBuffer_4_4_valid\"\
      , (numValid >= (3 * (IBufSize / 4)).U) & (numValid < (4 * (IBufSize / 4)).U)),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Tage.scala
    lines: 182-192
    context: "182:   when(resetRow === (BtSize - 1).U) {\n183:     doing_reset :=
      false.B\n184:   }\n185: \n186:   // Require power-on reset done before handling
      any request\n187:   io.req.ready := !doing_reset\n188: \n189:   val s0_pc  \
      \ = io.req.bits\n190:   val s0_fire = io.req.valid\n191:   val s0_idx  = bimAddr.getIdx(s0_pc)\n\
      192:   bt.io.r.req.valid       := s0_fire"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Tage.scala
    lines: 190-203
    context: "190:   val s0_fire = io.req.valid\n191:   val s0_idx  = bimAddr.getIdx(s0_pc)\n\
      192:   bt.io.r.req.valid       := s0_fire\n193:   bt.io.r.req.bits.setIdx :=
      s0_idx\n194: \n195:   val s1_read = bt.io.r.resp.data\n196:   val s1_idx  =
      RegEnable(s0_idx, s0_fire)\n197: \n198:   val per_br_ctr = VecInit((0 until
      numBr).map(i => Mux1H(UIntToOH(get_phy_br_idx(s1_idx, i), numBr), s1_read)))\n\
      199:   io.s1_cnt := per_br_ctr\n200: \n201:   // Update logic\n202:   val u_idx
      = bimAddr.getIdx(io.update_pc)\n203: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Tage.scala
    lines: 353-374
    context: "353: \n354:   val (s0_idx, s0_tag) = compute_tag_and_hash(req_unhashed_idx,
      io.req.bits.folded_hist)\n355:   val s0_bank_req_1h   = get_bank_mask(s0_idx)\n\
      356: \n357:   for (b <- 0 until nBanks) {\n358:     table_banks(b).io.r.req.valid\
      \       := io.req.fire && s0_bank_req_1h(b)\n359:     table_banks(b).io.r.req.bits.setIdx
      := get_bank_idx(s0_idx)\n360:   }\n361: \n362:   us.io.r.req.valid       :=
      io.req.fire\n363:   us.io.r.req.bits.setIdx := s0_idx\n364: \n365:   val s1_unhashed_idx\
      \               = RegEnable(req_unhashed_idx, io.req.fire)\n366:   val s1_idx\
      \                        = RegEnable(s0_idx, io.req.fire)\n367:   val s1_tag\
      \                        = RegEnable(s0_tag, io.req.fire)\n368:   val s1_pc\
      \                         = RegEnable(io.req.bits.pc, io.req.fire)\n369:   val
      s1_bank_req_1h                = RegEnable(s0_bank_req_1h, io.req.fire)\n370:\
      \   val s1_bank_has_write_on_this_req = RegEnable(VecInit(table_banks.map(_.io.w.req.valid)),
      io.req.valid)\n371: \n372:   val resp_invalid_by_write = Wire(Bool())\n373:\
      \ \n374:   val tables_r = table_banks.map(_.io.r.resp.data)                \
      \               // s1"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Tage.scala
    lines: 438-448
    context: "438:     )\n439:   }\n440: \n441:   // Power-on reset\n442:   val powerOnResetState
      = RegInit(true.B)\n443:   when(us.io.r.req.ready && table_banks.map(_.io.r.req.ready).reduce(_
      && _)) {\n444:     // When all the SRAM first reach ready state, we consider
      power-on reset is done\n445:     powerOnResetState := false.B\n446:   }\n447:\
      \   // Do not use table banks io.r.req.ready directly\n448:   // All the us
      & table_banks are single port SRAM, ready := !wen"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Tage.scala
    lines: 445-455
    context: "445:     powerOnResetState := false.B\n446:   }\n447:   // Do not use
      table banks io.r.req.ready directly\n448:   // All the us & table_banks are
      single port SRAM, ready := !wen\n449:   // We do not want write request block
      the whole BPU pipeline\n450:   io.req.ready := !powerOnResetState\n451: \n452:\
      \   val bank_conflict = (0 until nBanks).map(b => table_banks(b).io.w.req.valid
      && s0_bank_req_1h(b)).reduce(_ || _)\n453:   XSPerfAccumulate(f\"tage_table_bank_conflict\"\
      , bank_conflict)\n454: \n455:   val update_u_idx = update_idx"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Tage.scala
    lines: 569-579
    context: "569: \n570:   val u  = io.update\n571:   val b  = PriorityEncoder(u.mask)\n\
      572:   val ub = PriorityEncoder(u.uMask)\n573:   XSDebug(\n574:     io.req.fire,\n\
      575:     p\"tableReq: pc=0x${Hexadecimal(io.req.bits.pc)}, \" +\n576:      \
      \ p\"idx=$s0_idx, tag=$s0_tag\\n\"\n577:   )\n578:   for (i <- 0 until numBr)
      {\n579:     XSDebug("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Tage.scala
    lines: 575-585
    context: "575:     p\"tableReq: pc=0x${Hexadecimal(io.req.bits.pc)}, \" +\n576:\
      \       p\"idx=$s0_idx, tag=$s0_tag\\n\"\n577:   )\n578:   for (i <- 0 until
      numBr) {\n579:     XSDebug(\n580:       RegNext(io.req.fire) && per_br_hit(i),\n\
      581:       p\"TageTableResp_br_$i: idx=$s1_idx, hit:${per_br_hit(i)}, \" +\n\
      582:         p\"ctr:${io.resps(i).bits.ctr}, u:${io.resps(i).bits.u}\\n\"\n\
      583:     )\n584:     XSDebug(\n585:       io.update.mask(i),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Tage.scala
    lines: 591-601
    context: "591:     XSDebug(\n592:       io.update.mask(i),\n593:       p\"update
      Table_$i: writing tag:$update_tag, \" +\n594:         p\"ctr: ${per_bank_update_wdata(bank)(pi).ctr}
      in idx ${update_idx}\\n\"\n595:     )\n596:     XSDebug(RegNext(io.req.fire)
      && !per_br_hit(i), p\"TageTableResp_$i: not hit!\\n\")\n597:   }\n598: \n599:\
      \   // ------------------------------Debug-------------------------------------\n\
      600:   val valids = RegInit(VecInit(Seq.fill(nRowsPerBr)(false.B)))\n601:  \
      \ when(io.update.mask.reduce(_ || _))(valids(update_idx) := true.B)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Tage.scala
    lines: 608-619
    context: "608: \n609: class FakeTage(implicit p: Parameters) extends BaseTage
      {\n610:   io.out <> 0.U.asTypeOf(DecoupledIO(new BasePredictorOutput))\n611:\
      \ \n612:   // io.s0_ready := true.B\n613:   io.s1_ready := true.B\n614:   io.s2_ready
      := true.B\n615: }\n616: \n617: class Tage(implicit p: Parameters) extends BaseTage
      {\n618: \n619:   val resp_meta          = Wire(new TageMeta)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Tage.scala
    lines: 973-984
    context: "973:   bt.io.update_cnt    := RegEnable(updatebcnt, baseupdate.reduce(_
      | _))\n974:   bt.io.update_pc     := RegEnable(update_pc, baseupdate.reduce(_
      | _))\n975:   bt.io.update_takens := RegEnable(bUpdateTakens, baseupdate.reduce(_
      | _))\n976: \n977:   // all should be ready for req\n978:   io.s1_ready := tables.map(_.io.req.ready).reduce(_
      && _) && bt.io.req.ready\n979:   XSPerfAccumulate(f\"tage_write_blocks_read\"\
      , !io.s1_ready)\n980: \n981:   def pred_perf(name:   String, cnt: UInt) = XSPerfAccumulate(s\"\
      ${name}_at_pred\", cnt)\n982:   def commit_perf(name: String, cnt: UInt) = XSPerfAccumulate(s\"\
      ${name}_at_commit\", cnt)\n983:   def tage_perf(name: String, pred_cnt: UInt,
      commit_cnt: UInt) = {\n984:     pred_perf(name, pred_cnt)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 62-80
    context: "62:       Mux(target_higher > pc_higher, TAR_OVF, Mux(target_higher
      < pc_higher, TAR_UDF, TAR_FIT))\n63:     def getLowerByTarget(target: UInt,
      offsetLen: Int) = target(offsetLen, 1)\n64:     val offLen        = if (isShare)
      this.subOffsetLen.get else this.offsetLen\n65:     val pc_higher     = pc(VAddrBits
      - 1, offLen + 1)\n66:     val target_higher = target(VAddrBits - 1, offLen +
      1)\n67:     val stat          = getTargetStatByHigher(pc_higher, target_higher)\n\
      68:     val lower         = ZeroExt(getLowerByTarget(target, offLen), this.offsetLen)\n\
      69:     this.lower   := lower\n70:     this.tarStat := stat\n71:     this.sharing
      := isShare.B\n72:   }\n73: \n74:   def getTarget(pc: UInt, last_stage: Option[Tuple2[UInt,
      Bool]] = None) = {\n75:     def getTarget(offLen: Int)(pc: UInt, lower: UInt,
      stat: UInt, last_stage: Option[Tuple2[UInt, Bool]] = None) = {\n76:       val
      h                = pc(VAddrBits - 1, offLen + 1)\n77:       val higher     \
      \      = Wire(UInt((VAddrBits - offLen - 1).W))\n78:       val higher_plus_one\
      \  = Wire(UInt((VAddrBits - offLen - 1).W))\n79:       val higher_minus_one
      = Wire(UInt((VAddrBits - offLen - 1).W))\n80: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 93-105
    context: "93:         higher_minus_one := h - 1.U\n94:       }\n95:       val
      target =\n96:         Cat(\n97:           Mux1H(Seq(\n98:             (stat
      === TAR_OVF, higher_plus_one),\n99:             (stat === TAR_UDF, higher_minus_one),\n\
      100:             (stat === TAR_FIT, higher)\n101:           )),\n102:      \
      \     lower(offLen - 1, 0),\n103:           0.U(1.W)\n104:         )\n105: \
      \      require(target.getWidth == VAddrBits)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 210-220
    context: "210:     this.tailSlot.setLowerStatByTarget(pc, target, false)\n211:\
      \ \n212:   def getTargetVec(pc: UInt, last_stage: Option[Tuple2[UInt, Bool]]
      = None) = {\n213:     /*\n214:     Previous design: Use the getTarget function
      of FTBSlot to calculate three sets of targets separately;\n215:     During this
      process, nine sets of registers will be generated to register the values of
      the higher plus one minus one\n216:     Current design: Reuse the duplicate
      parts of the original nine sets of registers,\n217:     calculate the common
      high bits last_stage_pc_higher of brtarget and jmptarget,\n218:     and the
      high bits last_stage_pc_middle that need to be added and subtracted from each
      other,\n219:     and then concatenate them according to the carry situation
      to obtain brtarget and jmptarget\n220:      */"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 420-430
    context: "420:     entry.display(cond)\n421:     XSDebug(cond, p\"tag is ${Hexadecimal(tag)}\\
      n------------------------------- \\n\")\n422:   }\n423: }\n424: \n425: class
      FTBMeta(implicit p: Parameters) extends XSBundle with FTBParams {\n426:   val
      writeWay   = UInt(log2Ceil(numWays).W)\n427:   val hit        = Bool()\n428:\
      \   val pred_cycle = if (!env.FPGAPlatform) Some(UInt(64.W)) else None\n429:
      }\n430: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 426-438
    context: "426:   val writeWay   = UInt(log2Ceil(numWays).W)\n427:   val hit  \
      \      = Bool()\n428:   val pred_cycle = if (!env.FPGAPlatform) Some(UInt(64.W))
      else None\n429: }\n430: \n431: object FTBMeta {\n432:   def apply(writeWay:
      UInt, hit: Bool, pred_cycle: UInt)(implicit p: Parameters): FTBMeta = {\n433:\
      \     val e = Wire(new FTBMeta)\n434:     e.writeWay := writeWay\n435:     e.hit\
      \      := hit\n436:     e.pred_cycle.map(_ := pred_cycle)\n437:     e\n438:\
      \   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 462-472
    context: "462:   def getTag(x: UInt) = addr.getTag(x)\n463: }\n464: \n465: class
      FTB(implicit p: Parameters) extends BasePredictor with FTBParams with BPUUtils\n\
      466:     with HasCircularQueuePtrHelper with HasPerfEvents {\n467:   override
      val meta_size = WireInit(0.U.asTypeOf(new FTBMeta)).getWidth\n468: \n469:  \
      \ val ftbAddr = new FTBTableAddr(log2Up(numSets), 1, 3)\n470: \n471:   class
      FTBBank(val numSets: Int, val nWays: Int) extends XSModule with BPUUtils {\n\
      472:     val io = IO(new Bundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 520-531
    context: "520:       ftbAddr.getIdx(io.req_pc.bits)\n521:     ) // s0_idx\n522:\
      \ \n523:     assert(!(io.req_pc.valid && io.u_req_pc.valid))\n524: \n525:  \
      \   io.req_pc.ready   := ftb.io.r.req.ready\n526:     io.u_req_pc.ready := ftb.io.r.req.ready\n\
      527: \n528:     val req_tag = RegEnable(ftbAddr.getTag(io.req_pc.bits)(tagLength
      - 1, 0), io.req_pc.valid)\n529:     val req_idx = RegEnable(ftbAddr.getIdx(io.req_pc.bits),
      io.req_pc.valid)\n530: \n531:     val u_req_tag = RegEnable(ftbAddr.getTag(io.u_req_pc.bits)(tagLength
      - 1, 0), io.u_req_pc.valid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 562-572
    context: "562:       val req_pc_reg       = RegEnable(io.req_pc.bits, 0.U.asTypeOf(io.req_pc.bits),
      io.req_pc.valid)\n563:       val req_pc_reg_lower = Cat(0.U(1.W), req_pc_reg(instOffsetBits
      + log2Ceil(PredictWidth) - 1, instOffsetBits))\n564:       val ftbEntryEndLowerwithCarry
      = Cat(read_entries(n).carry, read_entries(n).pftAddr)\n565:       val fallThroughErr\
      \            = req_pc_reg_lower + PredictWidth.U >= ftbEntryEndLowerwithCarry\n\
      566:       when(read_entries(n).valid && total_hits(n) && io.s1_fire) {\n567:\
      \         assert(fallThroughErr, s\"FTB read sram entry in way${n} fallThrough
      address error!\")\n568:       }\n569:     }\n570: \n571:     val u_total_hits
      = VecInit((0 until numWays).map(b =>\n572:       ftb.io.r.resp.data(b).tag ===
      u_req_tag && ftb.io.r.resp.data(b).entry.valid && RegNext(io.update_access)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 576-586
    context: "576:     val u_hit_way = OHToUInt(u_total_hits)\n577: \n578:     //
      assert(PopCount(total_hits) === 1.U || PopCount(total_hits) === 0.U)\n579: \
      \    // assert(PopCount(u_total_hits) === 1.U || PopCount(u_total_hits) ===
      0.U)\n580:     for (n <- 1 to numWays) {\n581:       XSPerfAccumulate(f\"ftb_pred_${n}_way_hit\"\
      , PopCount(total_hits) === n.U)\n582:       XSPerfAccumulate(f\"ftb_update_${n}_way_hit\"\
      , PopCount(u_total_hits) === n.U)\n583:     }\n584: \n585:     val replacer
      = ReplacementPolicy.fromString(Some(\"setplru\"), numWays, numSets)\n586:  \
      \   // val allocWriteWay = replacer.way(req_idx)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 589-610
    context: "589:     val touch_way = Seq.fill(1)(Wire(Valid(UInt(log2Ceil(numWays).W))))\n\
      590: \n591:     val write_set = Wire(UInt(log2Ceil(numSets).W))\n592:     val
      write_way = Wire(Valid(UInt(log2Ceil(numWays).W)))\n593: \n594:     val read_set
      = Wire(UInt(log2Ceil(numSets).W))\n595:     val read_way = Wire(Valid(UInt(log2Ceil(numWays).W)))\n\
      596: \n597:     read_set       := req_idx\n598:     read_way.valid := hit\n\
      599:     read_way.bits  := hit_way\n600: \n601:     // Read replacer access
      is postponed for 1 cycle\n602:     // this helps timing\n603:     touch_set(0)\
      \       := Mux(write_way.valid, write_set, RegNext(read_set))\n604:     touch_way(0).valid
      := write_way.valid || RegNext(read_way.valid)\n605:     touch_way(0).bits  :=
      Mux(write_way.valid, write_way.bits, RegNext(read_way.bits))\n606: \n607:  \
      \   replacer.access(touch_set, touch_way)\n608: \n609:     // Select the update
      allocate way\n610:     // Selection logic:"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 716-727
    context: "716:   val s3_hit_dup = io.s2_fire.zip(s2_hit_dup).map { case (f, h)
      =>\n717:     RegEnable(Mux(s2_multi_hit_enable, s2_multi_hit, h), 0.B, f)\n\
      718:   }\n719:   val s3_multi_hit_dup  = io.s2_fire.map(f => RegEnable(s2_multi_hit_enable,
      f))\n720:   val writeWay          = Mux(s1_close_ftb_req, 0.U, ftbBank.io.read_hits.bits)\n\
      721:   val s2_ftb_meta       = RegEnable(FTBMeta(writeWay.asUInt, s1_hit, GTimer()).asUInt,
      io.s1_fire(0))\n722:   val s2_multi_hit_meta = FTBMeta(s2_multi_hit_way.asUInt,
      s2_multi_hit, GTimer()).asUInt\n723: \n724:   // Consistent count of entries
      for fauftb and ftb\n725:   val fauftb_ftb_entry_consistent_counter = RegInit(0.U(FTBCLOSE_THRESHOLD_SZ.W))\n\
      726:   val fauftb_ftb_entry_consistent         = s2_fauftb_ftb_entry_dup(0).entryConsistent(s2_ftbBank_dup(0))\n\
      727: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 751-761
    context: "751:   // To improve Clock Gating Efficiency\n752:   update.meta :=
      RegEnable(io.update.bits.meta, io.update.valid && !io.update.bits.old_entry)\n\
      753: \n754:   // Clear counter during false_hit or ifuRedirect\n755:   val ftb_false_hit
      = WireInit(false.B)\n756:   val needReopen    = s0_close_ftb_req && (ftb_false_hit
      || io.redirectFromIFU)\n757:   ftb_false_hit := update_valid && update.false_hit\n\
      758:   when(needReopen) {\n759:     fauftb_ftb_entry_consistent_counter := 0.U\n\
      760:     s0_close_ftb_req                    := false.B\n761:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 771-781
    context: "771: \n772:   val reopenCounter         = !s1_close_ftb_req && s2_close_ftb_req
      && io.s2_fire(0)\n773:   val falseHitReopenCounter = ftb_false_hit && s1_close_ftb_req\n\
      774:   XSPerfAccumulate(\"ftb_req_reopen_counter\", reopenCounter)\n775:   XSPerfAccumulate(\"\
      false_hit_reopen_Counter\", falseHitReopenCounter)\n776:   XSPerfAccumulate(\"\
      ifuRedirec_needReopen\", s1_close_ftb_req && io.redirectFromIFU)\n777:   XSPerfAccumulate(\"\
      this_cycle_is_close\", s2_close_ftb_req && io.s2_fire(0))\n778:   XSPerfAccumulate(\"\
      this_cycle_is_open\", !s2_close_ftb_req && io.s2_fire(0))\n779: \n780:   //
      io.out.bits.resp := RegEnable(io.in.bits.resp_in(0), 0.U.asTypeOf(new BranchPredictionResp),
      io.s1_fire)\n781:   io.out := io.in.bits.resp_in(0)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 810-820
    context: "810:   io.out.last_stage_ftb_entry := s3_ftb_entry_dup(0)\n811:   io.out.last_stage_meta\
      \      := RegEnable(Mux(s2_multi_hit_enable, s2_multi_hit_meta, s2_ftb_meta),
      io.s2_fire(0))\n812:   io.out.s1_ftbCloseReq       := s1_close_ftb_req\n813:\
      \   io.out.s1_uftbHit           := io.fauftb_entry_hit_in\n814:   val s1_uftbHasIndirect
      = io.fauftb_entry_in.jmpValid &&\n815:     io.fauftb_entry_in.isJalr && !io.fauftb_entry_in.isRet
      // uFTB determines that it's real JALR, RET and JAL are excluded\n816:   io.out.s1_uftbHasIndirect
      := s1_uftbHasIndirect\n817: \n818:   // always taken logic\n819:   for (i <-
      0 until numBr) {\n820:     for ("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 834-857
    context: "834:   val s3_ftb_entry_endLowerwithCarry = Cat(s3_ftb_entry_dup(0).carry,
      s3_ftb_entry_dup(0).pftAddr)\n835:   val fallThroughErr =\n836:     s3_pc_startLower
      >= s3_ftb_entry_endLowerwithCarry || s3_ftb_entry_endLowerwithCarry > (s3_pc_startLower
      + PredictWidth.U)\n837:   XSError(\n838:     s3_ftb_entry_dup(0).valid && s3_hit_dup(0)
      && io.s3_fire(0) && fallThroughErr,\n839:     \"FTB read sram entry in s3 fallThrough
      address error!\"\n840:   )\n841: \n842:   // Update logic\n843:   val u_meta\
      \  = update.meta.asTypeOf(new FTBMeta)\n844:   val u_valid = update_valid &&
      !update.old_entry && !s0_close_ftb_req\n845: \n846:   val (_, delay2_pc)   \
      \ = DelayNWithValid(update_pc, u_valid, 2)\n847:   val (_, delay2_entry) = DelayNWithValid(update.ftb_entry,
      u_valid, 2)\n848: \n849:   val update_now       = u_valid && u_meta.hit\n850:\
      \   val update_need_read = u_valid && !u_meta.hit\n851:   // stall one more
      cycle because we use a whole cycle to do update read tag hit\n852:   io.s1_ready
      := ftbBank.io.req_pc.ready && !update_need_read && !RegNext(update_need_read)\n\
      853: \n854:   ftbBank.io.u_req_pc.valid := update_need_read\n855:   ftbBank.io.u_req_pc.bits\
      \  := update_pc\n856: \n857:   val ftb_write = Wire(new FTBEntryWithTag)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 880-890
    context: "880:   val ftb_write_fallThrough = ftb_write.entry.getFallThrough(write_pc)\n\
      881:   when(write_valid) {\n882:     assert(write_pc + (FetchWidth * 4).U >=
      ftb_write_fallThrough, s\"FTB write_entry fallThrough address error!\")\n883:\
      \   }\n884: \n885:   XSDebug(\"req_v=%b, req_pc=%x, ready=%b (resp at next cycle)\\\
      n\", io.s0_fire(0), s0_pc_dup(0), ftbBank.io.req_pc.ready)\n886:   XSDebug(\"\
      s2_hit=%b, hit_way=%b\\n\", s2_hit_dup(0), writeWay.asUInt)\n887:   XSDebug(\n\
      888:     \"s2_br_taken_mask=%b, s2_real_taken_mask=%b\\n\",\n889:     io.in.bits.resp_in(0).s2.full_pred(0).br_taken_mask.asUInt,\n\
      890:     io.out.s2.full_pred(0).real_slot_taken_mask().asUInt"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/SC.scala
    lines: 108-118
    context: "108:   def ctrUpdate(ctr: SInt, cond: Bool): SInt = signedSatUpdate(ctr,
      ctrBits, cond)\n109: \n110:   val s0_idx = getIdx(io.req.bits.pc, io.req.bits.folded_hist)\n\
      111:   val s1_idx = RegEnable(s0_idx, io.req.valid)\n112: \n113:   val s1_pc\
      \           = RegEnable(io.req.bits.pc, io.req.fire)\n114:   val s1_unhashed_idx
      = s1_pc >> instOffsetBits\n115: \n116:   table.io.r.req.valid       := io.req.valid\n\
      117:   table.io.r.req.bits.setIdx := s0_idx\n118: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/SC.scala
    lines: 318-328
    context: "318:       io.out.last_stage_spec_info.sc_disagree.map(_ := s3_disagree)\n\
      319: \n320:       scMeta.scPreds(w) := RegEnable(s2_scPreds(s2_chooseBit), io.s2_fire(3))\n\
      321:       scMeta.ctrs(w)    := RegEnable(s2_scCtrs, io.s2_fire(3))\n322: \n\
      323:       val pred     = s2_scPreds(s2_chooseBit)\n324:       val debug_pc
      = Cat(debug_pc_s2, w.U, 0.U(instOffsetBits.W))\n325:       when(s2_provideds(w))
      {\n326:         s2_sc_used(w) := true.B\n327:         s2_unconf(w)  := !s2_sumAboveThresholds(s2_chooseBit)\n\
      328:         s2_conf(w)    := s2_sumAboveThresholds(s2_chooseBit)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/SC.scala
    lines: 326-337
    context: "326:         s2_sc_used(w) := true.B\n327:         s2_unconf(w)  :=
      !s2_sumAboveThresholds(s2_chooseBit)\n328:         s2_conf(w)    := s2_sumAboveThresholds(s2_chooseBit)\n\
      329:         // Use prediction from Statistical Corrector\n330:         when(s2_sumAboveThresholds(s2_chooseBit))
      {\n331:           s2_agree(w)    := s2_tageTakens_dup(3)(w) === pred\n332: \
      \          s2_disagree(w) := s2_tageTakens_dup(3)(w) =/= pred\n333:        \
      \   // fit to always-taken condition\n334:           // io.out.s2.full_pred.br_taken_mask(w)
      := pred\n335:         }\n336:       }\n337:       XSDebug(s2_provideds(w), p\"\
      ---------tage_bank_${w} provided so that sc used---------\\n\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/SC.scala
    lines: 335-345
    context: "335:         }\n336:       }\n337:       XSDebug(s2_provideds(w), p\"\
      ---------tage_bank_${w} provided so that sc used---------\\n\")\n338:      \
      \ XSDebug(\n339:         s2_provideds(w) && s2_sumAboveThresholds(s2_chooseBit),\n\
      340:         p\"pc(${Hexadecimal(debug_pc)}) SC(${w.U}) overriden pred to ${pred}\\\
      n\"\n341:       )\n342: \n343:       val s3_pred_dup   = io.s2_fire.map(f =>
      RegEnable(s2_pred, f))\n344:       val sc_enable_dup = dup(RegNext(io.ctrl.sc_enable))\n\
      345:       for ("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/SC.scala
    lines: 364-374
    context: "364:       val thres             = useThresholds(w)\n365:       val
      newThres          = scThresholds(w).update(scPred =/= taken)\n366:       when(updateValids(w)
      && updateTageMeta.providers(w).valid) {\n367:         scUpdateTagePreds(w) :=
      tagePred\n368:         scUpdateTakens(w)    := taken\n369:         (scUpdateOldCtrs(w)
      zip scOldCtrs).foreach { case (t, c) => t := c }\n370: \n371:         update_sc_used(w)\
      \    := true.B\n372:         update_unconf(w)     := !sumAboveThreshold\n373:\
      \         update_conf(w)       := sumAboveThreshold\n374:         update_agree(w)\
      \      := scPred === tagePred"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/SC.scala
    lines: 379-389
    context: "379:         when(scPred =/= tagePred && totalSumAbs >= thres - 4.U
      && totalSumAbs <= thres - 2.U) {\n380:           scThresholds(w) := newThres\n\
      381:         }\n382: \n383:         when(scPred =/= taken || !sumAboveThreshold)
      {\n384:           scUpdateMask(w).foreach(_ := true.B)\n385:           update_on_mispred(w)
      := scPred =/= taken\n386:           update_on_unconf(w)  := scPred === taken\n\
      387:         }\n388:       }\n389:       XSDebug("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 27-37
    context: "27: import xiangshan.cache.mmu._\n28: import xiangshan.frontend.icache._\n\
      29: \n30: trait HasInstrMMIOConst extends HasXSParameter with HasIFUConst {\n\
      31:   def mmioBusWidth = 64\n32:   def mmioBusBytes = mmioBusWidth / 8\n33:\
      \   def maxInstrLen  = 32\n34: }\n35: \n36: trait HasIFUConst extends HasXSParameter
      {\n37:   def addrAlign(addr: UInt, bytes: Int, highest: Int): UInt ="
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 77-87
    context: "77:   val uncacheInter    = new UncacheInterface\n78:   val frontendTrigger
      = Flipped(new FrontendTdataDistributeIO)\n79:   val rob_commits     = Flipped(Vec(CommitWidth,
      Valid(new RobCommitInfo)))\n80:   val iTLBInter       = new TlbRequestIO\n81:\
      \   val pmp             = new ICachePMPBundle\n82:   val mmioCommitRead  = new
      mmioCommitRead\n83:   val csr_fsIsOff     = Input(Bool())\n84: }\n85: \n86:
      // record the situation in which fallThruAddr falls into\n87: // the middle
      of an RVI inst"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 83-93
    context: "83:   val csr_fsIsOff     = Input(Bool())\n84: }\n85: \n86: // record
      the situation in which fallThruAddr falls into\n87: // the middle of an RVI
      inst\n88: class LastHalfInfo(implicit p: Parameters) extends XSBundle {\n89:\
      \   val valid    = Bool()\n90:   val middlePC = UInt(VAddrBits.W)\n91:   def
      matchThisBlock(startAddr: UInt) = valid && middlePC === startAddr\n92: }\n93: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 140-150
    context: "140:   val fromICache               = io.icacheInter.resp\n141:   val
      (toUncache, fromUncache) = (io.uncacheInter.toUncache, io.uncacheInter.fromUncache)\n\
      142: \n143:   def isCrossLineReq(start: UInt, end: UInt): Bool = start(blockOffBits)
      ^ end(blockOffBits)\n144: \n145:   def numOfStage = 3\n146:   // equal lower_result
      overflow bit\n147:   def PcCutPoint = (VAddrBits / 4) - 1\n148:   def CatPC(low:
      UInt, high: UInt, high1: UInt): UInt =\n149:     Mux(\n150:       low(PcCutPoint),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 150-161
    context: "150:       low(PcCutPoint),\n151:       Cat(high1, low(PcCutPoint -
      1, 0)),\n152:       Cat(high, low(PcCutPoint - 1, 0))\n153:     )\n154:   def
      CatPC(lowVec: Vec[UInt], high: UInt, high1: UInt): Vec[UInt] = VecInit(lowVec.map(CatPC(_,
      high, high1)))\n155:   require(numOfStage > 1, \"BPU numOfStage must be greater
      than 1\")\n156:   val topdown_stages = RegInit(VecInit(Seq.fill(numOfStage)(0.U.asTypeOf(new
      FrontendTopDownBundle))))\n157:   // bubble events in IFU, only happen in stage
      1\n158:   val icacheMissBubble = Wire(Bool())\n159:   val itlbMissBubble   =
      Wire(Bool())\n160: \n161:   // only driven by clock, not valid-ready"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 158-168
    context: "158:   val icacheMissBubble = Wire(Bool())\n159:   val itlbMissBubble\
      \   = Wire(Bool())\n160: \n161:   // only driven by clock, not valid-ready\n\
      162:   topdown_stages(0) := fromFtq.req.bits.topdown_info\n163:   for (i <-
      1 until numOfStage) {\n164:     topdown_stages(i) := topdown_stages(i - 1)\n\
      165:   }\n166:   when(icacheMissBubble) {\n167:     topdown_stages(1).reasons(TopDownCounters.ICacheMissBubble.id)
      := true.B\n168:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 167-219
    context: "167:     topdown_stages(1).reasons(TopDownCounters.ICacheMissBubble.id)
      := true.B\n168:   }\n169:   when(itlbMissBubble) {\n170:     topdown_stages(1).reasons(TopDownCounters.ITLBMissBubble.id)
      := true.B\n171:   }\n172:   io.toIbuffer.bits.topdown_info := topdown_stages(numOfStage
      - 1)\n173:   when(fromFtq.topdown_redirect.valid) {\n174:     // only redirect
      from backend, IFU redirect itself is handled elsewhere\n175:     when(fromFtq.topdown_redirect.bits.debugIsCtrl)
      {\n176:       /*\n177:       for (i <- 0 until numOfStage) {\n178:         topdown_stages(i).reasons(TopDownCounters.ControlRedirectBubble.id)
      := true.B\n179:       }\n180:       io.toIbuffer.bits.topdown_info.reasons(TopDownCounters.ControlRedirectBubble.id)
      := true.B\n181:        */\n182:       when(fromFtq.topdown_redirect.bits.ControlBTBMissBubble)
      {\n183:         for (i <- 0 until numOfStage) {\n184:           topdown_stages(i).reasons(TopDownCounters.BTBMissBubble.id)
      := true.B\n185:         }\n186:         io.toIbuffer.bits.topdown_info.reasons(TopDownCounters.BTBMissBubble.id)
      := true.B\n187:       }.elsewhen(fromFtq.topdown_redirect.bits.TAGEMissBubble)
      {\n188:         for (i <- 0 until numOfStage) {\n189:           topdown_stages(i).reasons(TopDownCounters.TAGEMissBubble.id)
      := true.B\n190:         }\n191:         io.toIbuffer.bits.topdown_info.reasons(TopDownCounters.TAGEMissBubble.id)
      := true.B\n192:       }.elsewhen(fromFtq.topdown_redirect.bits.SCMissBubble)
      {\n193:         for (i <- 0 until numOfStage) {\n194:           topdown_stages(i).reasons(TopDownCounters.SCMissBubble.id)
      := true.B\n195:         }\n196:         io.toIbuffer.bits.topdown_info.reasons(TopDownCounters.SCMissBubble.id)
      := true.B\n197:       }.elsewhen(fromFtq.topdown_redirect.bits.ITTAGEMissBubble)
      {\n198:         for (i <- 0 until numOfStage) {\n199:           topdown_stages(i).reasons(TopDownCounters.ITTAGEMissBubble.id)
      := true.B\n200:         }\n201:         io.toIbuffer.bits.topdown_info.reasons(TopDownCounters.ITTAGEMissBubble.id)
      := true.B\n202:       }.elsewhen(fromFtq.topdown_redirect.bits.RASMissBubble)
      {\n203:         for (i <- 0 until numOfStage) {\n204:           topdown_stages(i).reasons(TopDownCounters.RASMissBubble.id)
      := true.B\n205:         }\n206:         io.toIbuffer.bits.topdown_info.reasons(TopDownCounters.RASMissBubble.id)
      := true.B\n207:       }\n208:     }.elsewhen(fromFtq.topdown_redirect.bits.debugIsMemVio)
      {\n209:       for (i <- 0 until numOfStage) {\n210:         topdown_stages(i).reasons(TopDownCounters.MemVioRedirectBubble.id)
      := true.B\n211:       }\n212:       io.toIbuffer.bits.topdown_info.reasons(TopDownCounters.MemVioRedirectBubble.id)
      := true.B\n213:     }.otherwise {\n214:       for (i <- 0 until numOfStage)
      {\n215:         topdown_stages(i).reasons(TopDownCounters.OtherRedirectBubble.id)
      := true.B\n216:       }\n217:       io.toIbuffer.bits.topdown_info.reasons(TopDownCounters.OtherRedirectBubble.id)
      := true.B\n218:     }\n219:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 219-229
    context: "219:   }\n220: \n221:   class TlbExept(implicit p: Parameters) extends
      XSBundle {\n222:     val pageFault   = Bool()\n223:     val accessFault = Bool()\n\
      224:     val mmio        = Bool()\n225:   }\n226: \n227:   val preDecoder =
      Module(new PreDecode)\n228: \n229:   val predChecker     = Module(new PredChecker)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 236-274
    context: "236:     * IFU Stage 0\n237:     * - send cacheline fetch request to
      ICacheMainPipe\n238:     ******************************************************************************\n\
      239:     */\n240: \n241:   val f0_valid      = fromFtq.req.valid\n242:   val
      f0_ftq_req    = fromFtq.req.bits\n243:   val f0_doubleLine = fromFtq.req.bits.crossCacheline\n\
      244:   val f0_vSetIdx    = VecInit(get_idx(f0_ftq_req.startAddr), get_idx(f0_ftq_req.nextlineStart))\n\
      245:   val f0_fire       = fromFtq.req.fire\n246: \n247:   val f0_flush, f1_flush,
      f2_flush, f3_flush = WireInit(false.B)\n248: \n249:   val f0_flush_from_bpu
      = fromFtq.flushFromBpu.shouldFlushByStage2(f0_ftq_req.ftqIdx) ||\n250:     fromFtq.flushFromBpu.shouldFlushByStage3(f0_ftq_req.ftqIdx)\n\
      251: \n252:   val wb_redirect, mmio_redirect, backend_redirect = WireInit(false.B)\n\
      253:   val f3_wb_not_flush                              = WireInit(false.B)\n\
      254: \n255:   backend_redirect := fromFtq.redirect.valid\n256:   f3_flush  \
      \       := backend_redirect || (wb_redirect && !f3_wb_not_flush)\n257:   f2_flush\
      \         := backend_redirect && mmio_redirect || wb_redirect\n258:   f1_flush\
      \         := f2_flush\n259:   f0_flush         := f1_flush || f0_flush_from_bpu\n\
      260: \n261:   val f1_ready, f2_ready, f3_ready = WireInit(false.B)\n262: \n\
      263:   fromFtq.req.ready := f1_ready && io.icacheInter.icacheReady\n264: \n\
      265:   when(wb_redirect) {\n266:     when(f3_wb_not_flush) {\n267:       topdown_stages(2).reasons(TopDownCounters.BTBMissBubble.id)
      := true.B\n268:     }\n269:     for (i <- 0 until numOfStage - 1) {\n270:  \
      \     topdown_stages(i).reasons(TopDownCounters.BTBMissBubble.id) := true.B\n\
      271:     }\n272:   }\n273: \n274:   /** <PERF> f0 fetch bubble */"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 271-287
    context: "271:     }\n272:   }\n273: \n274:   /** <PERF> f0 fetch bubble */\n\
      275: \n276:   XSPerfAccumulate(\"fetch_bubble_ftq_not_valid\", !fromFtq.req.valid
      && fromFtq.req.ready)\n277:   // XSPerfAccumulate(\"fetch_bubble_pipe_stall\"\
      ,    f0_valid && toICache(0).ready && toICache(1).ready && !f1_ready )\n278:\
      \   // XSPerfAccumulate(\"fetch_bubble_icache_0_busy\",   f0_valid && !toICache(0).ready\
      \  )\n279:   // XSPerfAccumulate(\"fetch_bubble_icache_1_busy\",   f0_valid
      && !toICache(1).ready  )\n280:   XSPerfAccumulate(\"fetch_flush_backend_redirect\"\
      , backend_redirect)\n281:   XSPerfAccumulate(\"fetch_flush_wb_redirect\", wb_redirect)\n\
      282:   XSPerfAccumulate(\"fetch_flush_f0_flush_from_bpu\", f0_flush_from_bpu)\n\
      283: \n284:   /**\n285:     ******************************************************************************\n\
      286:     * IFU Stage 1\n287:     * - calculate pc/half_pc/cut_ptr for every
      instruction"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 286-309
    context: "286:     * IFU Stage 1\n287:     * - calculate pc/half_pc/cut_ptr for
      every instruction\n288:     ******************************************************************************\n\
      289:     */\n290: \n291:   val f1_valid   = RegInit(false.B)\n292:   val f1_ftq_req
      = RegEnable(f0_ftq_req, f0_fire)\n293:   // val f1_situation  = RegEnable(f0_situation,\
      \  f0_fire)\n294:   val f1_doubleLine = RegEnable(f0_doubleLine, f0_fire)\n\
      295:   val f1_vSetIdx    = RegEnable(f0_vSetIdx, f0_fire)\n296:   val f1_fire\
      \       = f1_valid && f2_ready\n297: \n298:   f1_ready := f1_fire || !f1_valid\n\
      299: \n300:   assert(!(fromFtq.flushFromBpu.shouldFlushByStage3(f1_ftq_req.ftqIdx)
      && f1_valid))\n301: \n302:   when(f1_flush)(f1_valid := false.B)\n303:     .elsewhen(f0_fire
      && !f0_flush)(f1_valid := true.B)\n304:     .elsewhen(f1_fire)(f1_valid := false.B)\n\
      305: \n306:   val f1_pc_high       = f1_ftq_req.startAddr(VAddrBits - 1, PcCutPoint)\n\
      307:   val f1_pc_high_plus1 = f1_pc_high + 1.U\n308: \n309:   /**"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 352-369
    context: "352:     ******************************************************************************\n\
      353:     */\n354: \n355:   val icacheRespAllValid = WireInit(false.B)\n356:\
      \ \n357:   val f2_valid   = RegInit(false.B)\n358:   val f2_ftq_req = RegEnable(f1_ftq_req,
      f1_fire)\n359:   // val f2_situation  = RegEnable(f1_situation,  f1_fire)\n\
      360:   val f2_doubleLine = RegEnable(f1_doubleLine, f1_fire)\n361:   val f2_vSetIdx\
      \    = RegEnable(f1_vSetIdx, f1_fire)\n362:   val f2_fire       = f2_valid &&
      f3_ready && icacheRespAllValid\n363: \n364:   f2_ready := f2_fire || !f2_valid\n\
      365:   // TODO: addr compare may be timing critical\n366:   val f2_icache_all_resp_wire
      =\n367:     fromICache.valid &&\n368:       fromICache.bits.vaddr(0) === f2_ftq_req.startAddr
      &&\n369:       (fromICache.bits.doubleline && fromICache.bits.vaddr(1) === f2_ftq_req.nextlineStart
      || !f2_doubleLine)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 372-390
    context: "372:   icacheRespAllValid := f2_icache_all_resp_reg || f2_icache_all_resp_wire\n\
      373: \n374:   icacheMissBubble := io.icacheInter.topdownIcacheMiss\n375:   itlbMissBubble\
      \   := io.icacheInter.topdownItlbMiss\n376: \n377:   io.icacheStop := !f3_ready\n\
      378: \n379:   when(f2_flush)(f2_icache_all_resp_reg := false.B)\n380:     .elsewhen(f2_valid
      && f2_icache_all_resp_wire && !f3_ready)(f2_icache_all_resp_reg := true.B)\n\
      381:     .elsewhen(f2_fire && f2_icache_all_resp_reg)(f2_icache_all_resp_reg
      := false.B)\n382: \n383:   when(f2_flush)(f2_valid := false.B)\n384:     .elsewhen(f1_fire
      && !f1_flush)(f2_valid := true.B)\n385:     .elsewhen(f2_fire)(f2_valid := false.B)\n\
      386: \n387:   val f2_exception_in     = fromICache.bits.exception\n388:   val
      f2_backendException = fromICache.bits.backendException\n389:   // paddr and
      gpaddr of [startAddr, nextLineAddr]\n390:   val f2_paddrs            = fromICache.bits.paddr"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 397-407
    context: "397:     Mux(\n398:       // not double-line, skip check\n399:     \
      \  !fromICache.bits.doubleline || (\n400:         // is double-line, ask for
      consistent pmp_mmio and itlb_pbmt value\n401:         fromICache.bits.pmp_mmio(0)
      === fromICache.bits.pmp_mmio(1) &&\n402:           fromICache.bits.itlb_pbmt(0)
      === fromICache.bits.itlb_pbmt(1)\n403:       ),\n404:       ExceptionType.none,\n\
      405:       ExceptionType.af\n406:     )\n407:   ))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 409-419
    context: "409:   // merge exceptions\n410:   val f2_exception = ExceptionType.merge(f2_exception_in,
      f2_mmio_mismatch_exception)\n411: \n412:   // we need only the first port, as
      the second is asked to be the same\n413:   val f2_pmp_mmio  = fromICache.bits.pmp_mmio(0)\n\
      414:   val f2_itlb_pbmt = fromICache.bits.itlb_pbmt(0)\n415: \n416:   /**\n\
      417:     * reduce the number of registers, origin code\n418:     * f2_pc = RegEnable(f1_pc,
      f1_fire)\n419:     */"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 458-468
    context: "458:   def cut(cacheline: UInt, cutPtr: Vec[UInt]): Vec[UInt] = {\n\
      459:     require(HasCExtension)\n460:     // if(HasCExtension){\n461:     val
      result  = Wire(Vec(PredictWidth + 1, UInt(16.W)))\n462:     val dataVec = cacheline.asTypeOf(Vec(blockBytes,
      UInt(16.W))) // 32 16-bit data vector\n463:     (0 until PredictWidth + 1).foreach(i
      =>\n464:       result(i) := dataVec(cutPtr(i)) // the max ptr is 3*blockBytes/4-1\n\
      465:     )\n466:     result\n467:     // } else {\n468:     //   val result\
      \   = Wire(Vec(PredictWidth, UInt(32.W)) )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 511-521
    context: "511:   // preDecoderRegInIn.frontendTrigger := io.frontendTrigger\n\
      512:   // preDecoderRegInIn.csrTriggerEnable := io.csrTriggerEnable\n513:  \
      \ // preDecoderRegIn.pc  := f2_pc\n514: \n515:   val preDecoderIn = preDecoder.io.in\n\
      516:   preDecoderIn.valid                := f2_valid\n517:   preDecoderIn.bits.data\
      \            := f2_cut_data\n518:   preDecoderIn.bits.frontendTrigger := io.frontendTrigger\n\
      519:   preDecoderIn.bits.pc              := f2_pc\n520:   val preDecoderOut
      = preDecoder.io.out\n521: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 521-531
    context: "521: \n522:   // val f2_expd_instr     = preDecoderOut.expInstr\n523:\
      \   val f2_instr        = preDecoderOut.instr\n524:   val f2_pd           =
      preDecoderOut.pd\n525:   val f2_jump_offset  = preDecoderOut.jumpOffset\n526:\
      \   val f2_hasHalfValid = preDecoderOut.hasHalfValid\n527:   /* if there is
      a cross-page RVI instruction, and the former page has no exception,\n528:  \
      \  * whether it has exception is actually depends on the latter page\n529: \
      \   */\n530:   val f2_crossPage_exception_vec = VecInit((0 until PredictWidth).map
      { i =>\n531:     Mux("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 532-542
    context: "532:       isLastInLine(f2_pc(i)) && !f2_pd(i).isRVC && f2_doubleLine
      && !ExceptionType.hasException(f2_exception(0)),\n533:       f2_exception(1),\n\
      534:       ExceptionType.none\n535:     )\n536:   })\n537:   XSPerfAccumulate(\"\
      fetch_bubble_icache_not_resp\", f2_valid && !icacheRespAllValid)\n538: \n539:\
      \   /**\n540:     ******************************************************************************\n\
      541:     * IFU Stage 3\n542:     * - handle MMIO instruciton"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 550-564
    context: "550:     ******************************************************************************\n\
      551:     */\n552: \n553:   val expanders = Seq.fill(PredictWidth)(Module(new
      RVCExpander))\n554: \n555:   val f3_valid   = RegInit(false.B)\n556:   val f3_ftq_req
      = RegEnable(f2_ftq_req, f2_fire)\n557:   // val f3_situation      = RegEnable(f2_situation,\
      \  f2_fire)\n558:   val f3_doubleLine = RegEnable(f2_doubleLine, f2_fire)\n\
      559:   val f3_fire       = io.toIbuffer.fire\n560: \n561:   val f3_cut_data
      = RegEnable(f2_cut_data, f2_fire)\n562: \n563:   val f3_exception        = RegEnable(f2_exception,
      f2_fire)\n564:   val f3_pmp_mmio         = RegEnable(f2_pmp_mmio, f2_fire)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 560-575
    context: "560: \n561:   val f3_cut_data = RegEnable(f2_cut_data, f2_fire)\n562:\
      \ \n563:   val f3_exception        = RegEnable(f2_exception, f2_fire)\n564:\
      \   val f3_pmp_mmio         = RegEnable(f2_pmp_mmio, f2_fire)\n565:   val f3_itlb_pbmt\
      \        = RegEnable(f2_itlb_pbmt, f2_fire)\n566:   val f3_backendException
      = RegEnable(f2_backendException, f2_fire)\n567: \n568:   val f3_instr = RegEnable(f2_instr,
      f2_fire)\n569: \n570:   expanders.zipWithIndex.foreach { case (expander, i)
      =>\n571:     expander.io.in      := f3_instr(i)\n572:     expander.io.fsIsOff
      := io.csr_fsIsOff\n573:   }\n574:   // Use expanded instruction only when input
      is legal.\n575:   // Otherwise use origin illegal RVC instruction."
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 609-619
    context: "609:     }\n610:   }\n611: \n612:   val f3_instr_range       = RegEnable(f2_instr_range,
      f2_fire)\n613:   val f3_foldpc            = RegEnable(f2_foldpc, f2_fire)\n\
      614:   val f3_hasHalfValid      = RegEnable(f2_hasHalfValid, f2_fire)\n615:\
      \   val f3_paddrs            = RegEnable(f2_paddrs, f2_fire)\n616:   val f3_gpaddr\
      \            = RegEnable(f2_gpaddr, f2_fire)\n617:   val f3_isForVSnonLeafPTE
      = RegEnable(f2_isForVSnonLeafPTE, f2_fire)\n618:   val f3_resend_vaddr     \
      \ = RegEnable(f2_resend_vaddr, f2_fire)\n619: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 630-642
    context: "630:     pd.isCall := f3Predecoder.io.out.pd(i).isCall\n631:     pd.isRet\
      \  := f3Predecoder.io.out.pd(i).isRet\n632:   }\n633: \n634:   val f3PdDiff
      = f3_pd_wire.zip(f3_pd).map { case (a, b) => a.asUInt =/= b.asUInt }.reduce(_
      || _)\n635:   XSError(f3_valid && f3PdDiff, \"f3 pd diff\")\n636: \n637:   when(f3_valid
      && !f3_ftq_req.ftqOffset.valid) {\n638:     assert(\n639:       f3_ftq_req_startAddr
      + (2 * PredictWidth).U >= f3_ftq_req_nextStartAddr,\n640:       s\"More tha
      ${2 * PredictWidth} Bytes fetch is not allowed!\"\n641:     )\n642:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 640-654
    context: "640:       s\"More tha ${2 * PredictWidth} Bytes fetch is not allowed!\"\
      \n641:     )\n642:   }\n643: \n644:   /*** MMIO State Machine***/\n645:   val
      f3_mmio_data     = Reg(Vec(2, UInt(16.W)))\n646:   val mmio_exception   = RegInit(0.U(ExceptionType.width.W))\n\
      647:   val mmio_is_RVC      = RegInit(false.B)\n648:   val mmio_has_resend \
      \ = RegInit(false.B)\n649:   val mmio_resend_addr = RegInit(0.U(PAddrBits.W))\n\
      650:   // NOTE: we dont use GPAddrBits here, refer to ICacheMainPipe.scala L43-48
      and PR#3795\n651:   val mmio_resend_gpaddr            = RegInit(0.U(PAddrBitsMax.W))\n\
      652:   val mmio_resend_isForVSnonLeafPTE = RegInit(false.B)\n653: \n654:   //
      last instuction finish"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 653-667
    context: "653: \n654:   // last instuction finish\n655:   val is_first_instr =
      RegInit(true.B)\n656: \n657:   /*** Determine whether the MMIO instruction is
      executable based on the previous prediction block ***/\n658:   io.mmioCommitRead.mmioFtqPtr
      := RegNext(f3_ftq_req.ftqIdx - 1.U)\n659: \n660:   val m_idle :: m_waitLastCmt
      :: m_sendReq :: m_waitResp :: m_sendTLB :: m_tlbResp :: m_sendPMP :: m_resendReq
      :: m_waitResendResp :: m_waitCommit :: m_commited :: Nil =\n661:     Enum(11)\n\
      662:   val mmio_state = RegInit(m_idle)\n663: \n664:   // do mmio fetch only
      when pmp/pbmt shows it is a uncacheable address and no exception occurs\n665:\
      \   /* FIXME: we do not distinguish pbmt is NC or IO now\n666:    *        but
      we actually can do speculative execution if pbmt is NC, maybe fix this later
      for performance\n667:    */"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 663-695
    context: "663: \n664:   // do mmio fetch only when pmp/pbmt shows it is a uncacheable
      address and no exception occurs\n665:   /* FIXME: we do not distinguish pbmt
      is NC or IO now\n666:    *        but we actually can do speculative execution
      if pbmt is NC, maybe fix this later for performance\n667:    */\n668:   val
      f3_req_is_mmio =\n669:     f3_valid && (f3_pmp_mmio || Pbmt.isUncache(f3_itlb_pbmt))
      && !ExceptionType.hasException(f3_exception)\n670:   val mmio_commit = VecInit(io.rob_commits.map
      { commit =>\n671:     commit.valid && commit.bits.ftqIdx === f3_ftq_req.ftqIdx
      && commit.bits.ftqOffset === 0.U\n672:   }).asUInt.orR\n673:   val f3_mmio_req_commit
      = f3_req_is_mmio && mmio_state === m_commited\n674: \n675:   val f3_mmio_to_commit\
      \      = f3_req_is_mmio && mmio_state === m_waitCommit\n676:   val f3_mmio_to_commit_next
      = RegNext(f3_mmio_to_commit)\n677:   val f3_mmio_can_go         = f3_mmio_to_commit
      && !f3_mmio_to_commit_next\n678: \n679:   val fromFtqRedirectReg = Wire(fromFtq.redirect.cloneType)\n\
      680:   fromFtqRedirectReg.bits := RegEnable(\n681:     fromFtq.redirect.bits,\n\
      682:     0.U.asTypeOf(fromFtq.redirect.bits),\n683:     fromFtq.redirect.valid\n\
      684:   )\n685:   fromFtqRedirectReg.valid := RegNext(fromFtq.redirect.valid,
      init = false.B)\n686:   val mmioF3Flush           = RegNext(f3_flush, init =
      false.B)\n687:   val f3_ftq_flush_self     = fromFtqRedirectReg.valid && RedirectLevel.flushItself(fromFtqRedirectReg.bits.level)\n\
      688:   val f3_ftq_flush_by_older = fromFtqRedirectReg.valid && isBefore(fromFtqRedirectReg.bits.ftqIdx,
      f3_ftq_req.ftqIdx)\n689: \n690:   val f3_need_not_flush = f3_req_is_mmio &&
      fromFtqRedirectReg.valid && !f3_ftq_flush_self && !f3_ftq_flush_by_older\n691:\
      \ \n692:   /**\n693:     **********************************************************************************\n\
      694:     * We want to defer instruction fetching when encountering MMIO instructions
      to ensure that the MMIO region is not negatively impacted.\n695:     * This
      is the exception when the first instruction is an MMIO instruction."
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 697-729
    context: "697:     */\n698:   when(is_first_instr && f3_fire) {\n699:     is_first_instr
      := false.B\n700:   }\n701: \n702:   when(f3_flush && !f3_req_is_mmio)(f3_valid
      := false.B)\n703:     .elsewhen(mmioF3Flush && f3_req_is_mmio && !f3_need_not_flush)(f3_valid
      := false.B)\n704:     .elsewhen(f2_fire && !f2_flush)(f3_valid := true.B)\n\
      705:     .elsewhen(io.toIbuffer.fire && !f3_req_is_mmio)(f3_valid := false.B)\n\
      706:     .elsewhen(f3_req_is_mmio && f3_mmio_req_commit)(f3_valid := false.B)\n\
      707: \n708:   val f3_mmio_use_seq_pc = RegInit(false.B)\n709: \n710:   val (redirect_ftqIdx,
      redirect_ftqOffset) = (fromFtqRedirectReg.bits.ftqIdx, fromFtqRedirectReg.bits.ftqOffset)\n\
      711:   val redirect_mmio_req =\n712:     fromFtqRedirectReg.valid && redirect_ftqIdx
      === f3_ftq_req.ftqIdx && redirect_ftqOffset === 0.U\n713: \n714:   when(RegNext(f2_fire
      && !f2_flush) && f3_req_is_mmio)(f3_mmio_use_seq_pc := true.B)\n715:     .elsewhen(redirect_mmio_req)(f3_mmio_use_seq_pc
      := false.B)\n716: \n717:   f3_ready := (io.toIbuffer.ready && (f3_mmio_req_commit
      || !f3_req_is_mmio)) || !f3_valid\n718: \n719:   // mmio state machine\n720:\
      \   switch(mmio_state) {\n721:     is(m_idle) {\n722:       when(f3_req_is_mmio)
      {\n723:         // in idempotent spaces, we can send request directly (i.e.
      can do speculative fetch)\n724:         mmio_state := Mux(f3_itlb_pbmt === Pbmt.nc,
      m_sendReq, m_waitLastCmt)\n725:       }\n726:     }\n727: \n728:     is(m_waitLastCmt)
      {\n729:       when(is_first_instr) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 725-770
    context: "725:       }\n726:     }\n727: \n728:     is(m_waitLastCmt) {\n729:\
      \       when(is_first_instr) {\n730:         mmio_state := m_sendReq\n731: \
      \      }.otherwise {\n732:         mmio_state := Mux(io.mmioCommitRead.mmioLastCommit,
      m_sendReq, m_waitLastCmt)\n733:       }\n734:     }\n735: \n736:     is(m_sendReq)
      {\n737:       mmio_state := Mux(toUncache.fire, m_waitResp, m_sendReq)\n738:\
      \     }\n739: \n740:     is(m_waitResp) {\n741:       when(fromUncache.fire)
      {\n742:         val isRVC      = fromUncache.bits.data(1, 0) =/= 3.U\n743: \
      \        val exception  = ExceptionType.fromTilelink(fromUncache.bits.corrupt)\n\
      744:         val needResend = !isRVC && f3_paddrs(0)(2, 1) === 3.U && !ExceptionType.hasException(exception)\n\
      745:         mmio_state      := Mux(needResend, m_sendTLB, m_waitCommit)\n746:\
      \         mmio_exception  := exception\n747:         mmio_is_RVC     := isRVC\n\
      748:         mmio_has_resend := needResend\n749:         f3_mmio_data(0) :=
      fromUncache.bits.data(15, 0)\n750:         f3_mmio_data(1) := fromUncache.bits.data(31,
      16)\n751:       }\n752:     }\n753: \n754:     is(m_sendTLB) {\n755:       mmio_state
      := Mux(io.iTLBInter.req.fire, m_tlbResp, m_sendTLB)\n756:     }\n757: \n758:\
      \     is(m_tlbResp) {\n759:       when(io.iTLBInter.resp.fire) {\n760:     \
      \    // we are using a blocked tlb, so resp.fire must have !resp.bits.miss\n\
      761:         assert(!io.iTLBInter.resp.bits.miss, \"blocked mode iTLB miss when
      resp.fire\")\n762:         val tlb_exception = ExceptionType.fromTlbResp(io.iTLBInter.resp.bits)\n\
      763:         // if itlb re-check respond pbmt mismatch with previous check,
      must be access fault\n764:         val pbmt_mismatch_exception = Mux(\n765:\
      \           io.iTLBInter.resp.bits.pbmt(0) =/= f3_itlb_pbmt,\n766:         \
      \  ExceptionType.af,\n767:           ExceptionType.none\n768:         )\n769:\
      \         val exception = ExceptionType.merge(tlb_exception, pbmt_mismatch_exception)\n\
      770:         // if tlb has exception, abort checking pmp, just send instr &
      exception to ibuffer and wait for commit"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 766-779
    context: "766:           ExceptionType.af,\n767:           ExceptionType.none\n\
      768:         )\n769:         val exception = ExceptionType.merge(tlb_exception,
      pbmt_mismatch_exception)\n770:         // if tlb has exception, abort checking
      pmp, just send instr & exception to ibuffer and wait for commit\n771:      \
      \   mmio_state := Mux(ExceptionType.hasException(exception), m_waitCommit, m_sendPMP)\n\
      772:         // also save itlb response\n773:         mmio_exception       \
      \         := exception\n774:         mmio_resend_addr              := io.iTLBInter.resp.bits.paddr(0)\n\
      775:         mmio_resend_gpaddr            := io.iTLBInter.resp.bits.gpaddr(0)\n\
      776:         mmio_resend_isForVSnonLeafPTE := io.iTLBInter.resp.bits.isForVSnonLeafPTE(0)\n\
      777:       }\n778:     }\n779: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 779-789
    context: "779: \n780:     is(m_sendPMP) {\n781:       val pmp_exception = ExceptionType.fromPMPResp(io.pmp.resp)\n\
      782:       // if pmp re-check respond mismatch with previous check, must be
      access fault\n783:       val mmio_mismatch_exception = Mux(\n784:         io.pmp.resp.mmio
      =/= f3_pmp_mmio,\n785:         ExceptionType.af,\n786:         ExceptionType.none\n\
      787:       )\n788:       val exception = ExceptionType.merge(pmp_exception,
      mmio_mismatch_exception)\n789:       // if pmp has exception, abort sending
      request, just send instr & exception to ibuffer and wait for commit"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 785-795
    context: "785:         ExceptionType.af,\n786:         ExceptionType.none\n787:\
      \       )\n788:       val exception = ExceptionType.merge(pmp_exception, mmio_mismatch_exception)\n\
      789:       // if pmp has exception, abort sending request, just send instr &
      exception to ibuffer and wait for commit\n790:       mmio_state := Mux(ExceptionType.hasException(exception),
      m_waitCommit, m_resendReq)\n791:       // also save pmp response\n792:     \
      \  mmio_exception := exception\n793:     }\n794: \n795:     is(m_resendReq)
      {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 791-824
    context: "791:       // also save pmp response\n792:       mmio_exception := exception\n\
      793:     }\n794: \n795:     is(m_resendReq) {\n796:       mmio_state := Mux(toUncache.fire,
      m_waitResendResp, m_resendReq)\n797:     }\n798: \n799:     is(m_waitResendResp)
      {\n800:       when(fromUncache.fire) {\n801:         mmio_state      := m_waitCommit\n\
      802:         mmio_exception  := ExceptionType.fromTilelink(fromUncache.bits.corrupt)\n\
      803:         f3_mmio_data(1) := fromUncache.bits.data(15, 0)\n804:       }\n\
      805:     }\n806: \n807:     is(m_waitCommit) {\n808:       // in idempotent
      spaces, we can skip waiting for commit (i.e. can do speculative fetch)\n809:\
      \       // but we do not skip m_waitCommit state, as other signals (e.g. f3_mmio_can_go
      relies on this)\n810:       mmio_state := Mux(mmio_commit || f3_itlb_pbmt ===
      Pbmt.nc, m_commited, m_waitCommit)\n811:     }\n812: \n813:     // normal mmio
      instruction\n814:     is(m_commited) {\n815:       mmio_state              \
      \      := m_idle\n816:       mmio_exception                := ExceptionType.none\n\
      817:       mmio_is_RVC                   := false.B\n818:       mmio_has_resend\
      \               := false.B\n819:       mmio_resend_addr              := 0.U\n\
      820:       mmio_resend_gpaddr            := 0.U\n821:       mmio_resend_isForVSnonLeafPTE
      := false.B\n822:     }\n823:   }\n824: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 822-848
    context: "822:     }\n823:   }\n824: \n825:   // Exception or flush by older branch
      prediction\n826:   // Condition is from RegNext(fromFtq.redirect), 1 cycle after
      backend rediect\n827:   when(f3_ftq_flush_self || f3_ftq_flush_by_older) {\n\
      828:     mmio_state                    := m_idle\n829:     mmio_exception  \
      \              := ExceptionType.none\n830:     mmio_is_RVC                 \
      \  := false.B\n831:     mmio_has_resend               := false.B\n832:     mmio_resend_addr\
      \              := 0.U\n833:     mmio_resend_gpaddr            := 0.U\n834: \
      \    mmio_resend_isForVSnonLeafPTE := false.B\n835:     f3_mmio_data.map(_ :=
      0.U)\n836:   }\n837: \n838:   toUncache.valid     := ((mmio_state === m_sendReq)
      || (mmio_state === m_resendReq)) && f3_req_is_mmio\n839:   toUncache.bits.addr
      := Mux(mmio_state === m_resendReq, mmio_resend_addr, f3_paddrs(0))\n840:   fromUncache.ready\
      \   := true.B\n841: \n842:   // send itlb request in m_sendTLB state\n843: \
      \  io.iTLBInter.req.valid                   := (mmio_state === m_sendTLB) &&
      f3_req_is_mmio\n844:   io.iTLBInter.req.bits.size               := 3.U\n845:\
      \   io.iTLBInter.req.bits.vaddr              := f3_resend_vaddr\n846:   io.iTLBInter.req.bits.debug.pc\
      \           := f3_resend_vaddr\n847:   io.iTLBInter.req.bits.cmd           \
      \     := TlbCmd.exec\n848:   io.iTLBInter.req.bits.isPrefetch         := false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 844-854
    context: "844:   io.iTLBInter.req.bits.size               := 3.U\n845:   io.iTLBInter.req.bits.vaddr\
      \              := f3_resend_vaddr\n846:   io.iTLBInter.req.bits.debug.pc   \
      \        := f3_resend_vaddr\n847:   io.iTLBInter.req.bits.cmd              \
      \  := TlbCmd.exec\n848:   io.iTLBInter.req.bits.isPrefetch         := false.B\n\
      849:   io.iTLBInter.req.bits.kill               := false.B // IFU use itlb for
      mmio, doesn't need sync, set it to false\n850:   io.iTLBInter.req.bits.no_translate\
      \       := false.B\n851:   io.iTLBInter.req.bits.fullva             := 0.U\n\
      852:   io.iTLBInter.req.bits.checkfullva        := false.B\n853:   io.iTLBInter.req.bits.hyperinst\
      \          := DontCare\n854:   io.iTLBInter.req.bits.hlvx               := DontCare"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 857-878
    context: "857:   io.iTLBInter.req.bits.debug.isFirstIssue := DontCare\n858:  \
      \ io.iTLBInter.req.bits.pmp_addr           := DontCare\n859:   // whats the
      difference between req_kill and req.bits.kill?\n860:   io.iTLBInter.req_kill
      := false.B\n861:   // wait for itlb response in m_tlbResp state\n862:   io.iTLBInter.resp.ready
      := (mmio_state === m_tlbResp) && f3_req_is_mmio\n863: \n864:   io.pmp.req.valid\
      \     := (mmio_state === m_sendPMP) && f3_req_is_mmio\n865:   io.pmp.req.bits.addr
      := mmio_resend_addr\n866:   io.pmp.req.bits.size := 3.U\n867:   io.pmp.req.bits.cmd\
      \  := TlbCmd.exec\n868: \n869:   val f3_lastHalf = RegInit(0.U.asTypeOf(new
      LastHalfInfo))\n870: \n871:   val f3_predecode_range = VecInit(preDecoderOut.pd.map(inst
      => inst.valid)).asUInt\n872:   val f3_mmio_range      = VecInit((0 until PredictWidth).map(i
      => if (i == 0) true.B else false.B))\n873:   val f3_instr_valid     = Wire(Vec(PredictWidth,
      Bool()))\n874: \n875:   /*** prediction result check   ***/\n876:   checkerIn.ftqOffset\
      \  := f3_ftq_req.ftqOffset\n877:   checkerIn.jumpOffset := f3_jump_offset\n\
      878:   checkerIn.target     := f3_ftq_req.nextStartAddr"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 875-885
    context: "875:   /*** prediction result check   ***/\n876:   checkerIn.ftqOffset\
      \  := f3_ftq_req.ftqOffset\n877:   checkerIn.jumpOffset := f3_jump_offset\n\
      878:   checkerIn.target     := f3_ftq_req.nextStartAddr\n879:   checkerIn.instrRange
      := f3_instr_range.asTypeOf(Vec(PredictWidth, Bool()))\n880:   checkerIn.instrValid
      := f3_instr_valid.asTypeOf(Vec(PredictWidth, Bool()))\n881:   checkerIn.pds\
      \        := f3_pd\n882:   checkerIn.pc         := f3_pc\n883:   checkerIn.fire_in\
      \    := RegNext(f2_fire, init = false.B)\n884: \n885:   /*** handle half RVI
      in the last 2 Bytes  ***/"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 882-918
    context: "882:   checkerIn.pc         := f3_pc\n883:   checkerIn.fire_in    :=
      RegNext(f2_fire, init = false.B)\n884: \n885:   /*** handle half RVI in the
      last 2 Bytes  ***/\n886: \n887:   def hasLastHalf(idx: UInt) =\n888:     //
      !f3_pd(idx).isRVC && checkerOutStage1.fixedRange(idx) && f3_instr_valid(idx)
      && !checkerOutStage1.fixedTaken(idx) && !checkerOutStage2.fixedMissPred(idx)
      && ! f3_req_is_mmio\n889:     !f3_pd(idx).isRVC && checkerOutStage1.fixedRange(idx)
      && f3_instr_valid(idx) && !checkerOutStage1.fixedTaken(\n890:       idx\n891:\
      \     ) && !f3_req_is_mmio\n892: \n893:   val f3_last_validIdx = ParallelPosteriorityEncoder(checkerOutStage1.fixedRange)\n\
      894: \n895:   val f3_hasLastHalf    = hasLastHalf((PredictWidth - 1).U)\n896:\
      \   val f3_false_lastHalf = hasLastHalf(f3_last_validIdx)\n897:   val f3_false_snpc\
      \     = f3_half_snpc(f3_last_validIdx)\n898: \n899:   val f3_lastHalf_mask \
      \   = VecInit((0 until PredictWidth).map(i => if (i == 0) false.B else true.B)).asUInt\n\
      900:   val f3_lastHalf_disable = RegInit(false.B)\n901: \n902:   when(f3_flush
      || (f3_fire && f3_lastHalf_disable)) {\n903:     f3_lastHalf_disable := false.B\n\
      904:   }\n905: \n906:   when(f3_flush) {\n907:     f3_lastHalf.valid := false.B\n\
      908:   }.elsewhen(f3_fire) {\n909:     f3_lastHalf.valid    := f3_hasLastHalf
      && !f3_lastHalf_disable\n910:     f3_lastHalf.middlePC := f3_ftq_req.nextStartAddr\n\
      911:   }\n912: \n913:   f3_instr_valid := Mux(f3_lastHalf.valid, f3_hasHalfValid,
      VecInit(f3_pd.map(inst => inst.valid)))\n914: \n915:   /*** frontend Trigger\
      \  ***/\n916:   frontendTrigger.io.pds  := f3_pd\n917:   frontendTrigger.io.pc\
      \   := f3_pc\n918:   frontendTrigger.io.data := f3_cut_data"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 918-934
    context: "918:   frontendTrigger.io.data := f3_cut_data\n919: \n920:   frontendTrigger.io.frontendTrigger
      := io.frontendTrigger\n921: \n922:   val f3_triggered       = frontendTrigger.io.triggered\n\
      923:   val f3_toIbuffer_valid = f3_valid && (!f3_req_is_mmio || f3_mmio_can_go)
      && !f3_flush\n924: \n925:   /*** send to Ibuffer  ***/\n926:   io.toIbuffer.valid\
      \          := f3_toIbuffer_valid\n927:   io.toIbuffer.bits.instrs    := f3_expd_instr\n\
      928:   io.toIbuffer.bits.valid     := f3_instr_valid.asUInt\n929:   io.toIbuffer.bits.enqEnable
      := checkerOutStage1.fixedRange.asUInt & f3_instr_valid.asUInt\n930:   io.toIbuffer.bits.pd\
      \        := f3_pd\n931:   io.toIbuffer.bits.ftqPtr    := f3_ftq_req.ftqIdx\n\
      932:   io.toIbuffer.bits.pc        := f3_pc\n933:   // Find last using PriorityMux\n\
      934:   io.toIbuffer.bits.isLastInFtqEntry := Reverse(PriorityEncoderOH(Reverse(io.toIbuffer.bits.enqEnable))).asBools"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 931-941
    context: "931:   io.toIbuffer.bits.ftqPtr    := f3_ftq_req.ftqIdx\n932:   io.toIbuffer.bits.pc\
      \        := f3_pc\n933:   // Find last using PriorityMux\n934:   io.toIbuffer.bits.isLastInFtqEntry
      := Reverse(PriorityEncoderOH(Reverse(io.toIbuffer.bits.enqEnable))).asBools\n\
      935:   io.toIbuffer.bits.ftqOffset.zipWithIndex.map { case (a, i) =>\n936: \
      \    a.bits := i.U; a.valid := checkerOutStage1.fixedTaken(i) && !f3_req_is_mmio\n\
      937:   }\n938:   io.toIbuffer.bits.foldpc        := f3_foldpc\n939:   io.toIbuffer.bits.exceptionType
      := ExceptionType.merge(f3_exception_vec, f3_crossPage_exception_vec)\n940: \
      \  // backendException only needs to be set for the first instruction.\n941:\
      \   // Other instructions in the same block may have pf or af set,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 946-961
    context: "946:   }\n947:   io.toIbuffer.bits.crossPageIPFFix := f3_crossPage_exception_vec.map(ExceptionType.hasException)\n\
      948:   io.toIbuffer.bits.illegalInstr    := f3_ill\n949:   io.toIbuffer.bits.triggered\
      \       := f3_triggered\n950: \n951:   when(f3_lastHalf.valid) {\n952:     io.toIbuffer.bits.enqEnable
      := checkerOutStage1.fixedRange.asUInt & f3_instr_valid.asUInt & f3_lastHalf_mask\n\
      953:     io.toIbuffer.bits.valid     := f3_lastHalf_mask & f3_instr_valid.asUInt\n\
      954:   }\n955: \n956:   when(io.toIbuffer.valid && io.toIbuffer.ready) {\n957:\
      \     val enqVec = io.toIbuffer.bits.enqEnable\n958:     val allocateSeqNum
      = VecInit((0 until PredictWidth).map { i =>\n959:       val idx  = PopCount(enqVec.take(i
      + 1))\n960:       val pc   = f3_pc(i)\n961:       val code = io.toIbuffer.bits.instrs(i)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 959-973
    context: "959:       val idx  = PopCount(enqVec.take(i + 1))\n960:       val pc\
      \   = f3_pc(i)\n961:       val code = io.toIbuffer.bits.instrs(i)\n962:    \
      \   PerfCCT.createInstMetaAtFetch(idx, pc, code, enqVec(i), clock, reset)\n\
      963:     })\n964:     io.toIbuffer.bits.debug_seqNum.zipWithIndex.foreach {
      case (a, i) =>\n965:       a := allocateSeqNum(i)\n966:     }\n967:   }.otherwise
      {\n968:     io.toIbuffer.bits.debug_seqNum.zipWithIndex.foreach { case (a, i)
      =>\n969:       a := 0.U\n970:     }\n971:   }\n972: \n973:   /** to backend
      */"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 971-988
    context: "971:   }\n972: \n973:   /** to backend */\n974:   // f3_gpaddr is valid
      iff gpf is detected\n975:   io.toBackend.gpaddrMem_wen := f3_toIbuffer_valid
      && Mux(\n976:     f3_req_is_mmio,\n977:     mmio_exception === ExceptionType.gpf,\n\
      978:     f3_exception.map(_ === ExceptionType.gpf).reduce(_ || _)\n979:   )\n\
      980:   io.toBackend.gpaddrMem_waddr        := f3_ftq_req.ftqIdx.value\n981:\
      \   io.toBackend.gpaddrMem_wdata.gpaddr := Mux(f3_req_is_mmio, mmio_resend_gpaddr,
      f3_gpaddr)\n982:   io.toBackend.gpaddrMem_wdata.isForVSnonLeafPTE := Mux(\n\
      983:     f3_req_is_mmio,\n984:     mmio_resend_isForVSnonLeafPTE,\n985:    \
      \ f3_isForVSnonLeafPTE\n986:   )\n987: \n988:   // Write back to Ftq"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 984-999
    context: "984:     mmio_resend_isForVSnonLeafPTE,\n985:     f3_isForVSnonLeafPTE\n\
      986:   )\n987: \n988:   // Write back to Ftq\n989:   val f3_cache_fetch    \
      \ = f3_valid && !(f2_fire && !f2_flush)\n990:   val finishFetchMaskReg = RegNext(f3_cache_fetch)\n\
      991: \n992:   val mmioFlushWb        = Wire(Valid(new PredecodeWritebackBundle))\n\
      993:   val f3_mmio_missOffset = Wire(ValidUndirectioned(UInt(log2Ceil(PredictWidth).W)))\n\
      994:   f3_mmio_missOffset.valid := f3_req_is_mmio\n995:   f3_mmio_missOffset.bits\
      \  := 0.U\n996: \n997:   // Send mmioFlushWb back to FTQ 1 cycle after uncache
      fetch return\n998:   // When backend redirect, mmio_state reset after 1 cycle.\n\
      999:   // In this case, mask .valid to avoid overriding backend redirect"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 995-1033
    context: "995:   f3_mmio_missOffset.bits  := 0.U\n996: \n997:   // Send mmioFlushWb
      back to FTQ 1 cycle after uncache fetch return\n998:   // When backend redirect,
      mmio_state reset after 1 cycle.\n999:   // In this case, mask .valid to avoid
      overriding backend redirect\n1000:   mmioFlushWb.valid := (f3_req_is_mmio &&
      mmio_state === m_waitCommit && RegNext(fromUncache.fire) &&\n1001:     f3_mmio_use_seq_pc
      && !f3_ftq_flush_self && !f3_ftq_flush_by_older)\n1002:   mmioFlushWb.bits.pc
      := f3_pc\n1003:   mmioFlushWb.bits.pd := f3_pd\n1004:   mmioFlushWb.bits.pd.zipWithIndex.map
      { case (instr, i) => instr.valid := f3_mmio_range(i) }\n1005:   mmioFlushWb.bits.ftqIdx\
      \     := f3_ftq_req.ftqIdx\n1006:   mmioFlushWb.bits.ftqOffset  := f3_ftq_req.ftqOffset.bits\n\
      1007:   mmioFlushWb.bits.misOffset  := f3_mmio_missOffset\n1008:   mmioFlushWb.bits.cfiOffset\
      \  := DontCare\n1009:   mmioFlushWb.bits.target     := Mux(mmio_is_RVC, f3_ftq_req.startAddr
      + 2.U, f3_ftq_req.startAddr + 4.U)\n1010:   mmioFlushWb.bits.jalTarget  := DontCare\n\
      1011:   mmioFlushWb.bits.instrRange := f3_mmio_range\n1012: \n1013:   val mmioRVCExpander
      = Module(new RVCExpander)\n1014:   mmioRVCExpander.io.in      := Mux(f3_req_is_mmio,
      Cat(f3_mmio_data(1), f3_mmio_data(0)), 0.U)\n1015:   mmioRVCExpander.io.fsIsOff
      := io.csr_fsIsOff\n1016: \n1017:   /** external predecode for MMIO instruction
      */\n1018:   when(f3_req_is_mmio) {\n1019:     val inst = Cat(f3_mmio_data(1),
      f3_mmio_data(0))\n1020: \n1021:     val brType :: isCall :: isRet :: Nil = brInfo(inst)\n\
      1022:     val jalOffset                        = jal_offset(inst, mmio_is_RVC)\n\
      1023:     val brOffset                         = br_offset(inst, mmio_is_RVC)\n\
      1024: \n1025:     io.toIbuffer.bits.instrs(0) := Mux(mmioRVCExpander.io.ill,
      mmioRVCExpander.io.in, mmioRVCExpander.io.out.bits)\n1026: \n1027:     io.toIbuffer.bits.pd(0).valid\
      \  := true.B\n1028:     io.toIbuffer.bits.pd(0).isRVC  := mmio_is_RVC\n1029:\
      \     io.toIbuffer.bits.pd(0).brType := brType\n1030:     io.toIbuffer.bits.pd(0).isCall
      := isCall\n1031:     io.toIbuffer.bits.pd(0).isRet  := isRet\n1032: \n1033:\
      \     io.toIbuffer.bits.exceptionType(0) := mmio_exception"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 1030-1046
    context: "1030:     io.toIbuffer.bits.pd(0).isCall := isCall\n1031:     io.toIbuffer.bits.pd(0).isRet\
      \  := isRet\n1032: \n1033:     io.toIbuffer.bits.exceptionType(0) := mmio_exception\n\
      1034:     // exception can happens in next page only when resend\n1035:    \
      \ io.toIbuffer.bits.crossPageIPFFix(0) := mmio_has_resend && ExceptionType.hasException(mmio_exception)\n\
      1036:     io.toIbuffer.bits.illegalInstr(0)    := mmioRVCExpander.io.ill\n1037:\
      \ \n1038:     io.toIbuffer.bits.enqEnable := f3_mmio_range.asUInt\n1039: \n\
      1040:     mmioFlushWb.bits.pd(0).valid  := true.B\n1041:     mmioFlushWb.bits.pd(0).isRVC\
      \  := mmio_is_RVC\n1042:     mmioFlushWb.bits.pd(0).brType := brType\n1043:\
      \     mmioFlushWb.bits.pd(0).isCall := isCall\n1044:     mmioFlushWb.bits.pd(0).isRet\
      \  := isRet\n1045:   }\n1046: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 1042-1054
    context: "1042:     mmioFlushWb.bits.pd(0).brType := brType\n1043:     mmioFlushWb.bits.pd(0).isCall
      := isCall\n1044:     mmioFlushWb.bits.pd(0).isRet  := isRet\n1045:   }\n1046:\
      \ \n1047:   mmio_redirect := (f3_req_is_mmio && mmio_state === m_waitCommit
      && RegNext(fromUncache.fire) && f3_mmio_use_seq_pc)\n1048: \n1049:   XSPerfAccumulate(\"\
      fetch_bubble_ibuffer_not_ready\", io.toIbuffer.valid && !io.toIbuffer.ready)\n\
      1050: \n1051:   /**\n1052:     ******************************************************************************\n\
      1053:     * IFU Write Back Stage\n1054:     * - write back predecode information
      to Ftq to update"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 1054-1064
    context: "1054:     * - write back predecode information to Ftq to update\n1055:\
      \     * - redirect if found fault prediction\n1056:     * - redirect if has
      false hit last half (last PC is not start + 32 Bytes, but in the midle of an
      notCFI RVI instruction)\n1057:     ******************************************************************************\n\
      1058:     */\n1059:   val wb_enable  = RegNext(f2_fire && !f2_flush) && !f3_req_is_mmio
      && !f3_flush\n1060:   val wb_valid   = RegNext(wb_enable, init = false.B)\n\
      1061:   val wb_ftq_req = RegEnable(f3_ftq_req, wb_enable)\n1062: \n1063:   val
      wb_check_result_stage1 = RegEnable(checkerOutStage1, wb_enable)\n1064:   val
      wb_check_result_stage2 = checkerOutStage2"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 1069-1086
    context: "1069:   val wb_pc_high_plus1   = RegEnable(f3_pc_high_plus1, wb_enable)\n\
      1070:   val wb_pc              = CatPC(wb_pc_lower_result, wb_pc_high, wb_pc_high_plus1)\n\
      1071: \n1072:   // val wb_pc             = RegEnable(f3_pc, wb_enable)\n1073:\
      \   val wb_pd          = RegEnable(f3_pd, wb_enable)\n1074:   val wb_instr_valid
      = RegEnable(f3_instr_valid, wb_enable)\n1075: \n1076:   /* false hit lastHalf
      */\n1077:   val wb_lastIdx        = RegEnable(f3_last_validIdx, wb_enable)\n\
      1078:   val wb_false_lastHalf = RegEnable(f3_false_lastHalf, wb_enable) && wb_lastIdx
      =/= (PredictWidth - 1).U\n1079:   val wb_false_target   = RegEnable(f3_false_snpc,
      wb_enable)\n1080: \n1081:   val wb_half_flush  = wb_false_lastHalf\n1082:  \
      \ val wb_half_target = wb_false_target\n1083: \n1084:   /* false oversize */\n\
      1085:   val lastIsRVC = wb_instr_range.asTypeOf(Vec(PredictWidth, Bool())).last
      && wb_pd.last.isRVC\n1086:   val lastIsRVI = wb_instr_range.asTypeOf(Vec(PredictWidth,
      Bool()))(PredictWidth - 2) && !wb_pd(PredictWidth - 2).isRVC"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 1084-1094
    context: "1084:   /* false oversize */\n1085:   val lastIsRVC = wb_instr_range.asTypeOf(Vec(PredictWidth,
      Bool())).last && wb_pd.last.isRVC\n1086:   val lastIsRVI = wb_instr_range.asTypeOf(Vec(PredictWidth,
      Bool()))(PredictWidth - 2) && !wb_pd(PredictWidth - 2).isRVC\n1087:   val lastTaken
      = wb_check_result_stage1.fixedTaken.last\n1088: \n1089:   f3_wb_not_flush :=
      wb_ftq_req.ftqIdx === f3_ftq_req.ftqIdx && f3_valid && wb_valid\n1090: \n1091:\
      \   /** if a req with a last half but miss predicted enters in wb stage, and
      this cycle f3 stalls,\n1092:     * we set a flag to notify f3 that the last
      half flag need not to be set.\n1093:     */\n1094:   // f3_fire is after wb_valid"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 1090-1111
    context: "1090: \n1091:   /** if a req with a last half but miss predicted enters
      in wb stage, and this cycle f3 stalls,\n1092:     * we set a flag to notify
      f3 that the last half flag need not to be set.\n1093:     */\n1094:   // f3_fire
      is after wb_valid\n1095:   when(wb_valid && RegNext(f3_hasLastHalf, init = false.B)\n\
      1096:     && wb_check_result_stage2.fixedMissPred(PredictWidth - 1) && !f3_fire
      && !RegNext(\n1097:       f3_fire,\n1098:       init = false.B\n1099:     )
      && !f3_flush) {\n1100:     f3_lastHalf_disable := true.B\n1101:   }\n1102: \n\
      1103:   // wb_valid and f3_fire are in same cycle\n1104:   when(wb_valid &&
      RegNext(f3_hasLastHalf, init = false.B)\n1105:     && wb_check_result_stage2.fixedMissPred(PredictWidth
      - 1) && f3_fire) {\n1106:     f3_lastHalf.valid := false.B\n1107:   }\n1108:\
      \ \n1109:   val checkFlushWb = Wire(Valid(new PredecodeWritebackBundle))\n1110:\
      \   val checkFlushWbjalTargetIdx = ParallelPriorityEncoder(VecInit(wb_pd.zip(wb_instr_valid).map
      { case (pd, v) =>\n1111:     v && pd.isJal"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 1115-1127
    context: "1115:   checkFlushWb.bits.pc := wb_pc\n1116:   checkFlushWb.bits.pd
      := wb_pd\n1117:   checkFlushWb.bits.pd.zipWithIndex.map { case (instr, i) =>
      instr.valid := wb_instr_valid(i) }\n1118:   checkFlushWb.bits.ftqIdx       \
      \   := wb_ftq_req.ftqIdx\n1119:   checkFlushWb.bits.ftqOffset       := wb_ftq_req.ftqOffset.bits\n\
      1120:   checkFlushWb.bits.misOffset.valid := ParallelOR(wb_check_result_stage2.fixedMissPred)
      || wb_half_flush\n1121:   checkFlushWb.bits.misOffset.bits := Mux(\n1122:  \
      \   wb_half_flush,\n1123:     wb_lastIdx,\n1124:     ParallelPriorityEncoder(wb_check_result_stage2.fixedMissPred)\n\
      1125:   )\n1126:   checkFlushWb.bits.cfiOffset.valid := ParallelOR(wb_check_result_stage1.fixedTaken)\n\
      1127:   checkFlushWb.bits.cfiOffset.bits  := ParallelPriorityEncoder(wb_check_result_stage1.fixedTaken)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 1124-1134
    context: "1124:     ParallelPriorityEncoder(wb_check_result_stage2.fixedMissPred)\n\
      1125:   )\n1126:   checkFlushWb.bits.cfiOffset.valid := ParallelOR(wb_check_result_stage1.fixedTaken)\n\
      1127:   checkFlushWb.bits.cfiOffset.bits  := ParallelPriorityEncoder(wb_check_result_stage1.fixedTaken)\n\
      1128:   checkFlushWb.bits.target := Mux(\n1129:     wb_half_flush,\n1130:  \
      \   wb_half_target,\n1131:     wb_check_result_stage2.fixedTarget(checkFlushWbTargetIdx)\n\
      1132:   )\n1133:   checkFlushWb.bits.jalTarget  := wb_check_result_stage2.jalTarget(checkFlushWbjalTargetIdx)\n\
      1134:   checkFlushWb.bits.instrRange := wb_instr_range.asTypeOf(Vec(PredictWidth,
      Bool()))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 1133-1143
    context: "1133:   checkFlushWb.bits.jalTarget  := wb_check_result_stage2.jalTarget(checkFlushWbjalTargetIdx)\n\
      1134:   checkFlushWb.bits.instrRange := wb_instr_range.asTypeOf(Vec(PredictWidth,
      Bool()))\n1135: \n1136:   toFtq.pdWb := Mux(wb_valid, checkFlushWb, mmioFlushWb)\n\
      1137: \n1138:   wb_redirect := checkFlushWb.bits.misOffset.valid && wb_valid\n\
      1139: \n1140:   /*write back flush type*/\n1141:   val checkFaultType    = wb_check_result_stage2.faultType\n\
      1142:   val checkJalFault     = wb_valid && checkFaultType.map(_.isjalFault).reduce(_
      || _)\n1143:   val checkJalrFault    = wb_valid && checkFaultType.map(_.isjalrFault).reduce(_
      || _)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 1162-1213
    context: "1162:     wb_ftq_req.ftqOffset.bits\n1163:   )\n1164: \n1165:   /**
      performance counter */\n1166:   val f3_perf_info = RegEnable(f2_perf_info, f2_fire)\n\
      1167:   val f3_req_0     = io.toIbuffer.fire\n1168:   val f3_req_1     = io.toIbuffer.fire
      && f3_doubleLine\n1169:   val f3_hit_0     = io.toIbuffer.fire && f3_perf_info.bank_hit(0)\n\
      1170:   val f3_hit_1     = io.toIbuffer.fire && f3_doubleLine & f3_perf_info.bank_hit(1)\n\
      1171:   val f3_hit       = f3_perf_info.hit\n1172:   val perfEvents = Seq(\n\
      1173:     (\"frontendFlush                \", wb_redirect),\n1174:     (\"ifu_req\
      \                      \", io.toIbuffer.fire),\n1175:     (\"ifu_miss      \
      \               \", io.toIbuffer.fire && !f3_perf_info.hit),\n1176:     (\"\
      ifu_req_cacheline_0          \", f3_req_0),\n1177:     (\"ifu_req_cacheline_1\
      \          \", f3_req_1),\n1178:     (\"ifu_req_cacheline_0_hit      \", f3_hit_1),\n\
      1179:     (\"ifu_req_cacheline_1_hit      \", f3_hit_1),\n1180:     (\"only_0_hit\
      \                   \", f3_perf_info.only_0_hit && io.toIbuffer.fire),\n1181:\
      \     (\"only_0_miss                  \", f3_perf_info.only_0_miss && io.toIbuffer.fire),\n\
      1182:     (\"hit_0_hit_1                  \", f3_perf_info.hit_0_hit_1 && io.toIbuffer.fire),\n\
      1183:     (\"hit_0_miss_1                 \", f3_perf_info.hit_0_miss_1 && io.toIbuffer.fire),\n\
      1184:     (\"miss_0_hit_1                 \", f3_perf_info.miss_0_hit_1 && io.toIbuffer.fire),\n\
      1185:     (\"miss_0_miss_1                \", f3_perf_info.miss_0_miss_1 &&
      io.toIbuffer.fire)\n1186:   )\n1187:   generatePerfEvent()\n1188: \n1189:  \
      \ XSPerfAccumulate(\"ifu_req\", io.toIbuffer.fire)\n1190:   XSPerfAccumulate(\"\
      ifu_miss\", io.toIbuffer.fire && !f3_hit)\n1191:   XSPerfAccumulate(\"ifu_req_cacheline_0\"\
      , f3_req_0)\n1192:   XSPerfAccumulate(\"ifu_req_cacheline_1\", f3_req_1)\n1193:\
      \   XSPerfAccumulate(\"ifu_req_cacheline_0_hit\", f3_hit_0)\n1194:   XSPerfAccumulate(\"\
      ifu_req_cacheline_1_hit\", f3_hit_1)\n1195:   XSPerfAccumulate(\"frontendFlush\"\
      , wb_redirect)\n1196:   XSPerfAccumulate(\"only_0_hit\", f3_perf_info.only_0_hit
      && io.toIbuffer.fire)\n1197:   XSPerfAccumulate(\"only_0_miss\", f3_perf_info.only_0_miss
      && io.toIbuffer.fire)\n1198:   XSPerfAccumulate(\"hit_0_hit_1\", f3_perf_info.hit_0_hit_1
      && io.toIbuffer.fire)\n1199:   XSPerfAccumulate(\"hit_0_miss_1\", f3_perf_info.hit_0_miss_1
      && io.toIbuffer.fire)\n1200:   XSPerfAccumulate(\"miss_0_hit_1\", f3_perf_info.miss_0_hit_1
      && io.toIbuffer.fire)\n1201:   XSPerfAccumulate(\"miss_0_miss_1\", f3_perf_info.miss_0_miss_1
      && io.toIbuffer.fire)\n1202:   XSPerfAccumulate(\"hit_0_except_1\", f3_perf_info.hit_0_except_1
      && io.toIbuffer.fire)\n1203:   XSPerfAccumulate(\"miss_0_except_1\", f3_perf_info.miss_0_except_1
      && io.toIbuffer.fire)\n1204:   XSPerfAccumulate(\"except_0\", f3_perf_info.except_0
      && io.toIbuffer.fire)\n1205:   XSPerfHistogram(\n1206:     \"ifu2ibuffer_validCnt\"\
      ,\n1207:     PopCount(io.toIbuffer.bits.valid & io.toIbuffer.bits.enqEnable),\n\
      1208:     io.toIbuffer.fire,\n1209:     0,\n1210:     PredictWidth + 1,\n1211:\
      \     1\n1212:   )\n1213: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 1218-1234
    context: "1218:   val ifuWbToFtqTable            = ChiselDB.createTable(s\"IfuWbToFtq$hartId\"\
      , new IfuWbToFtqDB)\n1219: \n1220:   val fetchIBufferDumpData = Wire(new FetchToIBufferDB)\n\
      1221:   fetchIBufferDumpData.start_addr  := f3_ftq_req.startAddr\n1222:   fetchIBufferDumpData.instr_count
      := PopCount(io.toIbuffer.bits.enqEnable)\n1223:   fetchIBufferDumpData.exception
      := (f3_perf_info.except_0 && io.toIbuffer.fire) || (f3_perf_info.hit_0_except_1
      && io.toIbuffer.fire) || (f3_perf_info.miss_0_except_1 && io.toIbuffer.fire)\n\
      1224:   fetchIBufferDumpData.is_cache_hit := f3_hit\n1225: \n1226:   val ifuWbToFtqDumpData
      = Wire(new IfuWbToFtqDB)\n1227:   ifuWbToFtqDumpData.start_addr        := wb_ftq_req.startAddr\n\
      1228:   ifuWbToFtqDumpData.is_miss_pred      := checkFlushWb.bits.misOffset.valid\n\
      1229:   ifuWbToFtqDumpData.miss_pred_offset  := checkFlushWb.bits.misOffset.bits\n\
      1230:   ifuWbToFtqDumpData.checkJalFault     := checkJalFault\n1231:   ifuWbToFtqDumpData.checkJalrFault\
      \    := checkJalrFault\n1232:   ifuWbToFtqDumpData.checkRetFault     := checkRetFault\n\
      1233:   ifuWbToFtqDumpData.checkTargetFault  := checkTargetFault\n1234:   ifuWbToFtqDumpData.checkNotCFIFault\
      \  := checkNotCFIFault"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 1234-1244
    context: "1234:   ifuWbToFtqDumpData.checkNotCFIFault  := checkNotCFIFault\n1235:\
      \   ifuWbToFtqDumpData.checkInvalidTaken := checkInvalidTaken\n1236: \n1237:\
      \   fetchToIBufferTable.log(\n1238:     data = fetchIBufferDumpData,\n1239:\
      \     en = isWriteFetchToIBufferTable.orR && io.toIbuffer.fire,\n1240:     site
      = \"IFU\" + p(XSCoreParamsKey).HartId.toString,\n1241:     clock = clock,\n\
      1242:     reset = reset\n1243:   )\n1244:   ifuWbToFtqTable.log("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/PreDecode.scala
    lines: 82-92
    context: "82:   def notCFI = brType === BrType.notCFI\n83: }\n84: \n85: class
      PreDecodeResp(implicit p: Parameters) extends XSBundle with HasPdConst {\n86:\
      \   val pd           = Vec(PredictWidth, new PreDecodeInfo)\n87:   val hasHalfValid
      = Vec(PredictWidth, Bool())\n88:   // val expInstr = Vec(PredictWidth, UInt(32.W))\n\
      89:   val instr      = Vec(PredictWidth, UInt(32.W))\n90:   val jumpOffset =
      Vec(PredictWidth, UInt(XLEN.W))\n91: //  val hasLastHalf = Bool()\n92:   val
      triggered = Vec(PredictWidth, TriggerAction())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/PreDecode.scala
    lines: 136-146
    context: "136: \n137:     val brType :: isCall :: isRet :: Nil = brInfo(inst)\n\
      138:     val jalOffset                        = jal_offset(inst, currentIsRVC(i))\n\
      139:     val brOffset                         = br_offset(inst, currentIsRVC(i))\n\
      140: \n141:     io.out.hasHalfValid(i) := h_validStart(i)\n142: \n143:     io.out.triggered(i)
      := DontCare // VecInit(Seq.fill(10)(false.B))\n144: \n145:     io.out.pd(i).valid
      := validStart(i)\n146:     io.out.pd(i).isRVC := currentIsRVC(i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/PreDecode.scala
    lines: 155-186
    context: "155:     io.out.jumpOffset(i) := Mux(io.out.pd(i).isBr, brOffset, jalOffset)\n\
      156:   }\n157: \n158:   // the first half is always reliable\n159:   for (i
      <- 0 until PredictWidth / 2) {\n160:     val lastIsValidEnd = if (i == 0) {
      true.B }\n161:     else { validEnd(i - 1) || !HasCExtension.B }\n162:     validStart(i)
      := (lastIsValidEnd || !HasCExtension.B)\n163:     validEnd(i)   := validStart(i)
      && currentIsRVC(i) || !validStart(i) || !HasCExtension.B\n164: \n165:     //
      prepared for last half match\n166:     val h_lastIsValidEnd = if (i == 0) {
      false.B }\n167:     else { h_validEnd(i - 1) || !HasCExtension.B }\n168:   \
      \  h_validStart(i) := (h_lastIsValidEnd || !HasCExtension.B)\n169:     h_validEnd(i)\
      \   := h_validStart(i) && currentIsRVC(i) || !h_validStart(i) || !HasCExtension.B\n\
      170:   }\n171: \n172:   for (i <- 0 until PredictWidth) {\n173:     val lastIsValidEnd
      = if (i == 0) { true.B }\n174:     else { validEnd_diff(i - 1) || !HasCExtension.B
      }\n175:     validStart_diff(i) := (lastIsValidEnd || !HasCExtension.B)\n176:\
      \     validEnd_diff(i)   := validStart_diff(i) && currentIsRVC(i) || !validStart_diff(i)
      || !HasCExtension.B\n177: \n178:     // prepared for last half match\n179: \
      \    val h_lastIsValidEnd = if (i == 0) { false.B }\n180:     else { h_validEnd_diff(i
      - 1) || !HasCExtension.B }\n181:     h_validStart_diff(i) := (h_lastIsValidEnd
      || !HasCExtension.B)\n182:     h_validEnd_diff(i)   := h_validStart_diff(i)
      && currentIsRVC(i) || !h_validStart_diff(i) || !HasCExtension.B\n183:   }\n\
      184: \n185:   // assume PredictWidth / 2 is a valid start\n186:   for (i <-
      PredictWidth / 2 until PredictWidth) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/PreDecode.scala
    lines: 182-200
    context: "182:     h_validEnd_diff(i)   := h_validStart_diff(i) && currentIsRVC(i)
      || !h_validStart_diff(i) || !HasCExtension.B\n183:   }\n184: \n185:   // assume
      PredictWidth / 2 is a valid start\n186:   for (i <- PredictWidth / 2 until PredictWidth)
      {\n187:     val lastIsValidEnd = if (i == PredictWidth / 2) { true.B }\n188:\
      \     else { validEnd_half(i - 1) || !HasCExtension.B }\n189:     validStart_half(i)
      := (lastIsValidEnd || !HasCExtension.B)\n190:     validEnd_half(i)   := validStart_half(i)
      && currentIsRVC(i) || !validStart_half(i) || !HasCExtension.B\n191: \n192: \
      \    // prepared for last half match\n193:     val h_lastIsValidEnd = if (i
      == PredictWidth / 2) { true.B }\n194:     else { h_validEnd_half(i - 1) || !HasCExtension.B
      }\n195:     h_validStart_half(i) := (h_lastIsValidEnd || !HasCExtension.B)\n\
      196:     h_validEnd_half(i)   := h_validStart_half(i) && currentIsRVC(i) ||
      !h_validStart_half(i) || !HasCExtension.B\n197:   }\n198: \n199:   // assume
      PredictWidth / 2 + 1 is a valid start (and PredictWidth / 2 is last half of
      RVI)\n200:   for (i <- PredictWidth / 2 + 1 until PredictWidth) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/PreDecode.scala
    lines: 196-214
    context: "196:     h_validEnd_half(i)   := h_validStart_half(i) && currentIsRVC(i)
      || !h_validStart_half(i) || !HasCExtension.B\n197:   }\n198: \n199:   // assume
      PredictWidth / 2 + 1 is a valid start (and PredictWidth / 2 is last half of
      RVI)\n200:   for (i <- PredictWidth / 2 + 1 until PredictWidth) {\n201:    \
      \ val lastIsValidEnd = if (i == PredictWidth / 2 + 1) { true.B }\n202:     else
      { validEnd_halfPlus1(i - 1) || !HasCExtension.B }\n203:     validStart_halfPlus1(i)
      := (lastIsValidEnd || !HasCExtension.B)\n204:     validEnd_halfPlus1(i) := validStart_halfPlus1(i)
      && currentIsRVC(i) || !validStart_halfPlus1(i) || !HasCExtension.B\n205: \n\
      206:     // prepared for last half match\n207:     val h_lastIsValidEnd = if
      (i == PredictWidth / 2 + 1) { true.B }\n208:     else { h_validEnd_halfPlus1(i
      - 1) || !HasCExtension.B }\n209:     h_validStart_halfPlus1(i) := (h_lastIsValidEnd
      || !HasCExtension.B)\n210:     h_validEnd_halfPlus1(i) := h_validStart_halfPlus1(i)
      && currentIsRVC(i) || !h_validStart_halfPlus1(\n211:       i\n212:     ) ||
      !HasCExtension.B\n213:   }\n214:   validStart_halfPlus1(PredictWidth / 2) :=
      false.B // could be true but when true we select half, not halfPlus1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/PreDecode.scala
    lines: 419-429
    context: "419:     fixedRangeNext(i) && instrValidNext(\n420:       i\n421:  \
      \   ) && (pd.isJal || pd.isBr) && takenIdxNext === i.U && predTakenNext && (predTargetNext
      =/= jumpTargetsNext(i))\n422:   })\n423: \n424:   io.out.stage2Out.faultType.zipWithIndex.foreach
      { case (faultType, i) =>\n425:     faultType.value := MuxCase(\n426:       FaultType.noFault,\n\
      427:       Seq(\n428:         jalFaultVecNext(i)  -> FaultType.jalFault,\n429:\
      \         jalrFaultVecNext(i) -> FaultType.jalrFault,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/PreDecode.scala
    lines: 433-450
    context: "433:         invalidTakenNext(i) -> FaultType.invalidTaken\n434:   \
      \    )\n435:     )\n436:   }\n437: \n438:   io.out.stage2Out.fixedMissPred.zipWithIndex.foreach
      { case (missPred, i) =>\n439:     missPred := jalFaultVecNext(i) || jalrFaultVecNext(i)
      || retFaultVecNext(i) || notCFITakenNext(i) ||\n440:       invalidTakenNext(i)
      || targetFault(i)\n441:   }\n442:   io.out.stage2Out.fixedTarget.zipWithIndex.foreach
      { case (target, i) =>\n443:     target := Mux(jalFaultVecNext(i) || targetFault(i),
      jumpTargetsNext(i), seqTargetsNext(i))\n444:   }\n445:   io.out.stage2Out.jalTarget.zipWithIndex.foreach
      { case (target, i) => target := jumpTargetsNext(i) }\n446: \n447: }\n448: \n\
      449: class FrontendTrigger(implicit p: Parameters) extends XSModule with SdtrigExt
      {\n450:   val io = IO(new Bundle() {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/L2Top.scala
    lines: 65-75
    context: "65: {\n66:   override def shouldBeInlined: Boolean = true\n67: \n68:\
      \   def chainBuffer(depth: Int, n: String): (Seq[LazyModule], TLNode) = {\n\
      69:     val buffers = Seq.fill(depth){ LazyModule(new TLBuffer()) }\n70:   \
      \  buffers.zipWithIndex.foreach{ case (b, i) => {\n71:       b.suggestName(s\"\
      ${n}_${i}\")\n72:     }}\n73:     val node = buffers.map(_.node.asInstanceOf[TLNode]).reduce(_
      :*=* _)\n74:     (buffers, node)\n75:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/L2Top.scala
    lines: 75-85
    context: "75:   }\n76:   val enableL2 = coreParams.L2CacheParamsOpt.isDefined\n\
      77:   // =========== Components ============\n78:   val l1_xbar = TLXbar()\n\
      79:   val mmio_xbar = TLXbar()\n80:   val mmio_port = TLIdentityNode() // to
      L3\n81:   val memory_port = if (enableCHI && enableL2) None else Some(TLIdentityNode())\n\
      82:   val beu = LazyModule(new BusErrorUnit(\n83:     new XSL1BusErrors(),\n\
      84:     BusErrorUnitParams(soc.BEURange.base, soc.BEURange.mask.toInt + 1)\n\
      85:   ))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/L2Top.scala
    lines: 136-146
    context: "136:       l2 match {\n137:         case l2: TL2TLCoupledL2 =>\n138:\
      \           memory_port.get := l2_l3_pmu := TLClientsMerger() := TLXbar() :=*
      l2_binder.get\n139:         case l2: TL2CHICoupledL2 =>\n140:           l2.managerNode
      := TLXbar() :=* l2_binder.get\n141:           l2.mmioNode := mmio_port\n142:\
      \       }\n143:     case None =>\n144:       memory_port.get := l1_xbar\n145:\
      \   }\n146: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/L2Top.scala
    lines: 155-167
    context: "155:   }\n156: \n157:   // filter out in-core addresses before sent
      to mmio_port\n158:   // Option[AddressSet] ++ Option[AddressSet] => List[AddressSet]\n\
      159:   private def cacheAddressSet: Seq[AddressSet] = (icacheParameters.cacheCtrlAddressOpt
      ++ dcacheParameters.cacheCtrlAddressOpt).toSeq\n160:   private def mmioFilters
      = if(SeperateTLBus) (SeperateTLBusRanges ++ cacheAddressSet) else cacheAddressSet\n\
      161:   mmio_port :=\n162:     TLFilter(TLFilter.mSubtract(mmioFilters)) :=\n\
      163:     TLBuffer() :=\n164:     mmio_xbar\n165: \n166:   class Imp(wrapper:
      LazyModule) extends LazyModuleImp(wrapper) {\n167:     val io = IO(new Bundle
      {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/L2Top.scala
    lines: 197-207
    context: "197:       val traceCoreInterface = new Bundle{\n198:         val fromCore
      = Flipped(new TraceCoreInterface)\n199:         val toTile   = new TraceCoreInterface\n\
      200:       }\n201:       val debugTopDown = new Bundle() {\n202:         val
      robTrueCommit = Input(UInt(64.W))\n203:         val robHeadPaddr = Flipped(Valid(UInt(36.W)))\n\
      204:         val l2MissMatch = Output(Bool())\n205:       }\n206:       val
      l2Miss = Output(Bool())\n207:       val l3Miss = new Bundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/L2Top.scala
    lines: 217-228
    context: "217:       val pfCtrlFromCore = Input(new PrefetchCtrlFromCore)\n218:\
      \       val l2_tlb_req = new TlbRequestIO(nRespDups = 2)\n219:       val l2_pmp_resp
      = Flipped(new PMPRespBundle)\n220:       val l2_hint = ValidIO(new L2ToL1Hint())\n\
      221:       val perfEvents = Output(Vec(numPCntHc * coreParams.L2NBanks + 1,
      new PerfEvent))\n222:       val l2_flush_en = Option.when(EnablePowerDown) (Input(Bool()))\n\
      223:       val l2_flush_done = Option.when(EnablePowerDown) (Output(Bool()))\n\
      224:       val dft = Option.when(hasDFT)(Input(new SramBroadcastBundle))\n225:\
      \       val dft_reset = Option.when(hasMbist)(Input(new DFTResetSignals()))\n\
      226:       val dft_out = Option.when(hasDFT)(Output(new SramBroadcastBundle))\n\
      227:       val dft_reset_out = Option.when(hasMbist)(Output(new DFTResetSignals()))\n\
      228:       // val reset_core = IO(Output(Reset()))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/L2Top.scala
    lines: 225-236
    context: "225:       val dft_reset = Option.when(hasMbist)(Input(new DFTResetSignals()))\n\
      226:       val dft_out = Option.when(hasDFT)(Output(new SramBroadcastBundle))\n\
      227:       val dft_reset_out = Option.when(hasMbist)(Output(new DFTResetSignals()))\n\
      228:       // val reset_core = IO(Output(Reset()))\n229:     })\n230:     io.dft_out.zip(io.dft).foreach({
      case(a, b) => a := b })\n231:     io.dft_reset_out.zip(io.dft_reset).foreach({
      case(a, b) => a := b })\n232: \n233:     val resetDelayN = Module(new DelayN(UInt(PAddrBits.W),
      5))\n234: \n235:     val (beu_int_out, _) = beu_local_int_source.out(0)\n236:\
      \     beu_int_out(0) := beu.module.io.interrupt"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/L2Top.scala
    lines: 257-269
    context: "257:     )\n258:     traceToTile.toEncoder.priv := RegEnable(\n259:\
      \       traceFromCore.toEncoder.priv,\n260:       traceFromCore.toEncoder.groups(0).valid\n\
      261:     )\n262:     (0 until TraceGroupNum).foreach{ i =>\n263:       traceToTile.toEncoder.groups(i).valid
      := RegNext(traceFromCore.toEncoder.groups(i).valid)\n264:       traceToTile.toEncoder.groups(i).bits.iretire
      := RegNext(traceFromCore.toEncoder.groups(i).bits.iretire)\n265:       traceToTile.toEncoder.groups(i).bits.itype
      := RegNext(traceFromCore.toEncoder.groups(i).bits.itype)\n266:       traceToTile.toEncoder.groups(i).bits.ilastsize
      := RegEnable(\n267:         traceFromCore.toEncoder.groups(i).bits.ilastsize,\n\
      268:         traceFromCore.toEncoder.groups(i).valid\n269:       )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/L2Top.scala
    lines: 284-309
    context: "284: \n285:     if (l2cache.isDefined) {\n286:       val l2 = l2cache.get.module\n\
      287: \n288:       l2.io.pfCtrlFromCore := io.pfCtrlFromCore\n289:       l2.io.dft.zip(io.dft).foreach({
      case(a, b) => a := b })\n290:       l2.io.dft_reset.zip(io.dft_reset).foreach({
      case(a, b) => a := b })\n291:       io.l2_hint := l2.io.l2_hint\n292:      \
      \ l2.io.debugTopDown.robHeadPaddr := DontCare\n293:       l2.io.hartId := io.hartId.fromTile\n\
      294:       l2.io.debugTopDown.robHeadPaddr := io.debugTopDown.robHeadPaddr\n\
      295:       l2.io.debugTopDown.robTrueCommit := io.debugTopDown.robTrueCommit\n\
      296:       io.debugTopDown.l2MissMatch := l2.io.debugTopDown.l2MissMatch\n297:\
      \       io.l2Miss := l2.io.l2Miss\n298:       io.l2_flush_done.foreach { _ :=
      l2.io.l2FlushDone.getOrElse(false.B) }\n299:       l2.io.l2Flush.foreach { _
      := io.l2_flush_en.getOrElse(false.B) }\n300: \n301:       /* l2 tlb */\n302:\
      \       io.l2_tlb_req.req.bits := DontCare\n303:       io.l2_tlb_req.req.valid
      := l2.io.l2_tlb_req.req.valid\n304:       io.l2_tlb_req.resp.ready := l2.io.l2_tlb_req.resp.ready\n\
      305:       io.l2_tlb_req.req.bits.vaddr := l2.io.l2_tlb_req.req.bits.vaddr\n\
      306:       io.l2_tlb_req.req.bits.cmd := l2.io.l2_tlb_req.req.bits.cmd\n307:\
      \       io.l2_tlb_req.req.bits.size := l2.io.l2_tlb_req.req.bits.size\n308:\
      \       io.l2_tlb_req.req.bits.kill := l2.io.l2_tlb_req.req.bits.kill\n309:\
      \       io.l2_tlb_req.req.bits.no_translate := l2.io.l2_tlb_req.req.bits.no_translate"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/L2Top.scala
    lines: 316-336
    context: "316:           println(\"L2 Cache perfEvents Set\", name, inc, i)\n\
      317:         }\n318:       }\n319: \n320:       l2.io.l2_tlb_req.resp.valid
      := io.l2_tlb_req.resp.valid\n321:       l2.io.l2_tlb_req.req.ready := io.l2_tlb_req.req.ready\n\
      322:       l2.io.l2_tlb_req.resp.bits.paddr.head := io.l2_tlb_req.resp.bits.paddr.head\n\
      323:       l2.io.l2_tlb_req.resp.bits.pbmt := io.l2_tlb_req.resp.bits.pbmt.head\n\
      324:       l2.io.l2_tlb_req.resp.bits.miss := io.l2_tlb_req.resp.bits.miss\n\
      325:       l2.io.l2_tlb_req.resp.bits.excp.head.gpf := io.l2_tlb_req.resp.bits.excp.head.gpf\n\
      326:       l2.io.l2_tlb_req.resp.bits.excp.head.pf := io.l2_tlb_req.resp.bits.excp.head.pf\n\
      327:       l2.io.l2_tlb_req.resp.bits.excp.head.af := io.l2_tlb_req.resp.bits.excp.head.af\n\
      328:       l2.io.l2_tlb_req.pmp_resp.ld := io.l2_pmp_resp.ld\n329:       l2.io.l2_tlb_req.pmp_resp.st
      := io.l2_pmp_resp.st\n330:       l2.io.l2_tlb_req.pmp_resp.instr := io.l2_pmp_resp.instr\n\
      331:       l2.io.l2_tlb_req.pmp_resp.mmio := io.l2_pmp_resp.mmio\n332:     \
      \  l2.io.l2_tlb_req.pmp_resp.atomic := io.l2_pmp_resp.atomic\n333:       l2cache.get
      match {\n334:         case l2cache: TL2CHICoupledL2 =>\n335:           val l2
      = l2cache.module\n336:           l2.io_nodeID := io.nodeID.get"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/L2Top.scala
    lines: 333-343
    context: "333:       l2cache.get match {\n334:         case l2cache: TL2CHICoupledL2
      =>\n335:           val l2 = l2cache.module\n336:           l2.io_nodeID := io.nodeID.get\n\
      337:           io.chi.get <> l2.io_chi\n338:           l2.io_cpu_halt.foreach
      { _:= io.cpu_halt.fromCore }\n339:         case l2cache: TL2TLCoupledL2 =>\n\
      340:       }\n341: \n342:       beu.module.io.errors.l2.ecc_error.valid := l2.io.error.valid\n\
      343:       beu.module.io.errors.l2.ecc_error.bits := l2.io.error.address"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/L2Top.scala
    lines: 347-357
    context: "347:       io.l2Miss := false.B\n348: \n349:       io.l2_tlb_req.req.valid
      := false.B\n350:       io.l2_tlb_req.req.bits := DontCare\n351:       io.l2_tlb_req.req_kill
      := DontCare\n352:       io.l2_tlb_req.resp.ready := true.B\n353:       io.perfEvents
      := DontCare\n354: \n355:       beu.module.io.errors.l2 := 0.U.asTypeOf(beu.module.io.errors.l2)\n\
      356:     }\n357:   }"
- sv_file: /code/XiangShan/build/rtl/CommitIDModule.sv
  diff_snippet: "--- a//code/XiangShan/build/rtl/CommitIDModule.sv\n+++ b//code/XiangShan/build/rtl/CommitIDModule.sv\n\
    @@ -91,7 +91,7 @@..."
  search_terms:
  - dirty
  - commitID
  chisel_hints:
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1099-1116
    context: "1099:     val l0vmidhit = VecInit(l0vmids.flatMap(_.map(_ === l0hashVmid))).asUInt\n\
      1100:     val l1vmidhit = VecInit(l1vmids.flatMap(_.map(_ === l1hashVmid))).asUInt\n\
      1101:     val l2vmidhit = VecInit(l2vmids.map(_.getOrElse(0.U) === io.csr_dup(2).hgatp.vmid)).asUInt\n\
      1102:     val spvmidhit = VecInit(spvmids.map(_.getOrElse(0.U) === io.csr_dup(0).hgatp.vmid)).asUInt\n\
      1103: \n1104:     val l0hhit = VecInit(l0h.flatMap(_.map{a => io.csr_dup(0).priv.virt
      && a === onlyStage1 || !io.csr_dup(0).priv.virt && a === noS2xlate})).asUInt\n\
      1105:     val l1hhit = VecInit(l1h.flatMap(_.map{a => io.csr_dup(1).priv.virt
      && a === onlyStage1 || !io.csr_dup(1).priv.virt && a === noS2xlate})).asUInt\n\
      1106:     val l2hhit = VecInit(l2h.map{a => io.csr_dup(2).priv.virt && a ===
      onlyStage1 || !io.csr_dup(2).priv.virt && a === noS2xlate}).asUInt\n1107:  \
      \   val sphhit = VecInit(sph.map{a => io.csr_dup(0).priv.virt && a === onlyStage1
      || !io.csr_dup(0).priv.virt && a === noS2xlate}).asUInt\n1108:     val l0virthit
      = l0hhit & VecInit(l0vmidhit.asBools.map{a => io.csr_dup(0).priv.virt && a ||
      !io.csr_dup(0).priv.virt}).asUInt\n1109:     val l1virthit = l1hhit & VecInit(l1vmidhit.asBools.map{a
      => io.csr_dup(1).priv.virt && a || !io.csr_dup(1).priv.virt}).asUInt\n1110:\
      \     val l2virthit = l2hhit & VecInit(l2vmidhit.asBools.map{a => io.csr_dup(2).priv.virt
      && a || !io.csr_dup(2).priv.virt}).asUInt\n1111:     val spvirthit = sphhit
      & VecInit(spvmidhit.asBools.map{a => io.csr_dup(0).priv.virt && a || !io.csr_dup(0).priv.virt}).asUInt\n\
      1112: \n1113:     val sfence_vpn = sfence_dup(0).bits.addr(sfence_dup(0).bits.addr.getWidth-1,
      offLen)\n1114:     val l0hashVpn = XORFold(sfence_vpn(vpnLen - 1, vpnLen - PtwL0TagLen),
      l2tlbParams.hashVpnWidth)\n1115:     val l0vpnhit = VecInit(l0vpns.flatMap(_.map(_
      === l0hashVpn))).asUInt\n1116:     val l0flushSetIdx = UIntToOH(genPtwL0SetIdx(sfence_vpn))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1132-1146
    context: "1132:       }\n1133:     } .otherwise {\n1134:       when (sfence_dup(0).bits.rs2)
      {\n1135:         // specific leaf of addr && all asid\n1136:         l0v :=
      l0v & ~(l0virthit & l0vpnhit & l0flushMask)\n1137:         spv := spv & ~(sphhit
      & VecInit(sp.map(_.hit(sfence_vpn, sfence_dup(0).bits.id, sfence_dup(0).bits.id,
      io.csr_dup(0).hgatp.vmid, allType = true, ignoreID = true.B, sfence = Mux(io.csr_dup(0).priv.virt,
      isVSfence, isSfence)))).asUInt)\n1138:       } .otherwise {\n1139:         //
      specific leaf of addr && specific asid\n1140:         l0v := l0v & ~(l0virthit
      & ~l0g & l0asidhit & l0vpnhit & l0flushMask)\n1141:         spv := spv & ~(~spg
      & sphhit & VecInit(sp.map(_.hit(sfence_vpn, sfence_dup(0).bits.id, sfence_dup(0).bits.id,
      io.csr_dup(0).hgatp.vmid, allType = true, sfence = Mux(io.csr_dup(0).priv.virt,
      isVSfence, isSfence)))).asUInt)\n1142:       }\n1143:     }\n1144:   }\n1145:\
      \ \n1146:   val hfencev_valid = sfence_dup(0).valid && sfence_dup(0).bits.hv"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1231-1245
    context: "1231:   }\n1232: \n1233:   if (EnableSv48) {\n1234:     val l3asidhit
      = VecInit(l3asids.get.map(_ === sfence_dup(2).bits.id)).asUInt\n1235:     val
      l3vmidhit = VecInit(l3vmids.get.map(_.getOrElse(0.U) === io.csr_dup(2).hgatp.vmid)).asUInt\n\
      1236:     val l3hhit = VecInit(l3h.get.map{a => io.csr_dup(2).priv.virt && a
      === onlyStage1 || !io.csr_dup(2).priv.virt && a === noS2xlate}).asUInt\n1237:\
      \ \n1238:     when (sfence_valid) {\n1239:       val l3vmidhit = VecInit(l3vmids.get.map(_.getOrElse(0.U)
      === io.csr_dup(2).hgatp.vmid)).asUInt\n1240:       val l3hhit = VecInit(l3h.get.map{a
      => io.csr_dup(2).priv.virt && a === onlyStage1 || !io.csr_dup(2).priv.virt &&
      a === noS2xlate}).asUInt\n1241:       val sfence_vpn = sfence_dup(2).bits.addr(sfence_dup(2).bits.addr.getWidth-1,
      offLen)\n1242: \n1243:       when (sfence_dup(2).bits.rs1/*va*/) {\n1244:  \
      \       when (sfence_dup(2).bits.rs2) {\n1245:           // all va && all asid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableCache.scala
    lines: 1241-1254
    context: "1241:       val sfence_vpn = sfence_dup(2).bits.addr(sfence_dup(2).bits.addr.getWidth-1,
      offLen)\n1242: \n1243:       when (sfence_dup(2).bits.rs1/*va*/) {\n1244:  \
      \       when (sfence_dup(2).bits.rs2) {\n1245:           // all va && all asid\n\
      1246:           l3v.map(_ := l3v.get & ~(l3hhit & VecInit(l3vmidhit.asBools.map{a
      => io.csr_dup(2).priv.virt && a || !io.csr_dup(2).priv.virt}).asUInt))\n1247:\
      \         } .otherwise {\n1248:           // all va && specific asid except
      global\n1249:           l3v.map(_ := l3v.get & ~(~l3g.get & l3hhit & l3asidhit
      & VecInit(l3vmidhit.asBools.map{a => io.csr_dup(2).priv.virt && a || !io.csr_dup(2).priv.virt}).asUInt))\n\
      1250:         }\n1251:       }\n1252:     }\n1253: \n1254:     when (hfencev_valid)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TlbPrefetch.scala
    lines: 46-58
    context: "46:   val next_req = RegEnable(next_line, io.in.valid)\n47:   val input_valid
      = io.in.valid && !flush && !already_have(next_line)\n48:   val v = ValidHold(input_valid,
      io.out.fire, flush)\n49:   val s2xlate = Wire(UInt(2.W))\n50:   s2xlate := MuxCase(noS2xlate,
      Seq(\n51:     (io.csr.priv.virt && io.csr.vsatp.mode =/= 0.U && io.csr.hgatp.mode
      =/= 0.U) -> allStage,\n52:     (io.csr.priv.virt && io.csr.vsatp.mode =/= 0.U)
      -> onlyStage1,\n53:     (io.csr.priv.virt && io.csr.hgatp.mode =/= 0.U) -> onlyStage2\n\
      54:   ))\n55:   io.out.valid := v\n56:   io.out.bits.req_info.vpn := next_req\n\
      57:   io.out.bits.req_info.s2xlate := s2xlate\n58:   io.out.bits.req_info.source
      := prefetchID.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/MMUBundle.scala
    lines: 656-666
    context: "656: class TlbIO(Width: Int, nRespDups: Int = 1, q: TLBParameters)(implicit
      p: Parameters) extends\n657:   MMUIOBaseBundle {\n658:   val hartId = Input(UInt(hartIdLen.W))\n\
      659:   val requestor = Vec(Width, Flipped(new TlbRequestIO(nRespDups)))\n660:\
      \   val flushPipe = Vec(Width, Input(Bool()))\n661:   val redirect = Flipped(ValidIO(new
      Redirect)) // flush the signal need_gpa in tlb\n662:   val ptw = new TlbPtwIOwithMemIdx(Width)\n\
      663:   val refill_to_mem = Output(new TlbRefilltoMemIO())\n664:   val replace
      = if (q.outReplace) Flipped(new TlbReplaceIO(Width, q)) else null\n665:   val
      pmp = Vec(Width, ValidIO(new PMPReqBundle(q.lgMaxSize)))\n666:   val tlbreplay
      = Vec(Width, Output(Bool()))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/L2TLB.scala
    lines: 252-262
    context: "252: \n253:   val mq_arb = Module(new Arbiter(new L2TlbWithHptwIdBundle,
      2))\n254:   mq_arb.io.in(0).valid := cache.io.resp.valid && !cache.io.resp.bits.hit
      &&\n255:     !from_pre(cache.io.resp.bits.req_info.source) && !cache.io.resp.bits.isHptwReq
      && // hptw reqs are not sent to missqueue\n256:     (cache.io.resp.bits.bypassed
      || (\n257:       (((!cache.io.resp.bits.toFsm.l1Hit && !toFsm_toLLPTW) || cache.io.resp.bits.toFsm.stage1Hit)
      && !cache.io.resp.bits.isHptwReq && (cache.io.resp.bits.isFirst || !ptw.io.req.ready))
      // send to ptw, is first or ptw is busy;\n258:       || ((cache.io.resp.bits.toFsm.l1Hit
      || toFsm_toLLPTW) && !llptw.io.in.ready) // send to llptw, llptw is full\n259:\
      \     ))\n260: \n261:   mq_arb.io.in(0).bits.req_info :=  cache.io.resp.bits.req_info\n\
      262:   mq_arb.io.in(0).bits.isHptwReq := false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 68-78
    context: "68:   val csr = DelayN(io.csr, q.fenceDelay)\n69: \n70:   val flush_mmu
      = sfence.valid || csr.satp.changed || csr.vsatp.changed || csr.hgatp.changed
      || csr.priv.virt_changed\n71:   val mmu_flush_pipe = sfence.valid && sfence.bits.flushPipe
      // for svinval, won't flush pipe\n72:   val flush_pipe = io.flushPipe\n73: \
      \  val redirect = io.redirect\n74:   val EffectiveVa = Wire(Vec(Width, UInt(XLEN.W)))\n\
      75:   val req_in = req\n76:   val req_out = Reg(Vec(Width, new TlbReq))\n77:\
      \   for (i <- 0 until Width) {\n78:     when (req(i).fire) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 87-98
    context: "87:   // ATTENTION: csr and flush from backend are delayed. csr should
      not be later than flush.\n88:   // because, csr will influence tlb behavior.\n\
      89:   val ifetch = if (q.fetchi) true.B else false.B\n90:   val mode_tmp = if
      (q.useDmode) csr.priv.dmode else csr.priv.imode\n91:   val mode = (0 until Width).map(i
      => Mux(isHyperInst(i), csr.priv.spvp, mode_tmp))\n92:   val virt_in = csr.priv.virt\n\
      93:   val virt_out = req.map(a => RegEnable(csr.priv.virt, a.fire))\n94:   val
      sum = (0 until Width).map(i => Mux(virt_out(i) || isHyperInst(i), csr.priv.vsum,
      csr.priv.sum))\n95:   val mxr = (0 until Width).map(i => Mux(virt_out(i) ||
      isHyperInst(i), csr.priv.vmxr || csr.priv.mxr, csr.priv.mxr))\n96:   val req_in_s2xlate
      = (0 until Width).map(i => MuxCase(noS2xlate, Seq(\n97:       (!(virt_in ||
      req_in(i).bits.hyperinst)) -> noS2xlate,\n98:       (csr.vsatp.mode =/= 0.U
      && csr.hgatp.mode =/= 0.U) -> allStage,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLB.scala
    lines: 274-287
    context: "274:     val enable = portTranslateEnable(i)\n275:     val isOnlys2xlate
      = req_out_s2xlate(i) === onlyStage2\n276:     val need_gpa_vpn_hit = need_gpa_vpn
      === get_pn(req_out(i).vaddr)\n277:     val isitlb = TlbCmd.isExec(req_out(i).cmd)\n\
      278:     val isPrefetch = req_out(i).isPrefetch\n279:     val currentRedirect
      = req_out(i).debug.robIdx.needFlush(redirect)\n280:     val lastCycleRedirect
      = req_out(i).debug.robIdx.needFlush(RegNext(redirect))\n281: \n282:     when
      (!isitlb && need_gpa_robidx.needFlush(redirect) || isitlb && flush_pipe(i)){\n\
      283:       need_gpa := false.B\n284:       resp_gpa_refill := false.B\n285:\
      \       need_gpa_vpn := 0.U\n286:     }.elsewhen (req_out_v(i) && !p_hit &&
      !(resp_gpa_refill && need_gpa_vpn_hit) && !isOnlys2xlate && hasGpf(i) && need_gpa
      === false.B && !io.requestor(i).req_kill && !isPrefetch && !currentRedirect
      && !lastCycleRedirect) {\n287:       need_gpa_wire := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 185-196
    context: "185:   }\n186: \n187:   val sfence = io.sfence\n188:   val sfence_valid
      = sfence.valid && !sfence.bits.hg && !sfence.bits.hv\n189:   val sfence_vpn
      = sfence.bits.addr(VAddrBits - 1, offLen)\n190:   val sfenceHit = entries.map(_.hit(sfence_vpn,
      sfence.bits.id, vmid = io.csr.hgatp.vmid, hasS2xlate = io.csr.priv.virt))\n\
      191:   val sfenceHit_noasid = entries.map(_.hit(sfence_vpn, sfence.bits.id,
      ignoreAsid = true, vmid = io.csr.hgatp.vmid, hasS2xlate = io.csr.priv.virt))\n\
      192:   // Sfence will flush all sectors of an entry when hit\n193:   when (sfence_valid)
      {\n194:     when (sfence.bits.rs1) { // virtual address *.rs1 <- (rs1===0.U)\n\
      195:       when (sfence.bits.rs2) { // asid, but i do not want to support asid,
      *.rs2 <- (rs2===0.U)\n196:         // all addr and all asid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/TLBStorage.scala
    lines: 192-207
    context: "192:   // Sfence will flush all sectors of an entry when hit\n193: \
      \  when (sfence_valid) {\n194:     when (sfence.bits.rs1) { // virtual address
      *.rs1 <- (rs1===0.U)\n195:       when (sfence.bits.rs2) { // asid, but i do
      not want to support asid, *.rs2 <- (rs2===0.U)\n196:         // all addr and
      all asid\n197:         v.zipWithIndex.map{ case(a, i) => a := a && !((io.csr.priv.virt
      === false.B && entries(i).s2xlate === noS2xlate) ||\n198:           (io.csr.priv.virt
      && entries(i).s2xlate =/= noS2xlate && entries(i).vmid === io.csr.hgatp.vmid))}\n\
      199:       }.otherwise {\n200:         // all addr but specific asid\n201: \
      \        v.zipWithIndex.map{ case (a, i) => a := a && !(!g(i) && ((!io.csr.priv.virt
      && entries(i).s2xlate === noS2xlate && entries(i).asid === sfence.bits.id) ||\n\
      202:           (io.csr.priv.virt && entries(i).s2xlate =/= noS2xlate && entries(i).asid
      === sfence.bits.id && entries(i).vmid === io.csr.hgatp.vmid)))}\n203:      \
      \ }\n204:     }.otherwise {\n205:       when (sfence.bits.rs2) {\n206:     \
      \    // specific addr but all asid\n207:         v.zipWithIndex.map{ case (a,
      i) => a := a & !sfenceHit_noasid(i) }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 170-180
    context: "170:   val ppn_af = if (HasBitmapCheck) {\n171:     Mux(enableS2xlate,
      Mux(onlyS1xlate, pte_isAf, false.B), pte_isAf) // In two-stage address translation,
      stage 1 ppn is a vpn for host, so don't need to check ppn_high\n172:   } else
      {\n173:     Mux(enableS2xlate, Mux(onlyS1xlate, pte.isAf(), false.B), pte.isAf())
      // In two-stage address translation, stage 1 ppn is a vpn for host, so don't
      need to check ppn_high\n174:   }\n175:   val pte_valid = RegInit(false.B)  //
      avoid l1tlb pf from stage1 when gpf happens in the first s2xlate in PTW\n176:\
      \ \n177:   val pageFault = pte.isPf(level, s1Pbmte)\n178:   val find_pte = pte.isLeaf()
      || ppn_af || pageFault\n179:   val to_find_pte = level === 1.U && find_pte ===
      false.B\n180:   val source = RegEnable(io.req.bits.req_info.source, io.req.fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/PageTableWalker.scala
    lines: 642-652
    context: "642:   val in = Flipped(DecoupledIO(new LLPTWInBundle()))\n643:   val
      out = DecoupledIO(new Bundle {\n644:     val req_info = Output(new L2TlbInnerBundle())\n\
      645:     val id = Output(UInt(bMemID.W))\n646:     val h_resp = Output(new HptwResp)\n\
      647:     val first_s2xlate_fault = Output(Bool()) // Whether the first stage
      2 translation occurs pf/af\n648:     val af = Output(Bool())\n649:     val bitmapCheck
      = Option.when(HasBitmapCheck)(new Bundle {\n650:       val jmp_bitmap_check
      = Bool() // find pte in l0 or sp, but need bitmap check\n651:       val ptes
      = Vec(tlbcontiguous, UInt(XLEN.W)) // Page Table Entry Vector\n652:       val
      cfs = Vec(tlbcontiguous, Bool()) // Bitmap Check Failed Vector"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 224-234
    context: "224:         dupBitmapPPN(entries(i).ppn, entries(j).ppn)\n225:    \
      \   )\n226:       val cm_dup_req_fire = mem_arb.io.out.fire && dupBitmapPPN(entries(i).ppn,
      mem_arb.io.out.bits.ppn)\n227:       val cm_dup_vec_wait = cm_dup_vec.zip(is_waiting).map{case
      (d, w) => d && w}\n228:       val cm_dup_wait_resp = io.mem.resp.fire && VecInit(cm_dup_vec_wait)(io.mem.resp.bits.id
      - (l2tlbParams.llptwsize + 2).U)\n229:       val cm_wait_id = Mux(cm_dup_req_fire,
      mem_arb.io.chosen, ParallelMux(cm_dup_vec_wait zip entries.map(_.wait_id)))\n\
      230:       val cm_to_wait = Cat(cm_dup_vec_wait).orR || cm_dup_req_fire\n231:\
      \       val cm_to_mem_out = cm_dup_wait_resp\n232:       val cm_next_state_normal
      = MuxCase(state_mem_req, Seq(\n233:         cm_to_mem_out -> state_mem_out,\n\
      234:         cm_to_wait -> state_mem_waiting"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/mmu/BitmapCheck.scala
    lines: 240-250
    context: "240:             entries(i).hit := true.B\n241:             entries(i).cfs
      := io.cache.resp.bits.cfs\n242:             state(i) := state_mem_out\n243:\
      \           } .otherwise {\n244:             state(i) := cm_next_state_normal\n\
      245:             entries(i).wait_id := Mux(cm_to_wait, cm_wait_id, entries(i).wait_id)\n\
      246:             entries(i).hit := cm_to_wait\n247:           }\n248:      \
      \ }\n249:     }\n250:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/wpu/WPUWrapper.scala
    lines: 166-176
    context: "166:         s0_pred_way_en(i) := UIntToOH(get_direct_map_way(io.req(i).bits.vaddr))\n\
      167:         s0_dmSel(i) := true.B\n168:       }\n169:       wayConflictPredictor.io.update(i).en
      := io.lookup_upd(i).valid\n170:       wayConflictPredictor.io.update(i).vaddr
      := io.cfpred(i).s1_vaddr\n171:       wayConflictPredictor.io.update(i).dm_hit
      := s1_dmSel(i) && io.cfpred(i).s1_dm_hit\n172:       wayConflictPredictor.io.update(i).sa_hit
      := !s1_dmSel(i) && s1_hit(i)\n173:     }\n174:     XSPerfAccumulate(\"wpu_pred_from_prediction\"\
      , PopCount((0 until nPorts).map(i => io.req(i).valid && !io.req(i).bits.replayCarry.valid
      && s0_pred_way_conflict(i))))\n175:     XSPerfAccumulate(\"wpu_pred_from_directMap\"\
      , PopCount((0 until nPorts).map(i => io.req(i).valid && !io.req(i).bits.replayCarry.valid
      && !s0_pred_way_conflict(i))))\n176:     // dm situation"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/wpu/VictimList.scala
    lines: 38-48
    context: "38: }\n39: \n40: class WayConflictUpdIO (implicit p: Parameters) extends
      WayConflictPredictorBundle {\n41:   val en = Input(Bool())\n42:   val vaddr
      = Input(UInt(VAddrBits.W))\n43:   val dm_hit = Input(Bool())\n44:   val sa_hit
      = Input(Bool())\n45: }\n46: \n47: class WayConflictPredictor (nPorts: Int) (implicit
      p: Parameters) extends WayConflictPredictorModule{\n48:   val io = IO(new Bundle()
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/wpu/VictimList.scala
    lines: 54-64
    context: "54:   for (i <- 0 until nPorts){\n55:     io.pred(i).way_conflict :=
      io.pred(i).en & PredTable(get_addr_idx(io.pred(i).vaddr))(CounterSize-1)\n56:\
      \     val ptVal = PredTable(get_addr_idx(io.update(i).vaddr))\n57:     when(io.update(i).en
      && io.update(i).sa_hit && ptVal =/= Fill(CounterSize, 1.U)) {\n58:       PredTable(get_addr_idx(io.update(i).vaddr))
      := ptVal + 1.U\n59:     }.elsewhen(io.update(i).en && io.update(i).dm_hit &&
      ptVal =/= Fill(CounterSize, 0.U)) {\n60:       PredTable(get_addr_idx(io.update(i).vaddr))
      := ptVal - 1.U\n61:     }\n62:   }\n63: \n64: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/CacheConstants.scala
    lines: 40-53
    context: "40:   def M_XA_AND  = \"b01011\".U\n41:   def M_XA_MIN  = \"b01100\"\
      .U\n42:   def M_XA_MAX  = \"b01101\".U\n43:   def M_XA_MINU = \"b01110\".U\n\
      44:   def M_XA_MAXU = \"b01111\".U\n45:   def M_FLUSH   = \"b10000\".U // write
      back dirty data and cede R/W permissions\n46:   def M_PWR     = \"b10001\".U
      // partial (masked.U store\n47:   def M_PRODUCE = \"b10010\".U // write back
      dirty data and cede W permissions\n48:   def M_CLEAN   = \"b10011\".U // write
      back dirty data and retain R/W permissions\n49:   def M_SFENCE  = \"b10100\"\
      .U // flush TLB\n50:   def M_WOK     = \"b10111\".U // check write permissions
      but don't perform a write\n51:   def M_XA_CASQ = \"b11000\".U // AMOCAS.Q\n\
      52:   def M_XA_CASW = \"b11010\".U // AMOCAS.W\n53:   def M_XA_CASD = \"b11011\"\
      .U // AMOCAS.D"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 32-42
    context: "32: import freechips.rocketchip.tilelink.ClientStates._\n33: import
      freechips.rocketchip.tilelink.MemoryOpCategories._\n34: import freechips.rocketchip.tilelink.TLPermissions._\n\
      35: import freechips.rocketchip.tilelink.TLMessages._\n36: import freechips.rocketchip.tilelink._\n\
      37: import huancun.{AliasKey, DirtyKey, PrefetchKey}\n38: import org.chipsalliance.cde.config.Parameters\n\
      39: import utility._\n40: import utils._\n41: import xiangshan._\n42: import
      xiangshan.mem.AddPipelineReg"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 106-116
    context: "106: }\n107: \n108: class MissQueueRefillInfo(implicit p: Parameters)
      extends MissReqStoreData {\n109:   // refill_info for mainpipe req awake\n110:\
      \   val miss_param = UInt(TLPermissions.bdWidth.W)\n111:   val miss_dirty =
      Bool()\n112:   val error      = Bool()\n113: }\n114: \n115: class MissReq(implicit
      p: Parameters) extends MissReqWoStoreData {\n116:   // store data and store
      mask will be written to miss queue entry"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 641-651
    context: "641:     // we only need to merge data for Store\n642:     new_mask(i)
      := Mux(req.isFromStore, req_store_mask(rowBytes * (i + 1) - 1, rowBytes * i),
      0.U)\n643:   }\n644: \n645:   val hasData = RegInit(true.B)\n646:   val isDirty
      = RegInit(false.B)\n647:   io.wfi.wfiSafe := GatedValidRegNext(no_pending &&
      io.wfi.wfiReq)\n648:   when (io.mem_grant.fire) {\n649:     w_grantfirst :=
      true.B\n650:     grant_param := io.mem_grant.bits.param\n651:     when (edge.hasData(io.mem_grant.bits))
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 679-689
    context: "679:     }\n680: \n681:     error := io.mem_grant.bits.denied || io.mem_grant.bits.corrupt
      || error\n682: \n683:     refill_data_raw(refill_count ^ isKeyword) := io.mem_grant.bits.data\n\
      684:     isDirty := io.mem_grant.bits.echo.lift(DirtyKey).getOrElse(false.B)\n\
      685:   }\n686: \n687:   when (io.mem_finish.fire) {\n688:     s_grantack :=
      true.B\n689:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MissQueue.scala
    lines: 904-914
    context: "904: \n905:   io.refill_info.valid := req_valid && w_grantlast\n906:\
      \   io.refill_info.bits.store_data := refill_and_store_data.asUInt\n907:   io.refill_info.bits.store_mask
      := ~0.U(blockBytes.W)\n908:   io.refill_info.bits.miss_param := grant_param\n\
      909:   io.refill_info.bits.miss_dirty := isDirty\n910:   io.refill_info.bits.error\
      \      := error\n911: \n912:   XSPerfAccumulate(\"miss_refill_mainpipe_req\"\
      , io.main_pipe_req.fire)\n913:   XSPerfAccumulate(\"miss_refill_without_hint\"\
      , io.main_pipe_req.fire && !mainpipe_req_fired && !w_l2hint)\n914:   XSPerfAccumulate(\"\
      miss_refill_replay\", io.main_pipe_replay)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 31-41
    context: "31: \n32: class MainPipeReq(implicit p: Parameters) extends DCacheBundle
      {\n33:   val miss = Bool() // only amo miss will refill in main pipe\n34:  \
      \ val miss_id = UInt(log2Up(cfg.nMissEntries).W)\n35:   val miss_param = UInt(TLPermissions.bdWidth.W)\n\
      36:   val miss_dirty = Bool()\n37:   val occupy_way = UInt(nWays.W)\n38:   val
      miss_fail_cause_evict_btot = Bool()\n39: \n40:   val probe = Bool()\n41:   val
      probe_param = UInt(TLPermissions.bdWidth.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 83-93
    context: "83: \n84:   def convertStoreReq(store: DCacheLineReq): MainPipeReq =
      {\n85:     val req = Wire(new MainPipeReq)\n86:     req := DontCare\n87:   \
      \  req.miss := false.B\n88:     req.miss_dirty := false.B\n89:     req.probe
      := false.B\n90:     req.probe_need_data := false.B\n91:     req.source := STORE_SOURCE.U\n\
      92:     req.cmd := store.cmd\n93:     req.addr := store.addr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 519-529
    context: "519: \n520:   // s3: write data, meta and tag\n521:   val s3_valid =
      RegInit(false.B)\n522:   val s3_req = RegEnable(s2_req, s2_fire_to_s3)\n523:\
      \   val s3_miss_param = RegEnable(io.refill_info.bits.miss_param, s2_fire_to_s3)\n\
      524:   val s3_miss_dirty = RegEnable(io.refill_info.bits.miss_dirty, s2_fire_to_s3)\n\
      525:   val s3_tag = RegEnable(s2_tag, s2_fire_to_s3)\n526:   val s3_tag_match
      = RegEnable(s2_tag_match, s2_fire_to_s3)\n527:   val s3_coh = RegEnable(s2_coh,
      s2_fire_to_s3)\n528:   val s3_hit = RegEnable(s2_hit, s2_fire_to_s3)\n529: \
      \  val s3_amo_hit = RegEnable(s2_amo_hit, s2_fire_to_s3)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 564-588
    context: "564:   val store_update_meta = s3_req.isStore && !s3_req.probe && s3_hit_coh
      =/= s3_new_hit_coh\n565:   val amo_update_meta = s3_req.isAMO && !s3_req.probe
      && s3_hit_coh =/= s3_new_hit_coh && !s3_sc_fail\n566:   val amo_wait_amoalu
      = s3_req.isAMO && s3_req.cmd =/= M_XLR && s3_req.cmd =/= M_XSC && !isAMOCAS(s3_req.cmd)\n\
      567:   val update_meta = (miss_update_meta || probe_update_meta || store_update_meta
      || amo_update_meta) && !s3_req.replace\n568: \n569:   def missCohGen(cmd: UInt,
      param: UInt, dirty: Bool) = {\n570:     val c = categorize(cmd)\n571:     MuxLookup(Cat(c,
      param, dirty), Nothing)(Seq(\n572:       //(effect param) -> (next)\n573:  \
      \     Cat(rd, toB, false.B)  -> Branch,\n574:       Cat(rd, toB, true.B)   ->
      Branch,\n575:       Cat(rd, toT, false.B)  -> Trunk,\n576:       Cat(rd, toT,
      true.B)   -> Dirty,\n577:       Cat(wi, toT, false.B)  -> Trunk,\n578:     \
      \  Cat(wi, toT, true.B)   -> Dirty,\n579:       Cat(wr, toT, false.B)  -> Dirty,\n\
      580:       Cat(wr, toT, true.B)   -> Dirty))\n581:   }\n582: \n583:   val miss_new_coh
      = ClientMetadata(missCohGen(s3_req.cmd, s3_miss_param, s3_miss_dirty))\n584:\
      \ \n585:   // report ecc error\n586:   val s3_tag_error_beu = RegEnable(s2_tag_error,
      s2_fire)\n587:   val s3_tag_error_wb = RegEnable(s2_tag_error, s2_fire_to_s3)\n\
      588: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 731-743
    context: "731:   val need_wb = miss_wb || probe_wb || replace_wb\n732: \n733:\
      \   val writeback_param = Mux(probe_wb, probe_shrink_param, miss_shrink_param)\n\
      734:   val writeback_data = if (dcacheParameters.alwaysReleaseData) {\n735:\
      \     s3_tag_match && s3_req.probe && s3_req.probe_need_data ||\n736:      \
      \ s3_coh === ClientStates.Dirty || (miss_wb || replace_wb) && s3_coh.state =/=
      ClientStates.Nothing\n737:   } else {\n738:     s3_tag_match && s3_req.probe
      && s3_req.probe_need_data || s3_coh === ClientStates.Dirty\n739:   }\n740: \n\
      741:   val s3_probe_can_go = s3_req.probe && io.wb.ready && (io.meta_write.ready
      || !probe_update_meta)\n742:   val s3_store_can_go = s3_req.source === STORE_SOURCE.U
      && !s3_req.probe && (io.meta_write.ready || !store_update_meta) && (io.data_write.ready
      || !update_data) && !s3_req.miss\n743:   val s3_amo_can_go = s3_amo_hit && (io.meta_write.ready
      || !amo_update_meta) && (io.data_write.ready || !update_data) && (s3_s_amoalu
      || !amo_wait_amoalu) || s3_sc_fail"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/MainPipe.scala
    lines: 992-1002
    context: "992: \n993:   io.wb.bits.addr := get_block_addr(Cat(s3_tag, get_untag(s3_req.vaddr)))\n\
      994:   io.wb.bits.param := writeback_param\n995:   io.wb.bits.voluntary := s3_req.miss
      || s3_req.replace\n996:   io.wb.bits.hasData := writeback_data && !s3_tag_error_wb\n\
      997:   io.wb.bits.dirty := s3_coh === ClientStates.Dirty\n998:   io.wb.bits.data
      := s3_data.asUInt\n999:   io.wb.bits.corrupt := s3_tag_error_wb || s3_data_error_wb\n\
      1000:   io.wb.bits.delay_release := s3_req.replace\n1001:   io.wb.bits.miss_id
      := s3_req.miss_id\n1002: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 28-38
    context: "28: class WritebackReqCtrl(implicit p: Parameters) extends DCacheBundle
      {\n29:   val param  = UInt(cWidth.W)\n30:   val voluntary = Bool()\n31:   val
      hasData = Bool()\n32:   val corrupt = Bool()\n33:   val dirty = Bool()\n34:\
      \ \n35:   val delay_release = Bool()\n36:   val miss_id = UInt(log2Up(cfg.nMissEntries).W)\n\
      37: }\n38: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 62-72
    context: "62:     out.addr := addr\n63:     out.param := param\n64:     out.voluntary
      := voluntary\n65:     out.hasData := hasData\n66:     out.corrupt := corrupt\n\
      67:     out.dirty := dirty\n68:     out.delay_release := delay_release\n69:\
      \     out.miss_id := miss_id\n70:     out\n71:   }\n72: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 74-84
    context: "74:     val out = Wire(new WritebackReqCtrl)\n75:     out.param := param\n\
      76:     out.voluntary := voluntary\n77:     out.hasData := hasData\n78:    \
      \ out.corrupt := corrupt\n79:     out.dirty := dirty\n80:     out.delay_release
      := delay_release\n81:     out.miss_id := miss_id\n82:     out\n83:   }\n84: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/mainpipe/WritebackQueue.scala
    lines: 257-267
    context: "257:     corrupt = req.corrupt\n258:   )._2\n259: \n260:   // voluntaryReleaseData.echo.lift(DirtyKey).foreach(_
      := req.dirty)\n261:   when(busy) {\n262:     assert(!req.dirty || req.hasData)\n\
      263:   }\n264: \n265:   val (_, _, release_done, release_count) = edge.count(io.mem_release)\n\
      266: \n267:   io.mem_release.valid := busy"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 355-365
    context: "355: }\n356: \n357: class DCacheExtraMeta(implicit p: Parameters) extends
      DCacheBundle\n358: {\n359:   val error = Bool() // cache line has been marked
      as corrupted by l2 / ecc error detected when store\n360:   val prefetch = UInt(L1PfSourceBits.W)
      // cache line is first required by prefetch\n361:   val access = Bool() // cache
      line has been accessed by load / store\n362: \n363:   // val debug_access_timestamp
      = UInt(64.W) // last time a load / store / refill access that cacheline\n364:
      }\n365: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/cache/dcache/DCacheWrapper.scala
    lines: 1177-1188
    context: "1177:     val extra_flag_valid = RegNext(mainPipe.io.prefetch_flag_write.valid)\n\
      1178:     val extra_flag_way_en = RegEnable(mainPipe.io.prefetch_flag_write.bits.way_en,
      mainPipe.io.prefetch_flag_write.valid)\n1179:     val extra_flag_prefetch =
      Mux1H(extra_flag_way_en, prefetchArray.io.resp.last)\n1180:     val extra_flag_access
      = Mux1H(extra_flag_way_en, accessArray.io.resp.last)\n1181: \n1182:     prefetcherMonitor.io.validity.good_prefetch
      := extra_flag_valid && isPrefetchRelated(extra_flag_prefetch) && extra_flag_access\n\
      1183:     prefetcherMonitor.io.validity.bad_prefetch := extra_flag_valid &&
      isPrefetchRelated(extra_flag_prefetch) && !extra_flag_access\n1184:   }\n1185:\
      \ \n1186:   // write extra meta\n1187:   val error_flag_write_ports = Seq(\n\
      1188:     mainPipe.io.error_flag_write // error flag generated by corrupted
      store"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Parameters.scala
    lines: 147-159
    context: "147:   ICacheForceDataECCError: Boolean = false,\n148:   IBufSize: Int
      = 48,\n149:   IBufNBank: Int = 6, // IBuffer bank amount, should divide IBufSize\n\
      150:   DecodeWidth: Int = 6,\n151:   RenameWidth: Int = 6,\n152:   CommitWidth:
      Int = 8,\n153:   RobCommitWidth: Int = 8,\n154:   RabCommitWidth: Int = 6,\n\
      155:   MaxUopSize: Int = 65,\n156:   EnableRenameSnapshot: Boolean = true,\n\
      157:   RenameSnapshotNum: Int = 4,\n158:   FtqSize: Int = 64,\n159:   EnableLoadFastWakeUp:
      Boolean = true, // NOTE: not supported now, make it false"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Parameters.scala
    lines: 721-733
    context: "721:   def IBufSize = coreParams.IBufSize\n722:   def IBufNBank = coreParams.IBufNBank\n\
      723:   def backendParams: BackendParams = coreParams.backendParams\n724:   def
      DecodeWidth = coreParams.DecodeWidth\n725:   def RenameWidth = coreParams.RenameWidth\n\
      726:   def CommitWidth = coreParams.CommitWidth\n727:   def RobCommitWidth =
      coreParams.RobCommitWidth\n728:   def RabCommitWidth = coreParams.RabCommitWidth\n\
      729:   def MaxUopSize = coreParams.MaxUopSize\n730:   def EnableRenameSnapshot
      = coreParams.EnableRenameSnapshot\n731:   def RenameSnapshotNum = coreParams.RenameSnapshotNum\n\
      732:   def FtqSize = coreParams.FtqSize\n733:   def EnableLoadFastWakeUp = coreParams.EnableLoadFastWakeUp"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Parameters.scala
    lines: 908-918
    context: "908:   def TvalWidth              = coreParams.traceParams.IaddrWidth\n\
      909:   def PrivWidth              = coreParams.traceParams.PrivWidth\n910: \
      \  def IaddrWidth             = coreParams.traceParams.IaddrWidth\n911:   def
      ItypeWidth             = coreParams.traceParams.ItypeWidth\n912:   def IretireWidthInPipe\
      \     = log2Up(RenameWidth * 2 + 1)\n913:   def IretireWidthCompressed = log2Up(RenameWidth
      * CommitWidth * 2 + 1)\n914:   def IlastsizeWidth         = coreParams.traceParams.IlastsizeWidth\n\
      915: \n916:   def wfiResume              = coreParams.wfiResume\n917:   def
      hasMbist               = p(DFTOptionsKey).EnableMbist\n918:   def hasSramCtl\
      \             = p(DFTOptionsKey).EnableSramCtl"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 200-212
    context: "200:   def getRdPortParams(dataCfg: DataConfig) = {\n201:     // port
      -> Seq[exuIdx, priority]\n202:     val cfgs: Seq[(Int, Seq[(Int, Int)])] = allRealExuParams\n\
      203:       .flatMap(x => x.rfrPortConfigs.flatten.map(xx => (xx, x.exuIdx)))\n\
      204:       .filter { x => x._1.getDataConfig == dataCfg }\n205:       .map(x
      => (x._1.port, (x._2, x._1.priority)))\n206:       .groupBy(_._1)\n207:    \
      \   .map(x => (x._1, x._2.map(_._2).sortBy({ case (priority, _) => priority
      })))\n208:       .toSeq\n209:       .sortBy(_._1)\n210:     cfgs\n211:   }\n\
      212: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 218-228
    context: "218:     */\n219:   def getWbPortParams(dataCfg: DataConfig) = {\n220:\
      \     val cfgs: Seq[(Int, Seq[(Int, Int)])] = allRealExuParams\n221:       .flatMap(x
      => x.wbPortConfigs.map(xx => (xx, x.exuIdx)))\n222:       .filter { x => x._1.dataCfg
      == dataCfg }\n223:       .map(x => (x._1.port, (x._2, x._1.priority)))\n224:\
      \       .groupBy(_._1)\n225:       .map(x => (x._1, x._2.map(_._2)))\n226: \
      \      .toSeq\n227:       .sortBy(_._1)\n228:     cfgs"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 453-463
    context: "453:               case _: VfRD  => rfReadPortConfigs.flatten.filter(_.isInstanceOf[VfRD])\n\
      454:               case _        => Seq()\n455:             }\n456:        \
      \     (wbConfigs, rdConfigs)\n457:         }.filter(_._1.isDefined)\n458:  \
      \         .sortBy(_._1.get.priority)\n459:           .groupBy(_._1.get.port).map
      { case (wbPort, intWbRdPairs) =>\n460:             val rdCfgs = intWbRdPairs.map(_._2).flatten\n\
      461:             println(s\"[BackendParams] wb port ${wbPort} rdcfgs: ${rdCfgs}\"\
      )\n462:             rdCfgs.groupBy(_.port).foreach { case (p, rdCfg) =>\n463:\
      \               //println(s\"[BackendParams] rdport: ${p}, cfgs: ${rdCfg}\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/BackendParams.scala
    lines: 459-469
    context: "459:           .groupBy(_._1.get.port).map { case (wbPort, intWbRdPairs)
      =>\n460:             val rdCfgs = intWbRdPairs.map(_._2).flatten\n461:     \
      \        println(s\"[BackendParams] wb port ${wbPort} rdcfgs: ${rdCfgs}\")\n\
      462:             rdCfgs.groupBy(_.port).foreach { case (p, rdCfg) =>\n463: \
      \              //println(s\"[BackendParams] rdport: ${p}, cfgs: ${rdCfg}\")\n\
      464:               rdCfg.zip(rdCfg.drop(1)).foreach { case (cfg0, cfg1) => assert(cfg0.priority
      <= cfg1.priority, s\"an exu has high priority at ${wbType} wb port ${wbPort},
      but has low priority at ${rdType} rd port ${p}\") }\n465:             }\n466:\
      \         }\n467:       }\n468:     }\n469:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 24-34
    context: "24:     ptr\n25:   }\n26: }\n27: \n28: class RenameBufferEntry(implicit
      p: Parameters) extends XSBundle {\n29:   val info = new RabCommitInfo\n30: \
      \  val robIdx = OptionWrapper(!env.FPGAPlatform, new RobPtr)\n31: }\n32: \n\
      33: class RenameBuffer(size: Int)(implicit p: Parameters) extends XSModule with
      HasCircularQueuePtrHelper {\n34:   val io = IO(new Bundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 30-40
    context: "30:   val robIdx = OptionWrapper(!env.FPGAPlatform, new RobPtr)\n31:
      }\n32: \n33: class RenameBuffer(size: Int)(implicit p: Parameters) extends XSModule
      with HasCircularQueuePtrHelper {\n34:   val io = IO(new Bundle {\n35:     val
      redirect = Input(ValidIO(new Bundle {\n36:     }))\n37: \n38:     val req =
      Vec(RenameWidth, Flipped(ValidIO(new DynInst)))\n39:     val fromRob = new Bundle
      {\n40:       val walkSize = Input(UInt(log2Up(size).W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 37-47
    context: "37: \n38:     val req = Vec(RenameWidth, Flipped(ValidIO(new DynInst)))\n\
      39:     val fromRob = new Bundle {\n40:       val walkSize = Input(UInt(log2Up(size).W))\n\
      41:       val walkEnd = Input(Bool())\n42:       val commitSize = Input(UInt(log2Up(size).W))\n\
      43:       val vecLoadExcp = Input(ValidIO(new Bundle{\n44:         val isStrided
      = Bool()\n45:         val isVlm = Bool()\n46:       }))\n47:     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 50-65
    context: "50: \n51:     val canEnq = Output(Bool())\n52:     val canEnqForDispatch
      = Output(Bool())\n53:     val enqPtrVec = Output(Vec(RenameWidth, new RenameBufferPtr))\n\
      54: \n55:     val commits = Output(new RabCommitIO)\n56:     val diffCommits
      = if (backendParams.basicDebugEn) Some(Output(new DiffCommitIO)) else None\n\
      57: \n58:     val status = Output(new Bundle {\n59:       val walkEnd = Bool()\n\
      60:       val commitEnd = Bool()\n61:     })\n62:     val toVecExcpMod = Output(new
      RabToVecExcpMod)\n63:   })\n64: \n65:   // alias"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 72-86
    context: "72:   private val enqPtrOHShift = CircularShift(enqPtrOH)\n73:   //
      may shift [0, RenameWidth] steps\n74:   private val enqPtrOHVec = VecInit.tabulate(RenameWidth
      + 1)(enqPtrOHShift.left)\n75:   private val enqPtrVecNext = Wire(enqPtrVec.cloneType)\n\
      76: \n77:   private val deqPtrVec = RegInit(VecInit.tabulate(RabCommitWidth)(idx
      => RenameBufferPtr(flag = false, idx)))\n78:   private val deqPtr = deqPtrVec.head\n\
      79:   private val deqPtrOH = RegInit(1.U(size.W))\n80:   private val deqPtrOHShift
      = CircularShift(deqPtrOH)\n81:   private val deqPtrOHVec = VecInit.tabulate(RabCommitWidth
      + 1)(deqPtrOHShift.left)\n82:   private val deqPtrVecNext = Wire(deqPtrVec.cloneType)\n\
      83:   XSError(deqPtr.toOH =/= deqPtrOH, p\"wrong one-hot reg between $deqPtr
      and $deqPtrOH\")\n84: \n85:   private val walkPtr = Reg(new RenameBufferPtr)\n\
      86:   private val walkPtrOH = walkPtr.toOH"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 82-95
    context: "82:   private val deqPtrVecNext = Wire(deqPtrVec.cloneType)\n83:   XSError(deqPtr.toOH
      =/= deqPtrOH, p\"wrong one-hot reg between $deqPtr and $deqPtrOH\")\n84: \n\
      85:   private val walkPtr = Reg(new RenameBufferPtr)\n86:   private val walkPtrOH
      = walkPtr.toOH\n87:   private val walkPtrOHVec = VecInit.tabulate(RabCommitWidth
      + 1)(CircularShift(walkPtrOH).left)\n88:   private val walkPtrNext = Wire(new
      RenameBufferPtr)\n89: \n90:   private val walkPtrSnapshots = SnapshotGenerator(enqPtr,
      io.snpt.snptEnq, io.snpt.snptDeq, io.redirect.valid, io.snpt.flushVec)\n91:\
      \ \n92:   val vcfgPtrOH = RegInit(1.U(size.W))\n93:   val vcfgPtrOHShift = CircularShift(vcfgPtrOH)\n\
      94:   // may shift [0, 2) steps\n95:   val vcfgPtrOHVec = VecInit.tabulate(2)(vcfgPtrOHShift.left)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 111-121
    context: "111:   val stateNext = WireInit(state) // otherwise keep state value\n\
      112: \n113:   private val robWalkEndReg = RegInit(false.B)\n114:   private val
      robWalkEnd = io.fromRob.walkEnd || robWalkEndReg\n115: \n116:   when(io.redirect.valid)
      {\n117:     robWalkEndReg := false.B\n118:   }.elsewhen(io.fromRob.walkEnd)
      {\n119:     robWalkEndReg := true.B\n120:   }\n121: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 119-162
    context: "119:     robWalkEndReg := true.B\n120:   }\n121: \n122:   val realNeedAlloc
      = io.req.map(req => req.valid && req.bits.needWriteRf)\n123:   val enqCount\
      \    = PopCount(realNeedAlloc)\n124:   val commitNum = Wire(UInt(log2Up(RabCommitWidth).W))\n\
      125:   val walkNum = Wire(UInt(log2Up(RabCommitWidth).W))\n126:   commitNum
      := Mux(io.commits.commitValid(0), PriorityMux((0 until RabCommitWidth).map(\n\
      127:     i => io.commits.commitValid(RabCommitWidth - 1 - i) -> (RabCommitWidth
      - i).U\n128:   )), 0.U)\n129:   walkNum := Mux(io.commits.walkValid(0), PriorityMux((0
      until RabCommitWidth).map(\n130:     i => io.commits.walkValid(RabCommitWidth
      - 1 - i) -> (RabCommitWidth-i).U\n131:   )), 0.U)\n132:   val commitCount =
      Mux(io.commits.isCommit && !io.commits.isWalk, commitNum, 0.U)\n133:   val walkCount\
      \   = Mux(io.commits.isWalk && !io.commits.isCommit, walkNum, 0.U)\n134:   val
      specialWalkCount = Mux(io.commits.isCommit && io.commits.isWalk, walkNum, 0.U)\n\
      135: \n136:   // number of pair(ldest, pdest) ready to commit to arch_rat\n\
      137:   val commitSize = RegInit(0.U(log2Up(size).W))\n138:   val walkSize =
      RegInit(0.U(log2Up(size).W))\n139:   val specialWalkSize = RegInit(0.U(log2Up(size).W))\n\
      140: \n141:   val newCommitSize = io.fromRob.commitSize\n142:   val newWalkSize
      = io.fromRob.walkSize\n143: \n144:   val commitSizeNxt = commitSize + newCommitSize
      - commitCount\n145:   val walkSizeNxt = walkSize + newWalkSize - walkCount\n\
      146: \n147:   val newSpecialWalkSize = Mux(io.redirect.valid && !io.snpt.useSnpt,
      commitSizeNxt, 0.U)\n148:   val specialWalkSizeNext = specialWalkSize + newSpecialWalkSize
      - specialWalkCount\n149: \n150:   commitSize := Mux(io.redirect.valid && !io.snpt.useSnpt,
      0.U, commitSizeNxt)\n151:   specialWalkSize := specialWalkSizeNext\n152:   walkSize
      := Mux(io.redirect.valid, 0.U, walkSizeNxt)\n153: \n154:   walkPtrNext := MuxCase(walkPtr,
      Seq(\n155:     (state === s_idle && stateNext === s_walk) -> walkPtrSnapshots(snptSelect),\n\
      156:     (state === s_special_walk && stateNext === s_walk) -> deqPtrVecNext.head,\n\
      157:     (state === s_walk && io.snpt.useSnpt && io.redirect.valid) -> walkPtrSnapshots(snptSelect),\n\
      158:     (state === s_walk) -> (walkPtr + walkCount),\n159:   ))\n160: \n161:\
      \   walkPtr := walkPtrNext\n162: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 159-173
    context: "159:   ))\n160: \n161:   walkPtr := walkPtrNext\n162: \n163:   val walkCandidates\
      \   = VecInit(walkPtrOHVec.map(sel => Mux1H(sel, renameBufferEntries)))\n164:\
      \   val commitCandidates = VecInit(deqPtrOHVec.map(sel => Mux1H(sel, renameBufferEntries)))\n\
      165:   val vcfgCandidates   = VecInit(vcfgPtrOHVec.map(sel => Mux1H(sel, renameBufferEntries)))\n\
      166: \n167:   // update diff pointer\n168:   diffPtrNext := diffPtr + newCommitSize\n\
      169:   diffPtr := diffPtrNext\n170: \n171:   // update vcfg pointer\n172:  \
      \ // TODO: do not use diffPtrNext here\n173:   vcfgPtrOH := diffPtrNext.toOH"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 187-197
    context: "187:   enqPtrOH := enqPtrOHNext\n188:   enqPtrVecNext.zipWithIndex.map{
      case(ptr, i) => ptr := enqPtrNext + i.U }\n189:   enqPtrVec := enqPtrVecNext\n\
      190: \n191:   val deqPtrSteps = Mux1H(Seq(\n192:     (state === s_idle) -> commitCount,\n\
      193:     (state === s_special_walk) -> specialWalkCount,\n194:   ))\n195: \n\
      196:   // update deq pointer\n197:   val deqPtrNext = deqPtr + deqPtrSteps"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 207-235
    context: "207:       renameBuffer(allocatePtr).info := req.bits\n208:       renameBuffer(allocatePtr).robIdx.foreach(_
      := req.bits.robIdx)\n209:     }\n210:   }\n211: \n212:   io.commits.isCommit
      := state === s_idle || state === s_special_walk\n213:   io.commits.isWalk :=
      state === s_walk || state === s_special_walk\n214: \n215:   for(i <- 0 until
      RabCommitWidth) {\n216:     io.commits.commitValid(i) := state === s_idle &&
      i.U < commitSize || state === s_special_walk && i.U < specialWalkSize\n217:\
      \     io.commits.walkValid(i) := state === s_walk && i.U < walkSize || state
      === s_special_walk && i.U < specialWalkSize\n218:     // special walk use commitPtr\n\
      219:     io.commits.info(i) := Mux(state === s_idle || state === s_special_walk,
      commitCandidates(i).info, walkCandidates(i).info)\n220:     io.commits.robIdx.foreach(_(i)
      := Mux(state === s_idle || state === s_special_walk, commitCandidates(i).robIdx.get,
      walkCandidates(i).robIdx.get))\n221:   }\n222: \n223:   private val walkEndNext
      = walkSizeNxt === 0.U\n224:   private val commitEndNext = commitSizeNxt ===
      0.U\n225:   private val specialWalkEndNext = specialWalkSize <= RabCommitWidth.U\n\
      226:   // when robWalkEndReg is 1, walkSize donot increase and decrease RabCommitWidth
      per Cycle\n227:   private val walkEndNextCycle = (robWalkEndReg || io.fromRob.walkEnd
      && io.fromRob.walkSize === 0.U) && (walkSize <= RabCommitWidth.U)\n228:   //
      change state\n229:   state := stateNext\n230:   when(io.redirect.valid) {\n\
      231:     when(io.snpt.useSnpt) {\n232:       stateNext := s_walk\n233:     }.otherwise
      {\n234:       stateNext := s_special_walk\n235:       vecLoadExcp := io.fromRob.vecLoadExcp"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rab.scala
    lines: 266-293
    context: "266:   io.canEnq := allowEnqueue && state === s_idle\n267:   io.canEnqForDispatch
      := allowEnqueueForDispatch && state === s_idle\n268:   io.enqPtrVec := enqPtrVec\n\
      269: \n270:   io.status.walkEnd := walkEndNext\n271:   io.status.commitEnd :=
      commitEndNext\n272: \n273:   for (i <- 0 until RabCommitWidth) {\n274:     val
      valid = (state === s_special_walk) && vecLoadExcp.valid && io.commits.commitValid(i)\n\
      275:     io.toVecExcpMod.logicPhyRegMap(i).valid := RegNext(valid)\n276:   \
      \  io.toVecExcpMod.logicPhyRegMap(i).bits match {\n277:       case x =>\n278:\
      \         x.lreg := RegEnable(io.commits.info(i).ldest, valid)\n279:       \
      \  x.preg := RegEnable(io.commits.info(i).pdest, valid)\n280:     }\n281:  \
      \ }\n282: \n283:   // for difftest\n284:   io.diffCommits.foreach(_ := 0.U.asTypeOf(new
      DiffCommitIO))\n285:   io.diffCommits.foreach(_.isCommit := true.B)\n286:  \
      \ for(i <- 0 until RabCommitWidth * MaxUopSize) {\n287:     io.diffCommits.foreach(_.commitValid(i)
      := i.U < newCommitSize)\n288:     io.diffCommits.foreach(_.info(i) := renameBufferEntries((diffPtr
      + i.U).value).info)\n289:   }\n290: \n291:   XSError(isBefore(enqPtr, deqPtr)
      && !isFull(enqPtr, deqPtr), \"\\ndeqPtr is older than enqPtr!\\n\")\n292: \n\
      293:   QueuePerf(RabSize, numValidEntries, numValidEntries === size.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobDeqPtrWrapper.scala
    lines: 36-49
    context: "36: \n37: class NewRobDeqPtrWrapper(implicit p: Parameters) extends
      XSModule with HasCircularQueuePtrHelper {\n38:   val io = IO(new Bundle {\n\
      39:     // for commits/flush\n40:     val state = Input(UInt(2.W))\n41:    \
      \ val deq_v = Vec(CommitWidth, Input(Bool()))\n42:     val deq_w = Vec(CommitWidth,
      Input(Bool()))\n43:     val hasCommitted = Vec(CommitWidth, Input(Bool()))\n\
      44:     val allCommitted = Input(Bool())\n45:     val exception_state = Flipped(ValidIO(new
      RobExceptionInfo))\n46:     // for flush: when exception occurs, reset deqPtrs
      to range(0, CommitWidth)\n47:     val intrBitSetReg = Input(Bool())\n48:   \
      \  val allowOnlyOneCommit = Input(Bool())\n49:     val hasNoSpecExec = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobDeqPtrWrapper.scala
    lines: 46-66
    context: "46:     // for flush: when exception occurs, reset deqPtrs to range(0,
      CommitWidth)\n47:     val intrBitSetReg = Input(Bool())\n48:     val allowOnlyOneCommit
      = Input(Bool())\n49:     val hasNoSpecExec = Input(Bool())\n50:     val interrupt_safe
      = Input(Bool())\n51:     val blockCommit = Input(Bool())\n52:     // output:
      the CommitWidth deqPtr\n53:     val out = Vec(CommitWidth, Output(new RobPtr))\n\
      54:     val next_out = Vec(CommitWidth, Output(new RobPtr))\n55:     val commitCnt
      = Output(UInt(log2Up(CommitWidth+1).W))\n56:     val canCommitPriorityCond =
      Output(Vec(CommitWidth+1,Bool()))\n57:     val commitEn = Output(Bool())\n58:\
      \   })\n59: \n60:   val bankAddrWidth = log2Up(CommitWidth)\n61:   val deqPtrVec
      = RegInit(VecInit((0 until CommitWidth).map(_.U.asTypeOf(new RobPtr))))\n62:\
      \   val deqPosition = deqPtrVec(0).value(bankAddrWidth - 1, 0)\n63: \n64:  \
      \ // for exceptions (flushPipe included) and interrupts:\n65:   // only consider
      the first instruction\n66:   val intrEnable = io.intrBitSetReg && !io.hasNoSpecExec
      && io.interrupt_safe"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobDeqPtrWrapper.scala
    lines: 62-72
    context: "62:   val deqPosition = deqPtrVec(0).value(bankAddrWidth - 1, 0)\n63:\
      \ \n64:   // for exceptions (flushPipe included) and interrupts:\n65:   // only
      consider the first instruction\n66:   val intrEnable = io.intrBitSetReg && !io.hasNoSpecExec
      && io.interrupt_safe\n67:   val exceptionEnable = io.deq_w(deqPosition) && io.exception_state.valid
      && io.exception_state.bits.not_commit && io.exception_state.bits.robIdx ===
      deqPtrVec(0)\n68:   val redirectOutValid = io.state === 0.U && io.deq_v(deqPosition)
      && (intrEnable || exceptionEnable)\n69: \n70:   // for normal commits: only
      to consider when there're no exceptions\n71:   // we don't need to consider
      whether the first instruction has exceptions since it wil trigger exceptions.\n\
      72:   val realCommitLast = deqPtrVec(0).lineHeadPtr + Fill(bankAddrWidth, 1.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobDeqPtrWrapper.scala
    lines: 68-98
    context: "68:   val redirectOutValid = io.state === 0.U && io.deq_v(deqPosition)
      && (intrEnable || exceptionEnable)\n69: \n70:   // for normal commits: only
      to consider when there're no exceptions\n71:   // we don't need to consider
      whether the first instruction has exceptions since it wil trigger exceptions.\n\
      72:   val realCommitLast = deqPtrVec(0).lineHeadPtr + Fill(bankAddrWidth, 1.U)\n\
      73:   val commit_exception = io.exception_state.valid && !isAfter(io.exception_state.bits.robIdx,
      realCommitLast)\n74:   val canCommit = VecInit((0 until CommitWidth).map(i =>
      io.deq_v(i) && io.deq_w(i) || io.hasCommitted(i)))\n75:   val normalCommitCnt
      = PriorityEncoder(canCommit.map(c => !c) :+ true.B) - PopCount(io.hasCommitted)\n\
      76:   // when io.intrBitSetReg or there're possible exceptions in these instructions,\n\
      77:   // only one instruction is allowed to commit\n78:   val allowOnlyOne =
      io.allowOnlyOneCommit\n79:   val commitCnt = Mux(allowOnlyOne, canCommit(realCommitLast.value),
      normalCommitCnt)\n80:   val allowOnlyOneCond = Wire(chiselTypeOf(io.canCommitPriorityCond))\n\
      81:   allowOnlyOneCond.zipWithIndex.map{ case (value,i) => {\n82:     if (i==0)
      value := false.B\n83:     else value := Mux((i-1).U === deqPosition, canCommit(deqPosition),
      false.B)\n84:   }\n85:   }\n86:   io.canCommitPriorityCond := Mux(allowOnlyOne,
      allowOnlyOneCond, VecInit(canCommit.map(c => !c) :+ true.B))\n87: \n88:   val
      commitDeqPtrAll = VecInit((0 until 2*CommitWidth).map{case i => deqPtrVec(0).lineHeadPtr
      + i.U})\n89:   val commitDeqPtrVec = Wire(chiselTypeOf(deqPtrVec))\n90:   for
      (i <- 0 until CommitWidth){\n91:     commitDeqPtrVec(i) := PriorityMuxDefault(io.canCommitPriorityCond.zip(commitDeqPtrAll.drop(i).take(CommitWidth+1)),
      deqPtrVec(i))\n92:   }\n93:   val deqPtrVec_next = Mux(io.state === 0.U && !redirectOutValid
      && !io.blockCommit, commitDeqPtrVec, deqPtrVec)\n94: \n95:   deqPtrVec := deqPtrVec_next\n\
      96: \n97:   io.next_out := deqPtrVec_next\n98:   io.out      := deqPtrVec"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobDeqPtrWrapper.scala
    lines: 94-111
    context: "94: \n95:   deqPtrVec := deqPtrVec_next\n96: \n97:   io.next_out :=
      deqPtrVec_next\n98:   io.out      := deqPtrVec\n99:   io.commitCnt := commitCnt\n\
      100:   io.commitEn := io.state === 0.U && !redirectOutValid && !io.blockCommit\n\
      101: \n102:   XSInfo(io.state === 0.U && commitCnt > 0.U, \"retired %d insts\\\
      n\", commitCnt)\n103: \n104:   if(backendParams.debugEn){\n105:     dontTouch(commitDeqPtrVec)\n\
      106:     dontTouch(commitDeqPtrAll)\n107:     dontTouch(allowOnlyOneCond)\n\
      108:     dontTouch(io.canCommitPriorityCond)\n109:     dontTouch(redirectOutValid)\n\
      110:   }\n111: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 62-74
    context: "62:   private val StaCnt = params.StaCnt\n63:   private val HyuCnt =
      params.HyuCnt\n64: \n65:   val io = IO(new Bundle() {\n66:     val hartId =
      Input(UInt(hartIdLen.W))\n67:     val redirect = Input(Valid(new Redirect))\n\
      68:     val enq = new RobEnqIO\n69:     val flushOut = ValidIO(new Redirect)\n\
      70:     val exception = ValidIO(new ExceptionInfo)\n71:     // exu + brq\n72:\
      \     val writeback: MixedVec[ValidIO[ExuOutput]] = Flipped(params.genWrite2CtrlBundles)\n\
      73:     val exuWriteback: MixedVec[ValidIO[ExuOutput]] = Flipped(params.genWrite2CtrlBundles)\n\
      74:     val writebackNums = Flipped(Vec(writeback.size - params.StdCnt, ValidIO(UInt(writeback.size.U.getWidth.W))))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 71-87
    context: "71:     // exu + brq\n72:     val writeback: MixedVec[ValidIO[ExuOutput]]
      = Flipped(params.genWrite2CtrlBundles)\n73:     val exuWriteback: MixedVec[ValidIO[ExuOutput]]
      = Flipped(params.genWrite2CtrlBundles)\n74:     val writebackNums = Flipped(Vec(writeback.size
      - params.StdCnt, ValidIO(UInt(writeback.size.U.getWidth.W))))\n75:     val writebackNeedFlush
      = Input(Vec(params.allExuParams.filter(_.needExceptionGen).length, Bool()))\n\
      76:     val commits = Output(new RobCommitIO)\n77:     val trace = new Bundle
      {\n78:       val blockCommit = Input(Bool())\n79:       val traceCommitInfo
      = new TraceBundle(hasIaddr = false, CommitWidth, IretireWidthInPipe)\n80:  \
      \   }\n81:     val rabCommits = Output(new RabCommitIO)\n82:     val diffCommits
      = if (backendParams.basicDebugEn) Some(Output(new DiffCommitIO)) else None\n\
      83:     val isVsetFlushPipe = Output(Bool())\n84:     val lsq = new RobLsqIO\n\
      85:     val robDeqPtr = Output(new RobPtr)\n86:     val csr = new RobCSRIO\n\
      87:     val snpt = Input(new SnapshotPort)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 96-106
    context: "96:     val wfi_enable = Input(Bool())\n97:     val toDecode = new Bundle
      {\n98:       val isResumeVType = Output(Bool())\n99:       val walkToArchVType
      = Output(Bool())\n100:       val walkVType = ValidIO(VType())\n101:       val
      commitVType = new Bundle {\n102:         val vtype = ValidIO(VType())\n103:\
      \         val hasVsetvl = Output(Bool())\n104:       }\n105:     }\n106:   \
      \  val fromVecExcpMod = Input(new Bundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 112-122
    context: "112:     })\n113:     val readGPAMemData = Input(new GPAMemEntry)\n\
      114:     val vstartIsZero = Input(Bool())\n115: \n116:     val toVecExcpMod
      = Output(new Bundle {\n117:       val logicPhyRegMap = Vec(RabCommitWidth, ValidIO(new
      RegWriteFromRab))\n118:       val excpInfo = ValidIO(new VecExcpInfo)\n119:\
      \     })\n120:     val debug_ls = Flipped(new DebugLSIO)\n121:     val debugRobHead
      = Output(new DynInst)\n122:     val debugEnqLsq = Input(new LsqEnqIO)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 140-150
    context: "140:   val exuWBs: Seq[ValidIO[ExuOutput]] = io.exuWriteback.filter(!_.bits.params.hasStdFu).toSeq\n\
      141:   val stdWBs: Seq[ValidIO[ExuOutput]] = io.exuWriteback.filter(_.bits.params.hasStdFu).toSeq\n\
      142:   val vldWBs: Seq[ValidIO[ExuOutput]] = io.exuWriteback.filter(_.bits.params.hasVLoadFu).toSeq\n\
      143:   val fflagsWBs = io.exuWriteback.filter(x => x.bits.fflags.nonEmpty).toSeq\n\
      144:   val exceptionWBs = io.writeback.filter(x => x.bits.exceptionVec.nonEmpty).toSeq\n\
      145:   val redirectWBs = io.writeback.filter(x => x.bits.redirect.nonEmpty).toSeq\n\
      146:   val vxsatWBs = io.exuWriteback.filter(x => x.bits.vxsat.nonEmpty).toSeq\n\
      147:   val branchWBs = io.exuWriteback.filter(_.bits.params.hasBrhFu).toSeq\n\
      148:   val jmpWBs = io.exuWriteback.filter(_.bits.params.hasJmpFu).toSeq\n149:\
      \   val csrWBs = io.exuWriteback.filter(x => x.bits.params.hasCSR).toSeq\n150: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 154-166
    context: "154:     PerfCCT.updateInstPos(wb.bits.debug_seqNum, PerfCCT.InstPos.AtWriteVal.id.U,
      wb.valid, clock, reset)\n155:   }\n156: \n157:   val numExuWbPorts = exuWBs.length\n\
      158:   val numStdWbPorts = stdWBs.length\n159:   val bankAddrWidth = log2Up(CommitWidth)\n\
      160: \n161:   println(s\"Rob: size $RobSize, numExuWbPorts: $numExuWbPorts,
      numStdWbPorts: $numStdWbPorts, commitwidth: $CommitWidth\")\n162: \n163:   val
      rab = Module(new RenameBuffer(RabSize))\n164:   val vtypeBuffer = Module(new
      VTypeBuffer(VTypeBufferSize))\n165:   val bankNum = 8\n166:   assert(RobSize
      % bankNum == 0, \"RobSize % bankNum must be 0\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 166-178
    context: "166:   assert(RobSize % bankNum == 0, \"RobSize % bankNum must be 0\"\
      )\n167:   val robEntries = RegInit(VecInit.fill(RobSize)((new RobEntryBundle).Lit(_.valid
      -> false.B)))\n168:   // pointers\n169:   // For enqueue ptr, we don't duplicate
      it since only enqueue needs it.\n170:   val enqPtrVec = Wire(Vec(RenameWidth,
      new RobPtr))\n171:   val deqPtrVec = Wire(Vec(CommitWidth, new RobPtr))\n172:\
      \   val deqPtrVec_next = Wire(Vec(CommitWidth, Output(new RobPtr)))\n173:  \
      \ val walkPtrVec = Reg(Vec(CommitWidth, new RobPtr))\n174:   val walkPtrTrue
      = Reg(new RobPtr)\n175:   val lastWalkPtr = Reg(new RobPtr)\n176:   val allowEnqueue
      = RegInit(true.B)\n177:   val allowEnqueueForDispatch = RegInit(true.B)\n178:\
      \   val vecExcpInfo = RegInit(ValidIO(new VecExcpInfo).Lit("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 196-206
    context: "196:   val timer = GTimer()\n197:   // robEntries enqueue\n198:   for
      (i <- 0 until RobSize) {\n199:     val enqOH = VecInit(canEnqueue.zip(allocatePtrVec.map(_.value
      === i.U)).map(x => x._1 && x._2))\n200:     assert(PopCount(enqOH) < 2.U, s\"\
      robEntries$i enqOH is not one hot\")\n201:     when(enqOH.asUInt.orR && !io.redirect.valid){\n\
      202:       connectEnq(robEntries(i), Mux1H(enqOH, io.enq.req.map(_.bits)))\n\
      203:     }\n204:   }\n205:   // robBanks0 include robidx : 0 8 16 24 32 ...\n\
      206:   val robBanks = VecInit((0 until bankNum).map(i => VecInit(robEntries.zipWithIndex.filter(_._2
      % bankNum == i).map(_._1))))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 223-254
    context: "223:   })\n224:   val robBanksRdataNextLine = VecInit(robBanks.map{
      case bank =>\n225:     val shiftBank = bank.drop(1) :+ bank(0)\n226:     Mux1H(robBanksRaddrThisLine,
      shiftBank)\n227:   })\n228:   val robBanksRdataThisLineUpdate = Wire(Vec(CommitWidth,
      new RobEntryBundle))\n229:   val robBanksRdataNextLineUpdate = Wire(Vec(CommitWidth,
      new RobEntryBundle))\n230:   val commitValidThisLine = Wire(Vec(CommitWidth,
      Bool()))\n231:   val hasCommitted = RegInit(VecInit(Seq.fill(CommitWidth)(false.B)))\n\
      232:   val donotNeedWalk = RegInit(VecInit(Seq.fill(CommitWidth)(false.B)))\n\
      233:   val allCommitted = Wire(Bool())\n234: \n235:   when(allCommitted) {\n\
      236:     hasCommitted := 0.U.asTypeOf(hasCommitted)\n237:   }.elsewhen(io.commits.isCommit){\n\
      238:     for (i <- 0 until CommitWidth){\n239:       hasCommitted(i) := commitValidThisLine(i)
      || hasCommitted(i)\n240:     }\n241:   }\n242:   allCommitted := io.commits.isCommit
      && commitValidThisLine.last\n243:   val walkPtrHead = Wire(new RobPtr)\n244:\
      \   val changeBankAddrToDeqPtr = (walkPtrVec.head + CommitWidth.U) > lastWalkPtr\n\
      245:   when(io.redirect.valid){\n246:     robBanksRaddrNextLine := UIntToOH(walkPtrHead.value(walkPtrHead.value.getWidth-1,
      bankAddrWidth))\n247:   }.elsewhen(allCommitted || io.commits.isWalk && !changeBankAddrToDeqPtr){\n\
      248:     robBanksRaddrNextLine := Mux(robBanksRaddrThisLine.head(1) === 1.U,
      1.U, robBanksRaddrThisLine << 1)\n249:   }.elsewhen(io.commits.isWalk && changeBankAddrToDeqPtr){\n\
      250:     robBanksRaddrNextLine := UIntToOH(deqPtr.value(deqPtr.value.getWidth-1,
      bankAddrWidth))\n251:   }.otherwise(\n252:     robBanksRaddrNextLine := robBanksRaddrThisLine\n\
      253:   )\n254:   val robDeqGroup = Reg(Vec(bankNum, new RobCommitEntryBundle))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 250-265
    context: "250:     robBanksRaddrNextLine := UIntToOH(deqPtr.value(deqPtr.value.getWidth-1,
      bankAddrWidth))\n251:   }.otherwise(\n252:     robBanksRaddrNextLine := robBanksRaddrThisLine\n\
      253:   )\n254:   val robDeqGroup = Reg(Vec(bankNum, new RobCommitEntryBundle))\n\
      255:   val rawInfo = VecInit((0 until CommitWidth).map(i => robDeqGroup(deqPtrVec(i).value(bankAddrWidth-1,
      0)))).toSeq\n256:   val commitInfo = VecInit((0 until CommitWidth).map(i =>
      robDeqGroup(deqPtrVec(i).value(bankAddrWidth-1,0)))).toSeq\n257:   val walkInfo
      = VecInit((0 until CommitWidth).map(i => robDeqGroup(walkPtrVec(i).value(bankAddrWidth-1,
      0)))).toSeq\n258:   for (i <- 0 until CommitWidth) {\n259:     connectCommitEntry(robDeqGroup(i),
      robBanksRdataThisLineUpdate(i))\n260:     when(allCommitted){\n261:       connectCommitEntry(robDeqGroup(i),
      robBanksRdataNextLineUpdate(i))\n262:     }\n263:   }\n264: \n265:   // In each
      robentry, the ftqIdx and ftqOffset belong to the first instruction that was
      compressed,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 264-276
    context: "264: \n265:   // In each robentry, the ftqIdx and ftqOffset belong to
      the first instruction that was compressed,\n266:   // That is Necessary when
      exceptions happen.\n267:   // Update the ftqOffset to correctly notify the frontend
      which instructions have been committed.\n268:   // Instructions in multiple
      Ftq entries compressed to one RobEntry do not occur.\n269:   for (i <- 0 until
      CommitWidth) {\n270:     val lastOffset = (rawInfo(i).traceBlockInPipe.iretire
      - (1.U << rawInfo(i).traceBlockInPipe.ilastsize.asUInt).asUInt) + rawInfo(i).ftqOffset\n\
      271:     commitInfo(i).ftqOffset := Mux(CommitType.isFused(rawInfo(i).commitType),
      rawInfo(i).ftqOffset, lastOffset)\n272:   }\n273: \n274:   // data for debug\n\
      275:   // Warn: debug_* prefix should not exist in generated verilog.\n276:\
      \   val debug_microOp = DebugMem(RobSize, new DynInst)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 281-296
    context: "281:   val debug_lqIdxValid = RegInit(VecInit.fill(RobSize)(false.B))\n\
      282:   val debug_lsIssued = RegInit(VecInit.fill(RobSize)(false.B))\n283: \n\
      284:   val isEmpty = enqPtr === deqPtr\n285:   val snptEnq = io.enq.canAccept
      && io.enq.req.map(x => x.valid && x.bits.snapshot).reduce(_ || _)\n286:   val
      snapshotPtrVec = Wire(Vec(CommitWidth, new RobPtr))\n287:   snapshotPtrVec(0)
      := io.enq.req(0).bits.robIdx\n288:   for (i <- 1 until CommitWidth) {\n289:\
      \     snapshotPtrVec(i) := snapshotPtrVec(0) + i.U\n290:   }\n291:   val snapshots
      = SnapshotGenerator(snapshotPtrVec, snptEnq, io.snpt.snptDeq, io.redirect.valid,
      io.snpt.flushVec)\n292:   val debug_lsIssue = WireDefault(debug_lsIssued)\n\
      293:   debug_lsIssue(deqPtr.value) := io.debugHeadLsIssue\n294: \n295:   /**\n\
      296:    * states of Rob"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 300-312
    context: "300:   val state_next = Wire(chiselTypeOf(state))\n301: \n302:   val
      tip_computing :: tip_stalled :: tip_walk :: tip_drained :: Nil = Enum(4)\n303:\
      \   val tip_state = WireInit(0.U(4.W))\n304:   when(!isEmpty) {  // One or more
      inst in ROB\n305:     when(state === s_walk || io.redirect.valid) {\n306:  \
      \     tip_state := tip_walk\n307:     }.elsewhen(io.commits.isCommit && PopCount(io.commits.commitValid)
      =/= 0.U) {\n308:       tip_state := tip_computing\n309:     }.otherwise {\n\
      310:       tip_state := tip_stalled\n311:     }\n312:   }.otherwise {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 312-324
    context: "312:   }.otherwise {\n313:     tip_state := tip_drained\n314:   }\n\
      315:   class TipEntry()(implicit p: Parameters) extends XSBundle {\n316:   \
      \  val state = UInt(4.W)\n317:     val commits = new RobCommitIO()      // info
      of commit\n318:     val redirect = Valid(new Redirect)   // info of redirect\n\
      319:     val redirect_pc = UInt(VAddrBits.W)  // PC of the redirect uop\n320:\
      \     val debugLsInfo = new DebugLsInfo()\n321:   }\n322:   val tip_table =
      ChiselDB.createTable(\"Tip_\" + p(XSCoreParamsKey).HartId.toString, new TipEntry)\n\
      323:   val tip_data = Wire(new TipEntry())\n324:   tip_data.state := tip_state"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 320-339
    context: "320:     val debugLsInfo = new DebugLsInfo()\n321:   }\n322:   val tip_table
      = ChiselDB.createTable(\"Tip_\" + p(XSCoreParamsKey).HartId.toString, new TipEntry)\n\
      323:   val tip_data = Wire(new TipEntry())\n324:   tip_data.state := tip_state\n\
      325:   tip_data.commits := io.commits\n326:   tip_data.redirect := io.redirect\n\
      327:   tip_data.redirect_pc := debug_microOp(io.redirect.bits.robIdx.value).pc\n\
      328:   tip_data.debugLsInfo := debug_lsInfo(io.commits.robIdx(0).value)\n329:\
      \   tip_table.log(tip_data, true.B, \"\", clock, reset)\n330: \n331:   val exceptionGen
      = Module(new ExceptionGen(params))\n332:   val exceptionDataRead = exceptionGen.io.state\n\
      333:   val fflagsDataRead = Wire(Vec(CommitWidth, UInt(5.W)))\n334:   val vxsatDataRead
      = Wire(Vec(CommitWidth, Bool()))\n335:   io.robDeqPtr := deqPtr\n336:   io.debugRobHead
      := debug_microOp(deqPtr.value)\n337: \n338:   /**\n339:    * connection of [[rab]]"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 336-346
    context: "336:   io.debugRobHead := debug_microOp(deqPtr.value)\n337: \n338: \
      \  /**\n339:    * connection of [[rab]]\n340:    */\n341:   rab.io.redirect.valid
      := io.redirect.valid\n342: \n343:   rab.io.req.zip(io.enq.req).map { case (dest,
      src) =>\n344:     dest.bits := src.bits\n345:     dest.valid := src.valid &&
      io.enq.canAccept\n346:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 343-360
    context: "343:   rab.io.req.zip(io.enq.req).map { case (dest, src) =>\n344:  \
      \   dest.bits := src.bits\n345:     dest.valid := src.valid && io.enq.canAccept\n\
      346:   }\n347: \n348:   val walkDestSizeDeqGroup = RegInit(VecInit(Seq.fill(CommitWidth)(0.U(log2Up(MaxUopSize
      + 1).W))))\n349:   val realDestSizeSeq = VecInit(robDeqGroup.zip(hasCommitted).map{case
      (r, h) => Mux(h, 0.U, r.realDestSize)})\n350:   val walkDestSizeSeq = VecInit(robDeqGroup.zip(donotNeedWalk).map{case
      (r, d) => Mux(d, 0.U, r.realDestSize)})\n351:   val commitSizeSumSeq = VecInit((0
      until CommitWidth).map(i => realDestSizeSeq.take(i + 1).reduce(_ +& _)))\n352:\
      \   val walkSizeSumSeq   = VecInit((0 until CommitWidth).map(i => walkDestSizeSeq.take(i
      + 1).reduce(_ +& _)))\n353:   val commitSizeSumCond = VecInit(commitValidThisLine.zip(hasCommitted).map{case
      (c,h) => (c || h) && io.commits.isCommit})\n354:   val walkSizeSumCond   = VecInit(io.commits.walkValid.zip(donotNeedWalk).map{case
      (w,d) => (w || d) && io.commits.isWalk})\n355:   val commitSizeSum = PriorityMuxDefault(commitSizeSumCond.reverse.zip(commitSizeSumSeq.reverse),
      0.U)\n356:   val walkSizeSum   = PriorityMuxDefault(walkSizeSumCond.reverse.zip(walkSizeSumSeq.reverse),
      0.U)\n357: \n358:   val deqVlsExceptionNeedCommit = RegInit(false.B)\n359: \
      \  val deqVlsExceptionCommitSize = RegInit(0.U(log2Up(MaxUopSize + 1).W))\n\
      360:   val deqVlsCanCommit= RegInit(false.B)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 356-366
    context: "356:   val walkSizeSum   = PriorityMuxDefault(walkSizeSumCond.reverse.zip(walkSizeSumSeq.reverse),
      0.U)\n357: \n358:   val deqVlsExceptionNeedCommit = RegInit(false.B)\n359: \
      \  val deqVlsExceptionCommitSize = RegInit(0.U(log2Up(MaxUopSize + 1).W))\n\
      360:   val deqVlsCanCommit= RegInit(false.B)\n361:   rab.io.fromRob.commitSize
      := Mux(deqVlsExceptionNeedCommit, deqVlsExceptionCommitSize, commitSizeSum)\n\
      362:   rab.io.fromRob.walkSize := walkSizeSum\n363:   rab.io.fromRob.vecLoadExcp.valid
      := RegNext(exceptionDataRead.valid && exceptionDataRead.bits.isVecLoad)\n364:\
      \   rab.io.fromRob.vecLoadExcp.bits.isStrided := RegEnable(exceptionDataRead.bits.isStrided,
      exceptionDataRead.valid)\n365:   rab.io.fromRob.vecLoadExcp.bits.isVlm := RegEnable(exceptionDataRead.bits.isVlm,
      exceptionDataRead.valid)\n366:   rab.io.snpt := io.snpt"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 365-376
    context: "365:   rab.io.fromRob.vecLoadExcp.bits.isVlm := RegEnable(exceptionDataRead.bits.isVlm,
      exceptionDataRead.valid)\n366:   rab.io.snpt := io.snpt\n367:   rab.io.snpt.snptEnq
      := snptEnq\n368: \n369:   // pipe rab commits for better timing and area\n370:\
      \   io.rabCommits := RegNext(rab.io.commits)\n371:   io.diffCommits.foreach(_
      := rab.io.diffCommits.get)\n372: \n373:   /**\n374:    * connection of [[vtypeBuffer]]\n\
      375:    */\n376: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 372-382
    context: "372: \n373:   /**\n374:    * connection of [[vtypeBuffer]]\n375:   \
      \ */\n376: \n377:   vtypeBuffer.io.redirect.valid := io.redirect.valid\n378:\
      \ \n379:   vtypeBuffer.io.req.zip(io.enq.req).map { case (sink, source) =>\n\
      380:     sink.valid := source.valid && io.enq.canAccept\n381:     sink.bits
      := source.bits\n382:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 379-396
    context: "379:   vtypeBuffer.io.req.zip(io.enq.req).map { case (sink, source)
      =>\n380:     sink.valid := source.valid && io.enq.canAccept\n381:     sink.bits
      := source.bits\n382:   }\n383: \n384:   private val commitIsVTypeVec = VecInit(io.commits.commitValid.zip(io.commits.info).map
      { case (valid, info) => io.commits.isCommit && valid && info.isVset })\n385:\
      \   private val walkIsVTypeVec = VecInit(io.commits.walkValid.zip(walkInfo).map
      { case (valid, info) => io.commits.isWalk && valid && info.isVset })\n386: \
      \  vtypeBuffer.io.fromRob.commitSize := PopCount(commitIsVTypeVec)\n387:   vtypeBuffer.io.fromRob.walkSize
      := PopCount(walkIsVTypeVec)\n388:   vtypeBuffer.io.snpt := io.snpt\n389:   vtypeBuffer.io.snpt.snptEnq
      := snptEnq\n390:   io.toDecode.walkToArchVType := vtypeBuffer.io.toDecode.walkToArchVType\n\
      391:   io.toDecode.commitVType := vtypeBuffer.io.toDecode.commitVType\n392:\
      \   io.toDecode.walkVType := vtypeBuffer.io.toDecode.walkVType\n393: \n394:\
      \   // When blockBackward instruction leaves Rob (commit or walk), hasBlockBackward
      should be set to false.B\n395:   // To reduce registers usage, for hasBlockBackward
      cases, we allow enqueue after ROB is empty.\n396:   when(isEmpty) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 395-405
    context: "395:   // To reduce registers usage, for hasBlockBackward cases, we
      allow enqueue after ROB is empty.\n396:   when(isEmpty) {\n397:     hasBlockBackward
      := false.B\n398:   }\n399:   // When any instruction commits, hasNoSpecExec
      should be set to false.B\n400:   when(io.commits.hasWalkInstr || io.commits.hasCommitInstr)
      {\n401:     hasWaitForward := false.B\n402:   }\n403: \n404:   // The wait-for-interrupt
      (WFI) instruction waits in the ROB until an interrupt might need servicing.\n\
      405:   // io.csr.wfiEvent will be asserted if the WFI can resume execution,
      and we change the state to s_wfi_idle."
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 495-510
    context: "495:       firstVInstrRobIdx := firstVInstrWait.bits.robIdx\n496:  \
      \   }\n497:   }\n498: \n499:   val hasVInstrAfterI = Cat(enqIsVInstrVec(0)).orR\n\
      500:   when(vsetvlState === vs_idle && !io.redirect.valid) {\n501:     when(enq0IsVsetFlush)
      {\n502:       vsetvlState := Mux(hasVInstrAfterI, vs_waitFlush, vs_waitVinstr)\n\
      503:     }\n504:   }.elsewhen(vsetvlState === vs_waitVinstr) {\n505:     when(io.redirect.valid)
      {\n506:       vsetvlState := vs_idle\n507:     }.elsewhen(Cat(enqIsVInstrOrVset).orR)
      {\n508:       vsetvlState := vs_waitFlush\n509:     }\n510:   }.elsewhen(vsetvlState
      === vs_waitFlush) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 506-516
    context: "506:       vsetvlState := vs_idle\n507:     }.elsewhen(Cat(enqIsVInstrOrVset).orR)
      {\n508:       vsetvlState := vs_waitFlush\n509:     }\n510:   }.elsewhen(vsetvlState
      === vs_waitFlush) {\n511:     when(io.redirect.valid) {\n512:       vsetvlState
      := vs_idle\n513:     }\n514:   }\n515: \n516:   // lqEnq"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 565-589
    context: "565:    * RedirectOut: Interrupt and Exceptions\n566:    */\n567:  \
      \ val debug_deqUop = debug_microOp(deqPtr.value)\n568: \n569:   val deqPtrEntry
      = rawInfo(0)\n570:   val deqPtrEntryValid = deqPtrEntry.commit_v\n571:   val
      deqHasFlushed = RegInit(false.B)\n572:   val intrBitSetReg = RegNext(io.csr.intrBitSet)\n\
      573:   val intrEnable = intrBitSetReg && !hasWaitForward && deqPtrEntry.interrupt_safe
      && !deqHasFlushed\n574:   val deqNeedFlush = deqPtrEntry.needFlush && deqPtrEntry.commit_v
      && deqPtrEntry.commit_w\n575:   val deqHitExceptionGenState = exceptionDataRead.valid
      && exceptionDataRead.bits.robIdx === deqPtr\n576:   val deqNeedFlushAndHitExceptionGenState
      = deqNeedFlush && deqHitExceptionGenState\n577:   val exceptionGenStateIsException
      = exceptionDataRead.bits.exceptionVec.asUInt.orR || exceptionDataRead.bits.singleStep
      || TriggerAction.isDmode(exceptionDataRead.bits.trigger)\n578:   val deqHasException
      = deqNeedFlushAndHitExceptionGenState && exceptionGenStateIsException && (!deqPtrEntry.isVls
      || RegNext(RegNext(deqPtrEntry.commit_w)))\n579:   val deqHasFlushPipe = deqNeedFlushAndHitExceptionGenState
      && exceptionDataRead.bits.flushPipe && !deqHasException && (!deqPtrEntry.isVls
      || RegNext(RegNext(deqPtrEntry.commit_w)))\n580:   val deqHasReplayInst = deqNeedFlushAndHitExceptionGenState
      && exceptionDataRead.bits.replayInst\n581:   val deqIsVlsException = deqHasException
      && deqPtrEntry.isVls && !exceptionDataRead.bits.isEnqExcp\n582:   // delay 2
      cycle wait exceptionGen out\n583:   // vls exception can be committed only when
      RAB commit all its reg pairs\n584:   deqVlsCanCommit := RegNext(RegNext(deqIsVlsException
      && deqPtrEntry.commit_w)) && rab.io.status.commitEnd\n585: \n586:   // lock
      at assertion of deqVlsExceptionNeedCommit until condition not assert\n587: \
      \  val deqVlsExcpLock = RegInit(false.B)\n588:   val handleVlsExcp = deqIsVlsException
      && deqVlsCanCommit && !deqVlsExcpLock && state === s_idle\n589:   when(handleVlsExcp)
      {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 601-614
    context: "601:   }\n602: \n603:   XSDebug(deqHasException && exceptionDataRead.bits.singleStep,
      \"Debug Mode: Deq has singlestep exception\\n\")\n604:   XSDebug(deqHasException
      && TriggerAction.isDmode(exceptionDataRead.bits.trigger), \"Debug Mode: Deq
      has trigger entry debug Mode\\n\")\n605: \n606:   val isFlushPipe = deqPtrEntry.commit_w
      && (deqHasFlushPipe || deqHasReplayInst)\n607: \n608:   // vsetvl instruction
      need another one cycle to write to vtype gen\n609:   val isVsetFlushPipe = deqPtrEntry.commit_w
      && deqHasFlushed && exceptionDataRead.bits.isVset\n610:   val isVsetFlushPipeReg
      = RegNext(isVsetFlushPipe)\n611:   //  val needModifyFtqIdxOffset = isVsetFlushPipe
      && (vsetvlState === vs_waitFlush)\n612:   val needModifyFtqIdxOffset = false.B\n\
      613:   io.isVsetFlushPipe := isVsetFlushPipe\n614:   io.toDecode.isResumeVType
      := vtypeBuffer.io.toDecode.isResumeVType || isVsetFlushPipeReg"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 634-644
    context: "634:   io.exception.valid := RegNext(exceptionHappen)\n635:   io.exception.bits.pc
      := RegEnable(debug_deqUop.pc, exceptionHappen)\n636:   io.exception.bits.gpaddr
      := io.readGPAMemData.gpaddr\n637:   io.exception.bits.isForVSnonLeafPTE := io.readGPAMemData.isForVSnonLeafPTE\n\
      638:   io.exception.bits.instr := RegEnable(debug_deqUop.instr, exceptionHappen)\n\
      639:   io.exception.bits.commitType := RegEnable(deqPtrEntry.commitType, exceptionHappen)\n\
      640:   io.exception.bits.exceptionVec := RegEnable(exceptionDataRead.bits.exceptionVec,
      exceptionHappen)\n641:   // fetch trigger fire or execute ebreak\n642:   io.exception.bits.isPcBkpt
      := RegEnable(\n643:     exceptionDataRead.bits.exceptionVec(ExceptionNO.EX_BP)
      && (\n644:       exceptionDataRead.bits.isEnqExcp ||"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 658-668
    context: "658:   io.readGPAMemAddr.valid := exceptionHappen\n659:   io.readGPAMemAddr.bits.ftqPtr
      := exceptionDataRead.bits.ftqPtr\n660:   io.readGPAMemAddr.bits.ftqOffset :=
      exceptionDataRead.bits.ftqOffset\n661: \n662:   XSDebug(io.flushOut.valid,\n\
      663:     p\"generate redirect: pc 0x${Hexadecimal(io.exception.bits.pc)} intr
      $intrEnable \" +\n664:       p\"excp $deqHasException flushPipe $isFlushPipe
      \" +\n665:       p\"Trap_target 0x${Hexadecimal(io.csr.trapTarget.pc)} exceptionVec
      ${Binary(exceptionDataRead.bits.exceptionVec.asUInt)}\\n\")\n666: \n667: \n\
      668:   /**"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 668-682
    context: "668:   /**\n669:    * Commits (and walk)\n670:    * They share the same
      width.\n671:    */\n672:   // T redirect.valid, T+1 use walkPtrVec read robEntries,
      T+2 start walk, shouldWalkVec used in T+2\n673:   val shouldWalkVec = Wire(Vec(CommitWidth,Bool()))\n\
      674:   val walkingPtrVec = RegNext(walkPtrVec)\n675:   when(io.redirect.valid){\n\
      676:     shouldWalkVec := 0.U.asTypeOf(shouldWalkVec)\n677:   }.elsewhen(RegNext(io.redirect.valid)){\n\
      678:     shouldWalkVec := 0.U.asTypeOf(shouldWalkVec)\n679:   }.elsewhen(state
      === s_walk){\n680:     shouldWalkVec := VecInit(walkingPtrVec.map(_ <= lastWalkPtr).zip(donotNeedWalk).map(x
      => x._1 && !x._2))\n681:   }.otherwise(\n682:     shouldWalkVec := 0.U.asTypeOf(shouldWalkVec)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 683-714
    context: "683:   )\n684:   val walkFinished = walkPtrTrue > lastWalkPtr\n685:\
      \   rab.io.fromRob.walkEnd := state === s_walk && walkFinished\n686:   vtypeBuffer.io.fromRob.walkEnd
      := state === s_walk && walkFinished\n687: \n688:   require(RenameWidth <= CommitWidth)\n\
      689: \n690:   // wiring to csr\n691:   val (wflags, dirtyFs) = (0 until CommitWidth).map(i
      => {\n692:     val v = io.commits.commitValid(i)\n693:     val info = io.commits.info(i)\n\
      694:     (v & info.wflags, v & info.dirtyFs)\n695:   }).unzip\n696:   val fflags
      = Wire(Valid(UInt(5.W)))\n697:   fflags.valid := io.commits.isCommit && VecInit(wflags).asUInt.orR\n\
      698:   fflags.bits := wflags.zip(fflagsDataRead).map({\n699:     case (w, f)
      => Mux(w, f, 0.U)\n700:   }).reduce(_ | _)\n701:   val dirtyVs = (0 until CommitWidth).map(i
      => {\n702:     val v = io.commits.commitValid(i)\n703:     val info = io.commits.info(i)\n\
      704:     v & info.dirtyVs\n705:   })\n706:   val dirty_fs = io.commits.isCommit
      && VecInit(dirtyFs).asUInt.orR\n707:   val dirty_vs = io.commits.isCommit &&
      VecInit(dirtyVs).asUInt.orR\n708: \n709:   val resetVstart = dirty_vs && !io.vstartIsZero\n\
      710: \n711:   vecExcpInfo.valid := exceptionHappen && !intrEnable && exceptionDataRead.bits.vstartEn
      && exceptionDataRead.bits.isVecLoad && !exceptionDataRead.bits.isEnqExcp\n712:\
      \   when (exceptionHappen) {\n713:     vecExcpInfo.bits.nf := exceptionDataRead.bits.nf\n\
      714:     vecExcpInfo.bits.vsew := exceptionDataRead.bits.vsew"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 723-734
    context: "723: \n724:   io.csr.vstart.valid := RegNext(Mux(exceptionHappen &&
      deqHasException, exceptionDataRead.bits.vstartEn, resetVstart))\n725:   io.csr.vstart.bits
      := RegNext(Mux(exceptionHappen && deqHasException, exceptionDataRead.bits.vstart,
      0.U))\n726: \n727:   val vxsat = Wire(Valid(Bool()))\n728:   vxsat.valid :=
      io.commits.isCommit && vxsat.bits\n729:   vxsat.bits := io.commits.commitValid.zip(vxsatDataRead).map
      {\n730:     case (valid, vxsat) => valid & vxsat\n731:   }.reduce(_ | _)\n732:\
      \ \n733:   // when mispredict branches writeback, stop commit in the next 2
      cycles\n734:   // TODO: don't check all exu write back"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 731-741
    context: "731:   }.reduce(_ | _)\n732: \n733:   // when mispredict branches writeback,
      stop commit in the next 2 cycles\n734:   // TODO: don't check all exu write
      back\n735:   val misPredWb = Cat(VecInit(redirectWBs.map(wb =>\n736:     wb.bits.redirect.get.bits.cfiUpdate.isMisPred
      && wb.bits.redirect.get.valid && wb.valid\n737:   ).toSeq)).orR\n738:   val
      misPredBlockCounter = Reg(UInt(3.W))\n739:   misPredBlockCounter := Mux(misPredWb,\n\
      740:     \"b111\".U,\n741:     misPredBlockCounter >> 1.U"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 741-754
    context: "741:     misPredBlockCounter >> 1.U\n742:   )\n743:   val misPredBlock
      = misPredBlockCounter(0)\n744:   val deqFlushBlockCounter = Reg(UInt(3.W))\n\
      745:   val deqFlushBlock = deqFlushBlockCounter(0)\n746:   val deqHasCommitted
      = io.commits.isCommit && io.commits.commitValid(0)\n747:   // TODO *** WARNING
      ***\n748:   // Blocking commit. Don't change this before we fully understand
      the logic.\n749:   val deqHitRedirectReg = RegNext(io.redirect.valid && io.redirect.bits.robIdx
      === deqPtr) || RegNext(RegNext(io.redirect.valid && io.redirect.bits.robIdx
      === deqPtr))\n750:   val criticalErrorState = io.csr.criticalErrorState\n751:\
      \   when(deqNeedFlush && deqHitRedirectReg){\n752:     deqFlushBlockCounter
      := \"b111\".U\n753:   }.otherwise{\n754:     deqFlushBlockCounter := deqFlushBlockCounter
      >> 1.U"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 751-813
    context: "751:   when(deqNeedFlush && deqHitRedirectReg){\n752:     deqFlushBlockCounter
      := \"b111\".U\n753:   }.otherwise{\n754:     deqFlushBlockCounter := deqFlushBlockCounter
      >> 1.U\n755:   }\n756:   when(deqHasCommitted){\n757:     deqHasFlushed := false.B\n\
      758:   }.elsewhen(deqNeedFlush && io.flushOut.valid && !io.flushOut.bits.flushItself()){\n\
      759:     deqHasFlushed := true.B\n760:   }\n761:   val traceBlock = io.trace.blockCommit\n\
      762:   val blockCommit = misPredBlock || lastCycleFlush || hasWFI || io.redirect.valid
      ||\n763:     (deqNeedFlush && !deqHasFlushed) || deqFlushBlock || criticalErrorState
      || traceBlock\n764: \n765:   io.commits.isWalk := state === s_walk\n766:   io.commits.isCommit
      := state === s_idle && !blockCommit\n767: \n768:   val walk_v = VecInit(walkingPtrVec.map(ptr
      => robEntries(ptr.value).valid))\n769:   val commit_vDeqGroup = VecInit(robDeqGroup.map(_.commit_v))\n\
      770:   val commit_wDeqGroup = VecInit(robDeqGroup.map(_.commit_w))\n771:   val
      realCommitLast = deqPtrVec(0).lineHeadPtr + Fill(bankAddrWidth, 1.U)\n772: \
      \  val commit_block = VecInit((0 until CommitWidth).map(i => !commit_wDeqGroup(i)
      && !hasCommitted(i)))\n773:   val allowOnlyOneCommit = VecInit(robDeqGroup.map(x
      => x.commit_v && x.needFlush)).asUInt.orR || intrBitSetReg\n774:   // for instructions
      that may block others, we don't allow them to commit\n775:   io.commits.commitValid
      := PriorityMux(commitValidThisLine, (0 until CommitWidth).map(i => (commitValidThisLine.asUInt
      >> i).asUInt.asTypeOf(io.commits.commitValid)))\n776: \n777:   for (i <- 0 until
      CommitWidth) {\n778:     // defaults: state === s_idle and instructions commit\n\
      779:     // when intrBitSetReg, allow only one instruction to commit at each
      clock cycle\n780:     val isBlocked = intrEnable || (deqNeedFlush && !deqHasFlushed)\n\
      781:     val isBlockedByOlder = if (i != 0) commit_block.asUInt(i, 0).orR ||
      allowOnlyOneCommit && !hasCommitted.asUInt(i - 1, 0).andR else false.B\n782:\
      \     commitValidThisLine(i) := commit_vDeqGroup(i) && commit_wDeqGroup(i) &&
      !isBlocked && !isBlockedByOlder && !hasCommitted(i)\n783:     io.commits.info(i)
      := commitInfo(i)\n784:     io.commits.robIdx(i) := deqPtrVec(i)\n785:     val
      deqDebugInst = debug_microOp(deqPtrVec(i).value)\n786:     PerfCCT.commitInstMeta(i.U,
      deqDebugInst.debug_seqNum, deqDebugInst.instrSize, io.commits.isCommit && io.commits.commitValid(i),
      clock, reset)\n787: \n788:     io.commits.walkValid(i) := shouldWalkVec(i)\n\
      789:     XSError(\n790:       state === s_walk &&\n791:       io.commits.isWalk
      && state === s_walk && shouldWalkVec(i) &&\n792:       !walk_v(i),\n793:   \
      \    s\"The walking entry($i) should be valid\\n\")\n794: \n795:     XSInfo(io.commits.isCommit
      && io.commits.commitValid(i),\n796:       \"retired pc %x wen %d ldest %d pdest
      %x data %x fflags: %b vxsat: %b\\n\",\n797:       debug_microOp(deqPtrVec(i).value).pc,\n\
      798:       io.commits.info(i).rfWen,\n799:       io.commits.info(i).debug_ldest.getOrElse(0.U),\n\
      800:       io.commits.info(i).debug_pdest.getOrElse(0.U),\n801:       debug_exuData(deqPtrVec(i).value),\n\
      802:       fflagsDataRead(i),\n803:       vxsatDataRead(i)\n804:     )\n805:\
      \     XSInfo(state === s_walk && io.commits.walkValid(i), \"walked pc %x wen
      %d ldst %d data %x\\n\",\n806:       debug_microOp(walkPtrVec(i).value).pc,\n\
      807:       io.commits.info(i).rfWen,\n808:       io.commits.info(i).debug_ldest.getOrElse(0.U),\n\
      809:       debug_exuData(walkPtrVec(i).value)\n810:     )\n811:   }\n812: \n\
      813:   // sync fflags/dirty_fs/vxsat to csr"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 810-837
    context: "810:     )\n811:   }\n812: \n813:   // sync fflags/dirty_fs/vxsat to
      csr\n814:   io.csr.fflags   := RegNextWithEnable(fflags)\n815:   io.csr.dirty_fs
      := GatedValidRegNext(dirty_fs)\n816:   io.csr.dirty_vs := GatedValidRegNext(dirty_vs)\n\
      817:   io.csr.vxsat    := RegNextWithEnable(vxsat)\n818: \n819:   // commit
      load/store to lsq\n820:   val ldCommitVec = VecInit((0 until CommitWidth).map(i
      => io.commits.commitValid(i) && io.commits.info(i).commitType === CommitType.LOAD))\n\
      821:   // TODO: Check if meet the require that only set scommit when commit
      scala store uop\n822:   val stCommitVec = VecInit((0 until CommitWidth).map(i
      => io.commits.commitValid(i) && io.commits.info(i).commitType === CommitType.STORE
      && !robEntries(deqPtrVec(i).value).vls ))\n823:   io.lsq.lcommit := RegNext(Mux(io.commits.isCommit,
      PopCount(ldCommitVec), 0.U))\n824:   io.lsq.scommit := RegNext(Mux(io.commits.isCommit,
      PopCount(stCommitVec), 0.U))\n825:   // indicate a pending load or store\n826:\
      \   io.lsq.pendingMMIOld := RegNext(io.commits.isCommit && io.commits.info(0).commitType
      === CommitType.LOAD && deqPtrEntryValid && deqPtrEntry.mmio)\n827:   io.lsq.pendingld
      := RegNext(io.commits.isCommit && io.commits.info(0).commitType === CommitType.LOAD
      && deqPtrEntryValid)\n828:   // TODO: Check if need deassert pendingst when
      it is vst\n829:   io.lsq.pendingst := RegNext(io.commits.isCommit && io.commits.info(0).commitType
      === CommitType.STORE && deqPtrEntryValid)\n830:   // TODO: Check if set correctly
      when vector store is at the head of ROB\n831:   io.lsq.pendingVst := RegNext(io.commits.isCommit
      && io.commits.info(0).commitType === CommitType.STORE && deqPtrEntryValid &&
      deqPtrEntry.vls)\n832:   io.lsq.commit := RegNext(io.commits.isCommit && io.commits.commitValid(0))\n\
      833:   io.lsq.pendingPtr := RegNext(deqPtr)\n834:   io.lsq.pendingPtrNext :=
      RegNext(deqPtrVec_next.head)\n835: \n836:   /**\n837:    * state changes"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 837-847
    context: "837:    * state changes\n838:    * (1) redirect: switch to s_walk\n\
      839:    * (2) walk: when walking comes to the end, switch to s_idle\n840:  \
      \  */\n841:   state_next := Mux(\n842:     io.redirect.valid || RegNext(io.redirect.valid),
      s_walk,\n843:     Mux(\n844:       state === s_walk && walkFinished && rab.io.status.walkEnd
      && vtypeBuffer.io.status.walkEnd, s_idle,\n845:       state\n846:     )\n847:\
      \   )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 854-865
    context: "854:   /**\n855:    * pointers and counters\n856:    */\n857:   val
      deqPtrGenModule = Module(new NewRobDeqPtrWrapper)\n858:   deqPtrGenModule.io.state
      := state\n859:   deqPtrGenModule.io.deq_v := commit_vDeqGroup\n860:   deqPtrGenModule.io.deq_w
      := commit_wDeqGroup\n861:   deqPtrGenModule.io.exception_state := exceptionDataRead\n\
      862:   deqPtrGenModule.io.intrBitSetReg := intrBitSetReg\n863:   deqPtrGenModule.io.hasNoSpecExec
      := hasWaitForward\n864:   deqPtrGenModule.io.allowOnlyOneCommit := allowOnlyOneCommit\n\
      865:   deqPtrGenModule.io.interrupt_safe := robDeqGroup(deqPtr.value(bankAddrWidth-1,0)).interrupt_safe"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 861-878
    context: "861:   deqPtrGenModule.io.exception_state := exceptionDataRead\n862:\
      \   deqPtrGenModule.io.intrBitSetReg := intrBitSetReg\n863:   deqPtrGenModule.io.hasNoSpecExec
      := hasWaitForward\n864:   deqPtrGenModule.io.allowOnlyOneCommit := allowOnlyOneCommit\n\
      865:   deqPtrGenModule.io.interrupt_safe := robDeqGroup(deqPtr.value(bankAddrWidth-1,0)).interrupt_safe\n\
      866:   deqPtrGenModule.io.blockCommit := blockCommit\n867:   deqPtrGenModule.io.hasCommitted
      := hasCommitted\n868:   deqPtrGenModule.io.allCommitted := allCommitted\n869:\
      \   deqPtrVec := deqPtrGenModule.io.out\n870:   deqPtrVec_next := deqPtrGenModule.io.next_out\n\
      871: \n872:   val enqPtrGenModule = Module(new RobEnqPtrWrapper)\n873:   enqPtrGenModule.io.redirect
      := io.redirect\n874:   enqPtrGenModule.io.allowEnqueue := allowEnqueue && rab.io.canEnq
      && !io.fromVecExcpMod.busy\n875:   enqPtrGenModule.io.hasBlockBackward := hasBlockBackward\n\
      876:   enqPtrGenModule.io.enq := VecInit(io.enq.req.map(req => req.valid &&
      req.bits.firstUop))\n877:   enqPtrVec := enqPtrGenModule.io.out\n878: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 878-895
    context: "878: \n879:   // next walkPtrVec:\n880:   // (1) redirect occurs: update
      according to state\n881:   // (2) walk: move forwards\n882:   val deqPtrReadBank
      = deqPtrVec_next(0).lineHeadPtr\n883:   val deqPtrVecForWalk = VecInit((0 until
      CommitWidth).map(i => deqPtrReadBank + i.U))\n884:   val snapPtrReadBank = snapshots(io.snpt.snptSelect)(0).lineHeadPtr\n\
      885:   val snapPtrVecForWalk = VecInit((0 until CommitWidth).map(i => snapPtrReadBank
      + i.U))\n886:   val walkPtrVec_next: Vec[RobPtr] = Mux(io.redirect.valid,\n\
      887:     Mux(io.snpt.useSnpt, snapPtrVecForWalk, deqPtrVecForWalk),\n888:  \
      \   Mux((state === s_walk) && !walkFinished, VecInit(walkPtrVec.map(_ + CommitWidth.U)),
      walkPtrVec)\n889:   )\n890:   val walkPtrTrue_next: RobPtr = Mux(io.redirect.valid,\n\
      891:     Mux(io.snpt.useSnpt, snapshots(io.snpt.snptSelect)(0), deqPtrVec_next(0)),\n\
      892:     Mux((state === s_walk) && !walkFinished, walkPtrVec_next.head, walkPtrTrue)\n\
      893:   )\n894:   walkPtrHead := walkPtrVec_next.head\n895:   walkPtrVec := walkPtrVec_next"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 894-910
    context: "894:   walkPtrHead := walkPtrVec_next.head\n895:   walkPtrVec := walkPtrVec_next\n\
      896:   walkPtrTrue := walkPtrTrue_next\n897:   // T io.redirect.valid, T+1 walkPtrLowBits
      update, T+2 donotNeedWalk update\n898:   val walkPtrLowBits = Reg(UInt(bankAddrWidth.W))\n\
      899:   when(io.redirect.valid){\n900:     walkPtrLowBits := Mux(io.snpt.useSnpt,
      snapshots(io.snpt.snptSelect)(0).value(bankAddrWidth-1, 0), deqPtrVec_next(0).value(bankAddrWidth-1,
      0))\n901:   }\n902:   when(io.redirect.valid) {\n903:     donotNeedWalk := Fill(donotNeedWalk.length,
      true.B).asTypeOf(donotNeedWalk)\n904:   }.elsewhen(RegNext(io.redirect.valid)){\n\
      905:     donotNeedWalk := (0 until CommitWidth).map(i => (i.U < walkPtrLowBits))\n\
      906:   }.otherwise{\n907:     donotNeedWalk := 0.U.asTypeOf(donotNeedWalk)\n\
      908:   }\n909:   walkDestSizeDeqGroup.zip(walkPtrVec_next).map {\n910:     case
      (reg, ptrNext) => reg := deqPtrEntry.realDestSize"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 908-925
    context: "908:   }\n909:   walkDestSizeDeqGroup.zip(walkPtrVec_next).map {\n910:\
      \     case (reg, ptrNext) => reg := deqPtrEntry.realDestSize\n911:   }\n912:\
      \   val numValidEntries = distanceBetween(enqPtr, deqPtr)\n913:   val commitCnt
      = PopCount(io.commits.commitValid)\n914: \n915:   allowEnqueue := numValidEntries
      + dispatchNum <= (RobSize - RenameWidth).U\n916:   allowEnqueueForDispatch :=
      numValidEntries + dispatchNum <= (RobSize - 2 * RenameWidth).U\n917: \n918:\
      \   val redirectWalkDistance = distanceBetween(io.redirect.bits.robIdx, deqPtrVec_next(0))\n\
      919:   when(io.redirect.valid) {\n920:     lastWalkPtr := Mux(io.redirect.bits.flushItself(),
      io.redirect.bits.robIdx - 1.U, io.redirect.bits.robIdx)\n921:   }\n922: \n923:\
      \ \n924:   /**\n925:    * States"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 927-948
    context: "927:    *\n928:    * All events: (1) enqueue (dispatch); (2) writeback;
      (3) cancel; (4) dequeue (commit);\n929:    * All states: (1) valid; (2) writebacked;
      (3) flagBkup\n930:    */\n931: \n932:   val deqPtrGroup = Wire(Vec(2 * CommitWidth,
      new RobPtr))\n933:   deqPtrGroup.zipWithIndex.map { case (deq, i) => deq :=
      deqPtrVec(0) + i.U }\n934:   val commitReadAddr = Mux(state === s_idle, VecInit(deqPtrVec.map(_.value)),
      VecInit(walkPtrVec.map(_.value)))\n935: \n936:   val redirectValidReg = RegNext(io.redirect.valid)\n\
      937:   val redirectBegin = Reg(UInt(log2Up(RobSize).W))\n938:   val redirectEnd
      = Reg(UInt(log2Up(RobSize).W))\n939:   val redirectAll = RegInit(false.B)\n\
      940:   when(io.redirect.valid){\n941:     redirectBegin := Mux(io.redirect.bits.flushItself(),
      io.redirect.bits.robIdx.value - 1.U, io.redirect.bits.robIdx.value)\n942:  \
      \   redirectEnd := enqPtr.value\n943:     redirectAll := io.redirect.bits.flushItself()
      && (io.redirect.bits.robIdx.value === enqPtr.value) && (io.redirect.bits.robIdx.flag
      ^ enqPtr.flag)\n944:   }\n945: \n946:   // update robEntries valid\n947:   for
      (i <- 0 until RobSize) {\n948:     val enqOH = VecInit(canEnqueue.zip(allocatePtrVec.map(_.value
      === i.U)).map(x => x._1 && x._2))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 944-954
    context: "944:   }\n945: \n946:   // update robEntries valid\n947:   for (i <-
      0 until RobSize) {\n948:     val enqOH = VecInit(canEnqueue.zip(allocatePtrVec.map(_.value
      === i.U)).map(x => x._1 && x._2))\n949:     val commitCond = io.commits.isCommit
      && io.commits.commitValid.zip(deqPtrVec.map(_.value === i.U)).map(x => x._1
      && x._2).reduce(_ || _)\n950:     assert(PopCount(enqOH) < 2.U, s\"robEntries$i
      enqOH is not one hot\")\n951:     val needFlush = redirectValidReg && (Mux(\n\
      952:       redirectEnd > redirectBegin,\n953:       (i.U > redirectBegin) &&
      (i.U < redirectEnd),\n954:       (i.U > redirectBegin) || (i.U < redirectEnd)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 951-963
    context: "951:     val needFlush = redirectValidReg && (Mux(\n952:       redirectEnd
      > redirectBegin,\n953:       (i.U > redirectBegin) && (i.U < redirectEnd),\n\
      954:       (i.U > redirectBegin) || (i.U < redirectEnd)\n955:     ) || redirectAll)\n\
      956:     when(commitCond) {\n957:       robEntries(i).valid := false.B\n958:\
      \     }.elsewhen(enqOH.asUInt.orR && !io.redirect.valid) {\n959:       robEntries(i).valid
      := true.B\n960:     }.elsewhen(needFlush){\n961:       robEntries(i).valid :=
      false.B\n962:     }\n963:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1055-1068
    context: "1055:     }.elsewhen(vxsatRes.orR) {\n1056:       robEntries(i).vxsat
      := robEntries(i).vxsat | vxsatRes\n1057:     }\n1058: \n1059:     // trace\n\
      1060:     val taken = branchWBs.map(writeback => writeback.valid && writeback.bits.robIdx.value
      === i.U && writeback.bits.redirect.get.bits.cfiUpdate.taken).reduce(_ || _)\n\
      1061:     when(robEntries(i).valid && Itype.isBranchType(robEntries(i).traceBlockInPipe.itype)
      && taken){\n1062:       // BranchType code(notaken itype = 4) must be correctly
      replaced!\n1063:       robEntries(i).traceBlockInPipe.itype := Itype.Taken\n\
      1064:     }\n1065:   }\n1066: \n1067:   // begin update robBanksRdata\n1068:\
      \   val robBanksRdata = VecInit(robBanksRdataThisLine ++ robBanksRdataNextLine)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1064-1077
    context: "1064:     }\n1065:   }\n1066: \n1067:   // begin update robBanksRdata\n\
      1068:   val robBanksRdata = VecInit(robBanksRdataThisLine ++ robBanksRdataNextLine)\n\
      1069:   val needUpdate = Wire(Vec(2 * CommitWidth, new RobEntryBundle))\n1070:\
      \   needUpdate := VecInit(robBanksRdataThisLine ++ robBanksRdataNextLine)\n\
      1071:   val needUpdateRobIdx = robIdxThisLine ++ robIdxNextLine\n1072:   for
      (i <- 0 until 2 * CommitWidth) {\n1073:     val robIdxMatchSeq = io.enq.req.map(_.bits.robIdx.value
      === needUpdateRobIdx(i))\n1074:     val uopCanEnqSeq = uopEnqValidSeq.zip(robIdxMatchSeq).map
      { case (valid, isMatch) => valid && isMatch }\n1075:     val instCanEnqSeq =
      instEnqValidSeq.zip(robIdxMatchSeq).map { case (valid, isMatch) => valid &&
      isMatch }\n1076:     val instCanEnqFlag = Cat(instCanEnqSeq).orR\n1077:    \
      \ val realDestEnqNum = PopCount(enqNeedWriteRFSeq.zip(uopCanEnqSeq).map { case
      (writeFlag, valid) => writeFlag && valid })"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1119-1132
    context: "1119:     val vxsatCanWbSeq = vxsat_wb.map(writeback => writeback.valid
      && writeback.bits.robIdx.value === needUpdateRobIdx(i))\n1120:     val vxsatRes
      = vxsatCanWbSeq.zip(vxsat_wb).map { case (canWb, wb) => Mux(canWb, wb.bits.vxsat.get,
      0.U) }.fold(false.B)(_ | _)\n1121:     needUpdate(i).vxsat := Mux(!robBanksRdata(i).valid
      && instCanEnqFlag, 0.U, robBanksRdata(i).vxsat | vxsatRes)\n1122: \n1123:  \
      \   // trace\n1124:     val taken = branchWBs.map(writeback => writeback.valid
      && writeback.bits.robIdx.value === needUpdateRobIdx(i) && writeback.bits.redirect.get.bits.cfiUpdate.taken).reduce(_
      || _)\n1125:     when(robBanksRdata(i).valid && Itype.isBranchType(robBanksRdata(i).traceBlockInPipe.itype)
      && taken){\n1126:       // BranchType code(notaken itype = 4) must be correctly
      replaced!\n1127:       needUpdate(i).traceBlockInPipe.itype := Itype.Taken\n\
      1128:     }\n1129:   }\n1130:   robBanksRdataThisLineUpdate := VecInit(needUpdate.take(8))\n\
      1131:   robBanksRdataNextLineUpdate := VecInit(needUpdate.drop(8))\n1132:  \
      \ // end update robBanksRdata"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1138-1148
    context: "1138:       // For MMIO instructions, they should not trigger interrupts
      since they may\n1139:       // be sent to lower level before it writes back.\n\
      1140:       // However, we cannot determine whether a load/store instruction
      is MMIO.\n1141:       // Thus, we don't allow load/store instructions to trigger
      an interrupt.\n1142:       // TODO: support non-MMIO load-store instructions
      to trigger interrupts\n1143:       val allow_interrupts = !CommitType.isLoadStore(io.enq.req(i).bits.commitType)
      && !FuType.isFence(io.enq.req(i).bits.fuType) && !FuType.isCsr(io.enq.req(i).bits.fuType)
      && !FuType.isVset(io.enq.req(i).bits.fuType)\n1144:       robEntries(allocatePtrVec(i).value).interrupt_safe
      := allow_interrupts\n1145:     }\n1146:   }\n1147: \n1148:   /**"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1151-1161
    context: "1151:   val commitReadAddr_next = Mux(state_next === s_idle,\n1152:\
      \     VecInit(deqPtrVec_next.map(_.value)),\n1153:     VecInit(walkPtrVec_next.map(_.value))\n\
      1154:   )\n1155: \n1156:   exceptionGen.io.redirect <> io.redirect\n1157:  \
      \ exceptionGen.io.flush := io.flushOut.valid\n1158: \n1159:   val canEnqueueEG
      = VecInit(io.enq.req.map(req => req.valid && io.enq.canAccept))\n1160:   for
      (i <- 0 until RenameWidth) {\n1161:     exceptionGen.io.enq(i).valid := canEnqueueEG(i)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1221-1246
    context: "1221:     exc_wb.bits.vsew := wb.bits.vls.map(_.vpu.vsew).getOrElse(0.U)\n\
      1222:     exc_wb.bits.veew := wb.bits.vls.map(_.vpu.veew).getOrElse(0.U)\n1223:\
      \     exc_wb.bits.vlmul := wb.bits.vls.map(_.vpu.vlmul).getOrElse(0.U)\n1224:\
      \   }\n1225: \n1226:   fflagsDataRead := (0 until CommitWidth).map(i => robEntries(deqPtrVec(i).value).fflags)\n\
      1227:   vxsatDataRead := (0 until CommitWidth).map(i => robEntries(deqPtrVec(i).value).vxsat)\n\
      1228: \n1229:   val isCommit = io.commits.isCommit\n1230:   val isCommitReg
      = GatedValidRegNext(io.commits.isCommit)\n1231:   val instrCntReg = RegInit(0.U(64.W))\n\
      1232:   val fuseCommitCnt = PopCount(io.commits.commitValid.zip(io.commits.info).map
      { case (v, i) => RegEnable(v && CommitType.isFused(i.commitType), isCommit)
      })\n1233:   val trueCommitCnt = RegEnable(io.commits.commitValid.zip(io.commits.info).map
      { case (v, i) => Mux(v, i.instrSize, 0.U) }.reduce(_ +& _), isCommit) +& fuseCommitCnt\n\
      1234:   val retireCounter = Mux(isCommitReg, trueCommitCnt, 0.U)\n1235:   val
      instrCnt = instrCntReg + retireCounter\n1236:   when(isCommitReg){\n1237:  \
      \   instrCntReg := instrCnt\n1238:   }\n1239:   io.csr.perfinfo.retiredInstr
      := retireCounter\n1240:   io.robFull := !allowEnqueue\n1241:   io.headNotReady
      := commit_vDeqGroup(deqPtr.value(bankNumWidth-1, 0)) && !commit_wDeqGroup(deqPtr.value(bankNumWidth-1,
      0))\n1242: \n1243:   io.toVecExcpMod.logicPhyRegMap := rab.io.toVecExcpMod.logicPhyRegMap\n\
      1244:   io.toVecExcpMod.excpInfo := vecExcpInfo\n1245: \n1246:   /**"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1246-1272
    context: "1246:   /**\n1247:    * trace\n1248:    */\n1249: \n1250:   // trace
      output\n1251:   val traceValids = io.trace.traceCommitInfo.blocks.map(_.valid)\n\
      1252:   val traceBlocks = io.trace.traceCommitInfo.blocks\n1253:   val traceBlockInPipe
      = io.trace.traceCommitInfo.blocks.map(_.bits.tracePipe)\n1254: \n1255:   for
      (i <- 0 until CommitWidth) {\n1256:     traceBlocks(i).bits.ftqIdx.foreach(_
      := rawInfo(i).ftqIdx)\n1257:     traceBlocks(i).bits.ftqOffset.foreach(_ :=
      rawInfo(i).ftqOffset)\n1258:     traceBlockInPipe(i).itype := rawInfo(i).traceBlockInPipe.itype\n\
      1259:     traceBlockInPipe(i).iretire := rawInfo(i).traceBlockInPipe.iretire\n\
      1260:     traceBlockInPipe(i).ilastsize := rawInfo(i).traceBlockInPipe.ilastsize\n\
      1261:     traceValids(i) := io.commits.isCommit && io.commits.commitValid(i)\n\
      1262:     // exception only occur in block(0).\n1263:     if(i == 0) {\n1264:\
      \       when(io.exception.valid){ // trace exception\n1265:         traceBlocks(i).bits.tracePipe.itype
      := Mux(io.exception.bits.isInterrupt,\n1266:           Itype.Interrupt,\n1267:\
      \           Itype.Exception\n1268:         )\n1269:         traceValids(i) :=
      true.B\n1270:         traceBlockInPipe(i).iretire := 0.U\n1271:       }\n1272:\
      \     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1292-1330
    context: "1292:     XSDebug(false, robEntries(i).valid && robEntries(i).isWritebacked,
      \"w \")\n1293:     XSDebug(false, robEntries(i).valid && !robEntries(i).isWritebacked,
      \"v \")\n1294:     if (i % 4 == 3) XSDebug(false, true.B, \"\\n\")\n1295:  \
      \ }\n1296: \n1297:   def ifCommit(counter: UInt): UInt = Mux(isCommit, counter,
      0.U)\n1298: \n1299:   def ifCommitReg(counter: UInt): UInt = Mux(isCommitReg,
      counter, 0.U)\n1300: \n1301:   val commitDebugUop = deqPtrVec.map(_.value).map(debug_microOp(_))\n\
      1302:   XSPerfAccumulate(\"clock_cycle\", 1.U, XSPerfLevel.CRITICAL)\n1303:\
      \   QueuePerf(RobSize, numValidEntries, numValidEntries === RobSize.U)\n1304:\
      \   XSPerfAccumulate(\"commitUop\", ifCommit(commitCnt))\n1305:   XSPerfAccumulate(\"\
      commitInstr\", ifCommitReg(trueCommitCnt), XSPerfLevel.CRITICAL)\n1306:   XSPerfRolling(\"\
      ipc\", ifCommitReg(trueCommitCnt), 1000, clock, reset)\n1307:   XSPerfRolling(\"\
      cpi\", perfCnt = 1.U /*Cycle*/ , eventTrigger = ifCommitReg(trueCommitCnt),
      granularity = 1000, clock, reset)\n1308:   XSPerfAccumulate(\"commitInstrFused\"\
      , ifCommitReg(fuseCommitCnt))\n1309:   val commitIsLoad = io.commits.info.map(_.commitType).map(_
      === CommitType.LOAD)\n1310:   val commitLoadValid = io.commits.commitValid.zip(commitIsLoad).map
      { case (v, t) => v && t }\n1311:   XSPerfAccumulate(\"commitInstrLoad\", ifCommit(PopCount(commitLoadValid)))\n\
      1312:   val commitIsBranch = io.commits.info.map(_.commitType).map(_ === CommitType.BRANCH)\n\
      1313:   val commitBranchValid = io.commits.commitValid.zip(commitIsBranch).map
      { case (v, t) => v && t }\n1314:   XSPerfAccumulate(\"commitInstrBranch\", ifCommit(PopCount(commitBranchValid)))\n\
      1315:   val commitIsStore = io.commits.info.map(_.commitType).map(_ === CommitType.STORE)\n\
      1316:   XSPerfAccumulate(\"commitInstrStore\", ifCommit(PopCount(io.commits.commitValid.zip(commitIsStore).map
      { case (v, t) => v && t })))\n1317:   XSPerfAccumulate(\"writeback\", PopCount((0
      until RobSize).map(i => robEntries(i).valid && robEntries(i).isWritebacked)))\n\
      1318:   // XSPerfAccumulate(\"enqInstr\", PopCount(io.dp1Req.map(_.fire)))\n\
      1319:   // XSPerfAccumulate(\"d2rVnR\", PopCount(io.dp1Req.map(p => p.valid
      && !p.ready)))\n1320:   XSPerfAccumulate(\"walkInstr\", Mux(io.commits.isWalk,
      PopCount(io.commits.walkValid), 0.U))\n1321:   XSPerfAccumulate(\"walkCycleTotal\"\
      , state === s_walk)\n1322:   XSPerfAccumulate(\"waitRabWalkEnd\", state ===
      s_walk && walkFinished && !rab.io.status.walkEnd)\n1323:   private val walkCycle
      = RegInit(0.U(8.W))\n1324:   private val waitRabWalkCycle = RegInit(0.U(8.W))\n\
      1325:   walkCycle := Mux(io.redirect.valid, 0.U, Mux(state === s_walk, walkCycle
      + 1.U, 0.U))\n1326:   waitRabWalkCycle := Mux(state === s_walk && walkFinished,
      0.U, Mux(state === s_walk, walkCycle + 1.U, 0.U))\n1327: \n1328:   XSPerfHistogram(\"\
      walkRobCycleHist\", walkCycle, state === s_walk && walkFinished, 0, 32)\n1329:\
      \   XSPerfHistogram(\"walkRabExtraCycleHist\", waitRabWalkCycle, state === s_walk
      && walkFinished && rab.io.status.walkEnd, 0, 32)\n1330:   XSPerfHistogram(\"\
      walkTotalCycleHist\", walkCycle, state === s_walk && state_next === s_idle,
      0, 32)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1331-1341
    context: "1331: \n1332:   private val deqNotWritebacked = robEntries(deqPtr.value).valid
      && !robEntries(deqPtr.value).isWritebacked\n1333:   private val deqStdNotWritebacked
      = robEntries(deqPtr.value).valid && !robEntries(deqPtr.value).stdWritebacked\n\
      1334:   private val deqUopNotWritebacked = robEntries(deqPtr.value).valid &&
      !robEntries(deqPtr.value).isUopWritebacked\n1335:   private val deqHeadInfo
      = debug_microOp(deqPtr.value)\n1336:   val deqUopCommitType = debug_microOp(deqPtr.value).commitType\n\
      1337: \n1338:   XSPerfAccumulate(\"waitAluCycle\", deqNotWritebacked && deqHeadInfo.fuType
      === FuType.alu.U)\n1339:   XSPerfAccumulate(\"waitMulCycle\", deqNotWritebacked
      && deqHeadInfo.fuType === FuType.mul.U)\n1340:   XSPerfAccumulate(\"waitDivCycle\"\
      , deqNotWritebacked && deqHeadInfo.fuType === FuType.div.U)\n1341:   XSPerfAccumulate(\"\
      waitBrhCycle\", deqNotWritebacked && deqHeadInfo.fuType === FuType.brh.U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1361-1387
    context: "1361:     case(fuoptype,i) =>  XSPerfAccumulate(s\"waitVfalu_${i}Cycle\"\
      , deqStdNotWritebacked && deqHeadInfo.fuOpType === fuoptype && deqHeadInfo.fuType
      === FuType.vfalu.U)\n1362:   }\n1363: \n1364: \n1365: \n1366:   XSPerfAccumulate(\"\
      waitNormalCycle\", deqNotWritebacked && deqUopCommitType === CommitType.NORMAL)\n\
      1367:   XSPerfAccumulate(\"waitBranchCycle\", deqNotWritebacked && deqUopCommitType
      === CommitType.BRANCH)\n1368:   XSPerfAccumulate(\"waitLoadCycle\", deqNotWritebacked
      && deqUopCommitType === CommitType.LOAD)\n1369:   XSPerfAccumulate(\"waitStoreCycle\"\
      , deqNotWritebacked && deqUopCommitType === CommitType.STORE)\n1370:   XSPerfAccumulate(\"\
      robHeadPC\", io.commits.info(0).debug_pc.getOrElse(0.U))\n1371:   XSPerfAccumulate(\"\
      commitCompressCntAll\", PopCount(io.commits.commitValid.zip(io.commits.info).map
      { case (valid, info) => io.commits.isCommit && valid && info.instrSize > 1.U
      }))\n1372:   (2 to RenameWidth).foreach(i =>\n1373:     XSPerfAccumulate(s\"\
      commitCompressCnt${i}\", PopCount(io.commits.commitValid.zip(io.commits.info).map
      { case (valid, info) => io.commits.isCommit && valid && info.instrSize === i.U
      }))\n1374:   )\n1375:   XSPerfAccumulate(\"compressSize\", io.commits.commitValid.zip(io.commits.info).map
      { case (valid, info) => Mux(io.commits.isCommit && valid && info.instrSize >
      1.U, info.instrSize, 0.U) }.reduce(_ +& _))\n1376:   val dispatchLatency = commitDebugUop.map(uop
      => uop.debugInfo.dispatchTime - uop.debugInfo.renameTime)\n1377:   val enqRsLatency
      = commitDebugUop.map(uop => uop.debugInfo.enqRsTime - uop.debugInfo.dispatchTime)\n\
      1378:   val selectLatency = commitDebugUop.map(uop => uop.debugInfo.selectTime
      - uop.debugInfo.enqRsTime)\n1379:   val issueLatency = commitDebugUop.map(uop
      => uop.debugInfo.issueTime - uop.debugInfo.selectTime)\n1380:   val executeLatency
      = commitDebugUop.map(uop => uop.debugInfo.writebackTime - uop.debugInfo.issueTime)\n\
      1381:   val rsFuLatency = commitDebugUop.map(uop => uop.debugInfo.writebackTime
      - uop.debugInfo.enqRsTime)\n1382:   val commitLatency = commitDebugUop.map(uop
      => timer - uop.debugInfo.writebackTime)\n1383: \n1384:   def latencySum(cond:
      Seq[Bool], latency: Seq[UInt]): UInt = {\n1385:     cond.zip(latency).map(x
      => Mux(x._1, x._2, 0.U)).reduce(_ +& _)\n1386:   }\n1387: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1385-1406
    context: "1385:     cond.zip(latency).map(x => Mux(x._1, x._2, 0.U)).reduce(_
      +& _)\n1386:   }\n1387: \n1388:   for (fuType <- FuType.functionNameMap.keys)
      {\n1389:     val fuName = FuType.functionNameMap(fuType)\n1390:     val commitIsFuType
      = io.commits.commitValid.zip(commitDebugUop).map(x => x._1 && x._2.fuType ===
      fuType.U)\n1391:     XSPerfRolling(s\"ipc_futype_${fuName}\", ifCommit(PopCount(commitIsFuType)),
      1000, clock, reset)\n1392:     XSPerfAccumulate(s\"${fuName}_instr_cnt\", ifCommit(PopCount(commitIsFuType)))\n\
      1393:     XSPerfAccumulate(s\"${fuName}_latency_dispatch\", ifCommit(latencySum(commitIsFuType,
      dispatchLatency)))\n1394:     XSPerfAccumulate(s\"${fuName}_latency_enq_rs\"\
      , ifCommit(latencySum(commitIsFuType, enqRsLatency)))\n1395:     XSPerfAccumulate(s\"\
      ${fuName}_latency_select\", ifCommit(latencySum(commitIsFuType, selectLatency)))\n\
      1396:     XSPerfAccumulate(s\"${fuName}_latency_issue\", ifCommit(latencySum(commitIsFuType,
      issueLatency)))\n1397:     XSPerfAccumulate(s\"${fuName}_latency_execute\",
      ifCommit(latencySum(commitIsFuType, executeLatency)))\n1398:     XSPerfAccumulate(s\"\
      ${fuName}_latency_enq_rs_execute\", ifCommit(latencySum(commitIsFuType, rsFuLatency)))\n\
      1399:     XSPerfAccumulate(s\"${fuName}_latency_commit\", ifCommit(latencySum(commitIsFuType,
      commitLatency)))\n1400:   }\n1401:   XSPerfAccumulate(s\"redirect_use_snapshot\"\
      , io.redirect.valid && io.snpt.useSnpt)\n1402: \n1403:   // top-down info\n\
      1404:   io.debugTopDown.toCore.robHeadVaddr.valid := debug_lsTopdownInfo(deqPtr.value).s1.vaddr_valid\n\
      1405:   io.debugTopDown.toCore.robHeadVaddr.bits := debug_lsTopdownInfo(deqPtr.value).s1.vaddr_bits\n\
      1406:   io.debugTopDown.toCore.robHeadPaddr.valid := debug_lsTopdownInfo(deqPtr.value).s2.paddr_valid"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1403-1413
    context: "1403:   // top-down info\n1404:   io.debugTopDown.toCore.robHeadVaddr.valid
      := debug_lsTopdownInfo(deqPtr.value).s1.vaddr_valid\n1405:   io.debugTopDown.toCore.robHeadVaddr.bits
      := debug_lsTopdownInfo(deqPtr.value).s1.vaddr_bits\n1406:   io.debugTopDown.toCore.robHeadPaddr.valid
      := debug_lsTopdownInfo(deqPtr.value).s2.paddr_valid\n1407:   io.debugTopDown.toCore.robHeadPaddr.bits
      := debug_lsTopdownInfo(deqPtr.value).s2.paddr_bits\n1408:   io.debugTopDown.toDispatch.robTrueCommit
      := ifCommitReg(trueCommitCnt)\n1409:   io.debugTopDown.toDispatch.robHeadLsIssue
      := debug_lsIssue(deqPtr.value)\n1410:   io.debugTopDown.robHeadLqIdx.valid :=
      debug_lqIdxValid(deqPtr.value)\n1411:   io.debugTopDown.robHeadLqIdx.bits :=
      debug_microOp(deqPtr.value).lqIdx\n1412: \n1413:   // rolling"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1409-1424
    context: "1409:   io.debugTopDown.toDispatch.robHeadLsIssue := debug_lsIssue(deqPtr.value)\n\
      1410:   io.debugTopDown.robHeadLqIdx.valid := debug_lqIdxValid(deqPtr.value)\n\
      1411:   io.debugTopDown.robHeadLqIdx.bits := debug_microOp(deqPtr.value).lqIdx\n\
      1412: \n1413:   // rolling\n1414:   io.debugRolling.robTrueCommit := ifCommitReg(trueCommitCnt)\n\
      1415: \n1416:   // debug trigger for simulation\n1417:   if (backendParams.debugEn)
      {\n1418:     val debug_sim_trig = dontTouch(Wire(Bool()))\n1419:     debug_sim_trig
      := io.commits.isCommit && (io.commits.commitValid zip commitDebugUop map {\n\
      1420:       case (valid, uop) => valid && uop.debug_sim_trig.get\n1421:    \
      \ }).reduce(_ || _)\n1422:   }\n1423: \n1424:   /**"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1473-1491
    context: "1473:       debug_VecOtherPdest(vldWbRobIdx)(vldWbvdIdx) := vldWbPdest\n\
      1474:     }\n1475:   }\n1476: \n1477:   //difftest signals\n1478:   val firstValidCommit
      = (deqPtr + PriorityMux(io.commits.commitValid, VecInit(List.tabulate(CommitWidth)(_.U(log2Up(CommitWidth).W))))).value\n\
      1479: \n1480:   val wdata = Wire(Vec(CommitWidth, UInt(XLEN.W)))\n1481:   val
      wpc = Wire(Vec(CommitWidth, UInt(XLEN.W)))\n1482: \n1483:   for (i <- 0 until
      CommitWidth) {\n1484:     val idx = deqPtrVec(i).value\n1485:     wdata(i) :=
      debug_exuData(idx)\n1486:     wpc(i) := SignExt(commitDebugUop(i).pc, XLEN)\n\
      1487:   }\n1488: \n1489:   if (env.EnableDifftest || env.AlwaysBasicDiff) {\n\
      1490:     // These are the structures used by difftest only and should be optimized
      after synthesis.\n1491:     val dt_eliminatedMove = Mem(RobSize, Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1504-1516
    context: "1504:         val wbIdx = wb.bits.robIdx.value\n1505:         dt_exuDebug(wbIdx)
      := wb.bits.debug\n1506:       }\n1507:     }\n1508:     // Always instantiate
      basic difftest modules.\n1509:     for (i <- 0 until CommitWidth) {\n1510: \
      \      val uop = commitDebugUop(i)\n1511:       val commitInfo = io.commits.info(i)\n\
      1512:       val ptr = deqPtrVec(i).value\n1513:       val exuOut = dt_exuDebug(ptr)\n\
      1514:       val eliminatedMove = dt_eliminatedMove(ptr)\n1515:       val isRVC
      = dt_isRVC(ptr)\n1516:       val instr = uop.instr.asTypeOf(new XSInstBitFields)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1518-1540
    context: "1518: \n1519:       val difftest = DifftestModule(new DiffInstrCommit(MaxPhyRegs),
      delay = 3, dontCare = true)\n1520:       val dt_skip = Mux(eliminatedMove, false.B,
      exuOut.isSkipDiff)\n1521:       difftest.coreid := io.hartId\n1522:       difftest.index
      := i.U\n1523:       difftest.valid := io.commits.commitValid(i) && io.commits.isCommit\n\
      1524:       difftest.skip := dt_skip\n1525:       difftest.isRVC := isRVC\n\
      1526:       difftest.rfwen := io.commits.commitValid(i) && commitInfo.rfWen
      && commitInfo.debug_ldest.get =/= 0.U\n1527:       difftest.fpwen := io.commits.commitValid(i)
      && uop.fpWen\n1528:       difftest.vecwen := io.commits.commitValid(i) && uop.vecWen\n\
      1529:       difftest.v0wen := io.commits.commitValid(i) && (uop.v0Wen || isVLoad
      && instr.VD === 0.U)\n1530:       difftest.wpdest := commitInfo.debug_pdest.get\n\
      1531:       difftest.wdest := Mux(isVLoad, instr.VD, commitInfo.debug_ldest.get)\n\
      1532:       difftest.otherwpdest := debug_VecOtherPdest(ptr)\n1533:       difftest.nFused
      := CommitType.isFused(commitInfo.commitType).asUInt + commitInfo.instrSize -
      1.U\n1534:       when(difftest.valid) {\n1535:         assert(CommitType.isFused(commitInfo.commitType).asUInt
      + commitInfo.instrSize >= 1.U)\n1536:       }\n1537:       if (env.EnableDifftest)
      {\n1538:         val pcTransType = dt_pcTransType.get(deqPtrVec(i).value)\n\
      1539:         difftest.pc := Mux(pcTransType.shouldBeSext, SignExt(uop.pc, XLEN),
      uop.pc)\n1540:         difftest.instr := uop.instr"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1539-1550
    context: "1539:         difftest.pc := Mux(pcTransType.shouldBeSext, SignExt(uop.pc,
      XLEN), uop.pc)\n1540:         difftest.instr := uop.instr\n1541:         difftest.robIdx
      := ZeroExt(ptr, 10)\n1542:         difftest.lqIdx := ZeroExt(uop.lqIdx.value,
      7)\n1543:         difftest.sqIdx := ZeroExt(uop.sqIdx.value, 7)\n1544:     \
      \    difftest.isLoad := io.commits.info(i).commitType === CommitType.LOAD\n\
      1545:         difftest.isStore := io.commits.info(i).commitType === CommitType.STORE\n\
      1546:         // Check LoadEvent only when isAmo or isLoad and skip MMIO\n1547:\
      \         val difftestLoadEvent = DifftestModule(new DiffLoadEvent, delay =
      3)\n1548:         difftestLoadEvent.coreid := io.hartId\n1549:         difftestLoadEvent.index
      := i.U\n1550:         val loadCheck = (FuType.isAMO(uop.fuType) || FuType.isLoad(uop.fuType)
      || isVLoad) && !dt_skip"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1546-1556
    context: "1546:         // Check LoadEvent only when isAmo or isLoad and skip
      MMIO\n1547:         val difftestLoadEvent = DifftestModule(new DiffLoadEvent,
      delay = 3)\n1548:         difftestLoadEvent.coreid := io.hartId\n1549:     \
      \    difftestLoadEvent.index := i.U\n1550:         val loadCheck = (FuType.isAMO(uop.fuType)
      || FuType.isLoad(uop.fuType) || isVLoad) && !dt_skip\n1551:         difftestLoadEvent.valid\
      \    := io.commits.commitValid(i) && io.commits.isCommit && loadCheck\n1552:\
      \         difftestLoadEvent.paddr    := exuOut.paddr\n1553:         difftestLoadEvent.opType\
      \   := uop.fuOpType\n1554:         difftestLoadEvent.isAtomic := FuType.isAMO(uop.fuType)\n\
      1555:         difftestLoadEvent.isLoad   := FuType.isLoad(uop.fuType)\n1556:\
      \         difftestLoadEvent.isVLoad  := isVLoad"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1563-1574
    context: "1563:     for (i <- 0 until RenameWidth) {\n1564:       when(canEnqueue(i))
      {\n1565:         dt_isXSTrap(allocatePtrVec(i).value) := io.enq.req(i).bits.isXSTrap\n\
      1566:       }\n1567:     }\n1568:     val trapVec = io.commits.commitValid.zip(deqPtrVec).map
      { case (v, d) =>\n1569:       io.commits.isCommit && v && dt_isXSTrap(d.value)\n\
      1570:     }\n1571:     val hitTrap = trapVec.reduce(_ || _)\n1572:     val difftest
      = DifftestModule(new DiffTrapEvent, dontCare = true)\n1573:     difftest.coreid
      := io.hartId\n1574:     difftest.hasTrap := hitTrap"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1590-1608
    context: "1590:     io.storeDebugInfo.map{port =>\n1591:       port.pc := debug_microOp(port.robidx.value).pc\n\
      1592:     }\n1593:   }\n1594: \n1595:   val brhMispred = PopCount(branchWBs.map(wb
      => wb.valid & wb.bits.redirect.get.valid))\n1596:   val jmpMispred = PopCount(jmpWBs.map(wb
      => wb.valid && wb.bits.redirect.get.valid))\n1597:   val misPred = brhMispred
      +& jmpMispred\n1598: \n1599:   XSPerfAccumulate(\"br_mis_pred\", misPred)\n\
      1600: \n1601:   val commitLoadVec = VecInit(commitLoadValid)\n1602:   val commitBranchVec
      = VecInit(commitBranchValid)\n1603:   val commitStoreVec = VecInit(io.commits.commitValid.zip(commitIsStore).map
      { case (v, t) => v && t })\n1604:   val perfEvents = Seq(\n1605:     (\"rob_interrupt_num\
      \      \", io.flushOut.valid && intrEnable),\n1606:     (\"rob_exception_num\
      \      \", io.flushOut.valid && deqHasException),\n1607:     (\"rob_flush_pipe_num\
      \     \", io.flushOut.valid && isFlushPipe),\n1608:     (\"rob_replay_inst_num\
      \    \", io.flushOut.valid && isFlushPipe && deqHasReplayInst),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1604-1620
    context: "1604:   val perfEvents = Seq(\n1605:     (\"rob_interrupt_num      \"\
      , io.flushOut.valid && intrEnable),\n1606:     (\"rob_exception_num      \"\
      , io.flushOut.valid && deqHasException),\n1607:     (\"rob_flush_pipe_num  \
      \   \", io.flushOut.valid && isFlushPipe),\n1608:     (\"rob_replay_inst_num\
      \    \", io.flushOut.valid && isFlushPipe && deqHasReplayInst),\n1609:     (\"\
      rob_commitUop          \", ifCommit(commitCnt)),\n1610:     (\"rob_commitInstr\
      \        \", ifCommitReg(trueCommitCnt)),\n1611:     (\"rob_commitInstrFused\
      \   \", ifCommitReg(fuseCommitCnt)),\n1612:     (\"rob_commitInstrLoad    \"\
      , ifCommitReg(PopCount(RegEnable(commitLoadVec, isCommit)))),\n1613:     (\"\
      rob_commitInstrBranch  \", ifCommitReg(PopCount(RegEnable(commitBranchVec, isCommit)))),\n\
      1614:     (\"rob_commitInstrStore   \", ifCommitReg(PopCount(RegEnable(commitStoreVec,
      isCommit)))),\n1615:     (\"rob_walkInstr          \", Mux(io.commits.isWalk,
      PopCount(io.commits.walkValid), 0.U)),\n1616:     (\"rob_walkCycle         \
      \ \", (state === s_walk)),\n1617:     (\"rob_1_4_valid          \", numValidEntries
      <= (RobSize / 4).U),\n1618:     (\"rob_2_4_valid          \", numValidEntries
      > (RobSize / 4).U && numValidEntries <= (RobSize / 2).U),\n1619:     (\"rob_3_4_valid\
      \          \", numValidEntries > (RobSize / 2).U && numValidEntries <= (RobSize
      * 3 / 4).U),\n1620:     (\"rob_4_4_valid          \", numValidEntries > (RobSize
      * 3 / 4).U),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1623-1637
    context: "1623:   )\n1624:   generatePerfEvent()\n1625: \n1626:   // max commit-stuck
      cycle\n1627:   val deqismmio = Mux(robEntries(deqPtr.value).valid, robEntries(deqPtr.value).mmio,
      false.B)\n1628:   val commitStuck = (!io.commits.commitValid.reduce(_ || _)
      || !io.commits.isCommit) && !deqismmio\n1629:   val commitStuckCycle = RegInit(0.U(log2Up(maxCommitStuck).W))\n\
      1630:   when(commitStuck) {\n1631:     commitStuckCycle := commitStuckCycle
      + 1.U\n1632:   }.elsewhen(!commitStuck && RegNext(commitStuck)) {\n1633:   \
      \  commitStuckCycle := 0.U\n1634:   }\n1635:   // check if stuck > 2^maxCommitStuckCycle\n\
      1636:   val commitStuck_overflow = commitStuckCycle.andR && (if (wfiResume)
      true.B else (!hasWFI))\n1637:   val criticalErrors = Seq("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1654-1674
    context: "1654:     dontTouch(robBanksRdataThisLineUpdate)\n1655:     dontTouch(robBanksRdataNextLineUpdate)\n\
      1656:     dontTouch(needUpdate)\n1657:     val exceptionWBsVec = MixedVecInit(exceptionWBs)\n\
      1658:     dontTouch(exceptionWBsVec)\n1659:     dontTouch(commit_wDeqGroup)\n\
      1660:     dontTouch(commit_vDeqGroup)\n1661:     dontTouch(commitSizeSumSeq)\n\
      1662:     dontTouch(walkSizeSumSeq)\n1663:     dontTouch(commitSizeSumCond)\n\
      1664:     dontTouch(walkSizeSumCond)\n1665:     dontTouch(commitSizeSum)\n1666:\
      \     dontTouch(walkSizeSum)\n1667:     dontTouch(realDestSizeSeq)\n1668:  \
      \   dontTouch(walkDestSizeSeq)\n1669:     dontTouch(io.commits)\n1670:     dontTouch(commitIsVTypeVec)\n\
      1671:     dontTouch(walkIsVTypeVec)\n1672:     dontTouch(commitValidThisLine)\n\
      1673:     dontTouch(commitReadAddr_next)\n1674:     dontTouch(donotNeedWalk)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/rob/Rob.scala
    lines: 1681-1688
    context: "1681:     dontTouch(shouldWalkVec)\n1682:     dontTouch(walkFinished)\n\
      1683:     dontTouch(changeBankAddrToDeqPtr)\n1684:   }\n1685:   if (env.EnableDifftest)
      {\n1686:     io.commits.info.map(info => dontTouch(info.debug_pc.get))\n1687:\
      \   }\n1688: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 28-38
    context: "28:   val vtype = new VType()\n29:   val isVsetvl = Bool()\n30: }\n\
      31: \n32: class VTypeBufferIO(size: Int)(implicit p: Parameters) extends XSBundle
      {\n33:   val redirect = Input(ValidIO(new Bundle{}))\n34: \n35:   val req =
      Vec(RenameWidth, Flipped(ValidIO(new DynInst)))\n36: \n37:   val fromRob = new
      Bundle {\n38:     val walkSize = Input(UInt(log2Up(size).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 35-45
    context: "35:   val req = Vec(RenameWidth, Flipped(ValidIO(new DynInst)))\n36:\
      \ \n37:   val fromRob = new Bundle {\n38:     val walkSize = Input(UInt(log2Up(size).W))\n\
      39:     val walkEnd = Input(Bool())\n40:     val commitSize = Input(UInt(log2Up(size).W))\n\
      41:   }\n42: \n43:   val snpt = Input(new SnapshotPort)\n44: \n45:   val canEnq
      = Output(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 47-57
    context: "47: \n48:   val toDecode = Output(new Bundle {\n49:     val isResumeVType
      = Bool()\n50:     val walkToArchVType = Bool()\n51:     val walkVType = ValidIO(VType())\n\
      52:     val commitVType = new Bundle {\n53:       val vtype = ValidIO(VType())\n\
      54:       val hasVsetvl = Bool()\n55:     }\n56:   })\n57: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 72-82
    context: "72:   private val stateNext = WireInit(state) // otherwise keep state
      value\n73:   private val stateLast = RegEnable(state, state =/= stateNext)\n\
      74:   private val stateLastCycle = RegNext(state)\n75: \n76:   // +1 read port
      to get walk initial state\n77:   private val vtypeBuffer = Module(new SyncDataModuleTemplate(new
      VTypeBufferEntry(), size, numWrite = RenameWidth, numRead = CommitWidth))\n\
      78:   private val vtypeBufferReadAddrVec = vtypeBuffer.io.raddr\n79:   private
      val vtypeBufferReadDataVec = vtypeBuffer.io.rdata\n80:   private val vtypeBufferWriteEnVec
      = vtypeBuffer.io.wen\n81:   private val vtypeBufferWriteAddrVec = vtypeBuffer.io.waddr\n\
      82:   private val vtypeBufferWriteDataVec = vtypeBuffer.io.wdata"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 88-111
    context: "88:   private val enqPtrOHShift = CircularShift(enqPtrOH)\n89:   //
      may shift [0, RenameWidth] steps\n90:   private val enqPtrOHVec = VecInit.tabulate(RenameWidth
      + 1)(enqPtrOHShift.left)\n91:   private val enqPtrVecNext = WireInit(enqPtrVec)\n\
      92: \n93:   private val deqPtrVec = RegInit(VecInit.tabulate(CommitWidth)(idx
      => VTypeBufferPtr(flag = false, idx)))\n94:   private val deqPtr = deqPtrVec.head\n\
      95:   private val deqPtrOH = RegInit(1.U(size.W))\n96:   private val deqPtrOHShift
      = CircularShift(deqPtrOH)\n97:   private val deqPtrOHVec = VecInit.tabulate(CommitWidth
      + 1)(deqPtrOHShift.left)\n98:   private val deqPtrVecNext = WireInit(deqPtrVec)\n\
      99:   XSError(deqPtr.toOH =/= deqPtrOH, p\"wrong one-hot reg between $deqPtr
      and $deqPtrOH\")\n100: \n101:   private val walkPtrVec = RegInit(VecInit.tabulate(CommitWidth)(idx
      => VTypeBufferPtr(flag = false, idx)))\n102:   private val walkPtr = Reg(new
      VTypeBufferPtr)\n103:   private val walkPtrOH = walkPtr.toOH\n104:   private
      val walkPtrOHVec = VecInit.tabulate(CommitWidth + 1)(CircularShift(walkPtrOH).left)\n\
      105:   private val walkPtrNext = Wire(new VTypeBufferPtr)\n106:   private val
      walkPtrVecNext = VecInit((0 until CommitWidth).map(x => walkPtrNext + x.U))\n\
      107: \n108:   // get enque vtypes in io.req\n109:   private val enqVTypes =
      VecInit(io.req.map(req => req.bits.vpu.specVType))\n110:   private val enqValids
      = VecInit(io.req.map(_.valid))\n111:   private val enqVType = PriorityMux(enqValids.zip(enqVTypes).map
      { case (valid, vtype) => valid -> vtype })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 108-124
    context: "108:   // get enque vtypes in io.req\n109:   private val enqVTypes =
      VecInit(io.req.map(req => req.bits.vpu.specVType))\n110:   private val enqValids
      = VecInit(io.req.map(_.valid))\n111:   private val enqVType = PriorityMux(enqValids.zip(enqVTypes).map
      { case (valid, vtype) => valid -> vtype })\n112: \n113:   private val walkPtrSnapshots
      = SnapshotGenerator(enqPtr, io.snpt.snptEnq, io.snpt.snptDeq, io.redirect.valid,
      io.snpt.flushVec)\n114:   private val walkVTypeSnapshots = SnapshotGenerator(enqVType,
      io.snpt.snptEnq, io.snpt.snptDeq, io.redirect.valid, io.snpt.flushVec)\n115:\
      \ \n116:   private val robWalkEndReg = RegInit(false.B)\n117:   private val
      robWalkEnd = io.fromRob.walkEnd || robWalkEndReg\n118: \n119:   when(io.redirect.valid)
      {\n120:     robWalkEndReg := false.B\n121:   }.elsewhen(io.fromRob.walkEnd)
      {\n122:     robWalkEndReg := true.B\n123:   }\n124: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 125-162
    context: "125:   // There are two uops mapped to one vset inst.\n126:   // Only
      record the last here.\n127:   private val needAllocVec = VecInit(io.req.map(req
      => req.valid && req.bits.isVset && req.bits.lastUop))\n128:   private val enqCount
      = PopCount(needAllocVec)\n129: \n130:   private val commitCount   = Wire(UInt(CommitWidth.U.getWidth.W))\n\
      131:   private val walkCount     = Wire(UInt(CommitWidth.U.getWidth.W))\n132:\
      \   private val spclWalkCount = Wire(UInt(CommitWidth.U.getWidth.W))\n133: \n\
      134:   private val commitSize   = RegInit(0.U(size.U.getWidth.W))\n135:   private
      val walkSize     = RegInit(0.U(size.U.getWidth.W))\n136:   private val spclWalkSize
      = RegInit(0.U(size.U.getWidth.W))\n137: \n138:   private val commitSizeNext\
      \   = Wire(UInt(CommitWidth.U.getWidth.W))\n139:   private val walkSizeNext\
      \     = Wire(UInt(CommitWidth.U.getWidth.W))\n140:   private val spclWalkSizeNext
      = Wire(UInt(CommitWidth.U.getWidth.W))\n141: \n142:   private val newCommitSize\
      \   = io.fromRob.commitSize\n143:   private val newWalkSize     = io.fromRob.walkSize\n\
      144:   private val newSpclWalkSize = Mux(io.redirect.valid && !io.snpt.useSnpt,
      commitSizeNext, 0.U)\n145: \n146:   commitSizeNext   := commitSize + newCommitSize
      - commitCount\n147:   walkSizeNext     := walkSize + newWalkSize - walkCount\n\
      148:   spclWalkSizeNext := spclWalkSize + newSpclWalkSize - spclWalkCount\n\
      149: \n150:   commitSize := Mux(io.redirect.valid && !io.snpt.useSnpt, 0.U,
      commitSizeNext)\n151:   spclWalkSize := spclWalkSizeNext\n152:   walkSize :=
      Mux(io.redirect.valid, 0.U, walkSizeNext)\n153: \n154:   walkPtrNext := MuxCase(walkPtr,
      Seq(\n155:     (state === s_idle && stateNext === s_walk) -> walkPtrSnapshots(snptSelect),\n\
      156:     (state === s_spcl_walk && stateNext === s_walk) -> deqPtrVecNext.head,\n\
      157:     (state === s_walk && io.snpt.useSnpt && io.redirect.valid) -> walkPtrSnapshots(snptSelect),\n\
      158:     (state === s_walk) -> (walkPtr + walkCount),\n159:   ))\n160: \n161:\
      \   walkPtr := walkPtrNext\n162: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 160-170
    context: "160: \n161:   walkPtr := walkPtrNext\n162: \n163:   private val useSnapshotNext
      = WireInit(false.B)\n164: \n165:   useSnapshotNext := (state === s_idle && stateNext
      === s_walk) || (state === s_walk && io.snpt.useSnpt && io.redirect.valid)\n\
      166:   private val useSnapshot = RegNext(useSnapshotNext)\n167:   private val
      snapshotVType = RegEnable(walkVTypeSnapshots(snptSelect), useSnapshotNext)\n\
      168: \n169:   // update enq ptr\n170:   private val enqPtrNext = Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 183-193
    context: "183:   enqPtrVecNext.zipWithIndex.map{ case(ptr, i) => ptr := enqPtrNext
      + i.U }\n184:   enqPtrVec := enqPtrVecNext\n185: \n186:   // update deq ptr\n\
      187:   private val deqPtrSteps = Mux1H(Seq(\n188:     (state === s_idle) ->
      commitCount,\n189:     (state === s_spcl_walk) -> spclWalkCount,\n190:   ))\n\
      191: \n192:   private val deqPtrNext = deqPtr + deqPtrSteps\n193:   private
      val deqPtrOHNext = deqPtrOHVec(deqPtrSteps)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 211-227
    context: "211:     entry.vtype := inst.vpu.vtype\n212:     entry.isVsetvl := VSETOpType.isVsetvl(inst.fuOpType)\n\
      213:   }\n214:   vtypeBufferReadAddrVec := vtypeBufferReadPtrVecNext.map(_.value)\n\
      215: \n216:   private val commitValidVec = Wire(Vec(CommitWidth, Bool()))\n\
      217:   private val walkValidVec = Wire(Vec(CommitWidth, Bool()))\n218:   private
      val infoVec = Wire(Vec(CommitWidth, VType()))\n219:   private val hasVsetvlVec
      = Wire(Vec(CommitWidth, Bool()))\n220: \n221:   for (i <- 0 until CommitWidth)
      {\n222:     commitValidVec(i) := state === s_idle && i.U < commitSize || state
      === s_spcl_walk && i.U < spclWalkSize\n223:     walkValidVec(i) := state ===
      s_walk && i.U < walkSize || state === s_spcl_walk && i.U < spclWalkSize\n224:\
      \ \n225:     infoVec(i) := vtypeBufferReadDataVec(i).vtype\n226:     hasVsetvlVec(i)
      := vtypeBufferReadDataVec(i).isVsetvl\n227:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 224-234
    context: "224: \n225:     infoVec(i) := vtypeBufferReadDataVec(i).vtype\n226:\
      \     hasVsetvlVec(i) := vtypeBufferReadDataVec(i).isVsetvl\n227:   }\n228:\
      \ \n229:   commitCount   := Mux(state === s_idle,      PopCount(commitValidVec),
      0.U)\n230:   walkCount     := Mux(state === s_walk,      PopCount(walkValidVec),
      0.U)\n231:   spclWalkCount := Mux(state === s_spcl_walk, PopCount(walkValidVec),
      0.U)\n232: \n233:   private val walkEndNext = walkSizeNext === 0.U\n234:   private
      val spclWalkEndNext = spclWalkSizeNext === 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 233-243
    context: "233:   private val walkEndNext = walkSizeNext === 0.U\n234:   private
      val spclWalkEndNext = spclWalkSizeNext === 0.U\n235: \n236:   state := stateNext\n\
      237: \n238:   when (io.redirect.valid) {\n239:     when (io.snpt.useSnpt) {\n\
      240:       stateNext := s_walk\n241:     }.otherwise {\n242:       stateNext
      := s_spcl_walk\n243:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 269-280
    context: "269:     true.B\n270:   )\n271: \n272:   private val decodeResumeVType
      = RegInit(0.U.asTypeOf(new ValidIO(VType())))\n273:   private val newestVType
      = PriorityMux(walkValidVec.zip(infoVec).map { case(walkValid, info) => walkValid
      -> info }.reverse)\n274:   private val newestArchVType = PriorityMux(commitValidVec.zip(infoVec).map
      { case(commitValid, info) => commitValid -> info }.reverse)\n275:   private
      val commitVTypeValid = commitValidVec.asUInt.orR\n276:   private val walkToArchVType
      = RegInit(false.B)\n277: \n278:   walkToArchVType := false.B\n279: \n280:  \
      \ when (state === s_spcl_walk) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 277-287
    context: "277: \n278:   walkToArchVType := false.B\n279: \n280:   when (state
      === s_spcl_walk) {\n281:     // special walk use commit vtype\n282:     decodeResumeVType.valid
      := commitVTypeValid\n283:     decodeResumeVType.bits := newestArchVType\n284:\
      \   }.elsewhen (useSnapshot) {\n285:     // use snapshot vtype\n286:     decodeResumeVType.valid
      := true.B\n287:     decodeResumeVType.bits := snapshotVType"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 303-320
    context: "303:   // note that VTypeBuffer can still send resuming request in the
      first cycle of s_idle\n304:   io.toDecode.isResumeVType := state =/= s_idle
      || decodeResumeVType.valid\n305:   io.toDecode.walkVType.valid := decodeResumeVType.valid\n\
      306:   io.toDecode.walkVType.bits := Mux(io.toDecode.walkVType.valid, decodeResumeVType.bits,
      0.U.asTypeOf(VType()))\n307: \n308:   io.toDecode.commitVType.vtype.valid :=
      commitVTypeValid\n309:   io.toDecode.commitVType.vtype.bits := newestArchVType\n\
      310: \n311:   io.toDecode.walkToArchVType := walkToArchVType\n312: \n313:  \
      \ // because vsetvl flush pipe, there is only one vset instruction when vsetvl
      is committed\n314:   private val hasVsetvl = commitValidVec.zip(hasVsetvlVec).map
      { case(commitValid, hasVsetvl) => commitValid && hasVsetvl }.reduce(_ || _)\n\
      315:   io.toDecode.commitVType.hasVsetvl := hasVsetvl\n316: \n317:   XSError(isBefore(enqPtr,
      deqPtr) && !isFull(enqPtr, deqPtr), \"\\ndeqPtr is older than enqPtr!\\n\")\n\
      318: \n319:   QueuePerf(size, numValidEntries, numValidEntries === size.U)\n\
      320: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/VTypeBuffer.scala
    lines: 330-352
    context: "330: \n331:   dontTouch(enqPtrVec)\n332:   dontTouch(deqPtrVec)\n333:\
      \   dontTouch(deqPtr)\n334:   dontTouch(numValidEntries)\n335:   dontTouch(commitCount)\n\
      336:   dontTouch(walkCount)\n337:   dontTouch(spclWalkCount)\n338:   dontTouch(commitSize)\n\
      339:   dontTouch(walkSize)\n340:   dontTouch(spclWalkSize)\n341:   dontTouch(commitSizeNext)\n\
      342:   dontTouch(walkSizeNext)\n343:   dontTouch(spclWalkSizeNext)\n344:   dontTouch(newCommitSize)\n\
      345:   dontTouch(newWalkSize)\n346:   dontTouch(newSpclWalkSize)\n347:   dontTouch(commitValidVec)\n\
      348:   dontTouch(walkValidVec)\n349:   dontTouch(infoVec)\n350: }\n351: \n352: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobEnqPtrWrapper.scala
    lines: 35-45
    context: "35: import xiangshan.backend.rename.SnapshotGenerator\n36: \n37: class
      RobEnqPtrWrapper(implicit p: Parameters) extends XSModule with HasCircularQueuePtrHelper
      {\n38:   val io = IO(new Bundle {\n39:     // for input redirect\n40:     val
      redirect = Input(Valid(new Redirect))\n41:     // for enqueue\n42:     val allowEnqueue
      = Input(Bool())\n43:     val hasBlockBackward = Input(Bool())\n44:     val enq
      = Vec(RenameWidth, Input(Bool()))\n45:     val out = Output(Vec(RenameWidth,
      new RobPtr))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobEnqPtrWrapper.scala
    lines: 50-61
    context: "50:   // enqueue\n51:   val canAccept = io.allowEnqueue && !io.hasBlockBackward\n\
      52:   val dispatchNum = Mux(canAccept, PopCount(io.enq), 0.U)\n53: \n54:   for
      ((ptr, i) <- enqPtrVec.zipWithIndex) {\n55:     when(io.redirect.valid) {\n\
      56:       ptr := Mux(io.redirect.bits.flushItself(), io.redirect.bits.robIdx
      + i.U, io.redirect.bits.robIdx + (i + 1).U)\n57:     }.otherwise {\n58:    \
      \   ptr := ptr + dispatchNum\n59:     }\n60:   }\n61: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 51-62
    context: "51:     // They have side effects on the states of the processor before
      they write back\n52:     val interrupt_safe = Bool()\n53:     val fpWen = Bool()\n\
      54:     val rfWen = Bool()\n55:     val wflags = Bool()\n56:     val dirtyVs
      = Bool()\n57:     val commitType = CommitType()\n58:     val ftqIdx = new FtqPtr\n\
      59:     val ftqOffset = UInt(log2Up(PredictWidth).W)\n60:     val isRVC = Bool()\n\
      61:     val isVset = Bool()\n62:     val isHls = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 90-101
    context: "90: \n91:   }\n92: \n93:   class RobCommitEntryBundle(implicit p: Parameters)
      extends XSBundle {\n94:     val walk_v = Bool()\n95:     val commit_v = Bool()\n\
      96:     val commit_w = Bool()\n97:     val realDestSize = UInt(log2Up(MaxUopSize
      + 1).W)\n98:     val interrupt_safe = Bool()\n99:     val wflags = Bool()\n\
      100:     val fflags = UInt(5.W)\n101:     val vxsat = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 103-113
    context: "103:     val isVset = Bool()\n104:     val isHls = Bool()\n105:    \
      \ val isVls = Bool()\n106:     val vls = Bool()\n107:     val mmio = Bool()\n\
      108:     val commitType = CommitType()\n109:     val ftqIdx = new FtqPtr\n110:\
      \     val ftqOffset = UInt(log2Up(PredictWidth).W)\n111:     val instrSize =
      UInt(log2Ceil(RenameWidth + 1).W)\n112:     val fpWen = Bool()\n113:     val
      rfWen = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 120-136
    context: "120:     val debug_ldest = OptionWrapper(backendParams.basicDebugEn,
      UInt(LogicRegsWidth.W))\n121:     val debug_pdest = OptionWrapper(backendParams.basicDebugEn,
      UInt(PhyRegIdxWidth.W))\n122:     val debug_otherPdest = OptionWrapper(backendParams.basicDebugEn,
      Vec(7, UInt(PhyRegIdxWidth.W)))\n123:     val debug_fuType = OptionWrapper(backendParams.debugEn,
      FuType())\n124:     // debug_end\n125:     val dirtyFs = Bool()\n126:     val
      dirtyVs = Bool()\n127:   }\n128: \n129:   def connectEnq(robEntry: RobEntryBundle,
      robEnq: DynInst): Unit = {\n130:     robEntry.wflags := robEnq.wfflags\n131:\
      \     robEntry.commitType := robEnq.commitType\n132:     robEntry.ftqIdx :=
      robEnq.ftqPtr\n133:     robEntry.ftqOffset := robEnq.ftqOffset\n134:     robEntry.isRVC
      := robEnq.preDecodeInfo.isRVC\n135:     robEntry.isVset := robEnq.isVset\n136:\
      \     robEntry.isHls := robEnq.isHls"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 134-145
    context: "134:     robEntry.isRVC := robEnq.preDecodeInfo.isRVC\n135:     robEntry.isVset
      := robEnq.isVset\n136:     robEntry.isHls := robEnq.isHls\n137:     robEntry.instrSize
      := robEnq.instrSize\n138:     robEntry.rfWen := robEnq.rfWen\n139:     robEntry.fpWen
      := robEnq.dirtyFs\n140:     robEntry.dirtyVs := robEnq.dirtyVs\n141:     //
      flushPipe needFlush but not exception\n142:     robEntry.needFlush := robEnq.hasException
      || robEnq.flushPipe\n143:     // trace\n144:     robEntry.traceBlockInPipe :=
      robEnq.traceBlockInPipe\n145:     robEntry.debug_pc.foreach(_ := robEnq.pc)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 149-160
    context: "149:     robEntry.debug_fuType.foreach(_ := robEnq.fuType)\n150:   }\n\
      151: \n152:   def connectCommitEntry(robCommitEntry: RobCommitEntryBundle, robEntry:
      RobEntryBundle): Unit = {\n153:     robCommitEntry.walk_v := robEntry.valid\n\
      154:     robCommitEntry.commit_v := robEntry.valid\n155:     robCommitEntry.commit_w
      := (robEntry.uopNum === 0.U) && (robEntry.stdWritebacked === true.B)\n156: \
      \    robCommitEntry.realDestSize := robEntry.realDestSize\n157:     robCommitEntry.interrupt_safe
      := robEntry.interrupt_safe\n158:     robCommitEntry.rfWen := robEntry.rfWen\n\
      159:     robCommitEntry.fpWen := robEntry.fpWen\n160:     robCommitEntry.fflags
      := robEntry.fflags"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 166-179
    context: "166:     robCommitEntry.isVls := robEntry.vls\n167:     robCommitEntry.vls
      := robEntry.vls\n168:     robCommitEntry.mmio := robEntry.mmio\n169:     robCommitEntry.ftqIdx
      := robEntry.ftqIdx\n170:     robCommitEntry.ftqOffset := robEntry.ftqOffset\n\
      171:     robCommitEntry.commitType := robEntry.commitType\n172:     robCommitEntry.instrSize
      := robEntry.instrSize\n173:     robCommitEntry.dirtyFs := robEntry.fpWen ||
      robEntry.wflags\n174:     robCommitEntry.dirtyVs := robEntry.dirtyVs\n175: \
      \    robCommitEntry.needFlush := robEntry.needFlush\n176:     robCommitEntry.traceBlockInPipe
      := robEntry.traceBlockInPipe\n177:     robCommitEntry.debug_pc.foreach(_ :=
      robEntry.debug_pc.get)\n178:     robCommitEntry.debug_instr.foreach(_ := robEntry.debug_instr.get)\n\
      179:     robCommitEntry.debug_ldest.foreach(_ := robEntry.debug_ldest.get)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 188-209
    context: "188:   entries\n189: ) with HasCircularQueuePtrHelper {\n190: \n191:\
      \   def this()(implicit p: Parameters) = this(p(XSCoreParamsKey).RobSize)\n\
      192: \n193:   def needFlush(redirect: Valid[Redirect]): Bool = {\n194:     val
      flushItself = redirect.bits.flushItself() && this === redirect.bits.robIdx\n\
      195:     redirect.valid && (flushItself || isAfter(this, redirect.bits.robIdx))\n\
      196:   }\n197: \n198:   def needFlush(redirect: Seq[Valid[Redirect]]): Bool
      = VecInit(redirect.map(needFlush)).asUInt.orR\n199: \n200:   def lineHeadPtr(implicit
      p: Parameters): RobPtr = {\n201:     val CommitWidth = p(XSCoreParamsKey).CommitWidth\n\
      202:     val out = Wire(new RobPtr)\n203:     out.flag := this.flag\n204:  \
      \   out.value := Cat(this.value(this.PTR_WIDTH-1, log2Up(CommitWidth)), 0.U(log2Up(CommitWidth).W))\n\
      205:     out\n206:   }\n207: \n208: }\n209: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 224-235
    context: "224:   val criticalErrorState = Input(Bool())\n225: \n226:   val fflags\
      \     = Output(Valid(UInt(5.W)))\n227:   val vxsat      = Output(Valid(Bool()))\n\
      228:   val vstart     = Output(Valid(UInt(XLEN.W)))\n229:   val dirty_fs   =
      Output(Bool())\n230:   val dirty_vs   = Output(Bool())\n231:   val perfinfo\
      \   = new Bundle {\n232:     val retiredInstr = Output(UInt(7.W))\n233:   }\n\
      234: }\n235: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 232-243
    context: "232:     val retiredInstr = Output(UInt(7.W))\n233:   }\n234: }\n235:\
      \ \n236: class RobLsqIO(implicit p: Parameters) extends XSBundle {\n237:   val
      lcommit = Output(UInt(log2Up(CommitWidth + 1).W))\n238:   val scommit = Output(UInt(log2Up(CommitWidth
      + 1).W))\n239:   val pendingMMIOld = Output(Bool())\n240:   val pendingld =
      Output(Bool())\n241:   val pendingst = Output(Bool())\n242:   // set when vector
      store at the head of ROB\n243:   val pendingVst = Output(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 239-249
    context: "239:   val pendingMMIOld = Output(Bool())\n240:   val pendingld = Output(Bool())\n\
      241:   val pendingst = Output(Bool())\n242:   // set when vector store at the
      head of ROB\n243:   val pendingVst = Output(Bool())\n244:   val commit = Output(Bool())\n\
      245:   val pendingPtr = Output(new RobPtr)\n246:   val pendingPtrNext = Output(new
      RobPtr)\n247: \n248:   val mmio = Input(Vec(LoadPipelineWidth, Bool()))\n249:\
      \   // Todo: what's this?"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 286-296
    context: "286:   val isEnqExcp = Bool()\n287:   val exceptionVec = ExceptionVec()\n\
      288:   val isFetchMalAddr = Bool()\n289:   val flushPipe = Bool()\n290:   val
      isVset = Bool()\n291:   val replayInst = Bool() // redirect to that inst itself\n\
      292:   val singleStep = Bool() // TODO add frontend hit beneath\n293:   val
      crossPageIPFFix = Bool()\n294:   val trigger = TriggerAction()\n295:   // if
      vstart is udpated by vector unit\n296:   val vstartEn = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/RobBundles.scala
    lines: 305-315
    context: "305:   val vsew = VSew()\n306:   val veew = VSew()\n307:   val vlmul
      = VLmul()\n308: \n309:   def has_exception = hasException || flushPipe || singleStep
      || replayInst || TriggerAction.isDmode(trigger)\n310:   def not_commit = hasException
      || singleStep || replayInst || TriggerAction.isDmode(trigger)\n311:   // only
      exceptions are allowed to writeback when enqueue\n312:   def can_writeback =
      hasException || singleStep || TriggerAction.isDmode(trigger)\n313: }\n314: \n\
      315: class RobFlushInfo(implicit p: Parameters) extends XSBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/ExceptionGen.scala
    lines: 34-44
    context: "34: import xiangshan.backend.fu.vector.Bundles.VType\n35: import xiangshan.backend.rename.SnapshotGenerator\n\
      36: \n37: class ExceptionGen(params: BackendParams)(implicit p: Parameters)
      extends XSModule with HasCircularQueuePtrHelper {\n38:   val io = IO(new Bundle
      {\n39:     val redirect = Input(Valid(new Redirect))\n40:     val flush = Input(Bool())\n\
      41:     val enq = Vec(RenameWidth, Flipped(ValidIO(new RobExceptionInfo)))\n\
      42:     // csr + load + store + varith + vload + vstore\n43:     val wb = Vec(params.numException,
      Flipped(ValidIO(new RobExceptionInfo)))\n44:     val out = ValidIO(new RobExceptionInfo)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/ExceptionGen.scala
    lines: 93-103
    context: "93:   val vls_wb = io.wb.zip(wbExuParams).filter(_._2.fuConfigs.exists(x
      => FuType.FuTypeOrR(x.fuType, FuType.vecMem))).map(_._1)\n94: \n95:   val writebacks
      = Seq(csr_wb, load_wb, store_wb, varith_wb, vls_wb)\n96:   val in_wb_valids
      = writebacks.map(_.map(w => w.valid && w.bits.has_exception && !lastCycleFlush))\n\
      97:   val wb_valid = in_wb_valids.zip(writebacks).map { case (valid, wb) =>\n\
      98:     valid.zip(wb.map(_.bits)).map { case (v, bits) => v && !(bits.robIdx.needFlush(io.redirect)
      || io.flush) }.reduce(_ || _)\n99:   }\n100:   val wb_bits = in_wb_valids.zip(writebacks).map
      { case (valid, wb) => getOldest(valid, wb.map(_.bits))}\n101: \n102:   val s0_out_valid
      = wb_valid.map(x => RegNext(x))\n103:   val s0_out_bits = wb_bits.zip(wb_valid).map{
      case(b, v) => RegEnable(b, v)}"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/ExceptionGen.scala
    lines: 101-116
    context: "101: \n102:   val s0_out_valid = wb_valid.map(x => RegNext(x))\n103:\
      \   val s0_out_bits = wb_bits.zip(wb_valid).map{ case(b, v) => RegEnable(b,
      v)}\n104: \n105:   // s1: compare last six and current flush\n106:   val s1_valid
      = VecInit(s0_out_valid.zip(s0_out_bits).map{ case (v, b) => v && !(b.robIdx.needFlush(io.redirect)
      || io.flush) })\n107:   val s1_out_bits = RegEnable(getOldest(s0_out_valid,
      s0_out_bits), s1_valid.asUInt.orR)\n108:   val s1_out_valid = RegNext(s1_valid.asUInt.orR)\n\
      109: \n110:   val enq_s1_valid = RegNext(enq_s0_valid.asUInt.orR && !io.redirect.valid
      && !io.flush)\n111:   val enq_s1_bits: RobExceptionInfo = RegEnable(ParallelPriorityMux(enq_s0_valid,
      enq_s0_bits), enq_s0_valid.asUInt.orR && !io.redirect.valid && !io.flush)\n\
      112: \n113:   // s2: compare the input exception with the current one\n114:\
      \   // priorities:\n115:   // (1) system reset\n116:   // (2) current is valid:
      flush, remain, merge, update"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/ExceptionGen.scala
    lines: 113-124
    context: "113:   // s2: compare the input exception with the current one\n114:\
      \   // priorities:\n115:   // (1) system reset\n116:   // (2) current is valid:
      flush, remain, merge, update\n117:   // (3) current is not valid: s1 or enq\n\
      118:   val current_flush = current.robIdx.needFlush(io.redirect) || io.flush\n\
      119:   val s1_flush = s1_out_bits.robIdx.needFlush(io.redirect) || io.flush\n\
      120: \n121:   val isVecUpdate = s1_out_bits.vstart < current.vstart || !current.vstartEn\n\
      122:   when (currentValid) {\n123:     when (current_flush) {\n124:       currentValid
      := Mux(s1_flush, false.B, s1_out_valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rob/ExceptionGen.scala
    lines: 152-162
    context: "152:     }\n153:   }.elsewhen (s1_out_valid && !s1_flush) {\n154:  \
      \   currentValid := true.B\n155:     current := s1_out_bits\n156:     current.isEnqExcp
      := false.B\n157:   }.elsewhen (enq_s1_valid && !(io.redirect.valid || io.flush))
      {\n158:     currentValid := true.B\n159:     current := enq_s1_bits\n160:  \
      \   current.isEnqExcp := true.B\n161:   }\n162: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 100-110
    context: "100:     val v0Wen           = Bool()\n101:     val vlWen          \
      \ = Bool()\n102:     val isXSTrap        = Bool()\n103:     val waitForward\
      \     = Bool() // no speculate execution\n104:     val blockBackward   = Bool()\n\
      105:     val flushPipe       = Bool() // This inst will flush all the pipe when
      commit, like exception but can commit\n106:     val canRobCompress  = Bool()\n\
      107:     val selImm          = SelImm()\n108:     val imm             = UInt(ImmUnion.maxLen.W)\n\
      109:     val fpu             = new FPUCtrlSignals\n110:     val vpu        \
      \     = new VPUCtrlSignals"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 116-126
    context: "116:     val isVset          = Bool()\n117:     val firstUop       \
      \ = Bool()\n118:     val lastUop         = Bool()\n119:     val numUops    \
      \     = UInt(log2Up(MaxUopSize).W) // rob need this\n120:     val numWB    \
      \       = UInt(log2Up(MaxUopSize).W) // rob need this\n121:     val commitType\
      \      = CommitType() // Todo: remove it\n122:     val needFrm         = new
      NeedFrmBundle\n123: \n124:     val debug_fuType    = OptionWrapper(backendParams.debugEn,
      FuType())\n125:     val debug_seqNum    = InstSeqNum()\n126: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 199-209
    context: "199:     val v0Wen           = Bool()\n200:     val vlWen          \
      \ = Bool()\n201:     val isXSTrap        = Bool()\n202:     val waitForward\
      \     = Bool() // no speculate execution\n203:     val blockBackward   = Bool()\n\
      204:     val flushPipe       = Bool() // This inst will flush all the pipe when
      commit, like exception but can commit\n205:     val canRobCompress  = Bool()\n\
      206:     val selImm          = SelImm()\n207:     val imm             = UInt(32.W)\n\
      208:     val fpu             = new FPUCtrlSignals\n209:     val vpu        \
      \     = new VPUCtrlSignals"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 215-225
    context: "215:     val isVset          = Bool()\n216:     val firstUop       \
      \ = Bool()\n217:     val lastUop         = Bool()\n218:     val numUops    \
      \     = UInt(log2Up(MaxUopSize).W) // rob need this\n219:     val numWB    \
      \       = UInt(log2Up(MaxUopSize).W) // rob need this\n220:     val commitType\
      \      = CommitType()\n221:     // rename\n222:     val srcState        = Vec(numSrc,
      SrcState())\n223:     val srcLoadDependency  = Vec(numSrc, Vec(LoadPipelineWidth,
      UInt(LoadDependencyWidth.W)))\n224:     val psrc            = Vec(numSrc, UInt(PhyRegIdxWidth.W))\n\
      225:     val pdest           = UInt(PhyRegIdxWidth.W)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 226-237
    context: "226:     // reg cache\n227:     val useRegCache     = Vec(backendParams.numIntRegSrc,
      Bool())\n228:     val regCacheIdx     = Vec(backendParams.numIntRegSrc, UInt(RegCacheIdxWidth.W))\n\
      229:     val robIdx          = new RobPtr\n230:     val instrSize       = UInt(log2Ceil(RenameWidth
      + 1).W)\n231:     val dirtyFs         = Bool()\n232:     val dirtyVs       \
      \  = Bool()\n233:     val traceBlockInPipe = new TracePipe(IretireWidthInPipe)\n\
      234: \n235:     val eliminatedMove  = Bool()\n236:     // Take snapshot at this
      CFI inst\n237:     val snapshot        = Bool()"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 710-720
    context: "710:     val intWen       = if (params.needIntWen)   Some(Bool())  \
      \                else None\n711:     val fpWen        = if (params.needFpWen)\
      \    Some(Bool())                  else None\n712:     val vecWen       = if
      (params.needVecWen)   Some(Bool())                  else None\n713:     val
      v0Wen        = if (params.needV0Wen)    Some(Bool())                  else None\n\
      714:     val vlWen        = if (params.needVlWen)    Some(Bool())          \
      \        else None\n715:     val redirect     = if (params.hasRedirect)  Some(ValidIO(new
      Redirect))   else None\n716:     val fflags       = if (params.writeFflags)\
      \  Some(UInt(5.W))               else None\n717:     val wflags       = if (params.writeFflags)\
      \  Some(Bool())                  else None\n718:     val vxsat        = if (params.writeVxsat)\
      \   Some(Bool())                  else None\n719:     val exceptionVec = if
      (params.exceptionOut.nonEmpty) Some(ExceptionVec()) else None\n720:     val
      flushPipe    = if (params.flushPipe)    Some(Bool())                  else None"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 753-763
    context: "753:     val pdest = UInt(params.pregIdxWidth(backendParams).W)\n754:\
      \     val data = UInt(params.dataWidth.W)\n755:     val robIdx = new RobPtr()(p)\n\
      756:     val flushPipe = Bool()\n757:     val replayInst = Bool()\n758:    \
      \ val redirect = ValidIO(new Redirect)\n759:     val fflags = UInt(5.W)\n760:\
      \     val vxsat = Bool()\n761:     val exceptionVec = ExceptionVec()\n762: \
      \    val debug = new DebugBundle\n763:     val debugInfo = new PerfDebugInfo"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 775-785
    context: "775:       this.pdest  := source.pdest\n776:       this.data   := source.data(source.params.wbIndex(typeMap(wbType)))\n\
      777:       this.robIdx := source.robIdx\n778:       this.flushPipe := source.flushPipe.getOrElse(false.B)\n\
      779:       this.replayInst := source.replay.getOrElse(false.B)\n780:       this.redirect
      := source.redirect.getOrElse(0.U.asTypeOf(this.redirect))\n781:       this.fflags
      := source.fflags.getOrElse(0.U.asTypeOf(this.fflags))\n782:       this.vxsat
      := source.vxsat.getOrElse(0.U.asTypeOf(this.vxsat))\n783:       this.exceptionVec
      := source.exceptionVec.getOrElse(0.U.asTypeOf(this.exceptionVec))\n784:    \
      \   this.debug := source.debug\n785:       this.debugInfo := source.debugInfo"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Bundles.scala
    lines: 864-874
    context: "864:   }\n865: \n866:   class ExceptionInfo(implicit p: Parameters)
      extends XSBundle {\n867:     val pc = UInt(VAddrData().dataWidth.W)\n868:  \
      \   val instr = UInt(32.W)\n869:     val commitType = CommitType()\n870:   \
      \  val exceptionVec = ExceptionVec()\n871:     val isPcBkpt = Bool()\n872: \
      \    val isFetchMalAddr = Bool()\n873:     val gpaddr = UInt(XLEN.W)\n874: \
      \    val singleStep = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/TraceBuffer.scala
    lines: 11-24
    context: "11:   with HasCircularQueuePtrHelper {\n12: \n13:   val io = IO(new
      Bundle {\n14:     val in = new Bundle{\n15:       val fromEncoder = Input(new
      FromEncoder)\n16:       val fromRob     = Flipped(new TraceBundle(hasIaddr =
      false, CommitWidth, IretireWidthCompressed))\n17:     }\n18:     val out = new
      Bundle { // output groups to pcMem\n19:       val blockCommit = Output(Bool())\n\
      20:       val groups = new TraceBundle(hasIaddr = false, TraceGroupNum, IretireWidthCompressed)\n\
      21:     }\n22:   })\n23: \n24:   // buffer: compress info from robCommit"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/TraceBuffer.scala
    lines: 20-31
    context: "20:       val groups = new TraceBundle(hasIaddr = false, TraceGroupNum,
      IretireWidthCompressed)\n21:     }\n22:   })\n23: \n24:   // buffer: compress
      info from robCommit\n25:   val traceEntries = Reg(Vec(CommitWidth, ValidIO(new
      TraceBlock(false, IretireWidthCompressed))))\n26:   val blockCommit = RegInit(false.B)
      // to rob\n27: \n28:   /**\n29:    * compress, update blocks\n30:    */\n31:\
      \   val inValidVec = VecInit(io.in.fromRob.blocks.map(_.valid))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/TraceBuffer.scala
    lines: 27-45
    context: "27: \n28:   /**\n29:    * compress, update blocks\n30:    */\n31:  \
      \ val inValidVec = VecInit(io.in.fromRob.blocks.map(_.valid))\n32:   val inTypeIsNotNoneVec
      = VecInit(io.in.fromRob.blocks.map(block => Itype.isNotNone(block.bits.tracePipe.itype)))\n\
      33:   val needPcVec = Wire(Vec(CommitWidth, Bool()))\n34:   for(i <- 0 until
      CommitWidth) {\n35:     val rightHasValid = if(i == CommitWidth - 1) false.B\
      \  else (inValidVec.asUInt(CommitWidth-1, i+1).orR)\n36:     needPcVec(i) :=
      inValidVec(i) & (inTypeIsNotNoneVec(i) || !rightHasValid) & !blockCommit\n37:\
      \   }\n38: \n39:   val blocksUpdate = WireInit(io.in.fromRob.blocks)\n40:  \
      \ for(i <- 1 until CommitWidth){\n41:     when(!needPcVec(i-1)){\n42:      \
      \ blocksUpdate(i).bits.tracePipe.iretire := blocksUpdate(i - 1).bits.tracePipe.iretire
      + io.in.fromRob.blocks(i).bits.tracePipe.iretire\n43:       blocksUpdate(i).bits.ftqOffset.get
      := blocksUpdate(i - 1).bits.ftqOffset.get\n44:       blocksUpdate(i).bits.ftqIdx.get
      := blocksUpdate(i - 1).bits.ftqIdx.get\n45:      }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/TraceBuffer.scala
    lines: 46-57
    context: "46:   }\n47: \n48:   /**\n49:    * enq to traceEntries\n50:    */\n\
      51:   val countVec = VecInit((0 until CommitWidth).map(i => PopCount(needPcVec.asUInt(i,
      0))))\n52:   val numNeedPc = countVec(CommitWidth-1)\n53: \n54:   val enqPtr
      = RegInit(TracePtr(false.B, 0.U))\n55:   val deqPtr = RegInit(TracePtr(false.B,
      0.U))\n56:   val deqPtrPre = RegNext(deqPtr)\n57:   val enqPtrNext = WireInit(enqPtr)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/TraceBuffer.scala
    lines: 57-67
    context: "57:   val enqPtrNext = WireInit(enqPtr)\n58:   val deqPtrNext = WireInit(deqPtr)\n\
      59:   enqPtr := enqPtrNext\n60:   deqPtr := deqPtrNext\n61:   val canNotTraceAll
      = distanceBetween(enqPtrNext, deqPtrNext) > 0.U\n62:   blockCommit := io.in.fromEncoder.enable
      && (canNotTraceAll || io.in.fromEncoder.stall)\n63: \n64:   enqPtrNext := enqPtr
      + numNeedPc\n65:   deqPtrNext := Mux(deqPtr + TraceGroupNum.U > enqPtrNext,
      enqPtrNext, deqPtr + TraceGroupNum.U)\n66: \n67:   val traceIdxVec = VecInit(countVec.map(count
      => (enqPtr + count - 1.U).value))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/TraceBuffer.scala
    lines: 63-73
    context: "63: \n64:   enqPtrNext := enqPtr + numNeedPc\n65:   deqPtrNext := Mux(deqPtr
      + TraceGroupNum.U > enqPtrNext, enqPtrNext, deqPtr + TraceGroupNum.U)\n66: \n\
      67:   val traceIdxVec = VecInit(countVec.map(count => (enqPtr + count - 1.U).value))\n\
      68:   for(i <- 0 until CommitWidth){\n69:     when(needPcVec(i)){\n70:     \
      \  traceEntries(traceIdxVec(i)) := blocksUpdate(i)\n71:     }\n72:   }\n73: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/TraceBuffer.scala
    lines: 81-91
    context: "81:     } .otherwise {\n82:       blockOut.blocks(i).valid := false.B\n\
      83:     }\n84:   }\n85: \n86:   io.out.blockCommit := blockCommit\n87:   io.out.groups
      := blockOut\n88: \n89:   if(backendParams.debugEn){\n90:     dontTouch(countVec)\n\
      91:     dontTouch(numNeedPc)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/TraceBuffer.scala
    lines: 95-105
    context: "95: \n96: class TracePtr(entries: Int) extends CircularQueuePtr[TracePtr](\n\
      97:   entries\n98: ) with HasCircularQueuePtrHelper {\n99: \n100:   def this()(implicit
      p: Parameters) = this(p(XSCoreParamsKey).CommitWidth)\n101: \n102: }\n103: \n\
      104: object TracePtr {\n105:   def apply(f: Bool, v: UInt)(implicit p: Parameters):
      TracePtr = {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/Trace.scala
    lines: 14-24
    context: "14: )\n15: \n16: class TraceIO(implicit val p: Parameters) extends Bundle
      with HasXSParameter {\n17:   val in = new Bundle {\n18:     val fromEncoder\
      \    = Input(new FromEncoder)\n19:     val fromRob        = Flipped(new TraceBundle(hasIaddr
      = false, CommitWidth, IretireWidthInPipe))\n20:   }\n21:   val out = new Bundle
      {\n22:     val toPcMem        = new TraceBundle(hasIaddr = false, TraceGroupNum,
      IretireWidthCompressed)\n23:     val toEncoder      = new TraceBundle(hasIaddr
      = false,  TraceGroupNum, IretireWidthCompressed)\n24:     val blockRobCommit
      = Output(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/Trace.scala
    lines: 30-41
    context: "30:   val (fromEncoder, fromRob, toPcMem, toEncoder) = (io.in.fromEncoder,
      io.in.fromRob, io.out.toPcMem, io.out.toEncoder)\n31: \n32:   /**\n33:    *
      stage 0: CommitInfo from rob\n34:    */\n35:   val blockCommit = Wire(Bool())\n\
      36:   io.out.blockRobCommit := blockCommit\n37: \n38:   /**\n39:    * stage
      1: regNext(robCommitInfo)\n40:    */\n41:   val s1_in = fromRob"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/Trace.scala
    lines: 38-49
    context: "38:   /**\n39:    * stage 1: regNext(robCommitInfo)\n40:    */\n41:\
      \   val s1_in = fromRob\n42:   val s1_out = WireInit(0.U.asTypeOf(s1_in))\n\
      43:   for(i <- 0 until CommitWidth) {\n44:     s1_out.blocks(i).valid := RegEnable(s1_in.blocks(i).valid,
      false.B, !blockCommit)\n45:     s1_out.blocks(i).bits := RegEnable(s1_in.blocks(i).bits,
      0.U.asTypeOf(s1_in.blocks(i).bits), s1_in.blocks(i).valid)\n46:   }\n47: \n\
      48:   /**\n49:    * stage 2: compress, s2_out(deq from traceBuffer) -> pcMem"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/Trace.scala
    lines: 51-61
    context: "51:   val s2_in = s1_out\n52:   val traceBuffer = Module(new TraceBuffer)\n\
      53:   traceBuffer.io.in.fromEncoder := fromEncoder\n54:   traceBuffer.io.in.fromRob
      := s2_in\n55:   val s2_out_groups = traceBuffer.io.out.groups\n56:   blockCommit
      := traceBuffer.io.out.blockCommit\n57: \n58:   /**\n59:    * stage 3: groups
      with iaddr from pcMem(ftqidx & ftqOffset -> iaddr) -> encoder\n60:    */\n61:\
      \   val s3_in_groups = s2_out_groups"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/Interface.scala
    lines: 13-23
    context: "13:   val lastPriv    = Priv()\n14:   val currentPriv = Priv()\n15:
      }\n16: \n17: class TracePipe(iretireWidth: Int)(implicit val p: Parameters)
      extends Bundle with HasXSParameter {\n18:   val itype     = Itype()\n19:   val
      iretire   = UInt(iretireWidth.W)\n20:   val ilastsize = Ilastsize()\n21: }\n\
      22: \n23: class TraceBlock(hasIaddr: Boolean, iretireWidth: Int)(implicit val
      p: Parameters) extends Bundle with HasXSParameter {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/Interface.scala
    lines: 48-58
    context: "48:       val tval  = UInt(TvalWidth.W)\n49:     }\n50:     val groups
      = Vec(TraceGroupNum, ValidIO(new Bundle{\n51:       val iaddr     = UInt(IaddrWidth.W)\n\
      52:       val ftqOffset = if (hasOffset)  Some(UInt(log2Up(PredictWidth).W))
      else None\n53:       val itype     = UInt(ItypeWidth.W)\n54:       val iretire\
      \   = UInt(IretireWidthCompressed.W)\n55:       val ilastsize = UInt(IlastsizeWidth.W)\n\
      56:     }))\n57:   })\n58: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/Interface.scala
    lines: 55-72
    context: "55:       val ilastsize = UInt(IlastsizeWidth.W)\n56:     }))\n57: \
      \  })\n58: }\n59: \n60: object Itype extends NamedUInt(4) {\n61:   def None\
      \                 = 0.U\n62:   def Exception            = 1.U    //rob\n63:\
      \   def Interrupt            = 2.U    //rob\n64:   def ExpIntReturn        \
      \ = 3.U    //rename\n65:   def NonTaken             = 4.U    //commit\n66: \
      \  def Taken                = 5.U    //commit\n67:   def UninferableJump   \
      \   = 6.U    //It's reserved when width of itype is 4.\n68:   def reserved \
      \            = 7.U    //reserved\n69:   def UninferableCall      = 8.U    //rename\n\
      70:   def InferableCall        = 9.U    //rename\n71:   def UninferableTailCall\
      \  = 10.U   //rename\n72:   def InferableTailCall    = 11.U   //rename"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/trace/Interface.scala
    lines: 121-141
    context: "121:     )\n122: \n123:     Mux(isBranch || isJal || isJalr, jumpType,
      0.U)\n124:   }\n125: \n126:   def isTrap(itype: UInt) = Seq(Exception, Interrupt).map(_
      === itype).reduce(_ || _)\n127: \n128:   def isTrapOrXret(itype: UInt) = Seq(Exception,
      Interrupt, ExpIntReturn).map(_ === itype).reduce(_ || _)\n129: \n130:   def
      isNotNone(itype: UInt) = itype =/= None\n131: \n132:   def isBranchType(itype:
      UInt) = itype === Branch\n133: \n134:   // supportSijump\n135:   def isUninferable(itype:
      UInt) = Seq(UninferableCall, UninferableTailCall, CoRoutineSwap,\n136:     UninferableTailCall,
      OtherUninferableJump).map(_ === itype).reduce(_ || _)\n137: }\n138: \n139: object
      Ilastsize extends NamedUInt(1) {\n140:   def HalfWord = 0.U\n141:   def Word\
      \     = 1.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 91-101
    context: "91: class DecodeUnitCompOutput(implicit p: Parameters) extends XSBundle
      {\n92:   val complexDecodedInsts = Vec(RenameWidth, DecoupledIO(new DecodedInst))\n\
      93: }\n94: \n95: class DecodeUnitCompIO(implicit p: Parameters) extends XSBundle
      {\n96:   val redirect = Input(Bool())\n97:   val csrCtrl = Input(new CustomCSRCtrlIO)\n\
      98:   val vtypeBypass = Input(new VType)\n99:   // When the first inst in decode
      vector is complex inst, pass it in\n100:   val in = Flipped(DecoupledIO(new
      DecodeUnitCompInput))\n101:   val out = new DecodeUnitCompOutput"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnitComp.scala
    lines: 2015-2027
    context: "2015:         countNext := count + outReadys.head.asUInt\n2016:    \
      \   }\n2017:     }\n2018:   }\n2019: \n2020:   state := Mux(io.redirect, s_idle,
      stateNext)\n2021:   uopRes := Mux(io.redirect, 0.U, uopResNext)\n2022:   count
      := Mux(io.redirect, 0.U, countNext)\n2023: \n2024:   val complexNum = Mux(uopRes
      > readyCounter, readyCounter, uopRes)\n2025: \n2026:   fixedDecodedInst := csBundle\n\
      2027: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VTypeGen.scala
    lines: 16-26
    context: "16:   val walkToArchVType = Input(Bool())\n17:   val walkVType   = Flipped(Valid(new
      VType))\n18:   val canUpdateVType = Input(Bool())\n19:   val vtype = Output(new
      VType)\n20:   val vsetvlVType = Input(new VType)\n21:   val commitVType = new
      Bundle {\n22:     val vtype = Flipped(Valid(new VType))\n23:     val hasVsetvl
      = Input(Bool())\n24:   }\n25: }\n26: /**"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VTypeGen.scala
    lines: 79-92
    context: "79: \n80:   /** New vtype generated by vsetModule */\n81:   private
      val vtypeNew = vsetModule.io.out.vconfig.vtype\n82: \n83:   /** Set the source
      of vtypeArch from commit instructions */\n84:   when(io.commitVType.hasVsetvl)
      {\n85:     vtypeArchNext := io.vsetvlVType\n86:   }.elsewhen(io.commitVType.vtype.valid)
      {\n87:     vtypeArchNext := io.commitVType.vtype.bits\n88:   }\n89: \n90:  \
      \ /** whether there is a vset instruction among input instructions */\n91: \
      \  private val inHasVset = isVsetVec.asUInt.orR\n92: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VTypeGen.scala
    lines: 95-105
    context: "95:    * 1. committed vsetvl instruction, which flushes the pipeline.\n\
      96:    * 2. walk-vtype, which is used to update vtype when walking.\n97:   \
      \ * 3. walking to architectural vtype\n98:    * 4. new vset instruction\n99:\
      \    */\n100:   when(io.commitVType.hasVsetvl) {\n101:     // when vsetvl instruction
      commit, also update vtypeSpec, because vsetvl flush pipe\n102:     vtypeSpecNext
      := io.vsetvlVType\n103:   }.elsewhen(io.walkVType.valid) {\n104:     vtypeSpecNext
      := io.walkVType.bits\n105:   }.elsewhen(io.walkToArchVType) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/VecDecoder.scala
    lines: 547-562
    context: "547: \n548:     FMUL_S -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.fmac
      , VfmaType.vfmul, F, T, F, UopSplitType.SCA_SIM),\n549:     FMUL_D -> OPFFF(SrcType.fp,
      SrcType.fp, SrcType.X, FuType.fmac , VfmaType.vfmul, F, T, F, UopSplitType.SCA_SIM),\n\
      550:     FMUL_H -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.fmac , VfmaType.vfmul,
      F, T, F, UopSplitType.SCA_SIM),\n551: \n552:     FDIV_S  -> OPFFF(SrcType.fp,
      SrcType.fp, SrcType.X, FuType.fDivSqrt, VfdivType.vfdiv , F, T, F, UopSplitType.SCA_SIM),\n\
      553:     FDIV_D  -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.fDivSqrt,
      VfdivType.vfdiv , F, T, F, UopSplitType.SCA_SIM),\n554:     FDIV_H  -> OPFFF(SrcType.fp,
      SrcType.fp, SrcType.X, FuType.fDivSqrt, VfdivType.vfdiv , F, T, F, UopSplitType.SCA_SIM),\n\
      555:     FSQRT_S -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.fDivSqrt,
      VfdivType.vfsqrt, F, T, F, UopSplitType.SCA_SIM),\n556:     FSQRT_D -> OPFFF(SrcType.fp,
      SrcType.fp, SrcType.X, FuType.fDivSqrt, VfdivType.vfsqrt, F, T, F, UopSplitType.SCA_SIM),\n\
      557:     FSQRT_H -> OPFFF(SrcType.fp, SrcType.fp, SrcType.X, FuType.fDivSqrt,
      VfdivType.vfsqrt, F, T, F, UopSplitType.SCA_SIM),\n558: \n559:     FMADD_S \
      \ -> OPFFF(SrcType.fp, SrcType.fp, SrcType.fp, FuType.fmac, VfmaType.vfmacc
      , F, T, F, UopSplitType.SCA_SIM),\n560:     FMSUB_S  -> OPFFF(SrcType.fp, SrcType.fp,
      SrcType.fp, FuType.fmac, VfmaType.vfmsac , F, T, F, UopSplitType.SCA_SIM),\n\
      561:     FNMADD_S -> OPFFF(SrcType.fp, SrcType.fp, SrcType.fp, FuType.fmac,
      VfmaType.vfnmacc, F, T, F, UopSplitType.SCA_SIM),\n562:     FNMSUB_S -> OPFFF(SrcType.fp,
      SrcType.fp, SrcType.fp, FuType.fmac, VfmaType.vfnmsac, F, T, F, UopSplitType.SCA_SIM),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/isa/predecode/predecode.scala
    lines: 31-41
    context: "31:   def NOP       = BitPat(\"b???????????????0_100_01010_0000001\"\
      )   //li\ta0,0\n32: \n33: \n34:   val brTable = Array(\n35:     // C_JAL   \
      \  -> List(BrType.jal),\n36:     C_EBREAK  -> List(BrType.notCFI), // c.ebreak
      should not be decoded as jalr, higher priority than c.jalr\n37:     C_J    \
      \   -> List(BrType.jal),\n38:     C_JALR    -> List(BrType.jalr),\n39:     C_BRANCH\
      \  -> List(BrType.branch),\n40:     JAL       -> List(BrType.jal),\n41:    \
      \ JALR      -> List(BrType.jalr),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 38-48
    context: "38:   private val numFpRegSrc = backendParams.numFpRegSrc\n39:   private
      val numFpRatPorts = numFpRegSrc\n40:   private val numVecRegSrc = backendParams.numVecRegSrc\n\
      41:   private val numVecRatPorts = numVecRegSrc\n42: \n43:   val redirect =
      Input(Bool())\n44:   val canAccept = Output(Bool())\n45:   // from Ibuffer\n\
      46:   val in = Vec(DecodeWidth, Flipped(DecoupledIO(new StaticInst)))\n47: \
      \  // to Rename\n48:   val out = Vec(DecodeWidth, DecoupledIO(new DecodedInst))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 59-69
    context: "59: \n60:   // vtype update\n61:   val fromRob = new Bundle {\n62: \
      \    val isResumeVType = Input(Bool())\n63:     val walkToArchVType = Input(Bool())\n\
      64:     val commitVType = new Bundle {\n65:       val vtype = Flipped(Valid(new
      VType))\n66:       val hasVsetvl = Input(Bool())\n67:     }\n68:     val walkVType
      = Flipped(Valid(new VType))\n69:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 155-172
    context: "155:   vtypeGen.io.insts.zip(io.in).foreach { case (inst, in) =>\n156:\
      \     inst.valid := in.valid\n157:     inst.bits := in.bits.instr\n158:   }\n\
      159:   // when io.redirect is True, never update vtype\n160:   vtypeGen.io.canUpdateVType
      := decoderComp.io.in.fire && decoderComp.io.in.bits.simpleDecodedInst.isVset
      && !io.redirect\n161:   vtypeGen.io.walkToArchVType := io.fromRob.walkToArchVType\n\
      162:   vtypeGen.io.commitVType := io.fromRob.commitVType\n163:   vtypeGen.io.walkVType
      := io.fromRob.walkVType\n164:   vtypeGen.io.vsetvlVType := io.vsetvlVType\n\
      165: \n166:   //Comp 1\n167:   decoderComp.io.redirect := io.redirect\n168:\
      \   decoderComp.io.csrCtrl := io.csrCtrl\n169:   decoderComp.io.vtypeBypass
      := vtypeGen.io.vtype\n170:   // The input inst of decoderComp is latched last
      cycle.\n171:   // Set input empty, if there is no complex inst latched last
      cycle.\n172:   decoderComp.io.in.valid := complexValid && !io.fromRob.isResumeVType"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 190-200
    context: "190: \n191:   // block vector inst when vtype is resuming\n192:   val
      hasVectorInst = VecInit(decoders.map(x => FuType.FuTypeOrR(x.io.deq.decodedInst.fuType,
      FuType.vecArithOrMem ++ FuType.vecVSET))).asUInt.orR\n193: \n194:   /** condition
      of acceptation: no redirection, ready from rename/complex decoder, no resumeVType
      */\n195:   canAccept := !io.redirect && (io.out.head.ready || decoderComp.io.in.ready)
      && !io.fromRob.isResumeVType\n196: \n197:   io.canAccept := canAccept\n198:\
      \ \n199:   /**\n200:    * Assign ready signal for DecodeStage's input. Ready
      signal in i-th channel:"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 204-214
    context: "204:    * instructions can be passed down to rename together with complex
      decoder's result.\n205:    * Another situation is that first \"i-1\" instructions
      are all simple instructions, and the \"i-th\" instructions needs\n206:    *
      to be sent to complex decoder, with complex decoder ready for new input.\n207:\
      \    */\n208:   io.in.zipWithIndex.foreach { case (in, i) =>\n209:     in.ready
      := !io.redirect && (\n210:       simplePrefixVec(i) && (i.U +& complexNum) <
      readyCounter ||\n211:       firstComplexOH(i) && (i.U +& complexNum) <= readyCounter
      && decoderComp.io.in.ready\n212:     ) && !io.fromRob.isResumeVType\n213:  \
      \ }\n214: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 250-260
    context: "250:   }\n251: \n252:   io.out.map(x =>\n253:     when(x.valid){\n254:\
      \       assert(PopCount(VecInit(x.bits.rfWen, x.bits.fpWen, x.bits.vecWen, x.bits.v0Wen,
      x.bits.vlWen)) < 2.U,\n255:         \"DecodeOut: can't wirte two regfile in
      one uop/instruction\")\n256:     }\n257:   )\n258: \n259:   /**\n260:    * Prepare
      address and hold for output to Rat (Rename Alias Table)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeStage.scala
    lines: 296-310
    context: "296:     out := Mux(io.stallReason.out.backReason.valid,\n297:     \
      \           io.stallReason.out.backReason.bits,\n298:                in)\n299:\
      \   }\n300: \n301:   io.toCSR.trapInstInfo.valid := hasIllegalInst && !io.redirect\n\
      302:   io.toCSR.trapInstInfo.bits.fromDecodedInst(illegalInst)\n303: \n304:\
      \   val recoveryFlag = RegInit(false.B)\n305:   when(io.redirect) {\n306:  \
      \   recoveryFlag := true.B\n307:   }.elsewhen(io.in.map(_.fire).reduce(_ ||
      _)) {\n308:     recoveryFlag := false.B\n309:   }\n310: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 220-230
    context: "220:     EBREAK  -> XSDecode(SrcType.reg, SrcType.imm, SrcType.X, FuType.csr,
      CSROpType.jmp, SelImm.IMM_I, xWen = T, noSpec = T, blockBack = T),\n221:   \
      \  ECALL   -> XSDecode(SrcType.reg, SrcType.imm, SrcType.X, FuType.csr, CSROpType.jmp,
      SelImm.IMM_I, xWen = T, noSpec = T, blockBack = T),\n222:     SRET    -> XSDecode(SrcType.reg,
      SrcType.imm, SrcType.X, FuType.csr, CSROpType.jmp, SelImm.IMM_I, xWen = T, noSpec
      = T, blockBack = T),\n223:     MRET    -> XSDecode(SrcType.reg, SrcType.imm,
      SrcType.X, FuType.csr, CSROpType.jmp, SelImm.IMM_I, xWen = T, noSpec = T, blockBack
      = T),\n224:     MNRET   -> XSDecode(SrcType.reg, SrcType.imm, SrcType.X, FuType.csr,
      CSROpType.jmp, SelImm.IMM_I, xWen = T, noSpec = T, blockBack = T),\n225:   \
      \  DRET    -> XSDecode(SrcType.reg, SrcType.imm, SrcType.X, FuType.csr, CSROpType.jmp,
      SelImm.IMM_I, xWen = T, noSpec = T, blockBack = T),\n226:     WFI     -> XSDecode(SrcType.pc
      , SrcType.imm, SrcType.X, FuType.csr, CSROpType.wfi, SelImm.X    , xWen = T,
      noSpec = T, blockBack = T),\n227: \n228:     SFENCE_VMA -> XSDecode(SrcType.reg,
      SrcType.reg, SrcType.X, FuType.fence, FenceOpType.sfence, SelImm.X, noSpec =
      T, blockBack = T, flushPipe = T),\n229:     FENCE_I    -> XSDecode(SrcType.pc
      , SrcType.imm, SrcType.X, FuType.fence, FenceOpType.fencei, SelImm.X, noSpec
      = T, blockBack = T, flushPipe = T),\n230:     FENCE      -> XSDecode(SrcType.pc
      , SrcType.imm, SrcType.X, FuType.fence, FenceOpType.fence , SelImm.X, noSpec
      = T, blockBack = T, flushPipe = T),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 426-439
    context: "426: /**\n427:  * FP Divide SquareRoot Constants\n428:  */\n429: object
      FDivSqrtDecode extends DecodeConstants {\n430:   val decodeArray: Array[(BitPat,
      XSDecodeBase)] = Array(\n431:     FDIV_S  -> FDecode(SrcType.fp,  SrcType.fp,\
      \  SrcType.X, FuType.fDivSqrt, FuOpType.X, fWen = T, canRobCompress = T),\n\
      432:     FDIV_D  -> FDecode(SrcType.fp,  SrcType.fp,  SrcType.X, FuType.fDivSqrt,
      FuOpType.X, fWen = T, canRobCompress = T),\n433:     FSQRT_S -> FDecode(SrcType.fp,\
      \  SrcType.imm, SrcType.X, FuType.fDivSqrt, FuOpType.X, fWen = T, canRobCompress
      = T),\n434:     FSQRT_D -> FDecode(SrcType.fp,  SrcType.imm, SrcType.X, FuType.fDivSqrt,
      FuOpType.X, fWen = T, canRobCompress = T),\n435:   )\n436: }\n437: \n438: /**\n\
      439:  * Svinval extension Constants"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/decode/DecodeUnit.scala
    lines: 938-948
    context: "938:   private val isStore = FuType.isStore(decodedInst.fuType)\n939:\
      \   private val isAMO = FuType.isAMO(decodedInst.fuType)\n940:   private val
      isVStore = FuType.isVStore(decodedInst.fuType)\n941:   private val isBranch
      = !decodedInst.preDecodeInfo.notCFI || FuType.isJump(decodedInst.fuType)\n942:\
      \ \n943:   decodedInst.commitType := Cat(isLs | isVls, (isStore && !isAMO) |
      isVStore | isBranch)\n944: \n945:   decodedInst.isVset := FuType.isVset(decodedInst.fuType)\n\
      946: \n947:   private val needReverseInsts = Seq(VRSUB_VI, VRSUB_VX, VFRDIV_VF,
      VFRSUB_VF, VFMV_F_S)\n948:   private val vextInsts = Seq(VZEXT_VF2, VZEXT_VF4,
      VZEXT_VF8, VSEXT_VF2, VSEXT_VF4, VSEXT_VF8)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Snapshot.scala
    lines: 10-25
    context: "10: class SnapshotPtr(implicit p: Parameters) extends CircularQueuePtr[SnapshotPtr](\n\
      11:   p => p(XSCoreParamsKey).RenameSnapshotNum\n12: )\n13: \n14: object SnapshotGenerator
      extends HasCircularQueuePtrHelper {\n15:   def apply[T <: Data](enqData: T,
      enq: Bool, deq: Bool, redirect: Bool, flushVec: Vec[Bool])(implicit p: Parameters):
      Vec[T] = {\n16:     val snapshotGen = Module(new SnapshotGenerator(enqData))\n\
      17:     snapshotGen.io.enq := enq\n18:     snapshotGen.io.enqData := enqData\n\
      19:     snapshotGen.io.deq := deq\n20:     snapshotGen.io.redirect := redirect\n\
      21:     snapshotGen.io.flushVec := flushVec\n22:     snapshotGen.io.snapshots\n\
      23:   }\n24: }\n25: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Snapshot.scala
    lines: 28-38
    context: "28: \n29:   class SnapshotGeneratorIO extends Bundle {\n30:     val
      enq = Input(Bool())\n31:     val enqData = Input(chiselTypeOf(dataType))\n32:\
      \     val deq = Input(Bool())\n33:     val redirect = Input(Bool())\n34:   \
      \  val flushVec = Input(Vec(RenameSnapshotNum, Bool()))\n35:     val snapshots
      = Output(Vec(RenameSnapshotNum, chiselTypeOf(dataType)))\n36:     val enqPtr
      = Output(new SnapshotPtr)\n37:     val deqPtr = Output(new SnapshotPtr)\n38:\
      \     val valids = Output(Vec(RenameSnapshotNum, Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Snapshot.scala
    lines: 48-67
    context: "48:   io.snapshots := snapshots\n49:   io.enqPtr := snptEnqPtr\n50:\
      \   io.deqPtr := snptDeqPtr\n51:   io.valids := snptValids\n52: \n53:   when(!io.redirect
      && !isFull(snptEnqPtr, snptDeqPtr) && io.enq) {\n54:     snapshots(snptEnqPtr.value)
      := io.enqData\n55:     snptValids(snptEnqPtr.value) := true.B\n56:     snptEnqPtr
      := snptEnqPtr + 1.U\n57:   }\n58:   when(!io.redirect && io.deq) {\n59:    \
      \ snptValids(snptDeqPtr.value) := false.B\n60:     snptDeqPtr := snptDeqPtr
      + 1.U\n61:   }\n62:   XSError(!io.redirect && io.deq && isEmpty(snptEnqPtr,
      snptDeqPtr), \"snapshots should not be empty when dequeue!\\n\")\n63: \n64:\
      \   snptValids.zip(io.flushVec).foreach { case (valid, flush) =>\n65:     when(flush)
      { valid := false.B }\n66:   }\n67:   when((Cat(io.flushVec) & Cat(snptValids)).orR)
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 71-88
    context: "71:     case Reg_V0 => log2Ceil(V0LogicRegs)\n72:     case Reg_Vl =>
      log2Ceil(VlLogicRegs)\n73:   }\n74: \n75:   val io = IO(new Bundle {\n76:  \
      \   val redirect = Input(Bool())\n77:     val readPorts = Vec(readPortsNum *
      RenameWidth, new RatReadPort(renameTableWidth))\n78:     val specWritePorts
      = Vec(RabCommitWidth, Input(new RatWritePort(renameTableWidth)))\n79:     val
      archWritePorts = Vec(RabCommitWidth, Input(new RatWritePort(renameTableWidth)))\n\
      80:     val old_pdest = Vec(RabCommitWidth, Output(UInt(PhyRegIdxWidth.W)))\n\
      81:     val need_free = Vec(RabCommitWidth, Output(Bool()))\n82:     val snpt
      = Input(new SnapshotPort)\n83:     val diffWritePorts = if (backendParams.basicDebugEn)
      Some(Vec(RabCommitWidth * MaxUopSize, Input(new RatWritePort(renameTableWidth))))
      else None\n84:     val debug_rdata = if (backendParams.debugEn) Some(Vec(rdataNums,
      Output(UInt(PhyRegIdxWidth.W)))) else None\n85:     val diff_rdata = if (backendParams.basicDebugEn)
      Some(Vec(rdataNums, Output(UInt(PhyRegIdxWidth.W)))) else None\n86:     val
      debug_v0 = if (backendParams.debugEn) reg_t match {\n87:       case Reg_V0 =>
      Some(Output(UInt(PhyRegIdxWidth.W)))\n88:       case _ => None"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 113-124
    context: "113:   val spec_table_next = WireInit(spec_table)\n114:   // arch state
      rename table\n115:   val arch_table = RegInit(rename_table_init)\n116:   val
      arch_table_next = WireDefault(arch_table)\n117:   // old_pdest\n118:   val old_pdest
      = RegInit(VecInit.fill(RabCommitWidth)(0.U(PhyRegIdxWidth.W)))\n119:   val need_free
      = RegInit(VecInit.fill(RabCommitWidth)(false.B))\n120: \n121:   // For better
      timing, we optimize reading and writing to RenameTable as follows:\n122:   //
      (1) Writing at T0 will be actually processed at T1.\n123:   // (2) Reading is
      synchronous now.\n124:   // (3) RAddr at T0 will be used to access the table
      and get data at T0."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 121-134
    context: "121:   // For better timing, we optimize reading and writing to RenameTable
      as follows:\n122:   // (1) Writing at T0 will be actually processed at T1.\n\
      123:   // (2) Reading is synchronous now.\n124:   // (3) RAddr at T0 will be
      used to access the table and get data at T0.\n125:   // (4) WData at T0 is bypassed
      to RData at T1.\n126:   val t1_redirect = GatedValidRegNext(io.redirect, false.B)\n\
      127:   val t1_raddr = io.readPorts.map(p => RegEnable(p.addr, !p.hold))\n128:\
      \   val t1_rdata_use_t1_raddr = VecInit(t1_raddr.map(spec_table(_)))\n129: \
      \  val t1_wSpec = RegNext(Mux(io.redirect, 0.U.asTypeOf(io.specWritePorts),
      io.specWritePorts))\n130: \n131:   val t1_snpt = RegNext(io.snpt, 0.U.asTypeOf(io.snpt))\n\
      132:   val t2_snpt = RegNext(t1_snpt, 0.U.asTypeOf(io.snpt))\n133: \n134:  \
      \ val snapshots = SnapshotGenerator(spec_table, t1_snpt.snptEnq, t1_snpt.snptDeq,
      t1_redirect, t1_snpt.flushVec)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 148-158
    context: "148:   spec_table := spec_table_next\n149: \n150:   // READ: decode-rename
      stage\n151:   for ((r, i) <- io.readPorts.zipWithIndex) {\n152:     val t0_bypass
      = io.specWritePorts.map(w => w.wen && Mux(r.hold, w.addr === t1_raddr(i), w.addr
      === r.addr))\n153:     val t1_bypass = RegNext(Mux(io.redirect, 0.U.asTypeOf(VecInit(t0_bypass)),
      VecInit(t0_bypass)))\n154:     val bypass_data = ParallelPriorityMux(t1_bypass.reverse,
      t1_wSpec.map(_.data).reverse)\n155:     r.data := Mux(t1_bypass.asUInt.orR,
      bypass_data, t1_rdata_use_t1_raddr(i))\n156:   }\n157: \n158:   for ((w, i)
      <- io.archWritePorts.zipWithIndex) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 212-224
    context: "212:   // params alias\n213:   private val numVecRegSrc = backendParams.numVecRegSrc\n\
      214:   private val numVecRatPorts = numVecRegSrc\n215: \n216:   val io = IO(new
      Bundle() {\n217:     val redirect = Input(Bool())\n218:     val rabCommits =
      Input(new RabCommitIO)\n219:     val diffCommits = if (backendParams.basicDebugEn)
      Some(Input(new DiffCommitIO)) else None\n220:     val intReadPorts = Vec(RenameWidth,
      Vec(2, new RatReadPort(IntLogicRegs)))\n221:     val intRenamePorts = Vec(RenameWidth,
      Input(new RatWritePort(IntLogicRegs)))\n222:     val fpReadPorts = Vec(RenameWidth,
      Vec(3, new RatReadPort(FpLogicRegs)))\n223:     val fpRenamePorts = Vec(RenameWidth,
      Input(new RatWritePort(FpLogicRegs)))\n224:     val vecReadPorts = Vec(RenameWidth,
      Vec(numVecRatPorts, new RatReadPort(VecLogicRegs)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 226-241
    context: "226:     val v0ReadPorts = Vec(RenameWidth, new RatReadPort(V0LogicRegs))\n\
      227:     val v0RenamePorts = Vec(RenameWidth, Input(new RatWritePort(V0LogicRegs)))\n\
      228:     val vlReadPorts = Vec(RenameWidth, new RatReadPort(VlLogicRegs))\n\
      229:     val vlRenamePorts = Vec(RenameWidth, Input(new RatWritePort(VlLogicRegs)))\n\
      230: \n231:     val int_old_pdest = Vec(RabCommitWidth, Output(UInt(PhyRegIdxWidth.W)))\n\
      232:     val fp_old_pdest = Vec(RabCommitWidth, Output(UInt(PhyRegIdxWidth.W)))\n\
      233:     val vec_old_pdest = Vec(RabCommitWidth, Output(UInt(PhyRegIdxWidth.W)))\n\
      234:     val v0_old_pdest = Vec(RabCommitWidth, Output(UInt(PhyRegIdxWidth.W)))\n\
      235:     val vl_old_pdest = Vec(RabCommitWidth, Output(UInt(PhyRegIdxWidth.W)))\n\
      236:     val int_need_free = Vec(RabCommitWidth, Output(Bool()))\n237:     val
      snpt = Input(new SnapshotPort)\n238: \n239:     // for debug assertions\n240:\
      \     val debug_int_rat = if (backendParams.debugEn) Some(Vec(32, Output(UInt(PhyRegIdxWidth.W))))
      else None\n241:     val debug_fp_rat  = if (backendParams.debugEn) Some(Vec(32,
      Output(UInt(PhyRegIdxWidth.W)))) else None"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 245-255
    context: "245: \n246:     // for difftest\n247:     val diff_int_rat = if (backendParams.basicDebugEn)
      Some(Vec(32, Output(UInt(PhyRegIdxWidth.W)))) else None\n248:     val diff_fp_rat\
      \  = if (backendParams.basicDebugEn) Some(Vec(32, Output(UInt(PhyRegIdxWidth.W))))
      else None\n249:     val diff_vec_rat = if (backendParams.basicDebugEn) Some(Vec(31,
      Output(UInt(PhyRegIdxWidth.W)))) else None\n250:     val diff_v0_rat  = if (backendParams.basicDebugEn)
      Some(Vec(1,Output(UInt(PhyRegIdxWidth.W)))) else None\n251:     val diff_vl_rat\
      \  = if (backendParams.basicDebugEn) Some(Vec(1,Output(UInt(PhyRegIdxWidth.W))))
      else None\n252:   })\n253: \n254:   val intRat = Module(new RenameTable(Reg_I))\n\
      255:   val fpRat  = Module(new RenameTable(Reg_F))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 258-282
    context: "258:   val vlRat  = Module(new RenameTable(Reg_Vl))\n259: \n260:   io.debug_int_rat
      .foreach(_ := intRat.io.debug_rdata.get)\n261:   io.diff_int_rat  .foreach(_
      := intRat.io.diff_rdata.get)\n262:   intRat.io.readPorts <> io.intReadPorts.flatten\n\
      263:   intRat.io.redirect := io.redirect\n264:   intRat.io.snpt := io.snpt\n\
      265:   io.int_old_pdest := intRat.io.old_pdest\n266:   io.int_need_free := intRat.io.need_free\n\
      267:   val intDestValid = io.rabCommits.info.map(_.rfWen)\n268:   for ((arch,
      i) <- intRat.io.archWritePorts.zipWithIndex) {\n269:     arch.wen  := io.rabCommits.isCommit
      && io.rabCommits.commitValid(i) && intDestValid(i)\n270:     arch.addr := io.rabCommits.info(i).ldest\n\
      271:     arch.data := io.rabCommits.info(i).pdest\n272:     XSError(arch.wen
      && arch.addr === 0.U && arch.data =/= 0.U, \"pdest for $0 should be 0\\n\")\n\
      273:   }\n274:   for ((spec, i) <- intRat.io.specWritePorts.zipWithIndex) {\n\
      275:     spec.wen  := io.rabCommits.isWalk && io.rabCommits.walkValid(i) &&
      intDestValid(i)\n276:     spec.addr := io.rabCommits.info(i).ldest\n277:   \
      \  spec.data := io.rabCommits.info(i).pdest\n278:     XSError(spec.wen && spec.addr
      === 0.U && spec.data =/= 0.U, \"pdest for $0 should be 0\\n\")\n279:   }\n280:\
      \   for ((spec, rename) <- intRat.io.specWritePorts.zip(io.intRenamePorts))
      {\n281:     when (rename.wen) {\n282:       spec.wen  := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 284-296
    context: "284:       spec.data := rename.data\n285:     }\n286:   }\n287:   if
      (backendParams.basicDebugEn) {\n288:     for ((diff, i) <- intRat.io.diffWritePorts.get.zipWithIndex)
      {\n289:       diff.wen := io.diffCommits.get.isCommit && io.diffCommits.get.commitValid(i)
      && io.diffCommits.get.info(i).rfWen\n290:       diff.addr := io.diffCommits.get.info(i).ldest\n\
      291:       diff.data := io.diffCommits.get.info(i).pdest\n292:     }\n293: \
      \  }\n294: \n295:   // debug read ports for difftest\n296:   io.debug_fp_rat.foreach(_
      := fpRat.io.debug_rdata.get)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 294-316
    context: "294: \n295:   // debug read ports for difftest\n296:   io.debug_fp_rat.foreach(_
      := fpRat.io.debug_rdata.get)\n297:   io.diff_fp_rat .foreach(_ := fpRat.io.diff_rdata.get)\n\
      298:   fpRat.io.readPorts <> io.fpReadPorts.flatten\n299:   fpRat.io.redirect
      := io.redirect\n300:   fpRat.io.snpt := io.snpt\n301:   io.fp_old_pdest := fpRat.io.old_pdest\n\
      302: \n303:   for ((arch, i) <- fpRat.io.archWritePorts.zipWithIndex) {\n304:\
      \     arch.wen  := io.rabCommits.isCommit && io.rabCommits.commitValid(i) &&
      io.rabCommits.info(i).fpWen\n305:     arch.addr := io.rabCommits.info(i).ldest\n\
      306:     arch.data := io.rabCommits.info(i).pdest\n307:   }\n308:   for ((spec,
      i) <- fpRat.io.specWritePorts.zipWithIndex) {\n309:     spec.wen  := io.rabCommits.isWalk
      && io.rabCommits.walkValid(i) && io.rabCommits.info(i).fpWen\n310:     spec.addr
      := io.rabCommits.info(i).ldest\n311:     spec.data := io.rabCommits.info(i).pdest\n\
      312:   }\n313:   for ((spec, rename) <- fpRat.io.specWritePorts.zip(io.fpRenamePorts))
      {\n314:     when (rename.wen) {\n315:       spec.wen  := true.B\n316:      \
      \ spec.addr := rename.addr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 317-329
    context: "317:       spec.data := rename.data\n318:     }\n319:   }\n320:   if
      (backendParams.basicDebugEn) {\n321:     for ((diff, i) <- fpRat.io.diffWritePorts.get.zipWithIndex)
      {\n322:       diff.wen := io.diffCommits.get.isCommit && io.diffCommits.get.commitValid(i)
      && io.diffCommits.get.info(i).fpWen\n323:       diff.addr := io.diffCommits.get.info(i).ldest\n\
      324:       diff.data := io.diffCommits.get.info(i).pdest\n325:     }\n326: \
      \  }\n327: \n328:   // debug read ports for difftest\n329:   io.debug_vec_rat\
      \    .foreach(_ := vecRat.io.debug_rdata.get)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 327-337
    context: "327: \n328:   // debug read ports for difftest\n329:   io.debug_vec_rat\
      \    .foreach(_ := vecRat.io.debug_rdata.get)\n330:   io.diff_vec_rat     .foreach(_
      := vecRat.io.diff_rdata.get)\n331:   vecRat.io.readPorts <> io.vecReadPorts.flatten\n\
      332:   vecRat.io.redirect := io.redirect\n333:   vecRat.io.snpt := io.snpt\n\
      334:   io.vec_old_pdest := vecRat.io.old_pdest\n335: \n336:   //TODO: RM the
      donTouch\n337:   if(backendParams.debugEn) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 336-353
    context: "336:   //TODO: RM the donTouch\n337:   if(backendParams.debugEn) {\n\
      338:     dontTouch(vecRat.io)\n339:   }\n340:   for ((arch, i) <- vecRat.io.archWritePorts.zipWithIndex)
      {\n341:     arch.wen  := io.rabCommits.isCommit && io.rabCommits.commitValid(i)
      && io.rabCommits.info(i).vecWen\n342:     arch.addr := io.rabCommits.info(i).ldest\n\
      343:     arch.data := io.rabCommits.info(i).pdest\n344:   }\n345:   for ((spec,
      i) <- vecRat.io.specWritePorts.zipWithIndex) {\n346:     spec.wen  := io.rabCommits.isWalk
      && io.rabCommits.walkValid(i) && io.rabCommits.info(i).vecWen\n347:     spec.addr
      := io.rabCommits.info(i).ldest\n348:     spec.data := io.rabCommits.info(i).pdest\n\
      349:   }\n350:   for ((spec, rename) <- vecRat.io.specWritePorts.zip(io.vecRenamePorts))
      {\n351:     when (rename.wen) {\n352:       spec.wen  := true.B\n353:      \
      \ spec.addr := rename.addr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 354-366
    context: "354:       spec.data := rename.data\n355:     }\n356:   }\n357:   if
      (backendParams.basicDebugEn) {\n358:     for ((diff, i) <- vecRat.io.diffWritePorts.get.zipWithIndex)
      {\n359:       diff.wen := io.diffCommits.get.isCommit && io.diffCommits.get.commitValid(i)
      && io.diffCommits.get.info(i).vecWen\n360:       diff.addr := io.diffCommits.get.info(i).ldest\n\
      361:       diff.data := io.diffCommits.get.info(i).pdest\n362:     }\n363: \
      \  }\n364: \n365:   // debug read ports for difftest\n366:   io.debug_v0_rat.foreach(_
      := v0Rat.io.debug_rdata.get)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 362-374
    context: "362:     }\n363:   }\n364: \n365:   // debug read ports for difftest\n\
      366:   io.debug_v0_rat.foreach(_ := v0Rat.io.debug_rdata.get)\n367:   io.diff_v0_rat.foreach(_
      := v0Rat.io.diff_rdata.get)\n368:   v0Rat.io.readPorts <> io.v0ReadPorts\n369:\
      \   v0Rat.io.redirect := io.redirect\n370:   v0Rat.io.snpt := io.snpt\n371:\
      \   io.v0_old_pdest := v0Rat.io.old_pdest\n372: \n373:   if (backendParams.debugEn)
      {\n374:     dontTouch(v0Rat.io)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 372-389
    context: "372: \n373:   if (backendParams.debugEn) {\n374:     dontTouch(v0Rat.io)\n\
      375:   }\n376:   for ((arch, i) <- v0Rat.io.archWritePorts.zipWithIndex) {\n\
      377:     arch.wen := io.rabCommits.isCommit && io.rabCommits.commitValid(i)
      && io.rabCommits.info(i).v0Wen\n378:     arch.addr := io.rabCommits.info(i).ldest\n\
      379:     arch.data := io.rabCommits.info(i).pdest\n380:   }\n381:   for ((spec,
      i) <- v0Rat.io.specWritePorts.zipWithIndex) {\n382:     spec.wen := io.rabCommits.isWalk
      && io.rabCommits.walkValid(i) && io.rabCommits.info(i).v0Wen\n383:     spec.addr
      := io.rabCommits.info(i).ldest\n384:     spec.data := io.rabCommits.info(i).pdest\n\
      385:   }\n386:   for ((spec, rename) <- v0Rat.io.specWritePorts.zip(io.v0RenamePorts))
      {\n387:     when(rename.wen) {\n388:       spec.wen := true.B\n389:       spec.addr
      := rename.addr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 390-402
    context: "390:       spec.data := rename.data\n391:     }\n392:   }\n393:   if
      (backendParams.basicDebugEn) {\n394:     for ((diff, i) <- v0Rat.io.diffWritePorts.get.zipWithIndex)
      {\n395:       diff.wen := io.diffCommits.get.isCommit && io.diffCommits.get.commitValid(i)
      && io.diffCommits.get.info(i).v0Wen\n396:       diff.addr := io.diffCommits.get.info(i).ldest\n\
      397:       diff.data := io.diffCommits.get.info(i).pdest\n398:     }\n399: \
      \  }\n400: \n401:   // debug read ports for difftest\n402:   io.debug_vl_rat.foreach(_
      := vlRat.io.debug_rdata.get)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 400-410
    context: "400: \n401:   // debug read ports for difftest\n402:   io.debug_vl_rat.foreach(_
      := vlRat.io.debug_rdata.get)\n403:   io.diff_vl_rat.foreach(_ := vlRat.io.diff_rdata.get)\n\
      404:   vlRat.io.readPorts <> io.vlReadPorts\n405:   vlRat.io.redirect := io.redirect\n\
      406:   vlRat.io.snpt := io.snpt\n407:   io.vl_old_pdest := vlRat.io.old_pdest\n\
      408: \n409:   if (backendParams.debugEn) {\n410:     dontTouch(vlRat.io)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 408-425
    context: "408: \n409:   if (backendParams.debugEn) {\n410:     dontTouch(vlRat.io)\n\
      411:   }\n412:   for ((arch, i) <- vlRat.io.archWritePorts.zipWithIndex) {\n\
      413:     arch.wen := io.rabCommits.isCommit && io.rabCommits.commitValid(i)
      && io.rabCommits.info(i).vlWen\n414:     arch.addr := io.rabCommits.info(i).ldest\n\
      415:     arch.data := io.rabCommits.info(i).pdest\n416:   }\n417:   for ((spec,
      i) <- vlRat.io.specWritePorts.zipWithIndex) {\n418:     spec.wen := io.rabCommits.isWalk
      && io.rabCommits.walkValid(i) && io.rabCommits.info(i).vlWen\n419:     spec.addr
      := io.rabCommits.info(i).ldest\n420:     spec.data := io.rabCommits.info(i).pdest\n\
      421:   }\n422:   for ((spec, rename) <- vlRat.io.specWritePorts.zip(io.vlRenamePorts))
      {\n423:     when(rename.wen) {\n424:       spec.wen := true.B\n425:       spec.addr
      := rename.addr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/RenameTable.scala
    lines: 426-436
    context: "426:       spec.data := rename.data\n427:     }\n428:   }\n429:   if
      (backendParams.basicDebugEn) {\n430:     for ((diff, i) <- vlRat.io.diffWritePorts.get.zipWithIndex)
      {\n431:       diff.wen := io.diffCommits.get.isCommit && io.diffCommits.get.commitValid(i)
      && io.diffCommits.get.info(i).vlWen\n432:       diff.addr := io.diffCommits.get.info(i).ldest\n\
      433:       diff.data := io.diffCommits.get.info(i).pdest\n434:     }\n435: \
      \  }\n436: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/CompressUnit.scala
    lines: 47-57
    context: "47:   })\n48: \n49:   val noExc = io.in.map(in => !in.bits.exceptionVec.asUInt.orR
      && !TriggerAction.isDmode(in.bits.trigger))\n50:   val uopCanCompress = io.in.map(_.bits.canRobCompress)\n\
      51:   val canCompress = io.in.zip(noExc).zip(uopCanCompress).map { case ((in,
      noExc), canComp) =>\n52:     in.valid && !CommitType.isFused(in.bits.commitType)
      && in.bits.lastUop && noExc && canComp\n53:   }\n54: \n55:   val compressTable
      = (0 until 1 << RenameWidth).map { case keyCandidate =>\n56:     // padding
      0s at each side for convenience\n57:     val key = 0 +: (0 until RenameWidth).map(idx
      => (keyCandidate >> idx) & 1) :+ 0"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/BaseFreeList.scala
    lines: 25-47
    context: "25: import utility._\n26: \n27: \n28: abstract class BaseFreeList(size:
      Int, numLogicRegs:Int = 32)(implicit p: Parameters) extends XSModule with HasCircularQueuePtrHelper
      {\n29:   val io = IO(new Bundle {\n30:     val redirect = Input(Bool())\n31:\
      \     val walk = Input(Bool())\n32: \n33:     val allocateReq = Input(Vec(RenameWidth,
      Bool()))\n34:     val walkReq = Input(Vec(RabCommitWidth, Bool()))\n35:    \
      \ val allocatePhyReg = Output(Vec(RenameWidth, UInt(PhyRegIdxWidth.W)))\n36:\
      \     val canAllocate = Output(Bool())\n37:     val doAllocate = Input(Bool())\n\
      38: \n39:     val freeReq = Input(Vec(RabCommitWidth, Bool()))\n40:     val
      freePhyReg = Input(Vec(RabCommitWidth, UInt(PhyRegIdxWidth.W)))\n41: \n42: \
      \    val commit = Input(new RabCommitIO)\n43: \n44:     val snpt = Input(new
      SnapshotPort)\n45: \n46:     val debug_rat = if(backendParams.debugEn) Some(Vec(numLogicRegs,
      Input(UInt(PhyRegIdxWidth.W)))) else None\n47:   })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/BaseFreeList.scala
    lines: 55-65
    context: "55:       ptr.value := v.U\n56:       ptr\n57:     }\n58:   }\n59: \n\
      60:   val lastCycleRedirect = RegNext(RegNext(io.redirect))\n61:   val lastCycleSnpt
      = RegNext(RegNext(io.snpt, 0.U.asTypeOf(io.snpt)))\n62: \n63:   val headPtr
      = RegInit(FreeListPtr(false, 0))\n64:   val headPtrOH = RegInit(1.U(size.W))\n\
      65:   val archHeadPtr = RegInit(FreeListPtr(false, 0))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/BaseFreeList.scala
    lines: 66-76
    context: "66:   XSError(headPtr.toOH =/= headPtrOH, p\"wrong one-hot reg between
      $headPtr and $headPtrOH\")\n67:   val headPtrOHShift = CircularShift(headPtrOH)\n\
      68:   // may shift [0, RenameWidth] steps\n69:   val headPtrOHVec = VecInit.tabulate(RenameWidth
      + 1)(headPtrOHShift.left)\n70: \n71:   val snapshots = SnapshotGenerator(headPtr,
      io.snpt.snptEnq, io.snpt.snptDeq, io.redirect, io.snpt.flushVec)\n72: \n73:\
      \   val redirectedHeadPtr = Mux(\n74:     lastCycleSnpt.useSnpt,\n75:     snapshots(lastCycleSnpt.snptSelect)
      + PopCount(io.walkReq),\n76:     archHeadPtr + PopCount(io.walkReq)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/MEFreeList.scala
    lines: 29-42
    context: "29:     // originally {1, 2, ..., size - 1} are free. Register 0-31
      are mapped to x0.\n30:     Seq.tabulate(size - 1)(i => (i + 1).U(PhyRegIdxWidth.W))
      :+ 0.U(PhyRegIdxWidth.W)))\n31: \n32:   val tailPtr = RegInit(FreeListPtr(false,
      size - 1))\n33: \n34:   val doWalkRename = io.walk && io.doAllocate && !io.redirect\n\
      35:   val doNormalRename = io.canAllocate && io.doAllocate && !io.redirect\n\
      36:   val doRename = doWalkRename || doNormalRename\n37:   val doCommit = io.commit.isCommit\n\
      38: \n39:   /**\n40:     * Allocation: from freelist (same as StdFreelist)\n\
      41:     */\n42:   val phyRegCandidates = VecInit(headPtrOHVec.map(sel => Mux1H(sel,
      freeList)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/MEFreeList.scala
    lines: 43-58
    context: "43:   for (i <- 0 until RenameWidth) {\n44:     // enqueue instr, is
      move elimination\n45:     io.allocatePhyReg(i) := phyRegCandidates(PopCount(io.allocateReq.take(i)))\n\
      46:   }\n47:   // update arch head pointer\n48:   val archAlloc = io.commit.commitValid
      zip io.commit.info map {\n49:     case (valid, info) => valid && info.rfWen
      && !info.isMove\n50:   }\n51:   val numArchAllocate = PopCount(archAlloc)\n\
      52:   val archHeadPtrNew  = archHeadPtr + numArchAllocate\n53:   val archHeadPtrNext
      = Mux(doCommit, archHeadPtrNew, archHeadPtr)\n54:   archHeadPtr := archHeadPtrNext\n\
      55: \n56:   // update head pointer\n57:   val numAllocate = Mux(io.walk, PopCount(io.walkReq),
      PopCount(io.allocateReq))\n58:   val headPtrNew   = Mux(lastCycleRedirect, redirectedHeadPtr,
      headPtr + numAllocate)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/MEFreeList.scala
    lines: 63-73
    context: "63:   headPtrOH := headPtrOHNext\n64: \n65:   /**\n66:     * Deallocation:
      when refCounter becomes zero, the register can be released to freelist\n67:\
      \     */\n68:   for (i <- 0 until RabCommitWidth) {\n69:     when (io.freeReq(i))
      {\n70:       val freePtr = tailPtr + PopCount(io.freeReq.take(i))\n71:     \
      \  freeList(freePtr.value) := io.freePhyReg(i)\n72:     }\n73:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/StdFreeList.scala
    lines: 34-44
    context: "34: \n35:   //\n36:   // free committed instructions' `old_pdest` reg\n\
      37:   //\n38:   val freeReqReg = io.freeReq\n39:   for (i <- 0 until RabCommitWidth)
      {\n40:     val offset = if (i == 0) 0.U else PopCount(freeReqReg.take(i))\n\
      41:     val enqPtr = lastTailPtr + offset\n42: \n43:     // Why RegNext (from
      RAT and Rename): for better timing\n44:     // Why we can RegNext: these free
      registers won't be used in the next cycle,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/StdFreeList.scala
    lines: 63-74
    context: "63: \n64:   for(i <- 0 until RenameWidth) {\n65:     io.allocatePhyReg(i)
      := phyRegCandidates(PopCount(io.allocateReq.take(i)))\n66:     XSDebug(p\"req:${io.allocateReq(i)}
      canAllocate:${io.canAllocate} pdest:${io.allocatePhyReg(i)}\\n\")\n67:   }\n\
      68:   val doCommit = io.commit.isCommit\n69:   val archAlloc = io.commit.commitValid
      zip io.commit.info map { case (valid, info) =>\n70:     valid && (regType match
      {\n71:       case Reg_F => info.fpWen\n72:       case Reg_V => info.vecWen\n\
      73:       case Reg_V0 => info.v0Wen\n74:       case Reg_Vl => info.vlWen"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/StdFreeList.scala
    lines: 74-84
    context: "74:       case Reg_Vl => info.vlWen\n75:     })\n76:   }\n77:   val
      numArchAllocate = PopCount(archAlloc)\n78:   val archHeadPtrNew  = archHeadPtr
      + numArchAllocate\n79:   val archHeadPtrNext = Mux(doCommit, archHeadPtrNew,
      archHeadPtr)\n80:   archHeadPtr := archHeadPtrNext\n81: \n82:   val isWalkAlloc
      = io.walk && io.doAllocate\n83:   val isNormalAlloc = io.canAllocate && io.doAllocate\n\
      84:   val isAllocate = isWalkAlloc || isNormalAlloc"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/freelist/StdFreeList.scala
    lines: 89-99
    context: "89:   freeRegCnt := Mux(isWalkAlloc && !lastCycleRedirect, distanceBetween(tailPtr,
      headPtr) - PopCount(io.walkReq),\n90:                 Mux(isNormalAlloc,   \
      \                  distanceBetween(tailPtr, headPtr) - PopCount(io.allocateReq),\n\
      91:                                                        distanceBetween(tailPtr,
      headPtr)))\n92: \n93:   // priority: (1) exception and flushPipe; (2) walking;
      (3) mis-prediction; (4) normal dequeue\n94:   val realDoAllocate = !io.redirect
      && isAllocate\n95:   headPtr := Mux(realDoAllocate, headPtrAllocate, headPtr)\n\
      96:   headPtrOH := Mux(realDoAllocate, headPtrOHAllocate, headPtrOH)\n97: \n\
      98:   XSDebug(p\"head:$headPtr tail:$tailPtr\\n\")\n99: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 45-56
    context: "45:   private val numVecRatPorts = numVecRegSrc\n46: \n47:   println(s\"\
      [Rename] numRegSrc: $numRegSrc\")\n48: \n49:   val io = IO(new Bundle() {\n\
      50:     val redirect = Flipped(ValidIO(new Redirect))\n51:     val rabCommits
      = Input(new RabCommitIO)\n52:     // from csr\n53:     val singleStep = Input(Bool())\n\
      54:     // from decode\n55:     val in = Vec(RenameWidth, Flipped(DecoupledIO(new
      DecodedInst)))\n56:     val fusionInfo = Vec(DecodeWidth - 1, Flipped(new FusionDecodeInfo))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 68-83
    context: "68:     val fpRenamePorts = Vec(RenameWidth, Output(new RatWritePort(log2Ceil(FpLogicRegs))))\n\
      69:     val vecRenamePorts = Vec(RenameWidth, Output(new RatWritePort(log2Ceil(VecLogicRegs))))\n\
      70:     val v0RenamePorts = Vec(RenameWidth, Output(new RatWritePort(log2Ceil(V0LogicRegs))))\n\
      71:     val vlRenamePorts = Vec(RenameWidth, Output(new RatWritePort(log2Ceil(VlLogicRegs))))\n\
      72:     // from rename table\n73:     val int_old_pdest = Vec(RabCommitWidth,
      Input(UInt(PhyRegIdxWidth.W)))\n74:     val fp_old_pdest = Vec(RabCommitWidth,
      Input(UInt(PhyRegIdxWidth.W)))\n75:     val vec_old_pdest = Vec(RabCommitWidth,
      Input(UInt(PhyRegIdxWidth.W)))\n76:     val v0_old_pdest = Vec(RabCommitWidth,
      Input(UInt(PhyRegIdxWidth.W)))\n77:     val vl_old_pdest = Vec(RabCommitWidth,
      Input(UInt(PhyRegIdxWidth.W)))\n78:     val int_need_free = Vec(RabCommitWidth,
      Input(Bool()))\n79:     // to dispatch1\n80:     val out = Vec(RenameWidth,
      DecoupledIO(new DynInst))\n81:     // for snapshots\n82:     val snpt = Input(new
      SnapshotPort)\n83:     val snptLastEnq = Flipped(ValidIO(new RobPtr))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 109-127
    context: "109:   val vecFreeList = Module(new StdFreeList(VfPhyRegs - VecLogicRegs,
      VecLogicRegs, Reg_V, 31))\n110:   val v0FreeList = Module(new StdFreeList(V0PhyRegs
      - V0LogicRegs, V0LogicRegs, Reg_V0, 1))\n111:   val vlFreeList = Module(new
      StdFreeList(VlPhyRegs - VlLogicRegs, VlLogicRegs, Reg_Vl, 1))\n112: \n113: \n\
      114:   intFreeList.io.commit    <> io.rabCommits\n115:   intFreeList.io.debug_rat.foreach(_
      <> io.debug_int_rat.get)\n116:   fpFreeList.io.commit     <> io.rabCommits\n\
      117:   fpFreeList.io.debug_rat.foreach(_ <> io.debug_fp_rat.get)\n118:   vecFreeList.io.commit\
      \    <> io.rabCommits\n119:   vecFreeList.io.debug_rat.foreach(_ <> io.debug_vec_rat.get)\n\
      120:   v0FreeList.io.commit <> io.rabCommits\n121:   v0FreeList.io.debug_rat.foreach(_
      <> io.debug_v0_rat.get)\n122:   vlFreeList.io.commit <> io.rabCommits\n123:\
      \   vlFreeList.io.debug_rat.foreach(_ <> io.debug_vl_rat.get)\n124: \n125: \
      \  // decide if given instruction needs allocating a new physical register (CfCtrl:
      from decode; RobCommitInfo: from rob)\n126:   def needDestReg[T <: DecodedInst](reg_t:
      RegType, x: T): Bool = reg_t match {\n127:     case Reg_I => x.rfWen"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 128-138
    context: "128:     case Reg_F => x.fpWen\n129:     case Reg_V => x.vecWen\n130:\
      \     case Reg_V0 => x.v0Wen\n131:     case Reg_Vl => x.vlWen\n132:   }\n133:\
      \   def needDestRegCommit[T <: RabCommitInfo](reg_t: RegType, x: T): Bool =
      {\n134:     reg_t match {\n135:       case Reg_I => x.rfWen\n136:       case
      Reg_F => x.fpWen\n137:       case Reg_V => x.vecWen\n138:       case Reg_V0
      => x.v0Wen"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 137-147
    context: "137:       case Reg_V => x.vecWen\n138:       case Reg_V0 => x.v0Wen\n\
      139:       case Reg_Vl => x.vlWen\n140:     }\n141:   }\n142:   def needDestRegWalk[T
      <: RabCommitInfo](reg_t: RegType, x: T): Bool = {\n143:     reg_t match {\n\
      144:       case Reg_I => x.rfWen\n145:       case Reg_F => x.fpWen\n146:   \
      \    case Reg_V => x.vecWen\n147:       case Reg_V0 => x.v0Wen"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 149-171
    context: "149:     }\n150:   }\n151: \n152:   // connect [redirect + walk] ports
      for fp & vec & int free list\n153:   Seq(fpFreeList, vecFreeList, intFreeList,
      v0FreeList, vlFreeList).foreach { case fl =>\n154:     fl.io.redirect := io.redirect.valid\n\
      155:     fl.io.walk := io.rabCommits.isWalk\n156:   }\n157:   // only when all
      free list and dispatch1 has enough space can we do allocation\n158:   // when
      isWalk, freelist can definitely allocate\n159:   intFreeList.io.doAllocate :=
      fpFreeList.io.canAllocate && vecFreeList.io.canAllocate && v0FreeList.io.canAllocate
      && vlFreeList.io.canAllocate && dispatchCanAcc || io.rabCommits.isWalk\n160:\
      \   fpFreeList.io.doAllocate := intFreeList.io.canAllocate && vecFreeList.io.canAllocate
      && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate && dispatchCanAcc
      || io.rabCommits.isWalk\n161:   vecFreeList.io.doAllocate := intFreeList.io.canAllocate
      && fpFreeList.io.canAllocate && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate
      && dispatchCanAcc || io.rabCommits.isWalk\n162:   v0FreeList.io.doAllocate :=
      intFreeList.io.canAllocate && fpFreeList.io.canAllocate && vecFreeList.io.canAllocate
      && vlFreeList.io.canAllocate && dispatchCanAcc || io.rabCommits.isWalk\n163:\
      \   vlFreeList.io.doAllocate := intFreeList.io.canAllocate && fpFreeList.io.canAllocate
      && vecFreeList.io.canAllocate && v0FreeList.io.canAllocate && dispatchCanAcc
      || io.rabCommits.isWalk\n164: \n165:   //           dispatch1 ready ++ float
      point free list ready ++ int free list ready ++ vec free list ready     ++ not
      walk\n166:   val canOut = dispatchCanAcc && fpFreeList.io.canAllocate && intFreeList.io.canAllocate
      && vecFreeList.io.canAllocate && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate
      && !io.rabCommits.isWalk\n167: \n168:   compressUnit.io.in.zip(io.in).foreach{
      case(sink, source) =>\n169:     sink.valid := source.valid && !io.singleStep\n\
      170:     sink.bits := source.bits\n171:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 174-185
    context: "174:   val compressMasksVec = compressUnit.io.out.masks\n175: \n176:\
      \   // speculatively assign the instruction with an robIdx\n177:   val validCount
      = PopCount(io.in.zip(needRobFlags).map{ case(in, needRobFlag) => in.valid &&
      in.bits.lastUop && needRobFlag}) // number of instructions waiting to enter
      rob (from decode)\n178:   val robIdxHead = RegInit(0.U.asTypeOf(new RobPtr))\n\
      179:   val lastCycleMisprediction = GatedValidRegNext(io.redirect.valid && !io.redirect.bits.flushItself())\n\
      180:   val robIdxHeadNext = Mux(io.redirect.valid, io.redirect.bits.robIdx,
      // redirect: move ptr to given rob index\n181:          Mux(lastCycleMisprediction,
      robIdxHead + 1.U, // mis-predict: not flush robIdx itself\n182:            Mux(canOut,
      robIdxHead + validCount, // instructions successfully entered next stage: increase
      robIdx\n183:                       /* default */  robIdxHead))) // no instructions
      passed by this cycle: stick to old value\n184:   robIdxHead := robIdxHeadNext\n\
      185: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 217-227
    context: "217:   private val mop          = fuOpType.map(fuOpTypeItem => LSUOpType.getVecLSMop(fuOpTypeItem))\n\
      218:   private val isVlsType    = fuType.map(fuTypeItem => isVls(fuTypeItem))\n\
      219:   private val isSegment    = fuType.map(fuTypeItem => isVsegls(fuTypeItem))\n\
      220:   private val isUnitStride = fuOpType.map(fuOpTypeItem => LSUOpType.isAllUS(fuOpTypeItem))\n\
      221:   private val nf           = fuOpType.zip(uops.map(_.vpu.nf)).map { case
      (fuOpTypeItem, nfItem) => Mux(LSUOpType.isWhole(fuOpTypeItem), 0.U, nfItem)
      }\n222:   private val mulBits      = 3 // dirty code\n223:   private val emul\
      \         = fuOpType.zipWithIndex.map { case (fuOpTypeItem, index) =>\n224:\
      \     Mux(\n225:       LSUOpType.isWhole(fuOpTypeItem),\n226:       GenUSWholeEmul(nf(index)),\n\
      227:       Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 319-335
    context: "319:     needV0Dest(i) := io.in(i).valid && needDestReg(Reg_V0, io.in(i).bits)\n\
      320:     needVlDest(i) := io.in(i).valid && needDestReg(Reg_Vl, io.in(i).bits)\n\
      321:     needVecDest(i) := io.in(i).valid && needDestReg(Reg_V, io.in(i).bits)\n\
      322:     needFpDest(i) := io.in(i).valid && needDestReg(Reg_F, io.in(i).bits)\n\
      323:     needIntDest(i) := io.in(i).valid && needDestReg(Reg_I, io.in(i).bits)\n\
      324:     if (i < RabCommitWidth) {\n325:       walkNeedIntDest(i) := io.rabCommits.walkValid(i)
      && needDestRegWalk(Reg_I, io.rabCommits.info(i))\n326:       walkNeedFpDest(i)
      := io.rabCommits.walkValid(i) && needDestRegWalk(Reg_F, io.rabCommits.info(i))\n\
      327:       walkNeedVecDest(i) := io.rabCommits.walkValid(i) && needDestRegWalk(Reg_V,
      io.rabCommits.info(i))\n328:       walkNeedV0Dest(i) := io.rabCommits.walkValid(i)
      && needDestRegWalk(Reg_V0, io.rabCommits.info(i))\n329:       walkNeedVlDest(i)
      := io.rabCommits.walkValid(i) && needDestRegWalk(Reg_Vl, io.rabCommits.info(i))\n\
      330:       walkIsMove(i) := io.rabCommits.info(i).isMove\n331:     }\n332: \
      \    fpFreeList.io.allocateReq(i) := needFpDest(i)\n333:     fpFreeList.io.walkReq(i)
      := walkNeedFpDest(i)\n334:     vecFreeList.io.allocateReq(i) := needVecDest(i)\n\
      335:     vecFreeList.io.walkReq(i) := walkNeedVecDest(i)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 363-374
    context: "363:       uops(i).lastUop := false.B\n364:       uops(i).numUops :=
      instrSizesVec(i) - PopCount(compressMasksVec(i) & Cat(isMove.reverse))\n365:\
      \       uops(i).numWB := instrSizesVec(i) - PopCount(compressMasksVec(i) & Cat(isMove.reverse))\n\
      366:     }\n367:     uops(i).wfflags := (compressMasksVec(i) & Cat(io.in.map(_.bits.wfflags).reverse)).orR\n\
      368:     uops(i).dirtyFs := (compressMasksVec(i) & Cat(io.in.map(_.bits.fpWen).reverse)).orR\n\
      369:     uops(i).dirtyVs := (\n370:       compressMasksVec(i) & Cat(io.in.map(in
      =>\n371:         // vector instructions' uopSplitType cannot be UopSplitType.SCA_SIM\n\
      372:         in.bits.uopSplitType =/= UopSplitType.SCA_SIM &&\n373:        \
      \ !UopSplitType.isAMOCAS(in.bits.uopSplitType) &&\n374:         // vfmv.f.s,
      vcpop.m, vfirst.m and vmv.x.s don't change vector state"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 409-419
    context: "409:     ))\n410: \n411:     // Assign performance counters\n412:  \
      \   uops(i).debugInfo.renameTime := GTimer()\n413: \n414:     io.out(i).valid
      := io.in(i).valid && intFreeList.io.canAllocate && fpFreeList.io.canAllocate
      && vecFreeList.io.canAllocate && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate
      && !io.rabCommits.isWalk\n415:     io.out(i).bits := uops(i)\n416:     // dirty
      code\n417:     if (i == 0) {\n418:       io.out(i).bits.psrc(0) := Mux(io.out(i).bits.isLUI,
      0.U, uops(i).psrc(0))\n419:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 442-461
    context: "442:       }\n443:     }\n444: \n445:     // write speculative rename
      table\n446:     // we update rat later inside commit code\n447:     intSpecWen(i)
      := needIntDest(i) && intFreeList.io.canAllocate && intFreeList.io.doAllocate
      && !io.rabCommits.isWalk && !io.redirect.valid\n448:     fpSpecWen(i)  := needFpDest(i)\
      \  && fpFreeList.io.canAllocate  && fpFreeList.io.doAllocate  && !io.rabCommits.isWalk
      && !io.redirect.valid\n449:     vecSpecWen(i) := needVecDest(i) && vecFreeList.io.canAllocate
      && vecFreeList.io.doAllocate && !io.rabCommits.isWalk && !io.redirect.valid\n\
      450:     v0SpecWen(i) := needV0Dest(i) && v0FreeList.io.canAllocate && v0FreeList.io.doAllocate
      && !io.rabCommits.isWalk && !io.redirect.valid\n451:     vlSpecWen(i) := needVlDest(i)
      && vlFreeList.io.canAllocate && vlFreeList.io.doAllocate && !io.rabCommits.isWalk
      && !io.redirect.valid\n452: \n453: \n454:     if (i < RabCommitWidth) {\n455:\
      \       walkIntSpecWen(i) := walkNeedIntDest(i) && !io.redirect.valid\n456:\
      \       walkPdest(i) := io.rabCommits.info(i).pdest\n457:     } else {\n458:\
      \       walkPdest(i) := io.out(i).bits.pdest\n459:     }\n460:   }\n461: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 463-473
    context: "463:    * trace begin\n464:    */\n465:   // note: fusionInst can't
      robcompress\n466:   val inVec = io.in.map(_.bits)\n467:   val isRVCVec = inVec.map(_.preDecodeInfo.isRVC)\n\
      468:   val isFusionVec = inVec.map(_.commitType).map(ctype => CommitType.isFused(ctype))\n\
      469: \n470:   val canRobCompressVec = compressUnit.io.out.canCompressVec\n471:\
      \   val iLastSizeVec = isRVCVec.map(isRVC => Mux(isRVC, Ilastsize.HalfWord,
      Ilastsize.Word))\n472:   val halfWordNumVec = isRVCVec.map(isRVC => Mux(isRVC,
      1.U, 2.U))\n473:   val halfWordNumMatrix = (0 until RenameWidth).map("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 497-510
    context: "497:     )\n498: \n499:     // CSR systemop instruction excluding ebreak
      & ecall\n500:     val csrAddr = Imm_Z().getCSRAddr(uops(i).imm(Imm_Z().len -
      1, 0))\n501:     val isXret = FuType.isCsr(uops(i).fuType) && CSROpType.isSystemOp(uops(i).fuOpType)
      && (csrAddr(11, 1).orR)\n502:     uops(i).traceBlockInPipe.itype := Mux(\n503:\
      \       isXret,\n504:       Itype.ExpIntReturn,\n505:       Itype.jumpTypeGen(inVec(i).preDecodeInfo.brType,
      inVec(i).ldest.asTypeOf(new OpRegType), inVec(i).lsrc(0).asTypeOf((new OpRegType)))\n\
      506:     )\n507:   }\n508:   /**\n509:    * trace end\n510:    */"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 595-605
    context: "595:   }\n596: \n597:   val genSnapshot = Cat(io.out.map(out => out.fire
      && out.bits.snapshot)).orR\n598:   val lastCycleCreateSnpt = RegInit(false.B)\n\
      599:   lastCycleCreateSnpt := genSnapshot && !io.snptIsFull\n600:   val sameSnptDistance
      = (RobCommitWidth * 4).U\n601:   // notInSameSnpt: 1.robidxHead - snapLastEnq
      >= sameSnptDistance 2.no snap\n602:   val notInSameSnpt = GatedValidRegNext(distanceBetween(robIdxHeadNext,
      io.snptLastEnq.bits) >= sameSnptDistance || !io.snptLastEnq.valid)\n603:   val
      allowSnpt = if (EnableRenameSnapshot) notInSameSnpt && !lastCycleCreateSnpt
      && io.in.head.bits.firstUop else false.B\n604:   io.out.zip(io.in).foreach{
      case (out, in) => out.bits.snapshot := allowSnpt && (!in.bits.preDecodeInfo.notCFI
      || FuType.isJump(in.bits.fuType)) && in.fire }\n605:   io.out.map{ x =>"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 622-634
    context: "622:   vlFreeList.io.snpt.snptEnq := genSnapshot\n623: \n624:   /**\n\
      625:     * Instructions commit: update freelist and rename table\n626:     */\n\
      627:   for (i <- 0 until RabCommitWidth) {\n628:     val commitValid = io.rabCommits.isCommit
      && io.rabCommits.commitValid(i)\n629:     val walkValid = io.rabCommits.isWalk
      && io.rabCommits.walkValid(i)\n630: \n631:     // I. RAT Update\n632:     //
      When redirect happens (mis-prediction), don't update the rename table\n633:\
      \     io.intRenamePorts(i).wen  := intSpecWen(i)\n634:     io.intRenamePorts(i).addr
      := uops(i).ldest(log2Ceil(IntLogicRegs) - 1, 0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 651-667
    context: "651:     io.vlRenamePorts(i).data := vlFreeList.io.allocatePhyReg(i)\n\
      652: \n653:     // II. Free List Update\n654:     intFreeList.io.freeReq(i)
      := io.int_need_free(i)\n655:     intFreeList.io.freePhyReg(i) := RegNext(io.int_old_pdest(i))\n\
      656:     fpFreeList.io.freeReq(i)  := GatedValidRegNext(commitValid && needDestRegCommit(Reg_F,
      io.rabCommits.info(i)))\n657:     fpFreeList.io.freePhyReg(i) := io.fp_old_pdest(i)\n\
      658:     vecFreeList.io.freeReq(i)  := GatedValidRegNext(commitValid && needDestRegCommit(Reg_V,
      io.rabCommits.info(i)))\n659:     vecFreeList.io.freePhyReg(i) := io.vec_old_pdest(i)\n\
      660:     v0FreeList.io.freeReq(i) := GatedValidRegNext(commitValid && needDestRegCommit(Reg_V0,
      io.rabCommits.info(i)))\n661:     v0FreeList.io.freePhyReg(i) := io.v0_old_pdest(i)\n\
      662:     vlFreeList.io.freeReq(i) := GatedValidRegNext(commitValid && needDestRegCommit(Reg_Vl,
      io.rabCommits.info(i)))\n663:     vlFreeList.io.freePhyReg(i) := io.vl_old_pdest(i)\n\
      664:   }\n665: \n666:   /*\n667:   Debug and performance counters"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 682-696
    context: "682:   io.out.map { case x =>\n683:     when(x.valid && x.bits.rfWen){\n\
      684:       assert(x.bits.ldest =/= 0.U, \"rfWen cannot be 1 when Int regfile
      ldest is 0\")\n685:     }\n686:   }\n687:   val debugRedirect = RegEnable(io.redirect.bits,
      io.redirect.valid)\n688:   // bad speculation\n689:   val recStall = io.redirect.valid
      || io.rabCommits.isWalk\n690:   val ctrlRecStall = Mux(io.redirect.valid, io.redirect.bits.debugIsCtrl,
      io.rabCommits.isWalk && debugRedirect.debugIsCtrl)\n691:   val mvioRecStall
      = Mux(io.redirect.valid, io.redirect.bits.debugIsMemVio, io.rabCommits.isWalk
      && debugRedirect.debugIsMemVio)\n692:   val otherRecStall = recStall && !(ctrlRecStall
      || mvioRecStall)\n693:   XSPerfAccumulate(\"recovery_stall\", recStall)\n694:\
      \   XSPerfAccumulate(\"control_recovery_stall\", ctrlRecStall)\n695:   XSPerfAccumulate(\"\
      mem_violation_recovery_stall\", mvioRecStall)\n696:   XSPerfAccumulate(\"other_recovery_stall\"\
      , otherRecStall)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 727-741
    context: "727:   ))\n728:   io.stallReason.out.reason.zip(io.stallReason.in.reason).zip(io.in.map(_.valid)).foreach
      { case ((out, in), valid) =>\n729:     out := Mux(io.stallReason.in.backReason.valid,
      io.stallReason.in.backReason.bits, in)\n730:   }\n731: \n732:   XSDebug(io.rabCommits.isWalk,
      p\"Walk Recovery Enabled\\n\")\n733:   XSDebug(io.rabCommits.isWalk, p\"validVec:${Binary(io.rabCommits.walkValid.asUInt)}\\\
      n\")\n734:   for (i <- 0 until RabCommitWidth) {\n735:     val info = io.rabCommits.info(i)\n\
      736:     XSDebug(io.rabCommits.isWalk && io.rabCommits.walkValid(i), p\"[#$i
      walk info] \" +\n737:       p\"ldest:${info.ldest} rfWen:${info.rfWen} fpWen:${info.fpWen}
      vecWen:${info.vecWen} v0Wen:${info.v0Wen} vlWen:${info.vlWen}\")\n738:   }\n\
      739: \n740:   XSDebug(p\"inValidVec: ${Binary(Cat(io.in.map(_.valid)))}\\n\"\
      )\n741: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 745-761
    context: "745:   XSPerfAccumulate(\"wait_cycle\", !io.in.head.valid && dispatchCanAcc)\n\
      746: \n747:   // These stall reasons could overlap each other, but we configure
      the priority as fellows.\n748:   // walk stall > dispatch stall > int freelist
      stall > fp freelist stall\n749:   private val inHeadStall = io.in.head match
      { case x => x.valid && !x.ready }\n750:   private val stallForWalk      = inHeadValid
      &&  io.rabCommits.isWalk\n751:   private val stallForDispatch  = inHeadValid
      && !io.rabCommits.isWalk && !dispatchCanAcc\n752:   private val stallForIntFL\
      \     = inHeadValid && !io.rabCommits.isWalk && dispatchCanAcc && fpFreeList.io.canAllocate
      && vecFreeList.io.canAllocate && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate
      && !intFreeList.io.canAllocate\n753:   private val stallForFpFL      = inHeadValid
      && !io.rabCommits.isWalk && dispatchCanAcc && intFreeList.io.canAllocate &&
      vecFreeList.io.canAllocate && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate
      && !fpFreeList.io.canAllocate\n754:   private val stallForVecFL     = inHeadValid
      && !io.rabCommits.isWalk && dispatchCanAcc && intFreeList.io.canAllocate &&
      fpFreeList.io.canAllocate && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate
      && !vecFreeList.io.canAllocate\n755:   private val stallForV0FL      = inHeadValid
      && !io.rabCommits.isWalk && dispatchCanAcc && intFreeList.io.canAllocate &&
      fpFreeList.io.canAllocate && vecFreeList.io.canAllocate && vlFreeList.io.canAllocate
      && !v0FreeList.io.canAllocate\n756:   private val stallForVlFL      = inHeadValid
      && !io.rabCommits.isWalk && dispatchCanAcc && intFreeList.io.canAllocate &&
      fpFreeList.io.canAllocate && vecFreeList.io.canAllocate && v0FreeList.io.canAllocate
      && !vlFreeList.io.canAllocate\n757:   XSPerfAccumulate(\"stall_cycle\",    \
      \      inHeadStall)\n758:   XSPerfAccumulate(\"stall_cycle_walk\",     stallForWalk)\n\
      759:   XSPerfAccumulate(\"stall_cycle_dispatch\", stallForDispatch)\n760:  \
      \ XSPerfAccumulate(\"stall_cycle_int\",      stallForIntFL)\n761:   XSPerfAccumulate(\"\
      stall_cycle_fp\",       stallForFpFL)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/rename/Rename.scala
    lines: 774-790
    context: "774: \n775:   val renamePerf = Seq(\n776:     (\"rename_in         \
      \         \", PopCount(io.in.map(_.valid & io.in(0).ready ))),\n777:     (\"\
      rename_waitinstr           \", PopCount((0 until RenameWidth).map(i => io.in(i).valid
      && !io.in(i).ready))),\n778:     (\"rename_stall               \", inHeadStall),\n\
      779:     (\"rename_stall_cycle_walk    \", inHeadValid &&  io.rabCommits.isWalk),\n\
      780:     (\"rename_stall_cycle_dispatch\", inHeadValid && !io.rabCommits.isWalk
      && !dispatchCanAcc),\n781:     (\"rename_stall_cycle_int     \", inHeadValid
      && !io.rabCommits.isWalk && dispatchCanAcc && fpFreeList.io.canAllocate && vecFreeList.io.canAllocate
      && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate && !intFreeList.io.canAllocate),\n\
      782:     (\"rename_stall_cycle_fp      \", inHeadValid && !io.rabCommits.isWalk
      && dispatchCanAcc && intFreeList.io.canAllocate && vecFreeList.io.canAllocate
      && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate && !fpFreeList.io.canAllocate),\n\
      783:     (\"rename_stall_cycle_vec     \", inHeadValid && !io.rabCommits.isWalk
      && dispatchCanAcc && intFreeList.io.canAllocate && fpFreeList.io.canAllocate
      && v0FreeList.io.canAllocate && vlFreeList.io.canAllocate && !vecFreeList.io.canAllocate),\n\
      784:     (\"rename_stall_cycle_v0      \", inHeadValid && !io.rabCommits.isWalk
      && dispatchCanAcc && intFreeList.io.canAllocate && fpFreeList.io.canAllocate
      && vecFreeList.io.canAllocate && vlFreeList.io.canAllocate && !v0FreeList.io.canAllocate),\n\
      785:     (\"rename_stall_cycle_vl      \", inHeadValid && !io.rabCommits.isWalk
      && dispatchCanAcc && intFreeList.io.canAllocate && fpFreeList.io.canAllocate
      && vecFreeList.io.canAllocate && v0FreeList.io.canAllocate && !vlFreeList.io.canAllocate),\n\
      786:   )\n787:   val intFlPerf = intFreeList.getPerfEvents\n788:   val fpFlPerf
      = fpFreeList.getPerfEvents\n789:   val vecFlPerf = vecFreeList.getPerfEvents\n\
      790:   val v0FlPerf = v0FreeList.getPerfEvents"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 25-35
    context: "25:     val status = new Bundle {\n26:       val busy = Bool()\n27:\
      \     }\n28:   }))\n29: \n30:   private val oldPregVecFromRat: Vec[ValidIO[UInt]]
      = Wire(Vec(RabCommitWidth, ValidIO(UInt(VfPhyRegIdxWidth.W))))\n31:   oldPregVecFromRat.zipWithIndex.foreach
      { case (oldPreg: ValidIO[UInt], idx) =>\n32:     val vecOldVd = i.fromRat.vecOldVdPdest(idx)\n\
      33:     val v0OldVd  = i.fromRat.v0OldVdPdest(idx)\n34:     oldPreg.valid :=
      (vecOldVd.valid || v0OldVd.valid)\n35:     oldPreg.bits := Mux1H(Seq("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 65-77
    context: "65:     sNoExcp_ivemulNoLessThanM1 === (sNoExcp_dvemulNoLessThanM1 +&
      idx.U) ||\n66:     (idx == 0).B && (sNoExcp_ivemulNoLessThanM1 < sNoExcp_dvemulNoLessThanM1)\n\
      67:   )\n68:   private val sNoExcp_nonSegIndexed = sNoExcp_vecExcpInfo.bits.isIndexed
      && sNoExcp_vecExcpInfo.bits.nf === 0.U\n69: \n70:   private val commitNeeded
      = RegInit(VecInit.fill(MaxLMUL)(false.B))\n71:   private val rabCommitted =
      RegInit(VecInit.fill(MaxLMUL)(false.B))\n72:   private val ratCommitted = RegInit(VecInit.fill(MaxLMUL)(false.B))\n\
      73:   private val hasReadRf    = RegInit(VecInit.fill(MaxLMUL)(false.B))\n74:\
      \ \n75:   private val regMaps = Reg(Vec(MaxLMUL, new LogicPhyRegMap))\n76: \n\
      77:   private val currentIdx = RegInit(0.U(log2Up(8 + 1).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 221-236
    context: "221:   private val mvFinished = currentIdx >= sWaitRab_handleUntil\n\
      222: \n223:   // get lreg and new preg, the last mapped newPdest\n224:   private
      val filteredRabCommitedVec: Vec[Vec[Bool]] = WireInit(VecInit.tabulate(4, MaxLMUL)
      { case (i_d_n, vdIdx) =>\n225:     val vdLoc = ((vdIdx + 1) << i_d_n) - 1\n\
      226:     rabCommitted(if (vdLoc >= MaxLMUL) 0 else vdLoc)\n227:   })\n228: \
      \  // get old preg, the first mapped oldPdest\n229:   private val filteredRatCommitedVec:
      Vec[Vec[Bool]] = WireInit(VecInit.tabulate(4, MaxLMUL) { case (i_d_n, vdIdx)
      =>\n230:     val vdLoc = vdIdx << i_d_n\n231:     ratCommitted(if (vdLoc >=
      MaxLMUL) 0 else vdLoc)\n232:   })\n233: \n234:   private val filteredRabCommited
      = Wire(Vec(MaxLMUL, Bool()))\n235:   private val filteredRatCommited = Wire(Vec(MaxLMUL,
      Bool()))\n236:   when (sWaitRab_nonSegIndexed) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 236-252
    context: "236:   when (sWaitRab_nonSegIndexed) {\n237:     filteredRabCommited
      := Mux1H(sWaitRab_vemul_i_d, filteredRabCommitedVec)\n238:     filteredRatCommited
      := Mux1H(sWaitRab_vemul_i_d, filteredRatCommitedVec)\n239:   }.otherwise {\n\
      240:     // No need to shuffle, since the vdIdx always compressed towards zero
      and left tail unused.\n241:     filteredRabCommited := rabCommitted\n242:  \
      \   filteredRatCommited := ratCommitted\n243:   }\n244: \n245:   // 1. no need
      commit\n246:   // 2. need commit and both rab and rat committed\n247:   collectedAllRegMap
      := ((~commitNeeded.asUInt).asUInt | (commitNeeded.asUInt & filteredRabCommited.asUInt
      & filteredRatCommited.asUInt)).andR\n248: \n249:   switch(state) {\n250:   \
      \  is(State.noExcp) {\n251:       when (i.fromExceptionGen.valid) {\n252:  \
      \       stateNext := State.waitRab"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 301-311
    context: "301:   }\n302: \n303:   private val hasRabWrite = regWriteFromRabVec.head.valid\n\
      304:   private val hasRatWrite = regWriteFromRatVec.head.valid\n305:   require(\n\
      306:     2 * RabCommitWidth >= (MaxLMUL + 2),\n307:     \"Cannot receive all
      10 reg maps from RAB and RAT in two cycles. \" +\n308:       \"This module should
      be rewrited to support more than 2 cycles receiving\"\n309:   )\n310: \n311:\
      \   switch (state) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 311-321
    context: "311:   switch (state) {\n312:     is (State.noExcp) {\n313:       when
      (stateNext === State.waitRab) {\n314:         sWaitRab_rabWriteOffset := 0.U\n\
      315:         sWaitRab_ratWriteOffset := 0.U\n316:         commitNeeded.zipWithIndex.foreach
      { case (needed, idx) =>\n317:           needed := sNoExcp_maxVdIdx > idx.U\n\
      318:         }\n319:       }\n320:     }\n321:     is (State.waitRab) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 319-329
    context: "319:       }\n320:     }\n321:     is (State.waitRab) {\n322:      \
      \ when (hasRabWrite) {\n323:         sWaitRab_rabWriteOffset := sWaitRab_rabWriteOffset
      +\n324:           PriorityMux((0 until RabCommitWidth).map(\n325:          \
      \   idx => i.fromRab.logicPhyRegMap.reverse(idx).valid -> (6 - idx).U\n326:\
      \           ))\n327:       }\n328:       when (hasRatWrite) {\n329:        \
      \ sWaitRab_ratWriteOffset := sWaitRab_ratWriteOffset +"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 325-335
    context: "325:             idx => i.fromRab.logicPhyRegMap.reverse(idx).valid
      -> (6 - idx).U\n326:           ))\n327:       }\n328:       when (hasRatWrite)
      {\n329:         sWaitRab_ratWriteOffset := sWaitRab_ratWriteOffset +\n330: \
      \          PriorityMux((0 until RabCommitWidth).map(\n331:             idx =>
      regWriteFromRatVec.reverse(idx).valid -> (6 - idx).U\n332:           ))\n333:\
      \       }\n334: \n335:       when(sWaitRab_rabWriteOffset === 0.U) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 333-357
    context: "333:       }\n334: \n335:       when(sWaitRab_rabWriteOffset === 0.U)
      {\n336:         // the first patch of RAB commit consider offset\n337:     \
      \    when(sWaitRab_vecExcpInfo.bits.isStride) {\n338:           (2 until RabCommitWidth).map
      { idx =>\n339:             val vdIdx = idx - 2\n340:             when(regWriteFromRabVec(idx).valid)
      {\n341:               regMaps(vdIdx).lreg := regWriteFromRabVec(idx).bits.lreg\n\
      342:               regMaps(vdIdx).newPreg := regWriteFromRabVec(idx).bits.preg\n\
      343:               rabCommitted(vdIdx) := true.B\n344:             }\n345: \
      \          }\n346:         }.otherwise {\n347:           (1 until RabCommitWidth).map
      { idx =>\n348:             val vdIdx = idx - 1\n349:             when(regWriteFromRabVec(idx).valid)
      {\n350:               regMaps(vdIdx).lreg := regWriteFromRabVec(idx).bits.lreg\n\
      351:               regMaps(vdIdx).newPreg := regWriteFromRabVec(idx).bits.preg\n\
      352:               rabCommitted(vdIdx) := true.B\n353:             }\n354: \
      \          }\n355:         }\n356:       }.otherwise {\n357:         // the
      second patch of RAB/RAT commit need no offset"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 354-378
    context: "354:           }\n355:         }\n356:       }.otherwise {\n357:   \
      \      // the second patch of RAB/RAT commit need no offset\n358:         when(sWaitRab_vecExcpInfo.bits.isStride)
      {\n359:           (0 until (MaxLMUL + 2 - RabCommitWidth)).map { idx =>\n360:\
      \             val vdIdx = idx - 2 + RabCommitWidth\n361:             when(regWriteFromRabVec(idx).valid)
      {\n362:               regMaps(vdIdx).lreg := regWriteFromRabVec(idx).bits.lreg\n\
      363:               regMaps(vdIdx).newPreg := regWriteFromRabVec(idx).bits.preg\n\
      364:               rabCommitted(vdIdx) := true.B\n365:             }\n366: \
      \          }\n367:         }.otherwise {\n368:           (0 until MaxLMUL +
      1 - RabCommitWidth).map { idx =>\n369:             val vdIdx = idx - 1 + RabCommitWidth\n\
      370:             when(regWriteFromRabVec(idx).valid) {\n371:               regMaps(vdIdx).lreg
      := regWriteFromRabVec(idx).bits.lreg\n372:               regMaps(vdIdx).newPreg
      := regWriteFromRabVec(idx).bits.preg\n373:               rabCommitted(vdIdx)
      := true.B\n374:             }\n375:           }\n376:         }\n377:      \
      \ }\n378: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 377-399
    context: "377:       }\n378: \n379:       when (sWaitRab_ratWriteOffset === 0.U)
      {\n380:         // the first patch of RAT commit consider offset\n381:     \
      \    when(sWaitRab_vecExcpInfo.bits.isStride) {\n382:           (2 until RabCommitWidth).map
      { idx =>\n383:             val vdIdx = idx - 2\n384:             when(regWriteFromRatVec(idx).valid)
      {\n385:               regMaps(vdIdx).oldPreg := regWriteFromRatVec(idx).bits\n\
      386:               ratCommitted(vdIdx) := true.B\n387:             }\n388: \
      \          }\n389:         }.otherwise {\n390:           (1 until RabCommitWidth).map
      { idx =>\n391:             val vdIdx = idx - 1\n392:             when(regWriteFromRatVec(idx).valid)
      {\n393:               regMaps(vdIdx).oldPreg := regWriteFromRatVec(idx).bits\n\
      394:               ratCommitted(vdIdx) := true.B\n395:             }\n396: \
      \          }\n397:         }\n398:       }.otherwise {\n399:         // the
      second patch of RAT commit need no offset"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 396-418
    context: "396:           }\n397:         }\n398:       }.otherwise {\n399:   \
      \      // the second patch of RAT commit need no offset\n400:         when(sWaitRab_vecExcpInfo.bits.isStride)
      {\n401:           (0 until (MaxLMUL + 2 - RabCommitWidth)).map { idx =>\n402:\
      \             val vdIdx = idx - 2 + RabCommitWidth\n403:             when(regWriteFromRatVec(idx).valid)
      {\n404:               regMaps(vdIdx).oldPreg := regWriteFromRatVec(idx).bits\n\
      405:               ratCommitted(vdIdx) := true.B\n406:             }\n407: \
      \          }\n408:         }.otherwise {\n409:           (0 until MaxLMUL +
      1 - RabCommitWidth).map { idx =>\n410:             val vdIdx = idx - 1 + RabCommitWidth\n\
      411:             when(regWriteFromRatVec(idx).valid) {\n412:               regMaps(vdIdx).oldPreg
      := regWriteFromRatVec(idx).bits\n413:               ratCommitted(vdIdx) := true.B\n\
      414:             }\n415:           }\n416:         }\n417:       }\n418:   \
      \  }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 415-427
    context: "415:           }\n416:         }\n417:       }\n418:     }\n419:   \
      \  is (State.finish) {\n420:       commitNeeded.foreach(_ := false.B)\n421:\
      \       rabCommitted.foreach(_ := false.B)\n422:       ratCommitted.foreach(_
      := false.B)\n423:       hasReadRf   .foreach(_ := false.B)\n424:       sWaitRab_rabWriteOffset
      := 0.U\n425:       sWaitRab_ratWriteOffset := 0.U\n426:       sWaitRab_vecExcpInfo.valid
      := false.B\n427:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 442-455
    context: "442:       val vdIdx = currentIdxVec(idx)\n443:       // when nonSegIndexed
      load, iemul/demul = 1 << 2, vdLoc will be mapped as (0, 1, 2, 3, ...) -> (0,
      4, ...)\n444:       val oldVdLoc = oldVdLocVec(idx)\n445:       // when nonSegIndexed
      load, iemul/demul = 1 << 2, vdLoc will be mapped as (0, 1, 2, 3, ...) -> (3,
      7, ...)\n446:       val newVdLoc = newVdLocVec(idx)\n447:       o.toVPRF.r(idx).valid
      := commitNeeded(vdIdx) && !hasReadRf(vdIdx) && vdIdx < sWaitRab_needMergeUntil\n\
      448:       o.toVPRF.r(idx).bits.addr := regMaps(oldVdLoc).oldPreg\n449:    \
      \   o.toVPRF.r(idx).bits.isV0 := (regMaps(oldVdLoc).lreg === 0.U) && (idx ==
      0).B\n450:       o.toVPRF.r(idx + maxMergeNumPerCycle).valid := commitNeeded(vdIdx)
      && !hasReadRf(vdIdx) && vdIdx < sWaitRab_needMergeUntil\n451:       o.toVPRF.r(idx
      + maxMergeNumPerCycle).bits.addr := regMaps(newVdLoc).newPreg\n452:       o.toVPRF.r(idx
      + maxMergeNumPerCycle).bits.isV0 := (regMaps(newVdLoc).lreg === 0.U) && (idx
      == 0).B\n453:       hasReadRf(vdIdx) := true.B && vdIdx < sWaitRab_needMergeUntil\n\
      454:     }\n455:   }.elsewhen (state === State.mvOldVd) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 457-467
    context: "457:       val vdIdx = currentIdxVec(idx)\n458:       // when nonSegIndexed
      load, iemul/demul = 1 << 2, vdLoc will be mapped as (0, 1, 2, 3, ...) -> (0,
      4, ...)\n459:       val oldVdLoc = oldVdLocVec(idx)\n460:       // when nonSegIndexed
      load, iemul/demul = 1 << 2, vdLoc will be mapped as (0, 1, 2, 3, ...) -> (3,
      7, ...)\n461:       val newVdLoc = newVdLocVec(idx)\n462:       o.toVPRF.r(idx).valid
      := commitNeeded(vdIdx) && !hasReadRf(vdIdx) && vdIdx < sWaitRab_handleUntil\n\
      463:       o.toVPRF.r(idx).bits.addr := regMaps(oldVdLoc).oldPreg\n464:    \
      \   o.toVPRF.r(idx).bits.isV0 := (regMaps(oldVdLoc).lreg === 0.U) && (idx ==
      0).B\n465:       o.toVPRF.r(idx + maxMergeNumPerCycle).valid := 0.U\n466:  \
      \     o.toVPRF.r(idx + maxMergeNumPerCycle).bits.addr := 0.U\n467:       o.toVPRF.r(idx
      + maxMergeNumPerCycle).bits.isV0 := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 497-507
    context: "497:   val lreg = UInt(LogicRegsWidth.W)\n498:   val preg = UInt(VfPhyRegIdxWidth.W)\n\
      499: }\n500: \n501: class RabToVecExcpMod(implicit p: Parameters) extends XSBundle
      {\n502:   val logicPhyRegMap = Vec(RabCommitWidth, ValidIO(new RegWriteFromRab))\n\
      503: }\n504: \n505: class VecExcpInfo(implicit p: Parameters) extends XSBundle
      {\n506:   val vstart = Vstart()\n507:   val vsew = VSew()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/VecExcpDataMergeModule.scala
    lines: 513-524
    context: "513:   val isWhole = Bool()\n514:   val isVlm = Bool()\n515: }\n516:\
      \ \n517: class RatToVecExcpMod(implicit p: Parameters) extends XSBundle {\n\
      518:   val vecOldVdPdest = Vec(RabCommitWidth, ValidIO(UInt(VfPhyRegIdxWidth.W)))\n\
      519:   val v0OldVdPdest = Vec(RabCommitWidth, ValidIO(UInt(VfPhyRegIdxWidth.W)))\n\
      520: }\n521: \n522: class VprfToExcpMod(numPort: Int)(implicit p: Parameters)
      extends XSBundle {\n523:   val rdata = Vec(numPort, ValidIO(UInt(VLEN.W)))\n\
      524: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/ctrlblock/MemCtrl.scala
    lines: 2-12
    context: "2: \n3: import org.chipsalliance.cde.config.Parameters\n4: import chisel3.util.ValidIO\n\
      5: import chisel3._\n6: import xiangshan.backend.BackendParams\n7: import xiangshan.{CustomCSRCtrlIO,
      MemPredUpdateReq, Redirect, XSBundle, XSModule}\n8: import xiangshan.mem.mdp.{DispatchLFSTIO,
      LFST, SSIT, SSITEntry, WaitTable}\n9: import xiangshan.backend.Bundles.DynInst\n\
      10: \n11: class MemCtrl(params: BackendParams)(implicit p: Parameters) extends
      XSModule {\n12:   val io = IO(new MemCtrlIO(params))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/ctrlblock/MemCtrl.scala
    lines: 22-32
    context: "22:   for (i <- 0 until RenameWidth) {\n23:     ssit.io.ren(i) := io.mdpFoldPcVecVld(i)\n\
      24:     ssit.io.raddr(i) := io.mdpFlodPcVec(i)\n25:     waittable.io.raddr(i)
      := io.mdpFlodPcVec(i)\n26:   }\n27:   lfst.io.redirect <> RegNext(io.redirect)\n\
      28:   lfst.io.storeIssue <> RegNext(io.stIn)\n29:   lfst.io.csrCtrl <> RegNext(io.csrCtrl)\n\
      30:   lfst.io.dispatch <> io.dispatchLFSTio\n31: \n32:   io.waitTable2Rename
      := waittable.io.rdata"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/ctrlblock/MemCtrl.scala
    lines: 32-42
    context: "32:   io.waitTable2Rename := waittable.io.rdata\n33:   io.ssit2Rename
      := ssit.io.rdata\n34: }\n35: \n36: class MemCtrlIO(params: BackendParams)(implicit
      p: Parameters) extends XSBundle {\n37:   val redirect = Flipped(ValidIO(new
      Redirect))\n38:   val csrCtrl = Input(new CustomCSRCtrlIO)\n39:   val stIn =
      Vec(params.StaExuCnt, Flipped(ValidIO(new DynInst))) // use storeSetHit, ssid,
      robIdx\n40:   val memPredUpdate = Input(new MemPredUpdateReq)\n41:   val mdpFoldPcVecVld
      = Input(Vec(DecodeWidth, Bool()))\n42:   val mdpFlodPcVec = Input(Vec(DecodeWidth,
      UInt(MemPredPCWidth.W)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/ctrlblock/RedirectGenerator.scala
    lines: 3-13
    context: "3: import org.chipsalliance.cde.config.Parameters\n4: import chisel3.util._\n\
      5: import chisel3._\n6: import utility.{HasCircularQueuePtrHelper, XORFold,
      GatedValidRegNext}\n7: import xiangshan.frontend.{FtqRead, PreDecodeInfo}\n\
      8: import xiangshan.{MemPredUpdateReq, Redirect, XSBundle, XSModule, AddrTransType}\n\
      9: \n10: class RedirectGenerator(implicit p: Parameters) extends XSModule\n\
      11:   with HasCircularQueuePtrHelper {\n12: \n13:   class RedirectGeneratorIO(implicit
      p: Parameters) extends XSBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/ctrlblock/RedirectGenerator.scala
    lines: 12-28
    context: "12: \n13:   class RedirectGeneratorIO(implicit p: Parameters) extends
      XSBundle {\n14:     def numRedirect = backendParams.numRedirect\n15: \n16: \
      \    val hartId = Input(UInt(8.W))\n17:     val oldestExuRedirect = Flipped(ValidIO(new
      Redirect))\n18:     val oldestExuRedirectIsCSR = Input(Bool())\n19:     val
      instrAddrTransType = Input(new AddrTransType)\n20:     val oldestExuOutPredecode
      = Input(new PreDecodeInfo) // guarded by exuRedirect.valid\n21:     val loadReplay
      = Flipped(ValidIO(new Redirect))\n22:     val robFlush = Flipped(ValidIO(new
      Redirect))\n23:     val stage2Redirect = ValidIO(new Redirect)\n24: \n25:  \
      \   val memPredUpdate = Output(new MemPredUpdateReq)\n26:     val memPredPcRead
      = new FtqRead(UInt(VAddrBits.W)) // read req send form stage 2\n27:     val
      stage2oldestOH = Output(UInt((1 + 1).W))\n28:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/ctrlblock/RedirectGenerator.scala
    lines: 37-49
    context: "37:   when(!io.oldestExuRedirectIsCSR){\n38:     oldestExuRedirect.bits.cfiUpdate.backendIAF
      := io.instrAddrTransType.checkAccessFault(oldestExuRedirect.bits.fullTarget)\n\
      39:     oldestExuRedirect.bits.cfiUpdate.backendIPF := io.instrAddrTransType.checkPageFault(oldestExuRedirect.bits.fullTarget)\n\
      40:     oldestExuRedirect.bits.cfiUpdate.backendIGPF := io.instrAddrTransType.checkGuestPageFault(oldestExuRedirect.bits.fullTarget)\n\
      41:   }\n42:   val allRedirect: Vec[ValidIO[Redirect]] = VecInit(oldestExuRedirect,
      loadRedirect)\n43:   val oldestOneHot = Redirect.selectOldestRedirect(allRedirect)\n\
      44:   val flushAfter = RegInit(0.U.asTypeOf(ValidIO(new Redirect)))\n45:   val
      needFlushVec = VecInit(allRedirect.map(_.bits.robIdx.needFlush(flushAfter) ||
      robFlush.valid))\n46:   val oldestValid = VecInit(oldestOneHot.zip(needFlushVec).map
      { case (v, f) => v && !f }).asUInt.orR\n47:   val oldestExuPredecode = io.oldestExuOutPredecode\n\
      48:   val oldestRedirect = Mux1H(oldestOneHot, allRedirect)\n49:   val s1_redirect_bits_reg
      = RegEnable(oldestRedirect.bits, oldestValid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FunctionUnit.scala
    lines: 62-72
    context: "62: class FunctionUnitIO(val len: Int)(implicit p: Parameters) extends
      XSBundle {\n63:   val in = Flipped(DecoupledIO(new FunctionUnitInput(len)))\n\
      64: \n65:   val out = DecoupledIO(new FuOutput(len))\n66: \n67:   val redirectIn
      = Flipped(ValidIO(new Redirect))\n68: }\n69: \n70: abstract class FunctionUnit(len:
      Int = 64)(implicit p: Parameters) extends XSModule {\n71: \n72:   val io = IO(new
      FunctionUnitIO(len))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VCVT.scala
    lines: 24-38
    context: "24: \n25:   // io alias\n26:   private val opcode = fuOpType(8, 0)\n\
      27:   private val sew = vsew\n28: \n29:   private val isRtz = opcode(2) & opcode(1)\n\
      30:   private val isRod = opcode(2) & !opcode(1) & opcode(0)\n31:   private
      val isFrm = !isRtz && !isRod\n32:   private val vfcvtRm = Mux1H(\n33:     Seq(isRtz,
      isRod, isFrm),\n34:     Seq(1.U, 6.U, rm)\n35:   )\n36: \n37:   private val
      lmul = vlmul // -3->3 => 1/8 ->8\n38: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/VIPU.scala
    lines: 92-102
    context: "92:   private val dataWidth = cfg.destDataBits\n93:   private val dataWidthOfDataModule
      = 64\n94:   private val numVecModule = dataWidth / dataWidthOfDataModule\n95:\
      \   private val needClearVs1 = (VipuType.vcpop_m === io.in.bits.ctrl.fuOpType
      && vuopIdx === 0.U) ||\n96:     (VipuType.viota_m === io.in.bits.ctrl.fuOpType
      && vuopIdx(log2Up(MaxUopSize)-1,1) === 0.U) ||\n97:     (VipuType.vid_v   ===
      io.in.bits.ctrl.fuOpType && vuopIdx(log2Up(MaxUopSize)-1,1) === 0.U)    // dirty
      code TODO:  inset into IAlu\n98:   private val lmul = MuxLookup(vlmul, 1.U(4.W))(Seq(\n\
      99:     \"b001\".U -> 2.U,\n100:     \"b010\".U -> 4.U,\n101:     \"b011\".U
      -> 8.U\n102:   ))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/JumpUnit.scala
    lines: 31-57
    context: "31:   jumpDataModule.io.isRVC := isRVC\n32: \n33:   val jmpTarget =
      io.in.bits.ctrl.predictInfo.get.target\n34:   val predTaken = io.in.bits.ctrl.predictInfo.get.taken\n\
      35: \n36:   val redirect = io.out.bits.res.redirect.get.bits\n37:   val redirectValid
      = io.out.bits.res.redirect.get.valid\n38:   redirectValid := io.in.valid &&
      !jumpDataModule.io.isAuipc\n39:   redirect := 0.U.asTypeOf(redirect)\n40:  \
      \ redirect.level := RedirectLevel.flushAfter\n41:   redirect.robIdx := io.in.bits.ctrl.robIdx\n\
      42:   redirect.ftqIdx := io.in.bits.ctrl.ftqIdx.get\n43:   redirect.ftqOffset
      := io.in.bits.ctrl.ftqOffset.get\n44:   redirect.fullTarget := jumpDataModule.io.target\n\
      45:   redirect.cfiUpdate.predTaken := true.B\n46:   redirect.cfiUpdate.taken
      := true.B\n47:   redirect.cfiUpdate.target := jumpDataModule.io.target\n48:\
      \   redirect.cfiUpdate.pc := io.in.bits.data.pc.get\n49:   redirect.cfiUpdate.isMisPred
      := jumpDataModule.io.target(VAddrData().dataWidth - 1, 0) =/= jmpTarget || !predTaken\n\
      50:   redirect.cfiUpdate.backendIAF := io.instrAddrTransType.get.checkAccessFault(jumpDataModule.io.target)\n\
      51:   redirect.cfiUpdate.backendIPF := io.instrAddrTransType.get.checkPageFault(jumpDataModule.io.target)\n\
      52:   redirect.cfiUpdate.backendIGPF := io.instrAddrTransType.get.checkGuestPageFault(jumpDataModule.io.target)\n\
      53: //  redirect.debug_runahead_checkpoint_id := uop.debugInfo.runahead_checkpoint_id
      // Todo: assign it\n54: \n55:   io.in.ready := io.out.ready\n56:   io.out.valid
      := io.in.valid\n57:   io.out.bits.res.data := jumpDataModule.io.result"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 24-37
    context: "24: {\n25:   val csrIn = io.csrio.get\n26:   val csrOut = io.csrio.get\n\
      27:   val csrToDecode = io.csrToDecode.get\n28: \n29:   val setFsDirty = csrIn.fpu.dirty_fs\n\
      30:   val setFflags = csrIn.fpu.fflags\n31: \n32:   val setVsDirty = csrIn.vpu.dirty_vs\n\
      33:   val setVstart = csrIn.vpu.set_vstart\n34:   val setVtype = csrIn.vpu.set_vtype\n\
      35:   val setVxsat = csrIn.vpu.set_vxsat\n36:   val vlFromPreg = csrIn.vpu.vl\n\
      37: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 111-121
    context: "111:       in.bits.src := src\n112:       in.bits.wdata := wdataReg\n\
      113:       in.bits.mret := isMret\n114:       in.bits.mnret := isMNret\n115:\
      \       in.bits.sret := isSret\n116:       in.bits.dret := isDret\n117:    \
      \   in.bits.redirectFlush := redirectFlush\n118:   }\n119:   csrMod.io.trapInst
      := trapInstMod.io.currentTrapInst\n120:   csrMod.io.fetchMalTval := trapTvalMod.io.tval\n\
      121:   csrMod.io.fromMem.excpVA  := csrIn.memExceptionVAddr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 136-162
    context: "136:   csrMod.io.fromRob.trap.bits.trigger := csrIn.exception.bits.trigger\n\
      137:   csrMod.io.fromRob.trap.bits.isHls := csrIn.exception.bits.isHls\n138:\
      \   csrMod.io.fromRob.trap.bits.isFetchMalAddr := csrIn.exception.bits.isFetchMalAddr\n\
      139:   csrMod.io.fromRob.trap.bits.isForVSnonLeafPTE := csrIn.exception.bits.isForVSnonLeafPTE\n\
      140: \n141:   csrMod.io.fromRob.commit.fflags := setFflags\n142:   csrMod.io.fromRob.commit.fsDirty
      := setFsDirty\n143:   csrMod.io.fromRob.commit.vxsat.valid := setVxsat.valid\n\
      144:   csrMod.io.fromRob.commit.vxsat.bits := setVxsat.bits\n145:   csrMod.io.fromRob.commit.vsDirty
      := setVsDirty\n146:   csrMod.io.fromRob.commit.vstart := setVstart\n147:   csrMod.io.fromRob.commit.vl
      := vlFromPreg\n148:   // Todo: correct vtype\n149:   csrMod.io.fromRob.commit.vtype.valid
      := setVtype.valid\n150:   csrMod.io.fromRob.commit.vtype.bits.VILL := setVtype.bits(XLEN
      - 1)\n151:   csrMod.io.fromRob.commit.vtype.bits.VMA := setVtype.bits(7)\n152:\
      \   csrMod.io.fromRob.commit.vtype.bits.VTA := setVtype.bits(6)\n153:   csrMod.io.fromRob.commit.vtype.bits.VSEW
      := setVtype.bits(5, 3)\n154:   csrMod.io.fromRob.commit.vtype.bits.VLMUL :=
      setVtype.bits(2, 0)\n155: \n156:   csrMod.io.fromRob.commit.instNum.valid :=
      true.B  // Todo: valid control signal\n157:   csrMod.io.fromRob.commit.instNum.bits\
      \  := csrIn.perf.retiredInstr\n158: \n159:   csrMod.io.fromRob.robDeqPtr :=
      csrIn.robDeqPtr\n160: \n161:   csrMod.io.fromVecExcpMod.busy := io.csrin.get.fromVecExcpMod.busy\n\
      162: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 204-214
    context: "204:   trapTvalMod.io.fromCtrlBlock.robDeqPtr := io.csrio.get.robDeqPtr\n\
      205: \n206:   val imsic = Module(new aia.IMSIC(soc.IMSICParams))\n207:   imsic.fromCSR.addr.valid
      := csrMod.toAIA.addr.valid\n208:   imsic.fromCSR.addr.bits.addr := csrMod.toAIA.addr.bits.addr\n\
      209:   imsic.fromCSR.addr.bits.virt := csrMod.toAIA.addr.bits.v.asUInt.asBool\n\
      210:   imsic.fromCSR.addr.bits.priv := aia.PrivType(csrMod.toAIA.addr.bits.prvm.asUInt)\n\
      211:   imsic.fromCSR.vgein := csrMod.toAIA.vgein\n212:   imsic.fromCSR.wdata.valid
      := csrMod.toAIA.wdata.valid\n213:   imsic.fromCSR.wdata.bits.op := aia.OpType(csrMod.toAIA.wdata.bits.op)\n\
      214:   imsic.fromCSR.wdata.bits.data := csrMod.toAIA.wdata.bits.data"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 267-278
    context: "267:   tlb.priv.mxr := csrMod.io.tlb.mxr\n268:   tlb.priv.sum := csrMod.io.tlb.sum\n\
      269:   tlb.priv.vmxr := csrMod.io.tlb.vmxr\n270:   tlb.priv.vsum := csrMod.io.tlb.vsum\n\
      271:   tlb.priv.spvp := csrMod.io.tlb.spvp\n272:   tlb.priv.virt := csrMod.io.tlb.dvirt\n\
      273:   tlb.priv.virt_changed := DataChanged(tlb.priv.virt)\n274:   tlb.priv.imode
      := csrMod.io.tlb.imode\n275:   tlb.priv.dmode := csrMod.io.tlb.dmode\n276: \n\
      277:   // Svpbmt extension enable\n278:   tlb.mPBMTE := csrMod.io.tlb.mPBMTE"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/CSR.scala
    lines: 289-313
    context: "289:   io.out.bits.res.data := csrMod.io.out.bits.rData\n290: \n291:\
      \   /** initialize NewCSR's io_out_ready from wrapper's io */\n292:   csrMod.io.out.ready
      := io.out.ready\n293: \n294:   io.out.bits.res.redirect.get.valid := io.out.valid
      && RegEnable(isXRet, false.B, io.in.fire)\n295:   val redirect = io.out.bits.res.redirect.get.bits\n\
      296:   redirect := 0.U.asTypeOf(redirect)\n297:   redirect.level := RedirectLevel.flushAfter\n\
      298:   redirect.robIdx := robIdxReg\n299:   redirect.ftqIdx := RegEnable(io.in.bits.ctrl.ftqIdx.get,
      io.in.fire)\n300:   redirect.ftqOffset := RegEnable(io.in.bits.ctrl.ftqOffset.get,
      io.in.fire)\n301:   redirect.cfiUpdate.predTaken := true.B\n302:   redirect.cfiUpdate.taken
      := true.B\n303:   redirect.cfiUpdate.target := csrMod.io.out.bits.targetPc.pc\n\
      304:   redirect.cfiUpdate.backendIPF := csrMod.io.out.bits.targetPc.raiseIPF\n\
      305:   redirect.cfiUpdate.backendIAF := csrMod.io.out.bits.targetPc.raiseIAF\n\
      306:   redirect.cfiUpdate.backendIGPF := csrMod.io.out.bits.targetPc.raiseIGPF\n\
      307:   // Only mispred will send redirect to frontend\n308:   redirect.cfiUpdate.isMisPred
      := true.B\n309: \n310:   connectNonPipedCtrlSingal\n311: \n312:   override val
      criticalErrors = csrMod.getCriticalErrors\n313:   generateCriticalErrors()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/BranchUnit.scala
    lines: 46-70
    context: "46: \n47:   io.out.valid := io.in.valid\n48:   io.in.ready := io.out.ready\n\
      49: \n50:   io.out.bits.res.data := 0.U\n51:   io.out.bits.res.redirect.get
      match {\n52:     case redirect =>\n53:       redirect.valid := io.out.valid
      && dataModule.io.mispredict\n54:       redirect.bits := 0.U.asTypeOf(io.out.bits.res.redirect.get.bits)\n\
      55:       redirect.bits.level := RedirectLevel.flushAfter\n56:       redirect.bits.robIdx
      := io.in.bits.ctrl.robIdx\n57:       redirect.bits.ftqIdx := io.in.bits.ctrl.ftqIdx.get\n\
      58:       redirect.bits.ftqOffset := io.in.bits.ctrl.ftqOffset.get\n59:    \
      \   redirect.bits.fullTarget := addModule.io.target\n60:       redirect.bits.cfiUpdate.isMisPred
      := dataModule.io.mispredict\n61:       redirect.bits.cfiUpdate.taken := dataModule.io.taken\n\
      62:       redirect.bits.cfiUpdate.predTaken := dataModule.io.pred_taken\n63:\
      \       redirect.bits.cfiUpdate.target := addModule.io.target\n64:       redirect.bits.cfiUpdate.pc
      := io.in.bits.data.pc.get\n65:       redirect.bits.cfiUpdate.backendIAF := io.instrAddrTransType.get.checkAccessFault(addModule.io.target)\n\
      66:       redirect.bits.cfiUpdate.backendIPF := io.instrAddrTransType.get.checkPageFault(addModule.io.target)\n\
      67:       redirect.bits.cfiUpdate.backendIGPF := io.instrAddrTransType.get.checkGuestPageFault(addModule.io.target)\n\
      68:   }\n69:   connect0LatencyCtrlSingal\n70: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/FCVT.scala
    lines: 24-38
    context: "24: \n25:   private val isFround  = opcode === VfcvtType.fround\n26:\
      \   private val isFoundnx = opcode === VfcvtType.froundnx\n27:   private val
      isFcvtmod = opcode === VfcvtType.fcvtmod_w_d\n28: \n29:   private val isRtz
      = opcode(2) & opcode(1) | isFcvtmod\n30:   private val isRod = opcode(2) & !opcode(1)
      & opcode(0)\n31:   private val isFrm = !isRtz && !isRod\n32:   private val vfcvtRm
      = Mux1H(\n33:     Seq(isRtz, isRod, isFrm),\n34:     Seq(1.U, 6.U, rm)\n35:\
      \   )\n36: \n37:   val widen = opcode(4, 3) // 0->single 1->widen 2->norrow
      => width of result\n38:   val isSingleCvt = !widen(1) & !widen(0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/wrapper/FDivSqrt.scala
    lines: 9-19
    context: "9: import xiangshan.backend.fu.fpu.FpNonPipedFuncUnit\n10: import xiangshan.backend.rob.RobPtr\n\
      11: import yunsuan.VfpuType\n12: import yunsuan.fpu.FloatDivider\n13: \n14:
      class FDivSqrt(cfg: FuConfig)(implicit p: Parameters) extends FpNonPipedFuncUnit(cfg)
      {\n15:   XSError(io.in.valid && io.in.bits.ctrl.fuOpType === VfpuType.dummy,
      \"fdiv OpType not supported\")\n16: \n17:   // io alias\n18:   private val opcode
      = fuOpType(0)\n19:   private val src0 = inData.src(0)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 154-164
    context: "154: \n155:   def needPc: Boolean = Seq(FuType.jmp, FuType.brh, FuType.ldu).contains(fuType)\n\
      156: \n157:   def needFPUCtrl: Boolean = {\n158:     import FuType._\n159: \
      \    Seq(fmac, fDivSqrt, i2f).contains(fuType)\n160:   }\n161: \n162:   def
      needVecCtrl: Boolean = {\n163:     import FuType._\n164:     Seq(vipu, vialuF,
      vimac, vidiv, vfpu, vppu, vfalu, vfma, vfdiv, vfcvt, vldu, vstu).contains(fuType)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuConfig.scala
    lines: 723-734
    context: "723:     needSrcFrm = true,\n724:   )\n725: \n726:   val FdivCfg = FuConfig(\n\
      727:     name = \"fdiv\",\n728:     fuType = FuType.fDivSqrt,\n729:     fuGen
      = (p: Parameters, cfg: FuConfig) => Module(new FDivSqrt(cfg)(p).suggestName(\"\
      Fdiv\")),\n730:     srcData = Seq(\n731:       Seq(FpData(), FpData()),\n732:\
      \     ),\n733:     piped = false,\n734:     writeFpRf = true,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/util/CSRConst.scala
    lines: 86-96
    context: "86:     IRQ_SEIP, IRQ_SSIP, IRQ_STIP,\n87:     IRQ_UEIP, IRQ_USIP, IRQ_UTIP,\n\
      88:     IRQ_VSEIP, IRQ_VSSIP, IRQ_VSTIP, IRQ_SGEIP\n89:   )\n90: \n91:   def
      csrAccessPermissionCheck(addr: UInt, wen: Bool, mode: UInt, virt: Bool, hasH:
      Bool): UInt = {\n92:     val readOnly = addr(11, 10) === \"b11\".U\n93:    \
      \ val lowestAccessPrivilegeLevel = addr(9,8)\n94:     val priv = Mux(mode ===
      ModeS, ModeH, mode)\n95:     val ret = Wire(Bool()) //0.U: normal, 1.U: illegal_instruction,
      2.U: virtual instruction\n96:     when (lowestAccessPrivilegeLevel === ModeH
      && !hasH){"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/util/CSRConst.scala
    lines: 96-106
    context: "96:     when (lowestAccessPrivilegeLevel === ModeH && !hasH){\n97: \
      \      ret := 1.U\n98:     }.elsewhen (readOnly && wen) {\n99:       ret :=
      1.U\n100:     }.elsewhen (priv < lowestAccessPrivilegeLevel) {\n101:       when(virt
      && lowestAccessPrivilegeLevel <= ModeH){\n102:         ret := 2.U\n103:    \
      \   }.otherwise{\n104:         ret := 1.U\n105:       }\n106:     }.otherwise{"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/util/DebugCSR.scala
    lines: 40-50
    context: "40:     private def stopcount_offset  = 10\n41:     private def stoptime_offset\
      \   = 9\n42:     private def mprven_offset     = 5\n43:     private def prv_offset\
      \        = 0\n44:     def init: UInt = (\n45:       (DEBUGVER_SPEC.litValue
      << debugver_offset) | /* Debug implementation as it described in 0.13 draft
      */\n46:       (0L << stopcount_offset) |                    /* Stop count updating
      has not been supported */\n47:       (0L << stoptime_offset) |             \
      \        /* Stop time updating has not been supported */\n48:       (0L << mprven_offset)
      |                       /* Whether use mstatus.perven as mprven */\n49:    \
      \   (ModeM.litValue << prv_offset)\n50:     ).U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/Radix2Divider.scala
    lines: 38-49
    context: "38:   val s_idle :: s_log2 :: s_shift :: s_compute :: s_finish :: Nil
      = Enum(5)\n39:   val state = RegInit(s_idle)\n40:   val newReq = (state ===
      s_idle) && io.in.fire\n41: \n42:   val (a, b) = (io.in.bits.src(0), io.in.bits.src(1))\n\
      43:   val divBy0 = b === 0.U(len.W)\n44:   val divBy0Reg = RegEnable(divBy0,
      newReq)\n45: \n46:   val shiftReg = Reg(UInt((1 + len * 2).W))\n47:   val hi
      = shiftReg(len * 2, len)\n48:   val lo = shiftReg(len - 1, 0)\n49: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/Radix2Divider.scala
    lines: 50-60
    context: "50:   val uop = io.in.bits.uop\n51: \n52:   val (aSign, aVal) = abs(a,
      sign)\n53:   val (bSign, bVal) = abs(b, sign)\n54:   val aSignReg = RegEnable(aSign,
      newReq)\n55:   val qSignReg = RegEnable((aSign ^ bSign) && !divBy0, newReq)\n\
      56:   val bReg = RegEnable(bVal, newReq)\n57:   val aValx2Reg = RegEnable(Cat(aVal,
      \"b0\".U), newReq)\n58:   val ctrlReg = RegEnable(ctrl, newReq)\n59:   val uopReg
      = RegEnable(uop, newReq)\n60: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 64-74
    context: "64: \n65: class FuncUnitDataOutput(cfg: FuConfig)(implicit p: Parameters)
      extends XSBundle {\n66:   val data      = UInt(cfg.destDataBits.W)\n67:   val
      fflags    = OptionWrapper(cfg.writeFflags, UInt(5.W))\n68:   val vxsat     =
      OptionWrapper(cfg.writeVxsat, Vxsat())\n69:   val redirect  = OptionWrapper(cfg.hasRedirect,
      ValidIO(new Redirect))\n70: }\n71: \n72: class FuncUnitInput(cfg: FuConfig)(implicit
      p: Parameters) extends XSBundle {\n73:   val needCtrlPipe = cfg.latency.latencyVal.nonEmpty
      && (!cfg.isStd)\n74:   val ctrl = new FuncUnitCtrlInput(cfg)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 86-96
    context: "86:   val perfDebugInfo = new PerfDebugInfo()\n87:   val debug_seqNum
      = InstSeqNum()\n88: }\n89: \n90: class FuncUnitIO(cfg: FuConfig)(implicit p:
      Parameters) extends XSBundle {\n91:   val flush = Flipped(ValidIO(new Redirect))\n\
      92:   val in = Flipped(DecoupledIO(new FuncUnitInput(cfg)))\n93:   val out =
      DecoupledIO(new FuncUnitOutput(cfg))\n94:   val csrin = OptionWrapper(cfg.isCsr,
      new CSRInput)\n95:   val csrio = OptionWrapper(cfg.isCsr, new CSRFileIO)\n96:\
      \   val csrToDecode = OptionWrapper(cfg.isCsr, Output(new CSRToDecode))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuncUnit.scala
    lines: 167-177
    context: "167: \n168:   val latdiff :Int = cfg.latency.extraLatencyVal.getOrElse(0)\n\
      169:   val preLat :Int = latency - latdiff\n170:   require(latency >= 0 && latdiff
      >=0)\n171: \n172:   def pipelineReg(init: FuncUnitInput , valid:Bool, ready:
      Bool,latency: Int, flush:ValidIO[Redirect]): (Seq[FuncUnitInput],Seq[Bool],Seq[Bool])={\n\
      173:     val rdyVec = Seq.fill(latency)(Wire(Bool())) :+ ready\n174:     val
      validVec = valid +: Seq.fill(latency)(RegInit(false.B))\n175:     val ctrlVec
      = init.ctrl +: Seq.fill(latency)(Reg(chiselTypeOf(io.in.bits.ctrl)))\n176: \
      \    val dataVec = init.data +: Seq.fill(latency)(Reg(chiselTypeOf(io.in.bits.data)))\n\
      177:     val perfVec = init.perfDebugInfo +: Seq.fill(latency)(Reg(chiselTypeOf(io.in.bits.perfDebugInfo)))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/Jump.scala
    lines: 26-36
    context: "26: import xiangshan.backend.decode.ImmUnion\n27: import xiangshan.backend.decode.isa._\n\
      28: \n29: trait HasRedirectOut { this: XSModule =>\n30:   val redirectOutValid
      = IO(Output(Bool()))\n31:   val redirectOut = IO(Output(new Redirect))\n32:
      }\n33: \n34: class JumpDataModule(implicit p: Parameters) extends XSModule {\n\
      35:   val io = IO(new Bundle() {\n36:     val src = Input(UInt(XLEN.W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuType.scala
    lines: 41-51
    context: "41: \n42:   // fp\n43:   val falu = addType(name = \"falu\")\n44:  \
      \ val fmac = addType(name = \"fmac\")\n45:   val fcvt = addType(name = \"fcvt\"\
      )\n46:   val fDivSqrt = addType(name = \"fDivSqrt\")\n47: \n48:   // ls\n49:\
      \   val ldu = addType(name = \"ldu\")\n50:   val stu = addType(name = \"stu\"\
      )\n51:   val mou = addType(name = \"mou\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuType.scala
    lines: 120-130
    context: "120:   }\n121:   def is0latency(fuType: UInt): Bool = {\n122:     val
      fuTypes = FuConfig.allConfigs.filter(_.latency == CertainLatency(0)).map(_.fuType)\n\
      123:     FuTypeOrR(fuType, fuTypes)\n124:   }\n125:   val fpArithAll = Seq(falu,
      fcvt, fmac, fDivSqrt, f2v)\n126:   val scalaMemAll = Seq(ldu, stu, mou)\n127:\
      \   val vecOPI = Seq(vipu, vialuF, vppu, vimac, vidiv)\n128:   val vecOPF =
      Seq(vfpu, vfalu, vfma, vfdiv, vfcvt)\n129:   val vecVSET = Seq(vsetiwi, vsetiwf,
      vsetfwf)\n130:   val vecArith = vecOPI ++ vecOPF"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuType.scala
    lines: 130-140
    context: "130:   val vecArith = vecOPI ++ vecOPF\n131:   val vecMem = Seq(vldu,
      vstu, vsegldu, vsegstu)\n132:   val vecArithOrMem = vecArith ++ vecMem\n133:\
      \   val vecAll = vecVSET ++ vecArithOrMem\n134:   val fpOP = fpArithAll ++ Seq(i2f,
      i2v)\n135:   val scalaNeedFrm = Seq(i2f, fmac, fDivSqrt)\n136:   val vectorNeedFrm
      = Seq(vfalu, vfma, vfdiv, vfcvt)\n137: \n138:   def X = BitPat.N(num) // Todo:
      Don't Care\n139: \n140:   def num = this.values.size"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuType.scala
    lines: 199-209
    context: "199: \n200:   def isVecOPF(fuType: UInt): Bool = FuTypeOrR(fuType, vecOPF)\n\
      201: \n202:   def isVArithMem(fuType: UInt): Bool = FuTypeOrR(fuType, vecArithOrMem)
      // except vset\n203: \n204:   def isDivSqrt(fuType: UInt): Bool = FuTypeOrR(fuType,
      div, fDivSqrt)\n205: \n206:   def storeIsAMO(fuType: UInt): Bool = FuTypeOrR(fuType,
      mou)\n207: \n208:   def isVppu(fuType: UInt): Bool = FuTypeOrR(fuType, vppu)\n\
      209: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/FuType.scala
    lines: 240-250
    context: "240:     mul -> \"mul\",\n241:     div -> \"div\",\n242:     fence ->
      \"fence\",\n243:     bku -> \"bku\",\n244:     fmac -> \"fmac\",\n245:     fDivSqrt
      -> \"fdiv_fsqrt\",\n246:     ldu -> \"load\",\n247:     stu -> \"store\",\n\
      248:     mou -> \"mou\",\n249:     vsetiwi -> \"vsetiwi\",\n250:     vsetiwf
      -> \"vsetiwf\","
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 37-47
    context: "37: import freechips.rocketchip.rocket.CSRs\n38: \n39: class FpuCsrIO
      extends Bundle {\n40:   val fflags = Output(Valid(UInt(5.W)))\n41:   val isIllegal
      = Output(Bool())\n42:   val dirty_fs = Output(Bool())\n43:   val frm = Input(UInt(3.W))\n\
      44: }\n45: \n46: class VpuCsrIO(implicit p: Parameters) extends XSBundle {\n\
      47:   val vstart = Input(UInt(XLEN.W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 51-61
    context: "51: \n52:   val set_vstart = Output(Valid(UInt(XLEN.W)))\n53:   val
      set_vtype = Output(Valid(UInt(XLEN.W)))\n54:   val set_vxsat = Output(Valid(UInt(1.W)))\n\
      55: \n56:   val dirty_vs = Output(Bool())\n57: }\n58: \n59: \n60: class PerfCounterIO(implicit
      p: Parameters) extends XSBundle {\n61:   val perfEventsFrontend  = Vec(numCSRPCntFrontend,
      new PerfEvent)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 370-380
    context: "370:   val mstatusStruct = mstatus.asTypeOf(new MstatusStruct)\n371:\
      \   def mstatusUpdateSideEffect(mstatus: UInt): UInt = {\n372:     val mstatusOld
      = WireInit(mstatus.asTypeOf(new MstatusStruct))\n373:     // Cat(sd, other)\n\
      374:     val mstatusNew = Cat(\n375:       mstatusOld.xs === ContextStatus.dirty
      || mstatusOld.fs === ContextStatus.dirty || mstatusOld.vs === ContextStatus.dirty,\n\
      376:       mstatus(XLEN-2, 0)\n377:     )\n378:     mstatusNew\n379:   }\n380:\
      \   def vsstatusUpdateSideEffect(vsstatus: UInt): UInt = {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1030-1040
    context: "1030:   when(RegNext(csrio.vpu.set_vxsat.valid)) {\n1031:     vcsr :=
      vxsat_wfn(update = true)(RegEnable(csrio.vpu.set_vxsat.bits, csrio.vpu.set_vxsat.valid))\n\
      1032:   }\n1033: \n1034:   // set fs and sd in mstatus\n1035:   when (csrw_dirty_fp_state
      || RegNext(csrio.fpu.dirty_fs)) {\n1036:     val mstatusNew = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1037:     mstatusNew.fs := \"b11\".U\n1038:     mstatusNew.sd
      := true.B\n1039:     mstatus := mstatusNew.asUInt\n1040:     when(virtMode){"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1052-1064
    context: "1052:   when (RegNext(csrio.vpu.set_vtype.valid)) {\n1053:     vtype
      := RegEnable(csrio.vpu.set_vtype.bits, csrio.vpu.set_vtype.valid)\n1054:   }\n\
      1055:   vl := csrio.vpu.vl\n1056:   // set vs and sd in mstatus\n1057:   when(csrw_dirty_vs_state
      || RegNext(csrio.vpu.dirty_vs)) {\n1058:     val mstatusNew = WireInit(mstatus.asTypeOf(new
      MstatusStruct))\n1059:     mstatusNew.vs := ContextStatus.dirty\n1060:     mstatusNew.sd
      := true.B\n1061:     mstatus := mstatusNew.asUInt\n1062:   }\n1063: \n1064:\
      \   csrio.vpu.vstart := vstart"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1132-1142
    context: "1132:   tlbBundle.priv.mxr   := mstatusStruct.mxr.asBool\n1133:   tlbBundle.priv.sum\
      \   := mstatusStruct.sum.asBool\n1134:   tlbBundle.priv.vmxr := vsstatusStruct.mxr.asBool\n\
      1135:   tlbBundle.priv.vsum := vsstatusStruct.sum.asBool\n1136:   tlbBundle.priv.spvp
      := hstatusStruct.spvp\n1137:   tlbBundle.priv.virt  := Mux(mstatusStruct.mprv.asBool,
      mstatusStruct.mpv & (mstatusStruct.mpp =/= ModeM), virtMode)\n1138:   tlbBundle.priv.imode
      := privilegeMode\n1139:   tlbBundle.priv.dmode := Mux((debugMode && dcsr.asTypeOf(new
      DcsrStruct).mprven || !debugMode) && mstatusStruct.mprv.asBool, mstatusStruct.mpp,
      privilegeMode)\n1140: \n1141:   // Branch control\n1142:   val retTarget = WireInit(0.U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1178-1188
    context: "1178:       mstatus := mstatusNew.asUInt\n1179:       privilegeMode
      := dcsr.asTypeOf(new DcsrStruct).prv\n1180:       debugModeNew := false.B\n\
      1181:       debugIntrEnable := true.B\n1182:       debugMode := debugModeNew\n\
      1183:       XSDebug(\"Debug Mode: Dret executed, returning to %x.\", retTarget)\n\
      1184:     }.elsewhen(isMret && !illegalMret) {\n1185:       val mstatusOld =
      WireInit(mstatus.asTypeOf(new MstatusStruct))\n1186:       val mstatusNew =
      WireInit(mstatus.asTypeOf(new MstatusStruct))\n1187:       mstatusNew.ie.m :=
      mstatusOld.pie.m\n1188:       privilegeMode := mstatusOld.mpp"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1499-1512
    context: "1499:       vsstatusNew.ie.s := false.B\n1500:       when (clearTval)
      {vstval := 0.U}\n1501:       virtMode := true.B\n1502:       privilegeMode :=
      ModeS\n1503:     }.elsewhen (delegS) {\n1504:       val virt = Mux(mstatusOld.mprv.asBool,
      mstatusOld.mpv, virtMode)\n1505:       // to do hld st\n1506:       hstatusNew.gva
      := (hasInstGuestPageFault || hasLoadGuestPageFault || hasStoreGuestPageFault
      ||\n1507:                       ((virt.asBool || isHyperInst) && ((hasException
      && 0.U <= exceptionNO && exceptionNO <= 7.U && exceptionNO =/= 2.U)\n1508: \
      \                      || hasInstrPageFault || hasLoadPageFault || hasStorePageFault)))\n\
      1509:       hstatusNew.spv := virtMode\n1510:       when(virtMode){\n1511: \
      \        hstatusNew.spvp := privilegeMode\n1512:       }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/fu/CSR.scala
    lines: 1518-1531
    context: "1518:       mstatusNew.ie.s := false.B\n1519:       privilegeMode :=
      ModeS\n1520:       when (clearTval) { stval := 0.U }\n1521:       when (clearTval_h)
      {htval := 0.U}\n1522:     }.otherwise {\n1523:       val virt = Mux(mstatusOld.mprv.asBool,
      mstatusOld.mpv, virtMode)\n1524:       // to do hld st\n1525:       mstatusNew.gva
      := (hasInstGuestPageFault || hasLoadGuestPageFault || hasStoreGuestPageFault
      ||\n1526:       ((virt.asBool || isHyperInst) && ((hasException && 0.U <= exceptionNO
      && exceptionNO <= 7.U && exceptionNO =/= 2.U)\n1527:         || hasInstrPageFault
      || hasLoadPageFault || hasStorePageFault)))\n1528:       mstatusNew.mpv := virtMode\n\
      1529:       virtMode := false.B\n1530:       mcause := causeNO\n1531:      \
      \ mepc := Mux(hasInstrPageFault || hasInstrAccessFault, iexceptionPC, dexceptionPC)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/vector/Mgu.scala
    lines: 205-215
    context: "205: object VerilogMgu extends App {\n206:   println(\"Generating the
      Mgu hardware\")\n207:   val (config, firrtlOpts, firtoolOpts) = ArgParser.parse(args)\n\
      208:   val p = config.alterPartial({case XSCoreParamsKey => config(XSTileKey).head})\n\
      209: \n210:   emitVerilog(new Mgu(128)(p), Array(\"--target-dir\", \"build/vifu\"\
      , \"--full-stacktrace\"))\n211: }\n212: \n213: class MguTest extends AnyFlatSpec
      with ChiselScalatestTester with Matchers {\n214: \n215:   val defaultConfig
      = (new DefaultConfig).alterPartial({"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/vector/utils/MaskExtrator.scala
    lines: 44-50
    context: "44:   }\n45: }\n46: \n47: object VerilogMaskExtrator extends App {\n\
      48:   println(\"Generating the MaskExtractor hardware\")\n49:   emitVerilog(new
      MaskExtractor(128), Array(\"--full-stacktrace\", \"--target-dir\", \"build/MaskExtractor\"\
      ))\n50: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 122-136
    context: "122:   private val (privState, debugMode) = (\n123:     io.in.privState,\n\
      124:     io.in.debugMode,\n125:   )\n126: \n127:   private val (mnret, mret,
      sret, dret) = (\n128:     io.in.xRet.mnret,\n129:     io.in.xRet.mret,\n130:\
      \     io.in.xRet.sret,\n131:     io.in.xRet.dret,\n132:   )\n133: \n134:   private
      val (tsr, vtsr) = (\n135:     io.in.status.tsr,\n136:     io.in.status.vtsr,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 144-154
    context: "144: \n145:   private val sret_EX_II = sret && (privState.isModeHU ||
      privState.isModeHS && tsr)\n146:   private val sret_EX_VI = sret && (privState.isModeVU
      || privState.isModeVS && vtsr)\n147:   private val sretIllegal = sret_EX_II
      || sret_EX_VI\n148: \n149:   private val dret_EX_II = dret && !debugMode\n150:\
      \   private val dretIllegal = dret_EX_II\n151: \n152:   io.out.Xret_EX_II :=
      mnret_EX_II || mret_EX_II || sret_EX_II || dret_EX_II\n153:   io.out.Xret_EX_VI
      := sret_EX_VI\n154:   io.out.hasLegalMNret := mnret && !mnretIllegal"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 152-162
    context: "152:   io.out.Xret_EX_II := mnret_EX_II || mret_EX_II || sret_EX_II
      || dret_EX_II\n153:   io.out.Xret_EX_VI := sret_EX_VI\n154:   io.out.hasLegalMNret
      := mnret && !mnretIllegal\n155:   io.out.hasLegalMret  := mret  && !mretIllegal\n\
      156:   io.out.hasLegalSret  := sret  && !sretIllegal\n157:   io.out.hasLegalDret\
      \  := dret  && !dretIllegal\n158: }\n159: \n160: class MLevelPermitModule extends
      Module {\n161:   val io = IO(new Bundle() {\n162:     val in = Input(new Bundle
      {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRPermitModule.scala
    lines: 577-587
    context: "577: \n578: class xRetIO extends Bundle {\n579:   val mnret = Bool()\n\
      580:   val mret = Bool()\n581:   val sret = Bool()\n582:   val dret = Bool()\n\
      583: }\n584: \n585: class statusIO extends Bundle {\n586:   // Trap SRET\n587:\
      \   val tsr = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 326-337
    context: "326: \n327: \n328:   val minstret = Module(new CSRModule(\"Minstret\"\
      ) with HasMachineCounterControlBundle with HasRobCommitBundle {\n329:     when(w.wen)
      {\n330:       reg := w.wdata\n331:     }.elsewhen(!this.mcountinhibit.IR &&
      robCommit.instNum.valid) {\n332:       reg := reg.ALL.asUInt + robCommit.instNum.bits\n\
      333:     }.otherwise {\n334:       reg := reg\n335:     }\n336:   }).setAddr(CSRs.minstret)\n\
      337: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 503-513
    context: "503:   val MBE  = CSRROField     (37).withReset(0.U)\n504:   val GVA\
      \  = CSRRWField     (38).withReset(0.U)\n505:   val MPV  = VirtMode       (39).withReset(0.U)\n\
      506:   val MDT  = CSRRWField     (42).withReset(mdtInit.U)\n507:   val SD  \
      \ = CSRROField     (63,\n508:     (_, _) => FS === ContextStatus.Dirty || VS
      === ContextStatus.Dirty\n509:   )\n510: }\n511: \n512: class MstatusModule(implicit
      override val p: Parameters) extends CSRModule(\"MStatus\", new MstatusBundle)\n\
      513:   with TrapEntryMEventSinkBundle"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 532-549
    context: "532:   }\n533: \n534:   // write connection\n535:   reconnectReg()\n\
      536: \n537:   when (robCommit.fsDirty || writeFCSR) {\n538:     assert(reg.FS
      =/= ContextStatus.Off, \"The [m|s]status.FS should not be Off when set dirty,
      please check decode\")\n539:     reg.FS := ContextStatus.Dirty\n540:   }\n541:\
      \ \n542:   when (robCommit.vsDirty || writeVCSR || robCommit.vstart.valid &&
      robCommit.vstart.bits =/= 0.U) {\n543:     assert(reg.VS =/= ContextStatus.Off,
      \"The [m|s]status.VS should not be Off when set dirty, please check decode\"\
      )\n544:     reg.VS := ContextStatus.Dirty\n545:   }\n546:   // when MDT is explicitly
      written by 1, clear MIE\n547:   // only when reg.MDT is zero or wdata.MDT is
      zero , MIE can be explicitly written by 1\n548:   when (w.wdataFields.MDT &&
      w.wen) {\n549:     reg.MIE := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/MachineLevel.scala
    lines: 795-805
    context: "795: trait HasMachineCounterControlBundle { self: CSRModule[_] =>\n\
      796:   val mcountinhibit = IO(Input(new McountinhibitBundle))\n797: }\n798:\
      \ \n799: trait HasRobCommitBundle { self: CSRModule[_] =>\n800:   val robCommit
      = IO(Input(new RobCommitCSR))\n801:   val writeFCSR = IO(Input(Bool()))\n802:\
      \   val writeVCSR = IO(Input(Bool()))\n803:   val isVirtMode = IO(Input(Bool()))\n\
      804: }\n805: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 6-16
    context: "6: import freechips.rocketchip.rocket.CSRs\n7: import org.chipsalliance.cde.config.Parameters\n\
      8: import top.{ArgParser, Generator}\n9: import utility._\n10: import utils.OptionWrapper\n\
      11: import xiangshan.backend.fu.NewCSR.CSRBundles.{CSRCustomState, PrivState,
      RobCommitCSR}\n12: import xiangshan.backend.fu.NewCSR.CSRDefines._\n13: import
      xiangshan.backend.fu.NewCSR.CSREnumTypeImplicitCast._\n14: import xiangshan.backend.fu.NewCSR.CSREvents.{CSREvents,
      DretEventSinkBundle, EventUpdatePrivStateOutput, MNretEventSinkBundle, MretEventSinkBundle,
      SretEventSinkBundle, SretEventSDTSinkBundle,  TargetPCBundle, TrapEntryDEventSinkBundle,
      TrapEntryEventInput, TrapEntryHSEventSinkBundle, TrapEntryMEventSinkBundle,
      TrapEntryMNEventSinkBundle, TrapEntryVSEventSinkBundle}\n15: import xiangshan.backend.fu.fpu.Bundles.Frm\n\
      16: import xiangshan.backend.fu.vector.Bundles.{Vl, Vstart, Vxrm, Vxsat}"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 79-89
    context: "79:   val src = UInt(64.W)\n80:   val wdata = UInt(64.W)\n81:   val
      mnret = Input(Bool())\n82:   val mret = Input(Bool())\n83:   val sret = Input(Bool())\n\
      84:   val dret = Input(Bool())\n85:   val redirectFlush = Input(Bool())\n86:
      }\n87: \n88: class NewCSROutput(implicit p: Parameters) extends Bundle {\n89:\
      \   val EX_II = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 146-156
    context: "146:         val isInterrupt = Bool()\n147:         val isHls = Bool()\n\
      148:         val isFetchMalAddr = Bool()\n149:         val isForVSnonLeafPTE
      = Bool()\n150:       })\n151:       val commit = Input(new RobCommitCSR)\n152:\
      \       val robDeqPtr = Input(new RobPtr)\n153:     })\n154: \n155:     val
      fromVecExcpMod = Input(new Bundle {\n156:       val busy = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 208-218
    context: "208:       val vmxr = Bool()\n209:       val vsum = Bool()\n210:   \
      \    val spvp = Bool()\n211:       val imode = UInt(2.W)\n212:       val dmode
      = UInt(2.W)\n213:       val dvirt = Bool()\n214:       val mPBMTE = Bool()\n\
      215:       val hPBMTE = Bool()\n216:       val pmm = new Bundle {\n217:    \
      \     val mseccfg = UInt(2.W)\n218:         val menvcfg = UInt(2.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 290-306
    context: "290:   private val (isModeHS, isModeHU) = (privState.isModeHS, privState.isModeHU)\n\
      291:   private val (isModeVS, isModeVU) = (privState.isModeVS, privState.isModeVU)\n\
      292: \n293:   val permitMod = Module(new CSRPermitModule)\n294:   val sstcIRGen
      = Module(new SstcInterruptGen)\n295:   val commidIdMod = Module(new CommitIDModule(40,
      hartIdLen))\n296: \n297:   commidIdMod.io.hartId := io.fromTop.hartId\n298:\
      \   val gitCommitSHA = WireInit(commidIdMod.io.commitID)\n299:   val gitDirty\
      \     = WireInit(commidIdMod.io.dirty)\n300:   dontTouch(gitCommitSHA)\n301:\
      \   dontTouch(gitDirty)\n302: \n303:   private val wenLegal = permitMod.io.out.hasLegalWen\n\
      304: \n305:   val legalSret  = permitMod.io.out.hasLegalSret\n306:   val legalMret\
      \  = permitMod.io.out.hasLegalMret"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 476-486
    context: "476:   permitMod.io.in.debugMode := debugMode\n477: \n478:   permitMod.io.in.xRet.mnret
      := io.in.bits.mnret && valid\n479:   permitMod.io.in.xRet.mret  := io.in.bits.mret\
      \  && valid\n480:   permitMod.io.in.xRet.sret  := io.in.bits.sret  && valid\n\
      481:   permitMod.io.in.xRet.dret  := io.in.bits.dret  && valid\n482: \n483:\
      \   permitMod.io.in.status.tsr := mstatus.regOut.TSR.asBool\n484:   permitMod.io.in.status.vtsr
      := hstatus.regOut.VTSR.asBool\n485: \n486:   permitMod.io.in.status.tvm  :=
      mstatus.regOut.TVM.asBool"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 597-614
    context: "597:       case _ =>\n598:     }\n599:     mod match {\n600:       case
      m: HasRobCommitBundle =>\n601:         // Todo: move RegNext from ROB to CSR\n\
      602:         m.robCommit.instNum := io.fromRob.commit.instNum\n603:        \
      \ m.robCommit.fflags  := RegNextWithEnable(io.fromRob.commit.fflags)\n604: \
      \        m.robCommit.fsDirty := GatedValidRegNext(io.fromRob.commit.fsDirty)\n\
      605:         m.robCommit.vsDirty := GatedValidRegNext(io.fromRob.commit.vsDirty)\n\
      606:         m.robCommit.vxsat   := RegNextWithEnable(io.fromRob.commit.vxsat)\n\
      607:         m.robCommit.vtype   := RegNextWithEnable(io.fromRob.commit.vtype)\n\
      608:         m.robCommit.vl      := RegNext          (io.fromRob.commit.vl)\n\
      609:         m.robCommit.vstart  := RegNextWithEnable(io.fromRob.commit.vstart)\n\
      610:         m.writeFCSR         := writeFpLegal\n611:         m.writeVCSR \
      \        := writeVecLegal\n612:         m.isVirtMode        := V.asUInt.asBool\n\
      613:       case _ =>\n614:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1428-1438
    context: "1428:   io.tlb.dmode := Mux(\n1429:     (debugMode && dcsr.regOut.MPRVEN
      || !debugMode) && mstatus.regOut.MPRV && mnstatus.regOut.NMIE,\n1430:     mstatus.regOut.MPP.asUInt,\n\
      1431:     PRVM.asUInt\n1432:   )\n1433:   io.tlb.dvirt := Mux(\n1434:     (debugMode
      && dcsr.regOut.MPRVEN || !debugMode) && mstatus.regOut.MPRV && mnstatus.regOut.NMIE
      && mstatus.regOut.MPP =/= PrivMode.M,\n1435:     mstatus.regOut.MPV.asUInt,\n\
      1436:     V.asUInt\n1437:   )\n1438:   io.tlb.mPBMTE := RegNext(menvcfg.regOut.PBMTE.asBool)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1584-1594
    context: "1584:     diffVecCSRState.coreid := hartId\n1585:     diffVecCSRState.vstart
      := vstart.rdata.asUInt\n1586:     diffVecCSRState.vxsat := vcsr.vxsat.asUInt\n\
      1587:     diffVecCSRState.vxrm := vcsr.vxrm.asUInt\n1588:     diffVecCSRState.vcsr
      := vcsr.rdata.asUInt\n1589:     diffVecCSRState.vl := RegNext(io.fromRob.commit.vl)\n\
      1590:     diffVecCSRState.vtype := vtype.rdata.asUInt\n1591:     diffVecCSRState.vlenb
      := vlenb.rdata.asUInt\n1592: \n1593:     val diffFpCSRState = DifftestModule(new
      DiffFpCSRState)\n1594:     diffFpCSRState.coreid := hartId"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/NewCSR.scala
    lines: 1700-1710
    context: "1700:     // Get XSCoreParams and pass it to the \"small module\"\n\
      1701:     case XSCoreParamsKey => config(XSTileKey).head\n1702:   })\n1703:\
      \ \n1704:   Generator.execute(\n1705:     firrtlOpts :+ \"--full-stacktrace\"\
      \ :+ \"--target-dir\" :+ \"backend\",\n1706:     new NewCSR()(defaultConfig),\n\
      1707:     firtoolOpts\n1708:   )\n1709: \n1710:   println(\"done\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/SupervisorLevel.scala
    lines: 221-231
    context: "221:   val XS   = ContextStatusRO(16, 15).withReset(0.U)\n222:   val
      SUM  = CSRWARLField   (18, wNoFilter).withReset(0.U)\n223:   val MXR  = CSRWARLField\
      \   (19, wNoFilter).withReset(0.U)\n224:   val SDT  = CSRWARLField   (24, wNoFilter).withReset(0.U)\n\
      225:   val UXL  = XLENField      (33, 32).withReset(XLENField.XLEN64)\n226:\
      \   val SD   = CSRROField     (63, (_, _) => FS === ContextStatus.Dirty || VS
      === ContextStatus.Dirty)\n227: }\n228: \n229: class SieBundle extends InterruptEnableBundle
      {\n230:   this.getHS.foreach(_.setRW().withReset(0.U))\n231:   this.STIE.setRO().withReset(0.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/TrapTvalMod.scala
    lines: 9-19
    context: "9: import xiangshan.backend.rob.RobPtr\n10: \n11: class TrapTvalMod(implicit
      p: Parameters) extends XSModule with HasCircularQueuePtrHelper {\n12:   val
      io = IO(new Bundle {\n13:     val fromCtrlBlock = Input(new Bundle {\n14:  \
      \     val flush = ValidIO(new Redirect)\n15:       val robDeqPtr = Input(new
      RobPtr)\n16:     })\n17: \n18:     val targetPc = Input(ValidIO(new TargetPCBundle))\n\
      19:     val clear = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptBundle.scala
    lines: 133-143
    context: "133:   val LC30IP   = RO(30)\n134:   val LC31IP   = RO(31)\n135:   val
      LC32IP   = RO(32)\n136:   val LC33IP   = RO(33)\n137:   val LC34IP   = RO(34)\n\
      138:   val LPRASEIP = RO(35) // Low-priority RAS event interrupt\n139:   val
      LC36IP   = RO(36)\n140:   val LC37IP   = RO(37)\n141:   val LC38IP   = RO(38)\n\
      142:   val LC39IP   = RO(39)\n143:   val LC40IP   = RO(40)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptBundle.scala
    lines: 141-151
    context: "141:   val LC38IP   = RO(38)\n142:   val LC39IP   = RO(39)\n143:   val
      LC40IP   = RO(40)\n144:   val LC41IP   = RO(41)\n145:   val LC42IP   = RO(42)\n\
      146:   val HPRASEIP = RO(43) // High-priority RAS event interrupt\n147:   val
      LC44IP   = RO(44)\n148:   val LC45IP   = RO(45)\n149:   val LC46IP   = RO(46)\n\
      150:   val LC47IP   = RO(47)\n151:   val LC48IP   = RO(48)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptBundle.scala
    lines: 226-236
    context: "226:   val LC30IE   = RO(30)\n227:   val LC31IE   = RO(31)\n228:   val
      LC32IE   = RO(32)\n229:   val LC33IE   = RO(33)\n230:   val LC34IE   = RO(34)\n\
      231:   val LPRASEIE = RO(35) // Low-priority RAS event interrupt\n232:   val
      LC36IE   = RO(36)\n233:   val LC37IE   = RO(37)\n234:   val LC38IE   = RO(38)\n\
      235:   val LC39IE   = RO(39)\n236:   val LC40IE   = RO(40)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptBundle.scala
    lines: 234-244
    context: "234:   val LC38IE   = RO(38)\n235:   val LC39IE   = RO(39)\n236:   val
      LC40IE   = RO(40)\n237:   val LC41IE   = RO(41)\n238:   val LC42IE   = RO(42)\n\
      239:   val HPRASEIE = RO(43) // High-priority RAS event interrupt\n240:   val
      LC44IE   = RO(44)\n241:   val LC45IE   = RO(45)\n242:   val LC46IE   = RO(46)\n\
      243:   val LC47IE   = RO(47)\n244:   val LC48IE   = RO(48)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptBundle.scala
    lines: 443-453
    context: "443:   val LC30IP   = ValidIO(RO(30))\n444:   val LC31IP   = ValidIO(RO(31))\n\
      445:   val LC32IP   = ValidIO(RO(32))\n446:   val LC33IP   = ValidIO(RO(33))\n\
      447:   val LC34IP   = ValidIO(RO(34))\n448:   val LPRASEIP = ValidIO(RO(35))
      // Low-priority RAS event interrupt\n449:   val LC36IP   = ValidIO(RO(36))\n\
      450:   val LC37IP   = ValidIO(RO(37))\n451:   val LC38IP   = ValidIO(RO(38))\n\
      452:   val LC39IP   = ValidIO(RO(39))\n453:   val LC40IP   = ValidIO(RO(40))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptBundle.scala
    lines: 451-461
    context: "451:   val LC38IP   = ValidIO(RO(38))\n452:   val LC39IP   = ValidIO(RO(39))\n\
      453:   val LC40IP   = ValidIO(RO(40))\n454:   val LC41IP   = ValidIO(RO(41))\n\
      455:   val LC42IP   = ValidIO(RO(42))\n456:   val HPRASEIP = ValidIO(RO(43))
      // High-priority RAS event interrupt\n457:   val LC44IP   = ValidIO(RO(44))\n\
      458:   val LC45IP   = ValidIO(RO(45))\n459:   val LC46IP   = ValidIO(RO(46))\n\
      460:   val LC47IP   = ValidIO(RO(47))\n461:   val LC48IP   = ValidIO(RO(48))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptBundle.scala
    lines: 518-528
    context: "518:   val LC30IE   = ValidIO(RO(30))\n519:   val LC31IE   = ValidIO(RO(31))\n\
      520:   val LC32IE   = ValidIO(RO(32))\n521:   val LC33IE   = ValidIO(RO(33))\n\
      522:   val LC34IE   = ValidIO(RO(34))\n523:   val LPRASEIE = ValidIO(RO(35))
      // Low-priority RAS event interrupt\n524:   val LC36IE   = ValidIO(RO(36))\n\
      525:   val LC37IE   = ValidIO(RO(37))\n526:   val LC38IE   = ValidIO(RO(38))\n\
      527:   val LC39IE   = ValidIO(RO(39))\n528:   val LC40IE   = ValidIO(RO(40))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptBundle.scala
    lines: 526-536
    context: "526:   val LC38IE   = ValidIO(RO(38))\n527:   val LC39IE   = ValidIO(RO(39))\n\
      528:   val LC40IE   = ValidIO(RO(40))\n529:   val LC41IE   = ValidIO(RO(41))\n\
      530:   val LC42IE   = ValidIO(RO(42))\n531:   val HPRASEIE = ValidIO(RO(43))
      // High-priority RAS event interrupt\n532:   val LC44IE   = ValidIO(RO(44))\n\
      533:   val LC45IE   = ValidIO(RO(45))\n534:   val LC46IE   = ValidIO(RO(46))\n\
      535:   val LC47IE   = ValidIO(RO(47))\n536:   val LC48IE   = ValidIO(RO(48))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptBundle.scala
    lines: 622-632
    context: "622:   val LC30IP   = ValidIO(RO(30))\n623:   val LC31IP   = ValidIO(RO(31))\n\
      624:   val LC32IP   = ValidIO(RO(32))\n625:   val LC33IP   = ValidIO(RO(33))\n\
      626:   val LC34IP   = ValidIO(RO(34))\n627:   val LPRASEIP = ValidIO(RO(35))
      // Low-priority RAS event interrupt\n628:   val LC36IP   = ValidIO(RO(36))\n\
      629:   val LC37IP   = ValidIO(RO(37))\n630:   val LC38IP   = ValidIO(RO(38))\n\
      631:   val LC39IP   = ValidIO(RO(39))\n632:   val LC40IP   = ValidIO(RO(40))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/InterruptBundle.scala
    lines: 630-640
    context: "630:   val LC38IP   = ValidIO(RO(38))\n631:   val LC39IP   = ValidIO(RO(39))\n\
      632:   val LC40IP   = ValidIO(RO(40))\n633:   val LC41IP   = ValidIO(RO(41))\n\
      634:   val LC42IP   = ValidIO(RO(42))\n635:   val HPRASEIP = ValidIO(RO(43))
      // High-priority RAS event interrupt\n636:   val LC44IP   = ValidIO(RO(44))\n\
      637:   val LC45IP   = ValidIO(RO(45))\n638:   val LC46IP   = ValidIO(RO(46))\n\
      639:   val LC47IP   = ValidIO(RO(47))\n640:   val LC48IP   = ValidIO(RO(48))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/DebugLevel.scala
    lines: 270-280
    context: "270: class DscratchBundle extends OneFieldBundle\n271: \n272: \n273:
      class DcsrBundle extends CSRBundle {\n274:   override val len: Int = 32\n275:\
      \   val DEBUGVER  = DcsrDebugVer(31, 28).withReset(DcsrDebugVer.Spec) // Debug
      implementation as it described in 0.13 draft\n276:   val EXTCAUSE  =       \
      \    RO(26, 24).withReset(0.U)\n277:   val CETRIG    =           RW(    19).withReset(0.U)\n\
      278:   // All ebreak Privileges are RW, instead of WARL, since XiangShan support
      U/S/VU/VS.\n279:   val EBREAKVS  =           RW(    17).withReset(0.U)\n280:\
      \   val EBREAKVU  =           RW(    16).withReset(0.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Unprivileged.scala
    lines: 40-55
    context: "40:     }\n41: \n42:     // write connection\n43:     reconnectReg()\n\
      44: \n45:     when (robCommit.fflags.valid) {\n46:       reg.NX := robCommit.fflags.bits(0)
      || reg.NX\n47:       reg.UF := robCommit.fflags.bits(1) || reg.UF\n48:     \
      \  reg.OF := robCommit.fflags.bits(2) || reg.OF\n49:       reg.DZ := robCommit.fflags.bits(3)
      || reg.DZ\n50:       reg.NV := robCommit.fflags.bits(4) || reg.NV\n51:     }\n\
      52: \n53:     // read connection\n54:     fflags := reg.asUInt(4, 0)\n55:  \
      \   frm := reg.FRM.asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Unprivileged.scala
    lines: 66-79
    context: "66:   }) with HasRobCommitBundle {\n67:     // Todo make The use of
      vstart values greater than the largest element index for the current SEW setting
      is reserved.\n68:     // Not trap\n69:     when (wen) {\n70:       reg.vstart
      := this.w.wdata(VlWidth - 2, 0)\n71:     }.elsewhen (robCommit.vsDirty && !robCommit.vstart.valid)
      {\n72:       reg.vstart := 0.U\n73:     }.elsewhen (robCommit.vstart.valid)
      {\n74:       reg.vstart := robCommit.vstart.bits\n75:     }.otherwise {\n76:\
      \       reg := reg\n77:     }\n78:   })\n79:     .setAddr(CSRs.vstart)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Unprivileged.scala
    lines: 101-112
    context: "101:     }\n102: \n103:     // write connection\n104:     reconnectReg()\n\
      105: \n106:     when(robCommit.vxsat.valid) {\n107:       reg.VXSAT := reg.VXSAT.asBool
      || robCommit.vxsat.bits.asBool\n108:     }\n109: \n110:     // read connection\n\
      111:     vxsat := reg.VXSAT.asUInt\n112:     vxrm  := reg.VXRM.asUInt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/Unprivileged.scala
    lines: 116-127
    context: "116:     val VL = RO(VlWidth - 1, 0).withReset(0.U)\n117:   }))\n118:\
      \     .setAddr(CSRs.vl)\n119: \n120:   val vtype = Module(new CSRModule(\"Vtype\"\
      , new CSRVTypeBundle) with HasRobCommitBundle {\n121:     when(robCommit.vtype.valid)
      {\n122:       reg := robCommit.vtype.bits\n123:     }\n124:   })\n125:     .setAddr(CSRs.vtype)\n\
      126: \n127:   val vlenb = Module(new CSRModule(\"Vlenb\", new CSRBundle {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CommitIDModule.scala
    lines: 6-17
    context: "6: import java.util.Properties\n7: \n8: class PrintCommitIDModule(shaWidth:
      Int, hartIdlen: Int) extends BlackBox with HasBlackBoxInline {\n9:   val io
      = IO(new Bundle{\n10:     val hartID = Input(UInt(hartIdlen.W))\n11:     val
      commitID = Input(UInt(shaWidth.W))\n12:     val dirty = Input(Bool())\n13: \
      \  })\n14: \n15:   setInline(\"PrintCommitIDModule.v\",\n16:     s\"\"\"\n17:\
      \       |module PrintCommitIDModule("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CommitIDModule.scala
    lines: 14-30
    context: "14: \n15:   setInline(\"PrintCommitIDModule.v\",\n16:     s\"\"\"\n\
      17:       |module PrintCommitIDModule(\n18:       |  input [${hartIdlen-1}:0]
      hartID,\n19:       |  input [${shaWidth-1}:0] commitID,\n20:       |  input
      dirty\n21:       |);\n22:       |  wire _dummy_unused = 1'b1;\n23:       |`ifndef
      SYNTHESIS\n24:       |  initial begin\n25:       |    $$fwrite(32'h80000001,
      \"Core %d's Commit SHA is: %h, dirty: %d\\\\n\", hartID, commitID, dirty);\n\
      26:       |  end\n27:       |`endif\n28:       |\n29:       |endmodule\n30:\
      \       |\"\"\".stripMargin"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CommitIDModule.scala
    lines: 29-43
    context: "29:       |endmodule\n30:       |\"\"\".stripMargin\n31:   )\n32: }\n\
      33: \n34: class CommitIDModule(shaWidth: Int, hartIdlen: Int) extends Module
      {\n35:   val io = IO(new Bundle {\n36:     val hartId = Input(UInt(hartIdlen.W))\n\
      37:     val commitID = Output(UInt(shaWidth.W))\n38:     val dirty    = Output(Bool())\n\
      39:   })\n40: \n41:   val props = new Properties()\n42:   props.load((os.resource
      / \"gitStatus\").getInputStream)\n43: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CommitIDModule.scala
    lines: 40-57
    context: "40: \n41:   val props = new Properties()\n42:   props.load((os.resource
      / \"gitStatus\").getInputStream)\n43: \n44:   val sha = props.get(\"SHA\").asInstanceOf[String].take(shaWidth
      / 4)\n45:   val dirty = props.get(\"dirty\").asInstanceOf[String].toInt\n46:\
      \ \n47:   println(s\"[CommitIDModule] SHA=$sha\")\n48:   println(s\"[CommitIDModule]
      dirty=$dirty\")\n49: \n50:   io.commitID := BigInt(sha, 16).U(shaWidth.W)\n\
      51:   io.dirty := dirty.U\n52: \n53:   val printCommitIDMod = Module(new PrintCommitIDModule(shaWidth,
      hartIdlen))\n54:   printCommitIDMod.io.hartID := io.hartId\n55:   printCommitIDMod.io.commitID
      := io.commitID\n56:   printCommitIDMod.io.dirty := io.dirty\n57: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRNamedConstant.scala
    lines: 3-13
    context: "3: import chisel3._\n4: import chisel3.util.Enum\n5: \n6: object CSRNamedConstant
      {\n7:   object ContextStatus {\n8:     val off :: initial :: clean :: dirty
      :: Nil = Enum(4)\n9:   }\n10: \n11:   object MXL {\n12:     val w = 2\n13: \
      \    val XLEN32 = 1.U(w.W)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/VirtualSupervisorLevel.scala
    lines: 26-43
    context: "26:       with DretEventSinkBundle\n27:       with TrapEntryVSEventSinkBundle\n\
      28:       with HasRobCommitBundle\n29:       with HasVirtualSupervisorEnvBundle\n\
      30:     {\n31:       when ((robCommit.fsDirty || writeFCSR) && isVirtMode) {\n\
      32:         assert(reg.FS =/= ContextStatus.Off, \"The vsstatus.FS should not
      be Off when set dirty, please check decode\")\n33:         reg.FS := ContextStatus.Dirty\n\
      34:       }\n35: \n36:       when ((robCommit.vsDirty || writeVCSR || robCommit.vstart.valid
      && robCommit.vstart.bits =/= 0.U) && isVirtMode) {\n37:         assert(reg.VS
      =/= ContextStatus.Off, \"The vsstatus.VS should not be Off when set dirty, please
      check decode\")\n38:         reg.VS := ContextStatus.Dirty\n39:       }\n40:\
      \       // when menvcfg or henvcfg.DTE close,  vsstatus.SDT is read-only\n41:\
      \       val writeSDT = Wire(Bool())\n42:       writeSDT := Mux(this.menvcfg.DTE
      && this.henvcfg.DTE, w.wdataFields.SDT.asBool, 0.U)\n43:       when (!(this.menvcfg.DTE
      && this.henvcfg.DTE)) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRBundles.scala
    lines: 156-172
    context: "156:       _.PRVM -> PrivMode.U,\n157:       _.V    -> VirtMode.On,\n\
      158:     ))\n159:   }\n160: \n161:   class RobCommitCSR(implicit p: Parameters)
      extends Bundle {\n162:     // need contain 8x8\n163:     val instNum = ValidIO(UInt(7.W))\n\
      164:     val fflags  = ValidIO(Fflags())\n165:     val fsDirty = Bool()\n166:\
      \     val vxsat   = ValidIO(Vxsat())\n167:     val vsDirty = Bool()\n168:  \
      \   val vtype   = ValidIO(new CSRVTypeBundle)\n169:     val vl      = Vl()\n\
      170:     val vstart  = ValidIO(Vstart())\n171:   }\n172: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRDefines.scala
    lines: 139-149
    context: "139:   object ContextStatusRO extends CSREnum with ContextStatusDef
      with ROApply\n140:   trait ContextStatusDef { this: CSREnum =>\n141:     val
      Off = Value(0.U)\n142:     val Initial = Value(1.U)\n143:     val Clean = Value(2.U)\n\
      144:     val Dirty = Value(3.U)\n145:   }\n146: \n147:   object BMAField extends
      CSREnum with WARLApply {\n148:     val ResetBMA = Value(0.U)\n149:     val TestBMA
      = Value(\"h4000000\".U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/fu/NewCSR/CSRDefines.scala
    lines: 154-167
    context: "154:     val XLEN64 = Value(2.U)\n155:     val XLEN128 = Value(3.U)\n\
      156:   }\n157: \n158:   object XtvecMode extends CSREnum with WARLApply {\n\
      159:     val Direct = Value(0.U)\n160:     val Vectored = Value(1.U)\n161: \n\
      162:     override def isLegal(enumeration: CSREnumType): Bool = enumeration.isOneOf(Direct,
      Vectored)\n163:   }\n164: \n165:   object SatpMode extends CSREnum with WARLApply
      {\n166:     val Bare = Value(0.U)\n167:     val Sv39 = Value(8.U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 38-49
    context: "38: import xiangshan.mem.{LqPtr, LsqEnqIO, SqPtr}\n39: import xiangshan.backend.issue.{FpScheduler,
      IntScheduler, MemScheduler, VfScheduler}\n40: import xiangshan.backend.trace._\n\
      41: \n42: class CtrlToFtqIO(implicit p: Parameters) extends XSBundle {\n43:\
      \   val rob_commits = Vec(CommitWidth, Valid(new RobCommitInfo))\n44:   val
      redirect = Valid(new Redirect)\n45:   val ftqIdxAhead = Vec(BackendRedirectNum,
      Valid(new FtqPtr))\n46:   val ftqIdxSelOH = Valid(UInt((BackendRedirectNum).W))\n\
      47: }\n48: \n49: class CtrlBlock(params: BackendParams)(implicit p: Parameters)
      extends LazyModule {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 66-76
    context: "66:   with HasCircularQueuePtrHelper\n67:   with HasPerfEvents\n68:\
      \   with HasCriticalErrors\n69: {\n70:   val pcMemRdIndexes = new NamedIndexes(Seq(\n\
      71:     \"redirect\"  -> 1,\n72:     \"memPred\"   -> 1,\n73:     \"robFlush\"\
      \  -> 1,\n74:     \"bjuPc\"     -> params.BrhCnt,\n75:     \"bjuTarget\" ->
      params.BrhCnt,\n76:     \"load\"      -> params.LduCnt,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 99-109
    context: "99:   private val memCtrl = Module(new MemCtrl(params))\n100: \n101:\
      \   private val disableFusion = decode.io.csrCtrl.singlestep || !decode.io.csrCtrl.fusion_enable\n\
      102: \n103:   private val s0_robFlushRedirect = rob.io.flushOut\n104:   private
      val s1_robFlushRedirect = Wire(Valid(new Redirect))\n105:   s1_robFlushRedirect.valid
      := GatedValidRegNext(s0_robFlushRedirect.valid, false.B)\n106:   s1_robFlushRedirect.bits
      := RegEnable(s0_robFlushRedirect.bits, s0_robFlushRedirect.valid)\n107: \n108:\
      \   pcMem.io.ren.get(pcMemRdIndexes(\"robFlush\").head) := s0_robFlushRedirect.valid\n\
      109:   pcMem.io.raddr(pcMemRdIndexes(\"robFlush\").head) := s0_robFlushRedirect.bits.ftqIdx.value"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 111-121
    context: "111:   private val s3_redirectGen = redirectGen.io.stage2Redirect\n\
      112:   private val s1_s3_redirect = Mux(s1_robFlushRedirect.valid, s1_robFlushRedirect,
      s3_redirectGen)\n113:   private val s2_s4_pendingRedirectValid = RegInit(false.B)\n\
      114:   when (s1_s3_redirect.valid) {\n115:     s2_s4_pendingRedirectValid :=
      true.B\n116:   }.elsewhen (GatedValidRegNext(io.frontend.toFtq.redirect.valid))
      {\n117:     s2_s4_pendingRedirectValid := false.B\n118:   }\n119: \n120:   //
      Redirect will be RegNext at ExuBlocks and IssueBlocks\n121:   val s2_s4_redirect
      = RegNextWithEnable(s1_s3_redirect)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 182-199
    context: "182:     delayed.bits := RegEnable(PopCount(sameRobidxBools), x.valid)\n\
      183:     delayed\n184:   }).toSeq\n185: \n186:   private val exuPredecode =
      VecInit(\n187:     io.fromWB.wbData.filter(_.bits.redirect.nonEmpty).map(x =>
      x.bits.predecodeInfo.get).toSeq\n188:   )\n189: \n190:   private val exuRedirects:
      Seq[ValidIO[Redirect]] = io.fromWB.wbData.filter(_.bits.redirect.nonEmpty).map(x
      => {\n191:     val hasCSR = x.bits.params.hasCSR\n192:     val out = Wire(Valid(new
      Redirect()))\n193:     out.valid := x.valid && x.bits.redirect.get.valid &&
      (x.bits.redirect.get.bits.cfiUpdate.isMisPred || x.bits.redirect.get.bits.cfiUpdate.hasBackendFault)
      && !x.bits.robIdx.needFlush(Seq(s1_s3_redirect, s2_s4_redirect))\n194:     out.bits
      := x.bits.redirect.get.bits\n195:     out.bits.debugIsCtrl := true.B\n196: \
      \    out.bits.debugIsMemVio := false.B\n197:     // for fix timing, next cycle
      assgin\n198:     if (!hasCSR) {\n199:       out.bits.cfiUpdate.backendIAF :=
      false.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 200-211
    context: "200:       out.bits.cfiUpdate.backendIPF := false.B\n201:       out.bits.cfiUpdate.backendIGPF
      := false.B\n202:     }\n203:     out\n204:   }).toSeq\n205:   private val oldestOneHot
      = Redirect.selectOldestRedirect(exuRedirects)\n206:   private val CSROH = VecInit(io.fromWB.wbData.filter(_.bits.redirect.nonEmpty).map(x
      => x.bits.params.hasCSR.B))\n207:   private val oldestExuRedirectIsCSR = oldestOneHot
      === CSROH\n208:   private val oldestExuRedirect = Mux1H(oldestOneHot, exuRedirects)\n\
      209:   private val oldestExuPredecode = Mux1H(oldestOneHot, exuPredecode)\n\
      210: \n211:   private val memViolation = io.fromMem.violation"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 207-217
    context: "207:   private val oldestExuRedirectIsCSR = oldestOneHot === CSROH\n\
      208:   private val oldestExuRedirect = Mux1H(oldestOneHot, exuRedirects)\n209:\
      \   private val oldestExuPredecode = Mux1H(oldestOneHot, exuPredecode)\n210:\
      \ \n211:   private val memViolation = io.fromMem.violation\n212:   val loadReplay
      = Wire(ValidIO(new Redirect))\n213:   loadReplay.valid := GatedValidRegNext(memViolation.valid)\n\
      214:   loadReplay.bits := RegEnable(memViolation.bits, memViolation.valid)\n\
      215:   loadReplay.bits.debugIsCtrl := false.B\n216:   loadReplay.bits.debugIsMemVio
      := true.B\n217: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 213-235
    context: "213:   loadReplay.valid := GatedValidRegNext(memViolation.valid)\n214:\
      \   loadReplay.bits := RegEnable(memViolation.bits, memViolation.valid)\n215:\
      \   loadReplay.bits.debugIsCtrl := false.B\n216:   loadReplay.bits.debugIsMemVio
      := true.B\n217: \n218:   pcMem.io.ren.get(pcMemRdIndexes(\"redirect\").head)
      := memViolation.valid\n219:   pcMem.io.raddr(pcMemRdIndexes(\"redirect\").head)
      := memViolation.bits.ftqIdx.value\n220:   pcMem.io.ren.get(pcMemRdIndexes(\"\
      memPred\").head) := memViolation.valid\n221:   pcMem.io.raddr(pcMemRdIndexes(\"\
      memPred\").head) := memViolation.bits.stFtqIdx.value\n222:   redirectGen.io.memPredPcRead.data
      := pcMem.io.rdata(pcMemRdIndexes(\"memPred\").head).startAddr + (RegEnable(memViolation.bits.stFtqOffset,
      memViolation.valid) << instOffsetBits)\n223: \n224:   for ((pcMemIdx, i) <-
      pcMemRdIndexes(\"bjuPc\").zipWithIndex) {\n225:     val ren = io.toDataPath.pcToDataPathIO.fromDataPathValid(i)\n\
      226:     val raddr = io.toDataPath.pcToDataPathIO.fromDataPathFtqPtr(i).value\n\
      227:     val roffset = io.toDataPath.pcToDataPathIO.fromDataPathFtqOffset(i)\n\
      228:     pcMem.io.ren.get(pcMemIdx) := ren\n229:     pcMem.io.raddr(pcMemIdx)
      := raddr\n230:     io.toDataPath.pcToDataPathIO.toDataPathPC(i) := pcMem.io.rdata(pcMemIdx).startAddr\n\
      231:   }\n232: \n233:   val newestEn = RegNext(io.frontend.fromFtq.newest_entry_en)\n\
      234:   val newestTarget = RegEnable(io.frontend.fromFtq.newest_entry_target,
      io.frontend.fromFtq.newest_entry_en)\n235:   val newestPtr = RegEnable(io.frontend.fromFtq.newest_entry_ptr,
      io.frontend.fromFtq.newest_entry_en)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 232-274
    context: "232: \n233:   val newestEn = RegNext(io.frontend.fromFtq.newest_entry_en)\n\
      234:   val newestTarget = RegEnable(io.frontend.fromFtq.newest_entry_target,
      io.frontend.fromFtq.newest_entry_en)\n235:   val newestPtr = RegEnable(io.frontend.fromFtq.newest_entry_ptr,
      io.frontend.fromFtq.newest_entry_en)\n236:   val newestTargetNext = RegEnable(newestTarget,
      newestEn)\n237:   for ((pcMemIdx, i) <- pcMemRdIndexes(\"bjuTarget\").zipWithIndex)
      {\n238:     val ren = io.toDataPath.pcToDataPathIO.fromDataPathValid(i)\n239:\
      \     val baseAddr = io.toDataPath.pcToDataPathIO.fromDataPathFtqPtr(i).value\n\
      240:     val raddr = io.toDataPath.pcToDataPathIO.fromDataPathFtqPtr(i).value
      + 1.U\n241:     pcMem.io.ren.get(pcMemIdx) := ren\n242:     pcMem.io.raddr(pcMemIdx)
      := raddr\n243:     val needNewest = RegNext(baseAddr === newestPtr.value)\n\
      244:     io.toDataPath.pcToDataPathIO.toDataPathTargetPC(i) := Mux(needNewest,
      newestTargetNext, pcMem.io.rdata(pcMemIdx).startAddr)\n245:   }\n246: \n247:\
      \   val baseIdx = params.BrhCnt\n248:   for ((pcMemIdx, i) <- pcMemRdIndexes(\"\
      load\").zipWithIndex) {\n249:     // load read pcMem (s0) -> get rdata (s1)
      -> reg next in Memblock (s2) -> reg next in Memblock (s3) -> consumed by pf
      (s3)\n250:     val ren = io.toDataPath.pcToDataPathIO.fromDataPathValid(baseIdx+i)\n\
      251:     val raddr = io.toDataPath.pcToDataPathIO.fromDataPathFtqPtr(baseIdx+i).value\n\
      252:     val roffset = io.toDataPath.pcToDataPathIO.fromDataPathFtqOffset(baseIdx+i)\n\
      253:     pcMem.io.ren.get(pcMemIdx) := ren\n254:     pcMem.io.raddr(pcMemIdx)
      := raddr\n255:     io.toDataPath.pcToDataPathIO.toDataPathPC(baseIdx+i) := pcMem.io.rdata(pcMemIdx).startAddr\n\
      256:   }\n257: \n258:   for ((pcMemIdx, i) <- pcMemRdIndexes(\"hybrid\").zipWithIndex)
      {\n259:     // load read pcMem (s0) -> get rdata (s1) -> reg next in Memblock
      (s2) -> reg next in Memblock (s3) -> consumed by pf (s3)\n260:     pcMem.io.ren.get(pcMemIdx)
      := io.memHyPcRead(i).valid\n261:     pcMem.io.raddr(pcMemIdx) := io.memHyPcRead(i).ptr.value\n\
      262:     io.memHyPcRead(i).data := pcMem.io.rdata(pcMemIdx).startAddr + (RegEnable(io.memHyPcRead(i).offset,
      io.memHyPcRead(i).valid) << instOffsetBits)\n263:   }\n264: \n265:   if (EnableStorePrefetchSMS)
      {\n266:     for ((pcMemIdx, i) <- pcMemRdIndexes(\"store\").zipWithIndex) {\n\
      267:       pcMem.io.ren.get(pcMemIdx) := io.memStPcRead(i).valid\n268:     \
      \  pcMem.io.raddr(pcMemIdx) := io.memStPcRead(i).ptr.value\n269:       io.memStPcRead(i).data
      := pcMem.io.rdata(pcMemIdx).startAddr + (RegEnable(io.memStPcRead(i).offset,
      io.memStPcRead(i).valid) << instOffsetBits)\n270:     }\n271:   } else {\n272:\
      \     io.memStPcRead.foreach(_.data := 0.U)\n273:   }\n274: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 276-297
    context: "276:    * trace begin\n277:    */\n278:   val trace = Module(new Trace)\n\
      279:   trace.io.in.fromEncoder.stall  := io.traceCoreInterface.fromEncoder.stall\n\
      280:   trace.io.in.fromEncoder.enable := io.traceCoreInterface.fromEncoder.enable\n\
      281:   trace.io.in.fromRob            := rob.io.trace.traceCommitInfo\n282:\
      \   rob.io.trace.blockCommit       := trace.io.out.blockRobCommit\n283:   val
      tracePcStart = Wire(Vec(TraceGroupNum, UInt(IaddrWidth.W)))\n284:   for ((pcMemIdx,
      i) <- pcMemRdIndexes(\"trace\").zipWithIndex) {\n285:     val traceValid = trace.toPcMem.blocks(i).valid\n\
      286:     pcMem.io.ren.get(pcMemIdx) := traceValid\n287:     pcMem.io.raddr(pcMemIdx)
      := trace.toPcMem.blocks(i).bits.ftqIdx.get.value\n288:     tracePcStart(i) :=
      pcMem.io.rdata(pcMemIdx).startAddr\n289:   }\n290: \n291:   // Trap/Xret only
      occur in block(0).\n292:   val tracePriv = Mux(Itype.isTrapOrXret(trace.toEncoder.blocks(0).bits.tracePipe.itype),\n\
      293:     io.fromCSR.traceCSR.lastPriv,\n294:     io.fromCSR.traceCSR.currentPriv\n\
      295:   )\n296:   io.traceCoreInterface.toEncoder.trap.cause := io.fromCSR.traceCSR.cause.asUInt\n\
      297:   io.traceCoreInterface.toEncoder.trap.tval  := io.fromCSR.traceCSR.tval.asUInt"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 298-308
    context: "298:   io.traceCoreInterface.toEncoder.priv       := tracePriv\n299:\
      \   (0 until TraceGroupNum).foreach(i => {\n300:     io.traceCoreInterface.toEncoder.groups(i).valid
      := trace.io.out.toEncoder.blocks(i).valid\n301:     io.traceCoreInterface.toEncoder.groups(i).bits.iaddr
      := tracePcStart(i)\n302:     io.traceCoreInterface.toEncoder.groups(i).bits.ftqOffset.foreach(_
      := trace.io.out.toEncoder.blocks(i).bits.ftqOffset.getOrElse(0.U))\n303:   \
      \  io.traceCoreInterface.toEncoder.groups(i).bits.itype := trace.io.out.toEncoder.blocks(i).bits.tracePipe.itype\n\
      304:     io.traceCoreInterface.toEncoder.groups(i).bits.iretire := trace.io.out.toEncoder.blocks(i).bits.tracePipe.iretire\n\
      305:     io.traceCoreInterface.toEncoder.groups(i).bits.ilastsize := trace.io.out.toEncoder.blocks(i).bits.tracePipe.ilastsize\n\
      306:   })\n307:   /**\n308:    * trace end"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 317-327
    context: "317:   redirectGen.io.oldestExuOutPredecode.valid := GatedValidRegNext(oldestExuPredecode.valid)\n\
      318:   redirectGen.io.oldestExuOutPredecode := RegEnable(oldestExuPredecode,
      oldestExuPredecode.valid)\n319:   redirectGen.io.loadReplay <> loadReplay\n\
      320:   val loadRedirectOffset = Mux(memViolation.bits.flushItself(), 0.U, Mux(memViolation.bits.isRVC,
      2.U, 4.U))\n321:   val loadRedirectPcFtqOffset = RegEnable((memViolation.bits.ftqOffset
      << instOffsetBits).asUInt +& loadRedirectOffset, memViolation.valid)\n322: \
      \  val loadRedirectPcRead = pcMem.io.rdata(pcMemRdIndexes(\"redirect\").head).startAddr
      + loadRedirectPcFtqOffset\n323: \n324:   redirectGen.io.loadReplay.bits.cfiUpdate.pc
      := loadRedirectPcRead\n325:   val load_target = loadRedirectPcRead\n326:   redirectGen.io.loadReplay.bits.cfiUpdate.target
      := load_target\n327: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 331-349
    context: "331:   val s6_flushFromRobValid = GatedValidRegNext(s5_flushFromRobValidAhead)\n\
      332:   val frontendFlushBits = RegEnable(s1_robFlushRedirect.bits, s1_robFlushRedirect.valid)
      // ??\n333:   // When ROB commits an instruction with a flush, we notify the
      frontend of the flush without the commit.\n334:   // Flushes to frontend may
      be delayed by some cycles and commit before flush causes errors.\n335:   //
      Thus, we make all flush reasons to behave the same as exceptions for frontend.\n\
      336:   for (i <- 0 until CommitWidth) {\n337:     // why flushOut: instructions
      with flushPipe are not commited to frontend\n338:     // If we commit them to
      frontend, it will cause flush after commit, which is not acceptable by frontend.\n\
      339:     val s1_isCommit = rob.io.commits.commitValid(i) && rob.io.commits.isCommit
      && !s0_robFlushRedirect.valid\n340:     io.frontend.toFtq.rob_commits(i).valid
      := GatedValidRegNext(s1_isCommit)\n341:     io.frontend.toFtq.rob_commits(i).bits
      := RegEnable(rob.io.commits.info(i), s1_isCommit)\n342:   }\n343:   io.frontend.toFtq.redirect.valid
      := s6_flushFromRobValid || s3_redirectGen.valid\n344:   io.frontend.toFtq.redirect.bits
      := Mux(s6_flushFromRobValid, frontendFlushBits, s3_redirectGen.bits)\n345: \
      \  io.frontend.toFtq.ftqIdxSelOH.valid := s6_flushFromRobValid || redirectGen.io.stage2Redirect.valid\n\
      346:   io.frontend.toFtq.ftqIdxSelOH.bits := Cat(s6_flushFromRobValid, redirectGen.io.stage2oldestOH
      & Fill(NumRedirect + 1, !s6_flushFromRobValid))\n347: \n348:   //jmp/brh, sel
      oldest first, only use one read port\n349:   io.frontend.toFtq.ftqIdxAhead(0).valid
      := RegNext(oldestExuRedirect.valid) && !s1_robFlushRedirect.valid && !s5_flushFromRobValidAhead"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 373-387
    context: "373:   val flushTarget = Mux(s5_csrIsTrap, s5_trapTargetFromCsr.pc,
      s2_robFlushPc)\n374:   val s5_trapTargetIAF = Mux(s5_csrIsTrap, s5_trapTargetFromCsr.raiseIAF,
      false.B)\n375:   val s5_trapTargetIPF = Mux(s5_csrIsTrap, s5_trapTargetFromCsr.raiseIPF,
      false.B)\n376:   val s5_trapTargetIGPF = Mux(s5_csrIsTrap, s5_trapTargetFromCsr.raiseIGPF,
      false.B)\n377:   when (s6_flushFromRobValid) {\n378:     io.frontend.toFtq.redirect.bits.level
      := RedirectLevel.flush\n379:     io.frontend.toFtq.redirect.bits.cfiUpdate.target
      := RegEnable(flushTarget, s5_flushFromRobValidAhead)\n380:     io.frontend.toFtq.redirect.bits.cfiUpdate.backendIAF
      := RegEnable(s5_trapTargetIAF, s5_flushFromRobValidAhead)\n381:     io.frontend.toFtq.redirect.bits.cfiUpdate.backendIPF
      := RegEnable(s5_trapTargetIPF, s5_flushFromRobValidAhead)\n382:     io.frontend.toFtq.redirect.bits.cfiUpdate.backendIGPF
      := RegEnable(s5_trapTargetIGPF, s5_flushFromRobValidAhead)\n383:   }\n384: \n\
      385:   for (i <- 0 until DecodeWidth) {\n386:     gpaMem.io.fromIFU := io.frontend.fromIfu\n\
      387:     gpaMem.io.exceptionReadAddr.valid := rob.io.readGPAMemAddr.valid"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 391-404
    context: "391: \n392:   // vtype commit\n393:   decode.io.fromCSR := io.fromCSR.toDecode\n\
      394:   decode.io.fromRob.isResumeVType := rob.io.toDecode.isResumeVType\n395:\
      \   decode.io.fromRob.walkToArchVType := rob.io.toDecode.walkToArchVType\n396:\
      \   decode.io.fromRob.commitVType := rob.io.toDecode.commitVType\n397:   decode.io.fromRob.walkVType
      := rob.io.toDecode.walkVType\n398: \n399:   decode.io.redirect := s1_s3_redirect.valid
      || s2_s4_pendingRedirectValid\n400: \n401:   // add decode Buf for in.ready
      better timing\n402:   /**\n403:    * Decode buffer: when decode.io.in cannot
      accept all insts, use this buffer to temporarily store insts that cannot\n404:\
      \    * be sent to DecodeStage."
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 459-469
    context: "459:    *   decodeBufValid(0) is false, decodeFromFrontendNotAccept.drop(i)
      has some true signals\n460:    *     decodeFromFrontend(i+decodeFromFrontendAcceptNum)\n\
      461:    */\n462:   for (i <- 0 until DecodeWidth) {\n463:     // decodeBufValid
      update\n464:     when(decode.io.redirect || decodeBufValid(0) && decodeBufValid(i)
      && decode.io.in(i).ready && !VecInit(decodeBufNotAccept.drop(i)).asUInt.orR)
      {\n465:       decodeBufValid(i) := false.B\n466:     }.elsewhen(decodeBufValid(i)
      && VecInit(decodeBufNotAccept.drop(i)).asUInt.orR) {\n467:       decodeBufValid(i)
      := Mux(decodeBufAcceptNum > DecodeWidth.U - 1.U - i.U, false.B, decodeBufValid(i.U
      + decodeBufAcceptNum))\n468:     }.elsewhen(!decodeBufValid(0) && VecInit(decodeFromFrontendNotAccept.drop(i)).asUInt.orR)
      {\n469:       decodeBufValid(i) := Mux(decodeFromFrontendAcceptNum > DecodeWidth.U
      - 1.U - i.U, false.B, decodeFromFrontend(i.U + decodeFromFrontendAcceptNum).valid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 493-503
    context: "493:    *     decodeBufValid(i) is true : decodeBufBits(i)         \
      \    | from decode buffer\n494:    *                         false : decodeConnectFromFrontend(i)
      | from frontend\n495:    */\n496:   decode.io.in.zipWithIndex.foreach { case
      (decodeIn, i) =>\n497:     decodeIn.valid := Mux(decodeBufValid(0), decodeBufValid(i),
      decodeFromFrontend(i).valid)\n498:     decodeFromFrontend(i).ready := decodeFromFrontend(0).valid
      && !decodeBufValid(0) && decodeFromFrontend(i).valid && !decode.io.redirect\n\
      499:     decodeIn.bits := Mux(decodeBufValid(i), decodeBufBits(i), decodeConnectFromFrontend(i))\n\
      500:   }\n501:   /** no valid instr in decode buffer && no valid instr from
      frontend --> can accept new instr from frontend */\n502:   io.frontend.canAccept
      := !decodeBufValid(0) || !decodeFromFrontend(0).valid\n503:   decode.io.csrCtrl
      := RegNext(io.csrCtrl)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 517-529
    context: "517:   val genSnapshot = Cat(rename.io.out.map(out => out.fire && out.bits.snapshot)).orR\n\
      518:   val snpt = Module(new SnapshotGenerator(0.U.asTypeOf(new CFIRobIdx)))\n\
      519:   snpt.io.enq := genSnapshot\n520:   snpt.io.enqData.robIdx := rename.io.out.map(_.bits.robIdx)\n\
      521:   snpt.io.enqData.isCFI := rename.io.out.map(_.bits.snapshot)\n522:   snpt.io.deq
      := snpt.io.valids(snpt.io.deqPtr.value) && rob.io.commits.isCommit &&\n523:\
      \     Cat(rob.io.commits.commitValid.zip(rob.io.commits.robIdx).map(x => x._1
      && x._2 === snpt.io.snapshots(snpt.io.deqPtr.value).robIdx.head)).orR\n524:\
      \   snpt.io.redirect := s1_s3_redirect.valid\n525:   val flushVec = VecInit(snpt.io.snapshots.map
      { snapshot =>\n526:     val notCFIMask = snapshot.isCFI.map(~_)\n527:     val
      shouldFlush = snapshot.robIdx.map(robIdx => robIdx >= s1_s3_redirect.bits.robIdx
      || robIdx.value === s1_s3_redirect.bits.robIdx.value)\n528:     val shouldFlushMask
      = (1 to RenameWidth).map(shouldFlush take _ reduce (_ || _))\n529:     s1_s3_redirect.valid
      && Cat(shouldFlushMask.zip(notCFIMask).map(x => x._1 | x._2)).andR"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 597-607
    context: "597:     val cond3 = !sameFtqPtr && ftqOffset1 === 0.U\n598:     val
      cond4 = !sameFtqPtr && ftqOffset1 === 1.U\n599:     when (fusionDecoder.io.out(i).valid)
      {\n600:       fusionDecoder.io.out(i).bits.update(rename.io.in(i).bits)\n601:\
      \       fusionDecoder.io.out(i).bits.update(dispatch.io.renameIn(i).bits)\n\
      602:       rename.io.in(i).bits.commitType := Mux(cond1, 4.U, Mux(cond2, 5.U,
      Mux(cond3, 6.U, 7.U)))\n603:     }\n604:     XSError(fusionDecoder.io.out(i).valid
      && !cond1 && !cond2 && !cond3 && !cond4, p\"new condition $sameFtqPtr $ftqOffset0
      $ftqOffset1\\n\")\n605:   }\n606: \n607:   // memory dependency predict"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 616-626
    context: "616:       rename.io.in(i).bits.foldpc\n617:     )\n618:   }\n619: \n\
      620:   // currently, we only update mdp info when isReplay\n621:   memCtrl.io.redirect
      := s1_s3_redirect\n622:   memCtrl.io.csrCtrl := io.csrCtrl                 \
      \         // RegNext in memCtrl\n623:   memCtrl.io.stIn := io.fromMem.stIn \
      \                       // RegNext in memCtrl\n624:   memCtrl.io.memPredUpdate
      := redirectGen.io.memPredUpdate  // RegNext in memCtrl\n625:   memCtrl.io.mdpFoldPcVecVld
      := mdpFlodPcVecVld\n626:   memCtrl.io.mdpFlodPcVec := mdpFlodPcVec"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 624-636
    context: "624:   memCtrl.io.memPredUpdate := redirectGen.io.memPredUpdate  //
      RegNext in memCtrl\n625:   memCtrl.io.mdpFoldPcVecVld := mdpFlodPcVecVld\n626:\
      \   memCtrl.io.mdpFlodPcVec := mdpFlodPcVec\n627:   memCtrl.io.dispatchLFSTio
      <> dispatch.io.lfst\n628: \n629:   rat.io.redirect := s1_s3_redirect.valid\n\
      630:   rat.io.rabCommits := rob.io.rabCommits\n631:   rat.io.diffCommits.foreach(_
      := rob.io.diffCommits.get)\n632:   rat.io.intRenamePorts := rename.io.intRenamePorts\n\
      633:   rat.io.fpRenamePorts := rename.io.fpRenamePorts\n634:   rat.io.vecRenamePorts
      := rename.io.vecRenamePorts\n635:   rat.io.v0RenamePorts := rename.io.v0RenamePorts\n\
      636:   rat.io.vlRenamePorts := rename.io.vlRenamePorts"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 633-644
    context: "633:   rat.io.fpRenamePorts := rename.io.fpRenamePorts\n634:   rat.io.vecRenamePorts
      := rename.io.vecRenamePorts\n635:   rat.io.v0RenamePorts := rename.io.v0RenamePorts\n\
      636:   rat.io.vlRenamePorts := rename.io.vlRenamePorts\n637: \n638:   rename.io.redirect
      := s1_s3_redirect\n639:   rename.io.rabCommits := rob.io.rabCommits\n640:  \
      \ rename.io.singleStep := GatedValidRegNext(io.csrCtrl.singlestep)\n641:   rename.io.waittable
      := (memCtrl.io.waitTable2Rename zip decode.io.out).map{ case(waittable2rename,
      decodeOut) =>\n642:     RegEnable(waittable2rename, decodeOut.fire)\n643:  \
      \ }\n644:   rename.io.ssit := memCtrl.io.ssit2Rename"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 682-692
    context: "682:   )\n683: \n684:   // pipeline between rename and dispatch\n685:\
      \   PipeGroupConnect(renameOut, dispatch.io.fromRename, s1_s3_redirect.valid,
      dispatch.io.toRenameAllFire, \"renamePipeDispatch\")\n686: \n687:   dispatch.io.redirect
      := s1_s3_redirect\n688:   val enqRob = Wire(chiselTypeOf(rob.io.enq))\n689:\
      \   enqRob.canAccept := rob.io.enq.canAccept\n690:   enqRob.canAcceptForDispatch
      := rob.io.enq.canAcceptForDispatch\n691:   enqRob.isEmpty := rob.io.enq.isEmpty\n\
      692:   enqRob.resp := rob.io.enq.resp"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 690-700
    context: "690:   enqRob.canAcceptForDispatch := rob.io.enq.canAcceptForDispatch\n\
      691:   enqRob.isEmpty := rob.io.enq.isEmpty\n692:   enqRob.resp := rob.io.enq.resp\n\
      693:   enqRob.needAlloc := RegNext(dispatch.io.enqRob.needAlloc)\n694:   enqRob.req.zip(dispatch.io.enqRob.req).map
      { case (sink, source) =>\n695:     sink.valid := RegNext(source.valid && !rob.io.redirect.valid)\n\
      696:     sink.bits := RegEnable(source.bits, source.valid)\n697:   }\n698: \
      \  dispatch.io.enqRob.canAccept := enqRob.canAcceptForDispatch && !enqRob.req.map(x
      => x.valid && x.bits.blockBackward && enqRob.canAccept).reduce(_ || _)\n699:\
      \   dispatch.io.enqRob.canAcceptForDispatch := enqRob.canAcceptForDispatch\n\
      700:   dispatch.io.enqRob.isEmpty := enqRob.isEmpty && !enqRob.req.map(_.valid).reduce(_
      || _)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 703-714
    context: "703:   rob.io.enq.req := enqRob.req\n704:   dispatch.io.robHead := rob.io.debugRobHead\n\
      705:   dispatch.io.stallReason <> rename.io.stallReason.out\n706:   dispatch.io.lqCanAccept
      := io.lqCanAccept\n707:   dispatch.io.sqCanAccept := io.sqCanAccept\n708:  \
      \ dispatch.io.fromMem.lcommit := io.fromMemToDispatch.lcommit\n709:   dispatch.io.fromMem.scommit
      := io.fromMemToDispatch.scommit\n710:   dispatch.io.fromMem.lqDeqPtr := io.fromMemToDispatch.lqDeqPtr\n\
      711:   dispatch.io.fromMem.sqDeqPtr := io.fromMemToDispatch.sqDeqPtr\n712: \
      \  dispatch.io.fromMem.lqCancelCnt := io.fromMemToDispatch.lqCancelCnt\n713:\
      \   dispatch.io.fromMem.sqCancelCnt := io.fromMemToDispatch.sqCancelCnt\n714:\
      \   io.toMem.lsqEnqIO <> dispatch.io.toMem.lsqEnqIO"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 740-750
    context: "740:   io.toDataPath.flush := s2_s4_redirect\n741:   io.toExuBlock.flush
      := s2_s4_redirect\n742: \n743: \n744:   rob.io.hartId := io.fromTop.hartId\n\
      745:   rob.io.redirect := s1_s3_redirect\n746:   rob.io.writeback := delayedNotFlushedWriteBack\n\
      747:   rob.io.exuWriteback := delayedWriteBack\n748:   rob.io.writebackNums
      := VecInit(delayedNotFlushedWriteBackNums)\n749:   rob.io.writebackNeedFlush
      := delayedNotFlushedWriteBackNeedFlush\n750:   rob.io.readGPAMemData := gpaMem.io.exceptionReadData"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 748-758
    context: "748:   rob.io.writebackNums := VecInit(delayedNotFlushedWriteBackNums)\n\
      749:   rob.io.writebackNeedFlush := delayedNotFlushedWriteBackNeedFlush\n750:\
      \   rob.io.readGPAMemData := gpaMem.io.exceptionReadData\n751:   rob.io.fromVecExcpMod.busy
      := io.fromVecExcpMod.busy\n752: \n753:   io.redirect := s1_s3_redirect\n754:\
      \ \n755:   // rob to int block\n756:   io.robio.csr <> rob.io.csr\n757:   //
      When wfi is disabled, it will not block ROB commit.\n758:   rob.io.csr.wfiEvent
      := io.robio.csr.wfiEvent"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 774-784
    context: "774:   io.robio.lsq <> rob.io.lsq\n775: \n776:   io.diff_int_rat.foreach(_
      := rat.io.diff_int_rat.get)\n777:   io.diff_fp_rat .foreach(_ := rat.io.diff_fp_rat.get)\n\
      778:   io.diff_vec_rat.foreach(_ := rat.io.diff_vec_rat.get)\n779:   io.diff_v0_rat
      .foreach(_ := rat.io.diff_v0_rat.get)\n780:   io.diff_vl_rat .foreach(_ := rat.io.diff_vl_rat.get)\n\
      781: \n782:   rob.io.debug_ls := io.robio.debug_ls\n783:   rob.io.debugHeadLsIssue
      := io.robio.robHeadLsIssue\n784:   rob.io.lsTopdownInfo := io.robio.lsTopdownInfo"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 789-799
    context: "789:   io.robio.robDeqPtr := rob.io.robDeqPtr\n790: \n791:   io.robio.storeDebugInfo
      <> rob.io.storeDebugInfo\n792: \n793:   // rob to backend\n794:   io.robio.commitVType
      := rob.io.toDecode.commitVType\n795:   // exu block to decode\n796:   decode.io.vsetvlVType
      := io.toDecode.vsetvlVType\n797:   // backend to decode\n798:   decode.io.vstart
      := io.toDecode.vstart\n799:   // backend to rob"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 805-828
    context: "805:   io.toVecExcpMod.excpInfo       := rob.io.toVecExcpMod.excpInfo\n\
      806:   // T  : rat receive rabCommit\n807:   // T+1: rat return oldPdest\n808:\
      \   io.toVecExcpMod.ratOldPest match {\n809:     case fromRat =>\n810:     \
      \  (0 until RabCommitWidth).foreach { idx =>\n811:         val v0Valid = RegNext(\n\
      812:           rat.io.rabCommits.isCommit &&\n813:           rat.io.rabCommits.isWalk
      &&\n814:           rat.io.rabCommits.commitValid(idx) &&\n815:           rat.io.rabCommits.info(idx).v0Wen\n\
      816:         )\n817:         fromRat.v0OldVdPdest(idx).valid := RegNext(v0Valid)\n\
      818:         fromRat.v0OldVdPdest(idx).bits := RegEnable(rat.io.v0_old_pdest(idx),
      v0Valid)\n819:         val vecValid = RegNext(\n820:           rat.io.rabCommits.isCommit
      &&\n821:           rat.io.rabCommits.isWalk &&\n822:           rat.io.rabCommits.commitValid(idx)
      &&\n823:           rat.io.rabCommits.info(idx).vecWen\n824:         )\n825:\
      \         fromRat.vecOldVdPdest(idx).valid := RegNext(vecValid)\n826:      \
      \   fromRat.vecOldVdPdest(idx).bits := RegEnable(rat.io.vec_old_pdest(idx),
      vecValid)\n827:       }\n828:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 856-866
    context: "856:     val toDecode = Input(new CSRToDecode)\n857:     val traceCSR
      = Input(new TraceCSR)\n858:     val instrAddrTransType = Input(new AddrTransType)\n\
      859:   }\n860:   val toIssueBlock = new Bundle {\n861:     val flush = ValidIO(new
      Redirect)\n862:     val intUopsNum = backendParams.intSchdParams.get.issueBlockParams.map(_.numEnq).sum\n\
      863:     val fpUopsNum = backendParams.fpSchdParams.get.issueBlockParams.map(_.numEnq).sum\n\
      864:     val vfUopsNum = backendParams.vfSchdParams.get.issueBlockParams.map(_.numEnq).sum\n\
      865:     val memUopsNum = backendParams.memSchdParams.get.issueBlockParams.filter(x
      => x.StdCnt == 0).map(_.numEnq).sum\n866:     val intUops = Vec(intUopsNum,
      DecoupledIO(new DynInst))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 867-878
    context: "867:     val fpUops = Vec(fpUopsNum, DecoupledIO(new DynInst))\n868:\
      \     val vfUops = Vec(vfUopsNum, DecoupledIO(new DynInst))\n869:     val memUops
      = Vec(memUopsNum, DecoupledIO(new DynInst))\n870:   }\n871:   val fromMemToDispatch
      = new Bundle {\n872:     val lcommit = Input(UInt(log2Up(CommitWidth + 1).W))\n\
      873:     val scommit = Input(UInt(log2Ceil(EnsbufferWidth + 1).W)) // connected
      to `memBlock.io.sqDeq` instead of ROB\n874:     val lqDeqPtr = Input(new LqPtr)\n\
      875:     val sqDeqPtr = Input(new SqPtr)\n876:     // from lsq\n877:     val
      lqCancelCnt = Input(UInt(log2Up(VirtualLoadQueueSize + 1).W))\n878:     val
      sqCancelCnt = Input(UInt(log2Up(StoreQueueSize + 1).W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 905-919
    context: "905:       val vlFromVfIsZero   = Input(Bool())\n906:       val vlFromVfIsVlmax\
      \  = Input(Bool())\n907:     }\n908:   }\n909:   val toDataPath = new Bundle
      {\n910:     val flush = ValidIO(new Redirect)\n911:     val pcToDataPathIO =
      new PcToDataPathIO(params)\n912:   }\n913:   val toExuBlock = new Bundle {\n\
      914:     val flush = ValidIO(new Redirect)\n915:   }\n916:   val toCSR = new
      Bundle {\n917:     val trapInstInfo = Output(ValidIO(new TrapInstInfo))\n918:\
      \   }\n919:   val fromWB = new Bundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 917-930
    context: "917:     val trapInstInfo = Output(ValidIO(new TrapInstInfo))\n918:\
      \   }\n919:   val fromWB = new Bundle {\n920:     val wbData = Flipped(MixedVec(params.genWrite2CtrlBundles))\n\
      921:   }\n922:   val redirect = ValidIO(new Redirect)\n923:   val fromMem =
      new Bundle {\n924:     val stIn = Vec(params.StaExuCnt, Flipped(ValidIO(new
      DynInst))) // use storeSetHit, ssid, robIdx\n925:     val violation = Flipped(ValidIO(new
      Redirect))\n926:   }\n927:   val memStPcRead = Vec(params.StaCnt, Flipped(new
      FtqRead(UInt(VAddrBits.W))))\n928:   val memHyPcRead = Vec(params.HyuCnt, Flipped(new
      FtqRead(UInt(VAddrBits.W))))\n929: \n930:   val csrCtrl = Input(new CustomCSRCtrlIO)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 934-944
    context: "934:     val lsq = new RobLsqIO\n935:     val lsTopdownInfo = Vec(params.LduCnt
      + params.HyuCnt, Input(new LsTopdownInfo))\n936:     val debug_ls = Input(new
      DebugLSIO())\n937:     val robHeadLsIssue = Input(Bool())\n938:     val robDeqPtr
      = Output(new RobPtr)\n939:     val commitVType = new Bundle {\n940:       val
      vtype = Output(ValidIO(VType()))\n941:       val hasVsetvl = Output(Bool())\n\
      942:     }\n943:     // store event difftest information\n944:     val storeDebugInfo
      = Vec(EnsbufferWidth, new Bundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 955-965
    context: "955:   val fromVecExcpMod = Input(new Bundle {\n956:     val busy =
      Bool()\n957:   })\n958: \n959:   val toVecExcpMod = Output(new Bundle {\n960:\
      \     val logicPhyRegMap = Vec(RabCommitWidth, ValidIO(new RegWriteFromRab))\n\
      961:     val excpInfo = ValidIO(new VecExcpInfo)\n962:     val ratOldPest =
      new RatToVecExcpMod\n963:   })\n964: \n965:   val traceCoreInterface = new TraceCoreInterface(hasOffset
      = true)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/CtrlBlock.scala
    lines: 973-983
    context: "973:     }\n974:   })\n975:   val diff_int_rat = if (params.basicDebugEn)
      Some(Vec(32, Output(UInt(PhyRegIdxWidth.W)))) else None\n976:   val diff_fp_rat\
      \  = if (params.basicDebugEn) Some(Vec(32, Output(UInt(PhyRegIdxWidth.W))))
      else None\n977:   val diff_vec_rat = if (params.basicDebugEn) Some(Vec(31, Output(UInt(PhyRegIdxWidth.W))))
      else None\n978:   val diff_v0_rat  = if (params.basicDebugEn) Some(Vec(1, Output(UInt(PhyRegIdxWidth.W))))
      else None\n979:   val diff_vl_rat  = if (params.basicDebugEn) Some(Vec(1, Output(UInt(PhyRegIdxWidth.W))))
      else None\n980: \n981:   val sqCanAccept = Input(Bool())\n982:   val lqCanAccept
      = Input(Bool())\n983: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 7-17
    context: "7: import utility.XSError\n8: import xiangshan.backend.BackendParams\n\
      9: import xiangshan.backend.Bundles.{ExuOutput, WriteBackBundle}\n10: import
      xiangshan.backend.datapath.DataConfig._\n11: import xiangshan.backend.regfile.RfWritePortWithConfig\n\
      12: import xiangshan.{Redirect, XSBundle, XSModule}\n13: import xiangshan.SrcType.v0\n\
      14: import xiangshan.backend.fu.vector.Bundles.Vstart\n15: \n16: class WbArbiterDispatcherIO[T
      <: Data](private val gen: T, n: Int) extends Bundle {\n17:   val in = Flipped(DecoupledIO(gen))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 36-50
    context: "36: \n37:   io.in.ready := Cat(io.out.zip(acceptVec).map{ case(out,
      canAccept) => out.ready && canAccept}).orR || acceptCond(io.in.bits)._2\n38:
      }\n39: \n40: class WbArbiterIO()(implicit p: Parameters, params: WbArbiterParams)
      extends XSBundle {\n41:   val flush = Flipped(ValidIO(new Redirect))\n42:  \
      \ val in: MixedVec[DecoupledIO[WriteBackBundle]] = Flipped(params.genInput)\n\
      43:   val out: MixedVec[ValidIO[WriteBackBundle]] = params.genOutput\n44: \n\
      45:   def inGroup: Map[Int, Seq[DecoupledIO[WriteBackBundle]]] = in.groupBy(_.bits.params.port).map(x
      => (x._1, x._2.sortBy(_.bits.params.priority).toSeq))\n46: }\n47: \n48: class
      RealWBCollideChecker(params: WbArbiterParams)(implicit p: Parameters) extends
      XSModule {\n49:   val io = IO(new WbArbiterIO()(p, params))\n50: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbArbiter.scala
    lines: 81-91
    context: "81:     (params.wbCfgs.indices zip params.wbCfgs.map(_.port)).toMap\n\
      82:   }\n83: }\n84: \n85: class WbDataPathIO()(implicit p: Parameters, params:
      BackendParams) extends XSBundle {\n86:   val flush = Flipped(ValidIO(new Redirect()))\n\
      87: \n88:   val fromTop = new Bundle {\n89:     val hartId = Input(UInt(8.W))\n\
      90:   }\n91: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFWBConflictChecker.scala
    lines: 139-149
    context: "139:   protected val pregWidth = pregParams.addrWidth\n140: \n141: \
      \  protected val inGroup = io.in\n142:     .flatten\n143:     .groupBy(_.bits.wbCfg.get.port)\n\
      144:     .map(x => (x._1, x._2.sortBy(_.bits.wbCfg.get.priority)))\n145: \n\
      146:   protected val arbiters: Seq[Option[WBArbiter[RFWBCollideCheckerBundle]]]
      = portRange.map { portIdx =>\n147:     OptionWrapper(\n148:       inGroup.isDefinedAt(portIdx),\n\
      149:       Module(new WBArbiter("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RdConfig.scala
    lines: 3-34
    context: "3: import xiangshan.backend.datapath.DataConfig._\n4: \n5: object RdConfig
      {\n6:   sealed abstract class RdConfig() {\n7:     val port: Int\n8:     val
      priority: Int\n9: \n10:     def getDataConfig: DataConfig\n11:   }\n12: \n13:\
      \   case class IntRD(port: Int = -1, priority: Int = Int.MaxValue) extends RdConfig()
      {\n14:     override def getDataConfig = IntData()\n15:   }\n16: \n17:   case
      class FpRD(port: Int = -1, priority: Int = Int.MaxValue) extends RdConfig()
      {\n18:     override def getDataConfig = FpData()\n19:   }\n20: \n21:   case
      class VfRD(port: Int = -1, priority: Int = Int.MaxValue) extends RdConfig()
      {\n22:     override def getDataConfig = VecData()\n23:   }\n24: \n25:   case
      class V0RD(port: Int = -1, priority: Int = Int.MaxValue) extends RdConfig()
      {\n26:     override def getDataConfig = V0Data()\n27:   }\n28: \n29:   case
      class VlRD(port: Int = -1, priority: Int = Int.MaxValue) extends RdConfig()
      {\n30:     override def getDataConfig = VlData()\n31:   }\n32: \n33:   case
      class NoRD() extends RdConfig() {\n34:     override val port: Int = -1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RdConfig.scala
    lines: 31-41
    context: "31:   }\n32: \n33:   case class NoRD() extends RdConfig() {\n34:   \
      \  override val port: Int = -1\n35: \n36:     override val priority: Int = Int.MaxValue\n\
      37: \n38:     override def getDataConfig: DataConfig = NoData()\n39:   }\n40:
      }\n41: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/VldMergeUnit.scala
    lines: 48-56
    context: "48:   io.writebackAfterMerge.bits.v0Wen.foreach(_ := wbReg.bits.v0Wen.get)\n\
      49:   io.writebackAfterMerge.bits.data := VecInit(Seq.fill(params.wbPathNum)(vdAfterMerge))\n\
      50: }\n51: \n52: class VldMergeUnitIO(param: ExeUnitParams)(implicit p: Parameters)
      extends XSBundle {\n53:   val flush = Flipped(ValidIO(new Redirect))\n54:  \
      \ val writeback = Flipped(DecoupledIO(new ExuOutput(param)))\n55:   val writebackAfterMerge
      = DecoupledIO(new ExuOutput(param))\n56: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbConfig.scala
    lines: 32-42
    context: "32:   }\n33: \n34:   sealed abstract class ExuWB extends WbConfig\n\
      35: \n36:   sealed abstract class PregWB extends ExuWB {\n37:     val priority:
      Int\n38: \n39:     def numPreg(backendParams: BackendParams): Int\n40: \n41:\
      \     def pregIdxWidth(backendParams: BackendParams) = log2Up(numPreg(backendParams))\n\
      42:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbConfig.scala
    lines: 41-51
    context: "41:     def pregIdxWidth(backendParams: BackendParams) = log2Up(numPreg(backendParams))\n\
      42:   }\n43: \n44:   case class IntWB(\n45:     port    : Int = -1,\n46:   \
      \  priority: Int = Int.MaxValue,\n47:   ) extends PregWB {\n48: \n49:     def
      dataCfg: DataConfig = IntData()\n50: \n51:     def numPreg(backendParams: BackendParams):
      Int = backendParams.getPregParams(IntData()).numEntries"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbConfig.scala
    lines: 51-61
    context: "51:     def numPreg(backendParams: BackendParams): Int = backendParams.getPregParams(IntData()).numEntries\n\
      52:   }\n53: \n54:   case class FpWB(\n55:     port: Int = -1,\n56:     priority:
      Int = Int.MaxValue,\n57:   ) extends PregWB {\n58: \n59:     def dataCfg: DataConfig
      = FpData()\n60: \n61:     def numPreg(backendParams: BackendParams): Int = backendParams.getPregParams(FpData()).numEntries"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbConfig.scala
    lines: 61-71
    context: "61:     def numPreg(backendParams: BackendParams): Int = backendParams.getPregParams(FpData()).numEntries\n\
      62:   }\n63: \n64:   case class VfWB(\n65:     port    : Int = -1,\n66:    \
      \ priority: Int = Int.MaxValue,\n67:   ) extends PregWB {\n68: \n69:     def
      dataCfg: DataConfig = VecData()\n70: \n71:     def numPreg(backendParams: BackendParams):
      Int = backendParams.getPregParams(VecData()).numEntries"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbConfig.scala
    lines: 71-81
    context: "71:     def numPreg(backendParams: BackendParams): Int = backendParams.getPregParams(VecData()).numEntries\n\
      72:   }\n73: \n74:   case class V0WB(\n75:     port    : Int = -1,\n76:    \
      \ priority: Int = Int.MaxValue,\n77:   ) extends PregWB {\n78: \n79:     def
      dataCfg: DataConfig = V0Data()\n80: \n81:     def numPreg(backendParams: BackendParams):
      Int = backendParams.getPregParams(V0Data()).numEntries"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbConfig.scala
    lines: 81-91
    context: "81:     def numPreg(backendParams: BackendParams): Int = backendParams.getPregParams(V0Data()).numEntries\n\
      82:   }\n83: \n84:   case class VlWB(\n85:     port    : Int = -1,\n86:    \
      \ priority: Int = Int.MaxValue,\n87:   ) extends PregWB {\n88: \n89:     def
      dataCfg: DataConfig = VlData()\n90: \n91:     def numPreg(backendParams: BackendParams):
      Int = backendParams.getPregParams(VlData()).numEntries"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbConfig.scala
    lines: 91-101
    context: "91:     def numPreg(backendParams: BackendParams): Int = backendParams.getPregParams(VlData()).numEntries\n\
      92:   }\n93: \n94:   case class NoWB(\n95:     port    : Int = -1,\n96:    \
      \ priority: Int = Int.MaxValue,\n97:   ) extends PregWB {\n98: \n99:     override
      def dataCfg: DataConfig = NoData()\n100: \n101:     override def numPreg(backendParams:
      BackendParams): Int = 0"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbConfig.scala
    lines: 102-112
    context: "102:   }\n103: \n104:   case class CtrlWB(\n105:     port: Int = -1,\n\
      106:   ) extends WbConfig {\n107:     val priority: Int = Int.MaxValue\n108:\
      \     override def dataCfg: DataConfig = NoData()\n109:   }\n110: \n111:   case
      class FakeIntWB(\n112:     port    : Int = -1,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/WbConfig.scala
    lines: 108-118
    context: "108:     override def dataCfg: DataConfig = NoData()\n109:   }\n110:\
      \ \n111:   case class FakeIntWB(\n112:     port    : Int = -1,\n113:     priority:
      Int = Int.MaxValue,\n114:   ) extends PregWB {\n115: \n116:     def dataCfg:
      DataConfig = FakeIntData()\n117: \n118:     def numPreg(backendParams: BackendParams):
      Int = backendParams.getPregParams(FakeIntData()).numEntries"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/Og2ForVector.scala
    lines: 76-86
    context: "76: \n77: class Og2ForVectorIO(params: BackendParams)(implicit p: Parameters)
      extends XSBundle {\n78:   private val vfSchdParams = params.schdParams(VfScheduler())\n\
      79:   private val memSchdParams = params.schdParams(MemScheduler())\n80: \n\
      81:   val flush: ValidIO[Redirect]                                    = Flipped(ValidIO(new
      Redirect))\n82:   val ldCancel                                             \
      \       = Vec(backendParams.LduCnt + backendParams.HyuCnt, Flipped(new LoadCancelIO))\n\
      83: \n84:   val fromOg1VfArith: MixedVec[MixedVec[DecoupledIO[ExuInput]]]  \
      \ = Flipped(vfSchdParams.genExuInputBundle)\n85:   val fromOg1VecMem: MixedVec[MixedVec[DecoupledIO[ExuInput]]]\
      \    = Flipped(MixedVec(memSchdParams.issueBlockParams.filter(_.needOg2Resp).map(_.genExuInputDecoupledBundle)))\n\
      86:   val fromOg1ImmInfo: Vec[ImmInfo]                                = Input(Vec(params.allIssueParams.filter(_.needOg2Resp).flatMap(_.exuBlockParams).size,
      new ImmInfo))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 435-445
    context: "435: \n436:   vfDiffRead.foreach { case (addr, _) =>\n437:     addr
      := io.diffVecRat.get\n438:   }\n439:   v0DiffRead.foreach { case (addr, _) =>\n\
      440:     addr := io.diffV0Rat.get\n441:   }\n442:   vlDiffRead.foreach { case
      (addr, _) =>\n443:     addr := io.diffVlRat.get\n444:   }\n445: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 895-905
    context: "895:   private val vfSchdParams = params.schdParams(VfScheduler())\n\
      896:   private val memSchdParams = params.schdParams(MemScheduler())\n897: \
      \  // bundles\n898:   val hartId = Input(UInt(8.W))\n899: \n900:   val flush:
      ValidIO[Redirect] = Flipped(ValidIO(new Redirect))\n901: \n902:   val wbConfictRead
      = Input(MixedVec(params.allSchdParams.map(x => MixedVec(x.issueBlockParams.map(x
      => x.genWbConflictBundle())))))\n903: \n904:   val fromIntIQ: MixedVec[MixedVec[DecoupledIO[IssueQueueIssueBundle]]]
      =\n905:     Flipped(MixedVec(intSchdParams.issueBlockParams.map(_.genIssueDecoupledBundle)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/DataPath.scala
    lines: 967-977
    context: "967:   )\n968: \n969:   val diffIntRat = if (params.basicDebugEn) Some(Input(Vec(32,
      UInt(intSchdParams.pregIdxWidth.W)))) else None\n970:   val diffFpRat  = if
      (params.basicDebugEn) Some(Input(Vec(32, UInt(fpSchdParams.pregIdxWidth.W))))
      else None\n971:   val diffVecRat = if (params.basicDebugEn) Some(Input(Vec(31,
      UInt(vfSchdParams.pregIdxWidth.W)))) else None\n972:   val diffV0Rat  = if (params.basicDebugEn)
      Some(Input(Vec(1, UInt(log2Up(V0PhyRegs).W)))) else None\n973:   val diffVlRat\
      \  = if (params.basicDebugEn) Some(Input(Vec(1, UInt(log2Up(VlPhyRegs).W))))
      else None\n974:   val diffVl     = if (params.basicDebugEn) Some(Output(UInt(VlData().dataWidth.W)))
      else None\n975: \n976:   val topDownInfo = new TopDownInfo\n977: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/datapath/RFReadArbiter.scala
    lines: 49-59
    context: "49:   protected val pregWidth = pregParams.addrWidth\n50: \n51:   protected
      val inGroup: Map[Int, Seq[DecoupledIO[RFArbiterBundle]]] = io.in\n52:     .flatten.flatten\n\
      53:     .groupBy(_.bits.rdCfg.get.port)\n54:     .map(x => (x._1, x._2.sortBy(_.bits.rdCfg.get.priority).toSeq))\n\
      55:   protected val arbiters: Seq[Option[WBArbiter[RFArbiterBundle]]] = portRange.map
      { portIdx =>\n56:     Option.when(\n57:       inGroup.isDefinedAt(portIdx))(\n\
      58:       Module(new WBArbiter(\n59:         new RFArbiterBundle(pregWidth),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 126-137
    context: "126:       val vlFromVfIsZero   = Input(Bool())\n127:       val vlFromVfIsVlmax\
      \  = Input(Bool())\n128:     }\n129:     // from MemBlock\n130:     val fromMem
      = new Bundle {\n131:       val lcommit = Input(UInt(log2Up(CommitWidth + 1).W))\n\
      132:       val scommit = Input(UInt(log2Ceil(EnsbufferWidth + 1).W)) // connected
      to `memBlock.io.sqDeq` instead of ROB\n133:       val lqDeqPtr = Input(new LqPtr)\n\
      134:       val sqDeqPtr = Input(new SqPtr)\n135:       // from lsq\n136:   \
      \    val lqCancelCnt = Input(UInt(log2Up(VirtualLoadQueueSize + 1).W))\n137:\
      \       val sqCancelCnt = Input(UInt(log2Up(StoreQueueSize + 1).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 139-149
    context: "139:     //toMem\n140:     val toMem = new Bundle {\n141:       val
      lsqEnqIO = Flipped(new LsqEnqIO)\n142:     }\n143:     // redirect\n144:   \
      \  val redirect = Flipped(ValidIO(new Redirect))\n145:     // singleStep\n146:\
      \     val singleStep = Input(Bool())\n147:     // lfst\n148:     val lfst =
      new DispatchLFSTIO\n149: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 347-357
    context: "347:   }\n348: \n349:   when(singleStepState === s_updateRobidx) {\n\
      350:     robidxCanCommitStepping := robidxStepHold\n351:   }.elsewhen(singleStepState
      === s_holdRobidx) {\n352:     when(io.redirect.valid){\n353:       robidxCanCommitStepping.flag
      := !robidxStepReg.flag\n354:     }.otherwise {\n355:       robidxCanCommitStepping
      := robidxStepReg\n356:     }\n357:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 513-525
    context: "513: \n514:   val lsqEnqCtrl = Module(new LsqEnqCtrl)\n515: \n516: \
      \  // TODO: check lsqEnqCtrl redirect logic\n517:   // here is RegNext because
      dispatch2iq use s2_s4_redirect, newDispatch use s1_s3_redirect\n518:   lsqEnqCtrl.io.redirect
      := RegNext(io.redirect)\n519:   lsqEnqCtrl.io.lcommit := io.fromMem.lcommit\n\
      520:   lsqEnqCtrl.io.scommit := io.fromMem.scommit\n521:   lsqEnqCtrl.io.lqCancelCnt
      := io.fromMem.lqCancelCnt\n522:   lsqEnqCtrl.io.sqCancelCnt := io.fromMem.sqCancelCnt\n\
      523:   lsqEnqCtrl.io.enq.iqAccept := io.fromRename.map(x => !x.valid || x.fire)\n\
      524:   io.toMem.lsqEnqIO <> lsqEnqCtrl.io.enqLsq\n525: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 719-730
    context: "719:   val isAMO    = VecInit(fromRename.map(req => FuType.isAMO(req.bits.fuType)))\n\
      720:   val isBlockBackward  = VecInit(fromRename.map(x => x.valid && x.bits.blockBackward))\n\
      721:   val isWaitForward    = VecInit(fromRename.map(x => x.valid && x.bits.waitForward))\n\
      722: \n723:   val updatedUop = Wire(Vec(RenameWidth, new DynInst))\n724:   val
      checkpoint_id = RegInit(0.U(64.W))\n725:   checkpoint_id := checkpoint_id +
      PopCount((0 until RenameWidth).map(i =>\n726:     fromRename(i).fire\n727: \
      \  ))\n728: \n729: \n730:   for (i <- 0 until RenameWidth) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 754-768
    context: "754:       fromRename(i).fire &&\n755:         (TriggerAction.isDmode(updatedUop(i).trigger)
      || updatedUop(i).exceptionVec(breakPoint)), s\"Debug Mode: inst ${i} has frontend
      trigger exception\\n\")\n756:     XSDebug(fromRename(i).fire && updatedUop(i).singleStep,
      s\"Debug Mode: inst ${i} has single step exception\\n\")\n757:     if (env.EnableDifftest)
      {\n758:       // debug runahead hint\n759:       val debug_runahead_checkpoint_id
      = Wire(checkpoint_id.cloneType)\n760:       if(i == 0){\n761:         debug_runahead_checkpoint_id
      := checkpoint_id\n762:       } else {\n763:         debug_runahead_checkpoint_id
      := checkpoint_id + PopCount((0 until i).map(i =>\n764:           fromRename(i).fire\n\
      765:         ))\n766:       }\n767:     }\n768:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/dispatch/NewDispatch.scala
    lines: 875-885
    context: "875:   TopDownCounters.LoadL1Stall.id.U))))))))\n876: \n877:   val fusedVec
      = (0 until RenameWidth).map{ case i =>\n878:     if (i == 0) false.B\n879: \
      \    else (io.fromRename(i-1).fire && !io.fromRename(i).valid &&\n880:     \
      \     CommitType.isFused(io.fromRename(i-1).bits.commitType))\n881:   }\n882:\
      \ \n883:   val decodeReason = RegNextN(io.stallReason.reason, 2)\n884:   val
      renameReason = RegNext(io.stallReason.reason)\n885: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 22-32
    context: "22: import chisel3.util._\n23: import freechips.rocketchip.diplomacy.{LazyModule,
      LazyModuleImp}\n24: import utility._\n25: import xiangshan.backend.fu.{CSRFileIO,
      FenceIO, FuncUnitInput}\n26: import xiangshan.backend.Bundles.{ExuInput, ExuOutput,
      MemExuInput, MemExuOutput}\n27: import xiangshan.{AddrTransType, FPUCtrlSignals,
      HasXSParameter, Redirect, XSBundle, XSModule}\n28: import xiangshan.backend.datapath.WbConfig.{PregWB,
      _}\n29: import xiangshan.backend.fu.FuType\n30: import xiangshan.backend.fu.vector.Bundles.{VType,
      Vxrm}\n31: import xiangshan.backend.fu.fpu.Bundles.Frm\n32: import xiangshan.backend.fu.wrapper.{CSRInput,
      CSRToDecode}"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 30-40
    context: "30: import xiangshan.backend.fu.vector.Bundles.{VType, Vxrm}\n31: import
      xiangshan.backend.fu.fpu.Bundles.Frm\n32: import xiangshan.backend.fu.wrapper.{CSRInput,
      CSRToDecode}\n33: \n34: class ExeUnitIO(params: ExeUnitParams)(implicit p: Parameters)
      extends XSBundle {\n35:   val flush = Flipped(ValidIO(new Redirect()))\n36:\
      \   val in = Flipped(DecoupledIO(new ExuInput(params, hasCopySrc = true)))\n\
      37:   val out = DecoupledIO(new ExuOutput(params))\n38:   val csrin = Option.when(params.hasCSR)(new
      CSRInput)\n39:   val csrio = Option.when(params.hasCSR)(new CSRFileIO)\n40:\
      \   val csrToDecode = Option.when(params.hasCSR)(Output(new CSRToDecode))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 141-156
    context: "141:     }\n142:   }\n143: \n144:   exuParams.wbPortConfigs.map{\n145:\
      \     x => x match {\n146:       case IntWB(port, priority) => assert(priority
      >= 0 && priority <= 2,\n147:         s\"${exuParams.name}: WbPort must priority=0
      or priority=1\")\n148:       case FpWB(port, priority) => assert(priority >=
      0 && priority <= 2,\n149:         s\"${exuParams.name}: WbPort must priority=0
      or priority=1\")\n150:       case VfWB (port, priority) => assert(priority >=
      0 && priority <= 2,\n151:         s\"${exuParams.name}: WbPort must priority=0
      or priority=1\")\n152:       case _ =>\n153:     }\n154:   }\n155:   val intWbPort
      = exuParams.getIntWBPort\n156:   if (intWbPort.isDefined){"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 158-170
    context: "158:       .filter(_.getIntWBPort.get.port == intWbPort.get.port)\n\
      159:     val samePortOneCertainOneUncertain = sameIntPortExuParam.map(_.latencyCertain).contains(true)
      && sameIntPortExuParam.map(_.latencyCertain).contains(false)\n160:     if (samePortOneCertainOneUncertain)
      sameIntPortExuParam.map(samePort =>\n161:       samePort.wbPortConfigs.map(\n\
      162:         x => x match {\n163:           case IntWB(port, priority) => {\n\
      164:             if (!samePort.latencyCertain) assert(priority == sameIntPortExuParam.size
      - 1,\n165:               s\"${samePort.name}: IntWbPort $port must latencyCertain
      priority=0 or latencyUnCertain priority=max(${sameIntPortExuParam.size - 1})\"\
      )\n166:             // Certain latency can be handled by WbBusyTable, so there
      is no need to limit the exu's WB priority\n167:           }\n168:          \
      \ case _ =>\n169:         }\n170:       )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 176-188
    context: "176:       .filter(_.getFpWBPort.get.port == fpWbPort.get.port)\n177:\
      \     val samePortOneCertainOneUncertain = sameFpPortExuParam.map(_.latencyCertain).contains(true)
      && sameFpPortExuParam.map(_.latencyCertain).contains(false)\n178:     if (samePortOneCertainOneUncertain)
      sameFpPortExuParam.map(samePort =>\n179:       samePort.wbPortConfigs.map(\n\
      180:         x => x match {\n181:           case FpWB(port, priority) => {\n\
      182:             if (!samePort.latencyCertain) assert(priority == sameFpPortExuParam.size
      - 1,\n183:               s\"${samePort.name}: FpWbPort $port must latencyCertain
      priority=0 or latencyUnCertain priority=max(${sameFpPortExuParam.size - 1})\"\
      )\n184:             // Certain latency can be handled by WbBusyTable, so there
      is no need to limit the exu's WB priority\n185:           }\n186:          \
      \ case _ =>\n187:         }\n188:       )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 194-206
    context: "194:       .filter(_.getVfWBPort.get.port == vfWbPort.get.port)\n195:\
      \     val samePortOneCertainOneUncertain = sameVfPortExuParam.map(_.latencyCertain).contains(true)
      && sameVfPortExuParam.map(_.latencyCertain).contains(false)\n196:     if (samePortOneCertainOneUncertain)\
      \  sameVfPortExuParam.map(samePort =>\n197:       samePort.wbPortConfigs.map(\n\
      198:         x => x match {\n199:           case VfWB(port, priority) => {\n\
      200:             if (!samePort.latencyCertain) assert(priority == sameVfPortExuParam.size
      - 1,\n201:               s\"${samePort.name}: VfWbPort $port must latencyCertain
      priority=0 or latencyUnCertain priority=max(${sameVfPortExuParam.size - 1})\"\
      )\n202:             // Certain latency can be handled by WbBusyTable, so there
      is no need to limit the exu's WB priority\n203:           }\n204:          \
      \ case _ =>\n205:         }\n206:       )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 223-233
    context: "223:   // ExeUnit.in <---> Dispatcher.in\n224:   in1ToN.io.in.valid
      := io.in.valid && !busy\n225:   in1ToN.io.in.bits := io.in.bits\n226:   io.in.ready
      := !busy && in1ToN.io.in.ready\n227: \n228:   def pipelineReg(init: ExuInput,
      valid: Bool, latency: Int, flush: ValidIO[Redirect]): (Seq[ExuInput], Seq[Bool])
      = {\n229:     val validVec = valid +: Seq.fill(latency)(RegInit(false.B))\n\
      230:     val inVec = init +: Seq.fill(latency)(Reg(new ExuInput(exuParams)))\n\
      231:     val robIdxVec = inVec.map(_.robIdx)\n232:     // if flush(0), valid
      0 will not given, so set flushVec(0) to false.B\n233:     val flushVec = validVec.zip(robIdxVec).map(x
      => x._1 && x._2.needFlush(flush))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 321-331
    context: "321: \n322:   private val fuOutValidOH = funcUnits.map(_.io.out.valid)\n\
      323:   XSError(PopCount(fuOutValidOH) > 1.U, p\"fuOutValidOH ${Binary(VecInit(fuOutValidOH).asUInt)}
      should be one-hot)\\n\")\n324:   private val fuOutBitsVec = funcUnits.map(_.io.out.bits)\n\
      325:   private val fuOutresVec = OutresVecs.map(_.last)\n326:   private val
      fuRedirectVec: Seq[Option[ValidIO[Redirect]]] = fuOutresVec.map(_.redirect)\n\
      327: \n328:   // Assume that one fu can only write int or fp or vec,\n329: \
      \  // otherwise, wenVec should be assigned to wen in fu.\n330:   private val
      fuIntWenVec = funcUnits.map(x => x.cfg.needIntWen.B && x.io.out.bits.ctrl.rfWen.getOrElse(false.B))\n\
      331:   private val fuFpWenVec  = funcUnits.map( x => x.cfg.needFpWen.B  && x.io.out.bits.ctrl.fpWen.getOrElse(false.B))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 374-384
    context: "374:   io.out.bits.intWen.foreach(x => x := Mux1H(fuOutValidOH, fuIntWenVec))\n\
      375:   io.out.bits.fpWen.foreach(x => x := Mux1H(fuOutValidOH, fuFpWenVec))\n\
      376:   io.out.bits.vecWen.foreach(x => x := Mux1H(fuOutValidOH, fuVecWenVec))\n\
      377:   io.out.bits.v0Wen.foreach(x => x := Mux1H(fuOutValidOH, fuV0WenVec))\n\
      378:   io.out.bits.vlWen.foreach(x => x := Mux1H(fuOutValidOH, fuVlWenVec))\n\
      379:   io.out.bits.redirect.foreach(x => x := Mux1H((fuOutValidOH zip fuRedirectVec).filter(_._2.isDefined).map(x
      => (x._1, x._2.get))))\n380:   io.out.bits.fflags.foreach(x => x := Mux1H(fuOutValidOH,
      fuOutresVec.map(_.fflags.getOrElse(0.U.asTypeOf(io.out.bits.fflags.get)))))\n\
      381:   io.out.bits.wflags.foreach(x => x := Mux1H(fuOutValidOH, fuOutBitsVec.map(_.ctrl.fpu.getOrElse(0.U.asTypeOf(new
      FPUCtrlSignals)).wflags)))\n382:   io.out.bits.vxsat.foreach(x => x := Mux1H(fuOutValidOH,
      fuOutresVec.map(_.vxsat.getOrElse(0.U.asTypeOf(io.out.bits.vxsat.get)))))\n\
      383:   io.out.bits.exceptionVec.foreach(x => x := Mux1H(fuOutValidOH, fuOutBitsVec.map(_.ctrl.exceptionVec.getOrElse(0.U.asTypeOf(io.out.bits.exceptionVec.get)))))\n\
      384:   io.out.bits.flushPipe.foreach(x => x := Mux1H(fuOutValidOH, fuOutBitsVec.map(_.ctrl.flushPipe.getOrElse(0.U.asTypeOf(io.out.bits.flushPipe.get)))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnit.scala
    lines: 434-444
    context: "434: \n435:   io.in.ready := Cat(io.out.map(_.ready)).andR\n436: }\n\
      437: \n438: class MemExeUnitIO (implicit p: Parameters) extends XSBundle {\n\
      439:   val flush = Flipped(ValidIO(new Redirect()))\n440:   val in = Flipped(DecoupledIO(new
      MemExuInput()))\n441:   val out = DecoupledIO(new MemExuOutput())\n442: }\n\
      443: \n444: class MemExeUnit(exuParams: ExeUnitParams)(implicit p: Parameters)
      extends XSModule {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExuBlock.scala
    lines: 5-15
    context: "5: import chisel3.util._\n6: import freechips.rocketchip.diplomacy.{LazyModule,
      LazyModuleImp}\n7: import xiangshan.backend.fu.{CSRFileIO, FenceIO}\n8: import
      xiangshan.backend.Bundles._\n9: import xiangshan.backend.issue.SchdBlockParams\n\
      10: import xiangshan.{HasXSParameter, Redirect, XSBundle}\n11: import utility._\n\
      12: import xiangshan.backend.fu.FuConfig.{AluCfg, BrhCfg}\n13: import xiangshan.backend.fu.vector.Bundles.{VType,
      Vxrm}\n14: import xiangshan.backend.fu.fpu.Bundles.Frm\n15: import xiangshan.backend.fu.wrapper.{CSRInput,
      CSRToDecode}"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExuBlock.scala
    lines: 67-77
    context: "67:   val criticalErrors = exus.filter(_.wrapper.exuParams.needCriticalErrors).flatMap(exu
      => exu.getCriticalErrors)\n68:   generateCriticalErrors()\n69: }\n70: \n71:
      class ExuBlockIO(implicit p: Parameters, params: SchdBlockParams) extends XSBundle
      {\n72:   val flush = Flipped(ValidIO(new Redirect))\n73:   // in(i)(j): issueblock(i),
      exu(j)\n74:   val in: MixedVec[MixedVec[DecoupledIO[ExuInput]]] = Flipped(params.genExuInputCopySrcBundle)\n\
      75:   // out(i)(j): issueblock(i), exu(j).\n76:   val out: MixedVec[MixedVec[DecoupledIO[ExuOutput]]]
      = params.genExuOutputDecoupledBundle\n77: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/exu/ExeUnitParams.scala
    lines: 79-89
    context: "79:   val needFPUCtrl: Boolean = fuConfigs.map(_.needFPUCtrl).reduce(_
      || _)\n80:   val needVPUCtrl: Boolean = fuConfigs.map(_.needVecCtrl).reduce(_
      || _)\n81:   val writeVConfig: Boolean = fuConfigs.map(_.writeVlRf).reduce(_
      || _)\n82:   val writeVType: Boolean = fuConfigs.map(_.writeVType).reduce(_
      || _)\n83:   val needCriticalErrors: Boolean = fuConfigs.map(_.needCriticalErrors).reduce(_
      || _)\n84:   val isHighestWBPriority: Boolean = wbPortConfigs.forall(_.priority
      == 0)\n85: \n86:   val isIntExeUnit: Boolean = schdType.isInstanceOf[IntScheduler]\n\
      87:   val isVfExeUnit: Boolean = schdType.isInstanceOf[VfScheduler]\n88:   val
      isMemExeUnit: Boolean = schdType.isInstanceOf[MemScheduler]\n89: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 118-138
    context: "118:       s\"srcReg(${exuCfg.numRegSrc})\"\n119:     )\n120:     require(\n\
      121:       wbPortConfigs.collectFirst { case x: IntWB => x }.nonEmpty ==\n122:\
      \         fuConfigs.map(_.writeIntRf).reduce(_ || _),\n123:       s\"${exuCfg.name}
      int wb port has no priority\"\n124:     )\n125:     require(\n126:       wbPortConfigs.collectFirst
      { case x: FpWB => x }.nonEmpty ==\n127:         fuConfigs.map(x => x.writeFpRf).reduce(_
      || _),\n128:       s\"${exuCfg.name} fp wb port has no priority\"\n129:    \
      \ )\n130:     require(\n131:       wbPortConfigs.collectFirst { case x: VfWB
      => x }.nonEmpty ==\n132:         fuConfigs.map(x => x.writeVecRf).reduce(_ ||
      _),\n133:       s\"${exuCfg.name} vec wb port has no priority\"\n134:     )\n\
      135:   }\n136: \n137:   println(s\"[Backend] all fu configs\")\n138:   for (cfg
      <- FuConfig.allConfigs) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 137-172
    context: "137:   println(s\"[Backend] all fu configs\")\n138:   for (cfg <- FuConfig.allConfigs)
      {\n139:     println(s\"[Backend]   $cfg\")\n140:   }\n141: \n142:   println(s\"\
      [Backend] Int RdConfigs: ExuName(Priority)\")\n143:   for ((port, seq) <- params.getRdPortParams(IntData()))
      {\n144:     println(s\"[Backend]   port($port): ${seq.map(x => params.getExuName(x._1)
      + \"(\" + x._2.toString + \")\").mkString(\",\")}\")\n145:   }\n146: \n147:\
      \   println(s\"[Backend] Int WbConfigs: ExuName(Priority)\")\n148:   for ((port,
      seq) <- params.getWbPortParams(IntData())) {\n149:     println(s\"[Backend]\
      \   port($port): ${seq.map(x => params.getExuName(x._1) + \"(\" + x._2.toString
      + \")\").mkString(\",\")}\")\n150:   }\n151: \n152:   println(s\"[Backend] Fp
      RdConfigs: ExuName(Priority)\")\n153:   for ((port, seq) <- params.getRdPortParams(FpData()))
      {\n154:     println(s\"[Backend]   port($port): ${seq.map(x => params.getExuName(x._1)
      + \"(\" + x._2.toString + \")\").mkString(\",\")}\")\n155:   }\n156: \n157:\
      \   println(s\"[Backend] Fp WbConfigs: ExuName(Priority)\")\n158:   for ((port,
      seq) <- params.getWbPortParams(FpData())) {\n159:     println(s\"[Backend] \
      \  port($port): ${seq.map(x => params.getExuName(x._1) + \"(\" + x._2.toString
      + \")\").mkString(\",\")}\")\n160:   }\n161: \n162:   println(s\"[Backend] Vf
      RdConfigs: ExuName(Priority)\")\n163:   for ((port, seq) <- params.getRdPortParams(VecData()))
      {\n164:     println(s\"[Backend]   port($port): ${seq.map(x => params.getExuName(x._1)
      + \"(\" + x._2.toString + \")\").mkString(\",\")}\")\n165:   }\n166: \n167:\
      \   println(s\"[Backend] Vf WbConfigs: ExuName(Priority)\")\n168:   for ((port,
      seq) <- params.getWbPortParams(VecData())) {\n169:     println(s\"[Backend]\
      \   port($port): ${seq.map(x => params.getExuName(x._1) + \"(\" + x._2.toString
      + \")\").mkString(\",\")}\")\n170:   }\n171: \n172:   println(s\"[Backend] Dispatch
      Configs:\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 265-276
    context: "265:   ctrlBlock.io.sqCanAccept := io.mem.sqCanAccept\n266: \n267: \
      \  io.mem.wfi <> ctrlBlock.io.toMem.wfi\n268: \n269:   io.mem.lsqEnqIO <> ctrlBlock.io.toMem.lsqEnqIO\n\
      270:   ctrlBlock.io.fromMemToDispatch.scommit := io.mem.sqDeq\n271:   ctrlBlock.io.fromMemToDispatch.lcommit
      := io.mem.lqDeq\n272:   ctrlBlock.io.fromMemToDispatch.sqDeqPtr := io.mem.sqDeqPtr\n\
      273:   ctrlBlock.io.fromMemToDispatch.lqDeqPtr := io.mem.lqDeqPtr\n274:   ctrlBlock.io.fromMemToDispatch.sqCancelCnt
      := io.mem.sqCancelCnt\n275:   ctrlBlock.io.fromMemToDispatch.lqCancelCnt :=
      io.mem.lqCancelCnt\n276:   ctrlBlock.io.toDispatch.wakeUpInt := intScheduler.io.toSchedulers.wakeupVec"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 415-426
    context: "415:   memScheduler.io.intWriteBackDelayed := intWriteBackDelayed\n\
      416:   memScheduler.io.fpWriteBackDelayed := fpWriteBackDelayed\n417:   memScheduler.io.vfWriteBackDelayed
      := vfWriteBackDelayed\n418:   memScheduler.io.v0WriteBackDelayed := v0WriteBackDelayed\n\
      419:   memScheduler.io.vlWriteBackDelayed := vlWriteBackDelayed\n420:   memScheduler.io.fromMem.get.scommit
      := io.mem.sqDeq\n421:   memScheduler.io.fromMem.get.lcommit := io.mem.lqDeq\n\
      422:   memScheduler.io.fromMem.get.wakeup := io.mem.wakeup\n423:   memScheduler.io.fromMem.get.sqDeqPtr
      := io.mem.sqDeqPtr\n424:   memScheduler.io.fromMem.get.lqDeqPtr := io.mem.lqDeqPtr\n\
      425:   memScheduler.io.fromMem.get.sqCancelCnt := io.mem.sqCancelCnt\n426: \
      \  memScheduler.io.fromMem.get.lqCancelCnt := io.mem.lqCancelCnt"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 492-502
    context: "492:   dataPath.io.fromV0Wb := wbDataPath.io.toV0Preg\n493:   dataPath.io.fromVlWb
      := wbDataPath.io.toVlPreg\n494:   dataPath.io.diffIntRat.foreach(_ := ctrlBlock.io.diff_int_rat.get)\n\
      495:   dataPath.io.diffFpRat .foreach(_ := ctrlBlock.io.diff_fp_rat.get)\n496:\
      \   dataPath.io.diffVecRat.foreach(_ := ctrlBlock.io.diff_vec_rat.get)\n497:\
      \   dataPath.io.diffV0Rat .foreach(_ := ctrlBlock.io.diff_v0_rat.get)\n498:\
      \   dataPath.io.diffVlRat .foreach(_ := ctrlBlock.io.diff_vl_rat.get)\n499:\
      \   dataPath.io.fromBypassNetwork := bypassNetwork.io.toDataPath\n500:   dataPath.io.fromVecExcpMod.r
      := vecExcpMod.o.toVPRF.r\n501:   dataPath.io.fromVecExcpMod.w := vecExcpMod.o.toVPRF.w\n\
      502:   dataPath.io.topDownInfo.lqEmpty := DelayN(io.topDownInfo.lqEmpty, 2)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 581-591
    context: "581: \n582:   private val csrio = intExuBlock.io.csrio.get\n583:   csrio.hartId
      := io.fromTop.hartId\n584:   csrio.fpu.fflags := ctrlBlock.io.robio.csr.fflags\n\
      585:   csrio.fpu.isIllegal := false.B // Todo: remove it\n586:   csrio.fpu.dirty_fs
      := ctrlBlock.io.robio.csr.dirty_fs\n587:   csrio.vpu <> WireDefault(0.U.asTypeOf(csrio.vpu))
      // Todo\n588: \n589:   val fromIntExuVsetVType = intExuBlock.io.vtype.getOrElse(0.U.asTypeOf((Valid(new
      VType))))\n590:   val fromVfExuVsetVType = vfExuBlock.io.vtype.getOrElse(0.U.asTypeOf((Valid(new
      VType))))\n591:   val fromVsetVType = Mux(fromIntExuVsetVType.valid, fromIntExuVsetVType.bits,
      fromVfExuVsetVType.bits)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 590-602
    context: "590:   val fromVfExuVsetVType = vfExuBlock.io.vtype.getOrElse(0.U.asTypeOf((Valid(new
      VType))))\n591:   val fromVsetVType = Mux(fromIntExuVsetVType.valid, fromIntExuVsetVType.bits,
      fromVfExuVsetVType.bits)\n592:   val vsetvlVType = RegEnable(fromVsetVType,
      0.U.asTypeOf(new VType), fromIntExuVsetVType.valid || fromVfExuVsetVType.valid)\n\
      593:   ctrlBlock.io.toDecode.vsetvlVType := vsetvlVType\n594: \n595:   val commitVType
      = ctrlBlock.io.robio.commitVType.vtype\n596:   val hasVsetvl = ctrlBlock.io.robio.commitVType.hasVsetvl\n\
      597:   val vtype = VType.toVtypeStruct(Mux(hasVsetvl, vsetvlVType, commitVType.bits)).asUInt\n\
      598: \n599:   // csr not store the value of vl, so when using difftest we assign
      the value of vl to debugVl\n600:   val debugVl_s0 = WireInit(UInt(VlData().dataWidth.W),
      0.U)\n601:   val debugVl_s1 = WireInit(UInt(VlData().dataWidth.W), 0.U)\n602:\
      \   debugVl_s0 := dataPath.io.diffVl.getOrElse(0.U.asTypeOf(UInt(VlData().dataWidth.W)))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 604-617
    context: "604:   csrio.vpu.set_vxsat := ctrlBlock.io.robio.csr.vxsat\n605:   csrio.vpu.set_vstart.valid
      := ctrlBlock.io.robio.csr.vstart.valid\n606:   csrio.vpu.set_vstart.bits :=
      ctrlBlock.io.robio.csr.vstart.bits\n607:   ctrlBlock.io.toDecode.vstart := csrio.vpu.vstart\n\
      608:   //Todo here need change design\n609:   csrio.vpu.set_vtype.valid := commitVType.valid\n\
      610:   csrio.vpu.set_vtype.bits := ZeroExt(vtype, XLEN)\n611:   csrio.vpu.vl
      := ZeroExt(debugVl_s1, XLEN)\n612:   csrio.vpu.dirty_vs := ctrlBlock.io.robio.csr.dirty_vs\n\
      613:   csrio.exception := ctrlBlock.io.robio.exception\n614:   csrio.robDeqPtr
      := ctrlBlock.io.robio.robDeqPtr\n615:   csrio.memExceptionVAddr := io.mem.exceptionAddr.vaddr\n\
      616:   csrio.memExceptionGPAddr := io.mem.exceptionAddr.gpaddr\n617:   csrio.memExceptionIsForVSnonLeafPTE
      := io.mem.exceptionAddr.isForVSnonLeafPTE"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 660-670
    context: "660:   fpExuBlock.io.frm.foreach(_ := csrio.fpu.frm)\n661:   fpExuBlock.io.vxrm.foreach(_
      := csrio.vpu.vxrm)\n662:   vfExuBlock.io.frm.foreach(_ := csrio.fpu.frm)\n663:\
      \   vfExuBlock.io.vxrm.foreach(_ := csrio.vpu.vxrm)\n664: \n665:   wbDataPath.io.flush
      := ctrlBlock.io.redirect\n666:   wbDataPath.io.fromTop.hartId := io.fromTop.hartId\n\
      667:   wbDataPath.io.fromIntExu <> intExuBlock.io.out\n668:   wbDataPath.io.fromFpExu
      <> fpExuBlock.io.out\n669:   wbDataPath.io.fromVfExu <> vfExuBlock.io.out\n\
      670:   wbDataPath.io.fromMemExu.flatten.zip(io.mem.writeBack).foreach { case
      (sink, source) =>"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 781-791
    context: "781:         }\n782:       }\n783:     }\n784:   }\n785: \n786:   io.mem.redirect
      := ctrlBlock.io.redirect\n787:   io.mem.issueUops.zip(toMem.flatten).foreach
      { case (sink, source) =>\n788:     val enableMdp = Constantin.createRecord(\"\
      EnableMdp\", true)\n789:     sink.valid := source.valid\n790:     source.ready
      := sink.ready\n791:     sink.bits.iqIdx              := source.bits.iqIdx"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 824-834
    context: "824:   io.mem.loadFastMatch := memScheduler.io.toMem.get.loadFastMatch.map(_.fastMatch)\n\
      825:   io.mem.loadFastImm := memScheduler.io.toMem.get.loadFastMatch.map(_.fastImm)\n\
      826:   io.mem.tlbCsr := csrio.tlb\n827:   io.mem.csrCtrl := csrio.customCtrl\n\
      828:   io.mem.sfence := fenceio.sfence\n829:   io.mem.isStoreException := CommitType.lsInstIsStore(ctrlBlock.io.robio.exception.bits.commitType)\n\
      830:   io.mem.isVlsException := ctrlBlock.io.robio.exception.bits.vls\n831:\
      \ \n832:   io.mem.storePcRead.zipWithIndex.foreach { case (storePcRead, i) =>\n\
      833:     storePcRead := ctrlBlock.io.memStPcRead(i).data\n834:     ctrlBlock.io.memStPcRead(i).valid
      := io.mem.issueSta(i).valid"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 982-992
    context: "982:   val writebackHyuSta = Vec(params.HyuCnt, Flipped(DecoupledIO(new
      MemExuOutput)))\n983:   val writebackVldu = Vec(params.VlduCnt, Flipped(DecoupledIO(new
      MemExuOutput(true))))\n984: \n985:   val s3_delayed_load_error = Input(Vec(LoadPipelineWidth,
      Bool()))\n986:   val stIn = Input(Vec(params.StaExuCnt, ValidIO(new DynInst())))\n\
      987:   val memoryViolation = Flipped(ValidIO(new Redirect))\n988:   val exceptionAddr
      = Input(new Bundle {\n989:     val vaddr = UInt(XLEN.W)\n990:     val gpaddr
      = UInt(XLEN.W)\n991:     val isForVSnonLeafPTE = Bool()\n992:   })"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 989-999
    context: "989:     val vaddr = UInt(XLEN.W)\n990:     val gpaddr = UInt(XLEN.W)\n\
      991:     val isForVSnonLeafPTE = Bool()\n992:   })\n993:   val sqDeq = Input(UInt(log2Ceil(EnsbufferWidth
      + 1).W))\n994:   val lqDeq = Input(UInt(log2Up(CommitWidth + 1).W))\n995:  \
      \ val sqDeqPtr = Input(new SqPtr)\n996:   val lqDeqPtr = Input(new LqPtr)\n\
      997: \n998:   val lqCancelCnt = Input(UInt(log2Up(VirtualLoadQueueSize + 1).W))\n\
      999:   val sqCancelCnt = Input(UInt(log2Up(StoreQueueSize + 1).W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/backend/Backend.scala
    lines: 1006-1016
    context: "1006: \n1007:   val debugLS = Flipped(Output(new DebugLSIO))\n1008:\
      \ \n1009:   val lsTopdownInfo = Vec(params.LduCnt + params.HyuCnt, Flipped(Output(new
      LsTopdownInfo)))\n1010:   // Output\n1011:   val redirect = ValidIO(new Redirect)\
      \   // rob flush MemBlock\n1012:   val issueLda = MixedVec(Seq.fill(params.LduCnt)(DecoupledIO(new
      MemExuInput())))\n1013:   val issueSta = MixedVec(Seq.fill(params.StaCnt)(DecoupledIO(new
      MemExuInput())))\n1014:   val issueStd = MixedVec(Seq.fill(params.StdCnt)(DecoupledIO(new
      MemExuInput())))\n1015:   val issueHylda = MixedVec(Seq.fill(params.HyuCnt)(DecoupledIO(new
      MemExuInput())))\n1016:   val issueHysta = MixedVec(Seq.fill(params.HyuCnt)(DecoupledIO(new
      MemExuInput())))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 44-54
    context: "44: \n45: class IssueQueueDeqRespBundle(implicit p:Parameters, params:
      IssueBlockParams) extends EntryDeqRespBundle\n46: \n47: class IssueQueueIO()(implicit
      p: Parameters, params: IssueBlockParams) extends XSBundle {\n48:   // Inputs\n\
      49:   val flush = Flipped(ValidIO(new Redirect))\n50:   val enq = Vec(params.numEnq,
      Flipped(DecoupledIO(new DynInst)))\n51: \n52:   val og0Resp = Vec(params.numDeq,
      Flipped(ValidIO(new IssueQueueDeqRespBundle)))\n53:   val og1Resp = Vec(params.numDeq,
      Flipped(ValidIO(new IssueQueueDeqRespBundle)))\n54:   val og2Resp = Option.when(params.needOg2Resp)(Vec(params.numDeq,
      Flipped(ValidIO(new IssueQueueDeqRespBundle))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 132-142
    context: "132:   val v0WbBusyTableRead = params.exuBlockParams.map { case x =>
      Option.when(x.v0LatencyCertain)(Module(new FuBusyTableRead(x.v0FuLatencyMap)))
      }\n133:   val vlWbBusyTableWrite = params.exuBlockParams.map { case x => Option.when(x.vlLatencyCertain)(Module(new
      FuBusyTableWrite(x.vlFuLatencyMap))) }\n134:   val vlWbBusyTableRead = params.exuBlockParams.map
      { case x => Option.when(x.vlLatencyCertain)(Module(new FuBusyTableRead(x.vlFuLatencyMap)))
      }\n135: \n136:   class WakeupQueueFlush extends Bundle {\n137:     val redirect
      = ValidIO(new Redirect)\n138:     val ldCancel = Vec(backendParams.LduCnt +
      backendParams.HyuCnt, new LoadCancelIO)\n139:     val og0Fail = Output(Bool())\n\
      140:     val og1Fail = Output(Bool())\n141:   }\n142: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 139-149
    context: "139:     val og0Fail = Output(Bool())\n140:     val og1Fail = Output(Bool())\n\
      141:   }\n142: \n143:   private def flushFunc(exuInput: ExuInput, flush: WakeupQueueFlush,
      stage: Int): Bool = {\n144:     val redirectFlush = exuInput.robIdx.needFlush(flush.redirect)\n\
      145:     val loadDependencyFlush = LoadShouldCancel(exuInput.loadDependency,
      flush.ldCancel)\n146:     val ogFailFlush = stage match {\n147:       case 1
      => flush.og0Fail\n148:       case 2 => flush.og1Fail\n149:       case _ => false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueQueue.scala
    lines: 746-756
    context: "746: \n747:   wakeUpQueues.zipWithIndex.foreach { case (wakeUpQueueOption,
      i) =>\n748:     wakeUpQueueOption.foreach {\n749:       wakeUpQueue =>\n750:\
      \         val flush = Wire(new WakeupQueueFlush)\n751:         flush.redirect
      := io.flush\n752:         flush.ldCancel := io.ldCancel\n753:         flush.og0Fail
      := io.og0Resp(i).valid && RespType.isBlocked(io.og0Resp(i).bits.resp)\n754:\
      \         flush.og1Fail := io.og1Resp(i).valid && RespType.isBlocked(io.og1Resp(i).bits.resp)\n\
      755:         wakeUpQueue.io.flush := flush\n756:         wakeUpQueue.io.enq.valid
      := deqBeforeDly(i).valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/IssueBlockParams.scala
    lines: 170-180
    context: "170: \n171:   def VsetCnt: Int = exuBlockParams.map(_.fuConfigs.count(x
      => x.fuType == FuType.vsetiwi || x.fuType == FuType.vsetiwf || x.fuType == FuType.vsetfwf)).sum\n\
      172: \n173:   def FmacCnt: Int = exuBlockParams.map(_.fuConfigs.count(_.fuType
      == FuType.fmac)).sum\n174: \n175:   def fDivSqrtCnt: Int = exuBlockParams.map(_.fuConfigs.count(_.fuType
      == FuType.fDivSqrt)).sum\n176: \n177:   def LduCnt: Int = exuBlockParams.count(x
      => x.hasLoadFu && !x.hasStoreAddrFu)\n178: \n179:   def StaCnt: Int = exuBlockParams.count(x
      => !x.hasLoadFu && x.hasStoreAddrFu)\n180: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 61-71
    context: "61:   }\n62:   val wbFuBusyTable = MixedVec(params.issueBlockParams.map(x
      => Output(x.genWbFuBusyTableWriteBundle)))\n63:   val IQValidNumVec = Output(Vec(IssueQueueDeqSum,
      UInt((maxIQSize).U.getWidth.W)))\n64: \n65:   val fromCtrlBlock = new Bundle
      {\n66:     val flush = Flipped(ValidIO(new Redirect))\n67:   }\n68:   val fromDispatch
      = new Bundle {\n69:     val uops =  Vec(fromDispatchUopNum, Flipped(DecoupledIO(new
      DynInst)))\n70:   }\n71:   val intWriteBack = MixedVec(Vec(backendParams.numPregWb(IntData()),"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Scheduler.scala
    lines: 129-140
    context: "129:     val staFeedback = Flipped(Vec(params.StaCnt, new MemRSFeedbackIO))\n\
      130:     val hyuFeedback = Flipped(Vec(params.HyuCnt, new MemRSFeedbackIO))\n\
      131:     val vstuFeedback = Flipped(Vec(params.VstuCnt, new MemRSFeedbackIO(isVector
      = true)))\n132:     val vlduFeedback = Flipped(Vec(params.VlduCnt, new MemRSFeedbackIO(isVector
      = true)))\n133:     val stIssuePtr = Input(new SqPtr())\n134:     val lcommit
      = Input(UInt(log2Up(CommitWidth + 1).W))\n135:     val scommit = Input(UInt(log2Ceil(EnsbufferWidth
      + 1).W)) // connected to `memBlock.io.sqDeq` instead of ROB\n136:     val wakeup
      = Vec(params.LdExuCnt, Flipped(Valid(new DynInst)))\n137:     val lqDeqPtr =
      Input(new LqPtr)\n138:     val sqDeqPtr = Input(new SqPtr)\n139:     // from
      lsq\n140:     val lqCancelCnt = Input(UInt(log2Up(LoadQueueSize + 1).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EnqEntry.scala
    lines: 15-25
    context: "15: import xiangshan.mem.Bundles.MemWaitUpdateReqBundle\n16: \n17: \n\
      18: class EnqEntryIO(implicit p: Parameters, params: IssueBlockParams) extends
      XSBundle {\n19:   //input\n20:   val commonIn            = new CommonInBundle\n\
      21:   val enqDelayIn1         = new EnqDelayInBundle\n22:   val enqDelayIn2\
      \         = new EnqDelayInBundle\n23: \n24:   //output\n25:   val commonOut\
      \           = new CommonOutBundle"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EnqEntry.scala
    lines: 22-32
    context: "22:   val enqDelayIn2         = new EnqDelayInBundle\n23: \n24:   //output\n\
      25:   val commonOut           = new CommonOutBundle\n26: \n27:   def wakeup\
      \              = commonIn.wakeUpFromWB ++ commonIn.wakeUpFromIQ\n28: }\n29:\
      \ \n30: class EnqEntry(isComp: Boolean)(implicit p: Parameters, params: IssueBlockParams)
      extends XSModule {\n31:   val io = IO(new EnqEntryIO)\n32: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EnqEntry.scala
    lines: 48-70
    context: "48:   val validReg = GatedValidRegNext(common.validRegNext, false.B)\n\
      49:   val entryReg = RegNext(entryRegNext)\n50:   val enqDelayValidReg = GatedValidRegNext(enqDelayValidRegNext,
      false.B)\n51: \n52:   //Wire\n53:   CommonWireConnect(common, hasWakeupIQ, validReg,
      currentStatus, io.commonIn, true)\n54: \n55:   when(io.commonIn.enq.valid) {\n\
      56:     assert(common.enqReady, s\"${params.getIQName}'s EnqEntry is not ready
      when enq is valid\\n\")\n57:   }\n58: \n59:   when(io.commonIn.enq.valid &&
      common.enqReady) {\n60:     entryRegNext := io.commonIn.enq.bits\n61:   }.otherwise
      {\n62:     entryRegNext := entryUpdate\n63:   }\n64: \n65:   when(io.commonIn.enq.valid
      && common.enqReady) {\n66:     enqDelayValidRegNext := true.B\n67:   }.otherwise
      {\n68:     enqDelayValidRegNext := false.B\n69:   }\n70: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EnqEntry.scala
    lines: 68-78
    context: "68:     enqDelayValidRegNext := false.B\n69:   }\n70: \n71:   if (params.hasIQWakeUp)
      {\n72:     ShiftLoadDependency(hasWakeupIQ.get)\n73:     CommonIQWakeupConnect(common,
      hasWakeupIQ.get, validReg, currentStatus, io.commonIn, true)\n74:   }\n75: \n\
      76:   // enq delay wakeup\n77:   val enqDelayOut1         = Wire(new EnqDelayOutBundle)\n\
      78:   val enqDelayOut2         = Wire(new EnqDelayOutBundle)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EnqEntry.scala
    lines: 81-93
    context: "81: \n82:   for (i <- 0 until params.numRegSrc) {\n83:     val enqDelay1WakeUpValid
      = enqDelayOut1.srcWakeUpByIQVec(i).asUInt.orR\n84:     val enqDelay1WakeUpOH\
      \    = enqDelayOut1.srcWakeUpByIQVec(i)\n85:     val enqDelay2WakeUpOH    =
      enqDelayOut2.srcWakeUpByIQVec(i)\n86:     val enqDelay1IsWakeupByMemIQ = enqDelay1WakeUpOH.zip(io.commonIn.wakeUpFromIQ).filter(_._2.bits.params.isMemExeUnit).map(_._1).fold(false.B)(_
      || _)\n87:     val enqDelay2IsWakeupByMemIQ = enqDelay2WakeUpOH.zip(io.commonIn.wakeUpFromIQ).filter(_._2.bits.params.isMemExeUnit).map(_._1).fold(false.B)(_
      || _)\n88:     val enqDelay2IsWakeupByVfIQ  = enqDelay2WakeUpOH.zip(io.commonIn.wakeUpFromIQ).filter(_._2.bits.params.isVfExeUnit).map(_._1).fold(false.B)(_
      || _)\n89: \n90:     if (params.inVfSchd && params.readVfRf && params.hasIQWakeUp)
      {\n91:       enqDelayDataSources(i).value            := MuxCase(entryReg.status.srcStatus(i).dataSources.value,
      Seq(\n92:                                                     (enqDelayOut1.srcWakeUpByIQ(i).asBool
      && !enqDelay1IsWakeupByMemIQ)  -> DataSource.bypass,\n93:                  \
      \                                   (enqDelayOut1.srcWakeUpByIQ(i).asBool &&
      enqDelay1IsWakeupByMemIQ)   -> DataSource.bypass2,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EnqEntry.scala
    lines: 148-161
    context: "148:       case ((currExu, regExu), enqDelayExu) =>\n149:         currExu
      := Mux(enqDelayValidReg, enqDelayExu, regExu)\n150:     }\n151:   }\n152: \n\
      153:   EntryRegCommonConnect(common, hasWakeupIQ, validReg, entryUpdate, entryReg,
      currentStatus, io.commonIn, true, isComp)\n154: \n155:   //output\n156:   CommonOutConnect(io.commonOut,
      common, hasWakeupIQ, validReg, entryUpdate, entryReg, currentStatus, io.commonIn,
      true, isComp)\n157: }\n158: \n159: class EnqEntryVecMem(isComp: Boolean)(implicit
      p: Parameters, params: IssueBlockParams) extends EnqEntry(isComp)\n160:   with
      HasCircularQueuePtrHelper {\n161: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EnqEntry.scala
    lines: 159-169
    context: "159: class EnqEntryVecMem(isComp: Boolean)(implicit p: Parameters, params:
      IssueBlockParams) extends EnqEntry(isComp)\n160:   with HasCircularQueuePtrHelper
      {\n161: \n162:   require(params.isVecMemIQ, \"EnqEntryVecMem can only be instance
      of VecMem IQ\")\n163: \n164:   EntryVecMemConnect(io.commonIn, common, validReg,
      entryReg, entryRegNext, entryUpdate)\n165: }\n166: \n167: object EnqEntry {\n\
      168:   def apply(isComp: Boolean)(implicit p: Parameters, iqParams: IssueBlockParams):
      EnqEntry = {\n169:     iqParams.schdType match {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 95-105
    context: "95:     val imm                   = Option.when(params.needImm)(UInt((params.deqImmTypesMaxLen).W))\n\
      96:     val payload               = new DynInst()\n97:   }\n98: \n99:   class
      CommonInBundle(implicit p: Parameters, params: IssueBlockParams) extends XSBundle
      {\n100:     val flush                 = Flipped(ValidIO(new Redirect))\n101:\
      \     val enq                   = Flipped(ValidIO(new EntryBundle))\n102:  \
      \   //wakeup\n103:     val wakeUpFromWB: MixedVec[ValidIO[IssueQueueWBWakeUpBundle]]
      = Flipped(params.genWBWakeUpSinkValidBundle)\n104:     val wakeUpFromIQ: MixedVec[ValidIO[IssueQueueIQWakeUpBundle]]
      = Flipped(params.genIQWakeUpSinkValidBundle)\n105:     // vl"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 168-183
    context: "168:     val srcLoadCancelVec      = Vec(params.numRegSrc, Bool())\n\
      169:     val srcLoadTransCancelVec = Vec(params.numRegSrc, Bool())\n170:   \
      \  val srcLoadDependencyNext = Vec(params.numRegSrc, Vec(LoadPipelineWidth,
      UInt(LoadDependencyWidth.W)))\n171:   }\n172: \n173:   def CommonWireConnect(common:
      CommonWireBundle, hasIQWakeup: Option[CommonIQWakeupBundle], validReg: Bool,
      status: Status, commonIn: CommonInBundle, isEnq: Boolean)(implicit p: Parameters,
      params: IssueBlockParams) = {\n174:     val hasIQWakeupGet        = hasIQWakeup.getOrElse(0.U.asTypeOf(new
      CommonIQWakeupBundle))\n175:     common.flushed            := status.robIdx.needFlush(commonIn.flush)\n\
      176:     common.deqSuccess         := (if (params.isVecMemIQ) status.issued
      else true.B) &&\n177:       commonIn.issueResp.valid && RespType.succeed(commonIn.issueResp.bits.resp)
      && !common.srcLoadCancelVec.asUInt.orR\n178:     common.srcWakeupByWB      :=
      commonIn.wakeUpFromWB.map{ bundle =>\n179:                                 \
      \    val psrcSrcTypeVec = status.srcStatus.map(_.psrc) zip status.srcStatus.map(_.srcType)\n\
      180:                                     if (params.numRegSrc == 5) {\n181:\
      \                                       bundle.bits.wakeUp(psrcSrcTypeVec.take(3),
      bundle.valid) :+\n182:                                       bundle.bits.wakeUpV0(psrcSrcTypeVec(3),
      bundle.valid) :+\n183:                                       bundle.bits.wakeUpVl(psrcSrcTypeVec(4),
      bundle.valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 184-198
    context: "184:                                     }\n185:                   \
      \                  else\n186:                                       bundle.bits.wakeUp(psrcSrcTypeVec,
      bundle.valid)\n187:                                  }.transpose.map(x => VecInit(x.toSeq).asUInt.orR).toSeq\n\
      188:     common.canIssue           := validReg && status.canIssue\n189:    \
      \ common.enqReady           := !validReg || commonIn.transSel\n190:     common.clear\
      \              := common.flushed || common.deqSuccess || commonIn.transSel\n\
      191:     common.srcCancelVec.zip(hasIQWakeupGet.srcWakeupByIQWithoutCancel).zipWithIndex.foreach
      { case ((srcCancel, wakeUpByIQVec), srcIdx) =>\n192:       common.srcLoadTransCancelVec(srcIdx)
      := (if(params.hasIQWakeUp) Mux1H(wakeUpByIQVec, hasIQWakeupGet.wakeupLoadDependencyByIQVec.map(dep
      => LoadShouldCancel(Some(dep), commonIn.ldCancel))) else false.B)\n193:    \
      \   common.srcLoadCancelVec(srcIdx) := LoadShouldCancel(Some(status.srcStatus(srcIdx).srcLoadDependency),
      commonIn.ldCancel)\n194:       srcCancel := common.srcLoadTransCancelVec(srcIdx)
      || common.srcLoadCancelVec(srcIdx)\n195:     }\n196:     common.srcLoadDependencyNext.zip(status.srcStatus.map(_.srcLoadDependency)).foreach
      { case (ldsNext, lds) =>\n197:       ldsNext.zip(lds).foreach{ case (ldNext,
      ld) => ldNext := ld << 1 }\n198:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 195-211
    context: "195:     }\n196:     common.srcLoadDependencyNext.zip(status.srcStatus.map(_.srcLoadDependency)).foreach
      { case (ldsNext, lds) =>\n197:       ldsNext.zip(lds).foreach{ case (ldNext,
      ld) => ldNext := ld << 1 }\n198:     }\n199:     if(isEnq) {\n200:       common.validRegNext\
      \     := Mux(commonIn.enq.valid && common.enqReady, true.B, Mux(common.clear,
      false.B, validReg))\n201:     } else {\n202:       common.validRegNext     :=
      Mux(commonIn.enq.valid, true.B, Mux(common.clear, false.B, validReg))\n203:\
      \     }\n204:     if (params.numRegSrc == 5) {\n205:       // only when numRegSrc
      == 5 need vl\n206:       val wakeUpFromVl = VecInit(commonIn.wakeUpFromWB.map{
      bundle =>\n207:         val psrcSrcTypeVec = status.srcStatus.map(_.psrc) zip
      status.srcStatus.map(_.srcType)\n208:         bundle.bits.wakeUpVl(psrcSrcTypeVec(4),
      bundle.valid)\n209:       })\n210:       var numVecWb = params.backendParam.getVfWBExeGroup.size\n\
      211:       var numV0Wb = params.backendParam.getV0WBExeGroup.size"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 228-239
    context: "228:     val wakeupLoadDependencyByIQVec               = Vec(params.numWakeupFromIQ,
      Vec(LoadPipelineWidth, UInt(LoadDependencyWidth.W)))\n229:     val shiftedWakeupLoadDependencyByIQVec\
      \        = Vec(params.numWakeupFromIQ, Vec(LoadPipelineWidth, UInt(LoadDependencyWidth.W)))\n\
      230:     val canIssueBypass                            = Bool()\n231:   }\n\
      232: \n233:   def CommonIQWakeupConnect(common: CommonWireBundle, hasIQWakeupGet:
      CommonIQWakeupBundle, validReg: Bool, status: Status, commonIn: CommonInBundle,
      isEnq: Boolean)(implicit p: Parameters, params: IssueBlockParams) = {\n234:\
      \     val wakeupVec: Seq[Seq[Bool]] = commonIn.wakeUpFromIQ.map{(bundle: ValidIO[IssueQueueIQWakeUpBundle])
      =>\n235:       val psrcSrcTypeVec = status.srcStatus.map(_.psrc) zip status.srcStatus.map(_.srcType)\n\
      236:       if (params.numRegSrc == 5) {\n237:         bundle.bits.wakeUpFromIQ(psrcSrcTypeVec.take(3))
      :+\n238:         bundle.bits.wakeUpV0FromIQ(psrcSrcTypeVec(3)) :+\n239:    \
      \     bundle.bits.wakeUpVlFromIQ(psrcSrcTypeVec(4))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 239-254
    context: "239:         bundle.bits.wakeUpVlFromIQ(psrcSrcTypeVec(4))\n240:   \
      \    }\n241:       else\n242:         bundle.bits.wakeUpFromIQ(psrcSrcTypeVec)\n\
      243:     }.toSeq.transpose\n244:     val cancelSel = params.wakeUpSourceExuIdx.zip(commonIn.wakeUpFromIQ).map
      { case (x, y) => commonIn.og0Cancel(x) && y.bits.is0Lat }\n245: \n246:     hasIQWakeupGet.srcWakeupByIQ\
      \                    := wakeupVec.map(x => VecInit(x.zip(cancelSel).map { case
      (wakeup, cancel) => wakeup && !cancel }))\n247:     hasIQWakeupGet.srcWakeupByIQButCancel\
      \           := wakeupVec.map(x => VecInit(x.zip(cancelSel).map { case (wakeup,
      cancel) => wakeup && cancel }))\n248:     hasIQWakeupGet.srcWakeupByIQWithoutCancel\
      \       := wakeupVec.map(x => VecInit(x))\n249:     hasIQWakeupGet.wakeupLoadDependencyByIQVec\
      \      := commonIn.wakeUpFromIQ.map(_.bits.loadDependency).toSeq\n250:     hasIQWakeupGet.canIssueBypass\
      \                   := validReg && !status.issued && !status.blocked &&\n251:\
      \       VecInit(status.srcStatus.map(_.srcState).zip(hasIQWakeupGet.srcWakeupByIQWithoutCancel).zipWithIndex.map
      { case ((state, wakeupVec), srcIdx) =>\n252:         wakeupVec.asUInt.orR |
      state\n253:       }).asUInt.andR\n254:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 273-287
    context: "273:     exuSource.toExuOH(params).zip(allExuParams).map{case (oh,e)
      =>\n274:       if (e.isVfExeUnit) oh else false.B\n275:     }.reduce(_ || _)\n\
      276:   }\n277: \n278:   def EntryRegCommonConnect(common: CommonWireBundle,
      hasIQWakeup: Option[CommonIQWakeupBundle], validReg: Bool, entryUpdate: EntryBundle,
      entryReg: EntryBundle, status: Status, commonIn: CommonInBundle, isEnq: Boolean,
      isComp: Boolean)(implicit p: Parameters, params: IssueBlockParams) = {\n279:\
      \     val hasIQWakeupGet                                 = hasIQWakeup.getOrElse(0.U.asTypeOf(new
      CommonIQWakeupBundle))\n280:     val cancelBypassVec                       \
      \         = Wire(Vec(params.numRegSrc, Bool()))\n281:     val srcCancelByLoad\
      \                                = common.srcLoadCancelVec.asUInt.orR\n282:\
      \     val respIssueFail                                  = commonIn.issueResp.valid
      && RespType.isBlocked(commonIn.issueResp.bits.resp)\n283:     entryUpdate.status.robIdx\
      \                         := status.robIdx\n284:     entryUpdate.status.fuType\
      \                         := IQFuType.readFuType(status.fuType, params.getFuCfgs.map(_.fuType))\n\
      285:     entryUpdate.status.srcStatus.zip(status.srcStatus).zipWithIndex.foreach
      { case ((srcStatusNext, srcStatus), srcIdx) =>\n286:       val srcLoadCancel
      = common.srcLoadCancelVec(srcIdx)\n287:       val loadTransCancel = common.srcLoadTransCancelVec(srcIdx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 286-296
    context: "286:       val srcLoadCancel = common.srcLoadCancelVec(srcIdx)\n287:\
      \       val loadTransCancel = common.srcLoadTransCancelVec(srcIdx)\n288:   \
      \    val wakeupByWB = common.srcWakeupByWB(srcIdx)\n289:       val wakeupByIQ
      = hasIQWakeupGet.srcWakeupByIQ(srcIdx).asUInt.orR && !loadTransCancel\n290:\
      \       val wakeupByIQOH = hasIQWakeupGet.srcWakeupByIQ(srcIdx)\n291:      \
      \ val wakeupByMemIQ = wakeupByIQOH.zip(commonIn.wakeUpFromIQ).filter(_._2.bits.params.isMemExeUnit).map(_._1).fold(false.B)(_
      || _)\n292:       cancelBypassVec(srcIdx) := (if (isComp) Mux(hasIQWakeupGet.srcWakeupByIQWithoutCancel(srcIdx).asUInt.orR,
      loadTransCancel, srcLoadCancel)\n293:                                   else
      srcLoadCancel)\n294: \n295:       val ignoreOldVd = Wire(Bool())\n296:     \
      \  val vlWakeUpByIntWb = common.vlWakeupByIntWb"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 298-311
    context: "298:       val isDependOldVd = entryReg.payload.vpu.isDependOldVd\n\
      299:       val isWritePartVd = entryReg.payload.vpu.isWritePartVd\n300:    \
      \   val vta = entryReg.payload.vpu.vta\n301:       val vma = entryReg.payload.vpu.vma\n\
      302:       val vm = entryReg.payload.vpu.vm\n303:       val vlFromIntIsZero
      = commonIn.vlFromIntIsZero\n304:       val vlFromIntIsVlmax = commonIn.vlFromIntIsVlmax\n\
      305:       val vlFromVfIsZero = commonIn.vlFromVfIsZero\n306:       val vlFromVfIsVlmax
      = commonIn.vlFromVfIsVlmax\n307:       val vlIsVlmax = (vlFromIntIsVlmax &&
      vlWakeUpByIntWb) || (vlFromVfIsVlmax && vlWakeUpByVfWb)\n308:       val vlIsNonZero
      = (!vlFromIntIsZero && vlWakeUpByIntWb) || (!vlFromVfIsZero && vlWakeUpByVfWb)\n\
      309:       val ignoreTail = vlIsVlmax && (vm =/= 0.U || vma) && !isWritePartVd\n\
      310:       val ignoreWhole = (vm =/= 0.U || vma) && vta\n311:       val srcIsVec
      = SrcType.isVp(srcStatus.srcType)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 360-370
    context: "360:       } else {\n361:         srcStatusNext.srcLoadDependency  \
      \             := common.srcLoadDependencyNext(srcIdx)\n362:       }\n363: \n\
      364:       if (params.needReadRegCache) {\n365:         val wakeupSrcExuWriteRC
      = wakeupByIQOH.zip(commonIn.wakeUpFromIQ).filter(_._2.bits.params.needWriteRegCache)\n\
      366:         val wakeupRC    = wakeupSrcExuWriteRC.map(_._1).fold(false.B)(_
      || _) && SrcType.isXp(srcStatus.srcType)\n367:         val wakeupRCIdx = Mux1H(wakeupSrcExuWriteRC.map(_._1),
      wakeupSrcExuWriteRC.map(_._2.bits.rcDest.get))\n368:         val replaceRC \
      \  = wakeupSrcExuWriteRC.map(x => x._2.bits.rfWen && x._2.bits.rcDest.get ===
      srcStatus.regCacheIdx.get).fold(false.B)(_ || _)\n369: \n370:         srcStatusNext.useRegCache.get\
      \                 := srcStatus.useRegCache.get && !(srcLoadCancel || replaceRC)
      || wakeupRC"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 371-386
    context: "371:         srcStatusNext.regCacheIdx.get                 := Mux(wakeupRC,
      wakeupRCIdx, srcStatus.regCacheIdx.get)\n372:       }\n373:     }\n374:    \
      \ entryUpdate.status.blocked                        := false.B\n375:     entryUpdate.status.issued\
      \                         := MuxCase(status.issued, Seq(\n376:             \
      \                                              (commonIn.deqSel && !cancelBypassVec.asUInt.orR)\
      \  -> true.B,\n377:                                                        \
      \   (srcCancelByLoad || respIssueFail)                -> false.B,\n378:    \
      \                                                      ))\n379:     entryUpdate.status.firstIssue\
      \                     := commonIn.deqSel || status.firstIssue\n380:     entryUpdate.status.issueTimer\
      \                     := Mux(commonIn.deqSel, 0.U, Mux(status.issued, Mux(status.issueTimer
      === \"b11\".U, status.issueTimer, status.issueTimer + 1.U), \"b11\".U))\n381:\
      \     entryUpdate.status.deqPortIdx                     := Mux(commonIn.deqSel,
      commonIn.deqPortIdxWrite, Mux(status.issued, status.deqPortIdx, 0.U))\n382:\
      \     entryUpdate.imm.foreach(_                         := entryReg.imm.get)\n\
      383:     entryUpdate.payload                               := entryReg.payload\n\
      384:     if (params.isVecMemIQ) {\n385:       entryUpdate.status.vecMem.get
      := entryReg.status.vecMem.get\n386:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 384-394
    context: "384:     if (params.isVecMemIQ) {\n385:       entryUpdate.status.vecMem.get
      := entryReg.status.vecMem.get\n386:     }\n387:   }\n388: \n389:   def CommonOutConnect(commonOut:
      CommonOutBundle, common: CommonWireBundle, hasIQWakeup: Option[CommonIQWakeupBundle],
      validReg: Bool, entryUpdate: EntryBundle, entryReg: EntryBundle, status: Status,
      commonIn: CommonInBundle, isEnq: Boolean, isComp: Boolean)(implicit p: Parameters,
      params: IssueBlockParams) = {\n390:     val hasIQWakeupGet                 \
      \                = hasIQWakeup.getOrElse(0.U.asTypeOf(new CommonIQWakeupBundle))\n\
      391:     commonOut.valid                                   := validReg\n392:\
      \     commonOut.issued                                  := entryReg.status.issued\n\
      393:     commonOut.canIssue                                := (if (isComp) (common.canIssue
      || hasIQWakeupGet.canIssueBypass) && !common.flushed\n394:                 \
      \                                          else common.canIssue && !common.flushed)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 395-405
    context: "395:     commonOut.fuType                                  := IQFuType.readFuType(status.fuType,
      params.getFuCfgs.map(_.fuType)).asUInt\n396:     commonOut.robIdx          \
      \                        := status.robIdx\n397:     commonOut.dataSources.zipWithIndex.foreach{
      case (dataSourceOut, srcIdx) =>\n398:       val wakeupByIQWithoutCancel = hasIQWakeupGet.srcWakeupByIQWithoutCancel(srcIdx).asUInt.orR\n\
      399:       val wakeupByIQWithoutCancelOH = hasIQWakeupGet.srcWakeupByIQWithoutCancel(srcIdx)\n\
      400:       val isWakeupByMemIQ = wakeupByIQWithoutCancelOH.zip(commonIn.wakeUpFromIQ).filter(_._2.bits.params.isMemExeUnit).map(_._1).fold(false.B)(_
      || _)\n401:       val useRegCache = status.srcStatus(srcIdx).useRegCache.getOrElse(false.B)
      && status.srcStatus(srcIdx).dataSources.readReg\n402:       dataSourceOut.value\
      \                             := (if (isComp)\n403:                        \
      \                                     if (params.inVfSchd && params.readVfRf
      && params.hasWakeupFromMem) {\n404:                                        \
      \                       MuxCase(status.srcStatus(srcIdx).dataSources.value,
      Seq(\n405:                                                                 (wakeupByIQWithoutCancel
      && !isWakeupByMemIQ)  -> DataSource.forward,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 460-472
    context: "460: \n461:     commonOut.enqReady                                :=
      common.enqReady\n462:     commonOut.transEntry.valid                       \
      \ := validReg && !common.flushed && !status.issued\n463:     commonOut.transEntry.bits\
      \                         := entryUpdate\n464:     // debug\n465:     commonOut.entryInValid\
      \                            := commonIn.enq.valid\n466:     commonOut.entryOutDeqValid\
      \                        := validReg && (common.flushed || common.deqSuccess)\n\
      467:     commonOut.entryOutTransValid                      := validReg && commonIn.transSel
      && !(common.flushed || common.deqSuccess)\n468:     commonOut.perfWakeupByWB\
      \                          := common.srcWakeupByWB.zip(status.srcStatus).map{
      case (w, s) => w && SrcState.isBusy(s.srcState) && validReg }\n469:     if (params.hasIQWakeUp)
      {\n470:       commonOut.perfLdCancel.get                      := common.srcCancelVec.map(_
      && validReg)\n471:       commonOut.perfOg0Cancel.get                     :=
      hasIQWakeupGet.srcWakeupByIQButCancel.map(_.asUInt.orR && validReg)\n472:  \
      \     commonOut.perfWakeupByIQ.get                    := hasIQWakeupGet.srcWakeupByIQ.map(x
      => VecInit(x.map(_ && validReg)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/EntryBundles.scala
    lines: 475-486
    context: "475:     if (params.isVecMemIQ) {\n476:       commonOut.uopIdx.get \
      \                           := entryReg.payload.uopIdx\n477:     }\n478:   }\n\
      479: \n480:   def EntryVecMemConnect(commonIn: CommonInBundle, common: CommonWireBundle,
      validReg: Bool, entryReg: EntryBundle, entryRegNext: EntryBundle, entryUpdate:
      EntryBundle)(implicit p: Parameters, params: IssueBlockParams) = {\n481:   \
      \  val fromLsq                                        = commonIn.fromLsq.get\n\
      482:     val vecMemStatus                                   = entryReg.status.vecMem.get\n\
      483:     val vecMemStatusUpdate                             = entryUpdate.status.vecMem.get\n\
      484:     vecMemStatusUpdate                                := vecMemStatus\n\
      485: \n486:     val isFirstLoad = entryReg.status.vecMem.get.lqIdx === fromLsq.lqDeqPtr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/OthersEntry.scala
    lines: 15-29
    context: "15: import xiangshan.mem.Bundles.MemWaitUpdateReqBundle\n16: \n17: \n\
      18: class OthersEntryIO(implicit p: Parameters, params: IssueBlockParams) extends
      XSBundle {\n19:   //input\n20:   val commonIn        = new CommonInBundle\n\
      21:   //output\n22:   val commonOut       = new CommonOutBundle\n23: \n24: \
      \  def wakeup          = commonIn.wakeUpFromWB ++ commonIn.wakeUpFromIQ\n25:
      }\n26: \n27: class OthersEntry(isComp: Boolean)(implicit p: Parameters, params:
      IssueBlockParams) extends XSModule {\n28:   val io = IO(new OthersEntryIO)\n\
      29: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/OthersEntry.scala
    lines: 35-65
    context: "35:   //Reg\n36:   val validReg = GatedValidRegNext(common.validRegNext,
      false.B)\n37:   val entryReg = RegNext(entryRegNext)\n38: \n39:   //Wire\n40:\
      \   CommonWireConnect(common, hasWakeupIQ, validReg, entryReg.status, io.commonIn,
      false)\n41: \n42:   if (params.hasIQWakeUp) {\n43:     ShiftLoadDependency(hasWakeupIQ.get)\n\
      44:     CommonIQWakeupConnect(common, hasWakeupIQ.get, validReg, entryReg.status,
      io.commonIn, false)\n45:   }\n46: \n47:   when(io.commonIn.enq.valid) {\n48:\
      \     assert(common.enqReady, s\"${params.getIQName}'s OthersEntry is not ready
      when enq is valid\\n\")\n49:   }\n50: \n51:   when(io.commonIn.enq.valid) {\n\
      52:     entryRegNext := io.commonIn.enq.bits\n53:   }.otherwise {\n54:     entryRegNext
      := entryUpdate\n55:   }\n56: \n57:   EntryRegCommonConnect(common, hasWakeupIQ,
      validReg, entryUpdate, entryReg, entryReg.status, io.commonIn, false, isComp)\n\
      58: \n59:   //output\n60:   CommonOutConnect(io.commonOut, common, hasWakeupIQ,
      validReg, entryUpdate, entryReg, entryReg.status, io.commonIn, false, isComp)\n\
      61: }\n62: \n63: class OthersEntryVecMem(isComp: Boolean)(implicit p: Parameters,
      params: IssueBlockParams) extends OthersEntry(isComp)\n64:   with HasCircularQueuePtrHelper
      {\n65: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/OthersEntry.scala
    lines: 63-73
    context: "63: class OthersEntryVecMem(isComp: Boolean)(implicit p: Parameters,
      params: IssueBlockParams) extends OthersEntry(isComp)\n64:   with HasCircularQueuePtrHelper
      {\n65: \n66:   require(params.isVecMemIQ, \"OthersEntryVecMem can only be instance
      of VecMem IQ\")\n67: \n68:   EntryVecMemConnect(io.commonIn, common, validReg,
      entryReg, entryRegNext, entryUpdate)\n69: }\n70: \n71: object OthersEntry {\n\
      72:   def apply(isComp: Boolean)(implicit p: Parameters, iqParams: IssueBlockParams):
      OthersEntry = {\n73:     iqParams.schdType match {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 130-143
    context: "130:   val cancelBypassVec        = Wire(Vec(params.numEntries, Bool()))\n\
      131: \n132: \n133:   //enqEntries\n134:   enqEntries.zipWithIndex.foreach {
      case (enqEntry, entryIdx) =>\n135:     enqEntry.io.commonIn.enq            \
      \      := io.enq(entryIdx)\n136:     enqEntry.io.commonIn.transSel         \
      \    := (if (params.isAllComp || params.isAllSimp) enqCanTrans2Others.get &&
      othersTransSelVec.get(entryIdx).valid\n137:                                \
      \                   else enqCanTrans2Simp.get && simpTransSelVec.get(entryIdx).valid
      || enqCanTrans2Comp.get && compTransSelVec.get(entryIdx).valid)\n138:     EntriesConnect(enqEntry.io.commonIn,
      enqEntry.io.commonOut, entryIdx)\n139:     enqEntry.io.enqDelayIn1.wakeUpFromWB
      := io.wakeUpFromWBDelayed\n140:     enqEntry.io.enqDelayIn1.wakeUpFromIQ :=
      io.wakeUpFromIQDelayed\n141:     enqEntry.io.enqDelayIn1.srcLoadDependency :=
      RegEnable(VecInit(io.enq(entryIdx).bits.payload.srcLoadDependency.take(params.numRegSrc)),
      io.enq(entryIdx).valid)\n142:     enqEntry.io.enqDelayIn1.og0Cancel        \
      \ := RegNext(io.og0Cancel)\n143:     enqEntry.io.enqDelayIn1.ldCancel      \
      \    := RegNext(io.ldCancel)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 149-163
    context: "149:     enqEntry.io.enqDelayIn2.ldCancel          := DelayN(io.ldCancel,
      2)\n150:     enqEntryTransVec(entryIdx)                := enqEntry.io.commonOut.transEntry\n\
      151:   }\n152:   //othersEntries\n153:   othersEntries.zipWithIndex.foreach
      { case (othersEntry, entryIdx) =>\n154:     othersEntry.io.commonIn.enq    \
      \           := othersEntryEnqVec(entryIdx)\n155:     othersEntry.io.commonIn.transSel\
      \          := (if (params.hasCompAndSimp && (entryIdx < SimpEntryNum))\n156:\
      \                                                     io.simpEntryDeqSelVec.get.zip(simpCanTrans2Comp.get).map(x
      => x._1(entryIdx) && x._2).reduce(_ | _)\n157:                             \
      \                      else false.B)\n158:     EntriesConnect(othersEntry.io.commonIn,
      othersEntry.io.commonOut, entryIdx + EnqEntryNum)\n159:     othersEntryEnqReadyVec(entryIdx)\
      \          := othersEntry.io.commonOut.enqReady\n160:     if (params.hasCompAndSimp
      && (entryIdx < SimpEntryNum)) {\n161:       simpEntryTransVec.get(entryIdx)\
      \         := othersEntry.io.commonOut.transEntry\n162:     }\n163:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 248-259
    context: "248:     }\n249: \n250:     compEnqVec.get.zip(enqEntryTransVec).zip(io.simpEntryDeqSelVec.get).foreach
      { case ((compEnq, enqEntry), deqSel) =>\n251:       compEnq := Mux(enqCanTrans2Comp.get,
      enqEntry, Mux1H(deqSel, simpEntryTransVec.get))\n252:     }\n253:     compEntryEnqVec.zipWithIndex.foreach
      { case (compEntryEnq, compIdx) =>\n254:       val compEnqOH = finalCompTransSelVec.get.map(_(compIdx))\n\
      255:       // shit Mux1H directly returns in(0) if the seq has only 1 elements\n\
      256:       if (compEnqOH.size == 1)\n257:         compEntryEnq := Mux(compEnqOH.head,
      compEnqVec.get.head, 0.U.asTypeOf(compEnqVec.get.head))\n258:       else\n259:\
      \         compEntryEnq := Mux1H(compEnqOH, compEnqVec.get)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/Entries.scala
    lines: 514-524
    context: "514:     }\n515:   }\n516: }\n517: \n518: class EntriesIO(implicit p:
      Parameters, params: IssueBlockParams) extends XSBundle {\n519:   val flush \
      \              = Flipped(ValidIO(new Redirect))\n520:   //enq\n521:   val enq\
      \                 = Vec(params.numEnq, Flipped(ValidIO(new EntryBundle)))\n\
      522:   val og0Resp             = Vec(params.numDeq, Flipped(ValidIO(new EntryDeqRespBundle)))\n\
      523:   val og1Resp             = Vec(params.numDeq, Flipped(ValidIO(new EntryDeqRespBundle)))\n\
      524:   val og2Resp             = OptionWrapper(params.needOg2Resp, Vec(params.numDeq,
      Flipped(ValidIO(new EntryDeqRespBundle))))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/WakeupQueue.scala
    lines: 25-35
    context: "25: \n26: class WakeupQueue(number: Int)(implicit p: Parameters) extends
      XSModule {\n27:   val io = IO(new Bundle {\n28:     val in  = Flipped(ValidIO(new
      MicroOp))\n29:     val out = ValidIO(new MicroOp)\n30:     val redirect = Flipped(ValidIO(new
      Redirect))\n31:   })\n32:   if (number < 0) {\n33:     io.out.valid := false.B\n\
      34:     io.out.bits := DontCare\n35:   } else if(number == 0) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/backend/issue/WakeupQueue.scala
    lines: 39-53
    context: "39:   } else {\n40:     val queue = Seq.fill(number)(RegInit(0.U.asTypeOf(new
      Bundle{\n41:       val valid = Bool()\n42:       val bits = new MicroOp\n43:\
      \     })))\n44:     queue(0).valid := io.in.valid && !io.in.bits.robIdx.needFlush(io.redirect)\n\
      45:     queue(0).bits  := io.in.bits\n46:     (0 until (number-1)).map{i =>\n\
      47:       queue(i+1) := queue(i)\n48:       queue(i+1).valid := queue(i).valid
      && !queue(i).bits.robIdx.needFlush(io.redirect)\n49:     }\n50:     io.out.valid
      := queue(number-1).valid\n51:     io.out.bits := queue(number-1).bits\n52: \
      \    for (i <- 0 until number) {\n53:       XSDebug(queue(i).valid, p\"BPQue(${i.U}):
      pc:${Hexadecimal(queue(i).bits.cf.pc)} robIdx:${queue(i).bits.robIdx}\" +"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 188-202
    context: "188:   val fpWen = Bool()\n189:   val vecWen = Bool()\n190:   val isXSTrap
      = Bool()\n191:   val noSpecExec = Bool() // wait forward\n192:   val blockBackward
      = Bool() // block backward\n193:   val flushPipe = Bool() // This inst will
      flush all the pipe when commit, like exception but can commit\n194:   val uopSplitType
      = UopSplitType()\n195:   val selImm = SelImm()\n196:   val imm = UInt(32.W)\n\
      197:   val commitType = CommitType()\n198:   val fpu = new FPUCtrlSignals\n\
      199:   val uopIdx = UopIdx()\n200:   val isMove = Bool()\n201:   val vm = Bool()\n\
      202:   val singleStep = Bool()"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 209-219
    context: "209:     isXSTrap, noSpecExec, blockBackward, flushPipe, canRobCompress,
      uopSplitType, selImm)\n210: \n211:   def decode(inst: UInt, table: Iterable[(BitPat,
      List[BitPat])]): CtrlSignals = {\n212:     val decoder = freechips.rocketchip.rocket.DecodeLogic(inst,
      XDecode.decodeDefault, table, EspressoMinimizer)\n213:     allSignals zip decoder
      foreach { case (s, d) => s := d }\n214:     commitType := DontCare\n215:   \
      \  this\n216:   }\n217: \n218:   def decode(bit: List[BitPat]): CtrlSignals
      = {\n219:     allSignals.zip(bit.map(bitPatToUInt(_))).foreach{ case (s, d)
      => s := d }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 298-308
    context: "298: \n299: class MicroOpRbExt(implicit p: Parameters) extends XSBundleWithMicroOp
      {\n300:   val flag = UInt(1.W)\n301: }\n302: \n303: class Redirect(implicit
      p: Parameters) extends XSBundle {\n304:   val isRVC = Bool()\n305:   val robIdx
      = new RobPtr\n306:   val ftqIdx = new FtqPtr\n307:   val ftqOffset = UInt(log2Up(PredictWidth).W)\n\
      308:   val level = RedirectLevel()"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 318-330
    context: "318:   val debugIsMemVio = Bool()\n319: \n320:   def flushItself() =
      RedirectLevel.flushItself(level)\n321: }\n322: \n323: object Redirect extends
      HasCircularQueuePtrHelper {\n324: \n325:   def selectOldestRedirect(xs: Seq[Valid[Redirect]]):
      Vec[Bool] = {\n326:     val compareVec = (0 until xs.length).map(i => (0 until
      i).map(j => isAfter(xs(j).bits.robIdx, xs(i).bits.robIdx)))\n327:     val resultOnehot
      = VecInit((0 until xs.length).map(i => Cat((0 until xs.length).map(j =>\n328:\
      \       (if (j < i) !xs(j).valid || compareVec(i)(j)\n329:       else if (j
      == i) xs(i).valid\n330:       else !xs(j).valid || !compareVec(j)(i))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 382-416
    context: "382:   val trapTarget = Output(UInt(VAddrBits.W))\n383:   val externalInterrupt
      = new ExternalInterruptIO\n384:   val interrupt = Output(Bool())\n385: }\n386:\
      \ \n387: class DiffCommitIO(implicit p: Parameters) extends XSBundle {\n388:\
      \   val isCommit = Bool()\n389:   val commitValid = Vec(CommitWidth * MaxUopSize,
      Bool())\n390: \n391:   val info = Vec(CommitWidth * MaxUopSize, new RabCommitInfo)\n\
      392: }\n393: \n394: class RobCommitInfo(implicit p: Parameters) extends RobCommitEntryBundle\n\
      395: \n396: class RobCommitIO(implicit p: Parameters) extends XSBundle {\n397:\
      \   val isCommit = Bool()\n398:   val commitValid = Vec(CommitWidth, Bool())\n\
      399: \n400:   val isWalk = Bool()\n401:   // valid bits optimized for walk\n\
      402:   val walkValid = Vec(CommitWidth, Bool())\n403: \n404:   val info = Vec(CommitWidth,
      new RobCommitInfo)\n405:   val robIdx = Vec(CommitWidth, new RobPtr)\n406: \n\
      407:   def hasWalkInstr: Bool = isWalk && walkValid.asUInt.orR\n408:   def hasCommitInstr:
      Bool = isCommit && commitValid.asUInt.orR\n409: }\n410: \n411: class RabCommitInfo(implicit
      p: Parameters) extends XSBundle {\n412:   val ldest = UInt(LogicRegsWidth.W)\n\
      413:   val pdest = UInt(PhyRegIdxWidth.W)\n414:   val rfWen = Bool()\n415: \
      \  val fpWen = Bool()\n416:   val vecWen = Bool()"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 417-439
    context: "417:   val v0Wen = Bool()\n418:   val vlWen = Bool()\n419:   val isMove
      = Bool()\n420: }\n421: \n422: class RabCommitIO(implicit p: Parameters) extends
      XSBundle {\n423:   val isCommit = Bool()\n424:   val commitValid = Vec(RabCommitWidth,
      Bool())\n425: \n426:   val isWalk = Bool()\n427:   // valid bits optimized for
      walk\n428:   val walkValid = Vec(RabCommitWidth, Bool())\n429: \n430:   val
      info = Vec(RabCommitWidth, new RabCommitInfo)\n431:   val robIdx = OptionWrapper(!env.FPGAPlatform,
      Vec(RabCommitWidth, new RobPtr))\n432: \n433:   def hasWalkInstr: Bool = isWalk
      && walkValid.asUInt.orR\n434:   def hasCommitInstr: Bool = isCommit && commitValid.asUInt.orR\n\
      435: }\n436: \n437: class SnapshotPort(implicit p: Parameters) extends XSBundle
      {\n438:   val snptEnq = Bool()\n439:   val snptDeq = Bool()"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/Bundle.scala
    lines: 549-559
    context: "549:   val priv = new Bundle {\n550:     val mxr = Bool()\n551:    \
      \ val sum = Bool()\n552:     val vmxr = Bool()\n553:     val vsum = Bool()\n\
      554:     val virt = Bool()\n555:     val virt_changed = Bool()\n556:     val
      spvp = UInt(1.W)\n557:     val imode = UInt(2.W)\n558:     val dmode = UInt(2.W)\n\
      559:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/XSCore.scala
    lines: 221-240
    context: "221:   memBlock.io.ooo_to_mem.loadFastImm := 0.U.asTypeOf(memBlock.io.ooo_to_mem.loadFastImm)\n\
      222:   memBlock.io.ooo_to_mem.loadFastFuOpType := 0.U.asTypeOf(memBlock.io.ooo_to_mem.loadFastFuOpType)\n\
      223: \n224:   memBlock.io.ooo_to_mem.sfence <> backend.io.mem.sfence\n225: \n\
      226:   memBlock.io.redirect := backend.io.mem.redirect\n227:   memBlock.io.ooo_to_mem.csrCtrl
      := backend.io.mem.csrCtrl\n228:   memBlock.io.ooo_to_mem.tlbCsr := backend.io.mem.tlbCsr\n\
      229:   memBlock.io.ooo_to_mem.lsqio.lcommit          := backend.io.mem.robLsqIO.lcommit\n\
      230:   memBlock.io.ooo_to_mem.lsqio.scommit          := backend.io.mem.robLsqIO.scommit\n\
      231:   memBlock.io.ooo_to_mem.lsqio.pendingMMIOld    := backend.io.mem.robLsqIO.pendingMMIOld\n\
      232:   memBlock.io.ooo_to_mem.lsqio.pendingld        := backend.io.mem.robLsqIO.pendingld\n\
      233:   memBlock.io.ooo_to_mem.lsqio.pendingst        := backend.io.mem.robLsqIO.pendingst\n\
      234:   memBlock.io.ooo_to_mem.lsqio.pendingVst       := backend.io.mem.robLsqIO.pendingVst\n\
      235:   memBlock.io.ooo_to_mem.lsqio.commit           := backend.io.mem.robLsqIO.commit\n\
      236:   memBlock.io.ooo_to_mem.lsqio.pendingPtr       := backend.io.mem.robLsqIO.pendingPtr\n\
      237:   memBlock.io.ooo_to_mem.lsqio.pendingPtrNext   := backend.io.mem.robLsqIO.pendingPtrNext\n\
      238:   memBlock.io.ooo_to_mem.isStoreException       := backend.io.mem.isStoreException\n\
      239:   memBlock.io.ooo_to_mem.isVlsException         := backend.io.mem.isVlsException\n\
      240: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 160-170
    context: "160:     def FMX_D_X    = \"b0_01_11\".U\n161:     def FMX_W_X    =
      \"b0_01_10\".U\n162:     def FMX_H_X   =  \"b0_01_01\".U\n163:   }\n164: \n\
      165:   object CommitType {\n166:     def NORMAL = \"b000\".U  // int/fp\n167:\
      \     def BRANCH = \"b001\".U  // branch\n168:     def LOAD   = \"b010\".U \
      \ // load\n169:     def STORE  = \"b011\".U  // store\n170: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 167-181
    context: "167:     def BRANCH = \"b001\".U  // branch\n168:     def LOAD   = \"\
      b010\".U  // load\n169:     def STORE  = \"b011\".U  // store\n170: \n171: \
      \    def apply() = UInt(3.W)\n172:     def isFused(commitType: UInt): Bool =
      commitType(2)\n173:     def isLoadStore(commitType: UInt): Bool = !isFused(commitType)
      && commitType(1)\n174:     def lsInstIsStore(commitType: UInt): Bool = commitType(0)\n\
      175:     def isStore(commitType: UInt): Bool = isLoadStore(commitType) && lsInstIsStore(commitType)\n\
      176:     def isBranch(commitType: UInt): Bool = commitType(0) && !commitType(1)
      && !isFused(commitType)\n177:   }\n178: \n179:   object RedirectLevel {\n180:\
      \     def flushAfter = \"b0\".U\n181:     def flush      = \"b1\".U"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 694-704
    context: "694:   }\n695: \n696:   object BTBtype {\n697:     def B = \"b00\".U\
      \  // branch\n698:     def J = \"b01\".U  // jump\n699:     def I = \"b10\"\
      .U  // indirect\n700:     def R = \"b11\".U  // return\n701: \n702:     def
      apply() = UInt(2.W)\n703:   }\n704: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 764-774
    context: "764:     }\n765:   }\n766: \n767:   object UopSplitType {\n768:    \
      \ def SCA_SIM          = \"b000000\".U //\n769:     def VSET             = \"\
      b010001\".U // dirty: vset\n770:     def VEC_VVV          = \"b010010\".U //
      VEC_VVV\n771:     def VEC_VXV          = \"b010011\".U // VEC_VXV\n772:    \
      \ def VEC_0XV          = \"b010100\".U // VEC_0XV\n773:     def VEC_VVW    \
      \      = \"b010101\".U // VEC_VVW\n774:     def VEC_WVW          = \"b010110\"\
      .U // VEC_WVW"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 796-806
    context: "796:     def VEC_RGATHEREI16  = \"b101111\".U // vrgatherei16.vv\n797:\
      \     def VEC_COMPRESS     = \"b110000\".U // vcompress.vm\n798:     def VEC_US_LDST\
      \      = \"b110001\".U // vector unit-strided load/store\n799:     def VEC_S_LDST\
      \       = \"b110010\".U // vector strided load/store\n800:     def VEC_I_LDST\
      \       = \"b110011\".U // vector indexed load/store\n801:     def VEC_US_FF_LD\
      \     = \"b110100\".U // vector unit-stride fault-only-first load\n802:    \
      \ def VEC_VFV          = \"b111000\".U // VEC_VFV\n803:     def VEC_VFW    \
      \      = \"b111001\".U // VEC_VFW\n804:     def VEC_WFW          = \"b111010\"\
      .U // VEC_WVW\n805:     def VEC_VFM          = \"b111011\".U // VEC_VFM\n806:\
      \     def VEC_VFRED        = \"b111100\".U // VEC_VFRED"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/package.scala
    lines: 884-894
    context: "884: \n885:     def getStoreFault = Seq(EX_SAM, EX_SAF, EX_SPF, EX_HWE)\n\
      886: \n887:     def priorities = Seq(\n888:       doubleTrap,\n889:       breakPoint,
      // TODO: different BP has different priority\n890:       instrPageFault,\n891:\
      \       instrGuestPageFault,\n892:       instrAccessFault,\n893:       illegalInstr,\n\
      894:       virtualInstr,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 427-437
    context: "427:     assert(UIntToOH(insertIdx) === insertVec)\n428:     val sameBlockInflightMask
      = genSameBlockInflightMask(reqptag)\n429:     (0 until StoreBufferSize).map(entryIdx
      => {\n430:       when(insertVec(entryIdx)){\n431:         stateVec(entryIdx).state_valid
      := true.B\n432:         stateVec(entryIdx).w_sameblock_inflight := sameBlockInflightMask.orR
      // set w_sameblock_inflight when a line is first allocated\n433:         when(sameBlockInflightMask.orR){\n\
      434:           waitInflightMask(entryIdx) := sameBlockInflightMask\n435:   \
      \      }\n436:         cohCount(entryIdx) := 0.U\n437:         // missqReplayCount(insertIdx)
      := 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 945-955
    context: "945:         val upperBits         = Mux(unaligned_start === 0.U &&
      unaligned_offset =/= 0.U,\n946:                                    (unaligned_offset
      << 3.U).asUInt - 1.U,\n947:                                    ((EEB + unaligned_offset)
      << 3.U).asUInt - 1.U)// unit-stride second write request\n948:         val splitMask\
      \         = UIntSlice(rawMask, upper, unaligned_start)(7,0)  // Byte\n949: \
      \        val splitData         = UIntSlice(rawData, upperBits, unaligned_start_bits)(63,0)
      // Double word\n950:         val storeCommit       = io.diffStore.pmaStore(i).fire
      && splitMask.orR && io.diffStore.pmaStore(i).bits.vecValid\n951:         //
      align with ref\n952:         val waddr             = Mux(unaligned_offset =/=
      0.U && rawAddr(3), ZeroExt(Cat(rawAddr(PAddrBits - 1, 3), 0.U(3.W)), 64), rawAddr)\n\
      953:         val wmask             = Mux(unaligned_offset =/= 0.U && rawAddr(3),
      0.U, splitMask << unaligned_offset)\n954:         val wdata             = Mux(unaligned_offset
      =/= 0.U && rawAddr(3), 0.U, (splitData & MaskExpand(splitMask)) << unaligned_offset_bits)\n\
      955: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 953-963
    context: "953:         val wmask             = Mux(unaligned_offset =/= 0.U &&
      rawAddr(3), 0.U, splitMask << unaligned_offset)\n954:         val wdata    \
      \         = Mux(unaligned_offset =/= 0.U && rawAddr(3), 0.U, (splitData & MaskExpand(splitMask))
      << unaligned_offset_bits)\n955: \n956:         difftestCommon.coreid := io.hartId\n\
      957:         difftestCommon.index  := (i*VecMemFLOWMaxNumber).U\n958:      \
      \   difftestCommon.valid  := storeCommit\n959:         difftestCommon.addr \
      \  := waddr\n960:         difftestCommon.data   := wdata\n961:         difftestCommon.mask\
      \   := wmask\n962:         difftestCommon.robidx := io.diffStore.diffInfo(i).uop.robIdx.value\n\
      963:         difftestCommon.pc     := io.diffStore.diffInfo(i).uop.pc"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 961-971
    context: "961:         difftestCommon.mask   := wmask\n962:         difftestCommon.robidx
      := io.diffStore.diffInfo(i).uop.robIdx.value\n963:         difftestCommon.pc\
      \     := io.diffStore.diffInfo(i).uop.pc\n964: \n965:       } .elsewhen (!isWline)
      {\n966:         val storeCommit       = io.diffStore.pmaStore(i).fire\n967:\
      \         val waddr             = ZeroExt(Cat(io.diffStore.pmaStore(i).bits.addr(PAddrBits
      - 1, 3), 0.U(3.W)), 64)\n968:         val sbufferMask       = shiftMaskToLow(io.diffStore.pmaStore(i).bits.addr,
      io.diffStore.pmaStore(i).bits.mask)\n969:         val sbufferData       = shiftDataToLow(io.diffStore.pmaStore(i).bits.addr,
      io.diffStore.pmaStore(i).bits.data)\n970:         val wmask             = sbufferMask\n\
      971:         val wdata             = sbufferData & MaskExpand(sbufferMask)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 970-980
    context: "970:         val wmask             = sbufferMask\n971:         val wdata\
      \             = sbufferData & MaskExpand(sbufferMask)\n972: \n973:         difftestCommon.coreid
      := io.hartId\n974:         difftestCommon.index  := (i*VecMemFLOWMaxNumber).U\n\
      975:         difftestCommon.valid  := storeCommit && io.diffStore.pmaStore(i).bits.vecValid\n\
      976:         difftestCommon.addr   := waddr\n977:         difftestCommon.data\
      \   := wdata\n978:         difftestCommon.mask   := wmask\n979:         difftestCommon.robidx
      := io.diffStore.diffInfo(i).uop.robIdx.value\n980:         difftestCommon.pc\
      \     := io.diffStore.diffInfo(i).uop.pc"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 982-992
    context: "982: \n983:       for (index <- 0 until WlineMaxNumber) {\n984:    \
      \     val difftest = DifftestModule(new DiffStoreEvent, delay = 2, dontCare
      = true)\n985:         diffStoreEventCount += 1\n986: \n987:         val storeCommit
      = io.diffStore.pmaStore(i).fire && io.diffStore.pmaStore(i).bits.vecValid\n\
      988:         val blockAddr = get_block_addr(io.diffStore.pmaStore(i).bits.addr)\n\
      989: \n990:         when (isWline) {\n991:           difftest.coreid := io.hartId\n\
      992:           difftest.index  := (i*VecMemFLOWMaxNumber + index).U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 988-998
    context: "988:         val blockAddr = get_block_addr(io.diffStore.pmaStore(i).bits.addr)\n\
      989: \n990:         when (isWline) {\n991:           difftest.coreid := io.hartId\n\
      992:           difftest.index  := (i*VecMemFLOWMaxNumber + index).U\n993:  \
      \         difftest.valid  := storeCommit\n994:           difftest.addr   :=
      blockAddr + (index.U << wordOffBits)\n995:           difftest.data   := io.diffStore.pmaStore(i).bits.data\n\
      996:           difftest.mask   := ((1 << wordBytes) - 1).U\n997:           difftest.robidx
      := io.diffStore.diffInfo(i).uop.robIdx.value\n998:           difftest.pc   \
      \  := io.diffStore.diffInfo(i).uop.pc"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 995-1005
    context: "995:           difftest.data   := io.diffStore.pmaStore(i).bits.data\n\
      996:           difftest.mask   := ((1 << wordBytes) - 1).U\n997:           difftest.robidx
      := io.diffStore.diffInfo(i).uop.robIdx.value\n998:           difftest.pc   \
      \  := io.diffStore.diffInfo(i).uop.pc\n999: \n1000:           assert(!storeCommit
      || (io.diffStore.pmaStore(i).bits.data === 0.U), \"wline only supports whole
      zero write now\")\n1001:         }\n1002:       }\n1003: \n1004:       // Only
      the interface used by the 'unit-store' and 'whole' vector store instr\n1005:\
      \       for (index <- 1 until VecMemFLOWMaxNumber) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 1016-1026
    context: "1016:           val shiftFlag   = shiftIndex(2,0).orR // Double word
      Flag\n1017:           val shiftBytes  = Mux(shiftFlag, shiftIndex(2,0), 0.U)\n\
      1018:           val shiftBits   = shiftBytes << 3.U\n1019:           val splitMask\
      \   = UIntSlice(rawMask, (EEB*(index+1).U - 1.U) + unaligned_offset, EEB*index.U
      + unaligned_offset)(7,0)  // Byte\n1020:           val splitData   = UIntSlice(rawData,
      (EEWBits*(index+1).U - 1.U) + unaligned_offset_bits, EEWBits*index.U + unaligned_offset_bits)(63,0)
      // Double word\n1021:           val storeCommit = io.diffStore.pmaStore(i).fire
      && splitMask.orR  && io.diffStore.pmaStore(i).bits.vecValid\n1022:         \
      \  val waddr       = Mux(unaligned_offset =/= 0.U && shiftIndex(3), Cat(rawAddr(PAddrBits
      - 1, 4),  0.U(4.W)),Cat(rawAddr(PAddrBits - 1, 4), Cat(shiftIndex(3), 0.U(3.W))))\n\
      1023:           val wmask       = Mux(unaligned_offset =/= 0.U && shiftIndex(3),
      0.U,splitMask << (shiftBytes + unaligned_offset))\n1024:           val wdata\
      \       = Mux(unaligned_offset =/= 0.U && shiftIndex(3), 0.U,(splitData & MaskExpand(splitMask))
      << (shiftBits.asUInt + unaligned_offset_bits))\n1025: \n1026:           difftest.coreid
      := io.hartId"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/sbuffer/Sbuffer.scala
    lines: 1023-1033
    context: "1023:           val wmask       = Mux(unaligned_offset =/= 0.U && shiftIndex(3),
      0.U,splitMask << (shiftBytes + unaligned_offset))\n1024:           val wdata\
      \       = Mux(unaligned_offset =/= 0.U && shiftIndex(3), 0.U,(splitData & MaskExpand(splitMask))
      << (shiftBits.asUInt + unaligned_offset_bits))\n1025: \n1026:           difftest.coreid
      := io.hartId\n1027:           difftest.index  := (i*VecMemFLOWMaxNumber+index).U\n\
      1028:           difftest.valid  := storeCommit\n1029:           difftest.addr\
      \   := waddr\n1030:           difftest.data   := wdata\n1031:           difftest.mask\
      \   := wmask\n1032:           difftest.robidx := io.diffStore.diffInfo(i).uop.robIdx.value\n\
      1033:           difftest.pc     := io.diffStore.diffInfo(i).uop.pc"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/Bundles.scala
    lines: 161-171
    context: "161:     // load inst replay informations\n162:     val rep_info = new
      LoadToLsqReplayIO\n163:     val nc_with_data = Bool() // nc access with data\n\
      164:     // queue entry data, except flag bits, will be updated if writeQueue
      is true,\n165:     // valid bit in LqWriteBundle will be ignored\n166:     val
      data_wen_dup = Vec(6, Bool()) // dirty reg dup\n167: \n168:     def fromLsPipelineBundle(input:
      LsPipelineBundle, latch: Boolean = false, enable: Bool = true.B) = {\n169: \
      \      val inputReg = latch match {\n170:         case true   => RegEnable(input,
      enable)\n171:         case false  => input"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/Bundles.scala
    lines: 378-388
    context: "378: }\n379: \n380: // for vector difftest store event\n381: class ToSbufferDifftestInfoBundle(implicit
      p: Parameters) extends XSBundle{\n382:   val uop        = new DynInst\n383:\
      \   val start      = UInt(log2Up(XLEN).W) // indicate first byte position of
      first unit-stride's element when unaligned\n384:   val offset     = UInt(log2Up(XLEN).W)
      // indicate byte offset of unit-stride's element when unaligned\n385: }\n386:\
      \ \n387: \n388: class VecMissalignedDebugBundle (implicit p: Parameters) extends
      XSBundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/Bundles.scala
    lines: 384-394
    context: "384:   val offset     = UInt(log2Up(XLEN).W) // indicate byte offset
      of unit-stride's element when unaligned\n385: }\n386: \n387: \n388: class VecMissalignedDebugBundle
      (implicit p: Parameters) extends XSBundle {\n389:   val start      = UInt(log2Up(XLEN).W)
      // indicate first byte position of first unit-stride's element when unaligned\n\
      390:   val offset     = UInt(log2Up(XLEN).W) // indicate byte offset of unit-stride's
      element when unaligned\n391: }\n392: \n393: class DiffStoreIO(implicit p: Parameters)
      extends XSBundle{\n394:   val diffInfo = Vec(EnsbufferWidth, Flipped(new ToSbufferDifftestInfoBundle()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 35-45
    context: "35:   with HasLoadHelper\n36:   with HasPerfEvents\n37: {\n38:   val
      io = IO(new Bundle() {\n39:     // control\n40:     val redirect = Flipped(ValidIO(new
      Redirect))\n41: \n42:     // violation query\n43:     val query = Vec(LoadPipelineWidth,
      Flipped(new LoadNukeQueryIO))\n44: \n45:     // from store unit s1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 44-54
    context: "44: \n45:     // from store unit s1\n46:     val storeIn = Vec(StorePipelineWidth,
      Flipped(Valid(new LsPipelineBundle)))\n47: \n48:     // global rollback flush\n\
      49:     val rollback = Vec(StorePipelineWidth,Output(Valid(new Redirect)))\n\
      50: \n51:     // to LoadQueueReplay\n52:     val stAddrReadySqPtr = Input(new
      SqPtr)\n53:     val stIssuePtr       = Input(new SqPtr)\n54:     val lqFull\
      \           = Output(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 112-122
    context: "112:   ))\n113:   freeList.io := DontCare\n114: \n115:   //  LoadQueueRAW
      enqueue\n116:   val canEnqueue = io.query.map(_.req.valid)\n117:   val cancelEnqueue
      = io.query.map(_.req.bits.uop.robIdx.needFlush(io.redirect))\n118:   val allAddrCheck
      = io.stIssuePtr === io.stAddrReadySqPtr\n119:   val hasAddrInvalidStore = io.query.map(_.req.bits.uop.sqIdx).map(sqIdx
      => {\n120:     Mux(!allAddrCheck, isBefore(io.stAddrReadySqPtr, sqIdx), false.B)\n\
      121:   })\n122:   val needEnqueue = canEnqueue.zip(hasAddrInvalidStore).zip(cancelEnqueue).map
      { case ((v, r), c) => v && r && !c }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 180-190
    context: "180: \n181:   // when the stores that \"older than\" current load address
      were ready.\n182:   // current load will be released.\n183:   for (i <- 0 until
      LoadQueueRAWSize) {\n184:     val deqNotBlock = Mux(!allAddrCheck, !isBefore(io.stAddrReadySqPtr,
      uop(i).sqIdx), true.B)\n185:     val needCancel = uop(i).robIdx.needFlush(io.redirect)\n\
      186: \n187:     when (allocated(i) && (deqNotBlock || needCancel)) {\n188: \
      \      allocated(i) := false.B\n189:       freeMaskVec(i) := true.B\n190:  \
      \   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 272-282
    context: "272:     // select logic\n273:     if (valid.length <= SelectGroupSize)
      {\n274:       val (selValid, selBits) = selectPartialOldest(valid, bits)\n275:\
      \       val selValidNext = GatedValidRegNext(selValid(0))\n276:       val selBitsNext
      = RegEnable(selBits(0), selValid(0))\n277:       (Seq(selValidNext && !selBitsNext.uop.robIdx.needFlush(RegNext(io.redirect))),
      Seq(selBitsNext))\n278:     } else {\n279:       val select = (0 until numSelectGroups).map(g
      => {\n280:         val (selValid, selBits) = selectPartialOldest(selectValidGroups(g),
      selectBitsGroups(g))\n281:         val selValidNext = RegNext(selValid(0))\n\
      282:         val selBitsNext = RegEnable(selBits(0), selValid(0))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 278-288
    context: "278:     } else {\n279:       val select = (0 until numSelectGroups).map(g
      => {\n280:         val (selValid, selBits) = selectPartialOldest(selectValidGroups(g),
      selectBitsGroups(g))\n281:         val selValidNext = RegNext(selValid(0))\n\
      282:         val selBitsNext = RegEnable(selBits(0), selValid(0))\n283:    \
      \     (selValidNext && !selBitsNext.uop.robIdx.needFlush(io.redirect) && !selBitsNext.uop.robIdx.needFlush(RegNext(io.redirect)),
      selBitsNext)\n284:       })\n285:       selectOldest(select.map(_._1), select.map(_._2))\n\
      286:     }\n287:   }\n288: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 293-303
    context: "293:     paddrModule.io.violationCheckLine.get(i) := storeIn(i).bits.wlineflag\n\
      294:     maskModule.io.violationMdata(i) := RegEnable(storeIn(i).bits.mask,
      storeIn(i).valid)\n295: \n296:     val addrMaskMatch = paddrModule.io.violationMmask(i).asUInt
      & maskModule.io.violationMmask(i).asUInt\n297:     val entryNeedCheck = GatedValidRegNext(VecInit((0
      until LoadQueueRAWSize).map(j => {\n298:       allocated(j) && storeIn(i).valid
      && isAfter(uop(j).robIdx, storeIn(i).bits.uop.robIdx) && datavalid(j) && !uop(j).robIdx.needFlush(io.redirect)\n\
      299:     })))\n300:     val lqViolationSelVec = VecInit((0 until LoadQueueRAWSize).map(j
      => {\n301:       addrMaskMatch(j) && entryNeedCheck(j)\n302:     }))\n303: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAW.scala
    lines: 342-364
    context: "342:   // Thus, here if last cycle's robIdx equals to this cycle's robIdx,
      it still triggers the redirect.\n343: \n344:   // select uop in parallel\n345:\
      \ \n346:   val allRedirect = (0 until StorePipelineWidth).map(i => {\n347: \
      \    val redirect = Wire(Valid(new Redirect))\n348:     redirect.valid := rollbackLqWb(i).valid\n\
      349:     redirect.bits             := DontCare\n350:     redirect.bits.isRVC\
      \       := rollbackLqWb(i).bits.preDecodeInfo.isRVC\n351:     redirect.bits.robIdx\
      \      := rollbackLqWb(i).bits.robIdx\n352:     redirect.bits.ftqIdx      :=
      rollbackLqWb(i).bits.ftqPtr\n353:     redirect.bits.ftqOffset   := rollbackLqWb(i).bits.ftqOffset\n\
      354:     redirect.bits.stFtqIdx    := stFtqIdx(i)\n355:     redirect.bits.stFtqOffset
      := stFtqOffset(i)\n356:     redirect.bits.level       := RedirectLevel.flush\n\
      357:     redirect.bits.cfiUpdate.target := rollbackLqWb(i).bits.pc\n358:   \
      \  redirect.bits.debug_runahead_checkpoint_id := rollbackLqWb(i).bits.debugInfo.runahead_checkpoint_id\n\
      359:     redirect\n360:   })\n361:   io.rollback := allRedirect\n362: \n363:\
      \   // perf cnt\n364:   val canEnqCount = PopCount(io.query.map(_.req.fire))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 34-44
    context: "34:   with HasCircularQueuePtrHelper\n35:   with HasLoadHelper\n36:
      {\n37:   val io = IO(new Bundle() {\n38:     /* control */\n39:     val redirect
      = Flipped(Valid(new Redirect))\n40:     // redirect flush\n41:     val flush
      = Output(Bool())\n42:     // mmio commit\n43:     val rob = Flipped(new RobLsqIO)\n\
      44:     // mmio select"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 78-88
    context: "78:     *\n79:     * 1. direct flush during idle\n80:     * 2. otherwise
      delayed flush until receiving uncache resp\n81:     */\n82:   val needFlushReg
      = RegInit(false.B)\n83:   val needFlush = req_valid && req.uop.robIdx.needFlush(io.redirect)\n\
      84:   val flush = WireInit(false.B)\n85:   when(flush){\n86:     needFlushReg
      := false.B\n87:   }.elsewhen(needFlush){\n88:     needFlushReg := true.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 259-269
    context: "259:   with HasCircularQueuePtrHelper\n260:   with HasMemBlockParameters\n\
      261: {\n262:   val io = IO(new Bundle() {\n263:     /* control */\n264:    \
      \ val redirect = Flipped(Valid(new Redirect))\n265:     // mmio commit\n266:\
      \     val rob = Flipped(new RobLsqIO)\n267: \n268:     /* transaction */\n269:\
      \     // enqueue: from ldu s3"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 276-286
    context: "276:     // <=>uncache\n277:     val uncache = new UncacheWordIO\n278:\
      \ \n279:     /* except */\n280:     // rollback from frontend when buffer is
      full\n281:     val rollback = Output(Valid(new Redirect))\n282:     // exception
      generated by outer bus\n283:     val exception = Valid(new LqWriteBundle)\n\
      284:   })\n285: \n286:   /******************************************************************"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 341-352
    context: "341: \n342:   // s2: enqueue\n343:   val s2_req = (0 until LoadPipelineWidth).map(i
      => {RegEnable(s1_req(i), s1_valid(i))})\n344:   val s2_valid = (0 until LoadPipelineWidth).map(i
      => {\n345:     RegNext(s1_valid(i)) &&\n346:     !s2_req(i).uop.robIdx.needFlush(RegNext(io.redirect))
      &&\n347:     !s2_req(i).uop.robIdx.needFlush(io.redirect)\n348:   })\n349: \
      \  val s2_has_exception = s2_req.map(x => ExceptionNO.selectByFu(x.uop.exceptionVec,
      LduCfg).asUInt.orR)\n350:   val s2_need_replay = s2_req.map(_.rep_info.need_rep)\n\
      351: \n352:   for (w <- 0 until LoadPipelineWidth) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 419-429
    context: "419:           e.io.req.bits := s2_req(w)\n420:         }\n421:    \
      \   }\n422: \n423:       // control\n424:       e.io.redirect <> io.redirect\n\
      425:       e.io.rob <> io.rob\n426: \n427:       // uncache req, writeback\n\
      428:       when (e.io.mmioSelect) {\n429:         mmioReq.valid := e.io.uncache.req.valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 536-546
    context: "536:    * stage 2:               lq\n537:    *                     \
      \   |\n538:    *                     rollback req\n539:    *\n540:    ******************************************************************/\n\
      541:   def selectOldestRedirect(xs: Seq[Valid[Redirect]]): Vec[Bool] = {\n542:\
      \     val compareVec = (0 until xs.length).map(i => (0 until i).map(j => isAfter(xs(j).bits.robIdx,
      xs(i).bits.robIdx)))\n543:     val resultOnehot = VecInit((0 until xs.length).map(i
      => Cat((0 until xs.length).map(j =>\n544:       (if (j < i) !xs(j).valid ||
      compareVec(i)(j)\n545:       else if (j == i) xs(i).valid\n546:       else !xs(j).valid
      || !compareVec(j)(i))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueUncache.scala
    lines: 550-581
    context: "550:   val reqNeedCheck = VecInit((0 until LoadPipelineWidth).map(w
      =>\n551:     s2_enqueue(w) && !s2_enqValidVec(w)\n552:   ))\n553:   val reqSelUops
      = VecInit(s2_req.map(_.uop))\n554:   val allRedirect = (0 until LoadPipelineWidth).map(i
      => {\n555:     val redirect = Wire(Valid(new Redirect))\n556:     redirect.valid
      := reqNeedCheck(i)\n557:     redirect.bits             := DontCare\n558:   \
      \  redirect.bits.isRVC       := reqSelUops(i).preDecodeInfo.isRVC\n559:    \
      \ redirect.bits.robIdx      := reqSelUops(i).robIdx\n560:     redirect.bits.ftqIdx\
      \      := reqSelUops(i).ftqPtr\n561:     redirect.bits.ftqOffset   := reqSelUops(i).ftqOffset\n\
      562:     redirect.bits.level       := RedirectLevel.flush\n563:     redirect.bits.cfiUpdate.target
      := reqSelUops(i).pc // TODO: check if need pc\n564:     redirect.bits.debug_runahead_checkpoint_id
      := reqSelUops(i).debugInfo.runahead_checkpoint_id\n565:     redirect\n566: \
      \  })\n567:   val oldestOneHot = selectOldestRedirect(allRedirect)\n568:   val
      oldestRedirect = Mux1H(oldestOneHot, allRedirect)\n569:   val lastCycleRedirect
      = Wire(Valid(new Redirect))\n570:   lastCycleRedirect.valid := RegNext(io.redirect.valid)\n\
      571:   lastCycleRedirect.bits := RegEnable(io.redirect.bits, io.redirect.valid)\n\
      572:   val lastLastCycleRedirect = Wire(Valid(new Redirect))\n573:   lastLastCycleRedirect.valid
      := RegNext(lastCycleRedirect.valid)\n574:   lastLastCycleRedirect.bits := RegEnable(lastCycleRedirect.bits,
      lastCycleRedirect.valid)\n575:   io.rollback.valid := GatedValidRegNext(oldestRedirect.valid
      &&\n576:                       !oldestRedirect.bits.robIdx.needFlush(io.redirect)
      &&\n577:                       !oldestRedirect.bits.robIdx.needFlush(lastCycleRedirect)
      &&\n578:                       !oldestRedirect.bits.robIdx.needFlush(lastLastCycleRedirect))\n\
      579:   io.rollback.bits := RegEnable(oldestRedirect.bits, oldestRedirect.valid)\n\
      580: \n581: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 65-75
    context: "65: \n66: // Load / Store Queue Wrapper for XiangShan Out of Order LSU\n\
      67: class LsqWrapper(implicit p: Parameters) extends XSModule with HasDCacheParameters
      with HasPerfEvents {\n68:   val io = IO(new Bundle() {\n69:     val hartId =
      Input(UInt(hartIdLen.W))\n70:     val brqRedirect = Flipped(ValidIO(new Redirect))\n\
      71:     val stvecFeedback = Vec(VecStorePipelineWidth, Flipped(ValidIO(new FeedbackToLsqIO)))\n\
      72:     val ldvecFeedback = Vec(VecLoadPipelineWidth, Flipped(ValidIO(new FeedbackToLsqIO)))\n\
      73:     val enq = new LsqEnqIO\n74:     val ldu = new Bundle() {\n75:      \
      \   val stld_nuke_query = Vec(LoadPipelineWidth, Flipped(new LoadNukeQueryIO))
      // from load_s2"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 89-100
    context: "89:     val ncOut = Vec(LoadPipelineWidth, DecoupledIO(new LsPipelineBundle))\n\
      90:     val replay = Vec(LoadPipelineWidth, Decoupled(new LsPipelineBundle))\n\
      91:     val sbuffer = Vec(EnsbufferWidth, Decoupled(new DCacheWordReqWithVaddrAndPfFlag))\n\
      92:     val forward = Vec(LoadPipelineWidth, Flipped(new PipeLoadForwardQueryIO))\n\
      93:     val rob = Flipped(new RobLsqIO)\n94:     val nuke_rollback = Vec(StorePipelineWidth,
      Output(Valid(new Redirect)))\n95:     val nack_rollback = Vec(1, Output(Valid(new
      Redirect))) // uncahce\n96:     val release = Flipped(Valid(new Release))\n\
      97:    // val refill = Flipped(Valid(new Refill))\n98:     val tl_d_channel\
      \  = Input(new DcacheToLduForwardIO)\n99:     val maControl     = Flipped(new
      StoreMaBufToSqControlIO)\n100:     val uncacheOutstanding = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 107-117
    context: "107:     val lq_rep_full = Output(Bool())\n108:     val sqFull = Output(Bool())\n\
      109:     val lqFull = Output(Bool())\n110:     val sqCancelCnt = Output(UInt(log2Up(StoreQueueSize+1).W))\n\
      111:     val lqCancelCnt = Output(UInt(log2Up(VirtualLoadQueueSize+1).W))\n\
      112:     val lqDeq = Output(UInt(log2Up(CommitWidth + 1).W))\n113:     val sqDeq
      = Output(UInt(log2Ceil(EnsbufferWidth + 1).W))\n114:     val lqCanAccept = Output(Bool())\n\
      115:     val sqCanAccept = Output(Bool())\n116:     val lqDeqPtr = Output(new
      LqPtr)\n117:     val sqDeqPtr = Output(new SqPtr)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 200-210
    context: "200:   io.diffStore := storeQueue.io.diffStore\n201: \n202:   /* <-------
      DANGEROUS: Don't change sequence here ! -------> */\n203: \n204:   //  load
      queue wiring\n205:   loadQueue.io.redirect            <> io.brqRedirect\n206:\
      \   loadQueue.io.vecFeedback           <> io.ldvecFeedback\n207:   loadQueue.io.ldu\
      \                 <> io.ldu\n208:   loadQueue.io.ldout               <> io.ldout\n\
      209:   loadQueue.io.ld_raw_data         <> io.ld_raw_data\n210:   loadQueue.io.ncOut\
      \               <> io.ncOut"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 322-338
    context: "322: }\n323: \n324: class LsqEnqCtrl(implicit p: Parameters) extends
      XSModule\n325:   with HasVLSUParameters  {\n326:   val io = IO(new Bundle {\n\
      327:     val redirect = Flipped(ValidIO(new Redirect))\n328:     // to dispatch\n\
      329:     val enq = new LsqEnqIO\n330:     // from `memBlock.io.lqDeq\n331: \
      \    val lcommit = Input(UInt(log2Up(CommitWidth + 1).W))\n332:     // from
      `memBlock.io.sqDeq`\n333:     val scommit = Input(UInt(log2Ceil(EnsbufferWidth
      + 1).W))\n334:     // from/tp lsq\n335:     val lqCancelCnt = Input(UInt(log2Up(VirtualLoadQueueSize
      + 1).W))\n336:     val sqCancelCnt = Input(UInt(log2Up(StoreQueueSize + 1).W))\n\
      337:     val lqFreeCount = Output(UInt(log2Up(VirtualLoadQueueSize + 1).W))\n\
      338:     val sqFreeCount = Output(UInt(log2Up(StoreQueueSize + 1).W))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 363-373
    context: "363:   io.lqFreeCount  := lqCounter\n364:   io.sqFreeCount  := sqCounter\n\
      365:   // How to update ptr and counter:\n366:   // (1) by default, updated
      according to enq/commit\n367:   // (2) when redirect and dispatch queue is empty,
      update according to lsq\n368:   val t1_redirect = RegNext(io.redirect.valid)\n\
      369:   val t2_redirect = RegNext(t1_redirect)\n370:   val t2_update = t2_redirect
      && !VecInit(io.enq.needAlloc.map(_.orR)).asUInt.orR\n371:   val t3_update =
      RegNext(t2_update)\n372:   val t3_lqCancelCnt = GatedRegNext(io.lqCancelCnt)\n\
      373:   val t3_sqCancelCnt = GatedRegNext(io.sqCancelCnt)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 371-391
    context: "371:   val t3_update = RegNext(t2_update)\n372:   val t3_lqCancelCnt
      = GatedRegNext(io.lqCancelCnt)\n373:   val t3_sqCancelCnt = GatedRegNext(io.sqCancelCnt)\n\
      374:   when (t3_update) {\n375:     lqPtr := lqPtr - t3_lqCancelCnt\n376:  \
      \   lqCounter := lqCounter + io.lcommit + t3_lqCancelCnt\n377:     sqPtr :=
      sqPtr - t3_sqCancelCnt\n378:     sqCounter := sqCounter + io.scommit + t3_sqCancelCnt\n\
      379:   }.elsewhen (!io.redirect.valid && io.enq.canAccept) {\n380:     lqPtr
      := lqPtr + lqAllocNumber\n381:     lqCounter := lqCounter + io.lcommit - lqAllocNumber\n\
      382:     sqPtr := sqPtr + sqAllocNumber\n383:     sqCounter := sqCounter + io.scommit
      - sqAllocNumber\n384:   }.otherwise {\n385:     lqCounter := lqCounter + io.lcommit\n\
      386:     sqCounter := sqCounter + io.scommit\n387:   }\n388: \n389: \n390: \
      \  //TODO MaxAllocate and width of lqOffset/sqOffset needs to be discussed\n\
      391:   val lqMaxAllocate = LSQLdEnqWidth"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LSQWrapper.scala
    lines: 408-418
    context: "408:   }\n409: \n410:   io.enqLsq.needAlloc := RegNext(io.enq.needAlloc)\n\
      411:   io.enqLsq.iqAccept := RegNext(io.enq.iqAccept)\n412:   io.enqLsq.req.zip(io.enq.req).zip(io.enq.resp).foreach{
      case ((toLsq, enq), resp) =>\n413:     val do_enq = enq.valid && !io.redirect.valid
      && io.enq.canAccept\n414:     toLsq.valid := RegNext(do_enq)\n415:     toLsq.bits
      := RegEnable(enq.bits, do_enq)\n416:     toLsq.bits.lqIdx := RegEnable(resp.lqIdx,
      do_enq)\n417:     toLsq.bits.sqIdx := RegEnable(resp.sqIdx, do_enq)\n418:  \
      \ }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 37-48
    context: "37:   with HasLoadHelper\n38:   with HasPerfEvents\n39:   with HasVLSUParameters
      {\n40:   val io = IO(new Bundle() {\n41:     // control\n42:     val redirect\
      \    = Flipped(Valid(new Redirect))\n43:     val vecCommit   = Vec(VecLoadPipelineWidth,
      Flipped(ValidIO(new FeedbackToLsqIO)))\n44:     // from dispatch\n45:     val
      enq         = new LqEnqIO\n46:     // from ldu s3\n47:     val ldin        =
      Vec(LoadPipelineWidth, Flipped(DecoupledIO(new LqWriteBundle)))\n48:     //
      to LoadQueueReplay and LoadQueueRAR"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 49-59
    context: "49:     val ldWbPtr     = Output(new LqPtr)\n50:     // global\n51:\
      \     val lqFull      = Output(Bool())\n52:     val lqEmpty     = Output(Bool())\n\
      53:     // to dispatch\n54:     val lqDeq       = Output(UInt(log2Up(CommitWidth
      + 1).W))\n55:     val lqCancelCnt = Output(UInt(log2Up(VirtualLoadQueueSize+1).W))\n\
      56:     // for topdown\n57:     val noUopsIssued = Input(Bool())\n58:   })\n\
      59: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 67-77
    context: "67:   //  Flags       : load flags\n68:   val allocated = RegInit(VecInit(List.fill(VirtualLoadQueueSize)(false.B)))
      // The control signals need to explicitly indicate the initial value\n69:  \
      \ val robIdx = Reg(Vec(VirtualLoadQueueSize, new RobPtr))\n70:   val uopIdx
      = Reg(Vec(VirtualLoadQueueSize, UopIdx()))\n71:   val isvec = RegInit(VecInit(List.fill(VirtualLoadQueueSize)(false.B)))
      // vector load flow\n72:   val committed = Reg(Vec(VirtualLoadQueueSize, Bool()))\n\
      73: \n74:   /**\n75:    * used for debug\n76:    */\n77:   val debug_mmio =
      Reg(Vec(VirtualLoadQueueSize, Bool())) // mmio: inst is an mmio inst"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 84-94
    context: "84:   val deqPtrNext = Wire(new LqPtr)\n85: \n86:   /**\n87:    * update
      pointer\n88:    */\n89:   val lastCycleRedirect = RegNext(io.redirect)\n90:\
      \   val lastLastCycleRedirect = RegNext(lastCycleRedirect)\n91: \n92:   val
      validCount = distanceBetween(enqPtrExt(0), deqPtr)\n93:   val allowEnqueue =
      validCount <= (VirtualLoadQueueSize - LSQLdEnqWidth).U\n94:   val canEnqueue
      = io.enq.req.map(_.valid)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 92-106
    context: "92:   val validCount = distanceBetween(enqPtrExt(0), deqPtr)\n93:  \
      \ val allowEnqueue = validCount <= (VirtualLoadQueueSize - LSQLdEnqWidth).U\n\
      94:   val canEnqueue = io.enq.req.map(_.valid)\n95:   val vLoadFlow = io.enq.req.map(_.bits.numLsElem.asTypeOf(UInt(elemIdxBits.W)))\n\
      96:   val needCancel = WireInit(VecInit((0 until VirtualLoadQueueSize).map(i
      => {\n97:     robIdx(i).needFlush(io.redirect) && allocated(i)\n98:   })))\n\
      99:   val lastNeedCancel = GatedValidRegNext(needCancel)\n100:   val enqCancel
      = canEnqueue.zip(io.enq.req).map{case (v , x) =>\n101:     v && x.bits.robIdx.needFlush(io.redirect)\n\
      102:   }\n103:   val enqCancelNum = enqCancel.zip(vLoadFlow).map{case (v, flow)
      =>\n104:     Mux(v, flow, 0.U)\n105:   }\n106:   val lastEnqCancel = GatedRegNext(enqCancelNum.reduce(_
      + _))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 129-148
    context: "129:     enqPtrExtNext := VecInit((0 until io.enq.req.length).map(i
      => deqPtrNext + i.U))\n130:   }\n131:   enqPtrExt := enqPtrExtNext\n132: \n\
      133:   // update dequeue pointer\n134:   val DeqPtrMoveStride = CommitWidth\n\
      135:   require(DeqPtrMoveStride == CommitWidth, \"DeqPtrMoveStride must be equal
      to CommitWidth!\")\n136:   val deqLookupVec = VecInit((0 until DeqPtrMoveStride).map(deqPtr
      + _.U))\n137:   val deqLookup = VecInit(deqLookupVec.map(ptr => allocated(ptr.value)
      && committed(ptr.value) && ptr =/= enqPtrExt(0)))\n138:   val deqInSameRedirectCycle
      = VecInit(deqLookupVec.map(ptr => needCancel(ptr.value)))\n139:   // make chisel
      happy\n140:   val deqCountMask = Wire(UInt(DeqPtrMoveStride.W))\n141:   deqCountMask
      := deqLookup.asUInt & (~deqInSameRedirectCycle.asUInt).asUInt\n142:   val commitCount
      = PopCount(PriorityEncoderOH(~deqCountMask) - 1.U)\n143:   val lastCommitCount
      = GatedRegNext(commitCount)\n144: \n145:   // update deqPtr\n146:   // cycle
      1: generate deqPtrNext\n147:   // cycle 2: update deqPtr\n148:   val deqPtrUpdateEna
      = lastCommitCount =/= 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 179-189
    context: "179:     when (entryCanEnq) {\n180:       allocated(i) := true.B\n181:\
      \       robIdx(i) := selectBits.robIdx\n182:       uopIdx(i) := selectBits.uopIdx\n\
      183:       isvec(i) :=  FuType.isVLoad(selectBits.fuType)\n184:       committed(i)
      := false.B\n185: \n186:       debug_mmio(i) := false.B\n187:       debug_paddr(i)
      := 0.U\n188:     }\n189:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 200-227
    context: "200:     * Load commits\n201:     *\n202:     * When load commited,
      mark it as !allocated and move deqPtr forward.\n203:     */\n204:   (0 until
      DeqPtrMoveStride).map(i => {\n205:     when (commitCount > i.U) {\n206:    \
      \   allocated((deqPtr+i.U).value) := false.B\n207:     }\n208:     XSError(commitCount
      > i.U && !allocated((deqPtr+i.U).value), s\"why commit invalid entry $i?\\n\"\
      )\n209:   })\n210: \n211:   // vector commit or replay\n212:   val vecLdCommittmp
      = Wire(Vec(VirtualLoadQueueSize, Vec(VecLoadPipelineWidth, Bool())))\n213: \
      \  val vecLdCommit = Wire(Vec(VirtualLoadQueueSize, Bool()))\n214:   for (i
      <- 0 until VirtualLoadQueueSize) {\n215:     val cmt = io.vecCommit\n216:  \
      \   for (j <- 0 until VecLoadPipelineWidth) {\n217:       vecLdCommittmp(i)(j)
      := allocated(i) && cmt(j).valid && robIdx(i) === cmt(j).bits.robidx && uopIdx(i)
      === cmt(j).bits.uopidx\n218:     }\n219:     vecLdCommit(i) := vecLdCommittmp(i).reduce(_
      || _)\n220: \n221:     when (vecLdCommit(i) && isvec(i)) {\n222:       committed(i)
      := true.B\n223:     }\n224:   }\n225: \n226:   // misprediction recovery / exception
      redirect\n227:   // invalidate lq term using robIdx"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 249-259
    context: "249:     val need_rep = io.ldin(i).bits.rep_info.need_rep\n250:    \
      \ val need_valid = io.ldin(i).bits.updateAddrValid\n251:     when (io.ldin(i).valid)
      {\n252:       val hasExceptions = ExceptionNO.selectByFu(io.ldin(i).bits.uop.exceptionVec,
      LduCfg).asUInt.orR\n253:       when (!need_rep && need_valid && !io.ldin(i).bits.isvec)
      {\n254:         committed(loadWbIndex) := true.B\n255:         //  Debug info\n\
      256:         debug_mmio(loadWbIndex) := io.ldin(i).bits.mmio\n257:         debug_paddr(loadWbIndex)
      := io.ldin(i).bits.paddr\n258:       }\n259:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/VirtualLoadQueue.scala
    lines: 298-308
    context: "298:     XSDebug(false, !flag, \" \") // otherwise\n299:   }\n300: \n\
      301:   for (i <- 0 until VirtualLoadQueueSize) {\n302:     PrintFlag(allocated(i),
      \"a\")\n303:     PrintFlag(allocated(i) && committed(i), \"c\")\n304:     PrintFlag(allocated(i)
      && isvec(i), \"v\")\n305:     XSDebug(false, true.B, \"\\n\")\n306:   }\n307:\
      \   // end\n308: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadExceptionBuffer.scala
    lines: 34-44
    context: "34: \n35: class LqExceptionBuffer(implicit p: Parameters) extends XSModule
      with HasCircularQueuePtrHelper {\n36:   val enqPortNum = LoadPipelineWidth +
      VecLoadPipelineWidth + 1 // 1 for mmio bus non-data error\n37: \n38:   val io
      = IO(new Bundle() {\n39:     val redirect      = Flipped(Valid(new Redirect))\n\
      40:     val req           = Vec(enqPortNum, Flipped(Valid(new LqWriteBundle)))\n\
      41:     val exceptionAddr = new ExceptionAddrIO\n42:   })\n43: \n44:   val req_valid
      = RegInit(false.B)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadExceptionBuffer.scala
    lines: 52-63
    context: "52:   // s2: delay 1 cycle\n53:   val s2_req = (0 until enqPortNum).map(i
      => {\n54:     RegEnable(s1_req(i), s1_valid(i))})\n55:   val s2_valid = (0 until
      enqPortNum).map(i =>\n56:     RegNext(s1_valid(i)) &&\n57:     !s2_req(i).uop.robIdx.needFlush(RegNext(io.redirect))
      &&\n58:     !s2_req(i).uop.robIdx.needFlush(io.redirect)\n59:   )\n60:   val
      s2_has_exception = s2_req.map(x => ExceptionNO.selectByFu(x.uop.exceptionVec,
      LduCfg).asUInt.orR)\n61: \n62:   val s2_enqueue = Wire(Vec(enqPortNum, Bool()))\n\
      63:   for (w <- 0 until enqPortNum) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadExceptionBuffer.scala
    lines: 62-72
    context: "62:   val s2_enqueue = Wire(Vec(enqPortNum, Bool()))\n63:   for (w <-
      0 until enqPortNum) {\n64:     s2_enqueue(w) := s2_valid(w) && s2_has_exception(w)\n\
      65:   }\n66: \n67:   when (req_valid && req.uop.robIdx.needFlush(io.redirect))
      {\n68:     req_valid := s2_enqueue.asUInt.orR\n69:   } .elsewhen (s2_enqueue.asUInt.orR)
      {\n70:     req_valid := true.B\n71:   }\n72: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 76-86
    context: "76:   // The following VecStorePipelineWidth ports: vector st exception\n\
      77:   // The last port: non-data error generated in SoC\n78:   val enqPortNum
      = StorePipelineWidth * 2 + VecStorePipelineWidth + 1\n79: \n80:   val io = IO(new
      Bundle() {\n81:     val redirect = Flipped(ValidIO(new Redirect))\n82:     val
      storeAddrIn = Vec(enqPortNum, Flipped(ValidIO(new LsPipelineBundle())))\n83:\
      \     val exceptionAddr = new ExceptionAddrIO\n84:   })\n85: \n86:   val req_valid
      = RegInit(false.B)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 88-98
    context: "88: \n89:   // enqueue\n90:   // S1:\n91:   val s1_req = VecInit(io.storeAddrIn.map(_.bits))\n\
      92:   val s1_valid = VecInit(io.storeAddrIn.map(x =>\n93:       x.valid && !x.bits.uop.robIdx.needFlush(io.redirect)
      && ExceptionNO.selectByFu(x.bits.uop.exceptionVec, StaCfg).asUInt.orR\n94: \
      \  ))\n95: \n96:   // S2: delay 1 cycle\n97:   val s2_req = (0 until enqPortNum).map(i
      =>\n98:     RegEnable(s1_req(i), s1_valid(i)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 95-105
    context: "95: \n96:   // S2: delay 1 cycle\n97:   val s2_req = (0 until enqPortNum).map(i
      =>\n98:     RegEnable(s1_req(i), s1_valid(i)))\n99:   val s2_valid = (0 until
      enqPortNum).map(i =>\n100:     RegNext(s1_valid(i)) && !s2_req(i).uop.robIdx.needFlush(io.redirect)\n\
      101:   )\n102: \n103:   val s2_enqueue = Wire(Vec(enqPortNum, Bool()))\n104:\
      \   for (w <- 0 until enqPortNum) {\n105:     s2_enqueue(w) := s2_valid(w)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 103-113
    context: "103:   val s2_enqueue = Wire(Vec(enqPortNum, Bool()))\n104:   for (w
      <- 0 until enqPortNum) {\n105:     s2_enqueue(w) := s2_valid(w)\n106:   }\n\
      107: \n108:   when (req_valid && req.uop.robIdx.needFlush(io.redirect)) {\n\
      109:     req_valid := s2_enqueue.asUInt.orR\n110:   }.elsewhen (s2_enqueue.asUInt.orR)
      {\n111:     req_valid := true.B\n112:   }\n113: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 165-175
    context: "165:   with HasPerfEvents\n166:   with HasVLSUParameters {\n167:   val
      io = IO(new Bundle() {\n168:     val hartId = Input(UInt(hartIdLen.W))\n169:\
      \     val enq = new SqEnqIO\n170:     val brqRedirect = Flipped(ValidIO(new
      Redirect))\n171:     val vecFeedback = Vec(VecLoadPipelineWidth, Flipped(ValidIO(new
      FeedbackToLsqIO)))\n172:     val storeAddrIn = Vec(StorePipelineWidth, Flipped(Valid(new
      LsPipelineBundle))) // store addr, data is not included\n173:     val storeAddrInRe
      = Vec(StorePipelineWidth, Input(new LsPipelineBundle())) // store more mmio
      and exception\n174:     val storeDataIn = Vec(StorePipelineWidth, Flipped(Valid(new
      MemExuOutput(isVector = true)))) // store data, send to sq from rs\n175:   \
      \  val storeMaskIn = Vec(StorePipelineWidth, Flipped(Valid(new StoreMaskBundle)))
      // store mask, send to sq from rs"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 171-181
    context: "171:     val vecFeedback = Vec(VecLoadPipelineWidth, Flipped(ValidIO(new
      FeedbackToLsqIO)))\n172:     val storeAddrIn = Vec(StorePipelineWidth, Flipped(Valid(new
      LsPipelineBundle))) // store addr, data is not included\n173:     val storeAddrInRe
      = Vec(StorePipelineWidth, Input(new LsPipelineBundle())) // store more mmio
      and exception\n174:     val storeDataIn = Vec(StorePipelineWidth, Flipped(Valid(new
      MemExuOutput(isVector = true)))) // store data, send to sq from rs\n175:   \
      \  val storeMaskIn = Vec(StorePipelineWidth, Flipped(Valid(new StoreMaskBundle)))
      // store mask, send to sq from rs\n176:     val sbuffer = Vec(EnsbufferWidth,
      Decoupled(new DCacheWordReqWithVaddrAndPfFlag)) // write committed store to
      sbuffer\n177:     val uncacheOutstanding = Input(Bool())\n178:     val cmoOpReq\
      \  = DecoupledIO(new CMOReq)\n179:     val cmoOpResp = Flipped(DecoupledIO(new
      CMOResp))\n180:     val cboZeroStout = DecoupledIO(new MemExuOutput)\n181: \
      \    val mmioStout = DecoupledIO(new MemExuOutput) // writeback uncached store"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 231-241
    context: "231:     numForward = LoadPipelineWidth\n232:   ))\n233:   vaddrModule.io
      := DontCare\n234:   val dataBuffer = Module(new DatamoduleResultBuffer(new DataBufferEntry))\n\
      235:   val exceptionBuffer = Module(new StoreExceptionBuffer)\n236:   exceptionBuffer.io.redirect
      := io.brqRedirect\n237:   exceptionBuffer.io.exceptionAddr.isStore := DontCare\n\
      238:   // vlsu exception!\n239:   for (i <- 0 until VecStorePipelineWidth) {\n\
      240:     exceptionBuffer.io.storeAddrIn(StorePipelineWidth * 2 + i).valid  \
      \             := io.vecFeedback(i).valid && io.vecFeedback(i).bits.feedback(VecFeedbacks.FLUSH)
      // have exception\n241:     exceptionBuffer.io.storeAddrIn(StorePipelineWidth
      * 2 + i).bits                := DontCare"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 261-271
    context: "261:   val allocated = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // sq entry has been allocated\n262:   val completed = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))\n\
      263:   val addrvalid = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))\n\
      264:   val datavalid = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))\n\
      265:   val allvalid  = VecInit((0 until StoreQueueSize).map(i => addrvalid(i)
      && datavalid(i)))\n266:   val committed = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // inst has been committed by rob\n267:   val unaligned = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // unaligned store\n268:   val cross16Byte = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // unaligned cross 16Byte boundary\n269:   val pending = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // mmio pending: inst is an mmio inst, it will not be executed until it reachs
      the end of rob\n270:   val nc = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // nc: inst is a nc inst\n271:   val mmio = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // mmio: inst is an mmio inst"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 268-281
    context: "268:   val cross16Byte = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // unaligned cross 16Byte boundary\n269:   val pending = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // mmio pending: inst is an mmio inst, it will not be executed until it reachs
      the end of rob\n270:   val nc = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // nc: inst is a nc inst\n271:   val mmio = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // mmio: inst is an mmio inst\n272:   val memBackTypeMM = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))\n\
      273:   val prefetch = RegInit(VecInit(List.fill(StoreQueueSize)(false.B))) //
      need prefetch when committing this store to sbuffer?\n274:   val isVec = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // vector store instruction\n275:   val vecLastFlow = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // last uop the last flow of vector store instruction\n276:   val vecMbCommit
      = RegInit(VecInit(List.fill(StoreQueueSize)(false.B))) // vector store committed
      from merge buffer to rob\n277:   val hasException = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // store has exception, should deq but not write sbuffer\n278:   val waitStoreS2
      = RegInit(VecInit(List.fill(StoreQueueSize)(false.B))) // wait for mmio and
      exception result until store_s2\n279:   // val vec_robCommit = Reg(Vec(StoreQueueSize,
      Bool())) // vector store committed by rob\n280:   // val vec_secondInv = RegInit(VecInit(List.fill(StoreQueueSize)(false.B)))
      // Vector unit-stride, second entry is invalid\n281:   val vecExceptionFlag
      = RegInit(0.U.asTypeOf(Valid(new DynInst)))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 283-293
    context: "283: \n284:   // ptr\n285:   val enqPtrExt = RegInit(VecInit((0 until
      io.enq.req.length).map(_.U.asTypeOf(new SqPtr))))\n286:   val rdataPtrExt =
      RegInit(VecInit((0 until EnsbufferWidth).map(_.U.asTypeOf(new SqPtr))))\n287:\
      \   val deqPtrExt = RegInit(VecInit((0 until EnsbufferWidth).map(_.U.asTypeOf(new
      SqPtr))))\n288:   val cmtPtrExt = RegInit(VecInit((0 until CommitWidth).map(_.U.asTypeOf(new
      SqPtr))))\n289:   val addrReadyPtrExt = RegInit(0.U.asTypeOf(new SqPtr))\n290:\
      \   val dataReadyPtrExt = RegInit(0.U.asTypeOf(new SqPtr))\n291: \n292:   val
      enqPtr = enqPtrExt(0).value\n293:   val deqPtr = deqPtrExt(0).value"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 298-309
    context: "298:   val allowEnqueue = validCount <= (StoreQueueSize - LSQStEnqWidth).U\n\
      299: \n300:   val deqMask = UIntToMask(deqPtr, StoreQueueSize)\n301:   val enqMask
      = UIntToMask(enqPtr, StoreQueueSize)\n302: \n303:   val commitCount = WireInit(0.U(log2Ceil(CommitWidth
      + 1).W))\n304:   val scommit = GatedRegNext(io.rob.scommit)\n305:   val mmioReq
      = Wire(chiselTypeOf(io.uncache.req))\n306:   val ncWaitRespPtrReg = RegInit(0.U(uncacheIdxBits.W))
      // it's valid only in non-outstanding situation\n307:   val ncReq = Wire(chiselTypeOf(io.uncache.req))\n\
      308:   val ncResp = Wire(chiselTypeOf(io.uncache.resp))\n309:   val ncDoReq
      = Wire(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 405-415
    context: "405:       completed(i) := false.B\n406:       datavalid(i) := false.B\n\
      407:       addrvalid(i) := false.B\n408:       unaligned(i) := false.B\n409:\
      \       cross16Byte(i) := false.B\n410:       committed(i) := false.B\n411:\
      \       pending(i) := false.B\n412:       prefetch(i) := false.B\n413:     \
      \  nc(i) := false.B\n414:       mmio(i) := false.B\n415:       isVec(i) := \
      \ FuType.isVStore(selectBits.fuType)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 411-421
    context: "411:       pending(i) := false.B\n412:       prefetch(i) := false.B\n\
      413:       nc(i) := false.B\n414:       mmio(i) := false.B\n415:       isVec(i)
      :=  FuType.isVStore(selectBits.fuType)\n416:       vecMbCommit(i) := false.B\n\
      417:       hasException(i) := false.B\n418:       waitStoreS2(i) := true.B\n\
      419:     }\n420:   }\n421: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 435-445
    context: "435:   val IssuePtrMoveStride = 4\n436:   require(IssuePtrMoveStride
      >= 2)\n437: \n438:   val addrReadyLookupVec = (0 until IssuePtrMoveStride).map(addrReadyPtrExt
      + _.U)\n439:   val addrReadyLookup = addrReadyLookupVec.map(ptr => allocated(ptr.value)
      &&\n440:    (mmio(ptr.value) || addrvalid(ptr.value) || vecMbCommit(ptr.value))\n\
      441:     && ptr =/= enqPtrExt(0))\n442:   val nextAddrReadyPtr = addrReadyPtrExt
      + PriorityEncoder(VecInit(addrReadyLookup.map(!_) :+ true.B))\n443:   addrReadyPtrExt
      := nextAddrReadyPtr\n444: \n445:   val stAddrReadyVecReg = Wire(Vec(StoreQueueSize,
      Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 442-452
    context: "442:   val nextAddrReadyPtr = addrReadyPtrExt + PriorityEncoder(VecInit(addrReadyLookup.map(!_)
      :+ true.B))\n443:   addrReadyPtrExt := nextAddrReadyPtr\n444: \n445:   val stAddrReadyVecReg
      = Wire(Vec(StoreQueueSize, Bool()))\n446:   (0 until StoreQueueSize).map(i =>
      {\n447:     stAddrReadyVecReg(i) := allocated(i) && (mmio(i) || addrvalid(i)
      || (isVec(i) && vecMbCommit(i)))\n448:   })\n449:   io.stAddrReadyVec := GatedValidRegNext(stAddrReadyVecReg)\n\
      450: \n451:   when (io.brqRedirect.valid) {\n452:     addrReadyPtrExt := Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 460-470
    context: "460: \n461:   // update\n462:   val dataReadyLookupVec = (0 until IssuePtrMoveStride).map(dataReadyPtrExt
      + _.U)\n463:   val dataReadyLookup = dataReadyLookupVec.map(ptr =>\n464:   \
      \  allocated(ptr.value) &&\n465:     (addrvalid(ptr.value) && (mmio(ptr.value)
      || datavalid(ptr.value)) || vecMbCommit(ptr.value)) &&\n466:     !unaligned(ptr.value)
      &&\n467:     ptr =/= enqPtrExt(0)\n468:   )\n469:   val nextDataReadyPtr = dataReadyPtrExt
      + PriorityEncoder(VecInit(dataReadyLookup.map(!_) :+ true.B))\n470:   dataReadyPtrExt
      := nextDataReadyPtr"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 481-491
    context: "481:   }\n482: \n483:   val stDataReadyVecReg = Wire(Vec(StoreQueueSize,
      Bool()))\n484:   (0 until StoreQueueSize).map(i => {\n485:     stDataReadyVecReg(i)
      := allocated(i) &&\n486:       (addrvalid(i) && (mmio(i) || datavalid(i)) ||
      (isVec(i) && vecMbCommit(i))) && !unaligned(i)\n487:   })\n488:   io.stDataReadyVec
      := GatedValidRegNext(stDataReadyVecReg)\n489: \n490:   when (io.brqRedirect.valid)
      {\n491:     dataReadyPtrExt := Mux("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 843-853
    context: "843:   val mmioState = RegInit(s_idle)\n844:   val uncacheUop = Reg(new
      DynInst)\n845:   val cboFlushedSb = RegInit(false.B)\n846:   val cmoOpCode =
      uncacheUop.fuOpType(1, 0)\n847:   val mmioDoReq = io.uncache.req.fire && !io.uncache.req.bits.nc\n\
      848:   val cboMmioPAddr = Reg(UInt(PAddrBits.W))\n849:   switch(mmioState) {\n\
      850:     is(s_idle) {\n851:       when(RegNext(io.rob.pendingst && uop(deqPtr).robIdx
      === io.rob.pendingPtr && pending(deqPtr) && allocated(deqPtr) && datavalid(deqPtr)
      && addrvalid(deqPtr) && !hasException(deqPtr))) {\n852:         mmioState :=
      s_req\n853:         uncacheUop := uop(deqPtr)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 852-862
    context: "852:         mmioState := s_req\n853:         uncacheUop := uop(deqPtr)\n\
      854:         uncacheUop.exceptionVec := 0.U.asTypeOf(ExceptionVec())\n855: \
      \        uncacheUop.trigger := 0.U.asTypeOf(TriggerAction())\n856:         cboFlushedSb
      := false.B\n857:         cboMmioPAddr := paddrModule.io.rdata(0)\n858:     \
      \  }\n859:     }\n860:     is(s_req) {\n861:       when (mmioDoReq) {\n862:\
      \         noPending := false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 882-892
    context: "882:         }\n883:       }\n884:     }\n885:     is(s_wait) {\n886:\
      \       // A MMIO store can always move cmtPtrExt as it must be ROB head\n887:\
      \       when(scommit > 0.U) {\n888:         mmioState := s_idle // ready for
      next mmio\n889:       }\n890:     }\n891:   }\n892: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 915-925
    context: "915:   val ncState = RegInit(nc_idle)\n916:   val rptr0 = rdataPtrExt(0).value\n\
      917:   switch(ncState){\n918:     is(nc_idle) {\n919:       when(\n920:    \
      \     nc(rptr0) && allocated(rptr0) && !completed(rptr0) && committed(rptr0)
      &&\n921:         allvalid(rptr0) && !isVec(rptr0) && !hasException(rptr0) &&
      !mmio(rptr0)\n922:       ) {\n923:         ncState := nc_req\n924:         ncWaitRespPtrReg
      := rptr0\n925:       }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 975-985
    context: "975:   io.uncache.req.valid := mmioReq.valid || ncReq.valid\n976:  \
      \ io.uncache.req.bits := Mux(mmioReq.valid, mmioReq.bits, ncReq.bits)\n977:\
      \ \n978:   // CBO op type check can be delayed for 1 cycle,\n979:   // as uncache
      op will not start in s_idle\n980:   val cboMmioAddr = get_block_addr(cboMmioPAddr)\n\
      981:   val deqCanDoCbo = GatedRegNext(LSUOpType.isCbo(uop(deqPtr).fuOpType)
      && allocated(deqPtr) && addrvalid(deqPtr) && !hasException(deqPtr))\n982: \n\
      983:   val isCboZeroToSbVec = (0 until EnsbufferWidth).map{ i =>\n984:     io.sbuffer(i).fire
      && io.sbuffer(i).bits.vecValid && io.sbuffer(i).bits.wline && allocated(dataBuffer.io.deq(i).bits.sqPtr.value)\n\
      985:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1015-1025
    context: "1015:     }\n1016:   }\n1017: \n1018:   io.cmoOpReq.valid := deqCanDoCbo
      && cboFlushedSb && (mmioState === s_req) && !io.wfi.wfiReq\n1019:   io.cmoOpReq.bits.opcode\
      \  := cmoOpCode\n1020:   io.cmoOpReq.bits.address := cboMmioAddr\n1021: \n1022:\
      \   io.cmoOpResp.ready := deqCanDoCbo && (mmioState === s_resp)\n1023: \n1024:\
      \   io.wfi.wfiSafe := GatedValidRegNext(noPending && io.wfi.wfiReq)\n1025: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1112-1134
    context: "1112:     * ROB commits store instructions (mark them as committed)\n\
      1113:     *\n1114:     * (1) When store commits, mark it as committed.\n1115:\
      \     * (2) They will not be cancelled and can be sent to lower level.\n1116:\
      \     */\n1117:   XSError(mmioState =/= s_idle && mmioState =/= s_wait && commitCount
      > 0.U,\n1118:    \"should not commit instruction when MMIO has not been finished\\\
      n\")\n1119: \n1120:   val commitVec = WireInit(VecInit(Seq.fill(CommitWidth)(false.B)))\n\
      1121:   val needCancel = Wire(Vec(StoreQueueSize, Bool())) // Will be assigned
      later\n1122: \n1123:   if (backendParams.debugEn){ dontTouch(commitVec) }\n\
      1124: \n1125:   // TODO: Deal with vector store mmio\n1126:   for (i <- 0 until
      CommitWidth) {\n1127:     // don't mark misalign store as committed\n1128: \
      \    val ptr = cmtPtrExt(i).value\n1129:     val isCommit = WireInit(false.B)\n\
      1130:     when (\n1131:       allocated(ptr) &&\n1132:       isNotAfter(uop(ptr).robIdx,
      GatedRegNext(io.rob.pendingPtr)) &&\n1133:       !needCancel(ptr) &&\n1134:\
      \       (!waitStoreS2(ptr) || isVec(ptr))) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1132-1163
    context: "1132:       isNotAfter(uop(ptr).robIdx, GatedRegNext(io.rob.pendingPtr))
      &&\n1133:       !needCancel(ptr) &&\n1134:       (!waitStoreS2(ptr) || isVec(ptr)))
      {\n1135:       if (i == 0){\n1136:         // TODO: fixme for vector mmio\n\
      1137:         when ((mmioState === s_idle) || (mmioState === s_wait && scommit
      > 0.U)){\n1138:           when ((isVec(ptr) && vecMbCommit(ptr)) || !isVec(ptr))
      {\n1139:             isCommit := true.B\n1140:             committed(ptr) :=
      true.B\n1141:             commitVec(0) := true.B\n1142:           }\n1143: \
      \        }\n1144:       } else {\n1145:         when ((isVec(ptr) && vecMbCommit(ptr))
      || !isVec(ptr)) {\n1146:           isCommit := commitVec(i - 1) || committed(ptr)\n\
      1147:           committed(ptr) := commitVec(i - 1) || committed(ptr)\n1148:\
      \           commitVec(i) := commitVec(i - 1)\n1149:         }\n1150:       }\n\
      1151:     }\n1152:     when(isCommit && nc(ptr) && hasException(ptr)) {\n1153:\
      \       completed(ptr) := true.B\n1154:     }\n1155:   }\n1156: \n1157:   commitCount
      := PopCount(commitVec)\n1158:   cmtPtrExt := cmtPtrExt.map(_ + commitCount)\n\
      1159: \n1160:   /**\n1161:    * committed stores will not be cancelled and can
      be sent to lower level.\n1162:    *\n1163:    * 1. Store NC: Read data to uncache"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1190-1201
    context: "1190:     }\n1191:     val vecNotAllMask = dataModule.io.rdata(i).mask.orR\n\
      1192:     // Vector instructions that prevent triggered exceptions from being
      written to the 'databuffer'.\n1193:     val vecHasExceptionFlagValid = vecExceptionFlag.valid
      && isVec(ptr) && vecExceptionFlag.bits.robIdx === uop(ptr).robIdx\n1194: \n\
      1195:     val misalignToDataBufferValid = allocated(rdataPtrExt(0).value) &&
      committed(rdataPtrExt(0).value) &&\n1196:                                  \
      \   (!isVec(rdataPtrExt(0).value) && allvalid(rdataPtrExt(0).value) || vecMbCommit(rdataPtrExt(0).value))
      &&\n1197:                                     canDeqMisaligned && (!isCross4KPage
      || isCross4KPageCanDeq || hasException(rdataPtrExt(0).value))\n1198:     //
      Only the first interface can write unaligned directives.\n1199:     // Simplified
      design, even if the two ports have exceptions, but still only one unaligned
      dequeue.\n1200:     val assert_flag = WireInit(false.B)\n1201:     when(firstWithMisalign
      && firstWithCross16Byte) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1201-1212
    context: "1201:     when(firstWithMisalign && firstWithCross16Byte) {\n1202: \
      \      dataBuffer.io.enq(i).valid := misalignToDataBufferValid\n1203:      \
      \ assert_flag := dataBuffer.io.enq(1).valid\n1204:     }.otherwise {\n1205:\
      \       dataBuffer.io.enq(i).valid := (\n1206:         allocated(ptr) && committed(ptr)\n\
      1207:           && ((!isVec(ptr) && (allvalid(ptr) || hasException(ptr))) ||
      vecMbCommit(ptr))\n1208:           && !mmioStall && !ncStall\n1209:        \
      \   && (!unaligned(ptr) || !cross16Byte(ptr) && (allvalid(ptr) || hasException(ptr)))\n\
      1210:         )\n1211:     }\n1212: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1230-1240
    context: "1230:     val maskHigh  = Cross16ByteMask(31, 16)\n1231: \n1232:   \
      \  val dataLow   = Cross16ByteData(127, 0)\n1233:     val dataHigh  = Cross16ByteData(255,
      128)\n1234: \n1235:     val toSbufferVecValid = (!isVec(ptr) || (vecMbCommit(ptr)
      && allvalid(ptr) && vecNotAllMask)) && !exceptionValid && !vecHasExceptionFlagValid\n\
      1236:     when(canDeqMisaligned && firstWithMisalign && firstWithCross16Byte)
      {\n1237:       when(isCross4KPage && isCross4KPageCanDeq) {\n1238:         if
      (i == 0) {\n1239:           dataBuffer.io.enq(i).bits.addr      := paddrLow\n\
      1240:           dataBuffer.io.enq(i).bits.vaddr     := vaddrLow"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1307-1317
    context: "1307:       dataBuffer.io.enq(i).bits.vecValid := toSbufferVecValid\n\
      1308: \n1309:     }\n1310: \n1311:     // Note that store data/addr should both
      be valid after store's commit\n1312:     assert(!dataBuffer.io.enq(i).valid
      || allvalid(ptr) || hasException(ptr) || (allocated(ptr) && vecMbCommit(ptr))
      || assert_flag)\n1313:   }\n1314: \n1315:   // Send data stored in sbufferReqBitsReg
      to sbuffer\n1316:   for (i <- 0 until EnsbufferWidth) {\n1317:     io.sbuffer(i).valid
      := dataBuffer.io.deq(i).valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1357-1367
    context: "1357:   val robidxEQ = dataBuffer.io.enq(0).fire && dataBuffer.io.enq(1).fire
      &&\n1358:     uop(rdataPtrExt(0).value).robIdx === uop(rdataPtrExt(1).value).robIdx\n\
      1359:   val robidxNE = dataBuffer.io.enq(0).fire && dataBuffer.io.enq(1).fire
      && (\n1360:     uop(rdataPtrExt(0).value).robIdx =/= uop(rdataPtrExt(1).value).robIdx\n\
      1361:   )\n1362:   val onlyCommit0 = dataBuffer.io.enq(0).fire && !dataBuffer.io.enq(1).fire\n\
      1363: \n1364:   /**\n1365:    * If rdataPtr(0) is misaligned and Cross16Byte,
      this store request will fill two ports of rdataBuffer,\n1366:    * Therefore,
      the judgement of vecCommitLastFlow should't to use rdataPtr(1)\n1367:    * */"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1369-1379
    context: "1369:   val vecCommitLastFlow =\n1370:     // robidx equal => check
      if 1 is last flow\n1371:     robidxEQ && vecCommitHasExceptionLastFlow(1) &&
      !firstSplit ||\n1372:     // robidx not equal => 0 must be the last flow, just
      check if 1 is last flow when 1 has exception\n1373:     robidxNE && (vecCommitHasExceptionValid(1)
      && vecCommitHasExceptionLastFlow(1) || !vecCommitHasExceptionValid(1)) ||\n\
      1374:     onlyCommit0 && vecCommitHasExceptionLastFlow(0)\n1375: \n1376: \n\
      1377:   val vecExceptionFlagCancel  = (0 until EnsbufferWidth).map{ i =>\n1378:\
      \     val ptr = rdataPtrExt(i).value\n1379:     val vecLastFlowCommit = vecLastFlow(ptr)
      && (uop(ptr).robIdx === vecExceptionFlag.bits.robIdx) &&"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1403-1413
    context: "1403:   if (env.EnableDifftest) {\n1404:     // commit cbo.inval to
      difftest\n1405:     val cmoInvalEvent = DifftestModule(new DiffCMOInvalEvent)\n\
      1406:     cmoInvalEvent.coreid := io.hartId\n1407:     cmoInvalEvent.valid :=
      io.mmioStout.fire && deqCanDoCbo && LSUOpType.isCboInval(uop(deqPtr).fuOpType)\n\
      1408:     cmoInvalEvent.addr := cboMmioAddr\n1409: \n1410:     // DiffStoreEvent
      happens when rdataPtr moves.\n1411:     // That is, pmsStore enter dataBuffer
      or ncStore enter Ubuffer\n1412:     (0 until EnsbufferWidth).foreach { i =>\n\
      1413:       // when i = 0, the sqPtr is rdataPtr(0), which is rdataPtrExt(0),
      so it applies to NC as well."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1426-1436
    context: "1426:   (1 until EnsbufferWidth).foreach(i => when(io.sbuffer(i).fire)
      { assert(io.sbuffer(i - 1).fire) })\n1427:   if (coreParams.dcacheParametersOpt.isEmpty)
      {\n1428:     for (i <- 0 until EnsbufferWidth) {\n1429:       val ptr = deqPtrExt(i).value\n\
      1430:       val ram = DifftestMem(64L * 1024 * 1024 * 1024, 8)\n1431:      \
      \ val wen = allocated(ptr) && committed(ptr) && !mmio(ptr)\n1432:       val
      waddr = ((paddrModule.io.rdata(i) - \"h80000000\".U) >> 3).asUInt\n1433:   \
      \    val wdata = Mux(paddrModule.io.rdata(i)(3), dataModule.io.rdata(i).data(127,
      64), dataModule.io.rdata(i).data(63, 0))\n1434:       val wmask = Mux(paddrModule.io.rdata(i)(3),
      dataModule.io.rdata(i).mask(15, 8), dataModule.io.rdata(i).mask(7, 0))\n1435:\
      \       when (wen) {\n1436:         ram.write(waddr, wdata.asTypeOf(Vec(8, UInt(8.W))),
      wmask.asBools)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1446-1467
    context: "1446:   io.exceptionAddr.vstart    := exceptionBuffer.io.exceptionAddr.vstart\n\
      1447:   io.exceptionAddr.vl        := exceptionBuffer.io.exceptionAddr.vl\n\
      1448:   io.exceptionAddr.isForVSnonLeafPTE := exceptionBuffer.io.exceptionAddr.isForVSnonLeafPTE\n\
      1449: \n1450:   // vector commit or replay from\n1451:   val vecCommittmp =
      Wire(Vec(StoreQueueSize, Vec(VecStorePipelineWidth, Bool())))\n1452:   val vecCommit
      = Wire(Vec(StoreQueueSize, Bool()))\n1453:   for (i <- 0 until StoreQueueSize)
      {\n1454:     val fbk = io.vecFeedback\n1455:     for (j <- 0 until VecStorePipelineWidth)
      {\n1456:       vecCommittmp(i)(j) := fbk(j).valid && (fbk(j).bits.isCommit ||
      fbk(j).bits.isFlush) &&\n1457:         uop(i).robIdx === fbk(j).bits.robidx
      && uop(i).uopIdx === fbk(j).bits.uopidx && allocated(i)\n1458:     }\n1459:\
      \     vecCommit(i) := vecCommittmp(i).reduce(_ || _)\n1460: \n1461:     when
      (vecCommit(i)) {\n1462:       vecMbCommit(i) := true.B\n1463:     }\n1464: \
      \  }\n1465: \n1466:   // For vector, when there is a store across pages with
      the same uop in storeMisalignBuffer, storequeue needs to mark this item as committed.\n\
      1467:   // TODO FIXME Can vecMbCommit be removed?"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1464-1474
    context: "1464:   }\n1465: \n1466:   // For vector, when there is a store across
      pages with the same uop in storeMisalignBuffer, storequeue needs to mark this
      item as committed.\n1467:   // TODO FIXME Can vecMbCommit be removed?\n1468:\
      \   when(io.maControl.toStoreQueue.withSameUop && allvalid(rdataPtrExt(0).value))
      {\n1469:     vecMbCommit(rdataPtrExt(0).value) := true.B\n1470:   }\n1471: \n\
      1472:   // misprediction recovery / exception redirect\n1473:   // invalidate
      sq term using robIdx\n1474:   for (i <- 0 until StoreQueueSize) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1470-1480
    context: "1470:   }\n1471: \n1472:   // misprediction recovery / exception redirect\n\
      1473:   // invalidate sq term using robIdx\n1474:   for (i <- 0 until StoreQueueSize)
      {\n1475:     needCancel(i) := allocated(i) && !committed(i) && Mux(\n1476: \
      \        vecExceptionFlag.valid,\n1477:         isAfter(uop(i).robIdx, io.brqRedirect.bits.robIdx)
      && io.brqRedirect.valid,\n1478:         uop(i).robIdx.needFlush(io.brqRedirect)\n\
      1479:       )\n1480:     when (needCancel(i)) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1490-1507
    context: "1490:     v && x.bits.robIdx.needFlush(io.brqRedirect)\n1491:   }\n\
      1492:   val enqCancelNum = enqCancelValid.zip(vStoreFlow).map{case (v, flow)
      =>\n1493:     Mux(v, flow, 0.U)\n1494:   }\n1495:   val lastEnqCancel = RegEnable(enqCancelNum.reduce(_
      + _), io.brqRedirect.valid) // 1 cycle after redirect\n1496: \n1497:   val lastCycleCancelCount
      = PopCount(RegEnable(needCancel, io.brqRedirect.valid)) // 1 cycle after redirect\n\
      1498:   val lastCycleRedirect = RegNext(io.brqRedirect.valid) // 1 cycle after
      redirect\n1499:   val enqNumber = validVStoreFlow.reduce(_ + _)\n1500: \n1501:\
      \   val lastlastCycleRedirect=RegNext(lastCycleRedirect)// 2 cycle after redirect\n\
      1502:   val redirectCancelCount = RegEnable(lastCycleCancelCount + lastEnqCancel,
      0.U, lastCycleRedirect) // 2 cycle after redirect\n1503: \n1504:   when (lastlastCycleRedirect)
      {\n1505:     // we recover the pointers in 2 cycle after redirect for better
      timing\n1506:     enqPtrExt := VecInit(enqPtrExt.map(_ - redirectCancelCount))\n\
      1507:   }.otherwise {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreQueue.scala
    lines: 1576-1586
    context: "1576:       debug_data(i)\n1577:     )\n1578:     PrintFlag(allocated(i),
      \"a\")\n1579:     PrintFlag(allocated(i) && addrvalid(i), \"a\")\n1580:    \
      \ PrintFlag(allocated(i) && datavalid(i), \"d\")\n1581:     PrintFlag(allocated(i)
      && committed(i), \"c\")\n1582:     PrintFlag(allocated(i) && pending(i), \"\
      p\")\n1583:     PrintFlag(allocated(i) && mmio(i), \"m\")\n1584:     XSDebug(false,
      true.B, \"\\n\")\n1585:   }\n1586: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 32-42
    context: "32:   with HasLoadHelper\n33:   with HasPerfEvents\n34: {\n35:   val
      io = IO(new Bundle() {\n36:     // control\n37:     val redirect = Flipped(Valid(new
      Redirect))\n38: \n39:     // violation query\n40:     val query = Vec(LoadPipelineWidth,
      Flipped(new LoadNukeQueryIO))\n41: \n42:     // release cacheline"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 135-145
    context: "135: \n136:   // LoadQueueRAR enqueue condition:\n137:   // There are
      still not completed load instructions before the current load instruction.\n\
      138:   // (e.g. \"not completed\" means that load instruction get the data or
      exception).\n139:   val canEnqueue = io.query.map(_.req.valid)\n140:   val cancelEnqueue
      = io.query.map(_.req.bits.uop.robIdx.needFlush(io.redirect))\n141:   val hasNotWritebackedLoad
      = io.query.map(_.req.bits.uop.lqIdx).map(lqIdx => isAfter(lqIdx, io.ldWbPtr))\n\
      142:   val needEnqueue = canEnqueue.zip(hasNotWritebackedLoad).zip(cancelEnqueue).map
      { case ((v, r), c) => v && r && !c }\n143: \n144:   // Allocate logic\n145:\
      \   val acceptedVec = Wire(Vec(LoadPipelineWidth, Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueRAR.scala
    lines: 197-207
    context: "197: \n198:   // when the loads that \"older than\" current load were
      writebacked,\n199:   // current load will be released.\n200:   for (i <- 0 until
      LoadQueueRARSize) {\n201:     val deqNotBlock = !isBefore(io.ldWbPtr, uop(i).lqIdx)\n\
      202:     val needFlush = uop(i).robIdx.needFlush(io.redirect)\n203: \n204: \
      \    when (allocated(i) && (deqNotBlock || needFlush)) {\n205:       allocated(i)
      := false.B\n206:       freeMaskVec(i) := true.B\n207:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 156-166
    context: "156:   with HasCircularQueuePtrHelper\n157:   with HasLoadHelper\n158:\
      \   with HasPerfEvents\n159: {\n160:   val io = IO(new Bundle() {\n161:    \
      \ val redirect = Flipped(Valid(new Redirect))\n162:     val vecFeedback = Vec(VecLoadPipelineWidth,
      Flipped(ValidIO(new FeedbackToLsqIO)))\n163:     val enq = new LqEnqIO\n164:\
      \     val ldu = new Bundle() {\n165:         val stld_nuke_query = Vec(LoadPipelineWidth,
      Flipped(new LoadNukeQueryIO)) // from load_s2\n166:         val ldld_nuke_query
      = Vec(LoadPipelineWidth, Flipped(new LoadNukeQueryIO)) // from load_s2"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 185-196
    context: "185:     val ncOut = Vec(LoadPipelineWidth, DecoupledIO(new LsPipelineBundle))\n\
      186:     val replay = Vec(LoadPipelineWidth, Decoupled(new LsPipelineBundle))\n\
      187:   //  val refill = Flipped(ValidIO(new Refill))\n188:     val tl_d_channel\
      \  = Input(new DcacheToLduForwardIO)\n189:     val release = Flipped(Valid(new
      Release))\n190:     val nuke_rollback = Vec(StorePipelineWidth, Output(Valid(new
      Redirect)))\n191:     val nack_rollback = Vec(1, Output(Valid(new Redirect)))
      // uncachebuffer\n192:     val rob = Flipped(new RobLsqIO)\n193:     val uncache
      = new UncacheWordIO\n194:     val exceptionAddr = new ExceptionAddrIO\n195:\
      \     val loadMisalignFull = Input(Bool())\n196:     val misalignAllowSpec =
      Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 193-203
    context: "193:     val uncache = new UncacheWordIO\n194:     val exceptionAddr
      = new ExceptionAddrIO\n195:     val loadMisalignFull = Input(Bool())\n196: \
      \    val misalignAllowSpec = Input(Bool())\n197:     val lqFull = Output(Bool())\n\
      198:     val lqDeq = Output(UInt(log2Up(CommitWidth + 1).W))\n199:     val lqCancelCnt
      = Output(UInt(log2Up(VirtualLoadQueueSize+1).W))\n200:     val lq_rep_full =
      Output(Bool())\n201:     val tlbReplayDelayCycleCtrl = Vec(4, Input(UInt(ReSelectLen.W)))\n\
      202:     val l2_hint = Input(Valid(new L2ToL1Hint()))\n203:     val tlb_hint
      = Flipped(new TlbHintIO)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 218-228
    context: "218:   val exceptionBuffer = Module(new LqExceptionBuffer) // exception
      buffer\n219:   val uncacheBuffer = Module(new LoadQueueUncache) // uncache\n\
      220:   /**\n221:    * LoadQueueRAR\n222:    */\n223:   loadQueueRAR.io.redirect\
      \  <> io.redirect\n224:   loadQueueRAR.io.release   <> io.release\n225:   loadQueueRAR.io.ldWbPtr\
      \   <> virtualLoadQueue.io.ldWbPtr\n226:   loadQueueRAR.io.validCount<> io.rarValidCount\n\
      227:   for (w <- 0 until LoadPipelineWidth) {\n228:     loadQueueRAR.io.query(w).req\
      \    <> io.ldu.ldld_nuke_query(w).req // from load_s1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 231-241
    context: "231:   }\n232: \n233:   /**\n234:    * LoadQueueRAW\n235:    */\n236:\
      \   loadQueueRAW.io.redirect         <> io.redirect\n237:   loadQueueRAW.io.storeIn\
      \          <> io.sta.storeAddrIn\n238:   loadQueueRAW.io.stAddrReadySqPtr <>
      io.sq.stAddrReadySqPtr\n239:   loadQueueRAW.io.stIssuePtr       <> io.sq.stIssuePtr\n\
      240:   for (w <- 0 until LoadPipelineWidth) {\n241:     loadQueueRAW.io.query(w).req\
      \    <> io.ldu.stld_nuke_query(w).req // from load_s1"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 244-255
    context: "244:   }\n245: \n246:   /**\n247:    * VirtualLoadQueue\n248:    */\n\
      249:   virtualLoadQueue.io.redirect      <> io.redirect\n250:   virtualLoadQueue.io.vecCommit\
      \     <> io.vecFeedback\n251:   virtualLoadQueue.io.enq           <> io.enq\n\
      252:   virtualLoadQueue.io.ldin          <> io.ldu.ldin // from load_s3\n253:\
      \   virtualLoadQueue.io.lqFull        <> io.lqFull\n254:   virtualLoadQueue.io.lqDeq\
      \         <> io.lqDeq\n255:   virtualLoadQueue.io.lqCancelCnt   <> io.lqCancelCnt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 257-267
    context: "257:   virtualLoadQueue.io.ldWbPtr       <> io.lqDeqPtr\n258: \n259:\
      \   /**\n260:    * Load queue exception buffer\n261:    */\n262:   exceptionBuffer.io.redirect
      <> io.redirect\n263:   for (i <- 0 until LoadPipelineWidth) {\n264:     exceptionBuffer.io.req(i).valid
      := io.ldu.ldin(i).valid && !io.ldu.ldin(i).bits.isvec // from load_s3\n265:\
      \     exceptionBuffer.io.req(i).bits := io.ldu.ldin(i).bits\n266:   }\n267:\
      \   // vlsu exception!"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 288-298
    context: "288:   io.exceptionAddr <> exceptionBuffer.io.exceptionAddr\n289: \n\
      290:   /**\n291:    * Load uncache buffer\n292:    */\n293:   uncacheBuffer.io.redirect
      <> io.redirect\n294:   uncacheBuffer.io.mmioOut <> io.ldout\n295:   uncacheBuffer.io.ncOut
      <> io.ncOut\n296:   uncacheBuffer.io.mmioRawData <> io.ld_raw_data\n297:   uncacheBuffer.io.rob
      <> io.rob\n298:   uncacheBuffer.io.uncache <> io.uncache"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueue.scala
    lines: 312-322
    context: "312:   /* <------- DANGEROUS: Don't change sequence here ! ------->
      */\n313: \n314:   /**\n315:    * LoadQueueReplay\n316:    */\n317:   loadQueueReplay.io.redirect\
      \         <> io.redirect\n318:   loadQueueReplay.io.enq              <> io.ldu.ldin
      // from load_s3\n319:   loadQueueReplay.io.storeAddrIn      <> io.sta.storeAddrIn
      // from store_s1\n320:   loadQueueReplay.io.storeDataIn      <> io.std.storeDataIn
      // from store_s0\n321:   loadQueueReplay.io.replay           <> io.replay\n\
      322:   //loadQueueReplay.io.refill           <> io.refill"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 93-103
    context: "93:       selectOldest(left._1 ++ right._1, left._2 ++ right._2, left._3
      ++ right._3)\n94:     }\n95:   }\n96: \n97:   val io = IO(new Bundle() {\n98:\
      \     val redirect        = Flipped(Valid(new Redirect))\n99:     val enq  \
      \           = Vec(enqPortNum, Flipped(new MisalignBufferEnqIO))\n100:     val
      rob             = Flipped(new RobLsqIO)\n101:     val splitStoreReq   = Decoupled(new
      LsPipelineBundle)\n102:     val splitStoreResp  = Flipped(Valid(new SqWriteBundle))\n\
      103:     val writeBack       = Decoupled(new MemExuOutput)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 149-159
    context: "149: \n150:   val reqSelValid = reqSel._1(0)\n151:   val reqSelBits\
      \  = reqSel._2(0)\n152:   val reqSelPort  = reqSel._3(0)\n153: \n154:   val
      reqRedirect = reqSelBits.uop.robIdx.needFlush(io.redirect)\n155: \n156:   val
      canEnq = WireInit(false.B)\n157:   canEnq := !req_valid && !reqRedirect && reqSelValid\n\
      158:   val robMatch = req_valid && io.rob.pendingst && (io.rob.pendingPtr ===
      req.uop.robIdx)\n159: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/StoreMisalignBuffer.scala
    lines: 640-650
    context: "640:       wb.bits.vecTriggerMask    := 0.U\n641:       wb.bits.nc \
      \               := globalNC\n642:     }\n643:   }\n644: \n645:   val flush =
      req_valid && req.uop.robIdx.needFlush(io.redirect)\n646: \n647:   when (flush
      || s2_needRevoke) {\n648:     bufferState := s_idle\n649:     req_valid := Mux(\n\
      650:       cross4KBPageEnq && cross4KBPageBoundary && !reqRedirect && !s2_needRevoke,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 113-123
    context: "113:       selectOldest(left._1 ++ right._1, left._2 ++ right._2)\n\
      114:     }\n115:   }\n116: \n117:   val io = IO(new Bundle() {\n118:     val
      redirect        = Flipped(Valid(new Redirect))\n119:     val enq           \
      \  = Vec(enqPortNum, Flipped(new MisalignBufferEnqIO))\n120:     val rob   \
      \          = Flipped(new RobLsqIO)\n121:     val splitLoadReq    = Decoupled(new
      LsPipelineBundle)\n122:     val splitLoadResp   = Flipped(Valid(new LqWriteBundle))\n\
      123:     val writeBack       = Decoupled(new MemExuOutput)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 152-162
    context: "152:     }\n153:   }\n154: \n155:   val select_req_bit   = ParallelPriorityMux(io.enq.map(_.req.valid),
      io.enq.map(_.req.bits))\n156:   val select_req_valid = io.enq.map(_.req.valid).reduce(_
      || _)\n157:   val canEnqValid = !req_valid && !select_req_bit.uop.robIdx.needFlush(io.redirect)
      && select_req_valid\n158:   when(canEnqValid) {\n159:     req := select_req_bit\n\
      160:     req_valid := true.B\n161:   }\n162: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadMisalignBuffer.scala
    lines: 595-605
    context: "595:   io.vecWriteBack.bits.vstart               := req.uop.vpu.vstart\n\
      596:   io.vecWriteBack.bits.vecTriggerMask       := req.vecTriggerMask\n597:\
      \   io.vecWriteBack.bits.nc                   := globalNC\n598: \n599: \n600:\
      \   val flush = req_valid && req.uop.robIdx.needFlush(io.redirect)\n601: \n\
      602:   when (flush) {\n603:     bufferState := s_idle\n604:     req_valid :=
      false.B\n605:     curPtr := 0.U"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 174-184
    context: "174:   with HasTlbConst\n175:   with HasPerfEvents\n176: {\n177:   val
      io = IO(new Bundle() {\n178:     // control\n179:     val redirect = Flipped(ValidIO(new
      Redirect))\n180:     val vecFeedback = Vec(VecLoadPipelineWidth, Flipped(ValidIO(new
      FeedbackToLsqIO)))\n181: \n182:     // from load unit s3\n183:     val enq =
      Vec(LoadPipelineWidth, Flipped(Decoupled(new LqWriteBundle)))\n184: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 272-282
    context: "272: \n273:   /**\n274:    * Enqueue\n275:    */\n276:   val canEnqueue
      = io.enq.map(_.valid)\n277:   val cancelEnq = io.enq.map(enq => enq.bits.uop.robIdx.needFlush(io.redirect))\n\
      278:   val needReplay = io.enq.map(enq => enq.bits.rep_info.need_rep)\n279:\
      \   val hasExceptions = io.enq.map(enq => ExceptionNO.selectByFu(enq.bits.uop.exceptionVec,
      LduCfg).asUInt.orR && !enq.bits.tlbMiss)\n280:   val loadReplay = io.enq.map(enq
      => enq.bits.isLoadReplay)\n281:   val needEnqueue = VecInit((0 until LoadPipelineWidth).map(w
      => {\n282:     canEnqueue(w) && !cancelEnq(w) && needReplay(w) && !hasExceptions(w)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 501-512
    context: "501: \n502:   val replay_req = Wire(Vec(LoadPipelineWidth, DecoupledIO(new
      LsPipelineBundle)))\n503: \n504:   for (i <- 0 until LoadPipelineWidth) {\n\
      505:     val s0_can_go = s1_can_go(i) ||\n506:                     uop(s1_oldestSel(i).bits).robIdx.needFlush(io.redirect)
      ||\n507:                     uop(s1_oldestSel(i).bits).robIdx.needFlush(RegNext(io.redirect))\n\
      508:     val s0_oldestSelIndexOH = s0_oldestSel(i).bits // one-hot\n509:   \
      \  s1_oldestSel(i).valid := RegEnable(s0_oldestSel(i).valid, false.B, s0_can_go)\n\
      510:     s1_oldestSel(i).bits := RegEnable(OHToUInt(s0_oldestSel(i).bits), s0_can_go)\n\
      511: \n512:     for (j <- 0 until LoadQueueReplaySize) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 515-526
    context: "515:       }\n516:     }\n517:   }\n518:   val s2_cancelReplay = Wire(Vec(LoadPipelineWidth,
      Bool()))\n519:   for (i <- 0 until LoadPipelineWidth) {\n520:     val s1_cancel
      = uop(s1_oldestSel(i).bits).robIdx.needFlush(io.redirect) ||\n521:         \
      \            uop(s1_oldestSel(i).bits).robIdx.needFlush(RegNext(io.redirect))\n\
      522:     val s1_oldestSelV = s1_oldestSel(i).valid && !s1_cancel\n523:     s1_can_go(i)\
      \          := replayCanFire(i) && (!s2_oldestSel(i).valid || replay_req(i).fire)
      || s2_cancelReplay(i)\n524:     s2_oldestSel(i).valid := RegEnable(Mux(s1_can_go(i),
      s1_oldestSelV, false.B), false.B, (s1_can_go(i) || replay_req(i).fire))\n525:\
      \     s2_oldestSel(i).bits  := RegEnable(s1_oldestSel(i).bits, s1_can_go(i))\n\
      526: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 536-546
    context: "536:     val s2_replacementUpdated = RegEnable(replacementUpdated(s1_replayIdx),
      s1_can_go(i))\n537:     val s2_missDbUpdated = RegEnable(missDbUpdated(s1_replayIdx),
      s1_can_go(i))\n538:     val s2_replayCauses = RegEnable(cause(s1_replayIdx),
      s1_can_go(i))\n539:     val s2_replayCarry = RegEnable(replayCarryReg(s1_replayIdx),
      s1_can_go(i))\n540:     val s2_replayCacheMissReplay = RegEnable(trueCacheMissReplay(s1_replayIdx),
      s1_can_go(i))\n541:     s2_cancelReplay(i) := s2_replayUop.robIdx.needFlush(io.redirect)\n\
      542: \n543:     s2_can_go(i) := DontCare\n544:     replay_req(i).valid     \
      \        := s2_oldestSel(i).valid\n545:     replay_req(i).bits             \
      \ := DontCare\n546:     replay_req(i).bits.uop          := s2_replayUop"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/lsqueue/LoadQueueReplay.scala
    lines: 734-758
    context: "734:   // vector load, all replay entries of same robidx and uopidx\n\
      735:   // should be released when vlmergebuffer commit or flush\n736:   val
      vecLdCanceltmp = Wire(Vec(LoadQueueReplaySize, Vec(VecLoadPipelineWidth, Bool())))\n\
      737:   val vecLdCancel = Wire(Vec(LoadQueueReplaySize, Bool()))\n738:   val
      vecLdCommittmp = Wire(Vec(LoadQueueReplaySize, Vec(VecLoadPipelineWidth, Bool())))\n\
      739:   val vecLdCommit = Wire(Vec(LoadQueueReplaySize, Bool()))\n740:   for
      (i <- 0 until LoadQueueReplaySize) {\n741:     val fbk = io.vecFeedback\n742:\
      \     for (j <- 0 until VecLoadPipelineWidth) {\n743:       vecLdCanceltmp(i)(j)
      := allocated(i) && fbk(j).valid && fbk(j).bits.isFlush && uop(i).robIdx ===
      fbk(j).bits.robidx && uop(i).uopIdx === fbk(j).bits.uopidx\n744:       vecLdCommittmp(i)(j)
      := allocated(i) && fbk(j).valid && fbk(j).bits.isCommit && uop(i).robIdx ===
      fbk(j).bits.robidx && uop(i).uopIdx === fbk(j).bits.uopidx\n745:     }\n746:\
      \     vecLdCancel(i) := vecLdCanceltmp(i).reduce(_ || _)\n747:     vecLdCommit(i)
      := vecLdCommittmp(i).reduce(_ || _)\n748:     XSError(((vecLdCancel(i) || vecLdCommit(i))
      && allocated(i)), s\"vector load, should not have replay entry $i when commit
      or flush.\\n\")\n749:   }\n750: \n751:   // misprediction recovery / exception
      redirect\n752:   for (i <- 0 until LoadQueueReplaySize) {\n753:     needCancel(i)
      := uop(i).robIdx.needFlush(io.redirect) && allocated(i)\n754:     when (needCancel(i))
      {\n755:       allocated(i) := false.B\n756:       freeMaskVec(i) := true.B\n\
      757:     }\n758:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 117-127
    context: "117:   with HasVLSUParameters\n118:   with SdtrigExt\n119: {\n120: \
      \  val io = IO(new Bundle() {\n121:     // control\n122:     val redirect  \
      \    = Flipped(ValidIO(new Redirect))\n123:     val csrCtrl       = Flipped(new
      CustomCSRCtrlIO)\n124: \n125:     // int issue path\n126:     val ldin     \
      \     = Flipped(Decoupled(new MemExuInput))\n127:     val ldout         = Decoupled(new
      MemExuOutput)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 201-211
    context: "201:     // to misalign buffer\n202:     val misalign_enq = new MisalignBufferEnqIO\n\
      203:     val misalign_allow_spec = Input(Bool())\n204: \n205:     // Load RAR
      rollback\n206:     val rollback = Valid(new Redirect)\n207: \n208:     // perf\n\
      209:     val debug_ls         = Output(new DebugLsInfoBundle)\n210:     val
      lsTopdownInfo    = Output(new LsTopdownInfo)\n211:     val correctMissTrain
      = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 303-313
    context: "303:   // priority: high to low\n304:   val s0_rep_stall           =
      io.ldin.valid && isAfter(io.replay.bits.uop.lqIdx, io.ldin.bits.uop.lqIdx) ||\n\
      305:                                io.vecldin.valid && isAfter(io.replay.bits.uop.lqIdx,
      io.vecldin.bits.uop.lqIdx)\n306:   private val SRC_NUM = 11\n307:   private
      val Seq(\n308:     mab_idx, super_rep_idx, fast_rep_idx, mmio_idx, nc_idx, lsq_rep_idx,\n\
      309:     high_pf_idx, vec_iss_idx, int_iss_idx, l2l_fwd_idx, low_pf_idx\n310:\
      \   ) = (0 until SRC_NUM).toSeq\n311:   // load flow source valid\n312:   val
      s0_src_valid_vec = WireInit(VecInit(Seq(\n313:     io.misalign_ldin.valid,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 316-326
    context: "316:     io.lsq.uncache.valid,\n317:     io.lsq.nc_ldin.valid,\n318:\
      \     io.replay.valid && !io.replay.bits.forward_tlDchannel && !s0_rep_stall,\n\
      319:     io.prefetch_req.valid && io.prefetch_req.bits.confidence > 0.U,\n320:\
      \     io.vecldin.valid,\n321:     io.ldin.valid, // int flow first issue or
      software prefetch\n322:     io.l2l_fwd_in.valid,\n323:     io.prefetch_req.valid
      && io.prefetch_req.bits.confidence === 0.U,\n324:   )))\n325:   // load flow
      source ready\n326:   val s0_src_ready_vec = Wire(Vec(SRC_NUM, Bool()))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 331-341
    context: "331:   // load flow source select (OH)\n332:   val s0_src_select_vec
      = WireInit(VecInit((0 until SRC_NUM).map{i => s0_src_valid_vec(i) && s0_src_ready_vec(i)}))\n\
      333:   val s0_hw_prf_select = s0_src_select_vec(high_pf_idx) || s0_src_select_vec(low_pf_idx)\n\
      334: \n335:   val s0_tlb_no_query = s0_hw_prf_select || s0_sel_src.prf_i ||\n\
      336:     s0_src_select_vec(fast_rep_idx) || s0_src_select_vec(mmio_idx) ||\n\
      337:     s0_src_select_vec(nc_idx)\n338:   s0_valid := !s0_kill && (s0_src_select_vec(nc_idx)
      || ((\n339:     s0_src_valid_vec(mab_idx) ||\n340:     s0_src_valid_vec(super_rep_idx)
      ||\n341:     s0_src_valid_vec(fast_rep_idx) ||"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 343-357
    context: "343:     s0_src_valid_vec(high_pf_idx) ||\n344:     s0_src_valid_vec(vec_iss_idx)
      ||\n345:     s0_src_valid_vec(int_iss_idx) ||\n346:     s0_src_valid_vec(l2l_fwd_idx)
      ||\n347:     s0_src_valid_vec(low_pf_idx)\n348:   ) && !s0_src_select_vec(mmio_idx)
      && io.dcache.req.ready &&\n349:     !(io.misalign_ldin.fire && io.misalign_ldin.bits.misalignNeedWakeUp)
      // Currently, misalign is the highest priority\n350:   ))\n351: \n352:   s0_mmio_select
      := s0_src_select_vec(mmio_idx) && !s0_kill\n353:   s0_nc_select := s0_src_select_vec(nc_idx)
      && !s0_kill\n354:   //judgment: is NC with data or not.\n355:   //If true, it's
      from `io.lsq.nc_ldin` or `io.fast_rep_in`\n356:   val s0_nc_with_data = s0_sel_src.isnc
      && !s0_kill\n357:   s0_misalign_select := s0_src_select_vec(mab_idx) && !s0_kill"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1050-1066
    context: "1050:   val s1_addr_misaligned       = WireInit(false.B)\n1051:   val
      s1_fast_mismatch         = WireInit(false.B)\n1052:   val s1_ptr_chasing_canceled\
      \  = WireInit(false.B)\n1053:   val s1_cancel_ptr_chasing    = WireInit(false.B)\n\
      1054: \n1055:   val s1_redirect_reg = Wire(Valid(new Redirect))\n1056:   s1_redirect_reg.bits
      := RegEnable(io.redirect.bits, io.redirect.valid)\n1057:   s1_redirect_reg.valid
      := GatedValidRegNext(io.redirect.valid)\n1058: \n1059:   s1_kill := s1_fast_rep_dly_kill
      ||\n1060:     s1_cancel_ptr_chasing ||\n1061:     s1_in.uop.robIdx.needFlush(io.redirect)
      ||\n1062:     (s1_in.uop.robIdx.needFlush(s1_redirect_reg) && !GatedValidRegNext(s0_try_ptr_chasing))
      ||\n1063:     RegEnable(s0_kill, false.B, io.ldin.valid ||\n1064:       io.vecldin.valid
      || io.replay.valid ||\n1065:       io.l2l_fwd_in.valid || io.fast_rep_in.valid
      ||\n1066:       io.misalign_ldin.valid || io.lsq.nc_ldin.valid"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1177-1187
    context: "1177:   val s3_misalign_wakeup_req_bits = WireInit(0.U.asTypeOf(new
      LqWriteBundle))\n1178:   connectSamePort(s3_misalign_wakeup_req_bits, io.misalign_ldin.bits)\n\
      1179:   s3_misalign_wakeup_req.valid := RegNextN(io.misalign_ldin.bits.misalignNeedWakeUp
      && io.misalign_ldin.fire, 3, Some(false.B))\n1180:   s3_misalign_wakeup_req.bits\
      \  := RegNextN(s3_misalign_wakeup_req_bits, 3)\n1181: \n1182:   s2_kill := s2_in.uop.robIdx.needFlush(io.redirect)\n\
      1183:   s2_ready := !s2_valid || s2_kill || s3_ready\n1184:   when (s1_fire)
      { s2_valid := true.B }\n1185:   .elsewhen (s2_fire) { s2_valid := false.B }\n\
      1186:   .elsewhen (s2_kill) { s2_valid := false.B }\n1187:   s2_in := RegEnable(s1_out,
      s1_fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1512-1522
    context: "1512:   // Pipeline\n1513:   // --------------------------------------------------------------------------------\n\
      1514:   // stage 3\n1515:   // --------------------------------------------------------------------------------\n\
      1516:   // writeback and update load queue\n1517:   val s3_valid        = GatedValidRegNext(s2_valid
      && !s2_out.isHWPrefetch && !s2_out.uop.robIdx.needFlush(io.redirect))\n1518:\
      \   val s3_in           = RegEnable(s2_out, s2_fire)\n1519:   val s3_out   \
      \       = Wire(Valid(new MemExuOutput))\n1520:   val s3_dcache_rep   = RegEnable(s2_dcache_fast_rep
      && s2_troublem, false.B, s2_fire)\n1521:   val s3_ld_valid_dup = RegEnable(s2_ld_valid_dup,
      s2_fire)\n1522:   val s3_fast_rep     = Wire(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1520-1530
    context: "1520:   val s3_dcache_rep   = RegEnable(s2_dcache_fast_rep && s2_troublem,
      false.B, s2_fire)\n1521:   val s3_ld_valid_dup = RegEnable(s2_ld_valid_dup,
      s2_fire)\n1522:   val s3_fast_rep     = Wire(Bool())\n1523:   val s3_nc_with_data
      = RegNext(s2_nc_with_data)\n1524:   val s3_troublem     = GatedValidRegNext(s2_troublem)\n\
      1525:   val s3_kill         = s3_in.uop.robIdx.needFlush(io.redirect)\n1526:\
      \   val s3_vecout       = Wire(new OnlyVecExuOutput)\n1527:   val s3_vecActive\
      \    = RegEnable(s2_out.vecActive, true.B, s2_fire)\n1528:   val s3_isvec  \
      \      = RegEnable(s2_out.isvec, false.B, s2_fire)\n1529:   val s3_vec_alignedType
      = RegEnable(s2_out.alignedType, s2_fire)\n1530:   val s3_vec_mBIndex     = RegEnable(s2_out.mbIndex,
      s2_fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/LoadUnit.scala
    lines: 1832-1842
    context: "1832:   io.vecldout.bits.mmio := DontCare\n1833:   io.vecldout.bits.vstart
      := s3_vecout.vstart\n1834:   io.vecldout.bits.vecTriggerMask := s3_vecout.vecTriggerMask\n\
      1835:   io.vecldout.bits.nc := DontCare\n1836: \n1837:   io.vecldout.valid :=
      s3_out.valid && !s3_out.bits.uop.robIdx.needFlush(io.redirect) && s3_vecout.isvec
      && !s3_mis_align && !s3_frm_mabuf //||\n1838:   // TODO: check this, why !io.lsq.uncache.bits.isVls
      before?\n1839:   // Now vector instruction don't support mmio.\n1840:     //
      io.lsq.uncache.valid && !io.lsq.uncache.bits.uop.robIdx.needFlush(io.redirect)
      && !s3_out.valid && io.lsq.uncache.bits.isVls\n1841:     //io.lsq.uncache.valid
      && !io.lsq.uncache.bits.uop.robIdx.needFlush(io.redirect) && !s3_out.valid &&
      !io.lsq.uncache.bits.isVls\n1842: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 36-46
    context: "36: class StoreUnit(implicit p: Parameters) extends XSModule\n37:  \
      \ with HasDCacheParameters\n38:   with HasVLSUParameters\n39:   {\n40:   val
      io = IO(new Bundle() {\n41:     val redirect        = Flipped(ValidIO(new Redirect))\n\
      42:     val csrCtrl         = Flipped(new CustomCSRCtrlIO)\n43:     val stin\
      \            = Flipped(Decoupled(new MemExuInput))\n44:     val issue      \
      \     = Valid(new MemExuInput)\n45:     // misalignBuffer issue path\n46:  \
      \   val misalign_stin   = Flipped(Decoupled(new LsPipelineBundle))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 114-124
    context: "114:   val s0_rob_idx      = Mux(s0_use_non_prf_flow, s0_uop.robIdx,
      0.U.asTypeOf(s0_uop.robIdx))\n115:   val s0_pc           = Mux(s0_use_non_prf_flow,
      s0_uop.pc, 0.U)\n116:   val s0_instr_type   = Mux(s0_use_non_prf_flow, STORE_SOURCE.U,
      DCACHE_PREFETCH_SOURCE.U)\n117:   val s0_wlineflag    = Mux(s0_use_flow_rs,
      LSUOpType.isCboAll(s0_uop.fuOpType), false.B)\n118:   val s0_out          =
      Wire(new LsPipelineBundle)\n119:   val s0_kill         = s0_uop.robIdx.needFlush(io.redirect)\n\
      120:   val s0_can_go       = s1_ready\n121:   val s0_fire         = s0_valid
      && !s0_kill && s0_can_go\n122:   val s0_is128bit     = Wire(Bool())\n123:  \
      \ // vector\n124:   val s0_vecActive    = !s0_use_flow_vec || s0_vecstin.vecActive"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 303-313
    context: "303:   //We don't want `StoreUnit` to have an additional effect on the
      Store of vector from a `misalignBuffer,`\n304:   //But there are places where
      a marker bit is needed to enable additional processing of vector instructions.\n\
      305:   //For example: `StoreQueue` is exceptionBuffer\n306:   val s1_frm_mab_vec
      = RegEnable(s0_use_flow_ma && io.misalign_stin.bits.isvec, false.B, s0_fire)\n\
      307:   // val s1_isLastElem = RegEnable(s0_isLastElem, false.B, s0_fire)\n308:\
      \   s1_kill := s1_in.uop.robIdx.needFlush(io.redirect) || (s1_tlb_miss && !s1_isvec
      && !s1_frm_mabuf)\n309: \n310:   s1_ready := !s1_valid || s1_kill || s2_ready\n\
      311:   io.tlb.resp.ready := true.B // TODO: why dtlbResp needs a ready?\n312:\
      \   when (s0_fire) { s1_valid := true.B }\n313:   .elsewhen (s1_fire) { s1_valid
      := false.B }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 406-416
    context: "406:   io.lsq.bits      := s1_out\n407:   io.lsq.bits.miss := s1_tlb_miss\n\
      408:   io.lsq.bits.isvec := s1_out.isvec || s1_frm_mab_vec\n409:   io.lsq.bits.updateAddrValid
      := (!s1_in.isMisalign || s1_in.misalignWith16Byte) && (!s1_frm_mabuf || s1_in.isFinalSplit)
      || s1_exception\n410:   // kill dcache write intent request when tlb miss or
      exception\n411:   io.dcache.s1_kill  := (s1_tlb_miss || s1_exception || s1_out.mmio
      || s1_out.nc || s1_in.uop.robIdx.needFlush(io.redirect))\n412:   io.dcache.s1_paddr
      := s1_paddr\n413: \n414:   // write below io.out.bits assign sentence to prevent
      overwriting values\n415:   val s1_tlb_memidx = io.tlb.resp.bits.memidx\n416:\
      \   when(s1_tlb_memidx.is_st && io.tlb.resp.valid && !s1_tlb_miss && s1_tlb_memidx.idx
      === s1_out.uop.sqIdx.value) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 468-478
    context: "468:   // This real physical address is located in uncache space.\n\
      469:   val s2_actually_uncache = s2_tlb_hit && !s2_un_access_exception && (Pbmt.isPMA(s2_pbmt)
      && s2_pmp.mmio || s2_in.nc || s2_in.mmio) && RegNext(s1_feedback.bits.hit)\n\
      470:   val s2_isCbo  = RegEnable(s1_isCbo, s1_fire) // all cbo instr\n471: \
      \  val s2_isCbo_noZero = LSUOpType.isCbo(s2_in.uop.fuOpType)\n472: \n473:  \
      \ s2_kill := ((s2_mmio && !s2_exception) && !s2_in.isvec && !s2_frm_mabuf) ||
      s2_in.uop.robIdx.needFlush(io.redirect)\n474: \n475:   s2_out        := s2_in\n\
      476:   s2_out.af     := s2_out.uop.exceptionVec(storeAccessFault)\n477:   s2_out.mmio\
      \   := s2_mmio && !s2_exception\n478:   s2_out.memBackTypeMM := s2_memBackTypeMM"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 483-493
    context: "483:                                                 ) && s2_vecActive\n\
      484:   s2_out.uop.exceptionVec(storeAddrMisaligned) := s2_actually_uncache &&
      !s2_in.isvec && (s2_in.isMisalign || s2_in.isFrmMisAlignBuf) && !s2_un_misalign_exception\n\
      485:   s2_out.uop.vpu.vstart     := s2_in.vecVaddrOffset >> s2_in.uop.vpu.veew\n\
      486: \n487:   // kill dcache write intent request when mmio or exception\n488:\
      \   io.dcache.s2_kill := (s2_actually_uncache || s2_exception || s2_in.uop.robIdx.needFlush(io.redirect))\n\
      489:   io.dcache.s2_pc   := s2_out.uop.pc\n490:   // TODO: dcache resp\n491:\
      \   io.dcache.resp.ready := true.B\n492: \n493:   val s2_mis_align = s2_valid
      && RegEnable(s1_mis_align, s1_fire) && !s2_exception"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 497-512
    context: "497:     RegEnable(s1_toMisalignBufferValid && !io.misalign_enq.req.ready,
      false.B, s1_fire)\n498: \n499:   // feedback tlb miss to RS in store_s2\n500:\
      \   val feedback_slow_valid = WireInit(false.B)\n501: \n502:   feedback_slow_valid
      := s1_feedback.valid && !s1_out.uop.robIdx.needFlush(io.redirect) && !s1_out.isvec
      && !s1_frm_mabuf\n503:   io.feedback_slow.valid := GatedValidRegNext(feedback_slow_valid)\n\
      504:   io.feedback_slow.bits  := RegEnable(s1_feedback.bits, feedback_slow_valid)\n\
      505:   io.feedback_slow.bits.hit  := RegEnable(s1_feedback.bits.hit, feedback_slow_valid)
      && !s2_misalignBufferNack\n506: \n507:   val s2_vecFeedback = RegNext(!s1_out.uop.robIdx.needFlush(io.redirect)
      && s1_feedback.bits.hit && s1_feedback.valid) &&\n508:                     \
      \   !s2_misalignBufferNack && s2_in.isvec && !s2_frm_mabuf\n509: \n510:   val
      s2_misalign_stout = WireInit(0.U.asTypeOf(io.misalign_stout))\n511:   s2_misalign_stout.valid
      := s2_valid && s2_can_go && s2_frm_mabuf\n512:   connectSamePort(s2_misalign_stout.bits,
      s2_out)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 562-572
    context: "562:   // --------------------------------------------------------------------------------\n\
      563:   // store write back\n564:   val s3_valid  = RegInit(false.B)\n565:  \
      \ val s3_in     = RegEnable(s2_out, s2_fire)\n566:   val s3_out    = Wire(new
      MemExuOutput(isVector = true))\n567:   val s3_kill   = s3_in.uop.robIdx.needFlush(io.redirect)\n\
      568:   val s3_can_go = s3_ready\n569:   val s3_fire   = s3_valid && !s3_kill
      && s3_can_go\n570:   val s3_vecFeedback = RegEnable(s2_vecFeedback, s2_fire)\n\
      571:   val s3_exception     = RegEnable(s2_exception, s2_fire)\n572: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 615-630
    context: "615:       sx_in(i).gpaddr      := s3_in.gpaddr\n616:       sx_in(i).isForVSnonLeafPTE\
      \     := s3_in.isForVSnonLeafPTE\n617:       sx_in(i).vecTriggerMask := s3_in.vecTriggerMask\n\
      618:       sx_in(i).hasException := s3_exception\n619:       sx_in_vec(i)  \
      \       := s3_in.isvec\n620:       sx_ready(i) := !s3_valid(i) || sx_in(i).output.uop.robIdx.needFlush(io.redirect)
      || (if (RAWTotalDelayCycles == 0) io.stout.ready else sx_ready(i+1))\n621: \
      \    } else {\n622:       val cur_kill   = sx_in(i).output.uop.robIdx.needFlush(io.redirect)\n\
      623:       val cur_can_go = (if (i == RAWTotalDelayCycles) io.stout.ready else
      sx_ready(i+1))\n624:       val cur_fire   = sx_valid(i) && !cur_kill && cur_can_go\n\
      625:       val prev_fire  = sx_valid(i-1) && !sx_in(i-1).output.uop.robIdx.needFlush(io.redirect)
      && sx_ready(i)\n626: \n627:       sx_ready(i) := !sx_valid(i) || cur_kill ||
      (if (i == RAWTotalDelayCycles) io.stout.ready else sx_ready(i+1))\n628:    \
      \   val sx_valid_can_go = prev_fire || cur_fire || cur_kill\n629:       sx_valid(i)
      := RegEnable(Mux(prev_fire, true.B, false.B), false.B, sx_valid_can_go)\n630:\
      \       sx_in(i) := RegEnable(sx_in(i-1), prev_fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/StoreUnit.scala
    lines: 633-643
    context: "633:   }\n634:   val sx_last_valid = sx_valid.takeRight(1).head\n635:\
      \   val sx_last_ready = sx_ready.takeRight(1).head\n636:   val sx_last_in  \
      \  = sx_in.takeRight(1).head\n637:   val sx_last_in_vec = sx_in_vec.takeRight(1).head\n\
      638:   sx_last_ready := !sx_last_valid || sx_last_in.output.uop.robIdx.needFlush(io.redirect)
      || io.stout.ready\n639: \n640:   // write back: normal store, nc store\n641:\
      \   io.stout.valid := sx_last_valid && !sx_last_in_vec //isStore(sx_last_in.output.uop.fuType)\n\
      642:   io.stout.bits := sx_last_in.output\n643:   io.stout.bits.uop.exceptionVec
      := ExceptionNO.selectByFu(sx_last_in.output.uop.exceptionVec, StaCfg)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 45-55
    context: "45:   with HasVLSUParameters\n46:   with SdtrigExt\n47: {\n48:   val
      io = IO(new Bundle() {\n49:     // control\n50:     val redirect      = Flipped(ValidIO(new
      Redirect))\n51:     val csrCtrl       = Flipped(new CustomCSRCtrlIO)\n52: \n\
      53:     // flow in\n54:     val lsin          = Flipped(Decoupled(new MemExuInput))\n\
      55: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 110-120
    context: "110:       // Load fast replay path\n111:       val fast_rep_in  = Flipped(Decoupled(new
      LqWriteBundle))\n112:       val fast_rep_out = Decoupled(new LqWriteBundle)\n\
      113: \n114:       // Load RAR rollback\n115:       val rollback = Valid(new
      Redirect)\n116: \n117:       // perf\n118:       val debug_ls         = Output(new
      DebugLsInfoBundle)\n119:       val lsTopdownInfo    = Output(new LsTopdownInfo)\n\
      120:     }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 214-224
    context: "214:   val s0_src_valid_vec = WireInit(VecInit(Seq(\n215:     io.ldu_io.replay.valid
      && io.ldu_io.replay.bits.forward_tlDchannel,\n216:     io.ldu_io.fast_rep_in.valid,\n\
      217:     io.ldu_io.replay.valid && !io.ldu_io.replay.bits.forward_tlDchannel
      && !s0_rep_stall,\n218:     io.ldu_io.prefetch_req.valid && io.ldu_io.prefetch_req.bits.confidence
      > 0.U,\n219:     io.lsin.valid, // int flow first issue or software prefetch\n\
      220:     io.vec_stu_io.in.valid,\n221:     io.ldu_io.l2l_fwd_in.valid && io.ldu_io.ld_fast_match,\n\
      222:     io.ldu_io.prefetch_req.valid && io.ldu_io.prefetch_req.bits.confidence
      === 0.U,\n223:   )))\n224:   // load flow source ready"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 242-252
    context: "242:   // which is S0's out is ready and dcache is ready\n243:   val
      s0_try_ptr_chasing      = s0_src_select_vec(l2l_fwd_idx)\n244:   val s0_do_try_ptr_chasing\
      \   = s0_try_ptr_chasing && s0_can_go && io.ldu_io.dcache.req.ready\n245:  \
      \ val s0_ptr_chasing_vaddr    = io.ldu_io.l2l_fwd_in.data(5, 0) +& io.ldu_io.ld_fast_imm(5,
      0)\n246:   val s0_ptr_chasing_canceled = WireInit(false.B)\n247:   s0_kill :=
      s0_ptr_chasing_canceled || (s0_out.uop.robIdx.needFlush(io.redirect) && !s0_try_ptr_chasing)\n\
      248: \n249:   // prefetch related ctrl signal\n250:   val s0_prf    = Wire(Bool())\n\
      251:   val s0_prf_rd = Wire(Bool())\n252:   val s0_prf_wr = Wire(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 709-719
    context: "709:   val s1_ptr_chasing_canceled  = WireInit(false.B)\n710:   val
      s1_cancel_ptr_chasing    = WireInit(false.B)\n711: \n712:   s1_kill := s1_late_kill
      ||\n713:              s1_cancel_ptr_chasing ||\n714:              s1_in.uop.robIdx.needFlush(io.redirect)
      ||\n715:              RegEnable(s0_kill, false.B, io.lsin.valid || io.ldu_io.replay.valid
      || io.ldu_io.l2l_fwd_in.valid || io.ldu_io.fast_rep_in.valid || io.vec_stu_io.in.valid)\n\
      716: \n717:   if (EnableLoadToLoadForward) {\n718:     // Sometimes, we need
      to cancel the load-load forwarding.\n719:     // These can be put at S0 if timing
      is bad at S1."
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 767-777
    context: "767:   io.ldu_io.forward_mshr.paddr  := s1_out.paddr\n768: \n769:  \
      \ io.ldu_io.wakeup.valid := s0_fire && s0_ld_flow && (s0_src_select_vec(super_rep_idx)
      || s0_src_select_vec(fast_rep_idx) || s0_src_select_vec(lsq_rep_idx) || s0_src_select_vec(int_iss_idx))\n\
      770:   io.ldu_io.wakeup.bits := s0_uop\n771: \n772:   io.stu_io.dcache.s1_kill
      := s1_tlb_miss || s1_exception || s1_mmio || s1_in.uop.robIdx.needFlush(io.redirect)\n\
      773:   io.stu_io.dcache.s1_paddr := s1_paddr_dup_dcache\n774: \n775: \n776:\
      \   // load debug\n777:   XSDebug(s1_valid && s1_ld_flow,"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 819-829
    context: "819:   val s2_fire   = s2_valid && !s2_kill && s2_can_go\n820:   val
      s2_isvec  = RegEnable(s1_isvec, false.B, s1_fire)\n821:   val s2_vecActive \
      \   = RegEnable(s1_out.vecActive, true.B, s1_fire)\n822:   val s2_paddr  = RegEnable(s1_paddr_dup_lsu,
      s1_fire)\n823: \n824:   s2_kill := s2_in.uop.robIdx.needFlush(io.redirect)\n\
      825:   s2_ready := !s2_valid || s2_kill || s3_ready\n826:   when (s1_fire) {
      s2_valid := true.B }\n827:   .elsewhen (s2_fire) { s2_valid := false.B }\n828:\
      \   .elsewhen (s2_kill) { s2_valid := false.B }\n829:   s2_in := RegEnable(s1_out,
      s1_fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1119-1129
    context: "1119:   // Pipeline\n1120:   // --------------------------------------------------------------------------------\n\
      1121:   // stage 3\n1122:   // --------------------------------------------------------------------------------\n\
      1123:   // writeback and update load queue\n1124:   val s3_valid        = RegNext(s2_valid
      && !s2_out.isHWPrefetch && !s2_out.uop.robIdx.needFlush(io.redirect))\n1125:\
      \   val s3_in           = RegEnable(s2_out, s2_fire)\n1126:   val s3_out   \
      \       = Wire(Valid(new MemExuOutput))\n1127:   val s3_dcache_rep   = RegEnable(s2_dcache_fast_rep
      && s2_troublem, false.B, s2_fire)\n1128:   val s3_ld_valid_dup = RegEnable(s2_ld_valid_dup,
      s2_fire)\n1129:   val s3_fast_rep     = Wire(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1127-1137
    context: "1127:   val s3_dcache_rep   = RegEnable(s2_dcache_fast_rep && s2_troublem,
      false.B, s2_fire)\n1128:   val s3_ld_valid_dup = RegEnable(s2_ld_valid_dup,
      s2_fire)\n1129:   val s3_fast_rep     = Wire(Bool())\n1130:   val s3_ld_flow\
      \      = RegNext(s2_ld_flow)\n1131:   val s3_troublem     = RegNext(s2_troublem)\n\
      1132:   val s3_kill         = s3_in.uop.robIdx.needFlush(io.redirect)\n1133:\
      \   val s3_isvec        = RegNext(s2_isvec)\n1134:   s3_ready := !s3_valid ||
      s3_kill || sx_can_go\n1135: \n1136:   // s3 load fast replay\n1137:   io.ldu_io.fast_rep_out.valid
      := s3_valid &&"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1134-1144
    context: "1134:   s3_ready := !s3_valid || s3_kill || sx_can_go\n1135: \n1136:\
      \   // s3 load fast replay\n1137:   io.ldu_io.fast_rep_out.valid := s3_valid
      &&\n1138:                                   s3_fast_rep &&\n1139:          \
      \                         !s3_in.uop.robIdx.needFlush(io.redirect) &&\n1140:\
      \                                   s3_ld_flow &&\n1141:                   \
      \                !s3_isvec\n1142:   io.ldu_io.fast_rep_out.bits := s3_in\n1143:\
      \ \n1144:   io.ldu_io.lsq.ldin.valid := s3_valid &&"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1229-1239
    context: "1229:                  !s3_exception\n1230: \n1231:   val s3_fb_no_waiting
      = !s3_in.isLoadReplay && !(s3_fast_rep && io.ldu_io.fast_rep_out.ready) && !s3_in.feedbacked\n\
      1232: \n1233:   //\n1234:   io.feedback_slow.valid                 := s3_valid
      && !s3_in.uop.robIdx.needFlush(io.redirect) && s3_fb_no_waiting && s3_ld_flow\n\
      1235:   io.feedback_slow.bits.hit              := !io.ldu_io.lsq.ldin.bits.rep_info.need_rep
      || io.ldu_io.lsq.ldin.ready\n1236:   io.feedback_slow.bits.flushState      \
      \ := s3_in.ptwBack\n1237:   io.feedback_slow.bits.robIdx           := s3_in.uop.robIdx\n\
      1238:   io.feedback_slow.bits.sourceType       := RSFeedbackType.lrqFull\n1239:\
      \   io.feedback_slow.bits.dataInvalidSqIdx := DontCare"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1236-1246
    context: "1236:   io.feedback_slow.bits.flushState       := s3_in.ptwBack\n1237:\
      \   io.feedback_slow.bits.robIdx           := s3_in.uop.robIdx\n1238:   io.feedback_slow.bits.sourceType\
      \       := RSFeedbackType.lrqFull\n1239:   io.feedback_slow.bits.dataInvalidSqIdx
      := DontCare\n1240: \n1241:   io.vec_stu_io.feedbackSlow.valid := RegNext(s2_vec_feedback.valid
      && !s2_out.uop.robIdx.needFlush(io.redirect))\n1242:   io.vec_stu_io.feedbackSlow.bits
      := RegNext(s2_vec_feedback.bits)\n1243: \n1244:   io.ldu_io.ldCancel.ld2Cancel
      := s3_valid && s3_ld_flow && (                          // is load\n1245:  \
      \   io.ldu_io.lsq.ldin.bits.rep_info.need_rep || s3_in.mmio                \
      \            // exe fail or is mmio\n1246:   )"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1282-1292
    context: "1282:   val s3_ld_data_frm_cache = rdataHelper(s3_ld_raw_data_frm_cache.uop,
      s3_picked_data_frm_cache)\n1283: \n1284:   // FIXME: add 1 cycle delay ?\n1285:\
      \   io.ldout.bits      := s3_out.bits\n1286:   io.ldout.bits.data := s3_ld_data_frm_cache\n\
      1287:   io.ldout.valid     := s3_out.valid && !s3_out.bits.uop.robIdx.needFlush(io.redirect)
      && s3_ld_flow && !s3_isvec\n1288: \n1289:   // for uncache\n1290:   io.ldu_io.lsq.uncache.ready
      := true.B\n1291: \n1292:   // fast load to load forward"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1318-1333
    context: "1318:       sx_valid(i) := s3_valid &&\n1319:                     !s3_ld_flow
      &&\n1320:                     !s3_in.feedbacked &&\n1321:                  \
      \   !s3_in.mmio\n1322:       sx_in(i)    := s3_out.bits\n1323:       sx_ready(i)
      := !s3_valid(i) || sx_in(i).uop.robIdx.needFlush(io.redirect) || (if (TotalDelayCycles
      == 0) io.stout.ready else sx_ready(i+1))\n1324:     } else {\n1325:       val
      cur_kill   = sx_in(i).uop.robIdx.needFlush(io.redirect)\n1326:       val cur_can_go
      = (if (i == TotalDelayCycles) io.stout.ready else sx_ready(i+1))\n1327:    \
      \   val cur_fire   = sx_valid(i) && !cur_kill && cur_can_go\n1328:       val
      prev_fire  = sx_valid(i-1) && !sx_in(i-1).uop.robIdx.needFlush(io.redirect)
      && sx_ready(i)\n1329: \n1330:       sx_ready(i) := !sx_valid(i) || cur_kill
      || (if (i == TotalDelayCycles) io.stout.ready else sx_ready(i+1))\n1331:   \
      \    val sx_valid_can_go = prev_fire || cur_fire || cur_kill\n1332:       sx_valid(i)
      := RegEnable(Mux(prev_fire, true.B, false.B), sx_valid_can_go)\n1333:      \
      \ sx_in(i) := RegEnable(sx_in(i-1), prev_fire)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/HybridUnit.scala
    lines: 1336-1347
    context: "1336: \n1337:   val sx_last_valid = sx_valid.takeRight(1).head\n1338:\
      \   val sx_last_ready = sx_ready.takeRight(1).head\n1339:   val sx_last_in \
      \   = sx_in.takeRight(1).head\n1340: \n1341:   sx_last_ready  := !sx_last_valid
      || sx_last_in.uop.robIdx.needFlush(io.redirect) || io.stout.ready\n1342:   io.stout.valid
      := sx_last_valid && !sx_last_in.uop.robIdx.needFlush(io.redirect) && FuType.isStore(sx_last_in.uop.fuType)\n\
      1343:   io.stout.bits  := sx_last_in\n1344: \n1345:   // FIXME: please move
      this part to LoadQueueReplay\n1346:   io.ldu_io.debug_ls := DontCare\n1347:\
      \   io.stu_io.debug_ls := DontCare"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 49-59
    context: "49:     val dcache        = new AtomicWordIO\n50:     val dtlb     \
      \     = new TlbRequestIO(2)\n51:     val pmpResp       = Flipped(new PMPRespBundle())\n\
      52:     val flush_sbuffer = new SbufferFlushBundle\n53:     val feedbackSlow\
      \  = ValidIO(new RSFeedback)\n54:     val redirect      = Flipped(ValidIO(new
      Redirect))\n55:     val exceptionInfo = ValidIO(new Bundle {\n56:       val
      vaddr = UInt(XLEN.W)\n57:       val gpaddr = UInt(XLEN.W)\n58:       val isForVSnonLeafPTE
      = Bool()\n59:     })"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/pipeline/AtomicsUnit.scala
    lines: 416-426
    context: "416:     when (io.out.fire) {\n417:       resetFSM()\n418:     }\n419:\
      \   }\n420: \n421:   when (io.redirect.valid) {\n422:     atom_override_xtval
      := false.B\n423:   }\n424: \n425:   def resetFSM(): Unit = {\n426:     state
      := s_invalid"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/mdp/StoreSet.scala
    lines: 348-358
    context: "348: \n349: // Last Fetched Store Table\n350: class LFST(implicit p:
      Parameters) extends XSModule {\n351:   val io = IO(new Bundle {\n352:     //
      when redirect, mark canceled store as invalid\n353:     val redirect = Input(Valid(new
      Redirect))\n354:     val dispatch = Flipped(new DispatchLFSTIO)\n355:     //
      when store issued, mark store as invalid\n356:     val storeIssue = Vec(backendParams.StaExuCnt,
      Flipped(Valid(new DynInst)))\n357:     val csrCtrl = Input(new CustomCSRCtrlIO)\n\
      358:   })"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/mdp/StoreSet.scala
    lines: 418-428
    context: "418:   })\n419: \n420:   // when redirect, cancel store influenced\n\
      421:   (0 until LFSTSize).map(i => {\n422:     (0 until LFSTWidth).map(j =>
      {\n423:       when(validVec(i)(j) && robIdxVec(i)(j).needFlush(io.redirect)){\n\
      424:         validVec(i)(j) := false.B\n425:       }\n426:     })\n427:   })\n\
      428: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/mdp/StoreSet.scala
    lines: 426-436
    context: "426:     })\n427:   })\n428: \n429:   // recover robIdx after squash\n\
      430:   // behavior model, to be refactored later\n431:   when(RegNext(io.redirect.fire))
      {\n432:     (0 until LFSTSize).map(i => {\n433:       (0 until LFSTWidth).map(j
      => {\n434:         val check_position = WireInit(allocPtr(i) + (j+1).U)\n435:\
      \         when(!validVec(i)(check_position)){\n436:           allocPtr(i) :=
      check_position"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/PrefetcherMonitor.scala
    lines: 37-47
    context: "37:     val late_hit_prefetch = Input(Bool())\n38:     val late_miss_prefetch
      = Input(Bool())\n39:     val prefetch_hit = Input(UInt(2.W))\n40:   }\n41: \n\
      42:   val validity = new XSBundle {\n43:     val good_prefetch = Input(Bool())\n\
      44:     val bad_prefetch = Input(Bool())\n45:   }\n46: \n47:   val pf_ctrl =
      Output(new PrefetchControlBundle)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/PrefetcherMonitor.scala
    lines: 86-97
    context: "86:   total_prefetch_cnt := Mux(timely_reset, 0.U, total_prefetch_cnt
      + io.timely.total_prefetch)\n87:   late_hit_prefetch_cnt := Mux(timely_reset,
      0.U, late_hit_prefetch_cnt + io.timely.late_hit_prefetch)\n88:   late_miss_prefetch_cnt
      := Mux(timely_reset, 0.U, late_miss_prefetch_cnt + io.timely.late_miss_prefetch)\n\
      89:   prefetch_hit_cnt := Mux(timely_reset, 0.U, prefetch_hit_cnt + io.timely.prefetch_hit)\n\
      90: \n91:   good_prefetch_cnt := Mux(validity_reset, 0.U, good_prefetch_cnt
      + io.validity.good_prefetch)\n92:   bad_prefetch_cnt := Mux(validity_reset,
      0.U, bad_prefetch_cnt + io.validity.bad_prefetch)\n93: \n94:   back_off_cnt
      := Mux(back_off_reset, 0.U, back_off_cnt + !enable)\n95:   low_conf_cnt := Mux(conf_reset,
      0.U, low_conf_cnt + !confidence.asBool)\n96: \n97:   val trigger_late_hit =
      timely_reset && (late_hit_prefetch_cnt >= LATE_HIT_THRESHOLD.U)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/PrefetcherMonitor.scala
    lines: 139-150
    context: "139:   }\n140: \n141:   XSPerfAccumulate(\"total_prefetch\", io.timely.total_prefetch)\n\
      142:   XSPerfAccumulate(\"late_hit_prefetch\", io.timely.late_hit_prefetch)\n\
      143:   XSPerfAccumulate(\"late_miss_prefetch\", io.timely.late_miss_prefetch)\n\
      144:   XSPerfAccumulate(\"good_prefetch\", io.validity.good_prefetch)\n145:\
      \   XSPerfAccumulate(\"bad_prefetch\", io.validity.bad_prefetch)\n146:   for(i
      <- (0 until DEPTH_BITS)) {\n147:     val t = (1 << i)\n148:     XSPerfAccumulate(s\"\
      depth${t}\", depth === t.U)\n149:   }\n150:   XSPerfAccumulate(\"trigger_disable\"\
      , trigger_disable)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/prefetch/FDP.scala
    lines: 215-226
    context: "215:   val timely = new XSBundle {\n216:     val late_prefetch = Input(Bool())
      // from mshr enq, a load matches a mshr caused by prefetch\n217:   }\n218: \n\
      219:   val pollution = new XSBundle {\n220:     val demand_miss = Vec(LoadPipelineWidth,
      Input(Bool())) // from load pipeline, first miss\n221:     val cache_pollution
      = Vec(LoadPipelineWidth, Input(Bool())) // from load pipeline, first miss and
      pollution caused\n222:   }\n223: \n224:   val pf_ctrl = Output(new PrefetchControlBundle)\n\
      225:   val debugRolling = Flipped(new RobDebugRollingIO)\n226: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSegmentUnit.scala
    lines: 382-392
    context: "382:   when(io.in.fire && !instMicroOpValid && !isEnqFixVlUop){\n383:\
      \     // element number in a vd\n384:     // TODO Rewrite it in a more elegant
      way.\n385:     val uopFlowNum                    = ZeroExt(GenRealFlowNum(instType,
      emul, lmul, eew, sew, true), elemIdxBits)\n386:     instMicroOp.baseVaddr  \
      \           := io.in.bits.src_rs1\n387:     instMicroOpValid               \
      \   := true.B // if is first uop\n388:     instMicroOp.alignedType         \
      \  := Mux(isIndexed(instType), sew(1, 0), eew)\n389:     instMicroOp.uop   \
      \                := io.in.bits.uop\n390:     instMicroOp.mask              \
      \    := srcMask\n391:     instMicroOp.vstart                := 0.U\n392:   \
      \  instMicroOp.uopFlowNum            := uopFlowNum"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 61-71
    context: "61:   val s0_emul = Mux(us_whole_reg(s0_fuOpType) ,GenUSWholeEmul(s0_uop.vpu.nf),
      Mux(us_mask(s0_fuOpType), 0.U(mulBits.W), EewLog2(s0_eew) - s0_sew + s0_lmul))\n\
      62:   val s0_preIsSplit = !isUnitStride(s0_mop)\n63:   val s0_nfield       \
      \ = s0_nf +& 1.U\n64: \n65:   val s0_valid         = Wire(Bool())\n66:   val
      s0_kill          = io.in.bits.uop.robIdx.needFlush(io.redirect)\n67:   val s0_can_go\
      \        = s1_ready\n68:   val s0_fire          = s0_valid && s0_can_go\n69:\
      \   val s0_out           = Wire(new VLSBundle(isVStore))\n70: \n71:   val isUsWholeReg
      = isUnitStride(s0_mop) && us_whole_reg(s0_fuOpType)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 233-243
    context: "233:                           )\n234: \n235:   val activeNum      \
      \   = Mux(s1_in.preIsSplit, PopCount(s1_in.flowMask), usActiveNum)\n236: \n\
      237: \n238:   s1_kill               := s1_in.uop.robIdx.needFlush(io.redirect)\n\
      239: \n240:   // query mergeBuffer\n241:   io.toMergeBuffer.req.valid      \
      \       := io.out.ready && s1_valid// only can_go will get MergeBuffer entry\n\
      242:   io.toMergeBuffer.req.bits.flowNum      := activeNum\n243:   io.toMergeBuffer.req.bits.data\
      \         := s1_in.data"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 290-300
    context: "290:   val strideOffsetReg = RegInit(0.U(VLEN.W))\n291: \n292:   /**\n\
      293:     * Redirect\n294:     */\n295:   val cancelEnq    = io.in.bits.uop.robIdx.needFlush(io.redirect)\n\
      296:   val canEnqueue   = io.in.valid\n297:   val needEnqueue  = canEnqueue
      && !cancelEnq\n298: \n299:   // enqueue\n300:   val offset    = PopCount(needEnqueue)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 398-408
    context: "398:     x.isFirstIssue          := DontCare\n399:     x.mBIndex   \
      \            := issueMbIndex\n400:   }\n401: \n402:   // redirect\n403:   needCancel
      := uopq.uop.robIdx.needFlush(io.redirect) && allocated\n404: \n405:  /* Execute
      logic */\n406:   /** Issue to scala pipeline**/\n407: \n408:   lazy val misalignedCanGo
      = true.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 411-421
    context: "411:   splitFinish := splitIdx >= (issueFlowNum - issueCount)\n412:\
      \ \n413:   // handshake\n414:   activeIssue := issueValid && allowIssue && vecActive
      // active issue, current use in no unit-stride\n415:   inActiveIssue := issueValid
      && !vecActive\n416:   when (!issueEntry.uop.robIdx.needFlush(io.redirect)) {\n\
      417:     when (!splitFinish) {\n418:       when (activeIssue || inActiveIssue)
      {\n419:         // The uop has not been entirly splited yet\n420:         splitIdx
      := splitIdx + issueCount\n421:         strideOffsetReg := Mux(!issuePreIsSplit,
      0.U, strideOffsetReg + issueEntry.stride) // when normal unit-stride, don't
      use strideOffsetReg"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 430-442
    context: "430:   }.otherwise {\n431:     splitIdx := 0.U(flowIdxBits.W) // initialize
      flowIdx\n432:     strideOffsetReg := 0.U\n433:   }\n434:   // allocated\n435:\
      \   when(doEnqueue){ // if enqueue need to been cancelled, it will be false,
      so this have high priority\n436:     allocated := true.B\n437:   }.elsewhen(needCancel)
      { // redirect\n438:     allocated := false.B\n439:   }.elsewhen(splitFinish
      && (activeIssue || inActiveIssue)){ //dequeue\n440:     allocated := false.B\n\
      441:   }\n442: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 519-529
    context: "519:   val splitBuffer = Module(new VLSplitBufferImp())\n520:   val
      mergeBufferNack = io.threshold.get.valid && io.threshold.get.bits =/= io.in.bits.uop.lqIdx\n\
      521:   // Split Pipeline\n522:   splitPipeline.io.in <> io.in\n523:   io.in.ready
      := splitPipeline.io.in.ready && !mergeBufferNack\n524:   splitPipeline.io.redirect
      <> io.redirect\n525:   io.toMergeBuffer <> splitPipeline.io.toMergeBuffer\n\
      526: \n527:   // skid buffer\n528:   skidBuffer(splitPipeline.io.out, splitBuffer.io.in,\n\
      529:     Mux(splitPipeline.io.out.fire,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 525-540
    context: "525:   io.toMergeBuffer <> splitPipeline.io.toMergeBuffer\n526: \n527:\
      \   // skid buffer\n528:   skidBuffer(splitPipeline.io.out, splitBuffer.io.in,\n\
      529:     Mux(splitPipeline.io.out.fire,\n530:       splitPipeline.io.out.bits.uop.robIdx.needFlush(io.redirect),\n\
      531:       splitBuffer.io.in.bits.uop.robIdx.needFlush(io.redirect)),\n532:\
      \     \"VSSplitSkidBuffer\")\n533: \n534:   // Split Buffer\n535:   splitBuffer.io.redirect
      <> io.redirect\n536:   io.out <> splitBuffer.io.out\n537: }\n538: \n539: class
      VSSplitImp(implicit p: Parameters) extends VLSUModule{\n540:   val io = IO(new
      VSplitIO(isVStore=true))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 540-550
    context: "540:   val io = IO(new VSplitIO(isVStore=true))\n541:   val splitPipeline
      = Module(new VSSplitPipelineImp())\n542:   val splitBuffer = Module(new VSSplitBufferImp())\n\
      543:   // Split Pipeline\n544:   splitPipeline.io.in <> io.in\n545:   splitPipeline.io.redirect
      <> io.redirect\n546:   io.toMergeBuffer <> splitPipeline.io.toMergeBuffer\n\
      547: \n548:   // skid buffer\n549:   skidBuffer(splitPipeline.io.out, splitBuffer.io.in,\n\
      550:     Mux(splitPipeline.io.out.fire,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/vector/VSplit.scala
    lines: 546-561
    context: "546:   io.toMergeBuffer <> splitPipeline.io.toMergeBuffer\n547: \n548:\
      \   // skid buffer\n549:   skidBuffer(splitPipeline.io.out, splitBuffer.io.in,\n\
      550:     Mux(splitPipeline.io.out.fire,\n551:       splitPipeline.io.out.bits.uop.robIdx.needFlush(io.redirect),\n\
      552:       splitBuffer.io.in.bits.uop.robIdx.needFlush(io.redirect)),\n553:\
      \     \"VSSplitSkidBuffer\")\n554: \n555:   // Split Buffer\n556:   splitBuffer.io.redirect
      <> io.redirect\n557:   io.out <> splitBuffer.io.out\n558:   io.vstd.get <> splitBuffer.io.vstd.get\n\
      559: \n560:   io.vstdMisalign.get <> splitBuffer.io.vstdMisalign.get\n561: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VfofBuffer.scala
    lines: 49-59
    context: "49:     x.valid && x.bits.uop.vpu.isVleff\n50:   }\n51: \n52:   val
      enqValid = enqIsfof.reduce(_ || _)\n53:   val enqBits  = ParallelPriorityMux(enqIsfof,
      io.in.map(_.bits))\n54:   val enqNeedCancel = enqBits.uop.robIdx.needFlush(io.redirect)\n\
      55:   val enqIsFixVl = enqBits.uop.vpu.isVleff && enqBits.uop.vpu.lastUop\n\
      56: \n57:   XSError(entries.uop.robIdx.value =/= enqBits.uop.robIdx.value &&
      valid && enqValid, \"There should be no new fof instrction coming in!\\n\")\n\
      58:   XSError(entriesIsFixVl && valid && enqValid, \"There should not new uop
      enqueue!\\n\")\n59: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VfofBuffer.scala
    lines: 66-76
    context: "66:       entries.uop     := enqBits.uop\n67:     }\n68:   }\n69: \n\
      70:   //Control Signal\n71:   val needRedirect = entries.uop.robIdx.needFlush(io.redirect)\n\
      72: \n73: \n74:   when(io.uopWriteback.fire) {\n75:     valid := false.B  //Deq\n\
      76:   }.elsewhen(needRedirect) {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VfofBuffer.scala
    lines: 72-82
    context: "72: \n73: \n74:   when(io.uopWriteback.fire) {\n75:     valid := false.B\
      \  //Deq\n76:   }.elsewhen(needRedirect) {\n77:     valid := false.B //Redirect\n\
      78:   }.elsewhen(enqValid && !enqNeedCancel) {\n79:     valid := true.B //Enq\n\
      80:   }\n81: \n82: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 161-171
    context: "161: \n162: object VecFeedbacks {\n163:   // need to invalid lsq entry\n\
      164:   val FLUSH  = 0\n165:   // merge buffer commits one uop\n166:   val COMMIT\
      \  = 1\n167:   // last uop of an inst, sq can commit\n168:   val LAST = 2\n\
      169:   // total feedbacks\n170:   val allFeedbacks = 3\n171: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 214-224
    context: "214:   val vstart           = UInt(elemIdxBits.W)\n215:   val vl   \
      \            = UInt(elemIdxBits.W)\n216:   val exceptionVec     = ExceptionVec()\n\
      217: \n218:   def isFlush  = feedback(VecFeedbacks.FLUSH)\n219:   def isCommit
      = feedback(VecFeedbacks.COMMIT)\n220:   def isLast = feedback(VecFeedbacks.LAST)\n\
      221: }\n222: \n223: class storeMisaignIO(implicit p: Parameters) extends Bundle{\n\
      224:   val storePipeEmpty           = Input(Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 224-234
    context: "224:   val storePipeEmpty           = Input(Bool())\n225:   val storeMisalignBufferEmpty
      = Input(Bool())\n226: }\n227: \n228: class VSplitIO(isVStore: Boolean=false)(implicit
      p: Parameters) extends VLSUBundle{\n229:   val redirect            = Flipped(ValidIO(new
      Redirect))\n230:   val in                  = Flipped(Decoupled(new MemExuInput(isVector
      = true))) // from iq\n231:   val toMergeBuffer       = new ToMergeBufferIO(isVStore)
      //to merge buffer req mergebuffer entry\n232:   val out                 = Decoupled(new
      VecPipeBundle(isVStore))// to scala pipeline\n233:   val vstd              \
      \  = OptionWrapper(isVStore, Valid(new MemExuOutput(isVector = true)))\n234:\
      \   val vstdMisalign        = OptionWrapper(isVStore, new storeMisaignIO)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 234-244
    context: "234:   val vstdMisalign        = OptionWrapper(isVStore, new storeMisaignIO)\n\
      235:   val threshold            = OptionWrapper(!isVStore, Flipped(ValidIO(new
      LqPtr)))\n236: }\n237: \n238: class VSplitPipelineIO(isVStore: Boolean=false)(implicit
      p: Parameters) extends VLSUBundle{\n239:   val redirect            = Flipped(ValidIO(new
      Redirect))\n240:   val in                  = Flipped(Decoupled(new MemExuInput(isVector
      = true)))\n241:   val toMergeBuffer       = new ToMergeBufferIO(isVStore) //
      req mergebuffer entry, inactive elem issue\n242:   val out                 =
      Decoupled(new VLSBundle())// to split buffer\n243: }\n244: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 241-251
    context: "241:   val toMergeBuffer       = new ToMergeBufferIO(isVStore) // req
      mergebuffer entry, inactive elem issue\n242:   val out                 = Decoupled(new
      VLSBundle())// to split buffer\n243: }\n244: \n245: class VSplitBufferIO(isVStore:
      Boolean=false)(implicit p: Parameters) extends VLSUBundle{\n246:   val redirect\
      \            = Flipped(ValidIO(new Redirect))\n247:   val in               \
      \   = Flipped(Decoupled(new VLSBundle()))\n248:   val out                 =
      Decoupled(new VecPipeBundle(isVStore))//to scala pipeline\n249:   val vstd \
      \               = OptionWrapper(isVStore, ValidIO(new MemExuOutput(isVector
      = true)))\n250:   val vstdMisalign        = OptionWrapper(isVStore, new storeMisaignIO)\n\
      251: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 249-259
    context: "249:   val vstd                = OptionWrapper(isVStore, ValidIO(new
      MemExuOutput(isVector = true)))\n250:   val vstdMisalign        = OptionWrapper(isVStore,
      new storeMisaignIO)\n251: }\n252: \n253: class VMergeBufferIO(isVStore : Boolean=false)(implicit
      p: Parameters) extends VLSUBundle{\n254:   val redirect            = Flipped(ValidIO(new
      Redirect))\n255:   val fromPipeline        = if(isVStore) Vec(StorePipelineWidth,
      Flipped(DecoupledIO(new VecPipelineFeedbackIO(isVStore)))) else Vec(LoadPipelineWidth,
      Flipped(DecoupledIO(new VecPipelineFeedbackIO(isVStore))))\n256:   val fromSplit\
      \           = if(isVStore) Vec(VecStorePipelineWidth, new FromSplitIO) else
      Vec(VecLoadPipelineWidth, new FromSplitIO) // req mergebuffer entry, inactive
      elem issue\n257:   val uopWriteback        = if(isVStore) Vec(VSUopWritebackWidth,
      DecoupledIO(new MemExuOutput(isVector = true))) else Vec(VLUopWritebackWidth,
      DecoupledIO(new MemExuOutput(isVector = true)))\n258:   val toSplit        \
      \     = OptionWrapper(!isVStore, new FeedbackToSplitIO())\n259:   val toLsq\
      \               = if(isVStore) Vec(VSUopWritebackWidth, ValidIO(new FeedbackToLsqIO))
      else Vec(VLUopWritebackWidth, ValidIO(new FeedbackToLsqIO)) // for lsq deq"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 271-281
    context: "271:   val vecDifftestInfo     = Decoupled(new ToSbufferDifftestInfoBundle)
      // to sbuffer\n272:   val dtlb                = new TlbRequestIO(2)\n273:  \
      \ val pmpResp             = Flipped(new PMPRespBundle())\n274:   val flush_sbuffer\
      \       = new SbufferFlushBundle\n275:   val feedback            = ValidIO(new
      RSFeedback(isVector = true))\n276:   val redirect            = Flipped(ValidIO(new
      Redirect))\n277:   val exceptionInfo       = ValidIO(new FeedbackToLsqIO)\n\
      278:   //trigger\n279:   val fromCsrTrigger      = Input(new CsrTriggerBundle)\n\
      280: }\n281: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VecBundle.scala
    lines: 278-288
    context: "278:   //trigger\n279:   val fromCsrTrigger      = Input(new CsrTriggerBundle)\n\
      280: }\n281: \n282: class VfofDataBuffIO(implicit p: Parameters) extends VLSUBundle{\n\
      283:   val redirect            = Flipped(ValidIO(new Redirect))\n284:   val
      in                  = Vec(VecLoadPipelineWidth, Flipped(Decoupled(new MemExuInput(isVector=true))))\n\
      285:   val mergeUopWriteback   = Vec(VLUopWritebackWidth, Flipped(DecoupledIO(new
      FeedbackToLsqIO)))\n286: \n287:   val uopWriteback        = DecoupledIO(new
      MemExuOutput(isVector = true))\n288: }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 106-116
    context: "106:   def ToLsqConnect(source: MBufferBundle): FeedbackToLsqIO = {\n\
      107:     val sink                                 = WireInit(0.U.asTypeOf(new
      FeedbackToLsqIO))\n108:     val hasExp                               = ExceptionNO.selectByFu(source.exceptionVec,
      fuCfg).asUInt.orR\n109:     sink.robidx                             := source.uop.robIdx\n\
      110:     sink.uopidx                             := source.uop.uopIdx\n111:\
      \     sink.feedback(VecFeedbacks.COMMIT)      := !hasExp\n112:     sink.feedback(VecFeedbacks.FLUSH)\
      \       := hasExp\n113:     sink.feedback(VecFeedbacks.LAST)        := true.B\n\
      114:     sink.vstart                             := source.vstart // TODO: if
      lsq need vl for fof?\n115:     sink.vaddr                              := source.vaddr\n\
      116:     sink.vaNeedExt                          := source.vaNeedExt"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 128-138
    context: "128:   val freeMaskVec  = WireInit(VecInit(Seq.fill(uopSize)(false.B)))\n\
      129:   val uopFinish    = RegInit(VecInit(Seq.fill(uopSize)(false.B)))\n130:\
      \   val needRSReplay = RegInit(VecInit(Seq.fill(uopSize)(false.B)))\n131:  \
      \ // enq, from splitPipeline\n132:   // val allowEnqueue =\n133:   val cancelEnq\
      \    = io.fromSplit.map(_.req.bits.uop.robIdx.needFlush(io.redirect))\n134:\
      \   val canEnqueue   = io.fromSplit.map(_.req.valid)\n135:   val needEnqueue\
      \  = (0 until enqWidth).map{i =>\n136:     canEnqueue(i) && !cancelEnq(i)\n\
      137:   }\n138: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 163-173
    context: "163:     enq.resp.valid        := freeCount >= (i + 1).U // for better
      timing\n164:   }\n165: \n166:   //redirect\n167:   for (i <- 0 until uopSize){\n\
      168:     needCancel(i) := entries(i).uop.robIdx.needFlush(io.redirect) && allocated(i)\n\
      169:     when (needCancel(i)) {\n170:       allocated(i)   := false.B\n171:\
      \       freeMaskVec(i) := true.B\n172:       uopFinish(i)   := false.B\n173:\
      \       needRSReplay(i):= false.B"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 342-352
    context: "342:       allocated(entryIdx)   := false.B\n343:       uopFinish(entryIdx)\
      \   := false.B\n344:       needRSReplay(entryIdx):= false.B\n345:     }\n346:\
      \     //writeback connect\n347:     port.valid   := selFire && selAllocated
      && !needRSReplay(entryIdx) && !selEntry.uop.robIdx.needFlush(io.redirect)\n\
      348:     port.bits    := DeqConnect(selEntry)\n349:     //to lsq\n350:     lsqport.bits
      := ToLsqConnect(selEntry) // when uopwriteback, free MBuffer entry, write to
      lsq\n351:     lsqport.valid:= selFire && selAllocated && !needRSReplay(entryIdx)\n\
      352:     //to RS"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/mem/vector/VMergeBuffer.scala
    lines: 364-375
    context: "364:     io.feedback(i).bits                  := RegEnable(feedbackOut,
      feedbackValid)\n365: \n366:     NewPipelineConnect(\n367:       port, writeBackOut(i),
      writeBackOut(i).fire,\n368:       Mux(port.fire,\n369:         selEntry.uop.robIdx.needFlush(io.redirect),\n\
      370:         writeBackOut(i).bits.uop.robIdx.needFlush(io.redirect)),\n371:\
      \       Option(s\"VMergebufferPipelineConnect${i}\")\n372:     )\n373:     \
      \ io.uopWriteback(i)                  <> writeBackOut(i)\n374:      io.uopWriteback(i).bits.uop.exceptionVec
      := ExceptionNO.selectByFu(writeBackOutExceptionVec(i), fuCfg)\n375:    }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 40-50
    context: "40: import xiangshan.backend.fu.NewCSR.{CsrTriggerBundle, TriggerUtil,
      PFEvent}\n41: import xiangshan.backend.fu.util.{CSRConst, SdtrigExt}\n42: import
      xiangshan.backend.{BackendToTopBundle, TopToBackendBundle}\n43: import xiangshan.backend.rob.{RobDebugRollingIO,
      RobPtr, RobLsqIO}\n44: import xiangshan.backend.datapath.NewPipelineConnect\n\
      45: import xiangshan.backend.trace.{Itype, TraceCoreInterface}\n46: import xiangshan.backend.Bundles._\n\
      47: import xiangshan.mem._\n48: import xiangshan.mem.mdp._\n49: import xiangshan.mem.Bundles._\n\
      50: import xiangshan.mem.prefetch.{BasePrefecher, L1Prefetcher, SMSParams, SMSPrefetcher}"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 93-109
    context: "93:   val loadFastFuOpType = Vec(LdExuCnt, Input(FuOpType()))\n94: \
      \  val loadFastImm = Vec(LdExuCnt, Input(UInt(12.W)))\n95:   val sfence = Input(new
      SfenceBundle)\n96:   val tlbCsr = Input(new TlbCsrBundle)\n97:   val lsqio =
      new Bundle {\n98:     val lcommit = Input(UInt(log2Up(CommitWidth + 1).W))\n\
      99:     val scommit = Input(UInt(log2Up(CommitWidth + 1).W))\n100:     val pendingMMIOld
      = Input(Bool())\n101:     val pendingld = Input(Bool())\n102:     val pendingst
      = Input(Bool())\n103:     val pendingVst = Input(Bool())\n104:     val commit
      = Input(Bool())\n105:     val pendingPtr = Input(new RobPtr)\n106:     val pendingPtrNext
      = Input(new RobPtr)\n107:   }\n108: \n109:   val isStoreException = Input(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 129-139
    context: "129: \n130:   val otherFastWakeup = Vec(LdExuCnt, ValidIO(new DynInst))\n\
      131:   val lqCancelCnt = Output(UInt(log2Up(VirtualLoadQueueSize + 1).W))\n\
      132:   val sqCancelCnt = Output(UInt(log2Up(StoreQueueSize + 1).W))\n133:  \
      \ val sqDeq = Output(UInt(log2Ceil(EnsbufferWidth + 1).W))\n134:   val lqDeq
      = Output(UInt(log2Up(CommitWidth + 1).W))\n135:   // used by VLSU issue queue,
      the vector store would wait all store before it, and the vector load would wait
      all load\n136:   val sqDeqPtr = Output(new SqPtr)\n137:   val lqDeqPtr = Output(new
      LqPtr)\n138:   val stIn = Vec(StAddrCnt, ValidIO(new MemExuInput))\n139:   val
      stIssuePtr = Output(new SqPtr())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 136-146
    context: "136:   val sqDeqPtr = Output(new SqPtr)\n137:   val lqDeqPtr = Output(new
      LqPtr)\n138:   val stIn = Vec(StAddrCnt, ValidIO(new MemExuInput))\n139:   val
      stIssuePtr = Output(new SqPtr())\n140: \n141:   val memoryViolation = ValidIO(new
      Redirect)\n142:   val sbIsEmpty = Output(Bool())\n143: \n144:   val lsTopdownInfo
      = Vec(LdExuCnt, Output(new LsTopdownInfo))\n145: \n146:   val lsqio = new Bundle
      {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 301-311
    context: "301:   with HasTlbConst\n302:   with SdtrigExt\n303: {\n304:   val io
      = IO(new Bundle {\n305:     val hartId = Input(UInt(hartIdLen.W))\n306:    \
      \ val redirect = Flipped(ValidIO(new Redirect))\n307: \n308:     val ooo_to_mem
      = new ooo_to_mem\n309:     val mem_to_ooo = new mem_to_ooo\n310:     val fetch_to_mem
      = new fetch_to_mem\n311: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 390-400
    context: "390:   dontTouch(io.inner_beu_errors_icache)\n391:   dontTouch(io.outer_beu_errors_icache)\n\
      392:   dontTouch(io.inner_hc_perfEvents)\n393:   dontTouch(io.outer_hc_perfEvents)\n\
      394: \n395:   val redirect = RegNextWithEnable(io.redirect)\n396: \n397:   private
      val dcache = outer.dcache.module\n398:   val uncache = outer.uncache.module\n\
      399: \n400:   //val delayedDcacheRefill = RegNext(dcache.io.lsu.lsq)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 695-705
    context: "695:   val dtlb_pmps = dtlb.map(_.pmp).flatten\n696:   dtlb.map(_.hartId
      := io.hartId)\n697:   dtlb.map(_.sfence := sfence)\n698:   dtlb.map(_.csr :=
      tlbcsr)\n699:   dtlb.map(_.flushPipe.map(a => a := false.B)) // non-block doesn't
      need\n700:   dtlb.map(_.redirect := redirect)\n701:   if (refillBothTlb) {\n\
      702:     require(ldtlbParams.outReplace == sttlbParams.outReplace)\n703:   \
      \  require(ldtlbParams.outReplace == hytlbParams.outReplace)\n704:     require(ldtlbParams.outReplace
      == pftlbParams.outReplace)\n705:     require(ldtlbParams.outReplace)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 842-852
    context: "842: \n843:   // LoadUnit\n844:   val correctMissTrain = Constantin.createRecord(s\"\
      CorrectMissTrain$hartId\", initValue = false)\n845: \n846:   for (i <- 0 until
      LduCnt) {\n847:     loadUnits(i).io.redirect <> redirect\n848:     loadUnits(i).io.misalign_allow_spec
      := misalign_allow_spec\n849: \n850:     // get input form dispatch\n851:   \
      \  loadUnits(i).io.ldin <> io.ooo_to_mem.issueLda(i)\n852:     loadUnits(i).io.feedback_slow
      <> io.mem_to_ooo.ldaIqFeedback(i).feedbackSlow"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1033-1043
    context: "1033:     loadUnits(i).io.fromCsrTrigger.triggerCanRaiseBpExp := triggerCanRaiseBpExp\n\
      1034:     loadUnits(i).io.fromCsrTrigger.debugMode := debugMode\n1035:   }\n\
      1036: \n1037:   for (i <- 0 until HyuCnt) {\n1038:     hybridUnits(i).io.redirect
      <> redirect\n1039: \n1040:     // get input from dispatch\n1041:     hybridUnits(i).io.lsin
      <> io.ooo_to_mem.issueHya(i)\n1042:     hybridUnits(i).io.feedback_slow <> io.mem_to_ooo.hyuIqFeedback(i).feedbackSlow\n\
      1043:     hybridUnits(i).io.feedback_fast <> io.mem_to_ooo.hyuIqFeedback(i).feedbackFast"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1170-1187
    context: "1170:     hybridUnits(i).io.fromCsrTrigger.triggerCanRaiseBpExp := triggerCanRaiseBpExp\n\
      1171:     hybridUnits(i).io.fromCsrTrigger.debugMode := debugMode\n1172:   }\n\
      1173: \n1174:   // misalignBuffer\n1175:   loadMisalignBuffer.io.redirect  \
      \              <> redirect\n1176:   loadMisalignBuffer.io.rob.lcommit      \
      \       := io.ooo_to_mem.lsqio.lcommit\n1177:   loadMisalignBuffer.io.rob.scommit\
      \             := io.ooo_to_mem.lsqio.scommit\n1178:   loadMisalignBuffer.io.rob.pendingMMIOld\
      \       := io.ooo_to_mem.lsqio.pendingMMIOld\n1179:   loadMisalignBuffer.io.rob.pendingld\
      \           := io.ooo_to_mem.lsqio.pendingld\n1180:   loadMisalignBuffer.io.rob.pendingst\
      \           := io.ooo_to_mem.lsqio.pendingst\n1181:   loadMisalignBuffer.io.rob.pendingVst\
      \          := io.ooo_to_mem.lsqio.pendingVst\n1182:   loadMisalignBuffer.io.rob.commit\
      \              := io.ooo_to_mem.lsqio.commit\n1183:   loadMisalignBuffer.io.rob.pendingPtr\
      \          := io.ooo_to_mem.lsqio.pendingPtr\n1184:   loadMisalignBuffer.io.rob.pendingPtrNext\
      \      := io.ooo_to_mem.lsqio.pendingPtrNext\n1185: \n1186:   lsq.io.loadMisalignFull\
      \                       := loadMisalignBuffer.io.loadMisalignFull\n1187:   lsq.io.misalignAllowSpec\
      \                      := misalign_allow_spec"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1184-1201
    context: "1184:   loadMisalignBuffer.io.rob.pendingPtrNext      := io.ooo_to_mem.lsqio.pendingPtrNext\n\
      1185: \n1186:   lsq.io.loadMisalignFull                       := loadMisalignBuffer.io.loadMisalignFull\n\
      1187:   lsq.io.misalignAllowSpec                      := misalign_allow_spec\n\
      1188: \n1189:   storeMisalignBuffer.io.redirect               <> redirect\n\
      1190:   storeMisalignBuffer.io.rob.lcommit            := io.ooo_to_mem.lsqio.lcommit\n\
      1191:   storeMisalignBuffer.io.rob.scommit            := io.ooo_to_mem.lsqio.scommit\n\
      1192:   storeMisalignBuffer.io.rob.pendingMMIOld      := io.ooo_to_mem.lsqio.pendingMMIOld\n\
      1193:   storeMisalignBuffer.io.rob.pendingld          := io.ooo_to_mem.lsqio.pendingld\n\
      1194:   storeMisalignBuffer.io.rob.pendingst          := io.ooo_to_mem.lsqio.pendingst\n\
      1195:   storeMisalignBuffer.io.rob.pendingVst         := io.ooo_to_mem.lsqio.pendingVst\n\
      1196:   storeMisalignBuffer.io.rob.commit             := io.ooo_to_mem.lsqio.commit\n\
      1197:   storeMisalignBuffer.io.rob.pendingPtr         := io.ooo_to_mem.lsqio.pendingPtr\n\
      1198:   storeMisalignBuffer.io.rob.pendingPtrNext     := io.ooo_to_mem.lsqio.pendingPtrNext\n\
      1199: \n1200:   lsq.io.maControl                              <> storeMisalignBuffer.io.sqControl\n\
      1201: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1228-1238
    context: "1228:   dtlb_reqs(L2toL1DLBPortIndex).resp.ready := true.B\n1229:  \
      \ io.l2_pmp_resp := pmp_check(L2toL1DLBPortIndex).resp\n1230: \n1231:   // StoreUnit\n\
      1232:   for (i <- 0 until StdCnt) {\n1233:     stdExeUnits(i).io.flush <> redirect\n\
      1234:     stdExeUnits(i).io.in.valid := io.ooo_to_mem.issueStd(i).valid\n1235:\
      \     io.ooo_to_mem.issueStd(i).ready := stdExeUnits(i).io.in.ready\n1236: \
      \    stdExeUnits(i).io.in.bits := io.ooo_to_mem.issueStd(i).bits\n1237:   }\n\
      1238: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1237-1247
    context: "1237:   }\n1238: \n1239:   for (i <- 0 until StaCnt) {\n1240:     val
      stu = storeUnits(i)\n1241: \n1242:     stu.io.redirect      <> redirect\n1243:\
      \     stu.io.csrCtrl       <> csrCtrl\n1244:     stu.io.dcache        <> dcache.io.lsu.sta(i)\n\
      1245:     stu.io.feedback_slow <> io.mem_to_ooo.staIqFeedback(i).feedbackSlow\n\
      1246:     stu.io.stin         <> io.ooo_to_mem.issueSta(i)\n1247:     stu.io.lsq\
      \          <> lsq.io.sta.storeAddrIn(i)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1391-1407
    context: "1391:   lsq.io.uncacheOutstanding := io.ooo_to_mem.csrCtrl.uncache_write_outstanding_enable\n\
      1392: \n1393:   // Lsq\n1394:   io.mem_to_ooo.lsqio.mmio       := lsq.io.rob.mmio\n\
      1395:   io.mem_to_ooo.lsqio.uop        := lsq.io.rob.uop\n1396:   lsq.io.rob.lcommit\
      \             := io.ooo_to_mem.lsqio.lcommit\n1397:   lsq.io.rob.scommit   \
      \          := io.ooo_to_mem.lsqio.scommit\n1398:   lsq.io.rob.pendingMMIOld\
      \       := io.ooo_to_mem.lsqio.pendingMMIOld\n1399:   lsq.io.rob.pendingld \
      \          := io.ooo_to_mem.lsqio.pendingld\n1400:   lsq.io.rob.pendingst  \
      \         := io.ooo_to_mem.lsqio.pendingst\n1401:   lsq.io.rob.pendingVst  \
      \        := io.ooo_to_mem.lsqio.pendingVst\n1402:   lsq.io.rob.commit      \
      \        := io.ooo_to_mem.lsqio.commit\n1403:   lsq.io.rob.pendingPtr      \
      \    := io.ooo_to_mem.lsqio.pendingPtr\n1404:   lsq.io.rob.pendingPtrNext  \
      \    := io.ooo_to_mem.lsqio.pendingPtrNext\n1405: \n1406:   //  lsq.io.rob \
      \           <> io.lsqio.rob\n1407:   lsq.io.enq            <> io.ooo_to_mem.enqLsq"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1403-1416
    context: "1403:   lsq.io.rob.pendingPtr          := io.ooo_to_mem.lsqio.pendingPtr\n\
      1404:   lsq.io.rob.pendingPtrNext      := io.ooo_to_mem.lsqio.pendingPtrNext\n\
      1405: \n1406:   //  lsq.io.rob            <> io.lsqio.rob\n1407:   lsq.io.enq\
      \            <> io.ooo_to_mem.enqLsq\n1408:   lsq.io.brqRedirect    <> redirect\n\
      1409: \n1410:   //  violation rollback\n1411:   def selectOldestRedirect(xs:
      Seq[Valid[Redirect]]): Vec[Bool] = {\n1412:     val compareVec = (0 until xs.length).map(i
      => (0 until i).map(j => isAfter(xs(j).bits.robIdx, xs(i).bits.robIdx)))\n1413:\
      \     val resultOnehot = VecInit((0 until xs.length).map(i => Cat((0 until xs.length).map(j
      =>\n1414:       (if (j < i) !xs(j).valid || compareVec(i)(j)\n1415:       else
      if (j == i) xs(i).valid\n1416:       else !xs(j).valid || !compareVec(j)(i))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1579-1589
    context: "1579:     vsMergeBuffer(i).io.fromMisalignBuffer.get.flush := storeMisalignBuffer.io.toVecStoreMergeBuffer(i).flush\n\
      1580:     vsMergeBuffer(i).io.fromMisalignBuffer.get.mbIndex := storeMisalignBuffer.io.toVecStoreMergeBuffer(i).mbIndex\n\
      1581:   }\n1582: \n1583:   (0 until VstuCnt).foreach{i =>\n1584:     vsSplit(i).io.redirect
      <> redirect\n1585:     vsSplit(i).io.in <> io.ooo_to_mem.issueVldu(i)\n1586:\
      \     vsSplit(i).io.in.valid := io.ooo_to_mem.issueVldu(i).valid &&\n1587: \
      \                              vStoreCanAccept(i) && !isSegment\n1588:     vsSplit(i).io.toMergeBuffer
      <> vsMergeBuffer(i).io.fromSplit.head\n1589:     NewPipelineConnect("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1586-1596
    context: "1586:     vsSplit(i).io.in.valid := io.ooo_to_mem.issueVldu(i).valid
      &&\n1587:                               vStoreCanAccept(i) && !isSegment\n1588:\
      \     vsSplit(i).io.toMergeBuffer <> vsMergeBuffer(i).io.fromSplit.head\n1589:\
      \     NewPipelineConnect(\n1590:       vsSplit(i).io.out, storeUnits(i).io.vecstin,
      storeUnits(i).io.vecstin.fire,\n1591:       Mux(vsSplit(i).io.out.fire, vsSplit(i).io.out.bits.uop.robIdx.needFlush(io.redirect),
      storeUnits(i).io.vecstin.bits.uop.robIdx.needFlush(io.redirect)),\n1592:   \
      \    Option(\"VsSplitConnectStu\")\n1593:     )\n1594:     vsSplit(i).io.vstd.get
      := DontCare // Todo: Discuss how to pass vector store data\n1595: \n1596:  \
      \   vsSplit(i).io.vstdMisalign.get.storeMisalignBufferEmpty := !storeMisalignBuffer.io.full"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1596-1606
    context: "1596:     vsSplit(i).io.vstdMisalign.get.storeMisalignBufferEmpty :=
      !storeMisalignBuffer.io.full\n1597:     vsSplit(i).io.vstdMisalign.get.storePipeEmpty
      := !storeUnits(i).io.s0_s1_valid\n1598: \n1599:   }\n1600:   (0 until VlduCnt).foreach{i
      =>\n1601:     vlSplit(i).io.redirect <> redirect\n1602:     vlSplit(i).io.in
      <> io.ooo_to_mem.issueVldu(i)\n1603:     vlSplit(i).io.in.valid := io.ooo_to_mem.issueVldu(i).valid
      &&\n1604:                               vLoadCanAccept(i) && !isSegment && !isFixVlUop(i)\n\
      1605:     vlSplit(i).io.toMergeBuffer <> vlMergeBuffer.io.fromSplit(i)\n1606:\
      \     vlSplit(i).io.threshold.get.valid := vlMergeBuffer.io.toSplit.get.threshold"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1605-1615
    context: "1605:     vlSplit(i).io.toMergeBuffer <> vlMergeBuffer.io.fromSplit(i)\n\
      1606:     vlSplit(i).io.threshold.get.valid := vlMergeBuffer.io.toSplit.get.threshold\n\
      1607:     vlSplit(i).io.threshold.get.bits  := lsq.io.lqDeqPtr\n1608:     NewPipelineConnect(\n\
      1609:       vlSplit(i).io.out, loadUnits(i).io.vecldin, loadUnits(i).io.vecldin.fire,\n\
      1610:       Mux(vlSplit(i).io.out.fire, vlSplit(i).io.out.bits.uop.robIdx.needFlush(io.redirect),
      loadUnits(i).io.vecldin.bits.uop.robIdx.needFlush(io.redirect)),\n1611:    \
      \   Option(\"VlSplitConnectLdu\")\n1612:     )\n1613: \n1614:     //Subsequent
      instrction will be blocked\n1615:     vfofBuffer.io.in(i).valid := io.ooo_to_mem.issueVldu(i).valid"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1650-1661
    context: "1650: \n1651:   (0 until VlduCnt).foreach{i=>\n1652:     io.ooo_to_mem.issueVldu(i).ready
      := vLoadCanAccept(i) || vStoreCanAccept(i)\n1653:   }\n1654: \n1655:   vlMergeBuffer.io.redirect
      <> redirect\n1656:   vsMergeBuffer.map(_.io.redirect <> redirect)\n1657:   (0
      until VlduCnt).foreach{i=>\n1658:     vlMergeBuffer.io.toLsq(i) <> lsq.io.ldvecFeedback(i)\n\
      1659:   }\n1660:   (0 until VstuCnt).foreach{i=>\n1661:     vsMergeBuffer(i).io.toLsq.head
      <> lsq.io.stvecFeedback(i)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1715-1725
    context: "1715:     vfofBuffer.io.mergeUopWriteback(i).valid := vlMergeBuffer.io.toLsq(i).valid\n\
      1716:     vfofBuffer.io.mergeUopWriteback(i).bits  := vlMergeBuffer.io.toLsq(i).bits\n\
      1717:   }\n1718: \n1719: \n1720:   vfofBuffer.io.redirect <> redirect\n1721:\
      \ \n1722:   // Sbuffer\n1723:   sbuffer.io.csrCtrl    <> csrCtrl\n1724:   sbuffer.io.dcache\
      \     <> dcache.io.lsu.store\n1725:   sbuffer.io.memSetPattenDetected := dcache.io.memSetPattenDetected"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1771-1781
    context: "1771:     Seq.tabulate(HyuCnt)(i => st_atomics(StaCnt+i) -> io.ooo_to_mem.issueHya(i).bits))\n\
      1772:   atomicsUnit.io.storeDataIn.zipWithIndex.foreach { case (stdin, i) =>\n\
      1773:     stdin.valid := st_data_atomics(i)\n1774:     stdin.bits := stData(i).bits\n\
      1775:   }\n1776:   atomicsUnit.io.redirect <> redirect\n1777: \n1778:   // TODO:
      complete amo's pmp support\n1779:   val amoTlb = dtlb_ld(0).requestor(0)\n1780:\
      \   atomicsUnit.io.dtlb.resp.valid := false.B\n1781:   atomicsUnit.io.dtlb.resp.bits\
      \  := DontCare"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1819-1829
    context: "1819: \n1820:   lsq.io.exceptionAddr.isStore := io.ooo_to_mem.isStoreException\n\
      1821:   // Exception address is used several cycles after flush.\n1822:   //
      We delay it by 10 cycles to ensure its flush safety.\n1823:   val atomicsException
      = RegInit(false.B)\n1824:   when (DelayN(redirect.valid, 10) && atomicsException)
      {\n1825:     atomicsException := false.B\n1826:   }.elsewhen (atomicsUnit.io.exceptionInfo.valid)
      {\n1827:     atomicsException := true.B\n1828:   }\n1829: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1844-1854
    context: "1844:     loadMisalignBuffer.io.overwriteExpBuf.isForVSnonLeafPTE,\n\
      1845:     storeMisalignBuffer.io.overwriteExpBuf.isForVSnonLeafPTE\n1846:  \
      \ )\n1847: \n1848:   val vSegmentException = RegInit(false.B)\n1849:   when
      (DelayN(redirect.valid, 10) && vSegmentException) {\n1850:     vSegmentException
      := false.B\n1851:   }.elsewhen (vSegmentUnit.io.exceptionInfo.valid) {\n1852:\
      \     vSegmentException := true.B\n1853:   }\n1854:   val atomicsExceptionAddress
      = RegEnable(atomicsUnit.io.exceptionInfo.bits.vaddr, atomicsUnit.io.exceptionInfo.valid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 1938-1948
    context: "1938: \n1939:     ExceptionVa\n1940:   }\n1941: \n1942:   io.mem_to_ooo.lsqio.vaddr
      := RegNext(\n1943:     GenExceptionVa(tlbcsr.priv.dmode, tlbcsr.priv.virt ||
      exceptionIsHyper, exceptionVaNeedExt,\n1944:     tlbcsr.satp, tlbcsr.vsatp,
      tlbcsr.hgatp, exceptionVaddr)\n1945:   )\n1946: \n1947:   // vsegment instruction
      is executed atomic, which mean atomicsException and vSegmentException should
      not raise at the same time.\n1948:   XSError(atomicsException && vSegmentException,
      \"atomicsException and vSegmentException raise at the same time!\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 2012-2022
    context: "2012:   vSegmentUnit.io.in.valid := isSegment && io.ooo_to_mem.issueVldu.head.valid//
      is segment instruction\n2013:   vSegmentUnit.io.dtlb.resp.bits <> dtlb_reqs.take(LduCnt).head.resp.bits\n\
      2014:   vSegmentUnit.io.dtlb.resp.valid <> dtlb_reqs.take(LduCnt).head.resp.valid\n\
      2015:   vSegmentUnit.io.pmpResp <> pmp_check.head.resp\n2016:   vSegmentUnit.io.flush_sbuffer.empty
      := stIsEmpty\n2017:   vSegmentUnit.io.redirect <> redirect\n2018:   vSegmentUnit.io.rdcache.resp.bits
      := dcache.io.lsu.load(0).resp.bits\n2019:   vSegmentUnit.io.rdcache.resp.valid
      := dcache.io.lsu.load(0).resp.valid\n2020:   vSegmentUnit.io.rdcache.s2_bank_conflict
      := dcache.io.lsu.load(0).s2_bank_conflict\n2021:   // -------------------------\n\
      2022:   // Vector Segment Triggers"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 2060-2070
    context: "2060:   val traceToL2Top = io.traceCoreInterfaceBypass.toL2Top\n2061:\
      \   val traceFromBackend = io.traceCoreInterfaceBypass.fromBackend\n2062:  \
      \ traceFromBackend.fromEncoder := RegNext(traceToL2Top.fromEncoder)\n2063: \
      \  traceToL2Top.toEncoder.trap  := RegEnable(\n2064:     traceFromBackend.toEncoder.trap,\n\
      2065:     traceFromBackend.toEncoder.groups(0).valid && Itype.isTrap(traceFromBackend.toEncoder.groups(0).bits.itype)\n\
      2066:   )\n2067:   traceToL2Top.toEncoder.priv := RegEnable(\n2068:     traceFromBackend.toEncoder.priv,\n\
      2069:     traceFromBackend.toEncoder.groups(0).valid\n2070:   )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/mem/MemBlock.scala
    lines: 2069-2079
    context: "2069:     traceFromBackend.toEncoder.groups(0).valid\n2070:   )\n2071:\
      \   (0 until TraceGroupNum).foreach { i =>\n2072:     traceToL2Top.toEncoder.groups(i).valid
      := RegNext(traceFromBackend.toEncoder.groups(i).valid)\n2073:     traceToL2Top.toEncoder.groups(i).bits.iretire
      := RegNext(traceFromBackend.toEncoder.groups(i).bits.iretire)\n2074:     traceToL2Top.toEncoder.groups(i).bits.itype
      := RegNext(traceFromBackend.toEncoder.groups(i).bits.itype)\n2075:     traceToL2Top.toEncoder.groups(i).bits.ilastsize
      := RegEnable(\n2076:       traceFromBackend.toEncoder.groups(i).bits.ilastsize,\n\
      2077:       traceFromBackend.toEncoder.groups(i).valid\n2078:     )\n2079: \
      \    traceToL2Top.toEncoder.groups(i).bits.iaddr := RegEnable("
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 100-110
    context: "100:   val target     = UInt(VAddrBits.W)\n101:   val jalTarget  = UInt(VAddrBits.W)\n\
      102:   val instrRange = Vec(PredictWidth, Bool())\n103: }\n104: \n105: class
      mmioCommitRead(implicit p: Parameters) extends XSBundle {\n106:   val mmioFtqPtr\
      \     = Output(new FtqPtr)\n107:   val mmioLastCommit = Input(Bool())\n108:
      }\n109: \n110: object ExceptionType {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 539-549
    context: "539:   val br_taken_mask = Vec(numBr, Bool())\n540: \n541:   val slot_valids
      = Vec(totalSlot, Bool())\n542: \n543:   val targets         = Vec(totalSlot,
      UInt(VAddrBits.W))\n544:   val jalr_target     = UInt(VAddrBits.W) // special
      path for indirect predictors\n545:   val offsets         = Vec(totalSlot, UInt(log2Ceil(PredictWidth).W))\n\
      546:   val fallThroughAddr = UInt(VAddrBits.W)\n547:   val fallThroughErr  =
      Bool()\n548:   val multiHit        = Bool()\n549: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 548-558
    context: "548:   val multiHit        = Bool()\n549: \n550:   val is_jal      \
      \         = Bool()\n551:   val is_jalr              = Bool()\n552:   val is_call\
      \              = Bool()\n553:   val is_ret               = Bool()\n554:   val
      last_may_be_rvi_call = Bool()\n555:   val is_br_sharing        = Bool()\n556:\
      \ \n557:   // val call_is_rvc = Bool()\n558:   val hit = Bool()"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 623-633
    context: "623: \n624:   def hit_taken_on_jmp =\n625:     !real_slot_taken_mask().init.reduce(_
      || _) &&\n626:       real_slot_taken_mask().last && !is_br_sharing\n627:   def
      hit_taken_on_call = hit_taken_on_jmp && is_call\n628:   def hit_taken_on_ret\
      \  = hit_taken_on_jmp && is_ret\n629:   def hit_taken_on_jalr = hit_taken_on_jmp
      && is_jalr\n630: \n631:   def cfiIndex = {\n632:     val cfiIndex = Wire(ValidUndirectioned(UInt(log2Ceil(PredictWidth).W)))\n\
      633:     cfiIndex.valid := real_slot_taken_mask().asUInt.orR"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 651-661
    context: "651:     jalr_target          := targets.last\n652:     offsets    \
      \          := entry.getOffsetVec\n653:     is_jal               := entry.tailSlot.valid
      && entry.isJal\n654:     is_jalr              := entry.tailSlot.valid && entry.isJalr\n\
      655:     is_call              := entry.tailSlot.valid && entry.isCall\n656:\
      \     is_ret               := entry.tailSlot.valid && entry.isRet\n657:    \
      \ last_may_be_rvi_call := entry.last_may_be_rvi_call\n658:     is_br_sharing\
      \        := entry.tailSlot.valid && entry.tailSlot.sharing\n659:     predCycle.map(_
      := GTimer())\n660: \n661:     val startLower        = Cat(0.U(1.W), pc(instOffsetBits
      + log2Ceil(PredictWidth) - 1, instOffsetBits))"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 749-759
    context: "749:   val spec_info = new SpeculativeInfo\n750:   val ftb_entry = new
      FTBEntry()\n751: \n752:   val cfi_idx           = ValidUndirectioned(UInt(log2Ceil(PredictWidth).W))\n\
      753:   val br_taken_mask     = Vec(numBr, Bool())\n754:   val br_committed \
      \     = Vec(numBr, Bool()) // High only when br valid && br committed\n755:\
      \   val jmp_taken         = Bool()\n756:   val mispred_mask      = Vec(numBr
      + 1, Bool())\n757:   val pred_hit          = Bool()\n758:   val false_hit  \
      \       = Bool()\n759:   val new_br_insert_pos = Vec(numBr, Bool())"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 764-777
    context: "764:   val ghist             = UInt(HistoryLength.W)\n765: \n766:  \
      \ def is_jal  = ftb_entry.tailSlot.valid && ftb_entry.isJal\n767:   def is_jalr
      = ftb_entry.tailSlot.valid && ftb_entry.isJalr\n768:   def is_call = ftb_entry.tailSlot.valid
      && ftb_entry.isCall\n769:   def is_ret  = ftb_entry.tailSlot.valid && ftb_entry.isRet\n\
      770: \n771:   def is_call_taken = is_call && jmp_taken && cfi_idx.valid && cfi_idx.bits
      === ftb_entry.tailSlot.offset\n772:   def is_ret_taken  = is_ret && jmp_taken
      && cfi_idx.valid && cfi_idx.bits === ftb_entry.tailSlot.offset\n773: \n774:\
      \   def display(cond: Bool) = {\n775:     XSDebug(cond, p\"-----------BranchPredictionUpdate-----------\\\
      n\")\n776:     XSDebug(cond, p\"[mispred_mask] ${Binary(mispred_mask.asUInt)}
      [false_hit] $false_hit\\n\")\n777:     XSDebug(cond, p\"[new_br_insert_pos]
      ${Binary(new_br_insert_pos.asUInt)}\\n\")"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 777-787
    context: "777:     XSDebug(cond, p\"[new_br_insert_pos] ${Binary(new_br_insert_pos.asUInt)}\\\
      n\")\n778:     XSDebug(cond, p\"--------------------------------------------\\\
      n\")\n779:   }\n780: }\n781: \n782: class BranchPredictionRedirect(implicit
      p: Parameters) extends Redirect with HasBPUConst {\n783:   // override def toPrintable:
      Printable = {\n784:   //   p\"-----------BranchPredictionRedirect-----------
      \" +\n785:   //     p\"-----------cfiUpdate----------- \" +\n786:   //     p\"\
      [pc] ${Hexadecimal(cfiUpdate.pc)} \" +\n787:   //     p\"[predTaken] ${cfiUpdate.predTaken},
      [taken] ${cfiUpdate.taken}, [isMisPred] ${cfiUpdate.isMisPred} \" +"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 797-807
    context: "797: \n798:   // }\n799: \n800:   // TODO: backend should pass topdown
      signals here\n801:   // must not change its parent since BPU has used asTypeOf(this
      type) from its parent class\n802:   require(isInstanceOf[Redirect])\n803:  \
      \ val BTBMissBubble         = Bool()\n804:   def ControlRedirectBubble = debugIsCtrl\n\
      805:   // if mispred br not in ftb, count as BTB miss\n806:   def ControlBTBMissBubble
      = ControlRedirectBubble && !cfiUpdate.br_hit && !cfiUpdate.jr_hit\n807:   def
      TAGEMissBubble       = ControlRedirectBubble && cfiUpdate.br_hit && !cfiUpdate.sc_hit"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/FrontendBundle.scala
    lines: 804-819
    context: "804:   def ControlRedirectBubble = debugIsCtrl\n805:   // if mispred
      br not in ftb, count as BTB miss\n806:   def ControlBTBMissBubble = ControlRedirectBubble
      && !cfiUpdate.br_hit && !cfiUpdate.jr_hit\n807:   def TAGEMissBubble       =
      ControlRedirectBubble && cfiUpdate.br_hit && !cfiUpdate.sc_hit\n808:   def SCMissBubble\
      \         = ControlRedirectBubble && cfiUpdate.br_hit && cfiUpdate.sc_hit\n\
      809:   def ITTAGEMissBubble     = ControlRedirectBubble && cfiUpdate.jr_hit
      && !cfiUpdate.pd.isRet\n810:   def RASMissBubble        = ControlRedirectBubble
      && cfiUpdate.jr_hit && cfiUpdate.pd.isRet\n811:   def MemVioRedirectBubble =
      debugIsMemVio\n812:   def OtherRedirectBubble  = !debugIsCtrl && !debugIsMemVio\n\
      813: \n814:   def connectRedirect(source: Redirect): Unit =\n815:     for ((name,
      data) <- this.elements) {\n816:       if (source.elements.contains(name)) {\n\
      817:         data := source.elements(name)\n818:       }\n819:     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FauFTB.scala
    lines: 207-217
    context: "207:   /********************** perf counters **********************/\n\
      208:   val s0_fire_next_cycle = RegNext(io.s0_fire(0))\n209:   val u_pred_hit_way_map
      = (0 until numWays).map(w => s0_fire_next_cycle && s1_hit && s1_hit_way ===
      w.U)\n210:   XSPerfAccumulate(\"uftb_read_hits\", s0_fire_next_cycle && s1_hit)\n\
      211:   XSPerfAccumulate(\"uftb_read_misses\", s0_fire_next_cycle && !s1_hit)\n\
      212:   XSPerfAccumulate(\"uftb_commit_hits\", u_valid && u_meta.hit)\n213: \
      \  XSPerfAccumulate(\"uftb_commit_misses\", u_valid && !u_meta.hit)\n214:  \
      \ XSPerfAccumulate(\"uftb_commit_read_hit_pred_miss\", u_valid && !u_meta.hit
      && u_s0_hit_oh.orR)\n215:   for (w <- 0 until numWays) {\n216:     XSPerfAccumulate(f\"\
      uftb_pred_hit_way_${w}\", u_pred_hit_way_map(w))\n217:     XSPerfAccumulate(f\"\
      uftb_replace_way_${w}\", !u_s1_hit && u_s1_alloc_way === w.U)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FauFTB.scala
    lines: 223-233
    context: "223:       XSPerfAccumulate(f\"uftb_commit_hit_way_${w}\", u_commit_hit_way_map(w))\n\
      224:     }\n225:   }\n226: \n227:   override val perfEvents = Seq(\n228:   \
      \  (\"fauftb_commit_hit       \", u_valid && u_meta.hit),\n229:     (\"fauftb_commit_miss\
      \      \", u_valid && !u_meta.hit)\n230:   )\n231:   generatePerfEvent()\n232:\
      \ \n233: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 106-118
    context: "106:   val bpu          = Module(new Predictor)\n107:   val ifu    \
      \      = Module(new NewIFU)\n108:   val ibuffer      = Module(new IBuffer)\n\
      109:   val ftq          = Module(new Ftq)\n110: \n111:   val needFlush     \
      \       = RegNext(io.backend.toFtq.redirect.valid)\n112:   val FlushControlRedirect
      = RegNext(io.backend.toFtq.redirect.bits.debugIsCtrl)\n113:   val FlushMemVioRedirect\
      \  = RegNext(io.backend.toFtq.redirect.bits.debugIsMemVio)\n114:   val FlushControlBTBMiss\
      \  = Wire(Bool())\n115:   val FlushTAGEMiss        = Wire(Bool())\n116:   val
      FlushSCMiss          = Wire(Bool())\n117:   val FlushITTAGEMiss      = Wire(Bool())\n\
      118:   val FlushRASMiss         = Wire(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 155-165
    context: "155:   itlb.io.requestor.take(PortNumber) zip icache.io.itlb foreach
      { case (a, b) => a <> b }\n156:   itlb.io.requestor.last <> ifu.io.iTLBInter
      // mmio may need re-tlb, blocked\n157:   itlb.io.hartId := io.hartId\n158: \
      \  itlb.io.base_connect(sfence, tlbCsr)\n159:   itlb.io.flushPipe.foreach(_
      := icache.io.itlbFlushPipe)\n160:   itlb.io.redirect := DontCare // itlb has
      flushpipe, don't need redirect signal\n161: \n162:   val itlb_ptw = Wire(new
      VectorTlbPtwIO(coreParams.itlbPortNum))\n163:   itlb_ptw.connect(itlb.io.ptw)\n\
      164:   val itlbRepeater1 = PTWFilter(itlbParams.fenceDelay, itlb_ptw, sfence,
      tlbCsr, l2tlbParams.ifilterSize)\n165:   val itlbRepeater2 ="
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 182-192
    context: "182: \n183:   ftq.io.fromIfu <> ifu.io.ftqInter.toFtq\n184:   bpu.io.ftq_to_bpu
      <> ftq.io.toBpu\n185:   ftq.io.fromBpu <> bpu.io.bpu_to_ftq\n186: \n187:   ftq.io.mmioCommitRead
      <> ifu.io.mmioCommitRead\n188: \n189:   // IFU-ICache\n190:   icache.io.fetch.req
      <> ftq.io.toICache.req\n191:   ftq.io.toICache.req.ready := ifu.io.ftqInter.fromFtq.req.ready
      && icache.io.fetch.req.ready\n192: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Frontend.scala
    lines: 396-406
    context: "396:   // checkNotTakenConsecutive\n397:   checkTakenNotConsecutive\n\
      398:   checkTakenPC\n399:   checkNotTakenPC\n400: \n401:   ifu.io.rob_commits
      <> io.backend.toFtq.rob_commits\n402: \n403:   ibuffer.io.flush            \
      \    := needFlush\n404:   ibuffer.io.ControlRedirect      := FlushControlRedirect\n\
      405:   ibuffer.io.MemVioRedirect       := FlushMemVioRedirect\n406:   ibuffer.io.ControlBTBMissBubble
      := FlushControlBTBMiss"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 208-218
    context: "208: \n209:   val s2_jalr_target_dup = io.out.s2.full_pred.map(_.jalr_target)\n\
      210:   val s2_last_target_in_dup = s2_full_pred.map(_.targets.last)\n211:  \
      \ val s2_last_target_out_dup = io.out.s2.full_pred.map(_.targets.last)\n212:\
      \   val s2_is_jalr_dup = s2_full_pred.map(_.is_jalr)\n213:   val s2_is_ret_dup
      = s2_full_pred.map(_.is_ret)\n214:   // assert(is_jalr && is_ret || !is_ret)\n\
      215:   val ras_enable_dup = dup(RegNext(io.ctrl.ras_enable))\n216:   for (ras_enable
      & s2_is_ret & s2_jalr_target <-\n217:     ras_enable_dup zip s2_is_ret_dup zip
      s2_jalr_target_dup) {\n218:       when(s2_is_ret && ras_enable) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 232-242
    context: "232:   val s3_full_pred = io.in.bits.resp_in(0).s3.full_pred\n233: \
      \  val s3_jalr_target_dup = io.out.s3.full_pred.map(_.jalr_target)\n234:   val
      s3_last_target_in_dup = s3_full_pred.map(_.targets.last)\n235:   val s3_last_target_out_dup
      = io.out.s3.full_pred.map(_.targets.last)\n236:   val s3_is_jalr_dup = s3_full_pred.map(_.is_jalr)\n\
      237:   val s3_is_ret_dup = s3_full_pred.map(_.is_ret)\n238:   // assert(is_jalr
      && is_ret || !is_ret)\n239: \n240:   for (ras_enable & s3_is_ret & s3_jalr_target
      & s3_top <-\n241:     ras_enable_dup zip s3_is_ret_dup zip s3_jalr_target_dup
      zip s3_top_dup) {\n242:       when(s3_is_ret && ras_enable) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 257-286
    context: "257:   val s3_recover = io.s3_fire(2) && (s3_pushed_in_s2 =/= s3_push
      || s3_popped_in_s2 =/= s3_pop)\n258:   io.out.last_stage_spec_info.rasSp  :=
      s3_sp\n259:   io.out.last_stage_spec_info.rasTop := s3_top_dup(2)\n260: \n261:\
      \ \n262:   val redirect = RegNext(io.redirect)\n263:   val do_recover = redirect.valid
      || s3_recover\n264:   val recover_cfi = redirect.bits.cfiUpdate\n265: \n266:\
      \   val retMissPred  = do_recover && redirect.bits.level === 0.U && recover_cfi.pd.isRet\n\
      267:   val callMissPred = do_recover && redirect.bits.level === 0.U && recover_cfi.pd.isCall\n\
      268:   // when we mispredict a call, we must redo a push operation\n269:   //
      similarly, when we mispredict a return, we should redo a pop\n270:   spec_ras.recover_valid
      := do_recover\n271:   spec_ras.recover_push := Mux(redirect.valid, callMissPred,
      s3_push)\n272:   spec_ras.recover_pop  := Mux(redirect.valid, retMissPred, s3_pop)\n\
      273: \n274:   spec_ras.recover_sp  := Mux(redirect.valid, recover_cfi.rasSp,
      s3_sp)\n275:   spec_ras.recover_top := Mux(redirect.valid, recover_cfi.rasEntry,
      s3_top_dup(2))\n276:   spec_ras.recover_new_addr := Mux(redirect.valid, recover_cfi.pc
      + Mux(recover_cfi.pd.isRVC, 2.U, 4.U), s3_spec_new_addr)\n277: \n278: \n279:\
      \   XSPerfAccumulate(\"ras_s3_recover\", s3_recover)\n280:   XSPerfAccumulate(\"\
      ras_redirect_recover\", redirect.valid)\n281:   XSPerfAccumulate(\"ras_s3_and_redirect_recover_at_the_same_time\"\
      , s3_recover && redirect.valid)\n282:   // TODO: back-up stack for ras\n283:\
      \   // use checkpoint to recover RAS\n284: \n285:   val spec_debug = spec.debugIO\n\
      286:   XSDebug(\"----------------RAS----------------\\n\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/RAS.scala
    lines: 296-306
    context: "296:   XSDebug(s2_spec_pop, \"s2_spec_pop  outAddr: 0x%x \\n\",io.out.s2.getTarget(2))\n\
      297:   val s3_recover_entry = spec_debug.recover_push_entry\n298:   XSDebug(s3_recover
      && s3_push, \"s3_recover_push  inAddr: 0x%x  inCtr: %d |  allocNewEntry:%d |\
      \   sp:%d \\n\",\n299:     s3_recover_entry.retAddr, s3_recover_entry.ctr, spec_debug.recover_alloc_new,
      s3_sp.asUInt)\n300:   XSDebug(s3_recover && s3_pop, \"s3_recover_pop  outAddr:
      0x%x \\n\",io.out.s3.getTarget(2))\n301:   val redirectUpdate = redirect.bits.cfiUpdate\n\
      302:   XSDebug(do_recover && callMissPred, \"redirect_recover_push\\n\")\n303:\
      \   XSDebug(do_recover && retMissPred, \"redirect_recover_pop\\n\")\n304:  \
      \ XSDebug(do_recover, \"redirect_recover(SP:%d retAddr:%x ctr:%d) \\n\",\n305:\
      \       redirectUpdate.rasSp,redirectUpdate.rasEntry.retAddr,redirectUpdate.rasEntry.ctr)\n\
      306: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/icache/ICacheCtrlUnit.scala
    lines: 158-168
    context: "158:     private val is_idle :: is_readMetaReq :: is_readMetaResp ::
      is_writeMeta :: is_writeData :: Nil =\n159:       Enum(5)\n160:     private
      val istate = RegInit(is_idle)\n161: \n162:     io.metaRead.valid           \
      \  := istate === is_readMetaReq\n163:     io.metaRead.bits.isDoubleLine := false.B
      // we inject into first cacheline and ignore the rest port\n164:     io.metaRead.bits.vSetIdx\
      \      := VecInit(Seq.fill(PortNumber)(ivirIdx))\n165:     io.metaRead.bits.waymask\
      \   := VecInit(Seq.fill(PortNumber)(VecInit(Seq.fill(nWays)(false.B)))) // dontcare\n\
      166:     io.metaRead.bits.blkOffset := 0.U(blockBits.W)                    \
      \                             // dontcare\n167: \n168:     io.metaWrite.valid
      := istate === is_writeMeta"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 88-98
    context: "88: }\n89: \n90: class RASDebug(implicit p: Parameters) extends XSBundle
      {\n91:   val spec_queue   = Output(Vec(RasSpecSize, new RASEntry))\n92:   val
      spec_nos     = Output(Vec(RasSpecSize, new RASPtr))\n93:   val commit_stack
      = Output(Vec(RasSize, new RASEntry))\n94: }\n95: \n96: class RAS(implicit p:
      Parameters) extends BasePredictor with HasCircularQueuePtrHelper {\n97:   override
      val meta_size = WireInit(0.U.asTypeOf(new RASMeta)).getWidth\n98: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 119-132
    context: "119:       val s3_missed_pop  = Input(Bool())\n120:       val s3_missed_push
      = Input(Bool())\n121:       val s3_pushAddr    = Input(UInt(VAddrBits.W))\n\
      122:       val spec_pop_addr  = Output(UInt(VAddrBits.W))\n123: \n124:     \
      \  val commit_valid      = Input(Bool())\n125:       val commit_push_valid =
      Input(Bool())\n126:       val commit_pop_valid  = Input(Bool())\n127:      \
      \ val commit_push_addr  = Input(UInt(VAddrBits.W))\n128:       val commit_meta_TOSW\
      \  = Input(new RASPtr)\n129:       // for debug purpose only\n130:       val
      commit_meta_ssp = Input(UInt(log2Up(RasSize).W))\n131: \n132:       val redirect_valid\
      \     = Input(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 150-160
    context: "150:       val spec_near_overflow = Output(Bool())\n151: \n152:    \
      \   val debug = new RASDebug\n153:     })\n154: \n155:     val commit_stack
      = RegInit(VecInit(Seq.fill(RasSize)(RASEntry(0.U, 0.U))))\n156:     val spec_queue\
      \   = RegInit(VecInit(Seq.fill(rasSpecSize)(RASEntry(0.U, 0.U))))\n157:    \
      \ val spec_nos     = RegInit(VecInit(Seq.fill(rasSpecSize)(RASPtr(false.B, 0.U))))\n\
      158: \n159:     val nsp = RegInit(0.U(log2Up(rasSize).W))\n160:     val ssp
      = RegInit(0.U(log2Up(rasSize).W))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 179-190
    context: "179:         inflightValid := true.B\n180:       }\n181:       inflightValid\n\
      182:     }\n183: \n184:     def getCommitTop(currentSsp: UInt) =\n185:     \
      \  commit_stack(currentSsp)\n186: \n187:     def getTopNos(currentTOSR: RASPtr,
      allowBypass: Boolean): RASPtr = {\n188:       val ret = Wire(new RASPtr)\n189:\
      \       if (allowBypass) {\n190:         when(writeBypassValid) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 210-220
    context: "210:         when(writeBypassValid) {\n211:           ret := writeBypassEntry\n\
      212:         }.elsewhen(TOSRinRange(currentTOSR, currentTOSW)) {\n213:     \
      \      ret := spec_queue(currentTOSR.value)\n214:         }.otherwise {\n215:\
      \           ret := getCommitTop(currentSsp)\n216:         }\n217:       } else
      {\n218:         when(TOSRinRange(currentTOSR, currentTOSW)) {\n219:        \
      \   ret := spec_queue(currentTOSR.value)\n220:         }.otherwise {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 216-226
    context: "216:         }\n217:       } else {\n218:         when(TOSRinRange(currentTOSR,
      currentTOSW)) {\n219:           ret := spec_queue(currentTOSR.value)\n220: \
      \        }.otherwise {\n221:           ret := getCommitTop(currentSsp)\n222:\
      \         }\n223:       }\n224: \n225:       ret\n226:     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 306-316
    context: "306:       }.elsewhen(TOSRinRange(popRedTOSR, TOSW)) {\n307:       \
      \  popRedSsp  := ptrDec(io.redirect_meta_ssp)\n308:         popRedSctr := spec_queue(popRedTOSR.value).ctr\n\
      309:       }.otherwise {\n310:         popRedSsp  := ptrDec(io.redirect_meta_ssp)\n\
      311:         popRedSctr := getCommitTop(ptrDec(io.redirect_meta_ssp)).ctr\n\
      312:       }\n313:       // We are deciding top for the next cycle, no need
      to use bypass here\n314:       timingTop := getTop(popRedSsp, popRedSctr, popRedTOSR,
      popRedTOSW, false)\n315:     }.elsewhen(io.redirect_valid) {\n316:       //
      Neither call nor ret"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 334-344
    context: "334:       }.elsewhen(TOSRinRange(popTOSR, TOSW)) {\n335:         popSsp\
      \  := ptrDec(ssp)\n336:         popSctr := spec_queue(popTOSR.value).ctr\n337:\
      \       }.otherwise {\n338:         popSsp  := ptrDec(ssp)\n339:         popSctr
      := getCommitTop(ptrDec(ssp)).ctr\n340:       }\n341:       // We are deciding
      top for the next cycle, no need to use bypass here\n342:       timingTop :=
      getTop(popSsp, popSctr, popTOSR, popTOSW, false)\n343:     }.elsewhen(realPush)
      {\n344:       // just updating spec queue, cannot read from there"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 367-377
    context: "367:         }.elsewhen(TOSRinRange(popRedTOSR_s3, popRedTOSW_s3)) {\n\
      368:           popRedSsp_s3  := ptrDec(io.s3_meta.ssp)\n369:           popRedSctr_s3
      := spec_queue(popRedTOSR_s3.value).ctr\n370:         }.otherwise {\n371:   \
      \        popRedSsp_s3  := ptrDec(io.s3_meta.ssp)\n372:           popRedSctr_s3
      := getCommitTop(ptrDec(io.s3_meta.ssp)).ctr\n373:         }\n374:         //
      We are deciding top for the next cycle, no need to use bypass here\n375:   \
      \      timingTop := getTop(popRedSsp_s3, popRedSctr_s3, popRedTOSR_s3, popRedTOSW_s3,
      false)\n376:       }\n377:     }.otherwise {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 470-480
    context: "470:         ssp  := ptrDec(currentSsp)\n471:         sctr := spec_queue(currentTopNos.value).ctr\n\
      472:       }.otherwise {\n473:         // NOS not in range, use commit data\n\
      474:         ssp  := ptrDec(currentSsp)\n475:         sctr := getCommitTop(ptrDec(currentSsp)).ctr\n\
      476:         // in overflow state, we cannot determine the next sctr, sctr here
      is not accurate\n477:       }\n478:     }\n479:     when(io.spec_pop_valid)
      {\n480:       specPop(ssp, sctr, TOSR, TOSW, topNos)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 506-518
    context: "506:         // do not use any bypass from f2\n507:         specPush(io.s3_pushAddr,
      io.s3_meta.ssp, io.s3_meta.sctr, io.s3_meta.TOSR, io.s3_meta.TOSW, s3TopEntry)\n\
      508:       }\n509:     }\n510: \n511:     val commitTop = commit_stack(nsp)\n\
      512: \n513:     when(io.commit_pop_valid) {\n514: \n515:       val nsp_update
      = Wire(UInt(log2Up(rasSize).W))\n516:       when(io.commit_meta_ssp =/= nsp)
      {\n517:         // force set nsp to commit ssp to avoid permanent errors\n518:\
      \         nsp_update := io.commit_meta_ssp"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 519-530
    context: "519:       }.otherwise {\n520:         nsp_update := nsp\n521:     \
      \  }\n522: \n523:       // if ctr > 0, --ctr in stack, otherwise --nsp\n524:\
      \       when(commitTop.ctr > 0.U) {\n525:         commit_stack(nsp_update).ctr
      := commitTop.ctr - 1.U\n526:         nsp                          := nsp_update\n\
      527:       }.otherwise {\n528:         nsp := ptrDec(nsp_update);\n529:    \
      \   }\n530:       // XSError(io.commit_meta_ssp =/= nsp, \"nsp mismatch with
      expected ssp\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 528-540
    context: "528:         nsp := ptrDec(nsp_update);\n529:       }\n530:       //
      XSError(io.commit_meta_ssp =/= nsp, \"nsp mismatch with expected ssp\")\n531:\
      \     }\n532: \n533:     val commit_push_addr = spec_queue(io.commit_meta_TOSW.value).retAddr\n\
      534: \n535:     when(io.commit_push_valid) {\n536:       val nsp_update = Wire(UInt(log2Up(rasSize).W))\n\
      537:       when(io.commit_meta_ssp =/= nsp) {\n538:         // force set nsp
      to commit ssp to avoid permanent errors\n539:         nsp_update := io.commit_meta_ssp\n\
      540:       }.otherwise {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 539-555
    context: "539:         nsp_update := io.commit_meta_ssp\n540:       }.otherwise
      {\n541:         nsp_update := nsp\n542:       }\n543:       // if ctr < max
      && topAddr == push addr, ++ctr, otherwise ++nsp\n544:       when(commitTop.ctr
      < ctrMax && commitTop.retAddr === commit_push_addr) {\n545:         commit_stack(nsp_update).ctr
      := commitTop.ctr + 1.U\n546:         nsp                          := nsp_update\n\
      547:       }.otherwise {\n548:         nsp                                 \
      \     := ptrInc(nsp_update)\n549:         commit_stack(ptrInc(nsp_update)).retAddr
      := commit_push_addr\n550:         commit_stack(ptrInc(nsp_update)).ctr     :=
      0.U\n551:       }\n552: \n553:       // XSError(io.commit_meta_ssp =/= nsp,
      \"nsp mismatch with expected ssp\")\n554:       // XSError(io.commit_push_addr
      =/= commit_push_addr, \"addr from commit mismatch with addr from spec\")\n555:\
      \     }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 552-568
    context: "552: \n553:       // XSError(io.commit_meta_ssp =/= nsp, \"nsp mismatch
      with expected ssp\")\n554:       // XSError(io.commit_push_addr =/= commit_push_addr,
      \"addr from commit mismatch with addr from spec\")\n555:     }\n556: \n557:\
      \     when(io.commit_push_valid) {\n558:       BOS := io.commit_meta_TOSW\n\
      559:     }.elsewhen(io.commit_valid && (distanceBetween(io.commit_meta_TOSW,
      BOS) > 2.U)) {\n560:       BOS := specPtrDec(io.commit_meta_TOSW)\n561:    \
      \ }\n562:     XSError(\n563:       io.commit_valid && (distanceBetween(io.commit_meta_TOSW,
      BOS) > 2.U),\n564:       \"The use of inference queue of the RAS module has
      unexpected situations\"\n565:     )\n566: \n567:     when(io.redirect_valid)
      {\n568:       TOSR := io.redirect_meta_TOSR"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 597-607
    context: "597:       spec_near_overflowed := false.B\n598:     }\n599: \n600:\
      \     io.spec_near_overflow := spec_near_overflowed\n601:     XSPerfAccumulate(\"\
      spec_near_overflow\", spec_near_overflowed)\n602:     io.debug.commit_stack.zipWithIndex.foreach
      { case (a, i) => a := commit_stack(i) }\n603:     io.debug.spec_nos.zipWithIndex.foreach
      { case (a, i) => a := spec_nos(i) }\n604:     io.debug.spec_queue.zipWithIndex.foreach
      { case (a, i) => a := spec_queue(i) }\n605:   }\n606: \n607:   val stack = Module(new
      RASStack(RasSize, RasSpecSize)).io"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 622-632
    context: "622: \n623:   // val s2_jalr_target = io.out.s2.full_pred.jalr_target\n\
      624:   // val s2_last_target_in = s2_full_pred.targets.last\n625:   // val s2_last_target_out
      = io.out.s2.full_pred(2).targets.last\n626:   val s2_is_jalr = s2_full_pred.is_jalr\n\
      627:   val s2_is_ret  = s2_full_pred.is_ret\n628:   val s2_top     = stack.spec_pop_addr\n\
      629:   // assert(is_jalr && is_ret || !is_ret)\n630:   when(s2_is_ret && io.ctrl.ras_enable)
      {\n631:     io.out.s2.full_pred.map(_.jalr_target).foreach(_ := s2_top)\n632:\
      \     // FIXME: should use s1 globally"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 653-663
    context: "653:   // val s3_jalr_target = io.out.s3.full_pred.jalr_target\n654:\
      \   // val s3_last_target_in = io.in.bits.resp_in(0).s3.full_pred(2).targets.last\n\
      655:   // val s3_last_target_out = io.out.s3.full_pred(2).targets.last\n656:\
      \   val s3_is_jalr =\n657:     io.in.bits.resp_in(0).s3.full_pred(2).is_jalr
      && !io.in.bits.resp_in(0).s3.full_pred(2).fallThroughErr\n658:   val s3_is_ret
      = io.in.bits.resp_in(0).s3.full_pred(2).is_ret && !io.in.bits.resp_in(0).s3.full_pred(2).fallThroughErr\n\
      659:   // assert(is_jalr && is_ret || !is_ret)\n660:   when(s3_is_ret && io.ctrl.ras_enable)
      {\n661:     io.out.s3.full_pred.map(_.jalr_target).foreach(_ := s3_top)\n662:\
      \     // FIXME: should use s1 globally\n663:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 703-718
    context: "703:   io.out.last_stage_spec_info.TOSR    := s3_meta.TOSR\n704:   io.out.last_stage_spec_info.NOS\
      \     := s3_meta.NOS\n705:   io.out.last_stage_spec_info.topAddr := s3_top\n\
      706:   io.out.last_stage_meta              := last_stage_meta.asUInt\n707: \n\
      708:   val redirect    = RegNextWithEnable(io.redirect)\n709:   val do_recover\
      \  = redirect.valid\n710:   val recover_cfi = redirect.bits.cfiUpdate\n711:\
      \ \n712:   val retMissPred  = do_recover && redirect.bits.level === 0.U && recover_cfi.pd.isRet
      && recover_cfi.pd.valid\n713:   val callMissPred = do_recover && redirect.bits.level
      === 0.U && recover_cfi.pd.isCall && recover_cfi.pd.valid\n714:   // when we
      mispredict a call, we must redo a push operation\n715:   // similarly, when
      we mispredict a return, we should redo a pop\n716:   val stack_TOSW    = stack.TOSW\n\
      717:   val redirect_TOSW = recover_cfi.TOSW\n718:   stack.redirect_valid   \
      \  := do_recover && (isBefore(redirect_TOSW, stack_TOSW) || !stack_near_overflow)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 737-750
    context: "737:   // 'val updateMeta = RegEnable(io.update.bits.meta.asTypeOf(new
      RASMeta), io.update.valid && (io.update.bits.is_call || io.update.bits.is_ret))',\n\
      738:   // but the fault-tolerance mechanism of the return stack needs to be
      updated in time. Using an unexpected old value on reset will cause errors.\n\
      739:   // Only 9 registers have clock gate efficiency affected, so we relaxed
      the control signals.\n740:   val updateMeta = RegEnable(io.update.bits.meta.asTypeOf(new
      RASMeta), io.update.valid)\n741: \n742:   stack.commit_valid      := updateValid\n\
      743:   stack.commit_push_valid := updateValid && update.is_call_taken\n744:\
      \   stack.commit_pop_valid  := updateValid && update.is_ret_taken\n745:   stack.commit_push_addr
      := update.ftb_entry.getFallThrough(update_pc) + Mux(\n746:     update.ftb_entry.last_may_be_rvi_call,\n\
      747:     2.U,\n748:     0.U\n749:   )\n750:   stack.commit_meta_TOSW := updateMeta.TOSW"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 749-760
    context: "749:   )\n750:   stack.commit_meta_TOSW := updateMeta.TOSW\n751:   stack.commit_meta_ssp\
      \  := updateMeta.ssp\n752: \n753:   XSPerfAccumulate(\"ras_s3_cancel\", s3_cancel)\n\
      754:   XSPerfAccumulate(\"ras_redirect_recover\", redirect.valid)\n755:   XSPerfAccumulate(\"\
      ras_s3_and_redirect_recover_at_the_same_time\", s3_cancel && redirect.valid)\n\
      756: \n757:   val spec_debug = stack.debug\n758:   XSDebug(io.s2_fire(2), \"\
      ----------------RAS----------------\\n\")\n759:   XSDebug(io.s2_fire(2), \"\
      \ TopRegister: 0x%x\\n\", stack.spec_pop_addr)\n760:   XSDebug(io.s2_fire(2),
      \"  index       addr           ctr           nos (spec part)\\n\")"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 770-780
    context: "770:     XSDebug(io.s2_fire(2) && i.U === stack.TOSW.value, \"   <----TOSW\"\
      )\n771:     XSDebug(io.s2_fire(2) && i.U === stack.TOSR.value, \"   <----TOSR\"\
      )\n772:     XSDebug(io.s2_fire(2) && i.U === stack.BOS.value, \"   <----BOS\"\
      )\n773:     XSDebug(io.s2_fire(2), \"\\n\")\n774:   }\n775:   XSDebug(io.s2_fire(2),
      \"  index       addr           ctr   (committed part)\\n\")\n776:   for (i <-
      0 until RasSize) {\n777:     XSDebug(\n778:       io.s2_fire(2),\n779:     \
      \  \"  (%d)   0x%x      %d\",\n780:       i.U,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 776-787
    context: "776:   for (i <- 0 until RasSize) {\n777:     XSDebug(\n778:       io.s2_fire(2),\n\
      779:       \"  (%d)   0x%x      %d\",\n780:       i.U,\n781:       spec_debug.commit_stack(i).retAddr,\n\
      782:       spec_debug.commit_stack(i).ctr\n783:     )\n784:     XSDebug(io.s2_fire(2)
      && i.U === stack.ssp, \"   <----ssp\")\n785:     XSDebug(io.s2_fire(2) && i.U
      === stack.nsp, \"   <----nsp\")\n786:     XSDebug(io.s2_fire(2), \"\\n\")\n\
      787:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/newRAS.scala
    lines: 791-801
    context: "791:   XSDebug(s2_spec_pop, \"s2_spec_pop  outAddr: 0x%x \\n\",io.out.s2.getTarget)\n\
      792:   val s3_recover_entry = spec_debug.recover_push_entry\n793:   XSDebug(s3_recover
      && s3_push, \"s3_recover_push  inAddr: 0x%x  inCtr: %d |  allocNewEntry:%d |\
      \   sp:%d \\n\",\n794:     s3_recover_entry.retAddr, s3_recover_entry.ctr, spec_debug.recover_alloc_new,
      s3_sp.asUInt)\n795:   XSDebug(s3_recover && s3_pop, \"s3_recover_pop  outAddr:
      0x%x \\n\",io.out.s3.getTarget)\n796:   val redirectUpdate = redirect.bits.cfiUpdate\n\
      797:   XSDebug(do_recover && callMissPred, \"redirect_recover_push\\n\")\n798:\
      \   XSDebug(do_recover && retMissPred, \"redirect_recover_pop\\n\")\n799:  \
      \ XSDebug(do_recover, \"redirect_recover(SP:%d retAddr:%x ctr:%d) \\n\",\n800:\
      \       redirectUpdate.rasSp,redirectUpdate.rasEntry.retAddr,redirectUpdate.rasEntry.ctr)\n\
      801:    */"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 57-67
    context: "57: trait HasBPUParameter extends HasXSParameter with HasBPUConst {\n\
      58:   val BPUDebug            = true && !env.FPGAPlatform && env.EnablePerfDebug\n\
      59:   val EnableCFICommitLog  = true\n60:   val EnbaleCFIPredLog    = true\n\
      61:   val EnableBPUTimeRecord = (EnableCFICommitLog || EnbaleCFIPredLog) &&
      !env.FPGAPlatform\n62:   val EnableCommit        = false\n63: }\n64: \n65: class
      BPUCtrl(implicit p: Parameters) extends XSBundle {\n66:   val ubtb_enable =
      Bool()\n67:   val btb_enable  = Bool()"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 163-173
    context: "163:   val s1_ready = Output(Bool())\n164:   val s2_ready = Output(Bool())\n\
      165:   val s3_ready = Output(Bool())\n166: \n167:   val update          = Flipped(Valid(new
      BranchPredictionUpdate))\n168:   val redirect        = Flipped(Valid(new BranchPredictionRedirect))\n\
      169:   val redirectFromIFU = Input(Bool())\n170: }\n171: \n172: abstract class
      BasePredictor(implicit p: Parameters) extends XSModule\n173:     with HasBPUConst
      with BPUUtils with HasPerfEvents {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 184-194
    context: "184:   io.fauftb_entry_out     := io.fauftb_entry_in\n185:   io.fauftb_entry_hit_out
      := io.fauftb_entry_hit_in\n186: \n187:   io.out.last_stage_meta := 0.U\n188:\
      \ \n189:   io.in.ready := !io.redirect.valid\n190: \n191:   io.s1_ready := true.B\n\
      192:   io.s2_ready := true.B\n193:   io.s3_ready := true.B\n194: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 373-383
    context: "373:   // predictors.io.in.bits.resp_in(0).s1.pc := s0_pc\n374:   //
      predictors.io.in.bits.toFtq_fire := toFtq_fire\n375: \n376:   // predictors.io.out.ready
      := io.bpu_to_ftq.resp.ready\n377: \n378:   val redirect_req    = io.ftq_to_bpu.redirect\n\
      379:   val do_redirect_dup = dup_seq(RegNextWithEnable(redirect_req))\n380:\
      \ \n381:   // Pipeline logic\n382:   s2_redirect_dup.map(_ := false.B)\n383:\
      \   s3_redirect_dup.map(_ := false.B)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 380-390
    context: "380: \n381:   // Pipeline logic\n382:   s2_redirect_dup.map(_ := false.B)\n\
      383:   s3_redirect_dup.map(_ := false.B)\n384: \n385:   s3_flush_dup.map(_ :=
      redirect_req.valid) // flush when redirect comes\n386:   for (((s2_flush, s3_flush),
      s3_redirect) <- s2_flush_dup zip s3_flush_dup zip s3_redirect_dup)\n387:   \
      \  s2_flush := s3_flush || s3_redirect\n388:   for (((s1_flush, s2_flush), s2_redirect)
      <- s1_flush_dup zip s2_flush_dup zip s2_redirect_dup)\n389:     s1_flush :=
      s2_flush || s2_redirect\n390: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 911-921
    context: "911:     io.ftq_to_bpu.update.valid,\n912:     Some(\"predictors_io_update_pc\"\
      )\n913:   ).getAddr()\n914: \n915:   val redirect_dup = do_redirect_dup.map(_.bits)\n\
      916:   predictors.io.redirect := do_redirect_dup(0)\n917: \n918:   // Redirect
      logic\n919:   val shift_dup       = redirect_dup.map(_.cfiUpdate.shift)\n920:\
      \   val addIntoHist_dup = redirect_dup.map(_.cfiUpdate.addIntoHist)\n921:  \
      \ // TODO: remove these below"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 985-1002
    context: "985:     }\n986:   }\n987: \n988:   // Commit time history checker\n\
      989:   if (EnableCommitGHistDiff) {\n990:     val commitGHist    = RegInit(0.U.asTypeOf(Vec(HistoryLength,
      Bool())))\n991:     val commitGHistPtr = RegInit(0.U.asTypeOf(new CGHPtr))\n\
      992:     def getCommitHist(ptr: CGHPtr): UInt =\n993:       (Cat(commitGHist.asUInt,
      commitGHist.asUInt) >> (ptr.value + 1.U))(HistoryLength - 1, 0)\n994: \n995:\
      \     val updateValid:         Bool      = io.ftq_to_bpu.update.valid\n996:\
      \     val branchValidMask:     UInt      = io.ftq_to_bpu.update.bits.ftb_entry.brValids.asUInt\n\
      997:     val branchCommittedMask: Vec[Bool] = io.ftq_to_bpu.update.bits.br_committed\n\
      998:     val misPredictMask:      UInt      = io.ftq_to_bpu.update.bits.mispred_mask.asUInt\n\
      999:     val takenMask: UInt =\n1000:       io.ftq_to_bpu.update.bits.br_taken_mask.asUInt
      |\n1001:         io.ftq_to_bpu.update.bits.ftb_entry.strong_bias.asUInt // Always
      taken branch is recorded in history\n1002:     val takenIdx:      UInt = (PriorityEncoder(takenMask)
      + 1.U((log2Ceil(numBr) + 1).W)).asUInt"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 1008-1023
    context: "1008:       Mux(updateValid && branchValidMask.orR, PopCount(branchValidMask
      & shouldShiftMask), 0.U)\n1009: \n1010:     // Maintain the commitGHist\n1011:\
      \     for (i <- 0 until numBr) {\n1012:       when(updateShift >= (i + 1).U)
      {\n1013:         val ptr: CGHPtr = commitGHistPtr - i.asUInt\n1014:        \
      \ commitGHist(ptr.value) := takenMask(i)\n1015:       }\n1016:     }\n1017:\
      \     when(updateValid) {\n1018:       commitGHistPtr := commitGHistPtr - updateShift\n\
      1019:     }\n1020: \n1021:     // Calculate true history using Parallel XOR\n\
      1022:     // Do differential\n1023:     TageTableInfos.map {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 1022-1036
    context: "1022:     // Do differential\n1023:     TageTableInfos.map {\n1024:\
      \       case (nRows, histLen, _) => {\n1025:         val nRowsPerBr      = nRows
      / numBr\n1026:         val predictGHistPtr = io.ftq_to_bpu.update.bits.spec_info.histPtr\n\
      1027:         val commitTrueHist: UInt = computeFoldedHist(getCommitHist(commitGHistPtr),
      log2Ceil(nRowsPerBr))(histLen)\n1028:         val predictFHist:   UInt = computeFoldedHist(getHist(predictGHistPtr),
      log2Ceil(nRowsPerBr))(histLen)\n1029:         XSWarn(\n1030:           updateValid
      && predictFHist =/= commitTrueHist,\n1031:           p\"predict time ghist:
      ${predictFHist} is different from commit time: ${commitTrueHist}\\n\"\n1032:\
      \         )\n1033:       }\n1034:     }\n1035:   }\n1036: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 1155-1178
    context: "1155:     topdown_stages(0).reasons(TopDownCounters.FtqFullStall.id)
      := true.B\n1156:   }\n1157: \n1158:   XSError(\n1159:     isBefore(redirect_dup(0).cfiUpdate.histPtr,
      s3_ghist_ptr_dup(0)) && do_redirect_dup(0).valid,\n1160:     p\"s3_ghist_ptr
      ${s3_ghist_ptr_dup(0)} exceeds redirect histPtr ${redirect_dup(0).cfiUpdate.histPtr}\\\
      n\"\n1161:   )\n1162:   XSError(\n1163:     isBefore(redirect_dup(0).cfiUpdate.histPtr,
      s2_ghist_ptr_dup(0)) && do_redirect_dup(0).valid,\n1164:     p\"s2_ghist_ptr
      ${s2_ghist_ptr_dup(0)} exceeds redirect histPtr ${redirect_dup(0).cfiUpdate.histPtr}\\\
      n\"\n1165:   )\n1166:   XSError(\n1167:     isBefore(redirect_dup(0).cfiUpdate.histPtr,
      s1_ghist_ptr_dup(0)) && do_redirect_dup(0).valid,\n1168:     p\"s1_ghist_ptr
      ${s1_ghist_ptr_dup(0)} exceeds redirect histPtr ${redirect_dup(0).cfiUpdate.histPtr}\\\
      n\"\n1169:   )\n1170: \n1171:   XSDebug(RegNext(reset.asBool) && !reset.asBool,
      \"Reseting...\\n\")\n1172:   XSDebug(io.ftq_to_bpu.update.valid, p\"Update from
      ftq\\n\")\n1173:   XSDebug(io.ftq_to_bpu.redirect.valid, p\"Redirect from ftq\\\
      n\")\n1174: \n1175:   XSDebug(\"[BP0]                 fire=%d              \
      \        pc=%x\\n\", s0_fire_dup(0), s0_pc_dup(0))\n1176:   XSDebug(\n1177:\
      \     \"[BP1] v=%d r=%d cr=%d fire=%d             flush=%d pc=%x\\n\",\n1178:\
      \     s1_valid_dup(0),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 1181-1191
    context: "1181:     s1_fire_dup(0),\n1182:     s1_flush_dup(0),\n1183:     s1_pc\n\
      1184:   )\n1185:   XSDebug(\n1186:     \"[BP2] v=%d r=%d cr=%d fire=%d redirect=%d
      flush=%d pc=%x\\n\",\n1187:     s2_valid_dup(0),\n1188:     s2_ready_dup(0),\n\
      1189:     s2_components_ready_dup(0),\n1190:     s2_fire_dup(0),\n1191:    \
      \ s2_redirect_dup(0),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 1191-1201
    context: "1191:     s2_redirect_dup(0),\n1192:     s2_flush_dup(0),\n1193:   \
      \  s2_pc\n1194:   )\n1195:   XSDebug(\n1196:     \"[BP3] v=%d r=%d cr=%d fire=%d
      redirect=%d flush=%d pc=%x\\n\",\n1197:     s3_valid_dup(0),\n1198:     s3_ready_dup(0),\n\
      1199:     s3_components_ready_dup(0),\n1200:     s3_fire_dup(0),\n1201:    \
      \ s3_redirect_dup(0),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/BPU.scala
    lines: 1213-1223
    context: "1213:   XSDebug(p\"s1_ghist_ptr: ${s1_ghist_ptr_dup(0)}\\n\")\n1214:\
      \   XSDebug(p\"s2_ghist_ptr: ${s2_ghist_ptr_dup(0)}\\n\")\n1215:   XSDebug(p\"\
      s3_ghist_ptr: ${s3_ghist_ptr_dup(0)}\\n\")\n1216: \n1217:   io.ftq_to_bpu.update.bits.display(io.ftq_to_bpu.update.valid)\n\
      1218:   io.ftq_to_bpu.redirect.bits.display(io.ftq_to_bpu.redirect.valid)\n\
      1219: \n1220:   XSPerfAccumulate(\"s2_redirect\", s2_redirect_dup(0))\n1221:\
      \   XSPerfAccumulate(\"s3_redirect\", s3_redirect_dup(0))\n1222:   XSPerfAccumulate(\"\
      s1_not_valid\", !s1_valid_dup(0))\n1223: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 512-522
    context: "512:     io.update.valid // not using mispred_mask, because mispred_mask
      timing is bad\n513:   )\n514:   update.cfi_idx.bits := RegEnable(io.update.bits.cfi_idx.bits,
      io.update.valid && io.update.bits.cfi_idx.valid)\n515:   update.ghist      \
      \  := RegEnable(io.update.bits.ghist, io.update.valid) // TODO: CGE\n516: \n\
      517:   val updateValid = update.is_jalr && !update.is_ret && u_valid && update.ftb_entry.jmpValid
      &&\n518:     update.jmp_taken && update.cfi_idx.valid &&\n519:     update.cfi_idx.bits
      === update.ftb_entry.tailSlot.offset && !update.ftb_entry.strong_bias(numBr
      - 1)\n520: \n521:   val updateMask            = WireInit(0.U.asTypeOf(Vec(ITTageNTables,
      Bool())))\n522:   val updateUMask           = WireInit(0.U.asTypeOf(Vec(ITTageNTables,
      Bool())))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 563-573
    context: "563: \n564:   val selectedInfo = ParallelSelectTwo(inputRes.reverse)\n\
      565:   val provided     = selectedInfo.hasOne\n566:   val altProvided  = selectedInfo.hasTwo\n\
      567: \n568:   val providerInfo    = selectedInfo.first\n569:   val altProviderInfo
      = selectedInfo.second\n570:   val providerNull    = providerInfo.ctr === 0.U\n\
      571: \n572:   val baseTarget             = io.in.bits.resp_in(0).s2.full_pred(3).jalr_target
      // use ftb pred as base target\n573:   val region_r_target_offset = VecInit(s2_resps.map(r
      => r.bits.target_offset))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 755-768
    context: "755:   XSPerfAccumulate(\"ittage_used\", io.s1_fire(0) && s1_isIndirect)\n\
      756:   XSPerfAccumulate(\"ittage_closed_due_to_uftb_info\", io.s1_fire(0) &&
      !s1_isIndirect)\n757:   XSPerfAccumulate(\"ittage_allocate\", updateAlloc.reduce(_
      || _))\n758: \n759:   private def pred_perf(name:   String, cond: Bool) = XSPerfAccumulate(s\"\
      ${name}_at_pred\", cond && io.s2_fire(3))\n760:   private def commit_perf(name:
      String, cond: Bool) = XSPerfAccumulate(s\"${name}_at_commit\", cond && updateValid)\n\
      761:   private def ittage_perf(name: String, pred_cond: Bool, commit_cond: Bool)
      = {\n762:     pred_perf(s\"ittage_${name}\", pred_cond)\n763:     commit_perf(s\"\
      ittage_${name}\", commit_cond)\n764:   }\n765:   val pred_use_provider     \
      \  = s2_provided && !ctrNull(s2_providerCtr)\n766:   val pred_use_altpred  \
      \      = s2_provided && ctrNull(s2_providerCtr)\n767:   val pred_use_ht_as_altpred\
      \  = pred_use_altpred && s2_altProvided\n768:   val pred_use_bim_as_altpred
      = pred_use_altpred && !s2_altProvided"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 766-776
    context: "766:   val pred_use_altpred        = s2_provided && ctrNull(s2_providerCtr)\n\
      767:   val pred_use_ht_as_altpred  = pred_use_altpred && s2_altProvided\n768:\
      \   val pred_use_bim_as_altpred = pred_use_altpred && !s2_altProvided\n769:\
      \   val pred_use_bim_as_pred    = !s2_provided\n770: \n771:   val commit_use_provider\
      \       = updateMeta.provider.valid && !ctrNull(updateMeta.providerCtr)\n772:\
      \   val commit_use_altpred        = updateMeta.provider.valid && ctrNull(updateMeta.providerCtr)\n\
      773:   val commit_use_ht_as_altpred  = commit_use_altpred && updateMeta.altProvider.valid\n\
      774:   val commit_use_ftb_as_altpred = commit_use_altpred && !updateMeta.altProvider.valid\n\
      775:   val commit_use_ftb_as_pred    = !updateMeta.provider.valid\n776: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 780-790
    context: "780:     val commit_this_is_provider = updateMeta.provider.bits ===
      i.U\n781:     val commit_this_is_altpred  = updateMeta.altProvider.bits ===
      i.U\n782:     ittage_perf(\n783:       s\"table_${i}_final_provided\",\n784:\
      \       pred_use_provider && pred_this_is_provider,\n785:       commit_use_provider
      && commit_this_is_provider\n786:     )\n787:     ittage_perf(\n788:       s\"\
      table_${i}_provided_not_used\",\n789:       pred_use_altpred && pred_this_is_provider,\n\
      790:       commit_use_altpred && commit_this_is_provider"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/ITTAGE.scala
    lines: 795-810
    context: "795:       commit_use_ht_as_altpred && commit_this_is_altpred\n796:\
      \     )\n797:     ittage_perf(\n798:       s\"table_${i}_alt_provider_not_used\"\
      ,\n799:       pred_use_provider && pred_this_is_altpred,\n800:       commit_use_provider
      && commit_this_is_altpred\n801:     )\n802:   }\n803: \n804:   ittage_perf(\"\
      provided\", s2_provided, updateMeta.provider.valid)\n805:   ittage_perf(\"use_provider\"\
      , pred_use_provider, commit_use_provider)\n806:   ittage_perf(\"use_altpred\"\
      , pred_use_altpred, commit_use_altpred)\n807:   ittage_perf(\"use_ht_as_altpred\"\
      , pred_use_ht_as_altpred, commit_use_ht_as_altpred)\n808:   ittage_perf(\"use_ftb_when_no_provider\"\
      , pred_use_bim_as_pred, commit_use_ftb_as_pred)\n809:   ittage_perf(\"use_ftb_as_alt_provider\"\
      , pred_use_bim_as_altpred, commit_use_ftb_as_altpred)\n810:   XSPerfAccumulate(\"\
      updated\", updateValid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Composer.scala
    lines: 48-58
    context: "48:     c.io.s3_fire := io.s3_fire\n49: \n50:     c.io.s2_redirect :=
      io.s2_redirect\n51:     c.io.s3_redirect := io.s3_redirect\n52: \n53:     c.io.redirect\
      \        := io.redirect\n54:     c.io.ctrl            := DelayN(io.ctrl, 1)\n\
      55:     c.io.redirectFromIFU := io.redirectFromIFU\n56: \n57:     if (c.meta_size
      > 0) {\n58:       metas = (metas << c.meta_size) | c.io.out.last_stage_meta(c.meta_size
      - 1, 0)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 40-50
    context: "40:   val pc        = UInt(39.W)\n41:   val target    = UInt(39.W)\n\
      42:   val isBr      = Bool()\n43:   val isJmp     = Bool()\n44:   val isCall\
      \    = Bool()\n45:   val isRet     = Bool()\n46:   val misPred   = Bool()\n\
      47:   val isTaken   = Bool()\n48:   val predStage = UInt(2.W)\n49: }\n50: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 141-151
    context: "141:     val pds = pdWb.pd\n142:     this.brMask        := VecInit(pds.map(pd
      => pd.isBr && pd.valid))\n143:     this.jmpInfo.valid := VecInit(pds.map(pd
      => (pd.isJal || pd.isJalr) && pd.valid)).asUInt.orR\n144:     this.jmpInfo.bits
      := ParallelPriorityMux(\n145:       pds.map(pd => (pd.isJal || pd.isJalr) &&
      pd.valid),\n146:       pds.map(pd => VecInit(pd.isJalr, pd.isCall, pd.isRet))\n\
      147:     )\n148:     this.jmpOffset := ParallelPriorityEncoder(pds.map(pd =>
      (pd.isJal || pd.isJalr) && pd.valid))\n149:     this.rvcMask   := VecInit(pds.map(pd
      => pd.isRVC))\n150:     this.jalTarget := pdWb.jalTarget\n151:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 157-167
    context: "157:     pd.isRVC := rvcMask(offset)\n158:     val isBr   = brMask(offset)\n\
      159:     val isJalr = offset === jmpOffset && jmpInfo.valid && jmpInfo.bits(0)\n\
      160:     pd.brType := Cat(offset === jmpOffset && jmpInfo.valid, isJalr || isBr)\n\
      161:     pd.isCall := offset === jmpOffset && jmpInfo.valid && jmpInfo.bits(1)\n\
      162:     pd.isRet  := offset === jmpOffset && jmpInfo.valid && jmpInfo.bits(2)\n\
      163:     pd\n164:   }\n165: }\n166: \n167: class PrefetchPtrDB(implicit p: Parameters)
      extends Bundle {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 195-205
    context: "195:     this.data\n196:   }\n197: }\n198: \n199: class FtqToBpuIO(implicit
      p: Parameters) extends XSBundle {\n200:   val redirect       = Valid(new BranchPredictionRedirect)\n\
      201:   val update         = Valid(new BranchPredictionUpdate)\n202:   val enq_ptr\
      \        = Output(new FtqPtr)\n203:   val redirctFromIFU = Output(Bool())\n\
      204: }\n205: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 214-224
    context: "214:   def shouldFlushByStage3(idx: FtqPtr) = shouldFlushBy(s3, idx)\n\
      215: }\n216: \n217: class FtqToIfuIO(implicit p: Parameters) extends XSBundle
      {\n218:   val req              = Decoupled(new FetchRequestBundle)\n219:   val
      redirect         = Valid(new BranchPredictionRedirect)\n220:   val topdown_redirect
      = Valid(new BranchPredictionRedirect)\n221:   val flushFromBpu     = new BpuFlushInfo\n\
      222: }\n223: \n224: class FtqToICacheIO(implicit p: Parameters) extends XSBundle
      {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 232-242
    context: "232:   val flushFromBpu     = new BpuFlushInfo\n233:   val backendException
      = UInt(ExceptionType.width.W)\n234: }\n235: \n236: trait HasBackendRedirectInfo
      extends HasXSParameter {\n237:   def isLoadReplay(r: Valid[Redirect]) = r.bits.flushItself()\n\
      238: }\n239: \n240: class FtqToCtrlIO(implicit p: Parameters) extends XSBundle
      with HasBackendRedirectInfo {\n241:   // write to backend pc mem\n242:   val
      pc_mem_wen   = Output(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 324-334
    context: "324:       \"pftAddr := getLower(io.start_addr) and carry := true.B\
      \  not working!!\"\n325:   )\n326: \n327:   init_entry.isJalr := new_jmp_is_jalr\n\
      328:   init_entry.isCall := new_jmp_is_call\n329:   init_entry.isRet  := new_jmp_is_ret\n\
      330:   // that means fall thru points to the middle of an inst\n331:   init_entry.last_may_be_rvi_call
      := pd.jmpOffset === (PredictWidth - 1).U && !pd.rvcMask(pd.jmpOffset)\n332:\
      \ \n333:   // if hit, check whether a new cfi(only br is possible) is detected\n\
      334:   val oe              = io.old_entry"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 386-396
    context: "386:     // set jmp to invalid\n387:     old_entry_modified.pftAddr\
      \              := getLower(io.start_addr) + new_pft_offset\n388:     old_entry_modified.carry\
      \                := (getLower(io.start_addr) +& new_pft_offset).head(1).asBool\n\
      389:     old_entry_modified.last_may_be_rvi_call := false.B\n390:     old_entry_modified.isCall\
      \               := false.B\n391:     old_entry_modified.isRet              \
      \  := false.B\n392:     old_entry_modified.isJalr               := false.B\n\
      393:   }\n394: \n395:   val old_entry_jmp_target_modified = WireInit(oe)\n396:\
      \   val old_target      = oe.tailSlot.getTarget(io.start_addr) // may be wrong
      because we store only 20 lowest bits"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 447-457
    context: "447:     val ifuPtr_w           = Input(new FtqPtr)\n448:     val ifuPtrPlus1_w\
      \      = Input(new FtqPtr)\n449:     val ifuPtrPlus2_w      = Input(new FtqPtr)\n\
      450:     val pfPtr_w            = Input(new FtqPtr)\n451:     val pfPtrPlus1_w\
      \       = Input(new FtqPtr)\n452:     val commPtr_w          = Input(new FtqPtr)\n\
      453:     val commPtrPlus1_w     = Input(new FtqPtr)\n454:     val ifuPtr_rdata\
      \       = Output(new Ftq_RF_Components)\n455:     val ifuPtrPlus1_rdata  = Output(new
      Ftq_RF_Components)\n456:     val ifuPtrPlus2_rdata  = Output(new Ftq_RF_Components)\n\
      457:     val pfPtr_rdata        = Output(new Ftq_RF_Components)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 454-464
    context: "454:     val ifuPtr_rdata       = Output(new Ftq_RF_Components)\n455:\
      \     val ifuPtrPlus1_rdata  = Output(new Ftq_RF_Components)\n456:     val ifuPtrPlus2_rdata\
      \  = Output(new Ftq_RF_Components)\n457:     val pfPtr_rdata        = Output(new
      Ftq_RF_Components)\n458:     val pfPtrPlus1_rdata   = Output(new Ftq_RF_Components)\n\
      459:     val commPtr_rdata      = Output(new Ftq_RF_Components)\n460:     val
      commPtrPlus1_rdata = Output(new Ftq_RF_Components)\n461: \n462:     val wen\
      \   = Input(Bool())\n463:     val waddr = Input(UInt(log2Ceil(FtqSize).W))\n\
      464:     val wdata = Input(new Ftq_RF_Components)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 476-486
    context: "476:     io.ifuPtrPlus1_w.value,\n477:     io.ifuPtrPlus2_w.value,\n\
      478:     io.pfPtr_w.value,\n479:     io.pfPtrPlus1_w.value,\n480:     io.commPtrPlus1_w.value,\n\
      481:     io.commPtr_w.value\n482:   ))\n483: \n484:   mem.io.raddr := raddr_vec\n\
      485: \n486:   io.ifuPtr_rdata       := mem.io.rdata.dropRight(6).last"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 487-497
    context: "487:   io.ifuPtrPlus1_rdata  := mem.io.rdata.dropRight(5).last\n488:\
      \   io.ifuPtrPlus2_rdata  := mem.io.rdata.dropRight(4).last\n489:   io.pfPtr_rdata\
      \        := mem.io.rdata.dropRight(3).last\n490:   io.pfPtrPlus1_rdata   :=
      mem.io.rdata.dropRight(2).last\n491:   io.commPtrPlus1_rdata := mem.io.rdata.dropRight(1).last\n\
      492:   io.commPtr_rdata      := mem.io.rdata.last\n493: }\n494: \n495: class
      Ftq(implicit p: Parameters) extends XSModule with HasCircularQueuePtrHelper\n\
      496:     with HasBackendRedirectInfo with BPUUtils with HasBPUConst with HasPerfEvents\n\
      497:     with HasICacheParameters {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 510-520
    context: "510:     val bpuInfo = new Bundle {\n511:       val bpRight = Output(UInt(XLEN.W))\n\
      512:       val bpWrong = Output(UInt(XLEN.W))\n513:     }\n514: \n515:     val
      mmioCommitRead = Flipped(new mmioCommitRead)\n516: \n517:     // for perf\n\
      518:     val ControlBTBMissBubble = Output(Bool())\n519:     val TAGEMissBubble\
      \       = Output(Bool())\n520:     val SCMissBubble         = Output(Bool())"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 532-543
    context: "532: \n533:   // io.fromBackend.ftqIdxAhead: bju(BjuCnt) + ldReplay
      + exception\n534:   val ftqIdxAhead = VecInit(Seq.tabulate(FtqRedirectAheadNum)(i
      => io.fromBackend.ftqIdxAhead(i))) // only bju\n535:   val ftqIdxSelOH = io.fromBackend.ftqIdxSelOH.bits(FtqRedirectAheadNum
      - 1, 0)\n536: \n537:   val aheadValid         = ftqIdxAhead.map(_.valid).reduce(_
      | _) && !io.fromBackend.redirect.valid\n538:   val realAhdValid       = io.fromBackend.redirect.valid
      && (ftqIdxSelOH > 0.U) && RegNext(aheadValid)\n539:   val backendRedirect  \
      \  = Wire(Valid(new BranchPredictionRedirect))\n540:   val backendRedirectReg
      = Wire(Valid(new BranchPredictionRedirect))\n541:   backendRedirectReg.valid
      := RegNext(Mux(realAhdValid, false.B, backendRedirect.valid))\n542:   backendRedirectReg.bits\
      \  := RegEnable(backendRedirect.bits, backendRedirect.valid)\n543:   val fromBackendRedirect
      = Wire(Valid(new BranchPredictionRedirect))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 553-563
    context: "553:   val flushToIfu             = !allowToIfu\n554:   allowBpuIn :=
      !ifuFlush && !backendRedirect.valid && !backendRedirectReg.valid\n555:   allowToIfu
      := !ifuFlush && !backendRedirect.valid && !backendRedirectReg.valid\n556: \n\
      557:   def copyNum                                              = 5\n558:  \
      \ val bpuPtr, ifuPtr, pfPtr, ifuWbPtr, commPtr, robCommPtr = RegInit(FtqPtr(false.B,
      0.U))\n559:   val ifuPtrPlus1                                          = RegInit(FtqPtr(false.B,
      1.U))\n560:   val ifuPtrPlus2                                          = RegInit(FtqPtr(false.B,
      2.U))\n561:   val pfPtrPlus1                                           = RegInit(FtqPtr(false.B,
      1.U))\n562:   val commPtrPlus1                                         = RegInit(FtqPtr(false.B,
      1.U))\n563:   val copied_ifu_ptr                                       = Seq.fill(copyNum)(RegInit(FtqPtr(false.B,
      0.U)))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 567-577
    context: "567:   val ifuPtrPlus1_write  = WireInit(ifuPtrPlus1)\n568:   val ifuPtrPlus2_write\
      \  = WireInit(ifuPtrPlus2)\n569:   val pfPtr_write        = WireInit(pfPtr)\n\
      570:   val pfPtrPlus1_write   = WireInit(pfPtrPlus1)\n571:   val ifuWbPtr_write\
      \     = WireInit(ifuWbPtr)\n572:   val commPtr_write      = WireInit(commPtr)\n\
      573:   val commPtrPlus1_write = WireInit(commPtrPlus1)\n574:   val robCommPtr_write\
      \   = WireInit(robCommPtr)\n575:   ifuPtr       := ifuPtr_write\n576:   ifuPtrPlus1\
      \  := ifuPtrPlus1_write\n577:   ifuPtrPlus2  := ifuPtrPlus2_write"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 576-586
    context: "576:   ifuPtrPlus1  := ifuPtrPlus1_write\n577:   ifuPtrPlus2  := ifuPtrPlus2_write\n\
      578:   pfPtr        := pfPtr_write\n579:   pfPtrPlus1   := pfPtrPlus1_write\n\
      580:   ifuWbPtr     := ifuWbPtr_write\n581:   commPtr      := commPtr_write\n\
      582:   commPtrPlus1 := commPtrPlus1_write\n583:   copied_ifu_ptr.map { ptr =>\n\
      584:     ptr := ifuPtr_write\n585:     dontTouch(ptr)\n586:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 583-594
    context: "583:   copied_ifu_ptr.map { ptr =>\n584:     ptr := ifuPtr_write\n585:\
      \     dontTouch(ptr)\n586:   }\n587:   robCommPtr := robCommPtr_write\n588:\
      \   val validEntries = distanceBetween(bpuPtr, commPtr)\n589:   val canCommit\
      \    = Wire(Bool())\n590: \n591:   // Instruction page fault and instruction
      access fault are sent from backend with redirect requests.\n592:   // When IPF
      and IAF are sent, backendPcFaultIfuPtr points to the FTQ entry whose first instruction\n\
      593:   // raises IPF or IAF, which is ifuWbPtr_write or IfuPtr_write.\n594:\
      \   // Only when IFU has written back that FTQ entry can backendIpf and backendIaf
      be false because this"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 612-622
    context: "612:   }\n613: \n614:   // **********************************************************************\n\
      615:   // **************************** enq from bpu ****************************\n\
      616:   // **********************************************************************\n\
      617:   val new_entry_ready = validEntries < FtqSize.U || canCommit\n618:   io.fromBpu.resp.ready
      := new_entry_ready\n619: \n620:   val bpu_s2_resp     = io.fromBpu.resp.bits.s2\n\
      621:   val bpu_s3_resp     = io.fromBpu.resp.bits.s3\n622:   val bpu_s2_redirect
      = bpu_s2_resp.valid(3) && bpu_s2_resp.hasRedirect(3)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 648-658
    context: "648:   ))\n649:   // these info is intended to enq at the last stage
      of bpu\n650:   ftq_redirect_mem.io.wen(0)   := io.fromBpu.resp.bits.lastStage.valid(3)\n\
      651:   ftq_redirect_mem.io.waddr(0) := io.fromBpu.resp.bits.lastStage.ftq_idx.value\n\
      652:   ftq_redirect_mem.io.wdata(0) := io.fromBpu.resp.bits.last_stage_spec_info\n\
      653:   println(f\"ftq redirect MEM: entry ${ftq_redirect_mem.io.wdata(0).getWidth}
      * ${FtqSize} * 3\")\n654: \n655:   val ftq_meta_1r_sram = Module(new FtqNRSRAM(new
      Ftq_1R_SRAMEntry, 1))\n656:   // these info is intended to enq at the last stage
      of bpu\n657:   ftq_meta_1r_sram.io.wen             := io.fromBpu.resp.bits.lastStage.valid(3)\n\
      658:   ftq_meta_1r_sram.io.waddr           := io.fromBpu.resp.bits.lastStage.ftq_idx.value"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 680-690
    context: "680:   val cfiIndex_vec                 = Reg(Vec(FtqSize, ValidUndirectioned(UInt(log2Ceil(PredictWidth).W))))\n\
      681:   val mispredict_vec               = Reg(Vec(FtqSize, Vec(PredictWidth,
      Bool())))\n682:   val pred_stage                   = Reg(Vec(FtqSize, UInt(2.W)))\n\
      683:   val pred_s1_cycle                = if (!env.FPGAPlatform) Some(Reg(Vec(FtqSize,
      UInt(64.W)))) else None\n684: \n685:   val c_empty :: c_toCommit :: c_committed
      :: c_flushed :: Nil = Enum(4)\n686:   val commitStateQueueReg = RegInit(VecInit(Seq.fill(FtqSize)
      {\n687:     VecInit(Seq.fill(PredictWidth)(c_empty))\n688:   }))\n689:   val
      commitStateQueueEnable = WireInit(VecInit(Seq.fill(FtqSize)(false.B)))\n690:\
      \   val commitStateQueueNext   = WireInit(commitStateQueueReg)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 814-824
    context: "814:     }\n815:   }\n816: \n817:   XSError(isBefore(bpuPtr, ifuPtr)
      && !isFull(bpuPtr, ifuPtr), \"\\nifuPtr is before bpuPtr!\\n\")\n818:   XSError(isBefore(bpuPtr,
      pfPtr) && !isFull(bpuPtr, pfPtr), \"\\npfPtr is before bpuPtr!\\n\")\n819: \
      \  XSError(isBefore(ifuWbPtr, commPtr) && !isFull(ifuWbPtr, commPtr), \"\\ncommPtr
      is before ifuWbPtr!\\n\")\n820: \n821:   (0 until copyNum).map(i => XSError(copied_bpu_ptr(i)
      =/= bpuPtr, \"\\ncopiedBpuPtr is different from bpuPtr!\\n\"))\n822: \n823:\
      \   // ****************************************************************\n824:\
      \   // **************************** to ifu ****************************"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 838-848
    context: "838:   ftq_pc_mem.io.ifuPtr_w       := ifuPtr_write\n839:   ftq_pc_mem.io.ifuPtrPlus1_w\
      \  := ifuPtrPlus1_write\n840:   ftq_pc_mem.io.ifuPtrPlus2_w  := ifuPtrPlus2_write\n\
      841:   ftq_pc_mem.io.pfPtr_w        := pfPtr_write\n842:   ftq_pc_mem.io.pfPtrPlus1_w\
      \   := pfPtrPlus1_write\n843:   ftq_pc_mem.io.commPtr_w      := commPtr_write\n\
      844:   ftq_pc_mem.io.commPtrPlus1_w := commPtrPlus1_write\n845: \n846:   io.toIfu.req.bits.ftqIdx
      := ifuPtr\n847: \n848:   val toICachePcBundle               = Wire(Vec(copyNum,
      new Ftq_RF_Components))"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1008-1018
    context: "1008:       case (v, inRange) => v && inRange\n1009:     })\n1010: \
      \    commitStateQueueEnable(ifu_wb_idx) := true.B\n1011:     (commitStateQueueNext(ifu_wb_idx)
      zip comm_stq_wen).map {\n1012:       case (qe, v) => when(v) {\n1013:      \
      \     qe := c_toCommit\n1014:         }\n1015:     }\n1016:   }\n1017: \n1018:\
      \   when(ifu_wb_valid) {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1043-1053
    context: "1043:     val jmp_pd    = pd_reg(jmpOffset)\n1044:     val jal_false_hit
      = pred_ftb_entry.jmpValid &&\n1045:       ((pred_ftb_entry.isJal && !(jmp_pd.valid
      && jmp_pd.isJal)) ||\n1046:         (pred_ftb_entry.isJalr && !(jmp_pd.valid
      && jmp_pd.isJalr)) ||\n1047:         (pred_ftb_entry.isCall && !(jmp_pd.valid
      && jmp_pd.isCall)) ||\n1048:         (pred_ftb_entry.isRet && !(jmp_pd.valid
      && jmp_pd.isRet)))\n1049: \n1050:     has_false_hit := br_false_hit || jal_false_hit
      || hit_pd_mispred_reg\n1051:     // assert(!has_false_hit)\n1052:   }\n1053:\
      \   XSDebug("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1160-1170
    context: "1160:   ftq_redirect_mem.io.ren.get.head := fromIfuRedirect.valid\n\
      1161:   ftq_redirect_mem.io.raddr.head   := fromIfuRedirect.bits.ftqIdx.value\n\
      1162: \n1163:   val toBpuCfi = ifuRedirectToBpu.bits.cfiUpdate\n1164:   toBpuCfi.fromFtqRedirectSram(ftq_redirect_mem.io.rdata.head)\n\
      1165:   when(ifuRedirectReg.bits.cfiUpdate.pd.isRet && ifuRedirectReg.bits.cfiUpdate.pd.valid)
      {\n1166:     toBpuCfi.target := toBpuCfi.topAddr\n1167:   }\n1168: \n1169: \
      \  when(ifuRedirectReg.valid) {\n1170:     ifuRedirected(ifuRedirectReg.bits.ftqIdx.value)
      := true.B"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1189-1203
    context: "1189: \n1190:   // *********************************************************************\n\
      1191:   // **************************** wb from exu ****************************\n\
      1192:   // *********************************************************************\n\
      1193: \n1194:   backendRedirect.valid := io.fromBackend.redirect.valid\n1195:\
      \   backendRedirect.bits.connectRedirect(io.fromBackend.redirect.bits)\n1196:\
      \   backendRedirect.bits.BTBMissBubble := false.B\n1197: \n1198:   def extractRedirectInfo(wb:
      Valid[Redirect]) = {\n1199:     val ftqPtr    = wb.bits.ftqIdx\n1200:     val
      ftqOffset = wb.bits.ftqOffset\n1201:     val taken     = wb.bits.cfiUpdate.taken\n\
      1202:     val mispred   = wb.bits.cfiUpdate.isMisPred\n1203:     (wb.valid,
      ftqPtr, ftqOffset, taken, mispred)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1207-1218
    context: "1207:   val lastIsMispredict = RegNext(\n1208:     backendRedirect.valid
      && backendRedirect.bits.level === RedirectLevel.flushAfter,\n1209:     init
      = false.B\n1210:   )\n1211: \n1212:   def updateCfiInfo(redirect: Valid[Redirect],
      isBackend: Boolean = true) = {\n1213:     val (r_valid, r_ptr, r_offset, r_taken,
      r_mispred) = extractRedirectInfo(redirect)\n1214:     val r_idx            \
      \                              = r_ptr.value\n1215:     val cfiIndex_bits_wen\
      \                              = r_valid && r_taken && r_offset < cfiIndex_vec(r_idx).bits\n\
      1216:     val cfiIndex_valid_wen                             = r_valid && r_offset
      === cfiIndex_vec(r_idx).bits\n1217:     when(cfiIndex_bits_wen || cfiIndex_valid_wen)
      {\n1218:       cfiIndex_vec(r_idx).valid := cfiIndex_bits_wen || cfiIndex_valid_wen
      && r_taken"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1221-1235
    context: "1221:     }\n1222:     when(cfiIndex_bits_wen) {\n1223:       cfiIndex_vec(r_idx).bits
      := r_offset\n1224:     }\n1225:     newest_entry_target_modified := true.B\n\
      1226:     newest_entry_target          := redirect.bits.cfiUpdate.target\n1227:\
      \     newest_entry_ptr_modified    := true.B\n1228:     newest_entry_ptr   \
      \          := r_ptr\n1229: \n1230:     update_target(r_idx) := redirect.bits.cfiUpdate.target
      // TODO: remove this\n1231:     if (isBackend) {\n1232:       mispredict_vec(r_idx)(r_offset)
      := r_mispred\n1233:     }\n1234:   }\n1235: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1316-1348
    context: "1316:       }\n1317:     }\n1318:   }\n1319: \n1320:   // only the valid
      bit is actually needed\n1321:   io.toIfu.redirect.bits    := backendRedirect.bits\n\
      1322:   io.toIfu.redirect.valid   := stage2Flush\n1323:   io.toIfu.topdown_redirect
      := fromBackendRedirect\n1324: \n1325:   // commit\n1326:   for (c <- io.fromBackend.rob_commits)
      {\n1327:     when(c.valid) {\n1328:       commitStateQueueEnable(c.bits.ftqIdx.value)\
      \                 := true.B\n1329:       commitStateQueueNext(c.bits.ftqIdx.value)(c.bits.ftqOffset)
      := c_committed\n1330:       // TODO: remove this\n1331:       // For instruction
      fusions, we also update the next instruction\n1332:       when(c.bits.commitType
      === 4.U) {\n1333:         commitStateQueueNext(c.bits.ftqIdx.value)(c.bits.ftqOffset
      + 1.U) := c_committed\n1334:       }.elsewhen(c.bits.commitType === 5.U) {\n\
      1335:         commitStateQueueNext(c.bits.ftqIdx.value)(c.bits.ftqOffset + 2.U)
      := c_committed\n1336:       }.elsewhen(c.bits.commitType === 6.U) {\n1337: \
      \        val index = (c.bits.ftqIdx + 1.U).value\n1338:         commitStateQueueEnable(index)\
      \  := true.B\n1339:         commitStateQueueNext(index)(0) := c_committed\n\
      1340:       }.elsewhen(c.bits.commitType === 7.U) {\n1341:         val index
      = (c.bits.ftqIdx + 1.U).value\n1342:         commitStateQueueEnable(index) \
      \ := true.B\n1343:         commitStateQueueNext(index)(1) := c_committed\n1344:\
      \       }\n1345:     }\n1346:   }\n1347: \n1348:   // ****************************************************************"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1348-1361
    context: "1348:   // ****************************************************************\n\
      1349:   // **************************** to bpu ****************************\n\
      1350:   // ****************************************************************\n\
      1351: \n1352:   io.toBpu.redirctFromIFU := ifuRedirectToBpu.valid\n1353:   io.toBpu.redirect\
      \       := Mux(fromBackendRedirect.valid, fromBackendRedirect, ifuRedirectToBpu)\n\
      1354:   val dummy_s1_pred_cycle_vec = VecInit(List.tabulate(FtqSize)(_ => 0.U(64.W)))\n\
      1355:   val redirect_latency =\n1356:     GTimer() - pred_s1_cycle.getOrElse(dummy_s1_pred_cycle_vec)(io.toBpu.redirect.bits.ftqIdx.value)
      + 1.U\n1357:   XSPerfHistogram(\"backend_redirect_latency\", redirect_latency,
      fromBackendRedirect.valid, 0, 60, 1)\n1358:   XSPerfHistogram(\n1359:     \"\
      ifu_redirect_latency\",\n1360:     redirect_latency,\n1361:     !fromBackendRedirect.valid
      && ifuRedirectToBpu.valid,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1363-1374
    context: "1363:     60,\n1364:     1\n1365:   )\n1366: \n1367:   XSError(\n1368:\
      \     io.toBpu.redirect.valid && isBefore(io.toBpu.redirect.bits.ftqIdx, commPtr),\n\
      1369:     \"Ftq received a redirect after its commit, check backend or replay\"\
      \n1370:   )\n1371: \n1372:   val may_have_stall_from_bpu = Wire(Bool())\n1373:\
      \   val bpu_ftb_update_stall    = RegInit(0.U(2.W)) // 2-cycle stall, so we
      need 3 states\n1374:   may_have_stall_from_bpu := bpu_ftb_update_stall =/= 0.U"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1371-1399
    context: "1371: \n1372:   val may_have_stall_from_bpu = Wire(Bool())\n1373:  \
      \ val bpu_ftb_update_stall    = RegInit(0.U(2.W)) // 2-cycle stall, so we need
      3 states\n1374:   may_have_stall_from_bpu := bpu_ftb_update_stall =/= 0.U\n\
      1375: \n1376:   val validInstructions     = commitStateQueueReg(commPtr.value).map(s
      => s === c_toCommit || s === c_committed)\n1377:   val lastInstructionStatus
      = PriorityMux(validInstructions.reverse.zip(commitStateQueueReg(commPtr.value).reverse))\n\
      1378:   val firstInstructionFlushed = commitStateQueueReg(commPtr.value)(0)
      === c_flushed ||\n1379:     commitStateQueueReg(commPtr.value)(0) === c_empty
      && commitStateQueueReg(commPtr.value)(1) === c_flushed\n1380:   canCommit :=
      commPtr =/= ifuWbPtr && !may_have_stall_from_bpu &&\n1381:     (isAfter(robCommPtr,
      commPtr) ||\n1382:       validInstructions.reduce(_ || _) && lastInstructionStatus
      === c_committed)\n1383:   val canMoveCommPtr = commPtr =/= ifuWbPtr && !may_have_stall_from_bpu
      &&\n1384:     (isAfter(robCommPtr, commPtr) ||\n1385:       validInstructions.reduce(_
      || _) && lastInstructionStatus === c_committed ||\n1386:       firstInstructionFlushed)\n\
      1387: \n1388:   when(io.fromBackend.rob_commits.map(_.valid).reduce(_ | _))
      {\n1389:     robCommPtr_write := ParallelPriorityMux(\n1390:       io.fromBackend.rob_commits.map(_.valid).reverse,\n\
      1391:       io.fromBackend.rob_commits.map(_.bits.ftqIdx).reverse\n1392:   \
      \  )\n1393:   }.elsewhen(isAfter(commPtr, robCommPtr)) {\n1394:     robCommPtr_write
      := commPtr\n1395:   }.otherwise {\n1396:     robCommPtr_write := robCommPtr\n\
      1397:   }\n1398: \n1399:   /**"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1399-1464
    context: "1399:   /**\n1400:     *************************************************************************************\n\
      1401:     * MMIO instruction fetch is allowed only if MMIO is the oldest instruction.\n\
      1402:     *************************************************************************************\n\
      1403:     */\n1404:   val mmioReadPtr = io.mmioCommitRead.mmioFtqPtr\n1405:\
      \   val mmioLastCommit = isAfter(commPtr, mmioReadPtr) ||\n1406:     commPtr
      === mmioReadPtr && validInstructions.reduce(_ || _) && lastInstructionStatus
      === c_committed\n1407:   io.mmioCommitRead.mmioLastCommit := RegNext(mmioLastCommit)\n\
      1408: \n1409:   // commit reads\n1410:   val commit_pc_bundle = RegNext(ftq_pc_mem.io.commPtr_rdata)\n\
      1411:   val commit_target =\n1412:     Mux(\n1413:       RegNext(commPtr ===
      newest_entry_ptr),\n1414:       RegEnable(newest_entry_target, newest_entry_target_modified),\n\
      1415:       RegNext(ftq_pc_mem.io.commPtrPlus1_rdata.startAddr)\n1416:     )\n\
      1417:   ftq_pd_mem.io.ren.get.last := canCommit\n1418:   ftq_pd_mem.io.raddr.last\
      \   := commPtr.value\n1419:   val commit_pd = ftq_pd_mem.io.rdata.last\n1420:\
      \   ftq_redirect_mem.io.ren.get.last := canCommit\n1421:   ftq_redirect_mem.io.raddr.last\
      \   := commPtr.value\n1422:   val commit_spec_meta = ftq_redirect_mem.io.rdata.last\n\
      1423:   ftq_meta_1r_sram.io.ren(0)   := canCommit\n1424:   ftq_meta_1r_sram.io.raddr(0)
      := commPtr.value\n1425:   val commit_meta      = ftq_meta_1r_sram.io.rdata(0).meta\n\
      1426:   val commit_ftb_entry = ftq_meta_1r_sram.io.rdata(0).ftb_entry\n1427:\
      \ \n1428:   // need one cycle to read mem and srams\n1429:   val do_commit_ptr
      = RegEnable(commPtr, canCommit)\n1430:   val do_commit     = RegNext(canCommit,
      init = false.B)\n1431:   when(canMoveCommPtr) {\n1432:     commPtr_write   \
      \   := commPtrPlus1\n1433:     commPtrPlus1_write := commPtrPlus1 + 1.U\n1434:\
      \   }\n1435:   val commit_state   = RegEnable(commitStateQueueReg(commPtr.value),
      canCommit)\n1436:   val can_commit_cfi = WireInit(cfiIndex_vec(commPtr.value))\n\
      1437:   val do_commit_cfi  = WireInit(cfiIndex_vec(do_commit_ptr.value))\n1438:\
      \   //\n1439:   // when (commitStateQueue(commPtr.value)(can_commit_cfi.bits)
      =/= c_commited) {\n1440:   //  can_commit_cfi.valid := false.B\n1441:   // }\n\
      1442:   val commit_cfi = RegEnable(can_commit_cfi, canCommit)\n1443:   val debug_cfi\
      \  = commitStateQueueReg(do_commit_ptr.value)(do_commit_cfi.bits) =/= c_committed
      && do_commit_cfi.valid\n1444: \n1445:   val commit_mispredict: Vec[Bool] =\n\
      1446:     VecInit((RegEnable(mispredict_vec(commPtr.value), canCommit) zip commit_state).map
      {\n1447:       case (mis, state) => mis && state === c_committed\n1448:    \
      \ })\n1449:   val commit_instCommited: Vec[Bool] = VecInit(commit_state.map(_
      === c_committed)) // [PredictWidth]\n1450:   val can_commit_hit     = entry_hit_status(commPtr.value)\n\
      1451:   val commit_hit         = RegEnable(can_commit_hit, canCommit)\n1452:\
      \   val diff_commit_target = RegEnable(update_target(commPtr.value), canCommit)
      // TODO: remove this\n1453:   val commit_stage       = RegEnable(pred_stage(commPtr.value),
      canCommit)\n1454:   val commit_valid       = commit_hit === h_hit || commit_cfi.valid\
      \           // hit or taken\n1455: \n1456:   val to_bpu_hit = can_commit_hit
      === h_hit || can_commit_hit === h_false_hit\n1457:   switch(bpu_ftb_update_stall)
      {\n1458:     is(0.U) {\n1459:       when(can_commit_cfi.valid && !to_bpu_hit
      && canCommit) {\n1460:         bpu_ftb_update_stall := 2.U // 2-cycle stall\n\
      1461:       }\n1462:     }\n1463:     is(2.U) {\n1464:       bpu_ftb_update_stall
      := 1.U"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1471-1509
    context: "1471:     }\n1472:   }\n1473:   XSError(bpu_ftb_update_stall === 3.U,
      \"bpu_ftb_update_stall should be 0, 1 or 2\")\n1474: \n1475:   // TODO: remove
      this\n1476:   XSError(do_commit && diff_commit_target =/= commit_target, \"\\
      ncommit target should be the same as update target\\n\")\n1477: \n1478:   //
      update latency stats\n1479:   val update_latency = GTimer() - pred_s1_cycle.getOrElse(dummy_s1_pred_cycle_vec)(do_commit_ptr.value)
      + 1.U\n1480:   XSPerfHistogram(\"bpu_update_latency\", update_latency, io.toBpu.update.valid,
      0, 64, 2)\n1481: \n1482:   io.toBpu.update       := DontCare\n1483:   io.toBpu.update.valid
      := commit_valid && do_commit\n1484:   val update = io.toBpu.update.bits\n1485:\
      \   update.false_hit   := commit_hit === h_false_hit\n1486:   update.pc    \
      \      := commit_pc_bundle.startAddr\n1487:   update.meta        := commit_meta\n\
      1488:   update.cfi_idx     := commit_cfi\n1489:   update.full_target := commit_target\n\
      1490:   update.from_stage  := commit_stage\n1491:   update.spec_info   := commit_spec_meta\n\
      1492:   XSError(commit_valid && do_commit && debug_cfi, \"\\ncommit cfi can
      be non c_commited\\n\")\n1493: \n1494:   val commit_real_hit  = commit_hit ===
      h_hit\n1495:   val update_ftb_entry = update.ftb_entry\n1496: \n1497:   val
      ftbEntryGen = Module(new FTBEntryGen).io\n1498:   ftbEntryGen.start_addr   \
      \  := commit_pc_bundle.startAddr\n1499:   ftbEntryGen.old_entry      := commit_ftb_entry\n\
      1500:   ftbEntryGen.pd             := commit_pd\n1501:   ftbEntryGen.cfiIndex\
      \       := commit_cfi\n1502:   ftbEntryGen.target         := commit_target\n\
      1503:   ftbEntryGen.hit            := commit_real_hit\n1504:   ftbEntryGen.mispredict_vec
      := commit_mispredict\n1505: \n1506:   update_ftb_entry         := ftbEntryGen.new_entry\n\
      1507:   update.new_br_insert_pos := ftbEntryGen.new_br_insert_pos\n1508:   update.mispred_mask\
      \      := ftbEntryGen.mispred_mask\n1509:   update.old_entry         := ftbEntryGen.is_old_entry"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1505-1518
    context: "1505: \n1506:   update_ftb_entry         := ftbEntryGen.new_entry\n\
      1507:   update.new_br_insert_pos := ftbEntryGen.new_br_insert_pos\n1508:   update.mispred_mask\
      \      := ftbEntryGen.mispred_mask\n1509:   update.old_entry         := ftbEntryGen.is_old_entry\n\
      1510:   update.pred_hit          := commit_hit === h_hit || commit_hit === h_false_hit\n\
      1511:   update.br_taken_mask     := ftbEntryGen.taken_mask\n1512:   update.br_committed
      := (ftbEntryGen.new_entry.brValids zip ftbEntryGen.new_entry.brOffset) map {\n\
      1513:     case (valid, offset) => valid && commit_instCommited(offset)\n1514:\
      \   }\n1515:   update.jmp_taken := ftbEntryGen.jmp_taken\n1516: \n1517:   //
      update.full_pred.fromFtbEntry(ftbEntryGen.new_entry, update.pc)\n1518:   //
      update.full_pred.jalr_target := commit_target"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1523-1544
    context: "1523: \n1524:   // ******************************************************************************\n\
      1525:   // **************************** commit perf counters ****************************\n\
      1526:   // ******************************************************************************\n\
      1527: \n1528:   val commit_inst_mask        = VecInit(commit_state.map(c =>
      c === c_committed && do_commit)).asUInt\n1529:   val commit_mispred_mask   \
      \  = commit_mispredict.asUInt\n1530:   val commit_not_mispred_mask = ~commit_mispred_mask\n\
      1531: \n1532:   val commit_br_mask  = commit_pd.brMask.asUInt\n1533:   val commit_jmp_mask
      = UIntToOH(commit_pd.jmpOffset) & Fill(PredictWidth, commit_pd.jmpInfo.valid.asTypeOf(UInt(1.W)))\n\
      1534:   val commit_cfi_mask = commit_br_mask | commit_jmp_mask\n1535: \n1536:\
      \   val mbpInstrs = commit_inst_mask & commit_cfi_mask\n1537: \n1538:   val
      mbpRights = mbpInstrs & commit_not_mispred_mask\n1539:   val mbpWrongs = mbpInstrs
      & commit_mispred_mask\n1540: \n1541:   io.bpuInfo.bpRight := PopCount(mbpRights)\n\
      1542:   io.bpuInfo.bpWrong := PopCount(mbpWrongs)\n1543: \n1544:   val hartId\
      \           = p(XSCoreParamsKey).HartId"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1544-1564
    context: "1544:   val hartId           = p(XSCoreParamsKey).HartId\n1545:   val
      isWriteFTQTable  = Constantin.createRecord(s\"isWriteFTQTable$hartId\")\n1546:\
      \   val ftqBranchTraceDB = ChiselDB.createTable(s\"FTQTable$hartId\", new FtqDebugBundle)\n\
      1547:   // Cfi Info\n1548:   for (i <- 0 until PredictWidth) {\n1549:     val
      pc      = commit_pc_bundle.startAddr + (i * instBytes).U\n1550:     val v  \
      \     = commit_state(i) === c_committed\n1551:     val isBr    = commit_pd.brMask(i)\n\
      1552:     val isJmp   = commit_pd.jmpInfo.valid && commit_pd.jmpOffset === i.U\n\
      1553:     val isCfi   = isBr || isJmp\n1554:     val isTaken = commit_cfi.valid
      && commit_cfi.bits === i.U\n1555:     val misPred = commit_mispredict(i)\n1556:\
      \     // val ghist = commit_spec_meta.ghist.predHist\n1557:     val histPtr\
      \   = commit_spec_meta.histPtr\n1558:     val predCycle = commit_meta(63, 0)\n\
      1559:     val target    = commit_target\n1560: \n1561:     val brIdx = OHToUInt(Reverse(Cat(update_ftb_entry.brValids.zip(update_ftb_entry.brOffset).map
      { case (v, offset) =>\n1562:       v && offset === i.U\n1563:     })))\n1564:\
      \     val inFtbEntry = update_ftb_entry.brValids.zip(update_ftb_entry.brOffset).map
      { case (v, offset) =>"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1563-1578
    context: "1563:     })))\n1564:     val inFtbEntry = update_ftb_entry.brValids.zip(update_ftb_entry.brOffset).map
      { case (v, offset) =>\n1565:       v && offset === i.U\n1566:     }.reduce(_
      || _)\n1567:     val addIntoHist =\n1568:       ((commit_hit === h_hit) && inFtbEntry)
      || (!(commit_hit === h_hit) && i.U === commit_cfi.bits && isBr && commit_cfi.valid)\n\
      1569:     XSDebug(\n1570:       v && do_commit && isCfi,\n1571:       p\"cfi_update:
      isBr(${isBr}) pc(${Hexadecimal(pc)}) \" +\n1572:         p\"taken(${isTaken})
      mispred(${misPred}) cycle($predCycle) hist(${histPtr.value}) \" +\n1573:   \
      \      p\"startAddr(${Hexadecimal(commit_pc_bundle.startAddr)}) AddIntoHist(${addIntoHist})
      \" +\n1574:         p\"brInEntry(${inFtbEntry}) brIdx(${brIdx}) target(${Hexadecimal(target)})\\\
      n\"\n1575:     )\n1576: \n1577:     val logbundle = Wire(new FtqDebugBundle)\n\
      1578:     logbundle.pc        := pc"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1577-1595
    context: "1577:     val logbundle = Wire(new FtqDebugBundle)\n1578:     logbundle.pc\
      \        := pc\n1579:     logbundle.target    := target\n1580:     logbundle.isBr\
      \      := isBr\n1581:     logbundle.isJmp     := isJmp\n1582:     logbundle.isCall\
      \    := isJmp && commit_pd.hasCall\n1583:     logbundle.isRet     := isJmp &&
      commit_pd.hasRet\n1584:     logbundle.misPred   := misPred\n1585:     logbundle.isTaken\
      \   := isTaken\n1586:     logbundle.predStage := commit_stage\n1587: \n1588:\
      \     ftqBranchTraceDB.log(\n1589:       data = logbundle /* hardware of type
      T */,\n1590:       en = isWriteFTQTable.orR && v && do_commit && isCfi,\n1591:\
      \       site = \"FTQ\" + p(XSCoreParamsKey).HartId.toString,\n1592:       clock
      = clock,\n1593:       reset = reset\n1594:     )\n1595:   }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1608-1635
    context: "1608:   XSPerfAccumulate(\"to_ifu_stall\", io.toIfu.req.valid && !io.toIfu.req.ready)\n\
      1609:   XSPerfAccumulate(\"from_bpu_real_bubble\", !enq.valid && enq.ready &&
      allowBpuIn)\n1610:   XSPerfAccumulate(\"bpu_to_ifu_bubble\", bpuPtr === ifuPtr)\n\
      1611:   XSPerfAccumulate(\n1612:     \"bpu_to_ifu_bubble_when_ftq_full\",\n\
      1613:     (bpuPtr === ifuPtr) && isFull(bpuPtr, commPtr) && io.toIfu.req.ready\n\
      1614:   )\n1615: \n1616:   XSPerfAccumulate(\"redirectAhead_ValidNum\", ftqIdxAhead.map(_.valid).reduce(_
      | _))\n1617:   XSPerfAccumulate(\"fromBackendRedirect_ValidNum\", io.fromBackend.redirect.valid)\n\
      1618:   XSPerfAccumulate(\"toBpuRedirect_ValidNum\", io.toBpu.redirect.valid)\n\
      1619: \n1620:   val from_bpu = io.fromBpu.resp.bits\n1621:   val to_ifu   =
      io.toIfu.req.bits\n1622: \n1623:   XSPerfHistogram(\"commit_num_inst\", PopCount(commit_inst_mask),
      do_commit, 0, PredictWidth + 1, 1)\n1624: \n1625:   val commit_jal_mask  = UIntToOH(commit_pd.jmpOffset)
      & Fill(PredictWidth, commit_pd.hasJal.asTypeOf(UInt(1.W)))\n1626:   val commit_jalr_mask
      = UIntToOH(commit_pd.jmpOffset) & Fill(PredictWidth, commit_pd.hasJalr.asTypeOf(UInt(1.W)))\n\
      1627:   val commit_call_mask = UIntToOH(commit_pd.jmpOffset) & Fill(PredictWidth,
      commit_pd.hasCall.asTypeOf(UInt(1.W)))\n1628:   val commit_ret_mask  = UIntToOH(commit_pd.jmpOffset)
      & Fill(PredictWidth, commit_pd.hasRet.asTypeOf(UInt(1.W)))\n1629: \n1630:  \
      \ val mbpBRights = mbpRights & commit_br_mask\n1631:   val mbpJRights = mbpRights
      & commit_jal_mask\n1632:   val mbpIRights = mbpRights & commit_jalr_mask\n1633:\
      \   val mbpCRights = mbpRights & commit_call_mask\n1634:   val mbpRRights =
      mbpRights & commit_ret_mask\n1635: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1631-1641
    context: "1631:   val mbpJRights = mbpRights & commit_jal_mask\n1632:   val mbpIRights
      = mbpRights & commit_jalr_mask\n1633:   val mbpCRights = mbpRights & commit_call_mask\n\
      1634:   val mbpRRights = mbpRights & commit_ret_mask\n1635: \n1636:   val mbpBWrongs
      = mbpWrongs & commit_br_mask\n1637:   val mbpJWrongs = mbpWrongs & commit_jal_mask\n\
      1638:   val mbpIWrongs = mbpWrongs & commit_jalr_mask\n1639:   val mbpCWrongs
      = mbpWrongs & commit_call_mask\n1640:   val mbpRWrongs = mbpWrongs & commit_ret_mask\n\
      1641: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1637-1651
    context: "1637:   val mbpJWrongs = mbpWrongs & commit_jal_mask\n1638:   val mbpIWrongs
      = mbpWrongs & commit_jalr_mask\n1639:   val mbpCWrongs = mbpWrongs & commit_call_mask\n\
      1640:   val mbpRWrongs = mbpWrongs & commit_ret_mask\n1641: \n1642:   val commit_pred_stage
      = RegNext(pred_stage(commPtr.value))\n1643: \n1644:   def pred_stage_map(src:
      UInt, name: String) =\n1645:     (0 until numBpStages).map(i =>\n1646:     \
      \  f\"${name}_stage_${i + 1}\" -> PopCount(src.asBools.map(_ && commit_pred_stage
      === BP_STAGES(i)))\n1647:     ).foldLeft(Map[String, UInt]())(_ + _)\n1648:\
      \ \n1649:   val mispred_stage_map      = pred_stage_map(mbpWrongs, \"mispredict\"\
      )\n1650:   val br_mispred_stage_map   = pred_stage_map(mbpBWrongs, \"br_mispredict\"\
      )\n1651:   val jalr_mispred_stage_map = pred_stage_map(mbpIWrongs, \"jalr_mispredict\"\
      )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1655-1665
    context: "1655: \n1656:   val update_valid = io.toBpu.update.valid\n1657:   def
      u(cond: Bool) = update_valid && cond\n1658:   val ftb_false_hit = u(update.false_hit)\n\
      1659:   // assert(!ftb_false_hit)\n1660:   val ftb_hit = u(commit_hit === h_hit)\n\
      1661: \n1662:   val ftb_new_entry                = u(ftbEntryGen.is_init_entry)\n\
      1663:   val ftb_new_entry_only_br        = ftb_new_entry && !update_ftb_entry.jmpValid\n\
      1664:   val ftb_new_entry_only_jmp       = ftb_new_entry && !update_ftb_entry.brValids(0)\n\
      1665:   val ftb_new_entry_has_br_and_jmp = ftb_new_entry && update_ftb_entry.brValids(0)
      && update_ftb_entry.jmpValid"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1667-1677
    context: "1667:   val ftb_old_entry = u(ftbEntryGen.is_old_entry)\n1668: \n1669:\
      \   val ftb_modified_entry =\n1670:     u(ftbEntryGen.is_new_br || ftbEntryGen.is_jalr_target_modified
      || ftbEntryGen.is_strong_bias_modified)\n1671:   val ftb_modified_entry_new_br\
      \               = u(ftbEntryGen.is_new_br)\n1672:   val ftb_modified_entry_ifu_redirected\
      \       = u(ifuRedirected(do_commit_ptr.value))\n1673:   val ftb_modified_entry_jalr_target_modified
      = u(ftbEntryGen.is_jalr_target_modified)\n1674:   val ftb_modified_entry_br_full\
      \              = ftb_modified_entry && ftbEntryGen.is_br_full\n1675:   val ftb_modified_entry_strong_bias\
      \          = ftb_modified_entry && ftbEntryGen.is_strong_bias_modified\n1676:\
      \ \n1677:   def getFtbEntryLen(pc: UInt, entry: FTBEntry) = (entry.getFallThrough(pc)
      - pc) >> instOffsetBits"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1718-1729
    context: "1718:   }\n1719: \n1720:   // --------------------------- Debug --------------------------------\n\
      1721:   // XSDebug(enq_fire, p\"enq! \" + io.fromBpu.resp.bits.toPrintable)\n\
      1722:   XSDebug(io.toIfu.req.fire, p\"fire to ifu \" + io.toIfu.req.bits.toPrintable)\n\
      1723:   XSDebug(do_commit, p\"deq! [ptr] $do_commit_ptr\\n\")\n1724:   XSDebug(true.B,
      p\"[bpuPtr] $bpuPtr, [ifuPtr] $ifuPtr, [ifuWbPtr] $ifuWbPtr [commPtr] $commPtr\\\
      n\")\n1725:   XSDebug(\n1726:     true.B,\n1727:     p\"[in] v:${io.fromBpu.resp.valid}
      r:${io.fromBpu.resp.ready} \" +\n1728:       p\"[out] v:${io.toIfu.req.valid}
      r:${io.toIfu.req.ready}\\n\"\n1729:   )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/NewFtq.scala
    lines: 1725-1735
    context: "1725:   XSDebug(\n1726:     true.B,\n1727:     p\"[in] v:${io.fromBpu.resp.valid}
      r:${io.fromBpu.resp.ready} \" +\n1728:       p\"[out] v:${io.toIfu.req.valid}
      r:${io.toIfu.req.ready}\\n\"\n1729:   )\n1730:   XSDebug(do_commit, p\"[deq
      info] cfiIndex: $commit_cfi, $commit_pc_bundle, target: ${Hexadecimal(commit_target)}\\\
      n\")\n1731: \n1732:   //   def ubtbCheck(commit: FtqEntry, predAns: Seq[PredictorAnswer],
      isWrong: Bool) = {\n1733:   //     commit.valids.zip(commit.pd).zip(predAns).zip(commit.takens).map
      {\n1734:   //       case (((valid, pd), ans), taken) =>\n1735:   //       Mux(valid
      && pd.isBr,"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Tage.scala
    lines: 977-990
    context: "977:   // all should be ready for req\n978:   io.s1_ready := tables.map(_.io.req.ready).reduce(_
      && _) && bt.io.req.ready\n979:   XSPerfAccumulate(f\"tage_write_blocks_read\"\
      , !io.s1_ready)\n980: \n981:   def pred_perf(name:   String, cnt: UInt) = XSPerfAccumulate(s\"\
      ${name}_at_pred\", cnt)\n982:   def commit_perf(name: String, cnt: UInt) = XSPerfAccumulate(s\"\
      ${name}_at_commit\", cnt)\n983:   def tage_perf(name: String, pred_cnt: UInt,
      commit_cnt: UInt) = {\n984:     pred_perf(name, pred_cnt)\n985:     commit_perf(name,
      commit_cnt)\n986:   }\n987: \n988:   // Debug and perf info\n989:   for (b <-
      0 until TageBanks) {\n990:     val updateProvided = updateMeta.providers(b).valid"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/Tage.scala
    lines: 990-1005
    context: "990:     val updateProvided = updateMeta.providers(b).valid\n991:  \
      \   val updateProvider = updateMeta.providers(b).bits\n992:     for (i <- 0
      until TageNTables) {\n993:       val pred_i_provided =\n994:         s2_provideds(b)
      && s2_providers(b) === i.U\n995:       val commit_i_provided =\n996:       \
      \  updateProvided && updateProvider === i.U && updateValids(b)\n997:       tage_perf(\n\
      998:         s\"bank_${b}_tage_table_${i}_provided\",\n999:         PopCount(pred_i_provided),\n\
      1000:         PopCount(commit_i_provided)\n1001:       )\n1002:     }\n1003:\
      \     tage_perf(\n1004:       s\"bank_${b}_tage_use_bim\",\n1005:       PopCount(!s2_provideds(b)),"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 138-148
    context: "138: \n139: }\n140: \n141: class FTBEntry_part(implicit p: Parameters)
      extends XSBundle with FTBParams with BPUUtils {\n142:   val isCall = Bool()\n\
      143:   val isRet  = Bool()\n144:   val isJalr = Bool()\n145: \n146:   def isJal
      = !isJalr\n147: }\n148: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 367-377
    context: "367:       }\n368:     val tailSlotDiff         = this.tailSlot.slotConsistent(that.tailSlot)\n\
      369:     val pftAddrDiff          = this.pftAddr === that.pftAddr\n370:    \
      \ val carryDiff            = this.carry === that.carry\n371:     val isCallDiff\
      \           = this.isCall === that.isCall\n372:     val isRetDiff          \
      \  = this.isRet === that.isRet\n373:     val isJalrDiff           = this.isJalr
      === that.isJalr\n374:     val lastMayBeRviCallDiff = this.last_may_be_rvi_call
      === that.last_may_be_rvi_call\n375:     val alwaysTakenDiff: IndexedSeq[Bool]
      =\n376:       this.strong_bias.zip(that.strong_bias).map {\n377:         case
      (x, y) => x === y"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 404-414
    context: "404:       cond,\n405:       p\"[tailSlot]: v=${tailSlot.valid}, offset=${tailSlot.offset},\"\
      \ +\n406:         p\"lower=${Hexadecimal(tailSlot.lower)}, sharing=${tailSlot.sharing}}\\\
      n\"\n407:     )\n408:     XSDebug(cond, p\"pftAddr=${Hexadecimal(pftAddr)},
      carry=$carry\\n\")\n409:     XSDebug(cond, p\"isCall=$isCall, isRet=$isRet,
      isjalr=$isJalr\\n\")\n410:     XSDebug(cond, p\"last_may_be_rvi_call=$last_may_be_rvi_call\\\
      n\")\n411:     XSDebug(cond, p\"------------------------------- \\n\")\n412:\
      \   }\n413: \n414: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 810-820
    context: "810:   io.out.last_stage_ftb_entry := s3_ftb_entry_dup(0)\n811:   io.out.last_stage_meta\
      \      := RegEnable(Mux(s2_multi_hit_enable, s2_multi_hit_meta, s2_ftb_meta),
      io.s2_fire(0))\n812:   io.out.s1_ftbCloseReq       := s1_close_ftb_req\n813:\
      \   io.out.s1_uftbHit           := io.fauftb_entry_hit_in\n814:   val s1_uftbHasIndirect
      = io.fauftb_entry_in.jmpValid &&\n815:     io.fauftb_entry_in.isJalr && !io.fauftb_entry_in.isRet
      // uFTB determines that it's real JALR, RET and JAL are excluded\n816:   io.out.s1_uftbHasIndirect
      := s1_uftbHasIndirect\n817: \n818:   // always taken logic\n819:   for (i <-
      0 until numBr) {\n820:     for ("
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 894-905
    context: "894:   s2_ftb_entry_dup(0).display(true.B)\n895: \n896:   XSPerfAccumulate(\"\
      ftb_read_hits\", RegNext(io.s0_fire(0)) && s1_hit)\n897:   XSPerfAccumulate(\"\
      ftb_read_misses\", RegNext(io.s0_fire(0)) && !s1_hit)\n898: \n899:   XSPerfAccumulate(\"\
      ftb_commit_hits\", update_valid && u_meta.hit)\n900:   XSPerfAccumulate(\"ftb_commit_misses\"\
      , update_valid && !u_meta.hit)\n901: \n902:   XSPerfAccumulate(\"ftb_update_req\"\
      , update_valid)\n903:   XSPerfAccumulate(\"ftb_update_ignored\", update_valid
      && update.old_entry)\n904:   XSPerfAccumulate(\"ftb_updated\", u_valid)\n905:\
      \   XSPerfAccumulate(\"ftb_closing_update_counter\", s0_close_ftb_req && u_valid)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/FTB.scala
    lines: 903-912
    context: "903:   XSPerfAccumulate(\"ftb_update_ignored\", update_valid && update.old_entry)\n\
      904:   XSPerfAccumulate(\"ftb_updated\", u_valid)\n905:   XSPerfAccumulate(\"\
      ftb_closing_update_counter\", s0_close_ftb_req && u_valid)\n906: \n907:   override
      val perfEvents = Seq(\n908:     (\"ftb_commit_hits            \", update_valid
      && u_meta.hit),\n909:     (\"ftb_commit_misses          \", update_valid &&
      !u_meta.hit)\n910:   )\n911:   generatePerfEvent()\n912: }"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 74-87
    context: "74:   val icachePerfInfo  = Input(new ICachePerfInfo)\n75:   val toIbuffer\
      \       = Decoupled(new FetchToIBuffer)\n76:   val toBackend       = new IfuToBackendIO\n\
      77:   val uncacheInter    = new UncacheInterface\n78:   val frontendTrigger
      = Flipped(new FrontendTdataDistributeIO)\n79:   val rob_commits     = Flipped(Vec(CommitWidth,
      Valid(new RobCommitInfo)))\n80:   val iTLBInter       = new TlbRequestIO\n81:\
      \   val pmp             = new ICachePMPBundle\n82:   val mmioCommitRead  = new
      mmioCommitRead\n83:   val csr_fsIsOff     = Input(Bool())\n84: }\n85: \n86:
      // record the situation in which fallThruAddr falls into\n87: // the middle
      of an RVI inst"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 250-260
    context: "250:     fromFtq.flushFromBpu.shouldFlushByStage3(f0_ftq_req.ftqIdx)\n\
      251: \n252:   val wb_redirect, mmio_redirect, backend_redirect = WireInit(false.B)\n\
      253:   val f3_wb_not_flush                              = WireInit(false.B)\n\
      254: \n255:   backend_redirect := fromFtq.redirect.valid\n256:   f3_flush  \
      \       := backend_redirect || (wb_redirect && !f3_wb_not_flush)\n257:   f2_flush\
      \         := backend_redirect && mmio_redirect || wb_redirect\n258:   f1_flush\
      \         := f2_flush\n259:   f0_flush         := f1_flush || f0_flush_from_bpu\n\
      260: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 626-636
    context: "626:   f3Predecoder.io.in.instr := f3_instr\n627: \n628:   f3_pd.zipWithIndex.map
      { case (pd, i) =>\n629:     pd.brType := f3Predecoder.io.out.pd(i).brType\n\
      630:     pd.isCall := f3Predecoder.io.out.pd(i).isCall\n631:     pd.isRet  :=
      f3Predecoder.io.out.pd(i).isRet\n632:   }\n633: \n634:   val f3PdDiff = f3_pd_wire.zip(f3_pd).map
      { case (a, b) => a.asUInt =/= b.asUInt }.reduce(_ || _)\n635:   XSError(f3_valid
      && f3PdDiff, \"f3 pd diff\")\n636: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 653-665
    context: "653: \n654:   // last instuction finish\n655:   val is_first_instr =
      RegInit(true.B)\n656: \n657:   /*** Determine whether the MMIO instruction is
      executable based on the previous prediction block ***/\n658:   io.mmioCommitRead.mmioFtqPtr
      := RegNext(f3_ftq_req.ftqIdx - 1.U)\n659: \n660:   val m_idle :: m_waitLastCmt
      :: m_sendReq :: m_waitResp :: m_sendTLB :: m_tlbResp :: m_sendPMP :: m_resendReq
      :: m_waitResendResp :: m_waitCommit :: m_commited :: Nil =\n661:     Enum(11)\n\
      662:   val mmio_state = RegInit(m_idle)\n663: \n664:   // do mmio fetch only
      when pmp/pbmt shows it is a uncacheable address and no exception occurs\n665:\
      \   /* FIXME: we do not distinguish pbmt is NC or IO now"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 665-690
    context: "665:   /* FIXME: we do not distinguish pbmt is NC or IO now\n666:  \
      \  *        but we actually can do speculative execution if pbmt is NC, maybe
      fix this later for performance\n667:    */\n668:   val f3_req_is_mmio =\n669:\
      \     f3_valid && (f3_pmp_mmio || Pbmt.isUncache(f3_itlb_pbmt)) && !ExceptionType.hasException(f3_exception)\n\
      670:   val mmio_commit = VecInit(io.rob_commits.map { commit =>\n671:     commit.valid
      && commit.bits.ftqIdx === f3_ftq_req.ftqIdx && commit.bits.ftqOffset === 0.U\n\
      672:   }).asUInt.orR\n673:   val f3_mmio_req_commit = f3_req_is_mmio && mmio_state
      === m_commited\n674: \n675:   val f3_mmio_to_commit      = f3_req_is_mmio &&
      mmio_state === m_waitCommit\n676:   val f3_mmio_to_commit_next = RegNext(f3_mmio_to_commit)\n\
      677:   val f3_mmio_can_go         = f3_mmio_to_commit && !f3_mmio_to_commit_next\n\
      678: \n679:   val fromFtqRedirectReg = Wire(fromFtq.redirect.cloneType)\n680:\
      \   fromFtqRedirectReg.bits := RegEnable(\n681:     fromFtq.redirect.bits,\n\
      682:     0.U.asTypeOf(fromFtq.redirect.bits),\n683:     fromFtq.redirect.valid\n\
      684:   )\n685:   fromFtqRedirectReg.valid := RegNext(fromFtq.redirect.valid,
      init = false.B)\n686:   val mmioF3Flush           = RegNext(f3_flush, init =
      false.B)\n687:   val f3_ftq_flush_self     = fromFtqRedirectReg.valid && RedirectLevel.flushItself(fromFtqRedirectReg.bits.level)\n\
      688:   val f3_ftq_flush_by_older = fromFtqRedirectReg.valid && isBefore(fromFtqRedirectReg.bits.ftqIdx,
      f3_ftq_req.ftqIdx)\n689: \n690:   val f3_need_not_flush = f3_req_is_mmio &&
      fromFtqRedirectReg.valid && !f3_ftq_flush_self && !f3_ftq_flush_by_older"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 727-737
    context: "727: \n728:     is(m_waitLastCmt) {\n729:       when(is_first_instr)
      {\n730:         mmio_state := m_sendReq\n731:       }.otherwise {\n732:    \
      \     mmio_state := Mux(io.mmioCommitRead.mmioLastCommit, m_sendReq, m_waitLastCmt)\n\
      733:       }\n734:     }\n735: \n736:     is(m_sendReq) {\n737:       mmio_state
      := Mux(toUncache.fire, m_waitResp, m_sendReq)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 740-750
    context: "740:     is(m_waitResp) {\n741:       when(fromUncache.fire) {\n742:\
      \         val isRVC      = fromUncache.bits.data(1, 0) =/= 3.U\n743:       \
      \  val exception  = ExceptionType.fromTilelink(fromUncache.bits.corrupt)\n744:\
      \         val needResend = !isRVC && f3_paddrs(0)(2, 1) === 3.U && !ExceptionType.hasException(exception)\n\
      745:         mmio_state      := Mux(needResend, m_sendTLB, m_waitCommit)\n746:\
      \         mmio_exception  := exception\n747:         mmio_is_RVC     := isRVC\n\
      748:         mmio_has_resend := needResend\n749:         f3_mmio_data(0) :=
      fromUncache.bits.data(15, 0)\n750:         f3_mmio_data(1) := fromUncache.bits.data(31,
      16)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 766-776
    context: "766:           ExceptionType.af,\n767:           ExceptionType.none\n\
      768:         )\n769:         val exception = ExceptionType.merge(tlb_exception,
      pbmt_mismatch_exception)\n770:         // if tlb has exception, abort checking
      pmp, just send instr & exception to ibuffer and wait for commit\n771:      \
      \   mmio_state := Mux(ExceptionType.hasException(exception), m_waitCommit, m_sendPMP)\n\
      772:         // also save itlb response\n773:         mmio_exception       \
      \         := exception\n774:         mmio_resend_addr              := io.iTLBInter.resp.bits.paddr(0)\n\
      775:         mmio_resend_gpaddr            := io.iTLBInter.resp.bits.gpaddr(0)\n\
      776:         mmio_resend_isForVSnonLeafPTE := io.iTLBInter.resp.bits.isForVSnonLeafPTE(0)"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 785-795
    context: "785:         ExceptionType.af,\n786:         ExceptionType.none\n787:\
      \       )\n788:       val exception = ExceptionType.merge(pmp_exception, mmio_mismatch_exception)\n\
      789:       // if pmp has exception, abort sending request, just send instr &
      exception to ibuffer and wait for commit\n790:       mmio_state := Mux(ExceptionType.hasException(exception),
      m_waitCommit, m_resendReq)\n791:       // also save pmp response\n792:     \
      \  mmio_exception := exception\n793:     }\n794: \n795:     is(m_resendReq)
      {"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 796-806
    context: "796:       mmio_state := Mux(toUncache.fire, m_waitResendResp, m_resendReq)\n\
      797:     }\n798: \n799:     is(m_waitResendResp) {\n800:       when(fromUncache.fire)
      {\n801:         mmio_state      := m_waitCommit\n802:         mmio_exception\
      \  := ExceptionType.fromTilelink(fromUncache.bits.corrupt)\n803:         f3_mmio_data(1)
      := fromUncache.bits.data(15, 0)\n804:       }\n805:     }\n806: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 802-819
    context: "802:         mmio_exception  := ExceptionType.fromTilelink(fromUncache.bits.corrupt)\n\
      803:         f3_mmio_data(1) := fromUncache.bits.data(15, 0)\n804:       }\n\
      805:     }\n806: \n807:     is(m_waitCommit) {\n808:       // in idempotent
      spaces, we can skip waiting for commit (i.e. can do speculative fetch)\n809:\
      \       // but we do not skip m_waitCommit state, as other signals (e.g. f3_mmio_can_go
      relies on this)\n810:       mmio_state := Mux(mmio_commit || f3_itlb_pbmt ===
      Pbmt.nc, m_commited, m_waitCommit)\n811:     }\n812: \n813:     // normal mmio
      instruction\n814:     is(m_commited) {\n815:       mmio_state              \
      \      := m_idle\n816:       mmio_exception                := ExceptionType.none\n\
      817:       mmio_is_RVC                   := false.B\n818:       mmio_has_resend\
      \               := false.B\n819:       mmio_resend_addr              := 0.U"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 995-1005
    context: "995:   f3_mmio_missOffset.bits  := 0.U\n996: \n997:   // Send mmioFlushWb
      back to FTQ 1 cycle after uncache fetch return\n998:   // When backend redirect,
      mmio_state reset after 1 cycle.\n999:   // In this case, mask .valid to avoid
      overriding backend redirect\n1000:   mmioFlushWb.valid := (f3_req_is_mmio &&
      mmio_state === m_waitCommit && RegNext(fromUncache.fire) &&\n1001:     f3_mmio_use_seq_pc
      && !f3_ftq_flush_self && !f3_ftq_flush_by_older)\n1002:   mmioFlushWb.bits.pc
      := f3_pc\n1003:   mmioFlushWb.bits.pd := f3_pd\n1004:   mmioFlushWb.bits.pd.zipWithIndex.map
      { case (instr, i) => instr.valid := f3_mmio_range(i) }\n1005:   mmioFlushWb.bits.ftqIdx\
      \     := f3_ftq_req.ftqIdx"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 1016-1026
    context: "1016: \n1017:   /** external predecode for MMIO instruction */\n1018:\
      \   when(f3_req_is_mmio) {\n1019:     val inst = Cat(f3_mmio_data(1), f3_mmio_data(0))\n\
      1020: \n1021:     val brType :: isCall :: isRet :: Nil = brInfo(inst)\n1022:\
      \     val jalOffset                        = jal_offset(inst, mmio_is_RVC)\n\
      1023:     val brOffset                         = br_offset(inst, mmio_is_RVC)\n\
      1024: \n1025:     io.toIbuffer.bits.instrs(0) := Mux(mmioRVCExpander.io.ill,
      mmioRVCExpander.io.in, mmioRVCExpander.io.out.bits)\n1026: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 1026-1036
    context: "1026: \n1027:     io.toIbuffer.bits.pd(0).valid  := true.B\n1028:  \
      \   io.toIbuffer.bits.pd(0).isRVC  := mmio_is_RVC\n1029:     io.toIbuffer.bits.pd(0).brType
      := brType\n1030:     io.toIbuffer.bits.pd(0).isCall := isCall\n1031:     io.toIbuffer.bits.pd(0).isRet\
      \  := isRet\n1032: \n1033:     io.toIbuffer.bits.exceptionType(0) := mmio_exception\n\
      1034:     // exception can happens in next page only when resend\n1035:    \
      \ io.toIbuffer.bits.crossPageIPFFix(0) := mmio_has_resend && ExceptionType.hasException(mmio_exception)\n\
      1036:     io.toIbuffer.bits.illegalInstr(0)    := mmioRVCExpander.io.ill"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/frontend/IFU.scala
    lines: 1039-1052
    context: "1039: \n1040:     mmioFlushWb.bits.pd(0).valid  := true.B\n1041:   \
      \  mmioFlushWb.bits.pd(0).isRVC  := mmio_is_RVC\n1042:     mmioFlushWb.bits.pd(0).brType
      := brType\n1043:     mmioFlushWb.bits.pd(0).isCall := isCall\n1044:     mmioFlushWb.bits.pd(0).isRet\
      \  := isRet\n1045:   }\n1046: \n1047:   mmio_redirect := (f3_req_is_mmio &&
      mmio_state === m_waitCommit && RegNext(fromUncache.fire) && f3_mmio_use_seq_pc)\n\
      1048: \n1049:   XSPerfAccumulate(\"fetch_bubble_ibuffer_not_ready\", io.toIbuffer.valid
      && !io.toIbuffer.ready)\n1050: \n1051:   /**\n1052:     ******************************************************************************"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/PreDecode.scala
    lines: 35-46
    context: "35:   def brInfo(instr: UInt) = {\n36:     val brType :: Nil = ListLookup(instr,
      List(BrType.notCFI), PreDecodeInst.brTable)\n37:     val rd            = Mux(isRVC(instr),
      instr(12), instr(11, 7))\n38:     val rs            = Mux(isRVC(instr), Mux(brType
      === BrType.jal, 0.U, instr(11, 7)), instr(19, 15))\n39:     val isCall = (brType
      === BrType.jal && !isRVC(instr) || brType === BrType.jalr) && isLink(rd) //
      Only for RV64\n40:     val isRet  = brType === BrType.jalr && isLink(rs) &&
      !isCall\n41:     List(brType, isCall, isRet)\n42:   }\n43:   def jal_offset(inst:
      UInt, rvc: Bool): UInt = {\n44:     val rvc_offset = Cat(inst(12), inst(8),
      inst(10, 9), inst(6), inst(7), inst(2), inst(11), inst(5, 3), 0.U(1.W))\n45:\
      \     val rvi_offset = Cat(inst(31), inst(19, 12), inst(20), inst(30, 21), 0.U(1.W))\n\
      46:     val max_width  = rvi_offset.getWidth"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/PreDecode.scala
    lines: 72-82
    context: "72: class PreDecodeInfo extends Bundle { // 8 bit\n73:   val valid \
      \ = Bool()\n74:   val isRVC  = Bool()\n75:   val brType = UInt(2.W)\n76:   val
      isCall = Bool()\n77:   val isRet  = Bool()\n78:   // val excType = UInt(3.W)\n\
      79:   def isBr   = brType === BrType.branch\n80:   def isJal  = brType === BrType.jal\n\
      81:   def isJalr = brType === BrType.jalr\n82:   def notCFI = brType === BrType.notCFI"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/PreDecode.scala
    lines: 132-142
    context: "132:     // val expander       = Module(new RVCExpander)\n133:     currentIsRVC(i)
      := isRVC(inst)\n134:     val currentPC = io.in.bits.pc(i)\n135:     // expander.io.in\
      \             := inst\n136: \n137:     val brType :: isCall :: isRet :: Nil
      = brInfo(inst)\n138:     val jalOffset                        = jal_offset(inst,
      currentIsRVC(i))\n139:     val brOffset                         = br_offset(inst,
      currentIsRVC(i))\n140: \n141:     io.out.hasHalfValid(i) := h_validStart(i)\n\
      142: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/PreDecode.scala
    lines: 146-156
    context: "146:     io.out.pd(i).isRVC := currentIsRVC(i)\n147: \n148:     // for
      diff purpose only\n149:     io.out.pd(i).brType := brType\n150:     io.out.pd(i).isCall
      := isCall\n151:     io.out.pd(i).isRet  := isRet\n152: \n153:     // io.out.expInstr(i)\
      \         := expander.io.out.bits\n154:     io.out.instr(i)      := inst\n155:\
      \     io.out.jumpOffset(i) := Mux(io.out.pd(i).isBr, brOffset, jalOffset)\n\
      156:   }"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/PreDecode.scala
    lines: 249-259
    context: "249:       p\"instr ${Hexadecimal(io.out.instr(i))}, \" +\n250:    \
      \     p\"validStart ${Binary(validStart(i))}, \" +\n251:         p\"validEnd
      ${Binary(validEnd(i))}, \" +\n252:         p\"isRVC ${Binary(io.out.pd(i).isRVC)},
      \" +\n253:         p\"brType ${Binary(io.out.pd(i).brType)}, \" +\n254:    \
      \     p\"isRet ${Binary(io.out.pd(i).isRet)}, \" +\n255:         p\"isCall ${Binary(io.out.pd(i).isCall)}\\\
      n\"\n256:     )\n257:   }\n258: }\n259: "
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/PreDecode.scala
    lines: 272-282
    context: "272:   io.out.pd.zipWithIndex.map { case (pd, i) =>\n273:     pd.valid\
      \  := DontCare\n274:     pd.isRVC  := DontCare\n275:     pd.brType := brInfo(io.in.instr(i))(0)\n\
      276:     pd.isCall := brInfo(io.in.instr(i))(1)\n277:     pd.isRet  := brInfo(io.in.instr(i))(2)\n\
      278:   }\n279: \n280: }\n281: \n282: class RVCExpander(implicit p: Parameters)
      extends XSModule {"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/PreDecode.scala
    lines: 362-375
    context: "362:   /** first check: remask Fault */\n363:   jalFaultVec := VecInit(pds.zipWithIndex.map
      { case (pd, i) =>\n364:     pd.isJal && instrRange(i) && instrValid(i) && (takenIdx
      > i.U && predTaken || !predTaken)\n365:   })\n366:   jalrFaultVec := VecInit(pds.zipWithIndex.map
      { case (pd, i) =>\n367:     pd.isJalr && !pd.isRet && instrRange(i) && instrValid(i)
      && (takenIdx > i.U && predTaken || !predTaken)\n368:   })\n369:   retFaultVec
      := VecInit(pds.zipWithIndex.map { case (pd, i) =>\n370:     pd.isRet && instrRange(i)
      && instrValid(i) && (takenIdx > i.U && predTaken || !predTaken)\n371:   })\n\
      372:   val remaskFault = VecInit((0 until PredictWidth).map(i => jalFaultVec(i)
      || jalrFaultVec(i) || retFaultVec(i)))\n373:   val remaskIdx   = ParallelPriorityEncoder(remaskFault.asUInt)\n\
      374:   val needRemask  = ParallelOR(remaskFault)\n375:   val fixedRange  = instrRange.asUInt
      & (Fill(PredictWidth, !needRemask) | Fill(PredictWidth, 1.U(1.W)) >> ~remaskIdx)"
  - scala_file: 
      /code/XiangShan/src/main/scala/xiangshan/frontend/PreDecode.scala
    lines: 381-391
    context: "381:   )\n382: \n383:   io.out.stage1Out.fixedRange := fixedRange.asTypeOf(Vec(PredictWidth,
      Bool()))\n384: \n385:   io.out.stage1Out.fixedTaken := VecInit(pds.zipWithIndex.map
      { case (pd, i) =>\n386:     instrValid(i) && fixedRange(i) && (pd.isRet || pd.isJal
      || pd.isJalr || takenIdx === i.U && predTaken && !pd.notCFI)\n387:   })\n388:\
      \ \n389:   /** second check: faulse prediction fault and target fault */\n390:\
      \   notCFITaken := VecInit(pds.zipWithIndex.map { case (pd, i) =>\n391:    \
      \ fixedRange(i) && instrValid(i) && i.U === takenIdx && pd.notCFI && predTaken"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/L2Top.scala
    lines: 33-43
    context: "33: import top.BusPerfMonitor\n34: import utility._\n35: import utility.sram.SramBroadcastBundle\n\
      36: import xiangshan.cache.mmu.TlbRequestIO\n37: import xiangshan.backend.fu.PMPRespBundle\n\
      38: import xiangshan.backend.trace.{Itype, TraceCoreInterface}\n39: \n40: class
      L1BusErrorUnitInfo(implicit val p: Parameters) extends Bundle with HasSoCParameter
      {\n41:   val ecc_error = Valid(UInt(soc.PAddrBits.W))\n42: }\n43: "
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/L2Top.scala
    lines: 251-261
    context: "251:     val traceToTile = io.traceCoreInterface.toTile\n252:     val
      traceFromCore = io.traceCoreInterface.fromCore\n253:     traceFromCore.fromEncoder
      := RegNext(traceToTile.fromEncoder)\n254:     traceToTile.toEncoder.trap :=
      RegEnable(\n255:       traceFromCore.toEncoder.trap,\n256:       traceFromCore.toEncoder.groups(0).valid
      && Itype.isTrap(traceFromCore.toEncoder.groups(0).bits.itype)\n257:     )\n\
      258:     traceToTile.toEncoder.priv := RegEnable(\n259:       traceFromCore.toEncoder.priv,\n\
      260:       traceFromCore.toEncoder.groups(0).valid\n261:     )"
  - scala_file: /code/XiangShan/src/main/scala/xiangshan/L2Top.scala
    lines: 260-270
    context: "260:       traceFromCore.toEncoder.groups(0).valid\n261:     )\n262:\
      \     (0 until TraceGroupNum).foreach{ i =>\n263:       traceToTile.toEncoder.groups(i).valid
      := RegNext(traceFromCore.toEncoder.groups(i).valid)\n264:       traceToTile.toEncoder.groups(i).bits.iretire
      := RegNext(traceFromCore.toEncoder.groups(i).bits.iretire)\n265:       traceToTile.toEncoder.groups(i).bits.itype
      := RegNext(traceFromCore.toEncoder.groups(i).bits.itype)\n266:       traceToTile.toEncoder.groups(i).bits.ilastsize
      := RegEnable(\n267:         traceFromCore.toEncoder.groups(i).bits.ilastsize,\n\
      268:         traceFromCore.toEncoder.groups(i).valid\n269:       )\n270:   \
      \    traceToTile.toEncoder.groups(i).bits.iaddr := RegEnable("
